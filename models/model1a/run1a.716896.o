Slurm job ID: 716896
argfile: scripts/runargs/run1a.csv
args: Namespace(name='model1a', outdir='out/model_training/model1a', training_data='data/model_training_data_3', validation_data='data/model_training_data_3', nsims_training=None, nsims_validation=None, num_epochs=100, batch_size=50, ndims=2, nsigs=2, ncells=100, dt=0.1, signal_function='jump', phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus'], metric_final_act='None', metric_layer_normalize=False, infer_noise=True, sigma=0.01, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method='constant', init_metric_bias_args=[0.0], loss='mcd', continuation=None, optimizer='rms', learning_rate=0.001, momentum=0.9, weight_decay=0.0, infer_metric=False, plot=True, use_gpu=True, dtype='float32', seed=11, timestamp=False, save_all=True)
Using seed: 11

Training model...

Saving initial model state to: out/model_training/model1a/states/model1a_0.pth
EPOCH 1/100:
	Training over batches...
		[batch 100/100] loss: 2.483539874686591
	LOSS [training: 2.483539874686591 | validation: 0.3750282190662522]
	TIME [epoch: 43.4 sec]
	Saving model to: out/model_training/model1a/states/model1a_1.pth
	Model improved!!!
EPOCH 2/100:
	Training over batches...
		[batch 100/100] loss: 0.263361532986208
	LOSS [training: 0.263361532986208 | validation: 0.24905895111075627]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_2.pth
	Model improved!!!
EPOCH 3/100:
	Training over batches...
		[batch 100/100] loss: 0.23406119803181238
	LOSS [training: 0.23406119803181238 | validation: 0.21370888625301954]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model1a/states/model1a_3.pth
	Model improved!!!
EPOCH 4/100:
	Training over batches...
		[batch 100/100] loss: 0.22633383913078628
	LOSS [training: 0.22633383913078628 | validation: 0.23150744009380067]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_4.pth
EPOCH 5/100:
	Training over batches...
		[batch 100/100] loss: 0.22623321365431057
	LOSS [training: 0.22623321365431057 | validation: 0.24103208866411371]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_5.pth
EPOCH 6/100:
	Training over batches...
		[batch 100/100] loss: 0.23522590058293208
	LOSS [training: 0.23522590058293208 | validation: 0.21040685195987868]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_6.pth
	Model improved!!!
EPOCH 7/100:
	Training over batches...
		[batch 100/100] loss: 0.22881141239613823
	LOSS [training: 0.22881141239613823 | validation: 0.20395467774625597]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_7.pth
	Model improved!!!
EPOCH 8/100:
	Training over batches...
		[batch 100/100] loss: 0.19918511730693275
	LOSS [training: 0.19918511730693275 | validation: 0.22326684798575006]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_8.pth
EPOCH 9/100:
	Training over batches...
		[batch 100/100] loss: 0.05930272038385935
	LOSS [training: 0.05930272038385935 | validation: 0.02223070376073219]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_9.pth
	Model improved!!!
EPOCH 10/100:
	Training over batches...
		[batch 100/100] loss: 0.0357131620920783
	LOSS [training: 0.0357131620920783 | validation: 0.02010055844376233]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_10.pth
	Model improved!!!
EPOCH 11/100:
	Training over batches...
		[batch 100/100] loss: 0.04714724436172741
	LOSS [training: 0.04714724436172741 | validation: 0.027344136559315245]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_11.pth
EPOCH 12/100:
	Training over batches...
		[batch 100/100] loss: 0.06411214783978078
	LOSS [training: 0.06411214783978078 | validation: 0.03052550486362008]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_12.pth
EPOCH 13/100:
	Training over batches...
		[batch 100/100] loss: 0.042126783322500874
	LOSS [training: 0.042126783322500874 | validation: 0.046356473076013406]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_13.pth
EPOCH 14/100:
	Training over batches...
		[batch 100/100] loss: 0.04104877924453491
	LOSS [training: 0.04104877924453491 | validation: 0.03777079550317234]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_14.pth
EPOCH 15/100:
	Training over batches...
		[batch 100/100] loss: 0.030617538942295814
	LOSS [training: 0.030617538942295814 | validation: 0.02508827839774548]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_15.pth
EPOCH 16/100:
	Training over batches...
		[batch 100/100] loss: 0.029119919037134546
	LOSS [training: 0.029119919037134546 | validation: 0.036474693986921984]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_16.pth
EPOCH 17/100:
	Training over batches...
		[batch 100/100] loss: 0.025418985986133475
	LOSS [training: 0.025418985986133475 | validation: 0.015754993400124255]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_17.pth
	Model improved!!!
EPOCH 18/100:
	Training over batches...
		[batch 100/100] loss: 0.02466954195788571
	LOSS [training: 0.02466954195788571 | validation: 0.022013148813216744]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_18.pth
EPOCH 19/100:
	Training over batches...
		[batch 100/100] loss: 0.030562307831615763
	LOSS [training: 0.030562307831615763 | validation: 0.055321282164274004]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_19.pth
EPOCH 20/100:
	Training over batches...
		[batch 100/100] loss: 0.02812277231953543
	LOSS [training: 0.02812277231953543 | validation: 0.013855158313453953]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_20.pth
	Model improved!!!
EPOCH 21/100:
	Training over batches...
		[batch 100/100] loss: 0.0265547291039822
	LOSS [training: 0.0265547291039822 | validation: 0.03006370319661676]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_21.pth
EPOCH 22/100:
	Training over batches...
		[batch 100/100] loss: 0.029033128039840806
	LOSS [training: 0.029033128039840806 | validation: 0.052900607803964196]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_22.pth
EPOCH 23/100:
	Training over batches...
		[batch 100/100] loss: 0.05518827049443474
	LOSS [training: 0.05518827049443474 | validation: 0.043678372614487086]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_23.pth
EPOCH 24/100:
	Training over batches...
		[batch 100/100] loss: 0.05064232785341298
	LOSS [training: 0.05064232785341298 | validation: 0.045740258097104566]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_24.pth
EPOCH 25/100:
	Training over batches...
		[batch 100/100] loss: 0.023784294210472397
	LOSS [training: 0.023784294210472397 | validation: 0.019362700046974667]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_25.pth
EPOCH 26/100:
	Training over batches...
		[batch 100/100] loss: 0.024670955641662974
	LOSS [training: 0.024670955641662974 | validation: 0.029081132955411575]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_26.pth
EPOCH 27/100:
	Training over batches...
		[batch 100/100] loss: 0.018242080967927673
	LOSS [training: 0.018242080967927673 | validation: 0.0243125097148851]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_27.pth
EPOCH 28/100:
	Training over batches...
		[batch 100/100] loss: 0.03291977455107933
	LOSS [training: 0.03291977455107933 | validation: 0.03036680830692892]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_28.pth
EPOCH 29/100:
	Training over batches...
		[batch 100/100] loss: 0.032246779926820936
	LOSS [training: 0.032246779926820936 | validation: 0.01325746795224483]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_29.pth
	Model improved!!!
EPOCH 30/100:
	Training over batches...
		[batch 100/100] loss: 0.017442636148955422
	LOSS [training: 0.017442636148955422 | validation: 0.02330809887725122]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_30.pth
EPOCH 31/100:
	Training over batches...
		[batch 100/100] loss: 0.02481946527811125
	LOSS [training: 0.02481946527811125 | validation: 0.03907938709014187]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_31.pth
EPOCH 32/100:
	Training over batches...
		[batch 100/100] loss: 0.02970472881932433
	LOSS [training: 0.02970472881932433 | validation: 0.04815561206830714]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_32.pth
EPOCH 33/100:
	Training over batches...
		[batch 100/100] loss: 0.027271301494766864
	LOSS [training: 0.027271301494766864 | validation: 0.0142118740508086]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_33.pth
EPOCH 34/100:
	Training over batches...
		[batch 100/100] loss: 0.02256576932393104
	LOSS [training: 0.02256576932393104 | validation: 0.012440783107128792]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_34.pth
	Model improved!!!
EPOCH 35/100:
	Training over batches...
		[batch 100/100] loss: 0.0442534904892872
	LOSS [training: 0.0442534904892872 | validation: 0.06488799265830222]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_35.pth
EPOCH 36/100:
	Training over batches...
		[batch 100/100] loss: 0.02601945347422924
	LOSS [training: 0.02601945347422924 | validation: 0.013539045913893846]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_36.pth
EPOCH 37/100:
	Training over batches...
		[batch 100/100] loss: 0.019936940556500173
	LOSS [training: 0.019936940556500173 | validation: 0.01345731097554106]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_37.pth
EPOCH 38/100:
	Training over batches...
		[batch 100/100] loss: 0.017965824510345365
	LOSS [training: 0.017965824510345365 | validation: 0.029887376728704573]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_38.pth
EPOCH 39/100:
	Training over batches...
		[batch 100/100] loss: 0.02170391683384256
	LOSS [training: 0.02170391683384256 | validation: 0.03141858193666405]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_39.pth
EPOCH 40/100:
	Training over batches...
		[batch 100/100] loss: 0.020279490221294858
	LOSS [training: 0.020279490221294858 | validation: 0.013555267405462167]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_40.pth
EPOCH 41/100:
	Training over batches...
		[batch 100/100] loss: 0.01610624617584561
	LOSS [training: 0.01610624617584561 | validation: 0.011868701761314488]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_41.pth
	Model improved!!!
EPOCH 42/100:
	Training over batches...
		[batch 100/100] loss: 0.020945805760879687
	LOSS [training: 0.020945805760879687 | validation: 0.014943229043714645]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_42.pth
EPOCH 43/100:
	Training over batches...
		[batch 100/100] loss: 0.013679647830976133
	LOSS [training: 0.013679647830976133 | validation: 0.01583335861051287]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_43.pth
EPOCH 44/100:
	Training over batches...
		[batch 100/100] loss: 0.015478681075321998
	LOSS [training: 0.015478681075321998 | validation: 0.015145946316815938]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_44.pth
EPOCH 45/100:
	Training over batches...
		[batch 100/100] loss: 0.015875587564268573
	LOSS [training: 0.015875587564268573 | validation: 0.011219813302780773]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_45.pth
	Model improved!!!
EPOCH 46/100:
	Training over batches...
		[batch 100/100] loss: 0.02457182080770112
	LOSS [training: 0.02457182080770112 | validation: 0.02754562909944016]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_46.pth
EPOCH 47/100:
	Training over batches...
		[batch 100/100] loss: 0.022959382504882112
	LOSS [training: 0.022959382504882112 | validation: 0.01944210821347718]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_47.pth
EPOCH 48/100:
	Training over batches...
		[batch 100/100] loss: 0.01395038825797287
	LOSS [training: 0.01395038825797287 | validation: 0.010733474880405103]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_48.pth
	Model improved!!!
EPOCH 49/100:
	Training over batches...
		[batch 100/100] loss: 0.01802895293749348
	LOSS [training: 0.01802895293749348 | validation: 0.01572543783118224]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_49.pth
EPOCH 50/100:
	Training over batches...
		[batch 100/100] loss: 0.018549112082277924
	LOSS [training: 0.018549112082277924 | validation: 0.029382717185824164]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_50.pth
EPOCH 51/100:
	Training over batches...
		[batch 100/100] loss: 0.01758078369218447
	LOSS [training: 0.01758078369218447 | validation: 0.012897067787656157]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_51.pth
EPOCH 52/100:
	Training over batches...
		[batch 100/100] loss: 0.0155129221529399
	LOSS [training: 0.0155129221529399 | validation: 0.01336890495980758]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_52.pth
EPOCH 53/100:
	Training over batches...
		[batch 100/100] loss: 0.01775370178946452
	LOSS [training: 0.01775370178946452 | validation: 0.019288281447682843]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_53.pth
EPOCH 54/100:
	Training over batches...
		[batch 100/100] loss: 0.01777591847928597
	LOSS [training: 0.01777591847928597 | validation: 0.025842150030748304]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_54.pth
EPOCH 55/100:
	Training over batches...
		[batch 100/100] loss: 0.02167003408228241
	LOSS [training: 0.02167003408228241 | validation: 0.021025375790763755]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_55.pth
EPOCH 56/100:
	Training over batches...
		[batch 100/100] loss: 0.024663376815644823
	LOSS [training: 0.024663376815644823 | validation: 0.04217947277571133]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_56.pth
EPOCH 57/100:
	Training over batches...
		[batch 100/100] loss: 0.017364939514313064
	LOSS [training: 0.017364939514313064 | validation: 0.028540478565765855]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_57.pth
EPOCH 58/100:
	Training over batches...
		[batch 100/100] loss: 0.01814547601229792
	LOSS [training: 0.01814547601229792 | validation: 0.02372737482823936]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_58.pth
EPOCH 59/100:
	Training over batches...
		[batch 100/100] loss: 2.2747235236177783
	LOSS [training: 2.2747235236177783 | validation: 4.581286980373084]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_59.pth
EPOCH 60/100:
	Training over batches...
		[batch 100/100] loss: 36.176063105905094
	LOSS [training: 36.176063105905094 | validation: 323.8820317087482]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_60.pth
EPOCH 61/100:
	Training over batches...
		[batch 100/100] loss: 70.2950206333036
	LOSS [training: 70.2950206333036 | validation: 41.532065338856725]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_61.pth
EPOCH 62/100:
	Training over batches...
		[batch 100/100] loss: 121.94873461427376
	LOSS [training: 121.94873461427376 | validation: 63.6333532453439]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_62.pth
EPOCH 63/100:
	Training over batches...
		[batch 100/100] loss: 5.711481668431029
	LOSS [training: 5.711481668431029 | validation: 5.50870874304009]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_63.pth
EPOCH 64/100:
	Training over batches...
		[batch 100/100] loss: 10.098580256655357
	LOSS [training: 10.098580256655357 | validation: 14.79303242076845]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_64.pth
EPOCH 65/100:
	Training over batches...
		[batch 100/100] loss: 14.84995077896193
	LOSS [training: 14.84995077896193 | validation: 7.172925001782962]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_65.pth
EPOCH 66/100:
	Training over batches...
		[batch 100/100] loss: 7.035801421339549
	LOSS [training: 7.035801421339549 | validation: 1.4979686244406754]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_66.pth
EPOCH 67/100:
	Training over batches...
		[batch 100/100] loss: 9.734656164069209
	LOSS [training: 9.734656164069209 | validation: 27.409503847680547]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_67.pth
EPOCH 68/100:
	Training over batches...
		[batch 100/100] loss: 48.833778409705246
	LOSS [training: 48.833778409705246 | validation: 92.42281027489241]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_68.pth
EPOCH 69/100:
	Training over batches...
		[batch 100/100] loss: 45.81376813510143
	LOSS [training: 45.81376813510143 | validation: 22.71829379128425]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_69.pth
EPOCH 70/100:
	Training over batches...
		[batch 100/100] loss: 9.208048703885872
	LOSS [training: 9.208048703885872 | validation: 33.909006544650225]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_70.pth
EPOCH 71/100:
	Training over batches...
		[batch 100/100] loss: 40.55621539633471
	LOSS [training: 40.55621539633471 | validation: 18.398717104893674]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_71.pth
EPOCH 72/100:
	Training over batches...
		[batch 100/100] loss: 12.014422626940565
	LOSS [training: 12.014422626940565 | validation: 21.02116992684777]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_72.pth
EPOCH 73/100:
	Training over batches...
		[batch 100/100] loss: 34.98021989948934
	LOSS [training: 34.98021989948934 | validation: 39.31945349853675]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_73.pth
EPOCH 74/100:
	Training over batches...
		[batch 100/100] loss: 61.35170286961933
	LOSS [training: 61.35170286961933 | validation: 52.36530752960518]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_74.pth
EPOCH 75/100:
	Training over batches...
		[batch 100/100] loss: 65.8469687881232
	LOSS [training: 65.8469687881232 | validation: 2.64838707214404]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_75.pth
EPOCH 76/100:
	Training over batches...
		[batch 100/100] loss: 59.815380208887674
	LOSS [training: 59.815380208887674 | validation: 11.154640854509033]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_76.pth
EPOCH 77/100:
	Training over batches...
		[batch 100/100] loss: 11.199789046210597
	LOSS [training: 11.199789046210597 | validation: 13.105996269874971]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_77.pth
EPOCH 78/100:
	Training over batches...
		[batch 100/100] loss: 8.22193382657463
	LOSS [training: 8.22193382657463 | validation: 46.26531641337972]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_78.pth
EPOCH 79/100:
	Training over batches...
		[batch 100/100] loss: 963.3500935634447
	LOSS [training: 963.3500935634447 | validation: 2758.1768313173343]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_79.pth
EPOCH 80/100:
	Training over batches...
		[batch 100/100] loss: 782.3530767447788
	LOSS [training: 782.3530767447788 | validation: 921.235145590058]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_80.pth
EPOCH 81/100:
	Training over batches...
		[batch 100/100] loss: 3187.894717249682
	LOSS [training: 3187.894717249682 | validation: 1713.2932102675377]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_81.pth
EPOCH 82/100:
	Training over batches...
		[batch 100/100] loss: 1952.7376845098372
	LOSS [training: 1952.7376845098372 | validation: 3097.9945405209637]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_82.pth
EPOCH 83/100:
	Training over batches...
		[batch 100/100] loss: 818.238004964517
	LOSS [training: 818.238004964517 | validation: 83.35760395277073]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_83.pth
EPOCH 84/100:
	Training over batches...
		[batch 100/100] loss: 34.58466488872472
	LOSS [training: 34.58466488872472 | validation: 70.08643942793542]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_84.pth
EPOCH 85/100:
	Training over batches...
		[batch 100/100] loss: 14.525047624836727
	LOSS [training: 14.525047624836727 | validation: 5.225891943612404]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_85.pth
EPOCH 86/100:
	Training over batches...
		[batch 100/100] loss: 3.6428031501345752
	LOSS [training: 3.6428031501345752 | validation: 3.728387231302256]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_86.pth
EPOCH 87/100:
	Training over batches...
		[batch 100/100] loss: 2.3561398122112274
	LOSS [training: 2.3561398122112274 | validation: 3.435133891470419]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_87.pth
EPOCH 88/100:
	Training over batches...
		[batch 100/100] loss: 41.84318370349008
	LOSS [training: 41.84318370349008 | validation: 211.06658156589822]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model1a/states/model1a_88.pth
EPOCH 89/100:
	Training over batches...
		[batch 100/100] loss: 24.59585574723129
	LOSS [training: 24.59585574723129 | validation: 10.684942930344603]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_89.pth
EPOCH 90/100:
	Training over batches...
		[batch 100/100] loss: 9.939067726219855
	LOSS [training: 9.939067726219855 | validation: 4.9393326865096165]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_90.pth
EPOCH 91/100:
	Training over batches...
		[batch 100/100] loss: 10.294901162494858
	LOSS [training: 10.294901162494858 | validation: 11.476748050492679]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_91.pth
EPOCH 92/100:
	Training over batches...
		[batch 100/100] loss: 1.6565246959614996
	LOSS [training: 1.6565246959614996 | validation: 1.111283553521644]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_92.pth
EPOCH 93/100:
	Training over batches...
		[batch 100/100] loss: 1.207099470983547
	LOSS [training: 1.207099470983547 | validation: 1.6588637460359967]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_93.pth
EPOCH 94/100:
	Training over batches...
		[batch 100/100] loss: 10.528940983729546
	LOSS [training: 10.528940983729546 | validation: 11.11843518453874]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_94.pth
EPOCH 95/100:
	Training over batches...
		[batch 100/100] loss: 24.76222561904629
	LOSS [training: 24.76222561904629 | validation: 123.6267042581581]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_95.pth
EPOCH 96/100:
	Training over batches...
		[batch 100/100] loss: 496.48122479289884
	LOSS [training: 496.48122479289884 | validation: 635.7419243939289]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_96.pth
EPOCH 97/100:
	Training over batches...
		[batch 100/100] loss: 140.18356260255499
	LOSS [training: 140.18356260255499 | validation: 164.34220657250523]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_97.pth
EPOCH 98/100:
	Training over batches...
		[batch 100/100] loss: 278.0770169576072
	LOSS [training: 278.0770169576072 | validation: 31.61695367108569]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_98.pth
EPOCH 99/100:
	Training over batches...
		[batch 100/100] loss: 1593.1137463630075
	LOSS [training: 1593.1137463630075 | validation: 3083.253187117524]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model1a/states/model1a_99.pth
EPOCH 100/100:
	Training over batches...
		[batch 100/100] loss: 3093.993724350333
	LOSS [training: 3093.993724350333 | validation: 10287.10866607975]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model1a/states/model1a_100.pth
Finished training in 1677.770 seconds.
