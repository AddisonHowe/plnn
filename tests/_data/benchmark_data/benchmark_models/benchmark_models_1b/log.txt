Args:
Namespace(name='model_benchmark_1b', outdir='tests/_data/benchmark_data/benchmark_models', training_data='tests/_data/benchmark_data/benchmark_data_1b/training', validation_data='tests/_data/benchmark_data/benchmark_data_1b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=20, batch_size=100, report_every=1, ndims=2, nparams=2, nsigs=2, ncells=100, dt=0.01, signal_function='sigmoid', solver='heun', confine=True, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1158324717

Training model...

Saving initial model state to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_0.pth
EPOCH 1/20:
	Training over batches...
		[batch 1/5] avg loss: 11.231002338423341		[learning rate: 0.01]
		[batch 2/5] avg loss: 11.424047747775198		[learning rate: 0.01]
		[batch 3/5] avg loss: 11.26714080117786		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.922102635664455		[learning rate: 0.01]
		[batch 5/5] avg loss: 11.209138954988894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.210686495605952 | validation: 11.226176699295603]
	TIME [epoch: 73 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_1.pth
	Model improved!!!
EPOCH 2/20:
	Training over batches...
		[batch 1/5] avg loss: 10.418539138618351		[learning rate: 0.01]
		[batch 2/5] avg loss: 11.69418818231084		[learning rate: 0.01]
		[batch 3/5] avg loss: 11.672631464976584		[learning rate: 0.01]
		[batch 4/5] avg loss: 11.610522336342878		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.634740788101945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.206124382070119 | validation: 11.185554932735052]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_2.pth
	Model improved!!!
EPOCH 3/20:
	Training over batches...
		[batch 1/5] avg loss: 11.077353054710134		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.680261558949152		[learning rate: 0.01]
		[batch 3/5] avg loss: 10.692062945225302		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.422795511975792		[learning rate: 0.01]
		[batch 5/5] avg loss: 9.538334729930593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.482161560158195 | validation: 11.10883412261683]
	TIME [epoch: 41.6 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_3.pth
	Model improved!!!
EPOCH 4/20:
	Training over batches...
		[batch 1/5] avg loss: 10.87738008144448		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.72238688378742		[learning rate: 0.01]
		[batch 3/5] avg loss: 9.979081710008156		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.57021618475084		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.22777245731456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.475367463461092 | validation: 11.121380380290555]
	TIME [epoch: 41.7 sec]
EPOCH 5/20:
	Training over batches...
		[batch 1/5] avg loss: 10.73146291853954		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.905861200562292		[learning rate: 0.01]
		[batch 3/5] avg loss: 11.012734048389117		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.835873322257422		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.982922752327424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.89377084841516 | validation: 11.10616556651951]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_5.pth
	Model improved!!!
EPOCH 6/20:
	Training over batches...
		[batch 1/5] avg loss: 10.437934446076772		[learning rate: 0.01]
		[batch 2/5] avg loss: 9.945682936631808		[learning rate: 0.01]
		[batch 3/5] avg loss: 10.888783824734567		[learning rate: 0.01]
		[batch 4/5] avg loss: 9.943062211982555		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.763795475050236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.395851778895189 | validation: 11.070759490135261]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_6.pth
	Model improved!!!
EPOCH 7/20:
	Training over batches...
		[batch 1/5] avg loss: 10.221921650923175		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.132402195991373		[learning rate: 0.01]
		[batch 3/5] avg loss: 11.045021784044797		[learning rate: 0.01]
		[batch 4/5] avg loss: 9.85225151196749		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.284153545799184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.307150137745204 | validation: 10.951868404656288]
	TIME [epoch: 41.6 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_7.pth
	Model improved!!!
EPOCH 8/20:
	Training over batches...
		[batch 1/5] avg loss: 10.021713448118422		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.530796445793175		[learning rate: 0.01]
		[batch 3/5] avg loss: 9.94629668343345		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.41428087300254		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.144687115051465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.211554913079812 | validation: 10.852007968470428]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_8.pth
	Model improved!!!
EPOCH 9/20:
	Training over batches...
		[batch 1/5] avg loss: 10.3276142817654		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.29365129386275		[learning rate: 0.01]
		[batch 3/5] avg loss: 9.341527554877343		[learning rate: 0.01]
		[batch 4/5] avg loss: 10.636465650786104		[learning rate: 0.01]
		[batch 5/5] avg loss: 10.436478771748712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.207147510608062 | validation: 11.016684331363848]
	TIME [epoch: 41.6 sec]
EPOCH 10/20:
	Training over batches...
		[batch 1/5] avg loss: 10.871675283452696		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.32538611518995		[learning rate: 0.01]
		[batch 3/5] avg loss: 9.93219107066895		[learning rate: 0.01]
		[batch 4/5] avg loss: 9.80723251048488		[learning rate: 0.01]
		[batch 5/5] avg loss: 9.747230043631166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.136743004685528 | validation: 10.644545252057853]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_10.pth
	Model improved!!!
EPOCH 11/20:
	Training over batches...
		[batch 1/5] avg loss: 8.839843071848		[learning rate: 0.01]
		[batch 2/5] avg loss: 10.66153461347735		[learning rate: 0.0095499]
		[batch 3/5] avg loss: 9.286794454494048		[learning rate: 0.0091201]
		[batch 4/5] avg loss: 10.128899787335504		[learning rate: 0.0087096]
		[batch 5/5] avg loss: 10.1069137769767		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 9.80479714082632 | validation: 10.626127461090622]
	TIME [epoch: 41.7 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_11.pth
	Model improved!!!
EPOCH 12/20:
	Training over batches...
		[batch 1/5] avg loss: 9.13571841174718		[learning rate: 0.0079433]
		[batch 2/5] avg loss: 9.022617474216899		[learning rate: 0.0075858]
		[batch 3/5] avg loss: 9.807743380675763		[learning rate: 0.0072444]
		[batch 4/5] avg loss: 9.749097251798336		[learning rate: 0.0069183]
		[batch 5/5] avg loss: 9.653899533189811		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 9.473815210325597 | validation: 10.751533167780648]
	TIME [epoch: 41.8 sec]
EPOCH 13/20:
	Training over batches...
		[batch 1/5] avg loss: 9.118108440515615		[learning rate: 0.0063096]
		[batch 2/5] avg loss: 10.067056456151596		[learning rate: 0.0060256]
		[batch 3/5] avg loss: 8.92043321775344		[learning rate: 0.0057544]
		[batch 4/5] avg loss: 9.494949911384529		[learning rate: 0.0054954]
		[batch 5/5] avg loss: 9.987800214799865		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 9.517669648121009 | validation: 10.586755911782127]
	TIME [epoch: 41.8 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_13.pth
	Model improved!!!
EPOCH 14/20:
	Training over batches...
		[batch 1/5] avg loss: 9.659890306701694		[learning rate: 0.0050119]
		[batch 2/5] avg loss: 9.319554139500363		[learning rate: 0.0047863]
		[batch 3/5] avg loss: 8.853832261678734		[learning rate: 0.0045709]
		[batch 4/5] avg loss: 9.674689196503362		[learning rate: 0.0043652]
		[batch 5/5] avg loss: 8.821368639667316		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 9.265866908810292 | validation: 10.587029015338615]
	TIME [epoch: 41.7 sec]
EPOCH 15/20:
	Training over batches...
		[batch 1/5] avg loss: 9.128051627844243		[learning rate: 0.0039811]
		[batch 2/5] avg loss: 9.447878649291425		[learning rate: 0.0038019]
		[batch 3/5] avg loss: 9.34898031576652		[learning rate: 0.0036308]
		[batch 4/5] avg loss: 8.930309143966243		[learning rate: 0.0034674]
		[batch 5/5] avg loss: 9.133261304165005		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 9.197696208206686 | validation: 10.7276660360629]
	TIME [epoch: 41.6 sec]
EPOCH 16/20:
	Training over batches...
		[batch 1/5] avg loss: 9.433564290622385		[learning rate: 0.0031623]
		[batch 2/5] avg loss: 8.551103663396802		[learning rate: 0.00302]
		[batch 3/5] avg loss: 8.74848486384882		[learning rate: 0.002884]
		[batch 4/5] avg loss: 10.379498682258681		[learning rate: 0.0027542]
		[batch 5/5] avg loss: 9.361267338576388		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 9.294783767740615 | validation: 10.580930266625035]
	TIME [epoch: 41.5 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_16.pth
	Model improved!!!
EPOCH 17/20:
	Training over batches...
		[batch 1/5] avg loss: 8.597709716261937		[learning rate: 0.0025119]
		[batch 2/5] avg loss: 9.376199291721234		[learning rate: 0.0023988]
		[batch 3/5] avg loss: 9.136406439681096		[learning rate: 0.0022909]
		[batch 4/5] avg loss: 9.462152344686343		[learning rate: 0.0021878]
		[batch 5/5] avg loss: 9.378448218896917		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 9.190183202249505 | validation: 10.560635975779743]
	TIME [epoch: 41.5 sec]
	Saving model to: tests/_data/benchmark_data/benchmark_models_20240211_105510/states/model_benchmark_1b_17.pth
	Model improved!!!
EPOCH 18/20:
	Training over batches...
		[batch 1/5] avg loss: 9.069590633440946		[learning rate: 0.0019953]
		[batch 2/5] avg loss: 9.01777462663353		[learning rate: 0.0019055]
		[batch 3/5] avg loss: 9.850806219368108		[learning rate: 0.0018197]
		[batch 4/5] avg loss: 9.13872747879977		[learning rate: 0.0017378]
		[batch 5/5] avg loss: 9.051140718798168		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 9.225607935408105 | validation: 10.566889430218659]
	TIME [epoch: 41.5 sec]
EPOCH 19/20:
	Training over batches...
		[batch 1/5] avg loss: 9.485092394495599		[learning rate: 0.0015849]
		[batch 2/5] avg loss: 9.772204370872222		[learning rate: 0.0015136]
		[batch 3/5] avg loss: 9.174582046839035		[learning rate: 0.0014454]
		[batch 4/5] avg loss: 8.173373289813917		[learning rate: 0.0013804]
		[batch 5/5] avg loss: 9.58258484748991		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 9.237567389902136 | validation: 10.670324715122364]
	TIME [epoch: 41.6 sec]
EPOCH 20/20:
	Training over batches...
		[batch 1/5] avg loss: 9.031185298900896		[learning rate: 0.0012589]
		[batch 2/5] avg loss: 9.688821115264696		[learning rate: 0.0012023]
		[batch 3/5] avg loss: 9.217945095437031		[learning rate: 0.0011482]
		[batch 4/5] avg loss: 9.165288972857198		[learning rate: 0.0010965]
		[batch 5/5] avg loss: 8.959349086200715		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 9.212517913732109 | validation: 10.569051869236674]
	TIME [epoch: 41.6 sec]
Finished training in 872.279 seconds.
