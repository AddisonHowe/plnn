Args:
Namespace(name='model_algphi1_1a_v_kl_20240703_161109_cont', outdir='out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='binary_choice', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.01, signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation='data/trained_models/model_algphi1_1a_v_kl_20240703_161109/states/model_algphi1_1a_v_kl_209.pth')

Using seed: 382268112
Continuing training of model data/trained_models/model_algphi1_1a_v_kl_20240703_161109/states/model_algphi1_1a_v_kl_209.pth
Overwriting loaded model's dt0. Was 0.1. Now 0.01.

Training model...

Saving initial model state to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 7.0467717824837734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0467717824837734 | validation: 6.988546512994928]
	TIME [epoch: 140 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 6.9789697711090986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9789697711090986 | validation: 6.89965331326743]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 6.9588204704360415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9588204704360415 | validation: 6.820070396885509]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 6.758195951757153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.758195951757153 | validation: 6.680137933224362]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 6.6278866770912925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6278866770912925 | validation: 6.580518585903073]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 6.566944994972324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.566944994972324 | validation: 6.5220837671781995]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 6.489091110585189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.489091110585189 | validation: 6.4119517186358195]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 6.52351102808626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.52351102808626 | validation: 6.507492255843744]
	TIME [epoch: 53.7 sec]
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 6.5709717645972745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5709717645972745 | validation: 6.692225512466075]
	TIME [epoch: 53.7 sec]
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 6.657508999185456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.657508999185456 | validation: 6.633528348288223]
	TIME [epoch: 53.8 sec]
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 6.688588695032334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.688588695032334 | validation: 6.797006361653709]
	TIME [epoch: 53.8 sec]
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 6.719431202831773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.719431202831773 | validation: 6.633133532231744]
	TIME [epoch: 53.7 sec]
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 6.593875277523099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.593875277523099 | validation: 6.549242194044092]
	TIME [epoch: 53.7 sec]
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 6.621583917638296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.621583917638296 | validation: 6.502064362122918]
	TIME [epoch: 53.7 sec]
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 6.481146728442529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.481146728442529 | validation: 6.333649929460254]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 6.373107188247802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.373107188247802 | validation: 6.286008404099015]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 6.458976557696557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.458976557696557 | validation: 6.4397755713352165]
	TIME [epoch: 53.7 sec]
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 6.536718115046135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.536718115046135 | validation: 6.6563567410452675]
	TIME [epoch: 53.6 sec]
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 6.589064997804366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.589064997804366 | validation: 6.565746248244006]
	TIME [epoch: 53.7 sec]
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 6.541502192227936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.541502192227936 | validation: 6.459265058010629]
	TIME [epoch: 53.7 sec]
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 6.4750468392234914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4750468392234914 | validation: 6.4414449513116665]
	TIME [epoch: 53.7 sec]
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 6.437375466424428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.437375466424428 | validation: 6.49039117456503]
	TIME [epoch: 53.8 sec]
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 6.563178235082589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.563178235082589 | validation: 6.778745318182713]
	TIME [epoch: 53.7 sec]
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 6.696959891461101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.696959891461101 | validation: 6.884656973755037]
	TIME [epoch: 53.7 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 6.784581249627513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.784581249627513 | validation: 6.92157216426515]
	TIME [epoch: 53.7 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 6.875204071814948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.875204071814948 | validation: 6.932864541507682]
	TIME [epoch: 53.8 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 6.889140369324027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.889140369324027 | validation: 6.884445896089241]
	TIME [epoch: 53.7 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 6.860850608886255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.860850608886255 | validation: 6.857807753995896]
	TIME [epoch: 53.7 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 6.838301219303973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.838301219303973 | validation: 6.831452462917068]
	TIME [epoch: 53.7 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 6.818427926539733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.818427926539733 | validation: 6.914535096228962]
	TIME [epoch: 53.8 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 6.896701403364329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.896701403364329 | validation: 6.875068858041068]
	TIME [epoch: 53.7 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 6.901517371464627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.901517371464627 | validation: 6.982185935010818]
	TIME [epoch: 53.6 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 6.990934035203388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.990934035203388 | validation: 6.963712210380447]
	TIME [epoch: 53.6 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 6.9576192763952305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9576192763952305 | validation: 6.9992834550376]
	TIME [epoch: 53.7 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 6.886085795318108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.886085795318108 | validation: 6.930577696542108]
	TIME [epoch: 53.7 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 6.942778114904437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.942778114904437 | validation: 6.925300413982071]
	TIME [epoch: 53.7 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 6.865200941308823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.865200941308823 | validation: 6.857808522415339]
	TIME [epoch: 53.7 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 6.887298238063091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.887298238063091 | validation: 6.8670010413574065]
	TIME [epoch: 53.7 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 6.9710326867667485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9710326867667485 | validation: 6.951059006653983]
	TIME [epoch: 53.7 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 6.979139814298586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.979139814298586 | validation: 6.965662951964305]
	TIME [epoch: 53.6 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 6.9906018290805845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9906018290805845 | validation: 6.897979153856317]
	TIME [epoch: 53.7 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 6.926903768033003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.926903768033003 | validation: 6.840980048895442]
	TIME [epoch: 53.8 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 6.881957750309785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.881957750309785 | validation: 6.847784130088101]
	TIME [epoch: 53.7 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 6.814183053465059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.814183053465059 | validation: 6.66501502194367]
	TIME [epoch: 53.6 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 6.74353620816843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.74353620816843 | validation: 6.753297131873682]
	TIME [epoch: 53.7 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 6.790915599754446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.790915599754446 | validation: 6.6512172081018885]
	TIME [epoch: 53.8 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 6.706170848971071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706170848971071 | validation: 6.585794704866302]
	TIME [epoch: 53.7 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 6.506698536970726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.506698536970726 | validation: 6.414998980107841]
	TIME [epoch: 53.7 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 6.434239531810393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.434239531810393 | validation: 6.462963091837583]
	TIME [epoch: 53.7 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 6.534070186313931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.534070186313931 | validation: 6.42768819470373]
	TIME [epoch: 53.7 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 6.508063081639239		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 6.508063081639239 | validation: 6.581270189025803]
	TIME [epoch: 53.7 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 6.555040303139755		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 6.555040303139755 | validation: 6.455446053994714]
	TIME [epoch: 53.7 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 6.403304659341838		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 6.403304659341838 | validation: 6.375873500655911]
	TIME [epoch: 53.7 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 6.2859403494700485		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 6.2859403494700485 | validation: 6.164871306148243]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 6.160148164520711		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 6.160148164520711 | validation: 6.111122186323561]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 6.129597416225019		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 6.129597416225019 | validation: 6.145248568531331]
	TIME [epoch: 53.7 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 6.134184921912259		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 6.134184921912259 | validation: 6.096795052483028]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 6.063170439291314		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 6.063170439291314 | validation: 5.957791115051169]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 5.868437557609731		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 5.868437557609731 | validation: 5.64148949017141]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 5.740922089254241		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 5.740922089254241 | validation: 5.679362153144593]
	TIME [epoch: 53.9 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 5.688527162499667		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 5.688527162499667 | validation: 5.604579864026977]
	TIME [epoch: 54.1 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 5.630698717753272		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 5.630698717753272 | validation: 5.52595267788891]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 5.550113570022905		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 5.550113570022905 | validation: 5.459257086412365]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 5.60807884708368		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 5.60807884708368 | validation: 5.402836017511568]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 5.531446823702279		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 5.531446823702279 | validation: 5.492133500891336]
	TIME [epoch: 53.8 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 5.634776450829666		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 5.634776450829666 | validation: 5.476270570378499]
	TIME [epoch: 53.8 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 5.6427512176282395		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 5.6427512176282395 | validation: 5.543560565276643]
	TIME [epoch: 53.8 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 5.539544194933272		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 5.539544194933272 | validation: 5.374629800348569]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 5.483214647289309		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 5.483214647289309 | validation: 5.468745340323025]
	TIME [epoch: 53.8 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 5.493630756040559		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 5.493630756040559 | validation: 5.381523984435389]
	TIME [epoch: 53.7 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 5.483566425977349		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 5.483566425977349 | validation: 5.396316986112492]
	TIME [epoch: 53.7 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 5.443294494514355		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 5.443294494514355 | validation: 5.375301189189673]
	TIME [epoch: 53.7 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 5.323924472236013		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 5.323924472236013 | validation: 5.2529390302991645]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 5.3586865962233		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 5.3586865962233 | validation: 5.273912359008919]
	TIME [epoch: 53.7 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 5.346693638826		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 5.346693638826 | validation: 5.190500234750484]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 5.283949661909462		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 5.283949661909462 | validation: 5.191820579051474]
	TIME [epoch: 53.8 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 5.313630381823277		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 5.313630381823277 | validation: 5.210419517815843]
	TIME [epoch: 53.8 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 5.262445109788139		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 5.262445109788139 | validation: 5.101168665138509]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 5.1741562920590685		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 5.1741562920590685 | validation: 5.136344314933686]
	TIME [epoch: 53.8 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 5.188049250995093		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 5.188049250995093 | validation: 5.123749062011292]
	TIME [epoch: 53.8 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 5.1817914272797685		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 5.1817914272797685 | validation: 5.032226139211904]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 5.082642593100717		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 5.082642593100717 | validation: 4.917555772994629]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 4.900022690696709		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 4.900022690696709 | validation: 4.756629674722536]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 4.755936340654665		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 4.755936340654665 | validation: 4.6008124986188115]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_84.pth
	Model improved!!!
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 4.656160358743377		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 4.656160358743377 | validation: 4.587096523966058]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 4.605997199686513		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 4.605997199686513 | validation: 4.533139837045601]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 4.6867950043145665		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 4.6867950043145665 | validation: 4.5384628768918205]
	TIME [epoch: 53.7 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 4.548350969748959		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 4.548350969748959 | validation: 4.451032876212788]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 4.500711473738056		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 4.500711473738056 | validation: 4.4716101225068]
	TIME [epoch: 53.8 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 4.546460661295969		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 4.546460661295969 | validation: 4.528901025256018]
	TIME [epoch: 53.8 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 4.485628971746514		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 4.485628971746514 | validation: 4.3288977380498]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 4.464525375504687		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 4.464525375504687 | validation: 4.3722687212561215]
	TIME [epoch: 53.9 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 4.38061145405133		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 4.38061145405133 | validation: 4.279369726551556]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 4.28032836486076		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 4.28032836486076 | validation: 4.202599611784983]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_94.pth
	Model improved!!!
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 4.206080634082809		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 4.206080634082809 | validation: 4.145553181318628]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 4.0950731908833315		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 4.0950731908833315 | validation: 3.875187293429101]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 3.8647637509140473		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 3.8647637509140473 | validation: 3.668964178027955]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_97.pth
	Model improved!!!
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 3.698516611300149		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 3.698516611300149 | validation: 3.5255689283973086]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5985402374615		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 3.5985402374615 | validation: 3.5722070503749235]
	TIME [epoch: 53.8 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5374654056039243		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 3.5374654056039243 | validation: 3.533757243616056]
	TIME [epoch: 53.8 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5316751449798875		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 3.5316751449798875 | validation: 3.388643216759713]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 3.4216437813898057		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 3.4216437813898057 | validation: 3.3317777340439876]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 3.28636987114227		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 3.28636987114227 | validation: 3.184038797528073]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 3.1588483400672667		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 3.1588483400672667 | validation: 3.100867364999532]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 3.1286583160797825		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 3.1286583160797825 | validation: 3.151706516903825]
	TIME [epoch: 53.7 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 3.2078144681427383		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 3.2078144681427383 | validation: 3.090077805514711]
	TIME [epoch: 54.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_106.pth
	Model improved!!!
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 3.0299104452101284		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 3.0299104452101284 | validation: 2.951929580827369]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 2.8853109751300092		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 2.8853109751300092 | validation: 2.7837061413354744]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7231603810779195		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 2.7231603810779195 | validation: 2.5971068572245932]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 2.6030863424437607		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 2.6030863424437607 | validation: 2.506954514022534]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 2.4608444844768536		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 2.4608444844768536 | validation: 2.3194333046926925]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 2.303381231168075		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 2.303381231168075 | validation: 2.2042141362714043]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 2.205132933306147		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 2.205132933306147 | validation: 2.0751688886278616]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 2.131612097450489		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 2.131612097450489 | validation: 2.0690211255416755]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 2.0934024741483697		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 2.0934024741483697 | validation: 1.9579711618925835]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_115.pth
	Model improved!!!
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 1.9896394056467037		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 1.9896394056467037 | validation: 1.8939983241676557]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_116.pth
	Model improved!!!
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 1.8847155442487684		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 1.8847155442487684 | validation: 1.7572305297356952]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_117.pth
	Model improved!!!
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7688287293466955		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 1.7688287293466955 | validation: 1.621185047602215]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_118.pth
	Model improved!!!
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 1.6808985819996527		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 1.6808985819996527 | validation: 1.531235638063028]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 1.5678582469611944		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 1.5678582469611944 | validation: 1.4020716746309319]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_120.pth
	Model improved!!!
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 1.491288720886002		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 1.491288720886002 | validation: 1.3026218851296365]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4072779128464667		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 1.4072779128464667 | validation: 1.2393025009149432]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_122.pth
	Model improved!!!
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 1.3218267769279741		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 1.3218267769279741 | validation: 1.1617768499106145]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_123.pth
	Model improved!!!
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2669683984909266		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 1.2669683984909266 | validation: 1.1343396166597082]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2066840071351526		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 1.2066840071351526 | validation: 1.066459159222498]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_125.pth
	Model improved!!!
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 1.141800617017199		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 1.141800617017199 | validation: 1.0069236179840688]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_126.pth
	Model improved!!!
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0935601011389362		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 1.0935601011389362 | validation: 0.9867388209640338]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0572827123011068		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 1.0572827123011068 | validation: 0.9455877091389926]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_128.pth
	Model improved!!!
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0163092479419948		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 1.0163092479419948 | validation: 0.886326327689714]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_129.pth
	Model improved!!!
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9676146752595411		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.9676146752595411 | validation: 0.8690839920957976]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9059768596999036		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.9059768596999036 | validation: 0.7876900425868518]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8616301486499084		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.8616301486499084 | validation: 0.7405305038720893]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8056524081407352		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.8056524081407352 | validation: 0.7091350011353716]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_133.pth
	Model improved!!!
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7706670363278645		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.7706670363278645 | validation: 0.6654992377903834]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_134.pth
	Model improved!!!
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7141017142217903		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.7141017142217903 | validation: 0.6121846782955244]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6583540195646135		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.6583540195646135 | validation: 0.5577210852613195]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_136.pth
	Model improved!!!
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6284610462929829		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.6284610462929829 | validation: 0.5455198772177121]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_137.pth
	Model improved!!!
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5930943024732955		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.5930943024732955 | validation: 0.5269453520433227]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_138.pth
	Model improved!!!
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5426069787701322		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.5426069787701322 | validation: 0.48402670277788085]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_139.pth
	Model improved!!!
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.514445444419238		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.514445444419238 | validation: 0.4686961240627429]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.48038005105206144		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.48038005105206144 | validation: 0.41613804653767206]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4564068119570647		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.4564068119570647 | validation: 0.4092069037494113]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_142.pth
	Model improved!!!
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4219374695798827		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.4219374695798827 | validation: 0.3667671150608664]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_143.pth
	Model improved!!!
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.38927771654905186		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.38927771654905186 | validation: 0.34961085946475423]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_144.pth
	Model improved!!!
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3557641466456615		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.3557641466456615 | validation: 0.31666764621322907]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3283091457680414		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.3283091457680414 | validation: 0.2902846326008057]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3037171120892865		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.3037171120892865 | validation: 0.2711496087361267]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_147.pth
	Model improved!!!
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28129316316942676		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.28129316316942676 | validation: 0.2625637123239849]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.25715433537090804		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.25715433537090804 | validation: 0.22406376191993724]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_149.pth
	Model improved!!!
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23371924239099154		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.23371924239099154 | validation: 0.21164251372783344]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_150.pth
	Model improved!!!
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22117594108478764		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.22117594108478764 | validation: 0.20309248721382978]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_151.pth
	Model improved!!!
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19879641109801047		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.19879641109801047 | validation: 0.18574666182613264]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1816292693416047		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.1816292693416047 | validation: 0.16058965076113407]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_153.pth
	Model improved!!!
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16659917760652282		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.16659917760652282 | validation: 0.14700978670705644]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1555150737953473		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.1555150737953473 | validation: 0.14232874935925577]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_155.pth
	Model improved!!!
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13631943019490972		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.13631943019490972 | validation: 0.11493819373674075]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11820581475823747		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.11820581475823747 | validation: 0.10412581240262389]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_157.pth
	Model improved!!!
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10403653654769857		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.10403653654769857 | validation: 0.10446363662159455]
	TIME [epoch: 53.7 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08906307831333082		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.08906307831333082 | validation: 0.08648766354462836]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_159.pth
	Model improved!!!
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08201112203593292		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.08201112203593292 | validation: 0.08321294588564135]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_160.pth
	Model improved!!!
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07182229288136587		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.07182229288136587 | validation: 0.07281640891656846]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_161.pth
	Model improved!!!
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07053838041139394		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.07053838041139394 | validation: 0.06606856889554139]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_162.pth
	Model improved!!!
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06094264713556653		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.06094264713556653 | validation: 0.053463744259095045]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_163.pth
	Model improved!!!
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046301449019805714		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.046301449019805714 | validation: 0.04473332385206455]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_164.pth
	Model improved!!!
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04204834112555844		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.04204834112555844 | validation: 0.05593717973573607]
	TIME [epoch: 53.7 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035857528486796394		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.035857528486796394 | validation: 0.035157985767186116]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_166.pth
	Model improved!!!
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03060395051620262		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.03060395051620262 | validation: 0.020341363311578108]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_167.pth
	Model improved!!!
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02905062307090872		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.02905062307090872 | validation: 0.03287481038705245]
	TIME [epoch: 53.7 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02551108080348609		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.02551108080348609 | validation: 0.026082117357043792]
	TIME [epoch: 53.7 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018535457349481303		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.018535457349481303 | validation: 0.021019344449674553]
	TIME [epoch: 53.7 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02245177155158744		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.02245177155158744 | validation: 0.027191892663614235]
	TIME [epoch: 53.7 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016417802329666477		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.016417802329666477 | validation: 0.014735898844565633]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_172.pth
	Model improved!!!
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01184702455154956		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.01184702455154956 | validation: 0.026013775556044165]
	TIME [epoch: 53.7 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005729593081504388		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.005729593081504388 | validation: 0.008306155770540996]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_174.pth
	Model improved!!!
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007967014261590055		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.007967014261590055 | validation: 0.00450541825193783]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_175.pth
	Model improved!!!
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001944107156073284		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.001944107156073284 | validation: 0.00702519065010917]
	TIME [epoch: 53.7 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00368348555971433		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.00368348555971433 | validation: -0.0019396891114546923]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_177.pth
	Model improved!!!
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005124166896644095		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.005124166896644095 | validation: 0.0006240666787195859]
	TIME [epoch: 53.7 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013736317740854803		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.0013736317740854803 | validation: 0.0017260729372423097]
	TIME [epoch: 53.7 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018282088197216781		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.0018282088197216781 | validation: -0.004494870221725366]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_180.pth
	Model improved!!!
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0008413883881803904		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.0008413883881803904 | validation: -0.0049152675459928265]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_181.pth
	Model improved!!!
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022358180036154357		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.0022358180036154357 | validation: 0.003460752521187927]
	TIME [epoch: 53.7 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008761501010800575		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.008761501010800575 | validation: -0.0005288135784034249]
	TIME [epoch: 53.7 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005866468437467347		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.005866468437467347 | validation: -0.01151144086656104]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_184.pth
	Model improved!!!
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007047482038929786		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.007047482038929786 | validation: -0.005691303718561843]
	TIME [epoch: 53.7 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007249746316879021		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.007249746316879021 | validation: -0.0031361759810931127]
	TIME [epoch: 53.7 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021404869725660538		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.0021404869725660538 | validation: -0.003935354638417948]
	TIME [epoch: 53.7 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005230410021299803		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.005230410021299803 | validation: 0.0003726886218733934]
	TIME [epoch: 53.7 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007125697191239084		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.007125697191239084 | validation: 0.000709248778589325]
	TIME [epoch: 53.7 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00393769533110194		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.00393769533110194 | validation: 0.003110277764602272]
	TIME [epoch: 53.7 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010879138028731219		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.010879138028731219 | validation: -0.015267068958887993]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_191.pth
	Model improved!!!
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010210835374312933		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.010210835374312933 | validation: -0.004316175548740742]
	TIME [epoch: 53.7 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007369747043749659		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.007369747043749659 | validation: -0.010677952259779716]
	TIME [epoch: 53.7 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005306558737069159		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.005306558737069159 | validation: -0.00584743338739116]
	TIME [epoch: 53.7 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011198694042345414		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.011198694042345414 | validation: -0.010659108353912462]
	TIME [epoch: 53.7 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009180626436524812		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.009180626436524812 | validation: -0.015672924468047945]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_196.pth
	Model improved!!!
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010573402467522353		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.010573402467522353 | validation: 0.00167799471487439]
	TIME [epoch: 53.8 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0120743636926204		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.0120743636926204 | validation: -0.00910322819626264]
	TIME [epoch: 53.7 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010999479521959529		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.010999479521959529 | validation: -0.0028417683137424484]
	TIME [epoch: 53.7 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009492009217515798		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.009492009217515798 | validation: -0.0017757451945531726]
	TIME [epoch: 53.7 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011446550542744714		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.011446550542744714 | validation: -0.0043191830135857175]
	TIME [epoch: 53.8 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00944633662796708		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.00944633662796708 | validation: -0.007042117882440932]
	TIME [epoch: 53.8 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007167796774669147		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.007167796774669147 | validation: -0.008204391497546468]
	TIME [epoch: 53.8 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009611070742761454		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.009611070742761454 | validation: -0.0025856268666763767]
	TIME [epoch: 53.8 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0066173662833681575		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.0066173662833681575 | validation: -0.0121889283576005]
	TIME [epoch: 53.9 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010491660481536554		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.010491660481536554 | validation: -0.0014580901828238292]
	TIME [epoch: 53.8 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00798944296293806		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.00798944296293806 | validation: 0.0007223834468680305]
	TIME [epoch: 53.8 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008681761486677611		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.008681761486677611 | validation: -0.009906250358051105]
	TIME [epoch: 53.9 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007847031292195362		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.007847031292195362 | validation: -0.010718148370708547]
	TIME [epoch: 53.8 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007896178050055783		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.007896178050055783 | validation: -0.020896226782490285]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_210.pth
	Model improved!!!
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008765436194498207		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.008765436194498207 | validation: -0.017406521084358986]
	TIME [epoch: 53.7 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013243685795300908		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.013243685795300908 | validation: -0.009088599501440763]
	TIME [epoch: 53.7 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01058839972394401		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.01058839972394401 | validation: -0.008823416369896196]
	TIME [epoch: 53.7 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010422796414915492		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.010422796414915492 | validation: -0.0053390804895022195]
	TIME [epoch: 53.7 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013600850822792013		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.013600850822792013 | validation: -0.014499403810307204]
	TIME [epoch: 53.7 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014490825252447158		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.014490825252447158 | validation: -0.008224959068749546]
	TIME [epoch: 53.7 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0075543116162487736		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.0075543116162487736 | validation: -0.0007389855208438378]
	TIME [epoch: 53.7 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01315885094180241		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.01315885094180241 | validation: -0.010026103844798946]
	TIME [epoch: 53.7 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009502721262614085		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.009502721262614085 | validation: -0.006704044652502756]
	TIME [epoch: 53.7 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010173436086370653		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.010173436086370653 | validation: -0.002266009052647672]
	TIME [epoch: 53.7 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008999356165265152		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.008999356165265152 | validation: -0.011986432196535786]
	TIME [epoch: 53.7 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011757441162367734		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.011757441162367734 | validation: -0.002595084063864986]
	TIME [epoch: 53.7 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008345725352182136		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.008345725352182136 | validation: -0.005367546246813333]
	TIME [epoch: 53.7 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010894576141869096		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.010894576141869096 | validation: -0.010178259778286266]
	TIME [epoch: 53.7 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010862089548970317		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.010862089548970317 | validation: -0.012704663902147873]
	TIME [epoch: 53.7 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010692335367450723		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.010692335367450723 | validation: -0.011704428616911485]
	TIME [epoch: 53.7 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008013391361314173		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.008013391361314173 | validation: -0.017521632045743748]
	TIME [epoch: 53.7 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011564062178646755		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.011564062178646755 | validation: -0.00390401810948653]
	TIME [epoch: 53.7 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010318007045797006		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.010318007045797006 | validation: -0.0062614189007954655]
	TIME [epoch: 53.7 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009705384352020407		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.009705384352020407 | validation: -0.008344645577013449]
	TIME [epoch: 53.7 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01647141677481465		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.01647141677481465 | validation: -0.016971216663920465]
	TIME [epoch: 53.7 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011533764857404602		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.011533764857404602 | validation: -0.015927086596062227]
	TIME [epoch: 53.7 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012840418918591247		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.012840418918591247 | validation: -0.01029704733300658]
	TIME [epoch: 53.7 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01088330345730936		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.01088330345730936 | validation: -0.01627171287754558]
	TIME [epoch: 53.7 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008398296955248082		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.008398296955248082 | validation: -0.006310001389329288]
	TIME [epoch: 53.7 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012742667960710677		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.012742667960710677 | validation: -0.011221847326378232]
	TIME [epoch: 53.7 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007988938121950733		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.007988938121950733 | validation: -0.01701138502126105]
	TIME [epoch: 53.7 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01500849988676018		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.01500849988676018 | validation: -0.012760838412709356]
	TIME [epoch: 53.7 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010014445761185115		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.010014445761185115 | validation: -0.014672493397466718]
	TIME [epoch: 53.7 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009412120665675455		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.009412120665675455 | validation: -0.007847364618628548]
	TIME [epoch: 53.7 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01111392398059568		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.01111392398059568 | validation: -0.008504335061822767]
	TIME [epoch: 53.7 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012488184455291318		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.012488184455291318 | validation: -0.015266300045571798]
	TIME [epoch: 53.7 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0090882687217336		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.0090882687217336 | validation: -0.0022903742043209503]
	TIME [epoch: 53.7 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010608161811431135		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.010608161811431135 | validation: -0.0005093997129602922]
	TIME [epoch: 53.7 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011495678727462195		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.011495678727462195 | validation: -0.006976177257775655]
	TIME [epoch: 53.7 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012018342464457984		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.012018342464457984 | validation: -0.009685375652231933]
	TIME [epoch: 53.7 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00915928029711146		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.00915928029711146 | validation: -0.004227626869159704]
	TIME [epoch: 53.7 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009532415212642429		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.009532415212642429 | validation: -0.012463591583193753]
	TIME [epoch: 53.7 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007858579470437742		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.007858579470437742 | validation: -0.009439409938725943]
	TIME [epoch: 53.7 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011067024424299774		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.011067024424299774 | validation: -0.003911674300215891]
	TIME [epoch: 53.7 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011003668471898048		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.011003668471898048 | validation: -0.016617575244661204]
	TIME [epoch: 53.7 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012618498971731479		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.012618498971731479 | validation: -0.01507956788069088]
	TIME [epoch: 53.7 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01169500264603372		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.01169500264603372 | validation: -0.014792176496356915]
	TIME [epoch: 53.7 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011400499011719755		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.011400499011719755 | validation: -0.015366635212811192]
	TIME [epoch: 53.7 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011759794727656564		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.011759794727656564 | validation: -0.012789774764765898]
	TIME [epoch: 53.7 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012091769041865288		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.012091769041865288 | validation: -0.004660479280539802]
	TIME [epoch: 53.7 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012614610215296772		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.012614610215296772 | validation: -0.011400802118850122]
	TIME [epoch: 53.7 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011508402638952532		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.011508402638952532 | validation: -0.007497589246091838]
	TIME [epoch: 53.7 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01083954865096548		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.01083954865096548 | validation: -0.01178927766657816]
	TIME [epoch: 53.7 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009419755258976288		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.009419755258976288 | validation: -0.006095639482487296]
	TIME [epoch: 53.7 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01148074579681592		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.01148074579681592 | validation: -0.014647462139179755]
	TIME [epoch: 53.7 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011048215860322638		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.011048215860322638 | validation: -0.011724316410953946]
	TIME [epoch: 53.7 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013724130607278088		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.013724130607278088 | validation: -0.0069034771641281025]
	TIME [epoch: 53.7 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009346013103204914		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.009346013103204914 | validation: -0.0004924507965298236]
	TIME [epoch: 53.7 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01220005179122105		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.01220005179122105 | validation: -0.012032500789024653]
	TIME [epoch: 53.7 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012362528672813497		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.012362528672813497 | validation: -0.01636845238513713]
	TIME [epoch: 53.7 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010230094549479294		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.010230094549479294 | validation: -0.00740867615815817]
	TIME [epoch: 53.7 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012522895101644341		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.012522895101644341 | validation: -0.01193987111726902]
	TIME [epoch: 53.7 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013836765453063817		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.013836765453063817 | validation: -0.00607507645703656]
	TIME [epoch: 53.7 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008767596650125815		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.008767596650125815 | validation: -0.014412214661160805]
	TIME [epoch: 53.7 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011298488621337349		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.011298488621337349 | validation: -0.015768216203415866]
	TIME [epoch: 53.7 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011361304505983112		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.011361304505983112 | validation: -0.012078838830225022]
	TIME [epoch: 53.7 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009206548546619085		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.009206548546619085 | validation: -0.00939446593412358]
	TIME [epoch: 53.7 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010966242281000241		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.010966242281000241 | validation: -0.008745690424129081]
	TIME [epoch: 53.7 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014510516342719139		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.014510516342719139 | validation: -0.004415973969615928]
	TIME [epoch: 53.7 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006406909115085417		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.006406909115085417 | validation: -0.014962422244151135]
	TIME [epoch: 53.7 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008994565750822796		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.008994565750822796 | validation: -0.0062718951530824525]
	TIME [epoch: 53.7 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004532105398076904		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.004532105398076904 | validation: -0.006553047847882106]
	TIME [epoch: 53.7 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0071041389609070495		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.0071041389609070495 | validation: -0.012477704615152414]
	TIME [epoch: 53.7 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013794454861445107		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.013794454861445107 | validation: -0.017024315186508918]
	TIME [epoch: 53.7 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012026779409477602		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.012026779409477602 | validation: -0.010998870651845346]
	TIME [epoch: 53.7 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009927737733297384		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.009927737733297384 | validation: -0.010676086978368388]
	TIME [epoch: 53.7 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013869473822011785		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.013869473822011785 | validation: -0.008145341807692132]
	TIME [epoch: 53.7 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00969612679162942		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.00969612679162942 | validation: -0.006703961369383959]
	TIME [epoch: 53.7 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009008048028920333		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.009008048028920333 | validation: -0.017487097448033662]
	TIME [epoch: 53.7 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008845360023217542		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.008845360023217542 | validation: -0.010941337774259503]
	TIME [epoch: 53.7 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012169399028119		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.012169399028119 | validation: -0.011654520450697762]
	TIME [epoch: 53.8 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010472643577248615		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.010472643577248615 | validation: -0.01222104933933128]
	TIME [epoch: 53.7 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007776639156660468		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.007776639156660468 | validation: -0.00762360416668582]
	TIME [epoch: 53.7 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008384052200005562		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.008384052200005562 | validation: -0.009274779745299134]
	TIME [epoch: 53.7 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00815047798879313		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.00815047798879313 | validation: -0.0029200910832876572]
	TIME [epoch: 53.8 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008362846526794379		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.008362846526794379 | validation: -0.004838751147915946]
	TIME [epoch: 53.8 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010446291811069533		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.010446291811069533 | validation: -0.005490901603444795]
	TIME [epoch: 53.7 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013648483459945793		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.013648483459945793 | validation: 0.0006822389198793202]
	TIME [epoch: 53.7 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009616176016361496		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.009616176016361496 | validation: -0.014019152659378033]
	TIME [epoch: 53.7 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008870290306226774		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.008870290306226774 | validation: -0.0053458185838540775]
	TIME [epoch: 53.7 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006401201921980451		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.006401201921980451 | validation: -0.009590382442304084]
	TIME [epoch: 53.7 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008283904676465944		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.008283904676465944 | validation: -0.02297530384528007]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_298.pth
	Model improved!!!
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006221534603543443		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.006221534603543443 | validation: -0.012163814086315127]
	TIME [epoch: 53.8 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007442661212291741		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.007442661212291741 | validation: -0.008382506817563338]
	TIME [epoch: 53.7 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01099949537776254		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.01099949537776254 | validation: -0.007594327434173979]
	TIME [epoch: 53.7 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006374705550807139		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.006374705550807139 | validation: -0.004813204714079073]
	TIME [epoch: 53.7 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007508873648535714		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.007508873648535714 | validation: -0.0038523628422246674]
	TIME [epoch: 53.7 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009941286685018267		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.009941286685018267 | validation: -0.0059055661211720074]
	TIME [epoch: 53.7 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011992954116568345		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.011992954116568345 | validation: -0.0066091891839863]
	TIME [epoch: 53.7 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00924441415559535		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.00924441415559535 | validation: -0.004029846420491278]
	TIME [epoch: 53.7 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014811434299313496		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.014811434299313496 | validation: -0.007045516842585396]
	TIME [epoch: 53.7 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010721043579630038		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.010721043579630038 | validation: -0.010962604429414172]
	TIME [epoch: 53.7 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013290815820761403		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.013290815820761403 | validation: -0.01086600894044731]
	TIME [epoch: 53.7 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015937805685619685		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.015937805685619685 | validation: -0.020559932870062476]
	TIME [epoch: 53.7 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00966503301373043		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.00966503301373043 | validation: -0.010651411055956924]
	TIME [epoch: 53.7 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009638405890191163		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.009638405890191163 | validation: -0.006715354425628973]
	TIME [epoch: 53.7 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009810321443854454		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.009810321443854454 | validation: -0.009039365142667196]
	TIME [epoch: 53.7 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012165652790795622		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.012165652790795622 | validation: -0.014500058098088079]
	TIME [epoch: 53.7 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009733273671693821		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.009733273671693821 | validation: -0.01515241550577354]
	TIME [epoch: 53.7 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01457671512790351		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.01457671512790351 | validation: -0.016274273754017035]
	TIME [epoch: 53.7 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01312714159016099		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.01312714159016099 | validation: -0.0061002092218262315]
	TIME [epoch: 53.7 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015653759856398768		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.015653759856398768 | validation: -0.005319478107173296]
	TIME [epoch: 53.7 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007082740175829354		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.007082740175829354 | validation: -0.001608999757120263]
	TIME [epoch: 53.7 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011393733624369354		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.011393733624369354 | validation: -0.006832891962902155]
	TIME [epoch: 53.7 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014582639567007038		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.014582639567007038 | validation: -0.021409543489885153]
	TIME [epoch: 53.7 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014574932672602655		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.014574932672602655 | validation: -0.004214279471814914]
	TIME [epoch: 53.7 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016393852836028365		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.016393852836028365 | validation: -0.007183132966124202]
	TIME [epoch: 53.7 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014192351590234287		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.014192351590234287 | validation: -0.014022144597320213]
	TIME [epoch: 53.7 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009680771198132088		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.009680771198132088 | validation: -0.00813799608985411]
	TIME [epoch: 53.7 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010096648427691623		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.010096648427691623 | validation: -0.0014886836608887333]
	TIME [epoch: 53.7 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009381864230738876		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.009381864230738876 | validation: 0.0031543366036175767]
	TIME [epoch: 53.7 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008470963154655418		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.008470963154655418 | validation: -0.01335034195731375]
	TIME [epoch: 53.7 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012158138849520385		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.012158138849520385 | validation: -0.014118477589798069]
	TIME [epoch: 53.7 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012536349274912473		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.012536349274912473 | validation: -0.009297370736555398]
	TIME [epoch: 53.7 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012269868042097202		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.012269868042097202 | validation: -0.011481036651410861]
	TIME [epoch: 53.7 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010681799623483694		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.010681799623483694 | validation: -0.016403722178317034]
	TIME [epoch: 53.7 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008120883015238799		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.008120883015238799 | validation: -0.002719377968998937]
	TIME [epoch: 53.7 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010881605351118073		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.010881605351118073 | validation: -0.004645674068404929]
	TIME [epoch: 53.7 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010564110214959097		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.010564110214959097 | validation: -0.007989730913031111]
	TIME [epoch: 53.7 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009454303824328762		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.009454303824328762 | validation: -0.01278393680664608]
	TIME [epoch: 53.7 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007627882671874229		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.007627882671874229 | validation: -0.008328025152066374]
	TIME [epoch: 53.7 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009637651641368629		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.009637651641368629 | validation: -0.007500765768239765]
	TIME [epoch: 53.7 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013567415893189935		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.013567415893189935 | validation: -0.01471608044845655]
	TIME [epoch: 53.7 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009085549445663579		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.009085549445663579 | validation: -0.01517698948959281]
	TIME [epoch: 53.7 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01090675653839382		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.01090675653839382 | validation: 0.0022123666968840282]
	TIME [epoch: 53.7 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012815214666516722		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.012815214666516722 | validation: -0.005985448819628194]
	TIME [epoch: 53.7 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.017084225506518155		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.017084225506518155 | validation: -0.008650429050197136]
	TIME [epoch: 53.7 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013211962461899412		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.013211962461899412 | validation: -0.0038455936836059024]
	TIME [epoch: 53.7 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012393121606803854		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.012393121606803854 | validation: -0.011482209377409316]
	TIME [epoch: 53.7 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008167067754209308		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.008167067754209308 | validation: -0.007964636414369501]
	TIME [epoch: 53.8 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01091357762798049		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.01091357762798049 | validation: -0.006032720723481504]
	TIME [epoch: 53.7 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015030841163478642		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.015030841163478642 | validation: -0.004456965267837871]
	TIME [epoch: 53.7 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010720481744665843		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.010720481744665843 | validation: -0.004927388394084541]
	TIME [epoch: 53.8 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008725015591112438		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.008725015591112438 | validation: -0.0068401898576155125]
	TIME [epoch: 53.8 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009292149092888951		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.009292149092888951 | validation: -0.016544366735189178]
	TIME [epoch: 53.8 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01497335071963908		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: -0.01497335071963908 | validation: -0.01269859437807891]
	TIME [epoch: 53.8 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013094100313911918		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: -0.013094100313911918 | validation: -0.009601171207169803]
	TIME [epoch: 53.8 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011306350928721261		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: -0.011306350928721261 | validation: -0.009274310825009985]
	TIME [epoch: 53.8 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009272518183563144		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: -0.009272518183563144 | validation: -0.0071986618452183305]
	TIME [epoch: 53.7 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0124301547915993		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: -0.0124301547915993 | validation: -0.007660177538183765]
	TIME [epoch: 53.7 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010398760261916863		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: -0.010398760261916863 | validation: -0.01972326146776538]
	TIME [epoch: 53.8 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01208356868612173		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: -0.01208356868612173 | validation: -0.008156889906374594]
	TIME [epoch: 53.8 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0087735506996868		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: -0.0087735506996868 | validation: -0.01638967006009782]
	TIME [epoch: 53.8 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016643503243844684		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: -0.016643503243844684 | validation: -0.0047468756957322914]
	TIME [epoch: 53.7 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012615504628369826		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: -0.012615504628369826 | validation: -0.013859194459003939]
	TIME [epoch: 53.8 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01050995157841812		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: -0.01050995157841812 | validation: -0.009218614165993967]
	TIME [epoch: 53.8 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012620318382250218		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: -0.012620318382250218 | validation: -0.009379329538617115]
	TIME [epoch: 53.7 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014484760530142523		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: -0.014484760530142523 | validation: -0.01204214399144528]
	TIME [epoch: 53.7 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010911872996751771		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: -0.010911872996751771 | validation: -0.012190017635804417]
	TIME [epoch: 53.8 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014423598441789929		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: -0.014423598441789929 | validation: -0.018833792511688315]
	TIME [epoch: 53.7 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014334951503097134		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: -0.014334951503097134 | validation: -0.006445318216704401]
	TIME [epoch: 53.7 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013497383966371446		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: -0.013497383966371446 | validation: -0.018960322439704875]
	TIME [epoch: 53.8 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011874880007367843		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: -0.011874880007367843 | validation: -0.016542992420064802]
	TIME [epoch: 53.7 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01088929428507713		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: -0.01088929428507713 | validation: 0.005557870267834754]
	TIME [epoch: 53.8 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011302996911998655		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: -0.011302996911998655 | validation: -0.001940275246362133]
	TIME [epoch: 53.8 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00792833354456873		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: -0.00792833354456873 | validation: -0.011438883630445807]
	TIME [epoch: 53.8 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01420192980317155		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: -0.01420192980317155 | validation: -0.011525935003462301]
	TIME [epoch: 53.8 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008651005644036328		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: -0.008651005644036328 | validation: -0.015197926679044824]
	TIME [epoch: 53.8 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013780098753716784		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: -0.013780098753716784 | validation: -0.013709122310589076]
	TIME [epoch: 53.8 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013153515632938675		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: -0.013153515632938675 | validation: -0.01694770701843107]
	TIME [epoch: 53.8 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008834925115657857		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: -0.008834925115657857 | validation: -0.020038396321765035]
	TIME [epoch: 53.8 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01546685420171238		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: -0.01546685420171238 | validation: -0.01771532416668139]
	TIME [epoch: 53.7 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013157516182398098		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: -0.013157516182398098 | validation: -0.020900439909738548]
	TIME [epoch: 53.8 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0148443708031171		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: -0.0148443708031171 | validation: -0.009759808902633789]
	TIME [epoch: 53.8 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011206036776190044		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: -0.011206036776190044 | validation: -0.004277538798163415]
	TIME [epoch: 53.7 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011452961874689273		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: -0.011452961874689273 | validation: -0.008740543544908759]
	TIME [epoch: 53.7 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011469947726006381		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: -0.011469947726006381 | validation: -0.012473520669067371]
	TIME [epoch: 53.8 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00977507663431299		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: -0.00977507663431299 | validation: -0.006550788454714241]
	TIME [epoch: 53.8 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012052626087251049		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: -0.012052626087251049 | validation: -0.009845260867802847]
	TIME [epoch: 53.8 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011056434753117187		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: -0.011056434753117187 | validation: -0.017746241694587828]
	TIME [epoch: 53.8 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012859176059019236		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: -0.012859176059019236 | validation: -0.014247760275617739]
	TIME [epoch: 53.8 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012515333376754083		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: -0.012515333376754083 | validation: -0.005019472573427291]
	TIME [epoch: 53.8 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015512003396862813		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: -0.015512003396862813 | validation: -0.014434459896709575]
	TIME [epoch: 53.8 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012096546693617607		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: -0.012096546693617607 | validation: -0.015309145224063726]
	TIME [epoch: 53.7 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009888806748112796		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: -0.009888806748112796 | validation: -0.01243892955383813]
	TIME [epoch: 53.7 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014265085882092335		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: -0.014265085882092335 | validation: -0.018524574898520975]
	TIME [epoch: 53.8 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016110500030127307		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: -0.016110500030127307 | validation: -0.018346449130528828]
	TIME [epoch: 53.7 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008536802139093263		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: -0.008536802139093263 | validation: -0.01651282239203723]
	TIME [epoch: 53.8 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012419479169155395		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: -0.012419479169155395 | validation: -0.013651589933552807]
	TIME [epoch: 53.8 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: -0.017205777393559593		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: -0.017205777393559593 | validation: -0.017050513105306975]
	TIME [epoch: 53.8 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014802213395744706		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: -0.014802213395744706 | validation: -0.009722044257744887]
	TIME [epoch: 53.8 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0069630638987519585		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: -0.0069630638987519585 | validation: -0.01861403852474517]
	TIME [epoch: 53.8 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012763150298326743		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: -0.012763150298326743 | validation: -0.01325565760722943]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240703_161109_cont_20240703_182345/states/model_algphi1_1a_v_kl_20240703_161109_cont_399.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 21603.791 seconds.
