Args:
Namespace(name='model_transition2_v1', outdir='out/model_training/model_transition2_v1', training_data='data/training_data/data_transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/data_transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=10, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3929517972

Training model...

Saving initial model state to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6725430952872751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6725430952872751 | validation: 0.582668410459696]
	TIME [epoch: 41.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585858646093242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5585858646093242 | validation: 0.5842123158408301]
	TIME [epoch: 17.7 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533149732267979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.533149732267979 | validation: 0.4888482304492353]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48214677585075855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48214677585075855 | validation: 0.49609976098917985]
	TIME [epoch: 17.6 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812451009480855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4812451009480855 | validation: 0.5754889138916573]
	TIME [epoch: 17.7 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44449657553017274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44449657553017274 | validation: 0.5243686943409286]
	TIME [epoch: 17.6 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49976135011963474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49976135011963474 | validation: 0.4677474426895666]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4502854144499577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4502854144499577 | validation: 0.44339031834642784]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45305258458273984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45305258458273984 | validation: 0.4673156158582079]
	TIME [epoch: 17.7 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43152662451542073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43152662451542073 | validation: 0.407579012384521]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3898516449186248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3898516449186248 | validation: 0.3969443488433335]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854397273498433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3854397273498433 | validation: 0.3989500282397411]
	TIME [epoch: 17.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011118145789303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4011118145789303 | validation: 0.3853349161303197]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665148411868104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3665148411868104 | validation: 0.3485563975258963]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34611370167900785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34611370167900785 | validation: 0.39673192212145697]
	TIME [epoch: 17.7 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35608520215009937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35608520215009937 | validation: 0.3244603128804446]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204232340932418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3204232340932418 | validation: 0.36673214174593166]
	TIME [epoch: 17.7 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31794211621067875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31794211621067875 | validation: 0.3197914837863107]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3275857811571602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3275857811571602 | validation: 0.36596954384978525]
	TIME [epoch: 17.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33773122392003985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33773122392003985 | validation: 0.3038120905117237]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105285328802628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3105285328802628 | validation: 0.26968681040993664]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29525917544634345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29525917544634345 | validation: 0.3042465530164839]
	TIME [epoch: 17.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28300923654395066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28300923654395066 | validation: 0.2755620784367213]
	TIME [epoch: 17.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24852102544031643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24852102544031643 | validation: 0.323229991073834]
	TIME [epoch: 17.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29118957970099785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29118957970099785 | validation: 0.29626508108315613]
	TIME [epoch: 17.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675411433076004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2675411433076004 | validation: 0.2912302429522755]
	TIME [epoch: 17.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26740755952645895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26740755952645895 | validation: 0.27337039022041487]
	TIME [epoch: 17.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27395068381637544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27395068381637544 | validation: 0.2829403846667299]
	TIME [epoch: 17.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26347586525435723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26347586525435723 | validation: 0.24740520210075512]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27849346368564376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27849346368564376 | validation: 0.23539644617845606]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748616654469828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2748616654469828 | validation: 0.23928930910015273]
	TIME [epoch: 17.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24318306189526095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24318306189526095 | validation: 0.37479505977069655]
	TIME [epoch: 17.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30661027679240527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30661027679240527 | validation: 0.2669489849652895]
	TIME [epoch: 17.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961174922028606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2961174922028606 | validation: 0.23376096015755515]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25358748375016243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25358748375016243 | validation: 0.28306593792318596]
	TIME [epoch: 17.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27270415496865186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27270415496865186 | validation: 0.21604953275619168]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21577488287768165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21577488287768165 | validation: 0.23486460282174773]
	TIME [epoch: 17.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21901393653531065		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.21901393653531065 | validation: 0.2281043104937156]
	TIME [epoch: 17.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22414176194315888		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.22414176194315888 | validation: 0.2704341835852892]
	TIME [epoch: 17.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22968214524773045		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.22968214524773045 | validation: 0.22276423164569248]
	TIME [epoch: 17.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21541497836675003		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.21541497836675003 | validation: 0.25478362106551816]
	TIME [epoch: 17.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21742355581217296		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.21742355581217296 | validation: 0.24966650314460131]
	TIME [epoch: 17.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25888895674991497		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.25888895674991497 | validation: 0.2236283824459841]
	TIME [epoch: 17.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21800373151824115		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.21800373151824115 | validation: 0.19764498438725936]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24254783550124745		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.24254783550124745 | validation: 0.29460233568109395]
	TIME [epoch: 17.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2330275121012275		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2330275121012275 | validation: 0.2456167193266543]
	TIME [epoch: 17.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22565450597609937		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.22565450597609937 | validation: 0.23703544177875902]
	TIME [epoch: 17.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19975853469377997		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.19975853469377997 | validation: 0.20654643672062356]
	TIME [epoch: 17.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215293367585679		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.215293367585679 | validation: 0.22433854998740405]
	TIME [epoch: 17.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055339902674161		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2055339902674161 | validation: 0.22795078612445144]
	TIME [epoch: 17.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23998066561366732		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.23998066561366732 | validation: 0.2654548046910456]
	TIME [epoch: 17.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21150092442636148		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.21150092442636148 | validation: 0.26189927227561927]
	TIME [epoch: 17.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20315097988832106		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.20315097988832106 | validation: 0.2074030714803269]
	TIME [epoch: 17.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21261983039186533		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.21261983039186533 | validation: 0.2459373488712363]
	TIME [epoch: 17.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536827040430982		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2536827040430982 | validation: 0.2183523508855295]
	TIME [epoch: 17.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028789111096734		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.2028789111096734 | validation: 0.23978076070356313]
	TIME [epoch: 17.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224145150025157		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.224145150025157 | validation: 0.25236372368573323]
	TIME [epoch: 17.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22912499082758722		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.22912499082758722 | validation: 0.2343322436282768]
	TIME [epoch: 17.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22067411169810724		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.22067411169810724 | validation: 0.21172959569629846]
	TIME [epoch: 17.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19199535007209842		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.19199535007209842 | validation: 0.24264645467211213]
	TIME [epoch: 17.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23270997450758762		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.23270997450758762 | validation: 0.24222687025444212]
	TIME [epoch: 17.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2051713818986906		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2051713818986906 | validation: 0.20889092202917858]
	TIME [epoch: 17.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19933974612483293		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.19933974612483293 | validation: 0.24549360524794261]
	TIME [epoch: 17.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834752981300375		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2834752981300375 | validation: 0.22768129084219207]
	TIME [epoch: 17.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20981587266635063		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.20981587266635063 | validation: 0.2012218327717429]
	TIME [epoch: 17.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1943509825439832		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.1943509825439832 | validation: 0.22053253754526364]
	TIME [epoch: 17.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24982710817732595		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.24982710817732595 | validation: 0.2355726001325219]
	TIME [epoch: 17.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080649478817909		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.2080649478817909 | validation: 0.22780126249058277]
	TIME [epoch: 17.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2285693827814546		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.2285693827814546 | validation: 0.2214974168674459]
	TIME [epoch: 17.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20304206660690302		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.20304206660690302 | validation: 0.22757066002840143]
	TIME [epoch: 17.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23085851431038557		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.23085851431038557 | validation: 0.23685410866611842]
	TIME [epoch: 17.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060089766192699		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.2060089766192699 | validation: 0.19021025294301522]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774201437267579		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.1774201437267579 | validation: 0.22882055737118312]
	TIME [epoch: 17.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928121347234458		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.18928121347234458 | validation: 0.1985733733877958]
	TIME [epoch: 17.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18915961890933616		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.18915961890933616 | validation: 0.22906329037854298]
	TIME [epoch: 17.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19641469083282934		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.19641469083282934 | validation: 0.2802611557707819]
	TIME [epoch: 17.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20446002408662792		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.20446002408662792 | validation: 0.18420485629436556]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1902318983479574		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.1902318983479574 | validation: 0.2329712046269539]
	TIME [epoch: 17.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21166060256305905		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.21166060256305905 | validation: 0.20113119866777027]
	TIME [epoch: 17.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176433762278522		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.176433762278522 | validation: 0.22440597969830803]
	TIME [epoch: 17.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20357041314380764		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.20357041314380764 | validation: 0.21968890224532928]
	TIME [epoch: 17.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914226978569999		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.1914226978569999 | validation: 0.2172477154042361]
	TIME [epoch: 17.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20964382341709198		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.20964382341709198 | validation: 0.22677367652619912]
	TIME [epoch: 17.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220053115443309		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.2220053115443309 | validation: 0.23187177487407892]
	TIME [epoch: 17.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24447664135754626		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.24447664135754626 | validation: 0.19771187513270905]
	TIME [epoch: 17.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19857501012137974		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.19857501012137974 | validation: 0.2013682094192396]
	TIME [epoch: 17.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19322843475814974		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.19322843475814974 | validation: 0.182381467229712]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22425396847640133		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.22425396847640133 | validation: 0.20093681641931574]
	TIME [epoch: 17.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2327413971162981		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.2327413971162981 | validation: 0.22031062863661258]
	TIME [epoch: 17.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586680184624656		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.20586680184624656 | validation: 0.20267581299137882]
	TIME [epoch: 17.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23067450497189534		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.23067450497189534 | validation: 0.2288125846828805]
	TIME [epoch: 17.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18816114753653781		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.18816114753653781 | validation: 0.23944791650448977]
	TIME [epoch: 17.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18937927965634638		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.18937927965634638 | validation: 0.22944166455844084]
	TIME [epoch: 17.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18665722565168125		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.18665722565168125 | validation: 0.21325694163837336]
	TIME [epoch: 17.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1847767118010533		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.1847767118010533 | validation: 0.26027121267822123]
	TIME [epoch: 17.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21755653557345564		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.21755653557345564 | validation: 0.2192884903685574]
	TIME [epoch: 17.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19601094261806973		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.19601094261806973 | validation: 0.21497096620729567]
	TIME [epoch: 17.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21825620440857296		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.21825620440857296 | validation: 0.19437346949530077]
	TIME [epoch: 17.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19258727949526883		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.19258727949526883 | validation: 0.20652321786129574]
	TIME [epoch: 17.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22493033362972661		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.22493033362972661 | validation: 0.19646486977175892]
	TIME [epoch: 17.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829596032437948		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.1829596032437948 | validation: 0.20704851719151995]
	TIME [epoch: 17.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20023955496115678		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.20023955496115678 | validation: 0.19039923204165732]
	TIME [epoch: 17.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857978704211516		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.1857978704211516 | validation: 0.23462355384107553]
	TIME [epoch: 17.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195704589054672		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.195704589054672 | validation: 0.21187615292701983]
	TIME [epoch: 17.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18639505930384836		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.18639505930384836 | validation: 0.23668921692326603]
	TIME [epoch: 17.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18848946678386747		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18848946678386747 | validation: 0.20853188667523812]
	TIME [epoch: 17.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20178183390218757		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.20178183390218757 | validation: 0.21698771587609372]
	TIME [epoch: 17.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18420428220448945		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.18420428220448945 | validation: 0.19560603949207003]
	TIME [epoch: 17.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18565536176210568		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.18565536176210568 | validation: 0.2010460314785662]
	TIME [epoch: 17.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22771216467368083		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.22771216467368083 | validation: 0.2003936577511125]
	TIME [epoch: 17.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19542368841006166		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19542368841006166 | validation: 0.2112941704703392]
	TIME [epoch: 17.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18667792988110163		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18667792988110163 | validation: 0.19429155937693351]
	TIME [epoch: 17.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18240881459363234		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.18240881459363234 | validation: 0.2160445570578407]
	TIME [epoch: 17.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19533031081750268		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.19533031081750268 | validation: 0.23218684493651173]
	TIME [epoch: 17.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823665879109927		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1823665879109927 | validation: 0.20663046568815002]
	TIME [epoch: 17.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20579507380538953		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.20579507380538953 | validation: 0.18474345316636476]
	TIME [epoch: 17.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21346314574882846		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.21346314574882846 | validation: 0.1889964934075389]
	TIME [epoch: 17.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19333864170394277		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.19333864170394277 | validation: 0.21138504677983133]
	TIME [epoch: 17.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786411713110448		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1786411713110448 | validation: 0.22422666641186523]
	TIME [epoch: 17.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20767970265854435		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.20767970265854435 | validation: 0.18379762723362575]
	TIME [epoch: 17.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19938814327795404		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19938814327795404 | validation: 0.19023296013509627]
	TIME [epoch: 17.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19409525286023396		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.19409525286023396 | validation: 0.19022990925268152]
	TIME [epoch: 17.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17321333419799267		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.17321333419799267 | validation: 0.18550165330335097]
	TIME [epoch: 17.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18510753632891752		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.18510753632891752 | validation: 0.20083075447370952]
	TIME [epoch: 17.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818817630276493		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.1818817630276493 | validation: 0.20352848048885333]
	TIME [epoch: 17.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20684064219169854		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.20684064219169854 | validation: 0.22599200319757473]
	TIME [epoch: 17.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20520049441175575		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.20520049441175575 | validation: 0.20993561907491032]
	TIME [epoch: 17.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19429599943677836		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.19429599943677836 | validation: 0.1985438772534867]
	TIME [epoch: 17.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17987777293880075		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.17987777293880075 | validation: 0.19962386495094292]
	TIME [epoch: 17.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21975290663382413		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.21975290663382413 | validation: 0.18336667997715245]
	TIME [epoch: 17.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048979370953292		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.2048979370953292 | validation: 0.20082268192275857]
	TIME [epoch: 17.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19703255190940352		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.19703255190940352 | validation: 0.18895710715456754]
	TIME [epoch: 17.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18253257243045315		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.18253257243045315 | validation: 0.20061737755897197]
	TIME [epoch: 17.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393044968457287		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.18393044968457287 | validation: 0.17959885376060616]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977528343617665		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1977528343617665 | validation: 0.18190978310939188]
	TIME [epoch: 17.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21179620454380135		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.21179620454380135 | validation: 0.18528284426774494]
	TIME [epoch: 17.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18409649009664455		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.18409649009664455 | validation: 0.24472370299137441]
	TIME [epoch: 17.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19212048094200254		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.19212048094200254 | validation: 0.1829159955709314]
	TIME [epoch: 17.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20242864729626114		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.20242864729626114 | validation: 0.21063206144539454]
	TIME [epoch: 17.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17507161145523176		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.17507161145523176 | validation: 0.19827541820409694]
	TIME [epoch: 17.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17380348994418987		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.17380348994418987 | validation: 0.20470510799699151]
	TIME [epoch: 17.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22510390484076068		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.22510390484076068 | validation: 0.194592022465167]
	TIME [epoch: 17.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309197031660018		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.2309197031660018 | validation: 0.20157590145459445]
	TIME [epoch: 17.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19240620127919073		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.19240620127919073 | validation: 0.20344042599539897]
	TIME [epoch: 17.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17129380042811002		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.17129380042811002 | validation: 0.18042095354425752]
	TIME [epoch: 17.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17929581652335186		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.17929581652335186 | validation: 0.18105152091804938]
	TIME [epoch: 17.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040166806914107		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.2040166806914107 | validation: 0.2052378902012011]
	TIME [epoch: 17.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1927058966966352		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1927058966966352 | validation: 0.20225217178773527]
	TIME [epoch: 17.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787201594659894		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1787201594659894 | validation: 0.19014077897363102]
	TIME [epoch: 17.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17866009061417976		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.17866009061417976 | validation: 0.16910354001646363]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909550644653727		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1909550644653727 | validation: 0.19528275333524556]
	TIME [epoch: 17.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19408375834470165		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.19408375834470165 | validation: 0.18883205471590353]
	TIME [epoch: 17.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19436483619297099		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.19436483619297099 | validation: 0.19433380850189907]
	TIME [epoch: 17.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16695681870158707		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.16695681870158707 | validation: 0.18718044968746234]
	TIME [epoch: 17.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800525013433948		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.16800525013433948 | validation: 0.19103756715902467]
	TIME [epoch: 17.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17827749215958344		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17827749215958344 | validation: 0.1836637047120181]
	TIME [epoch: 17.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911562219236421		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1911562219236421 | validation: 0.19095787853365873]
	TIME [epoch: 17.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20485084324057942		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.20485084324057942 | validation: 0.182157763213035]
	TIME [epoch: 17.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184799229893795		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.184799229893795 | validation: 0.19064882469441047]
	TIME [epoch: 17.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18271257523290269		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.18271257523290269 | validation: 0.19437425351560084]
	TIME [epoch: 17.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17503286543318552		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.17503286543318552 | validation: 0.17818405288436057]
	TIME [epoch: 17.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19472276537841665		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.19472276537841665 | validation: 0.18525501362907848]
	TIME [epoch: 17.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18345725332836216		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18345725332836216 | validation: 0.19324999098993753]
	TIME [epoch: 17.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17486511260617577		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.17486511260617577 | validation: 0.19289169464879458]
	TIME [epoch: 17.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22666499486225988		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.22666499486225988 | validation: 0.17226061000347098]
	TIME [epoch: 17.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20317947147284637		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.20317947147284637 | validation: 0.18513551363498476]
	TIME [epoch: 17.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2213291819929905		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.2213291819929905 | validation: 0.17635184068424264]
	TIME [epoch: 17.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18066684668014585		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.18066684668014585 | validation: 0.19179389991318468]
	TIME [epoch: 17.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915153069404646		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1915153069404646 | validation: 0.18163838546253136]
	TIME [epoch: 17.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17906834539259203		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.17906834539259203 | validation: 0.19251622483964165]
	TIME [epoch: 17.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19325698676286107		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.19325698676286107 | validation: 0.17484251738062964]
	TIME [epoch: 17.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259030221599987		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.18259030221599987 | validation: 0.18721866487671973]
	TIME [epoch: 17.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196503441958302		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.196503441958302 | validation: 0.17536292849077528]
	TIME [epoch: 17.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19025777941261104		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.19025777941261104 | validation: 0.1754973443727398]
	TIME [epoch: 17.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17502603017522247		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.17502603017522247 | validation: 0.1748916470385826]
	TIME [epoch: 17.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221808691667737		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.17221808691667737 | validation: 0.18024484687508655]
	TIME [epoch: 17.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171652198366513		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.171652198366513 | validation: 0.17589313909708898]
	TIME [epoch: 17.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18044235067702574		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.18044235067702574 | validation: 0.18362910848795008]
	TIME [epoch: 17.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870933389015073		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1870933389015073 | validation: 0.17527973476289233]
	TIME [epoch: 17.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20380092426343147		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.20380092426343147 | validation: 0.18872817536162503]
	TIME [epoch: 17.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139975940846875		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.2139975940846875 | validation: 0.18872901034593084]
	TIME [epoch: 17.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18396213469840536		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.18396213469840536 | validation: 0.18459382881304923]
	TIME [epoch: 17.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15984179036565543		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.15984179036565543 | validation: 0.18138353780926833]
	TIME [epoch: 17.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17856779963684072		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.17856779963684072 | validation: 0.18947314379326996]
	TIME [epoch: 17.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17331599140569626		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.17331599140569626 | validation: 0.1858639601953238]
	TIME [epoch: 17.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16063508451134428		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.16063508451134428 | validation: 0.18726078659767878]
	TIME [epoch: 17.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17151687880649402		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.17151687880649402 | validation: 0.17975659951875406]
	TIME [epoch: 17.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19878011001083512		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.19878011001083512 | validation: 0.20206158206306812]
	TIME [epoch: 17.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20417290496574297		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.20417290496574297 | validation: 0.19958572417595072]
	TIME [epoch: 17.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18556427615675222		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.18556427615675222 | validation: 0.1748896904837437]
	TIME [epoch: 17.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16251014212574946		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.16251014212574946 | validation: 0.17192533125880477]
	TIME [epoch: 17.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18060486515369256		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.18060486515369256 | validation: 0.21917281222918125]
	TIME [epoch: 17.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18109188940310084		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.18109188940310084 | validation: 0.17216501364796843]
	TIME [epoch: 17.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17818020999710554		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.17818020999710554 | validation: 0.1853524154398201]
	TIME [epoch: 17.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18124479493737752		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.18124479493737752 | validation: 0.19076400572626012]
	TIME [epoch: 17.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18960740212808647		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18960740212808647 | validation: 0.17754114702849286]
	TIME [epoch: 17.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735458459730568		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.1735458459730568 | validation: 0.19033223288060525]
	TIME [epoch: 17.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16343637315054355		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.16343637315054355 | validation: 0.16902021972860062]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17742991135657182		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.17742991135657182 | validation: 0.17991144072603718]
	TIME [epoch: 17.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17492143868514065		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.17492143868514065 | validation: 0.19466352211552518]
	TIME [epoch: 17.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21247845325979522		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.21247845325979522 | validation: 0.18577083075219816]
	TIME [epoch: 17.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17794383210774706		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.17794383210774706 | validation: 0.1828002123888587]
	TIME [epoch: 17.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17237846198808052		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.17237846198808052 | validation: 0.18571450490820093]
	TIME [epoch: 17.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18260231200718396		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.18260231200718396 | validation: 0.19871734423003068]
	TIME [epoch: 17.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646170726213164		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.1646170726213164 | validation: 0.176800635784852]
	TIME [epoch: 17.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16984368127156635		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.16984368127156635 | validation: 0.17667931221465408]
	TIME [epoch: 17.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183214801243756		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.183214801243756 | validation: 0.17454475879297332]
	TIME [epoch: 17.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188910068347265		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.16188910068347265 | validation: 0.17269401933003115]
	TIME [epoch: 17.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717156344779838		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.1717156344779838 | validation: 0.16471685065556227]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859564863390744		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1859564863390744 | validation: 0.17290640963356446]
	TIME [epoch: 17.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18039234374471064		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18039234374471064 | validation: 0.18315151633333718]
	TIME [epoch: 17.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170675293535675		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.170675293535675 | validation: 0.16453824180361207]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19219936413251387		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.19219936413251387 | validation: 0.18375618054111947]
	TIME [epoch: 17.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18699912853907366		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.18699912853907366 | validation: 0.16910033001612576]
	TIME [epoch: 17.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16255318632171853		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.16255318632171853 | validation: 0.18868865252830083]
	TIME [epoch: 17.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680422984257207		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.1680422984257207 | validation: 0.20094425053907314]
	TIME [epoch: 17.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962037357285729		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.1962037357285729 | validation: 0.1745498742780553]
	TIME [epoch: 17.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17491801344874125		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.17491801344874125 | validation: 0.17468183699352213]
	TIME [epoch: 17.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18678026022264985		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.18678026022264985 | validation: 0.1881434902939313]
	TIME [epoch: 17.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16675184855097344		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.16675184855097344 | validation: 0.18640651631218608]
	TIME [epoch: 17.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16893926839640286		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.16893926839640286 | validation: 0.18533841723135316]
	TIME [epoch: 17.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17892875747488698		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.17892875747488698 | validation: 0.1933896071873606]
	TIME [epoch: 17.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16908562629722382		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.16908562629722382 | validation: 0.18424310505708869]
	TIME [epoch: 17.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17151806246807724		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.17151806246807724 | validation: 0.17934067329504316]
	TIME [epoch: 17.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20485449465491423		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.20485449465491423 | validation: 0.16934557566949857]
	TIME [epoch: 17.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18123084956859514		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.18123084956859514 | validation: 0.17879154490166704]
	TIME [epoch: 17.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17243605698304867		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.17243605698304867 | validation: 0.16815340325239603]
	TIME [epoch: 17.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15973511575261612		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.15973511575261612 | validation: 0.16624866035459954]
	TIME [epoch: 17.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16202722246589663		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.16202722246589663 | validation: 0.1761488451039989]
	TIME [epoch: 17.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17072645223490407		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.17072645223490407 | validation: 0.1694232200443955]
	TIME [epoch: 17.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702151454543639		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.1702151454543639 | validation: 0.17511045871507167]
	TIME [epoch: 17.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19979436427677025		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.19979436427677025 | validation: 0.16850382292606267]
	TIME [epoch: 17.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17443033059172142		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.17443033059172142 | validation: 0.17755211685895927]
	TIME [epoch: 17.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1794258110167491		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.1794258110167491 | validation: 0.1790431683598687]
	TIME [epoch: 17.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2097249507451259		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.2097249507451259 | validation: 0.17662235405336704]
	TIME [epoch: 17.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17233458980538047		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.17233458980538047 | validation: 0.17211694472352695]
	TIME [epoch: 17.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16853801097030016		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.16853801097030016 | validation: 0.1737727039732664]
	TIME [epoch: 17.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18598868284067183		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.18598868284067183 | validation: 0.17231590242073191]
	TIME [epoch: 17.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16070929372170561		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.16070929372170561 | validation: 0.17903452047935087]
	TIME [epoch: 17.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17010416982424334		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.17010416982424334 | validation: 0.1729407714369597]
	TIME [epoch: 17.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17431357593339983		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17431357593339983 | validation: 0.1815232777057503]
	TIME [epoch: 17.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19875275504719025		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.19875275504719025 | validation: 0.16846738491217758]
	TIME [epoch: 17.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18914225894831732		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.18914225894831732 | validation: 0.1775766151615323]
	TIME [epoch: 17.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17320290920696543		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.17320290920696543 | validation: 0.18971347559021676]
	TIME [epoch: 17.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.179236385027052		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.179236385027052 | validation: 0.19480401427654706]
	TIME [epoch: 17.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569543290784223		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.17569543290784223 | validation: 0.16293131876940448]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169835931277619		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.169835931277619 | validation: 0.16723065740633555]
	TIME [epoch: 17.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17135409205861737		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.17135409205861737 | validation: 0.17784350047014644]
	TIME [epoch: 17.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755529597785628		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.1755529597785628 | validation: 0.17286554633310872]
	TIME [epoch: 17.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727439491728523		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1727439491728523 | validation: 0.1760952482066024]
	TIME [epoch: 17.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713132243238137		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1713132243238137 | validation: 0.17835518916312884]
	TIME [epoch: 17.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576938710101656		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.1576938710101656 | validation: 0.16851616960509536]
	TIME [epoch: 17.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20626380665790245		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.20626380665790245 | validation: 0.19108818548480197]
	TIME [epoch: 17.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372446252525452		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.16372446252525452 | validation: 0.16963747445648866]
	TIME [epoch: 17.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790887501045228		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1790887501045228 | validation: 0.17649686626580596]
	TIME [epoch: 17.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17203712127524462		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.17203712127524462 | validation: 0.17430289488589548]
	TIME [epoch: 17.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21701515370024765		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.21701515370024765 | validation: 0.16050328119852636]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21544754784757478		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.21544754784757478 | validation: 0.17894710888881088]
	TIME [epoch: 17.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17811684126737923		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.17811684126737923 | validation: 0.18056149623782042]
	TIME [epoch: 17.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20166397832766603		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.20166397832766603 | validation: 0.16721925688712952]
	TIME [epoch: 17.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17202687418967397		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.17202687418967397 | validation: 0.1778900632940894]
	TIME [epoch: 17.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1881300084781358		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.1881300084781358 | validation: 0.17854964883152652]
	TIME [epoch: 17.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645503218731297		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1645503218731297 | validation: 0.17810292233964342]
	TIME [epoch: 17.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14756790548253929		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.14756790548253929 | validation: 0.18043273011317243]
	TIME [epoch: 17.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165858674907152		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.165858674907152 | validation: 0.1732893411769685]
	TIME [epoch: 17.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18261570347000694		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.18261570347000694 | validation: 0.17113844062437036]
	TIME [epoch: 17.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15583218762843645		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.15583218762843645 | validation: 0.17279311983665335]
	TIME [epoch: 17.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112078011211686		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.2112078011211686 | validation: 0.18072373944139752]
	TIME [epoch: 17.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015411323723428		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.17015411323723428 | validation: 0.16667976889558322]
	TIME [epoch: 17.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161844647603069		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.161844647603069 | validation: 0.1677330457414225]
	TIME [epoch: 17.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20835162030076929		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.20835162030076929 | validation: 0.18169362464117056]
	TIME [epoch: 17.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16202252278820176		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.16202252278820176 | validation: 0.18752471345630803]
	TIME [epoch: 17.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18614466069985475		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.18614466069985475 | validation: 0.17770055217005887]
	TIME [epoch: 17.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18032782256604246		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.18032782256604246 | validation: 0.17902341422689974]
	TIME [epoch: 17.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716261758594434		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.1716261758594434 | validation: 0.17238441141725724]
	TIME [epoch: 17.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1993352639175322		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1993352639175322 | validation: 0.16675239160506627]
	TIME [epoch: 17.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845488595817414		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.1845488595817414 | validation: 0.18043481048733923]
	TIME [epoch: 17.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17884339981958053		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.17884339981958053 | validation: 0.1691727285458936]
	TIME [epoch: 17.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16712635426015973		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.16712635426015973 | validation: 0.1647763052298805]
	TIME [epoch: 17.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623444694803464		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.1623444694803464 | validation: 0.16848289251863238]
	TIME [epoch: 17.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16764745504872677		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.16764745504872677 | validation: 0.17342374170211855]
	TIME [epoch: 17.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19993672023920972		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.19993672023920972 | validation: 0.16744334610952333]
	TIME [epoch: 17.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16163786438992542		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.16163786438992542 | validation: 0.17489838226095103]
	TIME [epoch: 17.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18021472442067352		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.18021472442067352 | validation: 0.17162471216429717]
	TIME [epoch: 17.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17802591807814303		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.17802591807814303 | validation: 0.1707026590842657]
	TIME [epoch: 17.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20445860530193433		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.20445860530193433 | validation: 0.17675224921587215]
	TIME [epoch: 17.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17540581734550226		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.17540581734550226 | validation: 0.1748746552996375]
	TIME [epoch: 17.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579857694108191		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1579857694108191 | validation: 0.1835141222512917]
	TIME [epoch: 17.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19666586544449516		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.19666586544449516 | validation: 0.16791409502582963]
	TIME [epoch: 17.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19151683512656864		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.19151683512656864 | validation: 0.1636766816251665]
	TIME [epoch: 17.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974391905134026		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.16974391905134026 | validation: 0.18026750812111395]
	TIME [epoch: 17.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16853731764684204		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.16853731764684204 | validation: 0.16524990931818712]
	TIME [epoch: 17.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17639806767512178		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.17639806767512178 | validation: 0.17338093457972464]
	TIME [epoch: 17.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17469284933155943		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.17469284933155943 | validation: 0.16618215590724428]
	TIME [epoch: 17.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16098336347325004		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.16098336347325004 | validation: 0.17329198043166652]
	TIME [epoch: 17.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16779094567100278		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.16779094567100278 | validation: 0.17830222261153603]
	TIME [epoch: 17.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15694011295431953		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.15694011295431953 | validation: 0.16256015438740282]
	TIME [epoch: 17.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20242400285912118		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.20242400285912118 | validation: 0.16210399083095556]
	TIME [epoch: 17.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18189273174304174		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.18189273174304174 | validation: 0.1608263697219891]
	TIME [epoch: 17.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19612484769715238		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.19612484769715238 | validation: 0.17959316406659437]
	TIME [epoch: 17.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020397040379823		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.17020397040379823 | validation: 0.18770364376710175]
	TIME [epoch: 17.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614086253786968		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.1614086253786968 | validation: 0.18293392799587935]
	TIME [epoch: 17.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642970911613965		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1642970911613965 | validation: 0.16513964049771507]
	TIME [epoch: 17.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056682474842904		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.16056682474842904 | validation: 0.16253836980893638]
	TIME [epoch: 17.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16648010415703532		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.16648010415703532 | validation: 0.17255393885571513]
	TIME [epoch: 17.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20134305687263904		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.20134305687263904 | validation: 0.1700802406016282]
	TIME [epoch: 17.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16519798814721443		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.16519798814721443 | validation: 0.18171149082912774]
	TIME [epoch: 17.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16878186754150237		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.16878186754150237 | validation: 0.17508322914548707]
	TIME [epoch: 17.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15419605036592554		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.15419605036592554 | validation: 0.17410945832356764]
	TIME [epoch: 17.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15652815314227728		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.15652815314227728 | validation: 0.16847741753878567]
	TIME [epoch: 17.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1898726220395826		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1898726220395826 | validation: 0.16986103484664]
	TIME [epoch: 17.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1873630608182299		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.1873630608182299 | validation: 0.17131067668840336]
	TIME [epoch: 17.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766508014848782		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1766508014848782 | validation: 0.1643172056163884]
	TIME [epoch: 17.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16952824672315195		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.16952824672315195 | validation: 0.1734531504535641]
	TIME [epoch: 17.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434897075456898		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.17434897075456898 | validation: 0.17360858726799341]
	TIME [epoch: 17.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17291640478666004		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.17291640478666004 | validation: 0.16758723179796928]
	TIME [epoch: 17.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16590540888054112		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.16590540888054112 | validation: 0.17282279161754127]
	TIME [epoch: 17.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16534681891673436		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.16534681891673436 | validation: 0.16086827428278178]
	TIME [epoch: 17.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17623632712484838		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.17623632712484838 | validation: 0.17637731958859826]
	TIME [epoch: 17.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605965090247246		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1605965090247246 | validation: 0.1650898381127764]
	TIME [epoch: 17.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570454535786454		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.15570454535786454 | validation: 0.17175731168463235]
	TIME [epoch: 17.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428408995471682		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.15428408995471682 | validation: 0.17654114157639397]
	TIME [epoch: 17.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17924262433053284		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.17924262433053284 | validation: 0.1592188213723418]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252415421661087		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.16252415421661087 | validation: 0.16372055331182916]
	TIME [epoch: 17.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800268256096393		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.16800268256096393 | validation: 0.16537282926788427]
	TIME [epoch: 17.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17263460211579265		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.17263460211579265 | validation: 0.17276638625856355]
	TIME [epoch: 17.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16471893562437748		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.16471893562437748 | validation: 0.17380136195477505]
	TIME [epoch: 17.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242100414078348		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.16242100414078348 | validation: 0.16312694780929607]
	TIME [epoch: 17.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17590170937651878		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.17590170937651878 | validation: 0.16869727438294915]
	TIME [epoch: 17.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16475476437211858		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.16475476437211858 | validation: 0.1729503933497865]
	TIME [epoch: 17.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15699432539806663		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.15699432539806663 | validation: 0.18067626503367393]
	TIME [epoch: 17.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16249101648966818		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.16249101648966818 | validation: 0.17658873129893077]
	TIME [epoch: 17.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16678792302053938		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.16678792302053938 | validation: 0.17557696444019844]
	TIME [epoch: 17.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296098291034639		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.16296098291034639 | validation: 0.16728159706425832]
	TIME [epoch: 17.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17894214870645592		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.17894214870645592 | validation: 0.16419741254585418]
	TIME [epoch: 17.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759938232572391		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.1759938232572391 | validation: 0.16340322117922018]
	TIME [epoch: 17.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15527753454727541		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.15527753454727541 | validation: 0.16889778332050753]
	TIME [epoch: 17.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913402448772179		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.1913402448772179 | validation: 0.16562974325636157]
	TIME [epoch: 17.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17999479287851428		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.17999479287851428 | validation: 0.17746951187639043]
	TIME [epoch: 17.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15744963500423984		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.15744963500423984 | validation: 0.17308555208184348]
	TIME [epoch: 17.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19286863533837903		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.19286863533837903 | validation: 0.16302209338612478]
	TIME [epoch: 17.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18145209823887737		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.18145209823887737 | validation: 0.16653241668195987]
	TIME [epoch: 17.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17093272037786897		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.17093272037786897 | validation: 0.1682594999142882]
	TIME [epoch: 17.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617895560271657		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1617895560271657 | validation: 0.17048222593917883]
	TIME [epoch: 17.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659788756619362		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.1659788756619362 | validation: 0.16768093045025598]
	TIME [epoch: 17.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17750739665498644		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.17750739665498644 | validation: 0.16864036763639498]
	TIME [epoch: 17.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19108827029831996		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.19108827029831996 | validation: 0.15958837534871737]
	TIME [epoch: 17.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615130630512925		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.1615130630512925 | validation: 0.17349062137441482]
	TIME [epoch: 17.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15941665896874613		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.15941665896874613 | validation: 0.16616702195825622]
	TIME [epoch: 17.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307153234363677		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.15307153234363677 | validation: 0.1553624418792002]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20571826929646925		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.20571826929646925 | validation: 0.1679707011868048]
	TIME [epoch: 17.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505993020973942		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1505993020973942 | validation: 0.1771675458605029]
	TIME [epoch: 17.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548783274919655		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.1548783274919655 | validation: 0.17450705759876223]
	TIME [epoch: 17.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15964478098749568		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.15964478098749568 | validation: 0.16231275979576007]
	TIME [epoch: 17.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17012149961682885		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.17012149961682885 | validation: 0.16579383180711196]
	TIME [epoch: 17.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16750741445679188		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.16750741445679188 | validation: 0.16938387574773814]
	TIME [epoch: 17.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16885475315135895		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.16885475315135895 | validation: 0.1618087530621237]
	TIME [epoch: 17.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15454985083027778		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.15454985083027778 | validation: 0.16430974408447008]
	TIME [epoch: 17.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16059729933706135		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.16059729933706135 | validation: 0.17365851408305238]
	TIME [epoch: 17.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20066910725109294		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.20066910725109294 | validation: 0.15551814833055302]
	TIME [epoch: 17.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17451412791080875		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.17451412791080875 | validation: 0.1727092223173489]
	TIME [epoch: 17.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18577252237143657		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.18577252237143657 | validation: 0.16736306617406477]
	TIME [epoch: 17.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15738886956216308		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.15738886956216308 | validation: 0.1681933255343604]
	TIME [epoch: 17.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16451028313442354		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.16451028313442354 | validation: 0.16616529110225864]
	TIME [epoch: 17.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774327855950458		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.1774327855950458 | validation: 0.1720994574269707]
	TIME [epoch: 17.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15373396644377763		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.15373396644377763 | validation: 0.1653234725513406]
	TIME [epoch: 17.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17260030550799546		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.17260030550799546 | validation: 0.1615562599417549]
	TIME [epoch: 17.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16022739520323062		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.16022739520323062 | validation: 0.17260395382550714]
	TIME [epoch: 17.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16733652653494457		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.16733652653494457 | validation: 0.1651752043052474]
	TIME [epoch: 17.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16107951527849904		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.16107951527849904 | validation: 0.15854778201909028]
	TIME [epoch: 17.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159171386862717		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.16159171386862717 | validation: 0.16872963133983782]
	TIME [epoch: 17.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16386550740647562		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.16386550740647562 | validation: 0.17573426041175327]
	TIME [epoch: 17.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18787013141289205		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.18787013141289205 | validation: 0.15538821569758046]
	TIME [epoch: 17.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720050408195435		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.1720050408195435 | validation: 0.16922548696399398]
	TIME [epoch: 17.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111591071321164		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.17111591071321164 | validation: 0.17345276525294653]
	TIME [epoch: 17.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17215307196879057		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.17215307196879057 | validation: 0.168165080064882]
	TIME [epoch: 17.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15867453965848982		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.15867453965848982 | validation: 0.1581359899000938]
	TIME [epoch: 17.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15987063453479786		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.15987063453479786 | validation: 0.17408165408204213]
	TIME [epoch: 17.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592668676820978		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1592668676820978 | validation: 0.1738467209986192]
	TIME [epoch: 17.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16486082796659152		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.16486082796659152 | validation: 0.17233528926675773]
	TIME [epoch: 17.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18403117005839617		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.18403117005839617 | validation: 0.15406265780656087]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16302162694927158		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.16302162694927158 | validation: 0.1672977374664083]
	TIME [epoch: 17.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158613421978273		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.158613421978273 | validation: 0.15970823356489938]
	TIME [epoch: 17.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518042953837669		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1518042953837669 | validation: 0.15591796918112502]
	TIME [epoch: 17.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20829996853464108		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.20829996853464108 | validation: 0.16043336362165245]
	TIME [epoch: 17.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17156098389331817		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.17156098389331817 | validation: 0.1764425482239]
	TIME [epoch: 17.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662770136952348		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.1662770136952348 | validation: 0.1653036117610569]
	TIME [epoch: 17.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16032038365153337		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.16032038365153337 | validation: 0.16287158684637687]
	TIME [epoch: 17.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562685062403637		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.1562685062403637 | validation: 0.17112183917385843]
	TIME [epoch: 17.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598533171587747		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.1598533171587747 | validation: 0.16185867986664965]
	TIME [epoch: 17.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17679238670957204		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.17679238670957204 | validation: 0.1563667844499455]
	TIME [epoch: 17.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21188891359819395		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.21188891359819395 | validation: 0.1557653401695175]
	TIME [epoch: 17.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16175591150391241		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.16175591150391241 | validation: 0.15989221314305876]
	TIME [epoch: 17.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15659675872221873		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.15659675872221873 | validation: 0.16156205250585803]
	TIME [epoch: 17.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16596160165749815		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.16596160165749815 | validation: 0.17125131157173973]
	TIME [epoch: 17.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19070473959238973		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.19070473959238973 | validation: 0.15571198719525498]
	TIME [epoch: 17.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17802976700069534		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.17802976700069534 | validation: 0.17444134251951762]
	TIME [epoch: 17.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15702885747345563		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.15702885747345563 | validation: 0.15782038790826222]
	TIME [epoch: 17.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16913503435515703		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.16913503435515703 | validation: 0.16426094378442035]
	TIME [epoch: 17.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029358182951042		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.2029358182951042 | validation: 0.16677934478322776]
	TIME [epoch: 17.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15728126263861672		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.15728126263861672 | validation: 0.15615608029087755]
	TIME [epoch: 17.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556553079094365		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1556553079094365 | validation: 0.1732789446980814]
	TIME [epoch: 17.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18710729532991136		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.18710729532991136 | validation: 0.16302690860097016]
	TIME [epoch: 17.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16911411636908752		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.16911411636908752 | validation: 0.16046754962367665]
	TIME [epoch: 17.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20067924290993472		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.20067924290993472 | validation: 0.16226843233396288]
	TIME [epoch: 17.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16459547325636517		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.16459547325636517 | validation: 0.15699064131224702]
	TIME [epoch: 17.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16852272554714792		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.16852272554714792 | validation: 0.16112131366828625]
	TIME [epoch: 17.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17709535669970083		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.17709535669970083 | validation: 0.16381239371341172]
	TIME [epoch: 17.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14845934465728575		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.14845934465728575 | validation: 0.16186829328046204]
	TIME [epoch: 17.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18804101107426166		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.18804101107426166 | validation: 0.16366461172210592]
	TIME [epoch: 17.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16401693958163607		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.16401693958163607 | validation: 0.15535931084286864]
	TIME [epoch: 17.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17997415573229347		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.17997415573229347 | validation: 0.17662790198980005]
	TIME [epoch: 17.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162283134923496		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.162283134923496 | validation: 0.16021561864852749]
	TIME [epoch: 17.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16335790294030353		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.16335790294030353 | validation: 0.1632970882490007]
	TIME [epoch: 17.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17641112990581065		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.17641112990581065 | validation: 0.16210676810714486]
	TIME [epoch: 17.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16036999068355495		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.16036999068355495 | validation: 0.17039090580808997]
	TIME [epoch: 17.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16752258330947478		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.16752258330947478 | validation: 0.16723580268966684]
	TIME [epoch: 17.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16305763167985077		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.16305763167985077 | validation: 0.16346238621806516]
	TIME [epoch: 17.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297140681771265		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.15297140681771265 | validation: 0.1577072898150282]
	TIME [epoch: 17.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17609727742641978		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.17609727742641978 | validation: 0.16444707322668695]
	TIME [epoch: 17.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502962316651229		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1502962316651229 | validation: 0.16472802643419004]
	TIME [epoch: 17.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18594537883067264		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.18594537883067264 | validation: 0.16360231716644247]
	TIME [epoch: 17.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16430442561940461		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.16430442561940461 | validation: 0.16686321076624347]
	TIME [epoch: 17.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15384221214048904		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.15384221214048904 | validation: 0.15800543227340066]
	TIME [epoch: 17.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543579533099062		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1543579533099062 | validation: 0.1685481539909211]
	TIME [epoch: 17.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635514287085493		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.1635514287085493 | validation: 0.17281053610401853]
	TIME [epoch: 17.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16505084053047933		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.16505084053047933 | validation: 0.16515542546538378]
	TIME [epoch: 17.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17077093331060855		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.17077093331060855 | validation: 0.17501258474121728]
	TIME [epoch: 17.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16635925135198798		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.16635925135198798 | validation: 0.16410346908822532]
	TIME [epoch: 17.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16182350317982097		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.16182350317982097 | validation: 0.1585895305131735]
	TIME [epoch: 17.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15360728151475855		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.15360728151475855 | validation: 0.16019203053070205]
	TIME [epoch: 17.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17088037624281568		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.17088037624281568 | validation: 0.15452341684437623]
	TIME [epoch: 17.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1627401087459092		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1627401087459092 | validation: 0.1620632313669476]
	TIME [epoch: 17.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16943954228345043		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.16943954228345043 | validation: 0.1530598147201519]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17390221251389668		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.17390221251389668 | validation: 0.15749313808894155]
	TIME [epoch: 17.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15261639378465655		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15261639378465655 | validation: 0.1574965855431617]
	TIME [epoch: 17.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18214280822430845		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.18214280822430845 | validation: 0.17258243047543162]
	TIME [epoch: 17.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15726595540111699		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.15726595540111699 | validation: 0.16944620985215886]
	TIME [epoch: 17.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15662241877859245		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.15662241877859245 | validation: 0.15716510163256298]
	TIME [epoch: 17.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16148034054421986		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.16148034054421986 | validation: 0.1588938428955359]
	TIME [epoch: 17.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17620853102928605		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.17620853102928605 | validation: 0.15834824586266086]
	TIME [epoch: 17.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158371797876667		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.158371797876667 | validation: 0.16081435340667344]
	TIME [epoch: 17.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802517694873498		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.1802517694873498 | validation: 0.17196319137127328]
	TIME [epoch: 17.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16707461582006555		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.16707461582006555 | validation: 0.17485156402780194]
	TIME [epoch: 17.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18939108094138557		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.18939108094138557 | validation: 0.1628199159253355]
	TIME [epoch: 17.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16617562598614946		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.16617562598614946 | validation: 0.16558839085726793]
	TIME [epoch: 17.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14778768729714126		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.14778768729714126 | validation: 0.1544980797564255]
	TIME [epoch: 17.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19471302749611308		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.19471302749611308 | validation: 0.16512440005460072]
	TIME [epoch: 17.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586902881960205		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.1586902881960205 | validation: 0.1676219062987963]
	TIME [epoch: 17.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16422337577348511		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.16422337577348511 | validation: 0.1655837070202101]
	TIME [epoch: 17.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17039841345652484		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.17039841345652484 | validation: 0.15766897363610885]
	TIME [epoch: 17.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824411294445927		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.1824411294445927 | validation: 0.15619843045709295]
	TIME [epoch: 17.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264847004878738		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.16264847004878738 | validation: 0.1656636895038087]
	TIME [epoch: 17.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16891108924025594		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.16891108924025594 | validation: 0.16732016065188893]
	TIME [epoch: 17.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15940421459701656		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.15940421459701656 | validation: 0.1612855478646266]
	TIME [epoch: 17.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15602132291622273		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.15602132291622273 | validation: 0.1654345248207806]
	TIME [epoch: 17.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15680692153447118		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.15680692153447118 | validation: 0.16502848662865782]
	TIME [epoch: 17.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522428816766998		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1522428816766998 | validation: 0.17236566446475904]
	TIME [epoch: 17.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16036995063834253		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.16036995063834253 | validation: 0.1647655395069304]
	TIME [epoch: 17.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585919746256438		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1585919746256438 | validation: 0.17094273179842467]
	TIME [epoch: 17.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16163909670913026		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.16163909670913026 | validation: 0.1706014356528367]
	TIME [epoch: 17.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337926550998436		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.20337926550998436 | validation: 0.15114878210026408]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911060568045222		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.1911060568045222 | validation: 0.15501924140230736]
	TIME [epoch: 17.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15821831552214508		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.15821831552214508 | validation: 0.15790712322364475]
	TIME [epoch: 17.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15899351270669593		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.15899351270669593 | validation: 0.16677678895904477]
	TIME [epoch: 17.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15358899118966637		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15358899118966637 | validation: 0.15421477633053113]
	TIME [epoch: 17.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721005811021752		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.1721005811021752 | validation: 0.1714433389902396]
	TIME [epoch: 17.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18493055380587686		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.18493055380587686 | validation: 0.16693946580540364]
	TIME [epoch: 17.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842922712965253		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1842922712965253 | validation: 0.16395584562514626]
	TIME [epoch: 17.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19899817449205215		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.19899817449205215 | validation: 0.15979571817508026]
	TIME [epoch: 17.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163334444809576		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.163334444809576 | validation: 0.15833351925605763]
	TIME [epoch: 17.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16161034487221493		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.16161034487221493 | validation: 0.1765412424449006]
	TIME [epoch: 17.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899922484396349		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.1899922484396349 | validation: 0.16211942123295783]
	TIME [epoch: 17.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145385271273837		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.145385271273837 | validation: 0.17222062728711948]
	TIME [epoch: 17.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15542135931066267		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.15542135931066267 | validation: 0.15177647338083916]
	TIME [epoch: 17.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816250099461103		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.1816250099461103 | validation: 0.15631720943018446]
	TIME [epoch: 17.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425628876835643		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.15425628876835643 | validation: 0.15494746804269816]
	TIME [epoch: 17.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15712215959326256		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.15712215959326256 | validation: 0.1651834352678502]
	TIME [epoch: 17.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15692556259468254		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.15692556259468254 | validation: 0.16146150725800995]
	TIME [epoch: 17.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21476024837113128		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.21476024837113128 | validation: 0.15753015605619478]
	TIME [epoch: 17.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16607547889618757		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.16607547889618757 | validation: 0.1651932561241991]
	TIME [epoch: 17.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567185093210161		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.1567185093210161 | validation: 0.1646068649019756]
	TIME [epoch: 17.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15226155101120228		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.15226155101120228 | validation: 0.16217499556971265]
	TIME [epoch: 17.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17130020960856746		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.17130020960856746 | validation: 0.16021991548740597]
	TIME [epoch: 17.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169722169279696		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.16169722169279696 | validation: 0.16682337008756806]
	TIME [epoch: 17.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663528880663798		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.1663528880663798 | validation: 0.17621444913462547]
	TIME [epoch: 17.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375238464545604		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.15375238464545604 | validation: 0.15761729336766]
	TIME [epoch: 17.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19468660725267506		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.19468660725267506 | validation: 0.15807584826509585]
	TIME [epoch: 17.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16512894748813864		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.16512894748813864 | validation: 0.17320452593447705]
	TIME [epoch: 17.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573091110481306		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.17573091110481306 | validation: 0.16310676521783646]
	TIME [epoch: 17.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912236035604529		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.14912236035604529 | validation: 0.16809241792911522]
	TIME [epoch: 17.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17949100694855827		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.17949100694855827 | validation: 0.17010491447284148]
	TIME [epoch: 17.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16876446491706992		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.16876446491706992 | validation: 0.17665378973289025]
	TIME [epoch: 17.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16365582800849962		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.16365582800849962 | validation: 0.1642129843437626]
	TIME [epoch: 17.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884019348996772		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.1884019348996772 | validation: 0.1681609660733832]
	TIME [epoch: 17.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17949078933121035		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.17949078933121035 | validation: 0.16532031305138167]
	TIME [epoch: 17.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15744716198616943		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.15744716198616943 | validation: 0.1585606196772883]
	TIME [epoch: 17.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16098946776200626		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.16098946776200626 | validation: 0.17011278272480015]
	TIME [epoch: 17.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594215835235957		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.1594215835235957 | validation: 0.17521180136499565]
	TIME [epoch: 17.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15279560072936132		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.15279560072936132 | validation: 0.15621153312048394]
	TIME [epoch: 17.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16602198449690028		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.16602198449690028 | validation: 0.16363460586728032]
	TIME [epoch: 17.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16655286695013022		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.16655286695013022 | validation: 0.16419300214067228]
	TIME [epoch: 17.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16061346727529707		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.16061346727529707 | validation: 0.1585785310380617]
	TIME [epoch: 17.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669150736265721		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.1669150736265721 | validation: 0.16048222800626558]
	TIME [epoch: 17.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620852125142877		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.1620852125142877 | validation: 0.1720337166006113]
	TIME [epoch: 17.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150727378514703		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.150727378514703 | validation: 0.16312246566644584]
	TIME [epoch: 17.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16356283948706285		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.16356283948706285 | validation: 0.16416579172326493]
	TIME [epoch: 17.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166690759466243		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.166690759466243 | validation: 0.15902755442537883]
	TIME [epoch: 17.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15568666678235965		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.15568666678235965 | validation: 0.16209971581795832]
	TIME [epoch: 17.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043234394127105		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.17043234394127105 | validation: 0.16934981911001065]
	TIME [epoch: 17.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17642586543809846		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.17642586543809846 | validation: 0.17032305275438628]
	TIME [epoch: 17.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622853950435499		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1622853950435499 | validation: 0.16855269743049228]
	TIME [epoch: 17.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530932019261937		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.16530932019261937 | validation: 0.1646853482803374]
	TIME [epoch: 17.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668858764922555		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1668858764922555 | validation: 0.17203443527541876]
	TIME [epoch: 17.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17724664470458396		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.17724664470458396 | validation: 0.16813331887530988]
	TIME [epoch: 17.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662376355260256		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.1662376355260256 | validation: 0.16704028188804432]
	TIME [epoch: 17.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16840348826027074		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.16840348826027074 | validation: 0.15726309707841174]
	TIME [epoch: 17.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155879702524247		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.155879702524247 | validation: 0.1584495132879336]
	TIME [epoch: 17.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372280146531576		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.16372280146531576 | validation: 0.16349742510785253]
	TIME [epoch: 17.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561767637581419		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1561767637581419 | validation: 0.16683005421828073]
	TIME [epoch: 17.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18566784214063525		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.18566784214063525 | validation: 0.17195119781278723]
	TIME [epoch: 17.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559886176207864		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.1559886176207864 | validation: 0.16576602546592842]
	TIME [epoch: 17.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610647421138646		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1610647421138646 | validation: 0.15144902808942454]
	TIME [epoch: 17.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754632394603606		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.14754632394603606 | validation: 0.1596071168593184]
	TIME [epoch: 17.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910889057942146		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.15910889057942146 | validation: 0.16213253079966194]
	TIME [epoch: 17.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682625366178209		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.1682625366178209 | validation: 0.16093048773723895]
	TIME [epoch: 17.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14774894106192518		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.14774894106192518 | validation: 0.15837897524543965]
	TIME [epoch: 17.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852441631917543		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1852441631917543 | validation: 0.17012842365570552]
	TIME [epoch: 17.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17827333862210684		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.17827333862210684 | validation: 0.16567121221103942]
	TIME [epoch: 17.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16128974802514123		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.16128974802514123 | validation: 0.15559410159232165]
	TIME [epoch: 17.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689803812656792		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.1689803812656792 | validation: 0.16076095979682703]
	TIME [epoch: 17.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15188564421632927		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.15188564421632927 | validation: 0.16186655137251732]
	TIME [epoch: 17.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15672224229564197		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.15672224229564197 | validation: 0.1653061084266292]
	TIME [epoch: 17.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18219040867918412		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.18219040867918412 | validation: 0.1603308750451618]
	TIME [epoch: 17.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892203708201115		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.1892203708201115 | validation: 0.1581305172406302]
	TIME [epoch: 17.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15899843754008902		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.15899843754008902 | validation: 0.15890296344224367]
	TIME [epoch: 17.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19255160524702572		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.19255160524702572 | validation: 0.16146238964877685]
	TIME [epoch: 17.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15862200512162022		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.15862200512162022 | validation: 0.16084048331082335]
	TIME [epoch: 17.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15634433189953334		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.15634433189953334 | validation: 0.16000007859306564]
	TIME [epoch: 17.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16901383418964053		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.16901383418964053 | validation: 0.16378091137188014]
	TIME [epoch: 17.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16329676606562016		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.16329676606562016 | validation: 0.16783554755070218]
	TIME [epoch: 17.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16811701720412914		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.16811701720412914 | validation: 0.1660013936726244]
	TIME [epoch: 17.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15207098584462236		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.15207098584462236 | validation: 0.16760193009880675]
	TIME [epoch: 17.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16243526953376997		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.16243526953376997 | validation: 0.1671651303943117]
	TIME [epoch: 17.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20643906416385083		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.20643906416385083 | validation: 0.1672706194838691]
	TIME [epoch: 17.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16088816815923715		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.16088816815923715 | validation: 0.1629744944547145]
	TIME [epoch: 17.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15599617328050136		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.15599617328050136 | validation: 0.16111496844400658]
	TIME [epoch: 17.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16145704394015653		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.16145704394015653 | validation: 0.16420322713820368]
	TIME [epoch: 17.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743655638568615		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.1743655638568615 | validation: 0.152963874309775]
	TIME [epoch: 17.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16825300571431964		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.16825300571431964 | validation: 0.16357025302199146]
	TIME [epoch: 17.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15589284236016804		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.15589284236016804 | validation: 0.16323999147170054]
	TIME [epoch: 17.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16956739452773434		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.16956739452773434 | validation: 0.1574433638764749]
	TIME [epoch: 17.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14784872491146864		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.14784872491146864 | validation: 0.16387649652572944]
	TIME [epoch: 17.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17527027837892217		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.17527027837892217 | validation: 0.16340915866333744]
	TIME [epoch: 17.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15360921337093675		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.15360921337093675 | validation: 0.1529519836036376]
	TIME [epoch: 17.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18946288421793317		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.18946288421793317 | validation: 0.16312127139941024]
	TIME [epoch: 17.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164461084289574		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.164461084289574 | validation: 0.16801249900060972]
	TIME [epoch: 17.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16417180545282883		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.16417180545282883 | validation: 0.17708149971559897]
	TIME [epoch: 17.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516742340072521		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.1516742340072521 | validation: 0.17241088196286086]
	TIME [epoch: 17.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15100485329829919		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.15100485329829919 | validation: 0.16031710441351318]
	TIME [epoch: 17.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17139689702712554		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.17139689702712554 | validation: 0.16624853468203998]
	TIME [epoch: 17.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19593895762296248		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.19593895762296248 | validation: 0.1679243173594509]
	TIME [epoch: 17.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17374795790860648		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.17374795790860648 | validation: 0.1621952670343766]
	TIME [epoch: 17.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15043597442644274		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.15043597442644274 | validation: 0.16695114604704397]
	TIME [epoch: 17.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18589673536590784		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.18589673536590784 | validation: 0.15500235251278344]
	TIME [epoch: 17.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16184621903395405		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.16184621903395405 | validation: 0.15739612134592634]
	TIME [epoch: 17.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19700290246973454		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.19700290246973454 | validation: 0.16700924305829762]
	TIME [epoch: 17.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717787882381055		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1717787882381055 | validation: 0.15306369209345858]
	TIME [epoch: 17.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504192452049927		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.1504192452049927 | validation: 0.1641002176072398]
	TIME [epoch: 17.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15213415351823467		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.15213415351823467 | validation: 0.15654737760062923]
	TIME [epoch: 17.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15601372087875226		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15601372087875226 | validation: 0.1673997556409521]
	TIME [epoch: 17.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590270718792275		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.1590270718792275 | validation: 0.16235578797048525]
	TIME [epoch: 17.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622103896773777		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.1622103896773777 | validation: 0.15965457575251987]
	TIME [epoch: 17.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15946333601487264		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.15946333601487264 | validation: 0.15025561937839793]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603438439925871		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.1603438439925871 | validation: 0.15896391766673695]
	TIME [epoch: 17.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690844194670889		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.1690844194670889 | validation: 0.16238940941363766]
	TIME [epoch: 17.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16555864974214507		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.16555864974214507 | validation: 0.1558531706356626]
	TIME [epoch: 17.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538344283536118		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.1538344283536118 | validation: 0.15994807894554458]
	TIME [epoch: 17.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425599269624181		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.1425599269624181 | validation: 0.15825401352204466]
	TIME [epoch: 17.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16350637950047076		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.16350637950047076 | validation: 0.15154528951455853]
	TIME [epoch: 17.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14664711935396804		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.14664711935396804 | validation: 0.15780459429036453]
	TIME [epoch: 17.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14906349781888462		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.14906349781888462 | validation: 0.1553365231225709]
	TIME [epoch: 17.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19354583214358143		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.19354583214358143 | validation: 0.16321397701772533]
	TIME [epoch: 17.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974331245303537		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.16974331245303537 | validation: 0.16232687099235454]
	TIME [epoch: 17.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660958318938133		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.1660958318938133 | validation: 0.16687188268748943]
	TIME [epoch: 17.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15762486635131484		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.15762486635131484 | validation: 0.15812680106087515]
	TIME [epoch: 17.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15903426805301482		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.15903426805301482 | validation: 0.16607955863478407]
	TIME [epoch: 17.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708204545237459		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.1708204545237459 | validation: 0.16255922605661247]
	TIME [epoch: 17.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15707503248028232		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.15707503248028232 | validation: 0.1611576070752388]
	TIME [epoch: 17.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17051122446611394		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.17051122446611394 | validation: 0.1681268673608005]
	TIME [epoch: 17.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16688659690079855		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.16688659690079855 | validation: 0.15715969601508065]
	TIME [epoch: 17.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623066664261468		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.1623066664261468 | validation: 0.16332970706837868]
	TIME [epoch: 17.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15917720719944584		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.15917720719944584 | validation: 0.15615938856748435]
	TIME [epoch: 17.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16654638223522603		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.16654638223522603 | validation: 0.15693100558443984]
	TIME [epoch: 17.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14668702686950305		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.14668702686950305 | validation: 0.16401068584984857]
	TIME [epoch: 17.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751368061584733		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.18751368061584733 | validation: 0.15661553875780637]
	TIME [epoch: 17.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15553395178309687		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.15553395178309687 | validation: 0.1579560454551835]
	TIME [epoch: 17.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043936671627685		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.17043936671627685 | validation: 0.16900843776411723]
	TIME [epoch: 17.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944210730068527		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.14944210730068527 | validation: 0.16497681676412182]
	TIME [epoch: 17.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16370709231099248		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.16370709231099248 | validation: 0.1601282778129095]
	TIME [epoch: 17.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16069704958587458		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.16069704958587458 | validation: 0.16110302718725672]
	TIME [epoch: 17.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17181006510411145		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.17181006510411145 | validation: 0.16199541153287494]
	TIME [epoch: 17.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15740456541126838		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.15740456541126838 | validation: 0.16392102482329626]
	TIME [epoch: 17.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156472106179928		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.156472106179928 | validation: 0.1709843135543466]
	TIME [epoch: 17.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17815095832204506		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.17815095832204506 | validation: 0.1563299812720743]
	TIME [epoch: 17.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419449684344856		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.1419449684344856 | validation: 0.1596797148887254]
	TIME [epoch: 17.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15591244766989126		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.15591244766989126 | validation: 0.1643097953554421]
	TIME [epoch: 17.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18389855334137448		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.18389855334137448 | validation: 0.16012262819522793]
	TIME [epoch: 17.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14465214040357555		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.14465214040357555 | validation: 0.15880364477844755]
	TIME [epoch: 17.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598276566977178		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.1598276566977178 | validation: 0.1590853716732457]
	TIME [epoch: 17.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16268232886805606		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.16268232886805606 | validation: 0.17408276693276137]
	TIME [epoch: 17.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15592816710741164		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.15592816710741164 | validation: 0.15657537900818044]
	TIME [epoch: 17.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15301859517005414		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.15301859517005414 | validation: 0.15944784902446144]
	TIME [epoch: 17.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18835478957410492		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.18835478957410492 | validation: 0.15182722318694297]
	TIME [epoch: 17.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15065708010886106		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.15065708010886106 | validation: 0.16270049725163716]
	TIME [epoch: 17.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881462151840563		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.14881462151840563 | validation: 0.1495393108406264]
	TIME [epoch: 17.5 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15324807701920864		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.15324807701920864 | validation: 0.15571578220917415]
	TIME [epoch: 17.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17250900562170354		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.17250900562170354 | validation: 0.15652953099529787]
	TIME [epoch: 17.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15275538695025345		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.15275538695025345 | validation: 0.16034585250060227]
	TIME [epoch: 17.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16844545625585014		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.16844545625585014 | validation: 0.16475865069715318]
	TIME [epoch: 17.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14787469754998092		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.14787469754998092 | validation: 0.16669450285403137]
	TIME [epoch: 17.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17174800897322198		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.17174800897322198 | validation: 0.1641526434753291]
	TIME [epoch: 17.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537929988270585		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.1537929988270585 | validation: 0.1520883118402544]
	TIME [epoch: 17.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16114522503386455		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.16114522503386455 | validation: 0.16672680556640185]
	TIME [epoch: 17.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14752556451958201		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.14752556451958201 | validation: 0.167659314157202]
	TIME [epoch: 17.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590413486669382		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.1590413486669382 | validation: 0.16089884719818723]
	TIME [epoch: 17.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708195785469686		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.1708195785469686 | validation: 0.16162980663745732]
	TIME [epoch: 17.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16235876751762301		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.16235876751762301 | validation: 0.16079810893524535]
	TIME [epoch: 17.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1583181420711472		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.1583181420711472 | validation: 0.16119345985643085]
	TIME [epoch: 17.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16574832912775522		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.16574832912775522 | validation: 0.1653683289274209]
	TIME [epoch: 17.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673537529602011		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.1673537529602011 | validation: 0.1658232803264882]
	TIME [epoch: 17.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16098599386152085		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.16098599386152085 | validation: 0.1610240902760714]
	TIME [epoch: 17.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14832370957113394		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.14832370957113394 | validation: 0.16072145200596963]
	TIME [epoch: 17.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14490941631773377		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.14490941631773377 | validation: 0.16793463735314024]
	TIME [epoch: 17.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279766725802086		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.16279766725802086 | validation: 0.16624307338163077]
	TIME [epoch: 17.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17256913477617022		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.17256913477617022 | validation: 0.15846398999639966]
	TIME [epoch: 17.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19646172799909933		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.19646172799909933 | validation: 0.16227724932666532]
	TIME [epoch: 17.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15547472131946763		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.15547472131946763 | validation: 0.15291201992571501]
	TIME [epoch: 17.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724683230616188		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.1724683230616188 | validation: 0.16446458800178448]
	TIME [epoch: 17.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847109005642848		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.15847109005642848 | validation: 0.15820661913395168]
	TIME [epoch: 17.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328946556371353		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.15328946556371353 | validation: 0.15462182781676848]
	TIME [epoch: 17.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17485293787352013		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.17485293787352013 | validation: 0.1605135789092566]
	TIME [epoch: 17.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535376323212123		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.1535376323212123 | validation: 0.15469776023142273]
	TIME [epoch: 17.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17023185915711214		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.17023185915711214 | validation: 0.1543379104909227]
	TIME [epoch: 17.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18178234607681493		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.18178234607681493 | validation: 0.16223518537001058]
	TIME [epoch: 17.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596846193741975		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.1596846193741975 | validation: 0.1564814961608469]
	TIME [epoch: 17.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579880595354273		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.1579880595354273 | validation: 0.16246905998537312]
	TIME [epoch: 17.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271336980468515		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.16271336980468515 | validation: 0.16132138213365366]
	TIME [epoch: 17.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14415176574873495		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.14415176574873495 | validation: 0.16500403936685168]
	TIME [epoch: 17.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15501023643920264		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.15501023643920264 | validation: 0.16138851679213345]
	TIME [epoch: 17.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15238331118866655		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.15238331118866655 | validation: 0.15889735099772126]
	TIME [epoch: 17.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1979905508418776		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.1979905508418776 | validation: 0.16221004760394142]
	TIME [epoch: 17.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15209167649550212		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.15209167649550212 | validation: 0.1528483626130443]
	TIME [epoch: 17.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875379332224521		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.1875379332224521 | validation: 0.16042496654509492]
	TIME [epoch: 17.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19365110142767922		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.19365110142767922 | validation: 0.15987156139641842]
	TIME [epoch: 17.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15403586327693114		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.15403586327693114 | validation: 0.16388719060997192]
	TIME [epoch: 17.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15419290096225607		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.15419290096225607 | validation: 0.16003131529014994]
	TIME [epoch: 17.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650448550357269		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.1650448550357269 | validation: 0.16167705807852764]
	TIME [epoch: 17.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543158620007464		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.1543158620007464 | validation: 0.15657821685872095]
	TIME [epoch: 17.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15347760831843557		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.15347760831843557 | validation: 0.16403640833570196]
	TIME [epoch: 17.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17149708281202564		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.17149708281202564 | validation: 0.16389114877046543]
	TIME [epoch: 17.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16066120679831652		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.16066120679831652 | validation: 0.1604446578716228]
	TIME [epoch: 17.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18395090737009506		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.18395090737009506 | validation: 0.15830130065880313]
	TIME [epoch: 17.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600055485998654		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.1600055485998654 | validation: 0.15911457434663245]
	TIME [epoch: 17.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643754089204573		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.15643754089204573 | validation: 0.15111383793538763]
	TIME [epoch: 17.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15862315369705077		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.15862315369705077 | validation: 0.1541713726450017]
	TIME [epoch: 17.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16039235309127597		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.16039235309127597 | validation: 0.1676056901531564]
	TIME [epoch: 17.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190654078064037		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.16190654078064037 | validation: 0.15325804299898327]
	TIME [epoch: 17.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15620018729547425		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.15620018729547425 | validation: 0.15905088227709985]
	TIME [epoch: 17.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16046885649776943		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.16046885649776943 | validation: 0.16171368445218892]
	TIME [epoch: 17.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15864952308481606		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.15864952308481606 | validation: 0.1519523366595891]
	TIME [epoch: 17.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666833499028122		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.1666833499028122 | validation: 0.1613647714240293]
	TIME [epoch: 17.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16999441992306036		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.16999441992306036 | validation: 0.14344296077956206]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18602286125544826		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.18602286125544826 | validation: 0.1594320790859305]
	TIME [epoch: 17.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16905784103117732		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.16905784103117732 | validation: 0.15522926059158187]
	TIME [epoch: 17.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15345421738080167		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.15345421738080167 | validation: 0.15577479875639724]
	TIME [epoch: 17.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15821109894251761		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.15821109894251761 | validation: 0.15658128818834097]
	TIME [epoch: 17.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15694109979807494		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.15694109979807494 | validation: 0.1653356026845545]
	TIME [epoch: 17.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18714340858550418		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.18714340858550418 | validation: 0.1600586366410955]
	TIME [epoch: 17.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18670513363094343		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.18670513363094343 | validation: 0.16506447427877072]
	TIME [epoch: 17.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15435249455425096		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.15435249455425096 | validation: 0.16181384758177036]
	TIME [epoch: 17.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16043262345603945		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.16043262345603945 | validation: 0.16100713957696008]
	TIME [epoch: 17.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15207162053482742		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.15207162053482742 | validation: 0.16268619709563364]
	TIME [epoch: 17.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15409833367654696		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.15409833367654696 | validation: 0.16639898194102304]
	TIME [epoch: 17.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14155170769279013		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.14155170769279013 | validation: 0.15350596051106247]
	TIME [epoch: 17.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675702839893585		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.15675702839893585 | validation: 0.1676917030673524]
	TIME [epoch: 17.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15433096494013526		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.15433096494013526 | validation: 0.14982312510353438]
	TIME [epoch: 17.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664383766593184		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.1664383766593184 | validation: 0.15519406864009816]
	TIME [epoch: 17.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675785844697949		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.1675785844697949 | validation: 0.1628169643893215]
	TIME [epoch: 17.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543978614504012		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.1543978614504012 | validation: 0.15320219326541923]
	TIME [epoch: 17.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16966893927911011		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.16966893927911011 | validation: 0.16207973658405225]
	TIME [epoch: 17.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15984044813784018		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.15984044813784018 | validation: 0.15795104496833554]
	TIME [epoch: 17.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478613865405704		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.1478613865405704 | validation: 0.16061252151601757]
	TIME [epoch: 17.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17191047754316446		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.17191047754316446 | validation: 0.15468406520541098]
	TIME [epoch: 17.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17268271317479741		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.17268271317479741 | validation: 0.1554558955986458]
	TIME [epoch: 17.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15094559488754236		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.15094559488754236 | validation: 0.15774145673873627]
	TIME [epoch: 17.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18242078391967542		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.18242078391967542 | validation: 0.1624883006847249]
	TIME [epoch: 17.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623456515835588		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.1623456515835588 | validation: 0.16337169600851337]
	TIME [epoch: 17.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15414183057680622		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.15414183057680622 | validation: 0.16712565603636254]
	TIME [epoch: 17.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581412234813555		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.1581412234813555 | validation: 0.15893302515231555]
	TIME [epoch: 17.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16077437358136		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.16077437358136 | validation: 0.15482834441012755]
	TIME [epoch: 17.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16696731510259247		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.16696731510259247 | validation: 0.15527956791953407]
	TIME [epoch: 17.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17052433121766725		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.17052433121766725 | validation: 0.16947709359034346]
	TIME [epoch: 17.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18495866506767872		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.18495866506767872 | validation: 0.1599336008483119]
	TIME [epoch: 17.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16151155179584645		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.16151155179584645 | validation: 0.14863837155655044]
	TIME [epoch: 17.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15741441976393256		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.15741441976393256 | validation: 0.16368623878426794]
	TIME [epoch: 17.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16125249647767995		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.16125249647767995 | validation: 0.16184967471164172]
	TIME [epoch: 17.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528656296744282		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.1528656296744282 | validation: 0.15799370922752498]
	TIME [epoch: 17.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923504769073045		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.14923504769073045 | validation: 0.16861812278972402]
	TIME [epoch: 17.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19017165528019678		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.19017165528019678 | validation: 0.1590569865038298]
	TIME [epoch: 17.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16277007255369297		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.16277007255369297 | validation: 0.16585157219574484]
	TIME [epoch: 17.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16102794834152245		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.16102794834152245 | validation: 0.1641837329372976]
	TIME [epoch: 17.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948080137575062		[learning rate: 0.00041198]
	Learning Rate: 0.000411976
	LOSS [training: 0.14948080137575062 | validation: 0.15891487923239322]
	TIME [epoch: 17.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604759075334362		[learning rate: 0.00041003]
	Learning Rate: 0.000410035
	LOSS [training: 0.1604759075334362 | validation: 0.16256870158542083]
	TIME [epoch: 17.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517584785784037		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.1517584785784037 | validation: 0.1650698286488032]
	TIME [epoch: 17.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307735255033755		[learning rate: 0.00040618]
	Learning Rate: 0.000406179
	LOSS [training: 0.15307735255033755 | validation: 0.15821001536266133]
	TIME [epoch: 17.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206280050886578		[learning rate: 0.00040427]
	Learning Rate: 0.000404266
	LOSS [training: 0.15206280050886578 | validation: 0.15751191057947078]
	TIME [epoch: 17.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18333749672916544		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.18333749672916544 | validation: 0.1526198911454261]
	TIME [epoch: 17.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16492104081246042		[learning rate: 0.00040046]
	Learning Rate: 0.000400465
	LOSS [training: 0.16492104081246042 | validation: 0.15420329814493444]
	TIME [epoch: 17.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16968630334024584		[learning rate: 0.00039858]
	Learning Rate: 0.000398578
	LOSS [training: 0.16968630334024584 | validation: 0.15947935194499901]
	TIME [epoch: 17.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18620332886158614		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.18620332886158614 | validation: 0.16710363195878472]
	TIME [epoch: 17.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587777873382637		[learning rate: 0.00039483]
	Learning Rate: 0.00039483
	LOSS [training: 0.1587777873382637 | validation: 0.1589452265993376]
	TIME [epoch: 17.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18344281940360113		[learning rate: 0.00039297]
	Learning Rate: 0.00039297
	LOSS [training: 0.18344281940360113 | validation: 0.15671536692554355]
	TIME [epoch: 17.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157988454751591		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.157988454751591 | validation: 0.1567318009804142]
	TIME [epoch: 17.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16787711815111817		[learning rate: 0.00038927]
	Learning Rate: 0.000389275
	LOSS [training: 0.16787711815111817 | validation: 0.162547511707541]
	TIME [epoch: 17.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560421715436303		[learning rate: 0.00038744]
	Learning Rate: 0.000387441
	LOSS [training: 0.1560421715436303 | validation: 0.15910105059652035]
	TIME [epoch: 17.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15161635831606238		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.15161635831606238 | validation: 0.17158268852899367]
	TIME [epoch: 17.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529947000134572		[learning rate: 0.0003838]
	Learning Rate: 0.000383798
	LOSS [training: 0.1529947000134572 | validation: 0.1525028060016086]
	TIME [epoch: 17.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15683565494345023		[learning rate: 0.00038199]
	Learning Rate: 0.000381989
	LOSS [training: 0.15683565494345023 | validation: 0.16681277820145451]
	TIME [epoch: 17.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188737951566734		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.16188737951566734 | validation: 0.17144260427987654]
	TIME [epoch: 17.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19624719218199654		[learning rate: 0.0003784]
	Learning Rate: 0.000378398
	LOSS [training: 0.19624719218199654 | validation: 0.1591572375237124]
	TIME [epoch: 17.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592591770795541		[learning rate: 0.00037661]
	Learning Rate: 0.000376615
	LOSS [training: 0.1592591770795541 | validation: 0.1620108491371186]
	TIME [epoch: 17.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659730858995503		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.1659730858995503 | validation: 0.15439346074643148]
	TIME [epoch: 17.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16685400154437416		[learning rate: 0.00037307]
	Learning Rate: 0.000373074
	LOSS [training: 0.16685400154437416 | validation: 0.15864997853292695]
	TIME [epoch: 17.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15601542815937441		[learning rate: 0.00037132]
	Learning Rate: 0.000371316
	LOSS [training: 0.15601542815937441 | validation: 0.15826237046575253]
	TIME [epoch: 17.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434339325380954		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.17434339325380954 | validation: 0.16602634576350775]
	TIME [epoch: 17.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16733054948818807		[learning rate: 0.00036782]
	Learning Rate: 0.000367825
	LOSS [training: 0.16733054948818807 | validation: 0.1618105726482816]
	TIME [epoch: 17.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1609678643052761		[learning rate: 0.00036609]
	Learning Rate: 0.000366092
	LOSS [training: 0.1609678643052761 | validation: 0.16337464235103472]
	TIME [epoch: 17.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679226114457444		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.1679226114457444 | validation: 0.15847034190862863]
	TIME [epoch: 17.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679497354503855		[learning rate: 0.00036265]
	Learning Rate: 0.00036265
	LOSS [training: 0.1679497354503855 | validation: 0.15568389707905866]
	TIME [epoch: 17.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575536898959771		[learning rate: 0.00036094]
	Learning Rate: 0.000360941
	LOSS [training: 0.15575536898959771 | validation: 0.159563857452808]
	TIME [epoch: 17.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15993161653780769		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.15993161653780769 | validation: 0.166839343383953]
	TIME [epoch: 17.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16767149221649877		[learning rate: 0.00035755]
	Learning Rate: 0.000357547
	LOSS [training: 0.16767149221649877 | validation: 0.16342623097050396]
	TIME [epoch: 17.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15896713477921223		[learning rate: 0.00035586]
	Learning Rate: 0.000355862
	LOSS [training: 0.15896713477921223 | validation: 0.14851083118797148]
	TIME [epoch: 17.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16629607819826095		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.16629607819826095 | validation: 0.1613830133118288]
	TIME [epoch: 17.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632420141647158		[learning rate: 0.00035252]
	Learning Rate: 0.000352517
	LOSS [training: 0.15632420141647158 | validation: 0.16261630829768428]
	TIME [epoch: 17.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16984652777930265		[learning rate: 0.00035086]
	Learning Rate: 0.000350855
	LOSS [training: 0.16984652777930265 | validation: 0.1558772106255188]
	TIME [epoch: 17.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14957508742839853		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.14957508742839853 | validation: 0.16161847459430212]
	TIME [epoch: 17.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17346013248165804		[learning rate: 0.00034756]
	Learning Rate: 0.000347557
	LOSS [training: 0.17346013248165804 | validation: 0.16042678143127997]
	TIME [epoch: 17.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15552863392143682		[learning rate: 0.00034592]
	Learning Rate: 0.000345919
	LOSS [training: 0.15552863392143682 | validation: 0.15564739240457195]
	TIME [epoch: 17.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15670312696449362		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.15670312696449362 | validation: 0.1676631087087163]
	TIME [epoch: 17.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628879602433115		[learning rate: 0.00034267]
	Learning Rate: 0.000342667
	LOSS [training: 0.14628879602433115 | validation: 0.16741761132709929]
	TIME [epoch: 17.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313973763725603		[learning rate: 0.00034105]
	Learning Rate: 0.000341052
	LOSS [training: 0.16313973763725603 | validation: 0.16158758571820914]
	TIME [epoch: 17.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15886392317616627		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.15886392317616627 | validation: 0.15883485774609868]
	TIME [epoch: 17.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961432004839388		[learning rate: 0.00033785]
	Learning Rate: 0.000337845
	LOSS [training: 0.15961432004839388 | validation: 0.16205427854592125]
	TIME [epoch: 17.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544831709814761		[learning rate: 0.00033625]
	Learning Rate: 0.000336253
	LOSS [training: 0.1544831709814761 | validation: 0.1740725301245755]
	TIME [epoch: 17.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18266755564688766		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.18266755564688766 | validation: 0.16874948533400172]
	TIME [epoch: 17.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17184936173921184		[learning rate: 0.00033309]
	Learning Rate: 0.000333092
	LOSS [training: 0.17184936173921184 | validation: 0.1657814699135569]
	TIME [epoch: 17.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790105567760259		[learning rate: 0.00033152]
	Learning Rate: 0.000331522
	LOSS [training: 0.1790105567760259 | validation: 0.1704956341177854]
	TIME [epoch: 17.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690203283161207		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.1690203283161207 | validation: 0.15917552675421925]
	TIME [epoch: 17.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548493783931139		[learning rate: 0.00032841]
	Learning Rate: 0.000328405
	LOSS [training: 0.1548493783931139 | validation: 0.16103360203181044]
	TIME [epoch: 17.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604546716885008		[learning rate: 0.00032686]
	Learning Rate: 0.000326858
	LOSS [training: 0.1604546716885008 | validation: 0.15879255568438064]
	TIME [epoch: 17.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17259173920937682		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.17259173920937682 | validation: 0.16026018934699077]
	TIME [epoch: 17.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14859451366511028		[learning rate: 0.00032378]
	Learning Rate: 0.000323785
	LOSS [training: 0.14859451366511028 | validation: 0.1671287122733329]
	TIME [epoch: 17.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14791666484753532		[learning rate: 0.00032226]
	Learning Rate: 0.000322259
	LOSS [training: 0.14791666484753532 | validation: 0.16096079668425217]
	TIME [epoch: 17.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16907170634528845		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.16907170634528845 | validation: 0.16004669701213123]
	TIME [epoch: 17.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16750351153795834		[learning rate: 0.00031923]
	Learning Rate: 0.000319229
	LOSS [training: 0.16750351153795834 | validation: 0.15453753003777462]
	TIME [epoch: 17.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17364107928768857		[learning rate: 0.00031772]
	Learning Rate: 0.000317725
	LOSS [training: 0.17364107928768857 | validation: 0.158795838800055]
	TIME [epoch: 17.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580505657729976		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.1580505657729976 | validation: 0.16009562634883978]
	TIME [epoch: 17.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15970002680723358		[learning rate: 0.00031474]
	Learning Rate: 0.000314738
	LOSS [training: 0.15970002680723358 | validation: 0.15689946846175273]
	TIME [epoch: 17.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20098112952662414		[learning rate: 0.00031325]
	Learning Rate: 0.000313255
	LOSS [training: 0.20098112952662414 | validation: 0.15558230916041443]
	TIME [epoch: 17.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17142779654360268		[learning rate: 0.00031178]
	Learning Rate: 0.000311778
	LOSS [training: 0.17142779654360268 | validation: 0.16654452221700314]
	TIME [epoch: 17.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587919282024659		[learning rate: 0.00031031]
	Learning Rate: 0.000310309
	LOSS [training: 0.1587919282024659 | validation: 0.15999032020556497]
	TIME [epoch: 17.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17219304623999995		[learning rate: 0.00030885]
	Learning Rate: 0.000308847
	LOSS [training: 0.17219304623999995 | validation: 0.15844613003888866]
	TIME [epoch: 17.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19423093780768236		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.19423093780768236 | validation: 0.15735994323439506]
	TIME [epoch: 17.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15132364085793157		[learning rate: 0.00030594]
	Learning Rate: 0.000305943
	LOSS [training: 0.15132364085793157 | validation: 0.1599709027809968]
	TIME [epoch: 17.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14850629911538332		[learning rate: 0.0003045]
	Learning Rate: 0.000304502
	LOSS [training: 0.14850629911538332 | validation: 0.16328178127290924]
	TIME [epoch: 17.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462734546472613		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.1462734546472613 | validation: 0.16482894579183963]
	TIME [epoch: 17.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16696458282431567		[learning rate: 0.00030164]
	Learning Rate: 0.000301639
	LOSS [training: 0.16696458282431567 | validation: 0.15688368238089467]
	TIME [epoch: 17.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530676164871802		[learning rate: 0.00030022]
	Learning Rate: 0.000300217
	LOSS [training: 0.16530676164871802 | validation: 0.16279206862387996]
	TIME [epoch: 17.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180858314196284		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.180858314196284 | validation: 0.15257485998650988]
	TIME [epoch: 17.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603902149848619		[learning rate: 0.00029739]
	Learning Rate: 0.000297395
	LOSS [training: 0.1603902149848619 | validation: 0.15518722275537675]
	TIME [epoch: 17.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17272390352162859		[learning rate: 0.00029599]
	Learning Rate: 0.000295993
	LOSS [training: 0.17272390352162859 | validation: 0.15647797225737056]
	TIME [epoch: 17.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721573492499274		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.1721573492499274 | validation: 0.1620004398412515]
	TIME [epoch: 17.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14297562025902782		[learning rate: 0.00029321]
	Learning Rate: 0.00029321
	LOSS [training: 0.14297562025902782 | validation: 0.16381567571483321]
	TIME [epoch: 17.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152443713843858		[learning rate: 0.00029183]
	Learning Rate: 0.000291829
	LOSS [training: 0.152443713843858 | validation: 0.16534488617860188]
	TIME [epoch: 17.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642136028688601		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.1642136028688601 | validation: 0.15860086296384013]
	TIME [epoch: 17.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168239740382766		[learning rate: 0.00028909]
	Learning Rate: 0.000289085
	LOSS [training: 0.168239740382766 | validation: 0.15150340977533713]
	TIME [epoch: 17.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034126560869146		[learning rate: 0.00028772]
	Learning Rate: 0.000287723
	LOSS [training: 0.18034126560869146 | validation: 0.1538984160820546]
	TIME [epoch: 17.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17220887376952387		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.17220887376952387 | validation: 0.15930119802356832]
	TIME [epoch: 17.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1905796940517437		[learning rate: 0.00028502]
	Learning Rate: 0.000285018
	LOSS [training: 0.1905796940517437 | validation: 0.1658850337075212]
	TIME [epoch: 17.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15966125988514274		[learning rate: 0.00028367]
	Learning Rate: 0.000283675
	LOSS [training: 0.15966125988514274 | validation: 0.15618113437588646]
	TIME [epoch: 17.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14507484844682458		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.14507484844682458 | validation: 0.15745945296766123]
	TIME [epoch: 17.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123174037762524		[learning rate: 0.00028101]
	Learning Rate: 0.000281008
	LOSS [training: 0.15123174037762524 | validation: 0.16029814578599028]
	TIME [epoch: 17.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601905654346465		[learning rate: 0.00027968]
	Learning Rate: 0.000279683
	LOSS [training: 0.1601905654346465 | validation: 0.16449505475520465]
	TIME [epoch: 17.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15574994937348294		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.15574994937348294 | validation: 0.15556088052252692]
	TIME [epoch: 17.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17050549535386528		[learning rate: 0.00027705]
	Learning Rate: 0.000277054
	LOSS [training: 0.17050549535386528 | validation: 0.15489760736236685]
	TIME [epoch: 17.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17072911246032857		[learning rate: 0.00027575]
	Learning Rate: 0.000275748
	LOSS [training: 0.17072911246032857 | validation: 0.16439613375883666]
	TIME [epoch: 17.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17865515760672962		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.17865515760672962 | validation: 0.1538595652393258]
	TIME [epoch: 17.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659391968877107		[learning rate: 0.00027316]
	Learning Rate: 0.000273156
	LOSS [training: 0.1659391968877107 | validation: 0.17018234061957518]
	TIME [epoch: 17.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16336505418924469		[learning rate: 0.00027187]
	Learning Rate: 0.000271869
	LOSS [training: 0.16336505418924469 | validation: 0.1623042348968401]
	TIME [epoch: 17.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881780737628578		[learning rate: 0.00027059]
	Learning Rate: 0.000270587
	LOSS [training: 0.14881780737628578 | validation: 0.16431546984781759]
	TIME [epoch: 17.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529072569945515		[learning rate: 0.00026931]
	Learning Rate: 0.000269312
	LOSS [training: 0.1529072569945515 | validation: 0.16157597507395083]
	TIME [epoch: 17.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21408734779768177		[learning rate: 0.00026804]
	Learning Rate: 0.000268043
	LOSS [training: 0.21408734779768177 | validation: 0.15901895576289332]
	TIME [epoch: 17.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516700190936321		[learning rate: 0.00026678]
	Learning Rate: 0.00026678
	LOSS [training: 0.1516700190936321 | validation: 0.15313277243040616]
	TIME [epoch: 17.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15549293507288728		[learning rate: 0.00026552]
	Learning Rate: 0.000265523
	LOSS [training: 0.15549293507288728 | validation: 0.15369318159440437]
	TIME [epoch: 17.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15696430112663706		[learning rate: 0.00026427]
	Learning Rate: 0.000264272
	LOSS [training: 0.15696430112663706 | validation: 0.16633310903710283]
	TIME [epoch: 17.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266621603208193		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.20266621603208193 | validation: 0.15832234704375717]
	TIME [epoch: 17.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554475995091166		[learning rate: 0.00026179]
	Learning Rate: 0.000261787
	LOSS [training: 0.15554475995091166 | validation: 0.16309347347827077]
	TIME [epoch: 17.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17092419582787569		[learning rate: 0.00026055]
	Learning Rate: 0.000260554
	LOSS [training: 0.17092419582787569 | validation: 0.16067654831919298]
	TIME [epoch: 17.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510866281709493		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.1510866281709493 | validation: 0.16357401247676445]
	TIME [epoch: 17.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664442730731719		[learning rate: 0.0002581]
	Learning Rate: 0.000258104
	LOSS [training: 0.1664442730731719 | validation: 0.161351754297137]
	TIME [epoch: 17.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489464127634285		[learning rate: 0.00025689]
	Learning Rate: 0.000256888
	LOSS [training: 0.1489464127634285 | validation: 0.1565360381842831]
	TIME [epoch: 17.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16505509150245568		[learning rate: 0.00025568]
	Learning Rate: 0.000255677
	LOSS [training: 0.16505509150245568 | validation: 0.1614939757788111]
	TIME [epoch: 17.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20071355831532062		[learning rate: 0.00025447]
	Learning Rate: 0.000254473
	LOSS [training: 0.20071355831532062 | validation: 0.15874713194137494]
	TIME [epoch: 17.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15070147946596069		[learning rate: 0.00025327]
	Learning Rate: 0.000253274
	LOSS [training: 0.15070147946596069 | validation: 0.15852702072105912]
	TIME [epoch: 17.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16606451304752684		[learning rate: 0.00025208]
	Learning Rate: 0.00025208
	LOSS [training: 0.16606451304752684 | validation: 0.16563584479351884]
	TIME [epoch: 17.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15924222163567187		[learning rate: 0.00025089]
	Learning Rate: 0.000250892
	LOSS [training: 0.15924222163567187 | validation: 0.15748784674874938]
	TIME [epoch: 17.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15803282743966557		[learning rate: 0.00024971]
	Learning Rate: 0.00024971
	LOSS [training: 0.15803282743966557 | validation: 0.14821898955750504]
	TIME [epoch: 17.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484753105327904		[learning rate: 0.00024853]
	Learning Rate: 0.000248533
	LOSS [training: 0.16484753105327904 | validation: 0.1545538733665851]
	TIME [epoch: 17.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766801314221163		[learning rate: 0.00024736]
	Learning Rate: 0.000247362
	LOSS [training: 0.1766801314221163 | validation: 0.15925004728173583]
	TIME [epoch: 17.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15820377319356796		[learning rate: 0.0002462]
	Learning Rate: 0.000246197
	LOSS [training: 0.15820377319356796 | validation: 0.16815395885034082]
	TIME [epoch: 17.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18385924391152178		[learning rate: 0.00024504]
	Learning Rate: 0.000245037
	LOSS [training: 0.18385924391152178 | validation: 0.17055213561312071]
	TIME [epoch: 17.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15149621128319748		[learning rate: 0.00024388]
	Learning Rate: 0.000243882
	LOSS [training: 0.15149621128319748 | validation: 0.1610390994049008]
	TIME [epoch: 17.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14951587496491758		[learning rate: 0.00024273]
	Learning Rate: 0.000242733
	LOSS [training: 0.14951587496491758 | validation: 0.15032286335891276]
	TIME [epoch: 17.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153315266609994		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.153315266609994 | validation: 0.15686754108018708]
	TIME [epoch: 17.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17039879893740695		[learning rate: 0.00024045]
	Learning Rate: 0.00024045
	LOSS [training: 0.17039879893740695 | validation: 0.1555690500623353]
	TIME [epoch: 17.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486955367774772		[learning rate: 0.00023932]
	Learning Rate: 0.000239317
	LOSS [training: 0.1486955367774772 | validation: 0.1549097830470525]
	TIME [epoch: 17.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19018448801711796		[learning rate: 0.00023819]
	Learning Rate: 0.00023819
	LOSS [training: 0.19018448801711796 | validation: 0.1573040788798842]
	TIME [epoch: 17.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15459648322512848		[learning rate: 0.00023707]
	Learning Rate: 0.000237067
	LOSS [training: 0.15459648322512848 | validation: 0.15439993229907856]
	TIME [epoch: 17.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969773147292537		[learning rate: 0.00023595]
	Learning Rate: 0.00023595
	LOSS [training: 0.14969773147292537 | validation: 0.1542238350063686]
	TIME [epoch: 17.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890964721152233		[learning rate: 0.00023484]
	Learning Rate: 0.000234838
	LOSS [training: 0.1890964721152233 | validation: 0.15484480304301246]
	TIME [epoch: 17.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17869824635454457		[learning rate: 0.00023373]
	Learning Rate: 0.000233732
	LOSS [training: 0.17869824635454457 | validation: 0.15969876715820885]
	TIME [epoch: 17.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16345839783624408		[learning rate: 0.00023263]
	Learning Rate: 0.00023263
	LOSS [training: 0.16345839783624408 | validation: 0.16257581079021882]
	TIME [epoch: 17.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701325929327541		[learning rate: 0.00023153]
	Learning Rate: 0.000231534
	LOSS [training: 0.1701325929327541 | validation: 0.16461103840848532]
	TIME [epoch: 17.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527662773349575		[learning rate: 0.00023044]
	Learning Rate: 0.000230443
	LOSS [training: 0.1527662773349575 | validation: 0.16508691613190013]
	TIME [epoch: 17.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799133674502395		[learning rate: 0.00022936]
	Learning Rate: 0.000229357
	LOSS [training: 0.1799133674502395 | validation: 0.162497876236317]
	TIME [epoch: 17.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15698612853454313		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.15698612853454313 | validation: 0.16446942225221453]
	TIME [epoch: 17.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549381686648175		[learning rate: 0.0002272]
	Learning Rate: 0.000227201
	LOSS [training: 0.1549381686648175 | validation: 0.15131485090968155]
	TIME [epoch: 17.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158925382858365		[learning rate: 0.00022613]
	Learning Rate: 0.00022613
	LOSS [training: 0.158925382858365 | validation: 0.1629608804559986]
	TIME [epoch: 17.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496846246327357		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.1496846246327357 | validation: 0.14964919159288884]
	TIME [epoch: 17.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16046921407843717		[learning rate: 0.000224]
	Learning Rate: 0.000224004
	LOSS [training: 0.16046921407843717 | validation: 0.14700929698354356]
	TIME [epoch: 17.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505039665884529		[learning rate: 0.00022295]
	Learning Rate: 0.000222949
	LOSS [training: 0.1505039665884529 | validation: 0.1565317911210922]
	TIME [epoch: 17.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15216293167054587		[learning rate: 0.0002219]
	Learning Rate: 0.000221898
	LOSS [training: 0.15216293167054587 | validation: 0.1559064806860957]
	TIME [epoch: 17.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15486156511269533		[learning rate: 0.00022085]
	Learning Rate: 0.000220853
	LOSS [training: 0.15486156511269533 | validation: 0.1548783519628486]
	TIME [epoch: 17.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686191132497402		[learning rate: 0.00021981]
	Learning Rate: 0.000219812
	LOSS [training: 0.1686191132497402 | validation: 0.15041120692343046]
	TIME [epoch: 17.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14456692481691333		[learning rate: 0.00021878]
	Learning Rate: 0.000218776
	LOSS [training: 0.14456692481691333 | validation: 0.17047040959536586]
	TIME [epoch: 17.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16164909282486845		[learning rate: 0.00021775]
	Learning Rate: 0.000217745
	LOSS [training: 0.16164909282486845 | validation: 0.1607107128916293]
	TIME [epoch: 17.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816599507344536		[learning rate: 0.00021672]
	Learning Rate: 0.000216719
	LOSS [training: 0.1816599507344536 | validation: 0.16412897420690173]
	TIME [epoch: 17.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632455121352134		[learning rate: 0.0002157]
	Learning Rate: 0.000215698
	LOSS [training: 0.1632455121352134 | validation: 0.1548714590365671]
	TIME [epoch: 17.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386642404139546		[learning rate: 0.00021468]
	Learning Rate: 0.000214682
	LOSS [training: 0.14386642404139546 | validation: 0.16118269774361743]
	TIME [epoch: 17.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17135319466027132		[learning rate: 0.00021367]
	Learning Rate: 0.00021367
	LOSS [training: 0.17135319466027132 | validation: 0.1681349144687342]
	TIME [epoch: 17.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759273554330904		[learning rate: 0.00021266]
	Learning Rate: 0.000212663
	LOSS [training: 0.1759273554330904 | validation: 0.165494946149647]
	TIME [epoch: 17.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707567828985335		[learning rate: 0.00021166]
	Learning Rate: 0.000211661
	LOSS [training: 0.14707567828985335 | validation: 0.15922396909904055]
	TIME [epoch: 17.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14735081876080514		[learning rate: 0.00021066]
	Learning Rate: 0.000210664
	LOSS [training: 0.14735081876080514 | validation: 0.16585477464218598]
	TIME [epoch: 17.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15236349413532774		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.15236349413532774 | validation: 0.1654650653654132]
	TIME [epoch: 17.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16664659728979575		[learning rate: 0.00020868]
	Learning Rate: 0.000208683
	LOSS [training: 0.16664659728979575 | validation: 0.15551571213595805]
	TIME [epoch: 17.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16448220751686682		[learning rate: 0.0002077]
	Learning Rate: 0.0002077
	LOSS [training: 0.16448220751686682 | validation: 0.15179704862949905]
	TIME [epoch: 17.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566693895872217		[learning rate: 0.00020672]
	Learning Rate: 0.000206721
	LOSS [training: 0.1566693895872217 | validation: 0.15656594582643218]
	TIME [epoch: 17.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542958473841975		[learning rate: 0.00020575]
	Learning Rate: 0.000205747
	LOSS [training: 0.1542958473841975 | validation: 0.15701106407022142]
	TIME [epoch: 17.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15733293187262326		[learning rate: 0.00020478]
	Learning Rate: 0.000204777
	LOSS [training: 0.15733293187262326 | validation: 0.16705617451808025]
	TIME [epoch: 17.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18499569252026726		[learning rate: 0.00020381]
	Learning Rate: 0.000203812
	LOSS [training: 0.18499569252026726 | validation: 0.15649264341015687]
	TIME [epoch: 17.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16429806457441318		[learning rate: 0.00020285]
	Learning Rate: 0.000202852
	LOSS [training: 0.16429806457441318 | validation: 0.16714238624281244]
	TIME [epoch: 17.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17300176076184187		[learning rate: 0.0002019]
	Learning Rate: 0.000201896
	LOSS [training: 0.17300176076184187 | validation: 0.15520295578482673]
	TIME [epoch: 17.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15407606093132895		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.15407606093132895 | validation: 0.15248734522298413]
	TIME [epoch: 17.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127097466902903		[learning rate: 0.0002]
	Learning Rate: 0.000199998
	LOSS [training: 0.15127097466902903 | validation: 0.15887837166561194]
	TIME [epoch: 17.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21831918489248536		[learning rate: 0.00019906]
	Learning Rate: 0.000199056
	LOSS [training: 0.21831918489248536 | validation: 0.16139407642947645]
	TIME [epoch: 17.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778438826410746		[learning rate: 0.00019812]
	Learning Rate: 0.000198118
	LOSS [training: 0.1778438826410746 | validation: 0.1624808306720238]
	TIME [epoch: 17.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15250001750433223		[learning rate: 0.00019718]
	Learning Rate: 0.000197184
	LOSS [training: 0.15250001750433223 | validation: 0.15800933306624437]
	TIME [epoch: 17.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418873437855355		[learning rate: 0.00019625]
	Learning Rate: 0.000196255
	LOSS [training: 0.1418873437855355 | validation: 0.16539951170004666]
	TIME [epoch: 17.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19276679842276787		[learning rate: 0.00019533]
	Learning Rate: 0.00019533
	LOSS [training: 0.19276679842276787 | validation: 0.161989074026986]
	TIME [epoch: 17.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562231367938812		[learning rate: 0.00019441]
	Learning Rate: 0.00019441
	LOSS [training: 0.1562231367938812 | validation: 0.16265622303376653]
	TIME [epoch: 17.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15925369793598698		[learning rate: 0.00019349]
	Learning Rate: 0.000193494
	LOSS [training: 0.15925369793598698 | validation: 0.17439819171377424]
	TIME [epoch: 17.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053472099231267		[learning rate: 0.00019258]
	Learning Rate: 0.000192582
	LOSS [training: 0.2053472099231267 | validation: 0.16368744571010324]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_transition2_v1_20240606_193458/states/model_transition2_v1_874.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 15441.298 seconds.
