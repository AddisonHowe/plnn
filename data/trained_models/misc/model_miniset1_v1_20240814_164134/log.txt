Args:
Namespace(name='model_miniset1_v1', outdir='out/model_training/model_miniset1_v1', training_data='data/training_data/miniset1/training', validation_data='data/training_data/miniset1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=9, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[100, 200, 300, 400, 500, 600], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1870685073

Training model...

Saving initial model state to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.623863291760175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.623863291760175 | validation: 2.30737579876333]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.132312255661024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.132312255661024 | validation: 1.8892596497640646]
	TIME [epoch: 1.68 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6088835746588586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6088835746588586 | validation: 1.4603100550523334]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.271386286891592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.271386286891592 | validation: 1.0241419878569278]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9080323758619544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9080323758619544 | validation: 0.9517833635012753]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7180407107627526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7180407107627526 | validation: 0.7656931330014258]
	TIME [epoch: 1.68 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6898196329274233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6898196329274233 | validation: 0.5482478037311933]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6073230789128828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6073230789128828 | validation: 0.5370812342158742]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5888866685266101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5888866685266101 | validation: 0.5873753300602386]
	TIME [epoch: 1.67 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5894398283810418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5894398283810418 | validation: 0.4878426329806159]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5779445457341488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5779445457341488 | validation: 0.6019510299603025]
	TIME [epoch: 1.66 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5621825447361355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5621825447361355 | validation: 0.49111423269631516]
	TIME [epoch: 1.66 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.510226167289981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.510226167289981 | validation: 0.4417766400524089]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5503263486672976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5503263486672976 | validation: 0.6046715002116896]
	TIME [epoch: 1.66 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5284161725708799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5284161725708799 | validation: 0.44918390523602697]
	TIME [epoch: 1.66 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4904953720165734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4904953720165734 | validation: 0.4699571783510511]
	TIME [epoch: 1.66 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4853515740640836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4853515740640836 | validation: 0.41533034213946474]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4253796802262233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4253796802262233 | validation: 0.38259157228894974]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49181997862946664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49181997862946664 | validation: 0.4161791046867598]
	TIME [epoch: 1.67 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40294218532204795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40294218532204795 | validation: 0.47213531493060534]
	TIME [epoch: 1.66 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4713431487927681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4713431487927681 | validation: 0.3282443893093333]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3415881745384931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3415881745384931 | validation: 0.29606464097948343]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35506955339699553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35506955339699553 | validation: 0.28315614020797286]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2764399975167631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2764399975167631 | validation: 0.32135254427766113]
	TIME [epoch: 1.66 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24664423782735137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24664423782735137 | validation: 0.24323911251065264]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3453288698424589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3453288698424589 | validation: 0.30052599460092244]
	TIME [epoch: 1.66 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2064236156239275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2064236156239275 | validation: 0.1420651607628581]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519002159826092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1519002159826092 | validation: 0.1810524788900222]
	TIME [epoch: 1.67 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306630470671925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1306630470671925 | validation: 0.1695092452008869]
	TIME [epoch: 1.66 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14978503120400313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14978503120400313 | validation: 0.1044167750844643]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15004739242023918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15004739242023918 | validation: 0.09881694612140296]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09898114483958069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09898114483958069 | validation: 0.09838855521354169]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12386170989584519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12386170989584519 | validation: 0.1588096559269757]
	TIME [epoch: 1.67 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11321464929175007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11321464929175007 | validation: 0.08912940266400252]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07190733016749948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07190733016749948 | validation: 0.08264473191142781]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09930216337631663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09930216337631663 | validation: 0.1096277152736089]
	TIME [epoch: 1.66 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10057643537129242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10057643537129242 | validation: 0.06055207110030908]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07087705639135092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07087705639135092 | validation: 0.04172111530992396]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05547622953163765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05547622953163765 | validation: 0.05422332760708885]
	TIME [epoch: 1.66 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719570918254788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0719570918254788 | validation: 0.09426612368129265]
	TIME [epoch: 1.66 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07065009416971194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07065009416971194 | validation: 0.05255903084426926]
	TIME [epoch: 1.66 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10441369198722747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10441369198722747 | validation: 0.06158830724702841]
	TIME [epoch: 1.66 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07836410729274498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07836410729274498 | validation: 0.03755032864436372]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680888049810904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04680888049810904 | validation: 0.10092638254274158]
	TIME [epoch: 1.67 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349808087330823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06349808087330823 | validation: 0.037874851843723134]
	TIME [epoch: 1.66 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060472957200162124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060472957200162124 | validation: 0.03319773295997058]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09315039329610977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09315039329610977 | validation: 0.08472496243614942]
	TIME [epoch: 1.67 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05037604697733957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05037604697733957 | validation: 0.030336254967304677]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043560862656207275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043560862656207275 | validation: 0.031328623715952034]
	TIME [epoch: 1.67 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06160510762482556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06160510762482556 | validation: 0.06274617898728]
	TIME [epoch: 1.66 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04852513039025666		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 0.04852513039025666 | validation: 0.045182702127773644]
	TIME [epoch: 1.66 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053853174409912455		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 0.053853174409912455 | validation: 0.08574807505278341]
	TIME [epoch: 1.66 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04932018958186775		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 0.04932018958186775 | validation: 0.07662111535116307]
	TIME [epoch: 1.66 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05580847032439218		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 0.05580847032439218 | validation: 0.02992615929156765]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05568794905094658		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 0.05568794905094658 | validation: 0.03399205123467073]
	TIME [epoch: 1.66 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04426298497966834		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 0.04426298497966834 | validation: 0.0499063433970882]
	TIME [epoch: 1.66 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039071332149170065		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 0.039071332149170065 | validation: 0.02854565298137989]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.031047159434993338		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 0.031047159434993338 | validation: 0.04822035355007882]
	TIME [epoch: 1.67 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04332407226822527		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 0.04332407226822527 | validation: 0.02879776953301862]
	TIME [epoch: 1.66 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03275740783535097		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 0.03275740783535097 | validation: 0.025932252058471227]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04296729710799154		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 0.04296729710799154 | validation: 0.03507180146471515]
	TIME [epoch: 1.66 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03323186109614321		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 0.03323186109614321 | validation: 0.036676505997315735]
	TIME [epoch: 1.66 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038998606059684436		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 0.038998606059684436 | validation: 0.02502421211108451]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03604997013097159		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 0.03604997013097159 | validation: 0.0234822592807871]
	TIME [epoch: 1.67 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.030411606378302557		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 0.030411606378302557 | validation: 0.030390270250964156]
	TIME [epoch: 1.66 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.027566742204606354		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 0.027566742204606354 | validation: 0.019916159157286242]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03909542564571323		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 0.03909542564571323 | validation: 0.028347022371012786]
	TIME [epoch: 1.66 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.022993821497330612		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 0.022993821497330612 | validation: 0.026298984326406982]
	TIME [epoch: 1.66 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03498632090851349		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 0.03498632090851349 | validation: 0.02297416771780304]
	TIME [epoch: 1.66 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.024548468439209516		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 0.024548468439209516 | validation: 0.020292891849955707]
	TIME [epoch: 1.66 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03660946064961617		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 0.03660946064961617 | validation: 0.035396602236710616]
	TIME [epoch: 1.66 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0259719702684802		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 0.0259719702684802 | validation: 0.04956371138665722]
	TIME [epoch: 1.66 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038634423692035166		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 0.038634423692035166 | validation: 0.03393692068553454]
	TIME [epoch: 1.66 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03133990277748298		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 0.03133990277748298 | validation: 0.031576416992103395]
	TIME [epoch: 1.66 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.030606511212502168		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 0.030606511212502168 | validation: 0.01742706602677411]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03206174466914337		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 0.03206174466914337 | validation: 0.027726161204086497]
	TIME [epoch: 1.67 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03298697371157372		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 0.03298697371157372 | validation: 0.032535176638545]
	TIME [epoch: 1.67 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.021212808147165266		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 0.021212808147165266 | validation: 0.03067881407212597]
	TIME [epoch: 1.66 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.023824198423071884		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 0.023824198423071884 | validation: 0.03743965777859771]
	TIME [epoch: 1.66 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.029180845990714806		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 0.029180845990714806 | validation: 0.02990789005710177]
	TIME [epoch: 1.68 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.024751290316565505		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 0.024751290316565505 | validation: 0.0245289700170064]
	TIME [epoch: 1.67 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.026916348421597014		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 0.026916348421597014 | validation: 0.02772691329691639]
	TIME [epoch: 1.66 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0311732203008463		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 0.0311732203008463 | validation: 0.012429286808822129]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.026039380841977173		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 0.026039380841977173 | validation: 0.02013203362586266]
	TIME [epoch: 1.67 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.02183952859197848		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 0.02183952859197848 | validation: 0.017719456559847406]
	TIME [epoch: 1.66 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.026332134583405654		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 0.026332134583405654 | validation: 0.032165221968058585]
	TIME [epoch: 1.66 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.020431153230755804		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 0.020431153230755804 | validation: 0.033986126213886]
	TIME [epoch: 1.66 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.024376039811556664		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 0.024376039811556664 | validation: 0.012335487528901555]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.02039137643183607		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 0.02039137643183607 | validation: 0.03472356965926314]
	TIME [epoch: 1.67 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033678580656362485		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 0.033678580656362485 | validation: 0.02001207690878756]
	TIME [epoch: 1.66 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01566400516106407		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 0.01566400516106407 | validation: 0.02667611882872022]
	TIME [epoch: 1.66 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.026086088142567698		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 0.026086088142567698 | validation: 0.02062524860424552]
	TIME [epoch: 1.66 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.015493453621501466		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 0.015493453621501466 | validation: 0.021025378765709507]
	TIME [epoch: 1.66 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01743364364083065		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 0.01743364364083065 | validation: 0.021420199308811023]
	TIME [epoch: 1.66 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.021028710727014573		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 0.021028710727014573 | validation: 0.02052700904847745]
	TIME [epoch: 1.66 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.016281249876827157		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 0.016281249876827157 | validation: 0.01452298841334983]
	TIME [epoch: 1.66 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.021345965874251464		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 0.021345965874251464 | validation: 0.02964893628290357]
	TIME [epoch: 1.66 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.021085907132509307		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 0.021085907132509307 | validation: 0.014346233264245948]
	TIME [epoch: 1.66 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.020422216360366265		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 0.020422216360366265 | validation: 0.011961656756174614]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.012731111080793145		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 0.012731111080793145 | validation: 0.009054680967449996]
	TIME [epoch: 1.66 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_100.pth
	Model improved!!!
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.030734940542559524		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 0.030734940542559524 | validation: 0.021127109895608204]
	TIME [epoch: 15.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01613873478899825		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 0.01613873478899825 | validation: 0.008749148596016052]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_102.pth
	Model improved!!!
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.013608863000997973		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 0.013608863000997973 | validation: 0.017663480907894363]
	TIME [epoch: 3.21 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.016117749580154737		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 0.016117749580154737 | validation: 0.01542855147742651]
	TIME [epoch: 3.21 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.019557555057470196		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 0.019557555057470196 | validation: 0.013960070337980048]
	TIME [epoch: 3.21 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.015311322039260028		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 0.015311322039260028 | validation: 0.0157690672769315]
	TIME [epoch: 3.21 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01688405868685654		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 0.01688405868685654 | validation: 0.01192745798889805]
	TIME [epoch: 3.21 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0116263813693617		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 0.0116263813693617 | validation: 0.0124186552600186]
	TIME [epoch: 3.21 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.020323573296019186		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 0.020323573296019186 | validation: 0.020178568093118215]
	TIME [epoch: 3.2 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.016661311833049516		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 0.016661311833049516 | validation: 0.014394599459514218]
	TIME [epoch: 3.21 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.010497368703461237		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 0.010497368703461237 | validation: 0.01357588526096867]
	TIME [epoch: 3.2 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.015046533083331403		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 0.015046533083331403 | validation: 0.01729076901538437]
	TIME [epoch: 3.2 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.013978203117391461		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 0.013978203117391461 | validation: 0.011248656696932273]
	TIME [epoch: 3.21 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.013080163920595984		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 0.013080163920595984 | validation: 0.010048691133524319]
	TIME [epoch: 3.21 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.016605304057795544		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 0.016605304057795544 | validation: 0.00600995834522707]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.012817624006267066		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 0.012817624006267066 | validation: 0.027953115207964008]
	TIME [epoch: 3.21 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.016877430447644642		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 0.016877430447644642 | validation: 0.009891392726135515]
	TIME [epoch: 3.21 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.017847819896465555		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 0.017847819896465555 | validation: 0.008453680049420587]
	TIME [epoch: 3.21 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.011571124069478099		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 0.011571124069478099 | validation: 0.025396259443473325]
	TIME [epoch: 3.21 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.012821072780198261		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 0.012821072780198261 | validation: 0.013550020665701731]
	TIME [epoch: 3.21 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.018894295918043192		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 0.018894295918043192 | validation: 0.008045848847847925]
	TIME [epoch: 3.21 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00979570209880545		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 0.00979570209880545 | validation: 0.0066276210253546726]
	TIME [epoch: 3.21 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.010310454374293388		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 0.010310454374293388 | validation: 0.009539757741692238]
	TIME [epoch: 3.21 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01620335530653478		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 0.01620335530653478 | validation: 0.01768301745224923]
	TIME [epoch: 3.21 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01878511047661149		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 0.01878511047661149 | validation: 0.008857374838577849]
	TIME [epoch: 3.21 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.012602168605674573		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 0.012602168605674573 | validation: 0.006198960125970545]
	TIME [epoch: 3.22 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.010137474400661444		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 0.010137474400661444 | validation: 0.01169505330749296]
	TIME [epoch: 3.21 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.015450033344570397		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 0.015450033344570397 | validation: 0.01846234649454421]
	TIME [epoch: 3.2 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.010168687234756668		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 0.010168687234756668 | validation: 0.012666099150485766]
	TIME [epoch: 3.21 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.01125107896136179		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 0.01125107896136179 | validation: 0.0034163014058664043]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.014640172178093644		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 0.014640172178093644 | validation: 0.00901494344505761]
	TIME [epoch: 3.21 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.009742410599783265		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 0.009742410599783265 | validation: 0.023401331262110973]
	TIME [epoch: 3.2 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0074227428951494255		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 0.0074227428951494255 | validation: 0.0051662613780724]
	TIME [epoch: 3.2 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00982080200827498		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 0.00982080200827498 | validation: 0.006145058598446667]
	TIME [epoch: 3.21 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.007801365883178602		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 0.007801365883178602 | validation: 0.006907968940234169]
	TIME [epoch: 3.2 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004460638521609198		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 0.004460638521609198 | validation: 0.007186165802243363]
	TIME [epoch: 3.21 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.009718227368781609		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 0.009718227368781609 | validation: 0.011931571449000956]
	TIME [epoch: 3.2 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.007184138859428467		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 0.007184138859428467 | validation: 0.01616072739569433]
	TIME [epoch: 3.2 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00895636571040649		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 0.00895636571040649 | validation: 0.014488655636123227]
	TIME [epoch: 3.21 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.003156602547522051		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 0.003156602547522051 | validation: 0.006847983062172723]
	TIME [epoch: 3.21 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.009208026756511207		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 0.009208026756511207 | validation: 0.001775507433995946]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_141.pth
	Model improved!!!
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.010768119866266024		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 0.010768119866266024 | validation: 0.0074940285059774845]
	TIME [epoch: 3.2 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.006571523063005883		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 0.006571523063005883 | validation: 0.007053186289676392]
	TIME [epoch: 3.21 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.006810245218717838		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 0.006810245218717838 | validation: 0.006180998929973354]
	TIME [epoch: 3.2 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.009370710922354992		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 0.009370710922354992 | validation: 0.00870953399603821]
	TIME [epoch: 3.2 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.013684847127651506		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 0.013684847127651506 | validation: 0.001976880818821981]
	TIME [epoch: 3.21 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.005121470851854293		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 0.005121470851854293 | validation: 0.0032310021884527458]
	TIME [epoch: 3.21 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.003993853146972837		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 0.003993853146972837 | validation: 0.005814003688943015]
	TIME [epoch: 3.2 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004878376526430261		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 0.004878376526430261 | validation: 0.009804716803816376]
	TIME [epoch: 3.2 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.005536496964725251		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 0.005536496964725251 | validation: 0.0017270946584289491]
	TIME [epoch: 3.2 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.007789032321035498		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 0.007789032321035498 | validation: 0.005368958128449829]
	TIME [epoch: 3.2 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004825458414788816		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 0.004825458414788816 | validation: 0.008519179463646944]
	TIME [epoch: 3.21 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.006944555863086718		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 0.006944555863086718 | validation: 0.004279208291924938]
	TIME [epoch: 3.21 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037402474788624076		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 0.0037402474788624076 | validation: 0.010594532057205432]
	TIME [epoch: 3.21 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00750234684062286		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 0.00750234684062286 | validation: 0.006846442509999673]
	TIME [epoch: 3.21 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004754706867428458		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 0.004754706867428458 | validation: 0.0028760479966260257]
	TIME [epoch: 3.21 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.005830561600129056		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 0.005830561600129056 | validation: 0.0018380067886551402]
	TIME [epoch: 3.2 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.006208202188734543		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 0.006208202188734543 | validation: 0.005357950458219128]
	TIME [epoch: 3.21 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034775874502578673		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 0.0034775874502578673 | validation: 0.005337692513490856]
	TIME [epoch: 3.2 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004989046979076269		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 0.004989046979076269 | validation: 0.012104421523078553]
	TIME [epoch: 3.21 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056320976144512815		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 0.0056320976144512815 | validation: -0.00016319991465050257]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00796560654264657		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 0.00796560654264657 | validation: 0.0028192378417364054]
	TIME [epoch: 3.21 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.003436785587580085		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 0.003436785587580085 | validation: 0.0017415164013401805]
	TIME [epoch: 3.21 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009208868559442719		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 0.0009208868559442719 | validation: 0.0017495409148095293]
	TIME [epoch: 3.21 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023130311694234563		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 0.0023130311694234563 | validation: 0.01136613514759086]
	TIME [epoch: 3.21 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.007371886467209194		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 0.007371886467209194 | validation: 0.003921793805934711]
	TIME [epoch: 3.2 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004216656994410336		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 0.004216656994410336 | validation: -0.0004823968364164606]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.003054658215078233		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 0.003054658215078233 | validation: 0.004883060385609905]
	TIME [epoch: 3.21 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036603622915828554		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 0.0036603622915828554 | validation: 0.002213349929774987]
	TIME [epoch: 3.21 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037160808476369165		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 0.0037160808476369165 | validation: 0.0004198710293482746]
	TIME [epoch: 3.21 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019440091194990595		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 0.0019440091194990595 | validation: 0.004414490790260543]
	TIME [epoch: 3.21 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004965344089433634		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 0.004965344089433634 | validation: 0.0004811893559778117]
	TIME [epoch: 3.21 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018710663613267526		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 0.0018710663613267526 | validation: 0.0006454342998534498]
	TIME [epoch: 3.21 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.009965628615861567		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 0.009965628615861567 | validation: 0.02176626290150207]
	TIME [epoch: 3.21 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004418217056947158		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 0.004418217056947158 | validation: 0.002625799907942496]
	TIME [epoch: 3.21 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004706245391653637		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: -0.0004706245391653637 | validation: -0.00021473039366734322]
	TIME [epoch: 3.21 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00543395688216383		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 0.00543395688216383 | validation: 0.012125039203502951]
	TIME [epoch: 3.21 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018503196784177404		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 0.0018503196784177404 | validation: 0.0017673804027533713]
	TIME [epoch: 3.22 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038405958468872682		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 0.0038405958468872682 | validation: 0.0036353560519864206]
	TIME [epoch: 3.21 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025330287855545425		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 0.0025330287855545425 | validation: -0.000738275583707177]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_180.pth
	Model improved!!!
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00246746568199945		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 0.00246746568199945 | validation: 0.003471836315219109]
	TIME [epoch: 3.21 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024811108610255025		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 0.0024811108610255025 | validation: 0.002399849276550323]
	TIME [epoch: 3.21 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.006885309784288742		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 0.006885309784288742 | validation: 0.0004869217962615872]
	TIME [epoch: 3.22 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025498781595087484		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 0.0025498781595087484 | validation: -0.00040917475669937574]
	TIME [epoch: 3.21 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017526538973609354		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 0.0017526538973609354 | validation: -0.00010121386758966565]
	TIME [epoch: 3.21 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004182369625709183		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: -0.0004182369625709183 | validation: -0.001164850907159952]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007770802885580423		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: -0.0007770802885580423 | validation: 0.0009944928546169807]
	TIME [epoch: 3.22 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007772407727987336		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: -0.0007772407727987336 | validation: -0.0005294263527984529]
	TIME [epoch: 3.21 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.004213649757373414		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 0.004213649757373414 | validation: -0.0015771142076034124]
	TIME [epoch: 3.21 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.000761074979901689		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 0.000761074979901689 | validation: 0.0015522942699543179]
	TIME [epoch: 3.2 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023346466362250636		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: -0.0023346466362250636 | validation: 0.00204326860927838]
	TIME [epoch: 3.21 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003274112089944261		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: -0.003274112089944261 | validation: 0.008188787953101751]
	TIME [epoch: 3.2 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00378579149327017		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 0.00378579149327017 | validation: 0.005175444428440352]
	TIME [epoch: 3.2 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0020018699629927783		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 0.0020018699629927783 | validation: 0.0011720952263707843]
	TIME [epoch: 3.21 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027621563203347336		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: -0.0027621563203347336 | validation: 0.001682445064761695]
	TIME [epoch: 3.21 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.002413303850112968		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: -0.002413303850112968 | validation: 0.0006175086000137868]
	TIME [epoch: 3.2 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012316017567638375		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: -0.0012316017567638375 | validation: -0.0018397506418275852]
	TIME [epoch: 3.2 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0843494318164143e-05		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 1.0843494318164143e-05 | validation: 0.0029483866757419193]
	TIME [epoch: 3.21 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013802353519230055		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 0.0013802353519230055 | validation: 0.0024915441299575816]
	TIME [epoch: 3.21 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019116033707671156		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 0.0019116033707671156 | validation: -0.0003050494381926801]
	TIME [epoch: 3.21 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021026910038740134		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 0.0021026910038740134 | validation: -0.00024046384631031518]
	TIME [epoch: 18.7 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003527683793292442		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: -0.0003527683793292442 | validation: -0.0015255042119621265]
	TIME [epoch: 6.29 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018976902550970017		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 0.0018976902550970017 | validation: 0.010265025973017103]
	TIME [epoch: 6.28 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0031022501317900086		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 0.0031022501317900086 | validation: -0.001208281490038776]
	TIME [epoch: 6.29 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016643168803645273		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: -0.0016643168803645273 | validation: 0.005066988145611655]
	TIME [epoch: 6.29 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0022622385906450344		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 0.0022622385906450344 | validation: -0.003049138082998268]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_206.pth
	Model improved!!!
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014396062222159106		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: -0.0014396062222159106 | validation: -0.0032176034381117165]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_207.pth
	Model improved!!!
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007525719979026154		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: -0.0007525719979026154 | validation: -0.0033288191360889294]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008713269848777541		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: -0.0008713269848777541 | validation: -0.0007802357304295323]
	TIME [epoch: 6.3 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024785961207805184		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: -0.0024785961207805184 | validation: 0.0007525822525204764]
	TIME [epoch: 6.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008037364514414993		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: -0.0008037364514414993 | validation: -0.002548495485210115]
	TIME [epoch: 6.3 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.001408690796747367		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 0.001408690796747367 | validation: -0.0018768173100162694]
	TIME [epoch: 6.29 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021787708596034726		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: -0.0021787708596034726 | validation: -0.0014246963045256827]
	TIME [epoch: 6.29 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.531656680554847e-05		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 6.531656680554847e-05 | validation: -0.0011787896818366375]
	TIME [epoch: 6.28 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003935334387652051		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: -0.003935334387652051 | validation: -0.002556549080362541]
	TIME [epoch: 6.29 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021742526938865847		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: -0.0021742526938865847 | validation: -0.0043037139448617034]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037595518914156473		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: -0.0037595518914156473 | validation: 0.004036853017334934]
	TIME [epoch: 6.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014151453780476037		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: -0.0014151453780476037 | validation: -0.0038453508523468268]
	TIME [epoch: 6.29 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009100593589543527		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: -0.0009100593589543527 | validation: -0.000837110528028674]
	TIME [epoch: 6.28 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.001921695402690256		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: -0.001921695402690256 | validation: -0.0007321539203309689]
	TIME [epoch: 6.29 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026893036391031576		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: -0.0026893036391031576 | validation: 8.402536431494426e-06]
	TIME [epoch: 6.3 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032255562258929685		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: -0.0032255562258929685 | validation: -0.0027139468799968645]
	TIME [epoch: 6.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018392352221990992		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: -0.0018392352221990992 | validation: 0.0028420738525130225]
	TIME [epoch: 6.31 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021769332716838306		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: -0.0021769332716838306 | validation: -0.0050338561934976005]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007350257737854407		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: -0.0007350257737854407 | validation: -0.002926823195610269]
	TIME [epoch: 6.29 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.00029527654455564106		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 0.00029527654455564106 | validation: 0.008243052111473683]
	TIME [epoch: 6.29 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008934935493863014		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: -0.0008934935493863014 | validation: -0.0022418530869811296]
	TIME [epoch: 6.29 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032372350887255917		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: -0.0032372350887255917 | validation: -0.0012142619727797544]
	TIME [epoch: 6.29 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.002255665660085914		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: -0.002255665660085914 | validation: -0.0055786280247332575]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_229.pth
	Model improved!!!
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.002747470859318442		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: -0.002747470859318442 | validation: 0.00507241502440789]
	TIME [epoch: 6.3 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00046474760753650727		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: -0.00046474760753650727 | validation: -0.00025206601573212064]
	TIME [epoch: 6.29 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024871764229903665		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: -0.0024871764229903665 | validation: -0.0023421597613874252]
	TIME [epoch: 6.29 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00021142715701612946		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: -0.00021142715701612946 | validation: -0.0036126242806711487]
	TIME [epoch: 6.29 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010736224332703308		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: -0.0010736224332703308 | validation: -0.0014780231688445136]
	TIME [epoch: 6.29 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031219265892571107		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: -0.0031219265892571107 | validation: -0.0038975883557484194]
	TIME [epoch: 6.28 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.001103036756560837		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: -0.001103036756560837 | validation: -0.003488211996019122]
	TIME [epoch: 6.29 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.665736304666736e-05		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 5.665736304666736e-05 | validation: -0.005370861687389139]
	TIME [epoch: 6.29 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019786923118615307		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: -0.0019786923118615307 | validation: -0.004871476664762395]
	TIME [epoch: 6.29 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.001848655423179273		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: -0.001848655423179273 | validation: -0.004040737321368285]
	TIME [epoch: 6.29 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011938870925742267		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: -0.0011938870925742267 | validation: -0.0022820164807479427]
	TIME [epoch: 6.29 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003571628498204611		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: -0.003571628498204611 | validation: -0.004005274022835478]
	TIME [epoch: 6.29 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020078406925675934		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: -0.0020078406925675934 | validation: 0.0025780184499797918]
	TIME [epoch: 6.29 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022298143267134385		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: -0.0022298143267134385 | validation: -0.003603339857418198]
	TIME [epoch: 6.29 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007929440484928434		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: -0.0007929440484928434 | validation: 0.004770297616747319]
	TIME [epoch: 6.29 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001364234785263943		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: -0.0001364234785263943 | validation: -0.0056057137136161445]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_245.pth
	Model improved!!!
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024708169633595786		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: -0.0024708169633595786 | validation: -0.002127905732715586]
	TIME [epoch: 6.28 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0035733402647961086		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: -0.0035733402647961086 | validation: -0.004876073512757342]
	TIME [epoch: 6.28 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027480080830044255		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: -0.0027480080830044255 | validation: -0.005289984442492657]
	TIME [epoch: 6.28 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.002484730730831394		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: -0.002484730730831394 | validation: 0.001939240522900613]
	TIME [epoch: 6.27 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016347192648878638		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: -0.0016347192648878638 | validation: -0.0052988546929563]
	TIME [epoch: 6.29 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0002551414147985775		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: -0.0002551414147985775 | validation: 0.003684787694546183]
	TIME [epoch: 6.28 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004049447253419455		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: -0.0004049447253419455 | validation: -0.003777238871769646]
	TIME [epoch: 6.28 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016323069073389436		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: -0.0016323069073389436 | validation: -0.0016668636499818311]
	TIME [epoch: 6.27 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005151851790664105		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: -0.005151851790664105 | validation: -0.0045966053168596385]
	TIME [epoch: 6.28 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003990782507813884		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: -0.003990782507813884 | validation: -0.002197344165444555]
	TIME [epoch: 6.29 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004850249768394694		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: -0.004850249768394694 | validation: 0.003957196809276016]
	TIME [epoch: 6.28 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00018671963612366656		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: -0.00018671963612366656 | validation: -0.004776764679752289]
	TIME [epoch: 6.28 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003326527258422337		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: -0.003326527258422337 | validation: -0.0052965048245864664]
	TIME [epoch: 6.27 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012042256055696207		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: -0.0012042256055696207 | validation: -0.003769506610610583]
	TIME [epoch: 6.28 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003060857009963739		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: -0.003060857009963739 | validation: -0.0009953362155101983]
	TIME [epoch: 6.28 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022012279241692308		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: -0.0022012279241692308 | validation: 0.00026621705775203245]
	TIME [epoch: 6.28 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032791327981524744		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: -0.0032791327981524744 | validation: -0.0018193268496947835]
	TIME [epoch: 6.28 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018422365822541257		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: -0.0018422365822541257 | validation: -0.003061762796054743]
	TIME [epoch: 6.29 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017344552029987426		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: -0.0017344552029987426 | validation: -0.0005365074303525297]
	TIME [epoch: 6.29 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028489837152810386		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: -0.0028489837152810386 | validation: -0.005526679142367537]
	TIME [epoch: 6.28 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003042482785888407		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: -0.003042482785888407 | validation: -0.005334538094775233]
	TIME [epoch: 6.28 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0055227768155826605		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: -0.0055227768155826605 | validation: -0.0007066829214499577]
	TIME [epoch: 6.29 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018961125780252142		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: -0.0018961125780252142 | validation: 0.0020403064539674565]
	TIME [epoch: 6.29 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003337542247051803		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: -0.003337542247051803 | validation: -0.004623017236836691]
	TIME [epoch: 6.3 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003423802338199134		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: -0.003423802338199134 | validation: -0.004112522530258013]
	TIME [epoch: 6.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012930114617046942		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: -0.0012930114617046942 | validation: -0.0056733276092178295]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_271.pth
	Model improved!!!
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004627525043752905		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: -0.004627525043752905 | validation: -0.006557070710019167]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_272.pth
	Model improved!!!
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00142230386466276		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: -0.00142230386466276 | validation: -0.004034234011592972]
	TIME [epoch: 6.29 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003862420577911749		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: -0.003862420577911749 | validation: -0.003995922853410231]
	TIME [epoch: 6.29 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018490405291438725		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: -0.0018490405291438725 | validation: -0.0026871642382138043]
	TIME [epoch: 6.29 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037815587502636203		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: -0.0037815587502636203 | validation: -0.0016779281695532208]
	TIME [epoch: 6.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00622135811428437		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: -0.00622135811428437 | validation: -0.002062127215756061]
	TIME [epoch: 6.29 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003471335301115136		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: -0.003471335301115136 | validation: 0.0028810038050945137]
	TIME [epoch: 6.29 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010207586614796517		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.0010207586614796517 | validation: -0.006246855390979732]
	TIME [epoch: 6.28 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004548039181915639		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: -0.004548039181915639 | validation: -0.0036526543334185944]
	TIME [epoch: 6.29 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005398447379279544		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: -0.005398447379279544 | validation: -0.0049831182546406635]
	TIME [epoch: 6.28 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005425826322479698		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: -0.005425826322479698 | validation: -0.0055457871201485265]
	TIME [epoch: 6.29 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031602903510208682		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: -0.0031602903510208682 | validation: -0.0020398354132928976]
	TIME [epoch: 6.28 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038005922436024444		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: -0.0038005922436024444 | validation: -0.003185207573836525]
	TIME [epoch: 6.29 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003035033923020072		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: -0.003035033923020072 | validation: -0.004103733956363416]
	TIME [epoch: 6.29 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033897608818404543		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: -0.0033897608818404543 | validation: -0.002001317452644708]
	TIME [epoch: 6.28 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004619987205733377		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: -0.004619987205733377 | validation: -0.004103356229124765]
	TIME [epoch: 6.28 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013759089139095738		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: -0.0013759089139095738 | validation: -0.0010494768036645198]
	TIME [epoch: 6.29 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005295510266671958		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: -0.005295510266671958 | validation: -0.004043127889998969]
	TIME [epoch: 6.28 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032857207076400136		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: -0.0032857207076400136 | validation: -0.0033784755184132773]
	TIME [epoch: 6.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018760764463407083		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: -0.0018760764463407083 | validation: -0.004440195834495021]
	TIME [epoch: 6.29 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006744460906824385		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: -0.006744460906824385 | validation: -0.007718205910932074]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_292.pth
	Model improved!!!
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004672544545892124		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: -0.004672544545892124 | validation: -0.0039610605766742055]
	TIME [epoch: 6.28 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004425470298581406		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: -0.004425470298581406 | validation: -0.002416401593035044]
	TIME [epoch: 6.29 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004153388924004094		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: -0.004153388924004094 | validation: -0.004854200731909619]
	TIME [epoch: 6.29 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.002575265880189705		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: -0.002575265880189705 | validation: -0.005188038970297209]
	TIME [epoch: 6.28 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00346364943191646		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: -0.00346364943191646 | validation: -0.006390385986637609]
	TIME [epoch: 6.3 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006707049848102634		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: -0.006707049848102634 | validation: -0.0017673275290319777]
	TIME [epoch: 6.28 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003685773594698416		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: -0.003685773594698416 | validation: -0.0022920257868380427]
	TIME [epoch: 6.29 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003928439960674054		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: -0.003928439960674054 | validation: -0.004807406107963424]
	TIME [epoch: 6.28 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00542421575737531		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: -0.00542421575737531 | validation: -0.0035324182412033735]
	TIME [epoch: 24.7 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007004439343907616		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: -0.007004439343907616 | validation: -0.0006684308742948576]
	TIME [epoch: 12.5 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004892663957677422		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: -0.004892663957677422 | validation: -0.0034208965542289914]
	TIME [epoch: 12.5 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037120353555312006		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: -0.0037120353555312006 | validation: -0.005943642916300547]
	TIME [epoch: 12.5 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005469183795064839		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: -0.005469183795064839 | validation: -0.006359945014925088]
	TIME [epoch: 12.5 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005877884976025573		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: -0.005877884976025573 | validation: -0.005569976378320966]
	TIME [epoch: 12.4 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0040037504015098075		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: -0.0040037504015098075 | validation: -0.004288659339410599]
	TIME [epoch: 12.4 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006559303967994383		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: -0.006559303967994383 | validation: -0.0019583501696907183]
	TIME [epoch: 12.4 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004394911368525882		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: -0.004394911368525882 | validation: -0.008572188115482689]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_309.pth
	Model improved!!!
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005460396727368054		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: -0.005460396727368054 | validation: -0.004116774075495283]
	TIME [epoch: 12.4 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005083089135605569		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: -0.005083089135605569 | validation: -0.005362768422458237]
	TIME [epoch: 12.4 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0029449668021672383		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: -0.0029449668021672383 | validation: -0.002493973263036583]
	TIME [epoch: 12.4 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033405472434202923		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: -0.0033405472434202923 | validation: -0.0061907503101390135]
	TIME [epoch: 12.4 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034773382071856735		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: -0.0034773382071856735 | validation: -0.004838112073620126]
	TIME [epoch: 12.4 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004261951713350055		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: -0.004261951713350055 | validation: -0.0038233671186634647]
	TIME [epoch: 12.4 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038154107891524595		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: -0.0038154107891524595 | validation: -0.007210429930295271]
	TIME [epoch: 12.4 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004538093062469136		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: -0.004538093062469136 | validation: -0.0042624970590890935]
	TIME [epoch: 12.4 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005738702937992296		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: -0.005738702937992296 | validation: -0.005925258425052609]
	TIME [epoch: 12.4 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0056823560074312635		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: -0.0056823560074312635 | validation: -0.001583315255633444]
	TIME [epoch: 12.4 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004827303693423621		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: -0.004827303693423621 | validation: -0.006565734169635842]
	TIME [epoch: 12.4 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004603094351273664		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: -0.004603094351273664 | validation: -0.002009632067871952]
	TIME [epoch: 12.5 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004884442322329965		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: -0.004884442322329965 | validation: -0.005474335601128831]
	TIME [epoch: 12.4 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0052170404786776835		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: -0.0052170404786776835 | validation: -0.005391334412895799]
	TIME [epoch: 12.5 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005219976690880436		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: -0.005219976690880436 | validation: -0.0044839085823133295]
	TIME [epoch: 12.4 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015489940273494857		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: -0.0015489940273494857 | validation: -0.00536279806440903]
	TIME [epoch: 12.5 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00632003436464402		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: -0.00632003436464402 | validation: -0.008222659204371093]
	TIME [epoch: 12.5 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004894568258933739		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: -0.004894568258933739 | validation: -0.0058812051741798195]
	TIME [epoch: 12.5 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006762248560346929		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: -0.0006762248560346929 | validation: -0.005559625136888244]
	TIME [epoch: 12.5 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0067809324202738235		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: -0.0067809324202738235 | validation: -0.0047145586570611145]
	TIME [epoch: 12.5 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006582886160820066		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: -0.006582886160820066 | validation: -0.008135109656583818]
	TIME [epoch: 12.5 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0044237865976255696		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: -0.0044237865976255696 | validation: -0.005898411071259449]
	TIME [epoch: 12.5 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005278110866633204		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: -0.005278110866633204 | validation: -0.00724586541296277]
	TIME [epoch: 12.5 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005209737611822968		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: -0.005209737611822968 | validation: -0.00631835503203218]
	TIME [epoch: 12.4 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004556930703799552		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: -0.004556930703799552 | validation: -0.004975840494012581]
	TIME [epoch: 12.5 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006301864161718823		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: -0.006301864161718823 | validation: -0.005555710601836379]
	TIME [epoch: 12.4 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00500813298600596		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: -0.00500813298600596 | validation: -0.004212054765042707]
	TIME [epoch: 12.5 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036579094121328816		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: -0.0036579094121328816 | validation: -0.0071108180585959385]
	TIME [epoch: 12.4 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005700452912649363		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: -0.005700452912649363 | validation: -0.007503136335745106]
	TIME [epoch: 12.4 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004535289899242199		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: -0.004535289899242199 | validation: -0.005496336291834415]
	TIME [epoch: 12.4 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004948945221036879		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: -0.004948945221036879 | validation: -0.0053074009642596265]
	TIME [epoch: 12.4 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005949031954086158		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: -0.005949031954086158 | validation: -0.007030239797324927]
	TIME [epoch: 12.5 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005041569396577005		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: -0.005041569396577005 | validation: -0.00589334116337499]
	TIME [epoch: 12.4 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0047758723223588085		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: -0.0047758723223588085 | validation: -0.007913995013639317]
	TIME [epoch: 12.4 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006432057441210347		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: -0.006432057441210347 | validation: -0.007223075993130155]
	TIME [epoch: 12.5 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004826418372219298		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: -0.004826418372219298 | validation: -0.007603423665317283]
	TIME [epoch: 12.5 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00896031381875716		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: -0.00896031381875716 | validation: -0.00429800758089423]
	TIME [epoch: 12.5 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006670165000982937		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: -0.006670165000982937 | validation: -0.006518354166077711]
	TIME [epoch: 12.5 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005355325419363151		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: -0.005355325419363151 | validation: -0.006671564472669793]
	TIME [epoch: 12.5 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0064812717314788005		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: -0.0064812717314788005 | validation: -0.002446417268021843]
	TIME [epoch: 12.5 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005625684934588087		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: -0.005625684934588087 | validation: -0.006502782344044365]
	TIME [epoch: 12.5 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006389318998100348		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: -0.006389318998100348 | validation: -0.0053529710754924645]
	TIME [epoch: 12.5 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006184067805304086		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: -0.006184067805304086 | validation: -0.006513067022803064]
	TIME [epoch: 12.5 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034375028370771353		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: -0.0034375028370771353 | validation: -0.006243685736630715]
	TIME [epoch: 12.5 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0035186416914748933		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: -0.0035186416914748933 | validation: -0.0014102129624700833]
	TIME [epoch: 12.5 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0046019231686286605		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: -0.0046019231686286605 | validation: -0.006537246404603503]
	TIME [epoch: 12.5 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004336455809983647		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: -0.004336455809983647 | validation: -0.00716913102597808]
	TIME [epoch: 12.5 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005502668671496751		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: -0.005502668671496751 | validation: -0.00518268853099715]
	TIME [epoch: 12.5 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005563904595533548		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: -0.005563904595533548 | validation: -0.005185704373736022]
	TIME [epoch: 12.5 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.003201460334681159		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: -0.003201460334681159 | validation: -0.005670202376554625]
	TIME [epoch: 12.5 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005783724201099045		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: -0.005783724201099045 | validation: -0.008455854470365315]
	TIME [epoch: 12.5 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00795326665158534		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: -0.00795326665158534 | validation: -0.008012126826265963]
	TIME [epoch: 12.5 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007478308965788707		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: -0.007478308965788707 | validation: -0.0073834913088068835]
	TIME [epoch: 12.5 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00640977180173911		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: -0.00640977180173911 | validation: -0.0057104871174003145]
	TIME [epoch: 12.5 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032571677774377488		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: -0.0032571677774377488 | validation: -0.006334915879920871]
	TIME [epoch: 12.5 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0062155381889220295		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: -0.0062155381889220295 | validation: -0.006607814174411869]
	TIME [epoch: 12.5 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00622881358669739		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: -0.00622881358669739 | validation: -0.004897323876466915]
	TIME [epoch: 12.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00717764261551878		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: -0.00717764261551878 | validation: -0.005821305023245901]
	TIME [epoch: 12.4 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00593362035662308		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: -0.00593362035662308 | validation: -0.005965577190520155]
	TIME [epoch: 12.5 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005343602912704462		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: -0.005343602912704462 | validation: -0.006275048641998885]
	TIME [epoch: 12.5 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0070750315238087445		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: -0.0070750315238087445 | validation: -0.005003360902975653]
	TIME [epoch: 12.4 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006554248161278367		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: -0.006554248161278367 | validation: -0.007003003501617924]
	TIME [epoch: 12.4 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00568936611324749		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: -0.00568936611324749 | validation: -0.006442629762875063]
	TIME [epoch: 12.5 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007375524397674508		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: -0.007375524397674508 | validation: -0.006888246931696061]
	TIME [epoch: 12.4 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005670847420331339		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: -0.005670847420331339 | validation: -0.005019640906475286]
	TIME [epoch: 12.4 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006289724847795856		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: -0.006289724847795856 | validation: -0.006149278085672415]
	TIME [epoch: 12.4 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007592547900593233		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: -0.007592547900593233 | validation: -0.0074046832136460015]
	TIME [epoch: 12.4 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005672595804328951		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: -0.005672595804328951 | validation: -0.006264667986799805]
	TIME [epoch: 12.4 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007050571645735057		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: -0.007050571645735057 | validation: -0.004252868930281784]
	TIME [epoch: 12.4 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006718014589402558		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: -0.006718014589402558 | validation: -0.0076425875383368215]
	TIME [epoch: 12.5 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007285239705760983		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: -0.007285239705760983 | validation: -0.0059864942283198]
	TIME [epoch: 12.4 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0060597665780713185		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: -0.0060597665780713185 | validation: -0.005948257544362833]
	TIME [epoch: 12.4 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006722008374000658		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: -0.006722008374000658 | validation: -0.00713748215870072]
	TIME [epoch: 12.4 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0041230711928812785		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: -0.0041230711928812785 | validation: -0.007303364000954398]
	TIME [epoch: 12.5 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007329016396804012		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: -0.007329016396804012 | validation: -0.008488835361704748]
	TIME [epoch: 12.4 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006231356248900826		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: -0.006231356248900826 | validation: -0.0067899260761052505]
	TIME [epoch: 12.5 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004334950615024861		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: -0.004334950615024861 | validation: -0.005970626344118223]
	TIME [epoch: 12.4 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005429826142320562		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: -0.005429826142320562 | validation: -0.007243534087643187]
	TIME [epoch: 12.5 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008042514864892072		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: -0.008042514864892072 | validation: -0.00676903175057533]
	TIME [epoch: 12.5 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005659792539818528		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: -0.005659792539818528 | validation: -0.004552633616386998]
	TIME [epoch: 12.5 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008265289564725806		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: -0.008265289564725806 | validation: -0.0067037764712976605]
	TIME [epoch: 12.5 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007653282547206622		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: -0.007653282547206622 | validation: -0.004726627741972739]
	TIME [epoch: 12.4 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0062198915158452215		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: -0.0062198915158452215 | validation: -0.007737401249267457]
	TIME [epoch: 12.5 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005051358324939659		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: -0.005051358324939659 | validation: -0.005109816370580817]
	TIME [epoch: 12.4 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006481739033520966		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: -0.006481739033520966 | validation: -0.006543208293964627]
	TIME [epoch: 12.4 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006932857971952949		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: -0.006932857971952949 | validation: -0.004639815893619633]
	TIME [epoch: 12.4 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008848684843473969		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: -0.008848684843473969 | validation: -0.00649974459311343]
	TIME [epoch: 12.4 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004637977624082149		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: -0.004637977624082149 | validation: -0.008087771724974347]
	TIME [epoch: 12.4 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006625662604148643		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: -0.006625662604148643 | validation: -0.008058713647301121]
	TIME [epoch: 12.5 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006986372986428735		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: -0.006986372986428735 | validation: -0.006738470507023216]
	TIME [epoch: 12.4 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008504619226429248		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: -0.008504619226429248 | validation: -0.009145531253603716]
	TIME [epoch: 12.4 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_400.pth
	Model improved!!!
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006505244654035814		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: -0.006505244654035814 | validation: -0.006950175129902467]
	TIME [epoch: 38.7 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006688160379238127		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: -0.006688160379238127 | validation: -0.006876487094226074]
	TIME [epoch: 26.4 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008829718340096267		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: -0.008829718340096267 | validation: -0.006480041354987339]
	TIME [epoch: 26.3 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00785312239110086		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: -0.00785312239110086 | validation: -0.005625764919801754]
	TIME [epoch: 26.4 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006217090655511249		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: -0.006217090655511249 | validation: -0.006664477017244057]
	TIME [epoch: 26.4 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006705505981904257		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: -0.006705505981904257 | validation: -0.006897661588639076]
	TIME [epoch: 26.4 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005786245615165564		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: -0.005786245615165564 | validation: -0.007226808616120626]
	TIME [epoch: 26.4 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004539658574974398		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: -0.004539658574974398 | validation: -0.007427129203101718]
	TIME [epoch: 26.4 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007404231731011674		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: -0.007404231731011674 | validation: -0.005747242253287554]
	TIME [epoch: 26.4 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006464044927259639		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: -0.006464044927259639 | validation: -0.006675423537075497]
	TIME [epoch: 26.4 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006725583316278811		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: -0.006725583316278811 | validation: -0.008806984887571439]
	TIME [epoch: 26.3 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0071866595527796395		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: -0.0071866595527796395 | validation: -0.007248713783144849]
	TIME [epoch: 26.4 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006864187018140277		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: -0.006864187018140277 | validation: -0.007416936227993982]
	TIME [epoch: 26.4 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006785940315677806		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: -0.006785940315677806 | validation: -0.007712088721030105]
	TIME [epoch: 26.4 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005426764543961453		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: -0.005426764543961453 | validation: -0.005871513695375596]
	TIME [epoch: 26.4 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004188197706762726		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: -0.004188197706762726 | validation: -0.007455453689927965]
	TIME [epoch: 26.3 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005367611343410436		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: -0.005367611343410436 | validation: -0.0071048819375079345]
	TIME [epoch: 26.3 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006987600372548612		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: -0.006987600372548612 | validation: -0.005353409707757874]
	TIME [epoch: 26.4 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0062181779749128484		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: -0.0062181779749128484 | validation: -0.010613022410019903]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_419.pth
	Model improved!!!
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006537726299462994		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: -0.006537726299462994 | validation: -0.006961006043007691]
	TIME [epoch: 26.4 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005639610027181259		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: -0.005639610027181259 | validation: -0.007144591350504362]
	TIME [epoch: 26.4 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006473952846398036		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: -0.006473952846398036 | validation: -0.00788253453713388]
	TIME [epoch: 26.3 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005106914311487373		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: -0.005106914311487373 | validation: -0.008195861156550592]
	TIME [epoch: 26.4 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005947837708776037		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: -0.005947837708776037 | validation: -0.004916823616408399]
	TIME [epoch: 26.3 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006583141865493737		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: -0.006583141865493737 | validation: -0.006572451982240652]
	TIME [epoch: 26.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00632432484495505		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: -0.00632432484495505 | validation: -0.007966198893947677]
	TIME [epoch: 26.3 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0076915863698540825		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: -0.0076915863698540825 | validation: -0.00812363571930642]
	TIME [epoch: 26.3 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004937217853424117		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: -0.004937217853424117 | validation: -0.006906846577720815]
	TIME [epoch: 26.3 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.004401231505895496		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: -0.004401231505895496 | validation: -0.007759233494139622]
	TIME [epoch: 26.4 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0066646413477274725		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: -0.0066646413477274725 | validation: -0.006595976093563228]
	TIME [epoch: 26.4 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006508574642939272		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: -0.006508574642939272 | validation: -0.007367178536719579]
	TIME [epoch: 26.4 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005401537878632282		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: -0.005401537878632282 | validation: -0.007536001705176418]
	TIME [epoch: 26.4 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005992545940548649		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: -0.005992545940548649 | validation: -0.007602855017091774]
	TIME [epoch: 26.4 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008323840668684707		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: -0.008323840668684707 | validation: -0.006101938667591981]
	TIME [epoch: 26.4 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0052032429098552045		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: -0.0052032429098552045 | validation: -0.00583148466576138]
	TIME [epoch: 26.4 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006820884463858439		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: -0.006820884463858439 | validation: -0.007801396504325095]
	TIME [epoch: 26.4 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005295011419087755		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: -0.005295011419087755 | validation: -0.006253563392224021]
	TIME [epoch: 26.4 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00621693889506533		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: -0.00621693889506533 | validation: -0.004167734689108197]
	TIME [epoch: 26.4 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005434876373907149		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: -0.005434876373907149 | validation: -0.007676721509868921]
	TIME [epoch: 26.4 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005628515823841924		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: -0.005628515823841924 | validation: -0.006629059584796609]
	TIME [epoch: 26.4 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008415473187434668		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: -0.008415473187434668 | validation: -0.006281991945856125]
	TIME [epoch: 26.4 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007641184504416101		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: -0.007641184504416101 | validation: -0.007887116026402541]
	TIME [epoch: 26.4 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006427466601128605		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: -0.006427466601128605 | validation: -0.006837493937328444]
	TIME [epoch: 26.3 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006053430817872297		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: -0.006053430817872297 | validation: -0.00752133609924889]
	TIME [epoch: 26.4 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007598763191193424		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: -0.007598763191193424 | validation: -0.005420662288157825]
	TIME [epoch: 26.3 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00601261444132646		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: -0.00601261444132646 | validation: -0.008322685656087306]
	TIME [epoch: 26.4 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007569326026226698		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: -0.007569326026226698 | validation: -0.0071088782612140165]
	TIME [epoch: 26.3 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007334686476229932		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: -0.007334686476229932 | validation: -0.008647000188369579]
	TIME [epoch: 26.4 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00845895241388079		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: -0.00845895241388079 | validation: -0.00682218029480465]
	TIME [epoch: 26.3 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007044957712245908		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: -0.007044957712245908 | validation: -0.007639478692455305]
	TIME [epoch: 26.4 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007530086825032074		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: -0.007530086825032074 | validation: -0.006548517465800402]
	TIME [epoch: 26.4 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007839553957315787		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: -0.007839553957315787 | validation: -0.004435061399819398]
	TIME [epoch: 26.4 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0071795096261434		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: -0.0071795096261434 | validation: -0.00835919812410727]
	TIME [epoch: 26.3 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005044611705206837		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: -0.005044611705206837 | validation: -0.004542508280288749]
	TIME [epoch: 26.4 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005278894792262754		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: -0.005278894792262754 | validation: -0.007968370874050498]
	TIME [epoch: 26.4 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007970540866124429		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: -0.007970540866124429 | validation: -0.006551379211604888]
	TIME [epoch: 26.4 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007389842176951387		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: -0.007389842176951387 | validation: -0.00452253458664023]
	TIME [epoch: 26.4 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006454165138994071		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: -0.006454165138994071 | validation: -0.00832166659620118]
	TIME [epoch: 26.4 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006252213416258074		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: -0.006252213416258074 | validation: -0.00901855602778959]
	TIME [epoch: 26.4 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006300011552500755		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: -0.006300011552500755 | validation: -0.008671746308635528]
	TIME [epoch: 26.3 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.009638820888908302		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: -0.009638820888908302 | validation: -0.007299048114639874]
	TIME [epoch: 26.4 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007982157744807119		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: -0.007982157744807119 | validation: -0.008946525522377614]
	TIME [epoch: 26.4 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005976340435402388		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: -0.005976340435402388 | validation: -0.006972148248915161]
	TIME [epoch: 26.4 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007633161699336047		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: -0.007633161699336047 | validation: -0.007093732748783443]
	TIME [epoch: 26.4 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007331133952435441		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: -0.007331133952435441 | validation: -0.00808956707546426]
	TIME [epoch: 26.4 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007926758975470039		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: -0.007926758975470039 | validation: -0.004634246373895525]
	TIME [epoch: 26.4 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007077207602820564		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: -0.007077207602820564 | validation: -0.00766818307556769]
	TIME [epoch: 26.4 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008168724286838385		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: -0.008168724286838385 | validation: -0.007592382004746321]
	TIME [epoch: 26.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007386344466945906		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: -0.007386344466945906 | validation: -0.006357237912984451]
	TIME [epoch: 26.4 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007444890534799459		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: -0.007444890534799459 | validation: -0.00802900264229319]
	TIME [epoch: 26.4 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00700815411250791		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: -0.00700815411250791 | validation: -0.005400815542481669]
	TIME [epoch: 26.4 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.009517806603530635		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: -0.009517806603530635 | validation: -0.009283146008092158]
	TIME [epoch: 26.4 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006989762953934814		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: -0.006989762953934814 | validation: -0.0077913814670671514]
	TIME [epoch: 26.4 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007653198337930468		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: -0.007653198337930468 | validation: -0.008225352362489533]
	TIME [epoch: 26.3 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007679364603298424		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: -0.007679364603298424 | validation: -0.008060234744250017]
	TIME [epoch: 26.4 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007150969513997357		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: -0.007150969513997357 | validation: -0.004506388898598779]
	TIME [epoch: 26.3 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006676920061642185		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: -0.006676920061642185 | validation: -0.004990742050786413]
	TIME [epoch: 26.4 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007255475125442677		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: -0.007255475125442677 | validation: -0.007559813027794814]
	TIME [epoch: 26.4 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007745374662043359		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: -0.007745374662043359 | validation: -0.008376084129648865]
	TIME [epoch: 26.3 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008099805745851354		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: -0.008099805745851354 | validation: -0.007963423784232704]
	TIME [epoch: 26.3 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.009259842023467994		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: -0.009259842023467994 | validation: -0.007567103982492508]
	TIME [epoch: 26.4 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00774732154590414		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: -0.00774732154590414 | validation: -0.0059001636991423715]
	TIME [epoch: 26.3 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007814155904037908		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: -0.007814155904037908 | validation: -0.00827281507847912]
	TIME [epoch: 26.4 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008545758983174858		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: -0.008545758983174858 | validation: -0.00581995148338495]
	TIME [epoch: 26.4 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007189845215183547		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: -0.007189845215183547 | validation: -0.007580171886846362]
	TIME [epoch: 26.4 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0063987387032349		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: -0.0063987387032349 | validation: -0.007702727547089663]
	TIME [epoch: 26.4 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0075001335577092095		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: -0.0075001335577092095 | validation: -0.009109176672273555]
	TIME [epoch: 26.4 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008376338994979653		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: -0.008376338994979653 | validation: -0.006868329292901236]
	TIME [epoch: 26.4 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006503676637489998		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: -0.006503676637489998 | validation: -0.0069822842881891055]
	TIME [epoch: 26.4 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008230858257633217		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: -0.008230858257633217 | validation: -0.008174160034784782]
	TIME [epoch: 26.3 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008355532947995256		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: -0.008355532947995256 | validation: -0.007272509466002516]
	TIME [epoch: 26.4 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008763490443519149		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: -0.008763490443519149 | validation: -0.007060195832318357]
	TIME [epoch: 26.4 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.010736169913215753		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: -0.010736169913215753 | validation: -0.006690526690985589]
	TIME [epoch: 26.4 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00759177254568303		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: -0.00759177254568303 | validation: -0.005231664286420916]
	TIME [epoch: 26.3 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007702032496282811		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: -0.007702032496282811 | validation: -0.0073457288629493]
	TIME [epoch: 26.3 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005782895288513429		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: -0.005782895288513429 | validation: -0.009319944376137635]
	TIME [epoch: 26.3 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008837641735046226		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: -0.008837641735046226 | validation: -0.00740023195053371]
	TIME [epoch: 26.3 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00794219668331139		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: -0.00794219668331139 | validation: -0.008221612391389242]
	TIME [epoch: 26.3 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.0064384507068914205		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: -0.0064384507068914205 | validation: -0.006264852692001881]
	TIME [epoch: 26.4 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007825427225319858		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: -0.007825427225319858 | validation: -0.007365208948065102]
	TIME [epoch: 26.3 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007340074369479461		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: -0.007340074369479461 | validation: -0.007998344752714975]
	TIME [epoch: 71.3 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008849082661175848		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: -0.008849082661175848 | validation: -0.00771112160706653]
	TIME [epoch: 58.9 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.009415158211964657		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: -0.009415158211964657 | validation: -0.006729391852699017]
	TIME [epoch: 58.9 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007678331511341931		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: -0.007678331511341931 | validation: -0.006342027307751788]
	TIME [epoch: 59 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.009010721688392806		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: -0.009010721688392806 | validation: -0.0070690801832077165]
	TIME [epoch: 58.9 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007620465344705554		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: -0.007620465344705554 | validation: -0.007823775439642312]
	TIME [epoch: 58.9 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00932125277385319		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: -0.00932125277385319 | validation: -0.006536797982894296]
	TIME [epoch: 59 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008619040557993238		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: -0.008619040557993238 | validation: -0.007544834988069915]
	TIME [epoch: 59 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008521342009953373		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: -0.008521342009953373 | validation: -0.009618815901154746]
	TIME [epoch: 59 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008118775376250074		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: -0.008118775376250074 | validation: -0.006367748704670648]
	TIME [epoch: 58.9 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00880702985984687		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: -0.00880702985984687 | validation: -0.009167359858801988]
	TIME [epoch: 59 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.005283734745511315		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: -0.005283734745511315 | validation: -0.006326968072954742]
	TIME [epoch: 59 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007894943409315482		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: -0.007894943409315482 | validation: -0.007162800875743172]
	TIME [epoch: 58.9 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.006639519661763163		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: -0.006639519661763163 | validation: -0.007670659822824272]
	TIME [epoch: 58.9 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00867746539013114		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: -0.00867746539013114 | validation: -0.007958919946833867]
	TIME [epoch: 59 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.007029961604439148		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: -0.007029961604439148 | validation: -0.00826361077274593]
	TIME [epoch: 58.9 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00686982751444071		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: -0.00686982751444071 | validation: -0.00687824609078261]
	TIME [epoch: 58.9 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008189731605644701		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: -0.008189731605644701 | validation: -0.006927462449194131]
	TIME [epoch: 58.9 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.00809248742307023		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: -0.00809248742307023 | validation: -0.006654763740119221]
	TIME [epoch: 59 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: -0.008867838897254347		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: -0.008867838897254347 | validation: -0.005996491547169384]
	TIME [epoch: 58.9 sec]
	Saving model to: out/model_training/model_miniset1_v1_20240814_164134/states/model_miniset1_v1_520.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 6308.142 seconds.
