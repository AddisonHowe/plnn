Args:
Namespace(name='model_transition2_pcs123_v1', outdir='out/model_training/model_transition2_pcs123_v1', training_data='data/training_data/data_transition2_subset_ce_pn_m_pc123/training', validation_data='data/training_data/data_transition2_subset_ce_pn_m_pc123/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=3, nparams=3, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=False, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2529604118

Training model...

Saving initial model state to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.568021866163656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.568021866163656 | validation: 0.48259432711983435]
	TIME [epoch: 41.7 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.4490533721877123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4490533721877123 | validation: 0.4407288856533892]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.41321290585279946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41321290585279946 | validation: 0.3976511266592698]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.43176136082302125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43176136082302125 | validation: 0.4140753494453451]
	TIME [epoch: 26.1 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.4086708848802365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4086708848802365 | validation: 0.38784605673735545]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.3913401357381662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3913401357381662 | validation: 0.37393066077777337]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.38145566168511114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38145566168511114 | validation: 0.35549567451802416]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.3621123389476128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3621123389476128 | validation: 0.3728204606707275]
	TIME [epoch: 26.1 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.36974275039824167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36974275039824167 | validation: 0.32908364924052874]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.35361380940992715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35361380940992715 | validation: 0.326418787342276]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.3405064355535797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3405064355535797 | validation: 0.3008263560016514]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.3470696890051829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3470696890051829 | validation: 0.3656150582422221]
	TIME [epoch: 26.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.32752259599975625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32752259599975625 | validation: 0.30113121060840925]
	TIME [epoch: 26.1 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.3074825414162394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3074825414162394 | validation: 0.3209280868115689]
	TIME [epoch: 26.1 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2924754790139711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2924754790139711 | validation: 0.2516034881821268]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2804672769179863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2804672769179863 | validation: 0.2787849006852874]
	TIME [epoch: 26.1 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2861173577464357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2861173577464357 | validation: 0.2639875723620082]
	TIME [epoch: 26.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.27601975938727963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27601975938727963 | validation: 0.25791630909014984]
	TIME [epoch: 26.1 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.26941456526416346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26941456526416346 | validation: 0.28869739913722364]
	TIME [epoch: 26.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.269429701032827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.269429701032827 | validation: 0.24072906843107097]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2518500760959653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2518500760959653 | validation: 0.2506321217920623]
	TIME [epoch: 26.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.268681262483896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.268681262483896 | validation: 0.25974583498353115]
	TIME [epoch: 26.1 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.24782104641787414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24782104641787414 | validation: 0.24375825182504646]
	TIME [epoch: 26.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2592759422679992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2592759422679992 | validation: 0.24979428757927533]
	TIME [epoch: 26.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2417826459087038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2417826459087038 | validation: 0.25891629740668076]
	TIME [epoch: 26.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.24478420306694573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24478420306694573 | validation: 0.3620111114888198]
	TIME [epoch: 26.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2732161846991004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2732161846991004 | validation: 0.23378918719796415]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.25614238130333605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25614238130333605 | validation: 0.25826987532093915]
	TIME [epoch: 26.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.26591242840098067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26591242840098067 | validation: 0.2675758206512522]
	TIME [epoch: 26.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2531992902348499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2531992902348499 | validation: 0.2410651614716275]
	TIME [epoch: 26.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2461006385020972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2461006385020972 | validation: 0.2736170749952884]
	TIME [epoch: 26.1 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23918926466254867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23918926466254867 | validation: 0.23725916288960675]
	TIME [epoch: 26.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.24397123561348202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24397123561348202 | validation: 0.23035367013664843]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.248974001242744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.248974001242744 | validation: 0.22796538694249047]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23091988807107394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23091988807107394 | validation: 0.23785238758046542]
	TIME [epoch: 26.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23464570402457127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23464570402457127 | validation: 0.2385159492673039]
	TIME [epoch: 26.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2436492063111311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2436492063111311 | validation: 0.24080379311158373]
	TIME [epoch: 26.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2515831823009657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2515831823009657 | validation: 0.2461116270758391]
	TIME [epoch: 26.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2343861214480613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2343861214480613 | validation: 0.23933228156995578]
	TIME [epoch: 26.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.237642953132627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.237642953132627 | validation: 0.23579394348332688]
	TIME [epoch: 26.1 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.24287498850808933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24287498850808933 | validation: 0.22475587893470905]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2250454570457936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2250454570457936 | validation: 0.2632926971845269]
	TIME [epoch: 26.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2482866844304856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2482866844304856 | validation: 0.24347424306513307]
	TIME [epoch: 26.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2437260025465155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2437260025465155 | validation: 0.23126944342331354]
	TIME [epoch: 26.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2346876267803851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2346876267803851 | validation: 0.21667706823084132]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2430249179344996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2430249179344996 | validation: 0.24589616633640493]
	TIME [epoch: 26.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2446974192291155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2446974192291155 | validation: 0.24076792562909394]
	TIME [epoch: 26.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22520721704829644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22520721704829644 | validation: 0.2518717899337422]
	TIME [epoch: 26.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23364819864773376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23364819864773376 | validation: 0.29221011767752464]
	TIME [epoch: 26.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23457168229465494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23457168229465494 | validation: 0.23617741389278202]
	TIME [epoch: 26.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23425975908148214		[learning rate: 0.0099697]
	Learning Rate: 0.00996968
	LOSS [training: 0.23425975908148214 | validation: 0.22551752624625823]
	TIME [epoch: 26.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22749390698080943		[learning rate: 0.0099344]
	Learning Rate: 0.00993443
	LOSS [training: 0.22749390698080943 | validation: 0.23736695504916702]
	TIME [epoch: 26.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2300237836226091		[learning rate: 0.0098993]
	Learning Rate: 0.0098993
	LOSS [training: 0.2300237836226091 | validation: 0.22141498578585914]
	TIME [epoch: 26.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.23549773903705074		[learning rate: 0.0098643]
	Learning Rate: 0.00986429
	LOSS [training: 0.23549773903705074 | validation: 0.23266864086324476]
	TIME [epoch: 26.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22447364437543427		[learning rate: 0.0098294]
	Learning Rate: 0.00982941
	LOSS [training: 0.22447364437543427 | validation: 0.26284074706044475]
	TIME [epoch: 26.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22052999513809374		[learning rate: 0.0097947]
	Learning Rate: 0.00979465
	LOSS [training: 0.22052999513809374 | validation: 0.20500690479046746]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22952696352642477		[learning rate: 0.00976]
	Learning Rate: 0.00976002
	LOSS [training: 0.22952696352642477 | validation: 0.20880108903056613]
	TIME [epoch: 26.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21559146302757642		[learning rate: 0.0097255]
	Learning Rate: 0.0097255
	LOSS [training: 0.21559146302757642 | validation: 0.24297955422225478]
	TIME [epoch: 26.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22104393599433533		[learning rate: 0.0096911]
	Learning Rate: 0.00969111
	LOSS [training: 0.22104393599433533 | validation: 0.26998625231648804]
	TIME [epoch: 26.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21459101600971905		[learning rate: 0.0096568]
	Learning Rate: 0.00965684
	LOSS [training: 0.21459101600971905 | validation: 0.22757088718404395]
	TIME [epoch: 26.1 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2123069354390841		[learning rate: 0.0096227]
	Learning Rate: 0.00962269
	LOSS [training: 0.2123069354390841 | validation: 0.21774375672701074]
	TIME [epoch: 26.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20426816599762443		[learning rate: 0.0095887]
	Learning Rate: 0.00958867
	LOSS [training: 0.20426816599762443 | validation: 0.22102536148112584]
	TIME [epoch: 26.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2127889755918521		[learning rate: 0.0095548]
	Learning Rate: 0.00955476
	LOSS [training: 0.2127889755918521 | validation: 0.20238192059119559]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21587533848361704		[learning rate: 0.009521]
	Learning Rate: 0.00952097
	LOSS [training: 0.21587533848361704 | validation: 0.21973624388158966]
	TIME [epoch: 26.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21474634117931893		[learning rate: 0.0094873]
	Learning Rate: 0.0094873
	LOSS [training: 0.21474634117931893 | validation: 0.2217752631225274]
	TIME [epoch: 26.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19490426361926888		[learning rate: 0.0094538]
	Learning Rate: 0.00945376
	LOSS [training: 0.19490426361926888 | validation: 0.26350572561520313]
	TIME [epoch: 26.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22106714201073055		[learning rate: 0.0094203]
	Learning Rate: 0.00942033
	LOSS [training: 0.22106714201073055 | validation: 0.21961905075467045]
	TIME [epoch: 26.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20406346904516992		[learning rate: 0.009387]
	Learning Rate: 0.00938701
	LOSS [training: 0.20406346904516992 | validation: 0.21084458794937416]
	TIME [epoch: 26.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20273806167933373		[learning rate: 0.0093538]
	Learning Rate: 0.00935382
	LOSS [training: 0.20273806167933373 | validation: 0.23398652572372736]
	TIME [epoch: 26.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.22061937962968417		[learning rate: 0.0093207]
	Learning Rate: 0.00932074
	LOSS [training: 0.22061937962968417 | validation: 0.2122914176581208]
	TIME [epoch: 26.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21732860287893016		[learning rate: 0.0092878]
	Learning Rate: 0.00928778
	LOSS [training: 0.21732860287893016 | validation: 0.21239480791349724]
	TIME [epoch: 26.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20852373970256388		[learning rate: 0.0092549]
	Learning Rate: 0.00925494
	LOSS [training: 0.20852373970256388 | validation: 0.21803003605786192]
	TIME [epoch: 26.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20142950816024777		[learning rate: 0.0092222]
	Learning Rate: 0.00922221
	LOSS [training: 0.20142950816024777 | validation: 0.18716329845532673]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21331635714077443		[learning rate: 0.0091896]
	Learning Rate: 0.0091896
	LOSS [training: 0.21331635714077443 | validation: 0.198850455525185]
	TIME [epoch: 26.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2056322985707611		[learning rate: 0.0091571]
	Learning Rate: 0.00915711
	LOSS [training: 0.2056322985707611 | validation: 0.20820952029182685]
	TIME [epoch: 26.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20854523905666775		[learning rate: 0.0091247]
	Learning Rate: 0.00912473
	LOSS [training: 0.20854523905666775 | validation: 0.20777772018056767]
	TIME [epoch: 26.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20393428534892802		[learning rate: 0.0090925]
	Learning Rate: 0.00909246
	LOSS [training: 0.20393428534892802 | validation: 0.20317851142783516]
	TIME [epoch: 26.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20543384925365774		[learning rate: 0.0090603]
	Learning Rate: 0.00906031
	LOSS [training: 0.20543384925365774 | validation: 0.20416368239758723]
	TIME [epoch: 26.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20042709484228607		[learning rate: 0.0090283]
	Learning Rate: 0.00902827
	LOSS [training: 0.20042709484228607 | validation: 0.20335979412933436]
	TIME [epoch: 26.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20001973698284345		[learning rate: 0.0089963]
	Learning Rate: 0.00899634
	LOSS [training: 0.20001973698284345 | validation: 0.2105756665655643]
	TIME [epoch: 26.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19944693398523375		[learning rate: 0.0089645]
	Learning Rate: 0.00896453
	LOSS [training: 0.19944693398523375 | validation: 0.22145974399937002]
	TIME [epoch: 26.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19944476506474199		[learning rate: 0.0089328]
	Learning Rate: 0.00893283
	LOSS [training: 0.19944476506474199 | validation: 0.21153617762585067]
	TIME [epoch: 26.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19713562777325205		[learning rate: 0.0089012]
	Learning Rate: 0.00890124
	LOSS [training: 0.19713562777325205 | validation: 0.2051206921904043]
	TIME [epoch: 26.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.21622135494249672		[learning rate: 0.0088698]
	Learning Rate: 0.00886976
	LOSS [training: 0.21622135494249672 | validation: 0.2031914583995369]
	TIME [epoch: 26.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20825469687435152		[learning rate: 0.0088384]
	Learning Rate: 0.0088384
	LOSS [training: 0.20825469687435152 | validation: 0.19375381534899755]
	TIME [epoch: 26.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19210729631111703		[learning rate: 0.0088071]
	Learning Rate: 0.00880715
	LOSS [training: 0.19210729631111703 | validation: 0.22140721311560257]
	TIME [epoch: 26.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20432808861831653		[learning rate: 0.008776]
	Learning Rate: 0.008776
	LOSS [training: 0.20432808861831653 | validation: 0.20314509112912243]
	TIME [epoch: 26.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1970192432221863		[learning rate: 0.008745]
	Learning Rate: 0.00874497
	LOSS [training: 0.1970192432221863 | validation: 0.2207414431046027]
	TIME [epoch: 26.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19813270872989078		[learning rate: 0.008714]
	Learning Rate: 0.00871404
	LOSS [training: 0.19813270872989078 | validation: 0.21942728712424378]
	TIME [epoch: 26.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19864528301604575		[learning rate: 0.0086832]
	Learning Rate: 0.00868323
	LOSS [training: 0.19864528301604575 | validation: 0.22939368331690607]
	TIME [epoch: 26.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19912204646306983		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 0.19912204646306983 | validation: 0.1907049518833362]
	TIME [epoch: 26.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.194135579148811		[learning rate: 0.0086219]
	Learning Rate: 0.00862193
	LOSS [training: 0.194135579148811 | validation: 0.20119295476144813]
	TIME [epoch: 26.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1927676720133433		[learning rate: 0.0085914]
	Learning Rate: 0.00859144
	LOSS [training: 0.1927676720133433 | validation: 0.20418881741525174]
	TIME [epoch: 26.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19558674562772074		[learning rate: 0.0085611]
	Learning Rate: 0.00856106
	LOSS [training: 0.19558674562772074 | validation: 0.22083055954956549]
	TIME [epoch: 26.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20409961840999322		[learning rate: 0.0085308]
	Learning Rate: 0.00853078
	LOSS [training: 0.20409961840999322 | validation: 0.19299844331922678]
	TIME [epoch: 26.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19422713996328494		[learning rate: 0.0085006]
	Learning Rate: 0.00850062
	LOSS [training: 0.19422713996328494 | validation: 0.20854084139838697]
	TIME [epoch: 26.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20506722205158595		[learning rate: 0.0084706]
	Learning Rate: 0.00847056
	LOSS [training: 0.20506722205158595 | validation: 0.1927036327873896]
	TIME [epoch: 26.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1959443200544519		[learning rate: 0.0084406]
	Learning Rate: 0.00844061
	LOSS [training: 0.1959443200544519 | validation: 0.1931000452018841]
	TIME [epoch: 26.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18494295956929757		[learning rate: 0.0084108]
	Learning Rate: 0.00841076
	LOSS [training: 0.18494295956929757 | validation: 0.19791585288405164]
	TIME [epoch: 26.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20909218639521657		[learning rate: 0.008381]
	Learning Rate: 0.00838102
	LOSS [training: 0.20909218639521657 | validation: 0.20298410423701055]
	TIME [epoch: 26.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20332778008581767		[learning rate: 0.0083514]
	Learning Rate: 0.00835138
	LOSS [training: 0.20332778008581767 | validation: 0.18979123634489325]
	TIME [epoch: 26.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.190228043315478		[learning rate: 0.0083218]
	Learning Rate: 0.00832185
	LOSS [training: 0.190228043315478 | validation: 0.20077312961846283]
	TIME [epoch: 26.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18933832175051932		[learning rate: 0.0082924]
	Learning Rate: 0.00829242
	LOSS [training: 0.18933832175051932 | validation: 0.2054871247083098]
	TIME [epoch: 26.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19658173033732634		[learning rate: 0.0082631]
	Learning Rate: 0.0082631
	LOSS [training: 0.19658173033732634 | validation: 0.17994412315863234]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19007417991866873		[learning rate: 0.0082339]
	Learning Rate: 0.00823388
	LOSS [training: 0.19007417991866873 | validation: 0.19961153816567623]
	TIME [epoch: 26.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.20864654713291486		[learning rate: 0.0082048]
	Learning Rate: 0.00820476
	LOSS [training: 0.20864654713291486 | validation: 0.19151488517037885]
	TIME [epoch: 26.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18374424794377472		[learning rate: 0.0081757]
	Learning Rate: 0.00817575
	LOSS [training: 0.18374424794377472 | validation: 0.17935611033035176]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19780974223360773		[learning rate: 0.0081468]
	Learning Rate: 0.00814684
	LOSS [training: 0.19780974223360773 | validation: 0.18691546297255127]
	TIME [epoch: 26.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18671411772248897		[learning rate: 0.008118]
	Learning Rate: 0.00811803
	LOSS [training: 0.18671411772248897 | validation: 0.19552860167186745]
	TIME [epoch: 26.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.2090888145252243		[learning rate: 0.0080893]
	Learning Rate: 0.00808932
	LOSS [training: 0.2090888145252243 | validation: 0.19016820579846136]
	TIME [epoch: 26.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1999163294278355		[learning rate: 0.0080607]
	Learning Rate: 0.00806072
	LOSS [training: 0.1999163294278355 | validation: 0.20103176793333255]
	TIME [epoch: 26.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19187304563459848		[learning rate: 0.0080322]
	Learning Rate: 0.00803221
	LOSS [training: 0.19187304563459848 | validation: 0.18677015906906091]
	TIME [epoch: 26.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18840926945039865		[learning rate: 0.0080038]
	Learning Rate: 0.00800381
	LOSS [training: 0.18840926945039865 | validation: 0.2041218596120127]
	TIME [epoch: 26.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19063073268673408		[learning rate: 0.0079755]
	Learning Rate: 0.00797551
	LOSS [training: 0.19063073268673408 | validation: 0.19612397239027957]
	TIME [epoch: 26.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18557792784517124		[learning rate: 0.0079473]
	Learning Rate: 0.0079473
	LOSS [training: 0.18557792784517124 | validation: 0.18382291160314188]
	TIME [epoch: 26.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18853021401321554		[learning rate: 0.0079192]
	Learning Rate: 0.0079192
	LOSS [training: 0.18853021401321554 | validation: 0.1967558132473044]
	TIME [epoch: 26.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1882613490182072		[learning rate: 0.0078912]
	Learning Rate: 0.0078912
	LOSS [training: 0.1882613490182072 | validation: 0.17823529067749252]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18820045358066945		[learning rate: 0.0078633]
	Learning Rate: 0.00786329
	LOSS [training: 0.18820045358066945 | validation: 0.1901177569938503]
	TIME [epoch: 26.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18667056305027122		[learning rate: 0.0078355]
	Learning Rate: 0.00783549
	LOSS [training: 0.18667056305027122 | validation: 0.19623074601814666]
	TIME [epoch: 26.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19800937612229547		[learning rate: 0.0078078]
	Learning Rate: 0.00780778
	LOSS [training: 0.19800937612229547 | validation: 0.19805689766850026]
	TIME [epoch: 26.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18474411011593625		[learning rate: 0.0077802]
	Learning Rate: 0.00778017
	LOSS [training: 0.18474411011593625 | validation: 0.1947448427835407]
	TIME [epoch: 26.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19332312752863962		[learning rate: 0.0077527]
	Learning Rate: 0.00775266
	LOSS [training: 0.19332312752863962 | validation: 0.20511094094584498]
	TIME [epoch: 26.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.191938168608353		[learning rate: 0.0077252]
	Learning Rate: 0.00772524
	LOSS [training: 0.191938168608353 | validation: 0.1903060899742235]
	TIME [epoch: 26.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19039002376254202		[learning rate: 0.0076979]
	Learning Rate: 0.00769792
	LOSS [training: 0.19039002376254202 | validation: 0.18321797924972485]
	TIME [epoch: 26.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18328161441583024		[learning rate: 0.0076707]
	Learning Rate: 0.0076707
	LOSS [training: 0.18328161441583024 | validation: 0.19352434795310422]
	TIME [epoch: 26.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18882905509328038		[learning rate: 0.0076436]
	Learning Rate: 0.00764358
	LOSS [training: 0.18882905509328038 | validation: 0.19749487744506192]
	TIME [epoch: 26.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19900519465531152		[learning rate: 0.0076165]
	Learning Rate: 0.00761655
	LOSS [training: 0.19900519465531152 | validation: 0.19899062541327245]
	TIME [epoch: 26.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18924422644380498		[learning rate: 0.0075896]
	Learning Rate: 0.00758961
	LOSS [training: 0.18924422644380498 | validation: 0.1956560532584228]
	TIME [epoch: 26.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18601591718691876		[learning rate: 0.0075628]
	Learning Rate: 0.00756278
	LOSS [training: 0.18601591718691876 | validation: 0.19048353026428722]
	TIME [epoch: 26.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18763472214128954		[learning rate: 0.007536]
	Learning Rate: 0.00753603
	LOSS [training: 0.18763472214128954 | validation: 0.19383152322430824]
	TIME [epoch: 26.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18505468853638735		[learning rate: 0.0075094]
	Learning Rate: 0.00750939
	LOSS [training: 0.18505468853638735 | validation: 0.20229583619281977]
	TIME [epoch: 26.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18169392619705665		[learning rate: 0.0074828]
	Learning Rate: 0.00748283
	LOSS [training: 0.18169392619705665 | validation: 0.20864926574864048]
	TIME [epoch: 26.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1898477657105584		[learning rate: 0.0074564]
	Learning Rate: 0.00745637
	LOSS [training: 0.1898477657105584 | validation: 0.17897185229107884]
	TIME [epoch: 26.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18127704119007798		[learning rate: 0.00743]
	Learning Rate: 0.00743
	LOSS [training: 0.18127704119007798 | validation: 0.18244034189513447]
	TIME [epoch: 26.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1925497794331932		[learning rate: 0.0074037]
	Learning Rate: 0.00740373
	LOSS [training: 0.1925497794331932 | validation: 0.19271668717153626]
	TIME [epoch: 26.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19185163146307493		[learning rate: 0.0073775]
	Learning Rate: 0.00737755
	LOSS [training: 0.19185163146307493 | validation: 0.17605217426644545]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1843911768879615		[learning rate: 0.0073515]
	Learning Rate: 0.00735146
	LOSS [training: 0.1843911768879615 | validation: 0.18776125680743838]
	TIME [epoch: 26.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1833049220156681		[learning rate: 0.0073255]
	Learning Rate: 0.00732546
	LOSS [training: 0.1833049220156681 | validation: 0.19844159435751466]
	TIME [epoch: 26.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17444288684797518		[learning rate: 0.0072996]
	Learning Rate: 0.00729956
	LOSS [training: 0.17444288684797518 | validation: 0.19176955680685456]
	TIME [epoch: 26.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19329847180692086		[learning rate: 0.0072737]
	Learning Rate: 0.00727375
	LOSS [training: 0.19329847180692086 | validation: 0.19446478491778177]
	TIME [epoch: 26.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19687296523475548		[learning rate: 0.007248]
	Learning Rate: 0.00724803
	LOSS [training: 0.19687296523475548 | validation: 0.18942729011546297]
	TIME [epoch: 26.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1842943108273026		[learning rate: 0.0072224]
	Learning Rate: 0.0072224
	LOSS [training: 0.1842943108273026 | validation: 0.18386691110616427]
	TIME [epoch: 26.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18622497420711254		[learning rate: 0.0071969]
	Learning Rate: 0.00719686
	LOSS [training: 0.18622497420711254 | validation: 0.17800075527874779]
	TIME [epoch: 26.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17815357792093453		[learning rate: 0.0071714]
	Learning Rate: 0.00717141
	LOSS [training: 0.17815357792093453 | validation: 0.19313480434294586]
	TIME [epoch: 26.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18819482749004693		[learning rate: 0.007146]
	Learning Rate: 0.00714605
	LOSS [training: 0.18819482749004693 | validation: 0.18136156806519138]
	TIME [epoch: 26.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18363075542217594		[learning rate: 0.0071208]
	Learning Rate: 0.00712078
	LOSS [training: 0.18363075542217594 | validation: 0.2028001638078776]
	TIME [epoch: 26.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18427068099403193		[learning rate: 0.0070956]
	Learning Rate: 0.0070956
	LOSS [training: 0.18427068099403193 | validation: 0.1838377767667552]
	TIME [epoch: 26.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19142808578287923		[learning rate: 0.0070705]
	Learning Rate: 0.00707051
	LOSS [training: 0.19142808578287923 | validation: 0.19111762883817682]
	TIME [epoch: 26.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18390444683479892		[learning rate: 0.0070455]
	Learning Rate: 0.0070455
	LOSS [training: 0.18390444683479892 | validation: 0.18742063430265057]
	TIME [epoch: 26.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18456970653962626		[learning rate: 0.0070206]
	Learning Rate: 0.00702059
	LOSS [training: 0.18456970653962626 | validation: 0.1887939388107281]
	TIME [epoch: 26.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18712594408677025		[learning rate: 0.0069958]
	Learning Rate: 0.00699576
	LOSS [training: 0.18712594408677025 | validation: 0.18131361206593558]
	TIME [epoch: 26.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1806928004019892		[learning rate: 0.006971]
	Learning Rate: 0.00697103
	LOSS [training: 0.1806928004019892 | validation: 0.18745765625016397]
	TIME [epoch: 26.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17762471138204353		[learning rate: 0.0069464]
	Learning Rate: 0.00694637
	LOSS [training: 0.17762471138204353 | validation: 0.18722765623984827]
	TIME [epoch: 26.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18629233640610646		[learning rate: 0.0069218]
	Learning Rate: 0.00692181
	LOSS [training: 0.18629233640610646 | validation: 0.18857762096923836]
	TIME [epoch: 26.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1860550799897811		[learning rate: 0.0068973]
	Learning Rate: 0.00689733
	LOSS [training: 0.1860550799897811 | validation: 0.18416222986084285]
	TIME [epoch: 26.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1848212290432063		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 0.1848212290432063 | validation: 0.18700130328010678]
	TIME [epoch: 26.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19443615811358753		[learning rate: 0.0068486]
	Learning Rate: 0.00684864
	LOSS [training: 0.19443615811358753 | validation: 0.17758985348533657]
	TIME [epoch: 26.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18577088645505738		[learning rate: 0.0068244]
	Learning Rate: 0.00682442
	LOSS [training: 0.18577088645505738 | validation: 0.18853101038707887]
	TIME [epoch: 26.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17657782903530522		[learning rate: 0.0068003]
	Learning Rate: 0.00680029
	LOSS [training: 0.17657782903530522 | validation: 0.18146739091396163]
	TIME [epoch: 26.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1825988234882935		[learning rate: 0.0067762]
	Learning Rate: 0.00677624
	LOSS [training: 0.1825988234882935 | validation: 0.18150838564586372]
	TIME [epoch: 26.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18008698881659693		[learning rate: 0.0067523]
	Learning Rate: 0.00675228
	LOSS [training: 0.18008698881659693 | validation: 0.18246920743957062]
	TIME [epoch: 26.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17706522258548138		[learning rate: 0.0067284]
	Learning Rate: 0.0067284
	LOSS [training: 0.17706522258548138 | validation: 0.18649327625367096]
	TIME [epoch: 26.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18951764225468382		[learning rate: 0.0067046]
	Learning Rate: 0.00670461
	LOSS [training: 0.18951764225468382 | validation: 0.18980753518540522]
	TIME [epoch: 26.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18324287057620794		[learning rate: 0.0066809]
	Learning Rate: 0.0066809
	LOSS [training: 0.18324287057620794 | validation: 0.17801025325785125]
	TIME [epoch: 26.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17285816980658056		[learning rate: 0.0066573]
	Learning Rate: 0.00665728
	LOSS [training: 0.17285816980658056 | validation: 0.1792438096671404]
	TIME [epoch: 26.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18270206541927086		[learning rate: 0.0066337]
	Learning Rate: 0.00663374
	LOSS [training: 0.18270206541927086 | validation: 0.20736665412848412]
	TIME [epoch: 26.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18630432751777018		[learning rate: 0.0066103]
	Learning Rate: 0.00661028
	LOSS [training: 0.18630432751777018 | validation: 0.19912465958181758]
	TIME [epoch: 26.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18734608209557982		[learning rate: 0.0065869]
	Learning Rate: 0.0065869
	LOSS [training: 0.18734608209557982 | validation: 0.189509371275319]
	TIME [epoch: 26.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1893718352685662		[learning rate: 0.0065636]
	Learning Rate: 0.00656361
	LOSS [training: 0.1893718352685662 | validation: 0.19303854617543043]
	TIME [epoch: 26.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18813512049745132		[learning rate: 0.0065404]
	Learning Rate: 0.0065404
	LOSS [training: 0.18813512049745132 | validation: 0.19736669077983887]
	TIME [epoch: 26.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17972577203733137		[learning rate: 0.0065173]
	Learning Rate: 0.00651727
	LOSS [training: 0.17972577203733137 | validation: 0.17611263623656337]
	TIME [epoch: 26.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17235146551902947		[learning rate: 0.0064942]
	Learning Rate: 0.00649423
	LOSS [training: 0.17235146551902947 | validation: 0.18603341001055335]
	TIME [epoch: 26.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17305843299188117		[learning rate: 0.0064713]
	Learning Rate: 0.00647126
	LOSS [training: 0.17305843299188117 | validation: 0.19107603365544207]
	TIME [epoch: 26.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18264584931736846		[learning rate: 0.0064484]
	Learning Rate: 0.00644838
	LOSS [training: 0.18264584931736846 | validation: 0.1814801143407513]
	TIME [epoch: 26.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18713094449738074		[learning rate: 0.0064256]
	Learning Rate: 0.00642558
	LOSS [training: 0.18713094449738074 | validation: 0.18300224827092904]
	TIME [epoch: 26.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1870446096753752		[learning rate: 0.0064029]
	Learning Rate: 0.00640285
	LOSS [training: 0.1870446096753752 | validation: 0.20794220709385736]
	TIME [epoch: 26.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1811471908288776		[learning rate: 0.0063802]
	Learning Rate: 0.00638021
	LOSS [training: 0.1811471908288776 | validation: 0.18051880827938435]
	TIME [epoch: 26.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1809461354845061		[learning rate: 0.0063577]
	Learning Rate: 0.00635765
	LOSS [training: 0.1809461354845061 | validation: 0.1792505768253165]
	TIME [epoch: 26.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18229721777248883		[learning rate: 0.0063352]
	Learning Rate: 0.00633517
	LOSS [training: 0.18229721777248883 | validation: 0.19144102150687745]
	TIME [epoch: 26.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18487272435595653		[learning rate: 0.0063128]
	Learning Rate: 0.00631277
	LOSS [training: 0.18487272435595653 | validation: 0.18271776202062556]
	TIME [epoch: 26.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18722000270956513		[learning rate: 0.0062904]
	Learning Rate: 0.00629044
	LOSS [training: 0.18722000270956513 | validation: 0.18281037361086788]
	TIME [epoch: 26.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.178159467800108		[learning rate: 0.0062682]
	Learning Rate: 0.0062682
	LOSS [training: 0.178159467800108 | validation: 0.1739583600248829]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17620006865387947		[learning rate: 0.006246]
	Learning Rate: 0.00624603
	LOSS [training: 0.17620006865387947 | validation: 0.1856311994309267]
	TIME [epoch: 26.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18123888757062975		[learning rate: 0.0062239]
	Learning Rate: 0.00622395
	LOSS [training: 0.18123888757062975 | validation: 0.18255710649240448]
	TIME [epoch: 26.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1818961904188507		[learning rate: 0.0062019]
	Learning Rate: 0.00620194
	LOSS [training: 0.1818961904188507 | validation: 0.17562616603957493]
	TIME [epoch: 26.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1772676449970645		[learning rate: 0.00618]
	Learning Rate: 0.00618001
	LOSS [training: 0.1772676449970645 | validation: 0.17517919598503656]
	TIME [epoch: 26.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18464656029153154		[learning rate: 0.0061582]
	Learning Rate: 0.00615815
	LOSS [training: 0.18464656029153154 | validation: 0.19394705448634272]
	TIME [epoch: 26.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18757904775312628		[learning rate: 0.0061364]
	Learning Rate: 0.00613638
	LOSS [training: 0.18757904775312628 | validation: 0.16910691888746773]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18019690095011784		[learning rate: 0.0061147]
	Learning Rate: 0.00611468
	LOSS [training: 0.18019690095011784 | validation: 0.18050987380949832]
	TIME [epoch: 26.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18271137343261132		[learning rate: 0.0060931]
	Learning Rate: 0.00609306
	LOSS [training: 0.18271137343261132 | validation: 0.18207328221352112]
	TIME [epoch: 26.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.185624353825129		[learning rate: 0.0060715]
	Learning Rate: 0.00607151
	LOSS [training: 0.185624353825129 | validation: 0.18439074668603975]
	TIME [epoch: 26.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17786271558725322		[learning rate: 0.00605]
	Learning Rate: 0.00605004
	LOSS [training: 0.17786271558725322 | validation: 0.1778051802277615]
	TIME [epoch: 26.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17806023058534684		[learning rate: 0.0060286]
	Learning Rate: 0.00602865
	LOSS [training: 0.17806023058534684 | validation: 0.19218101614819366]
	TIME [epoch: 26.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18173176921638376		[learning rate: 0.0060073]
	Learning Rate: 0.00600733
	LOSS [training: 0.18173176921638376 | validation: 0.1782814279257667]
	TIME [epoch: 26.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18461662413271013		[learning rate: 0.0059861]
	Learning Rate: 0.00598608
	LOSS [training: 0.18461662413271013 | validation: 0.1773078339711793]
	TIME [epoch: 26.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17766389992306572		[learning rate: 0.0059649]
	Learning Rate: 0.00596492
	LOSS [training: 0.17766389992306572 | validation: 0.17679150160694768]
	TIME [epoch: 26.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17234890647965764		[learning rate: 0.0059438]
	Learning Rate: 0.00594382
	LOSS [training: 0.17234890647965764 | validation: 0.17856913240484668]
	TIME [epoch: 26.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.19436458948008956		[learning rate: 0.0059228]
	Learning Rate: 0.00592281
	LOSS [training: 0.19436458948008956 | validation: 0.18993253355872436]
	TIME [epoch: 26.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18217523531689142		[learning rate: 0.0059019]
	Learning Rate: 0.00590186
	LOSS [training: 0.18217523531689142 | validation: 0.1794578406941252]
	TIME [epoch: 26.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17671919939909636		[learning rate: 0.005881]
	Learning Rate: 0.00588099
	LOSS [training: 0.17671919939909636 | validation: 0.19449905334951004]
	TIME [epoch: 26.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18440387589014387		[learning rate: 0.0058602]
	Learning Rate: 0.00586019
	LOSS [training: 0.18440387589014387 | validation: 0.17861401246508554]
	TIME [epoch: 26.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18420423614451376		[learning rate: 0.0058395]
	Learning Rate: 0.00583947
	LOSS [training: 0.18420423614451376 | validation: 0.17963858327390808]
	TIME [epoch: 26.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17515600106683019		[learning rate: 0.0058188]
	Learning Rate: 0.00581882
	LOSS [training: 0.17515600106683019 | validation: 0.17998994784228178]
	TIME [epoch: 26.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17914668762386002		[learning rate: 0.0057982]
	Learning Rate: 0.00579825
	LOSS [training: 0.17914668762386002 | validation: 0.1721687981211722]
	TIME [epoch: 26.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17119151343257877		[learning rate: 0.0057777]
	Learning Rate: 0.00577774
	LOSS [training: 0.17119151343257877 | validation: 0.18433504875221576]
	TIME [epoch: 26.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18102233510264323		[learning rate: 0.0057573]
	Learning Rate: 0.00575731
	LOSS [training: 0.18102233510264323 | validation: 0.18039539663664372]
	TIME [epoch: 26.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1764647139987941		[learning rate: 0.005737]
	Learning Rate: 0.00573695
	LOSS [training: 0.1764647139987941 | validation: 0.173915398320152]
	TIME [epoch: 26.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17892519324033843		[learning rate: 0.0057167]
	Learning Rate: 0.00571667
	LOSS [training: 0.17892519324033843 | validation: 0.17594578639132027]
	TIME [epoch: 26.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17151530238684712		[learning rate: 0.0056965]
	Learning Rate: 0.00569645
	LOSS [training: 0.17151530238684712 | validation: 0.1844511876078379]
	TIME [epoch: 26.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17687067503249163		[learning rate: 0.0056763]
	Learning Rate: 0.00567631
	LOSS [training: 0.17687067503249163 | validation: 0.17949324867249217]
	TIME [epoch: 26.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18415583942896216		[learning rate: 0.0056562]
	Learning Rate: 0.00565623
	LOSS [training: 0.18415583942896216 | validation: 0.16901316511728356]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1729376490220769		[learning rate: 0.0056362]
	Learning Rate: 0.00563623
	LOSS [training: 0.1729376490220769 | validation: 0.18149929069473597]
	TIME [epoch: 26.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17751509895624937		[learning rate: 0.0056163]
	Learning Rate: 0.0056163
	LOSS [training: 0.17751509895624937 | validation: 0.1755540794798736]
	TIME [epoch: 26.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16826215784764179		[learning rate: 0.0055964]
	Learning Rate: 0.00559644
	LOSS [training: 0.16826215784764179 | validation: 0.1833586638239879]
	TIME [epoch: 26.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18394222922799153		[learning rate: 0.0055767]
	Learning Rate: 0.00557665
	LOSS [training: 0.18394222922799153 | validation: 0.17685589100199334]
	TIME [epoch: 26.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17889474995983476		[learning rate: 0.0055569]
	Learning Rate: 0.00555693
	LOSS [training: 0.17889474995983476 | validation: 0.17351973966342393]
	TIME [epoch: 26.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17827502810959941		[learning rate: 0.0055373]
	Learning Rate: 0.00553728
	LOSS [training: 0.17827502810959941 | validation: 0.17813147515247507]
	TIME [epoch: 26.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17578783688628793		[learning rate: 0.0055177]
	Learning Rate: 0.0055177
	LOSS [training: 0.17578783688628793 | validation: 0.18406256602740073]
	TIME [epoch: 26.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18187046901750187		[learning rate: 0.0054982]
	Learning Rate: 0.00549819
	LOSS [training: 0.18187046901750187 | validation: 0.1799560256045005]
	TIME [epoch: 26.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18032022378321858		[learning rate: 0.0054787]
	Learning Rate: 0.00547875
	LOSS [training: 0.18032022378321858 | validation: 0.17498079410891287]
	TIME [epoch: 26.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16722237389367814		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 0.16722237389367814 | validation: 0.1828888787874539]
	TIME [epoch: 26.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.175328951830986		[learning rate: 0.0054401]
	Learning Rate: 0.00544007
	LOSS [training: 0.175328951830986 | validation: 0.16952802596572464]
	TIME [epoch: 26.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1806763010590172		[learning rate: 0.0054208]
	Learning Rate: 0.00542083
	LOSS [training: 0.1806763010590172 | validation: 0.18000400311600756]
	TIME [epoch: 26.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1731841563975582		[learning rate: 0.0054017]
	Learning Rate: 0.00540166
	LOSS [training: 0.1731841563975582 | validation: 0.1840435591444315]
	TIME [epoch: 26.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16922571596446515		[learning rate: 0.0053826]
	Learning Rate: 0.00538256
	LOSS [training: 0.16922571596446515 | validation: 0.1897190529932031]
	TIME [epoch: 26.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18016674425706514		[learning rate: 0.0053635]
	Learning Rate: 0.00536353
	LOSS [training: 0.18016674425706514 | validation: 0.18194973472104833]
	TIME [epoch: 26.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17009867190755704		[learning rate: 0.0053446]
	Learning Rate: 0.00534456
	LOSS [training: 0.17009867190755704 | validation: 0.16944814574593287]
	TIME [epoch: 26.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1769532719067862		[learning rate: 0.0053257]
	Learning Rate: 0.00532566
	LOSS [training: 0.1769532719067862 | validation: 0.17865879491936307]
	TIME [epoch: 26.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17361395988361336		[learning rate: 0.0053068]
	Learning Rate: 0.00530683
	LOSS [training: 0.17361395988361336 | validation: 0.17957480271372323]
	TIME [epoch: 26.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17530876316933794		[learning rate: 0.0052881]
	Learning Rate: 0.00528806
	LOSS [training: 0.17530876316933794 | validation: 0.17851554981273615]
	TIME [epoch: 26.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18773119287839646		[learning rate: 0.0052694]
	Learning Rate: 0.00526936
	LOSS [training: 0.18773119287839646 | validation: 0.17444602885343316]
	TIME [epoch: 26.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1743276758324046		[learning rate: 0.0052507]
	Learning Rate: 0.00525073
	LOSS [training: 0.1743276758324046 | validation: 0.17705531574289016]
	TIME [epoch: 26.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16309879638914268		[learning rate: 0.0052322]
	Learning Rate: 0.00523216
	LOSS [training: 0.16309879638914268 | validation: 0.18148960011462764]
	TIME [epoch: 26.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17362209963740918		[learning rate: 0.0052137]
	Learning Rate: 0.00521366
	LOSS [training: 0.17362209963740918 | validation: 0.19461760684824153]
	TIME [epoch: 26.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1777024724511976		[learning rate: 0.0051952]
	Learning Rate: 0.00519523
	LOSS [training: 0.1777024724511976 | validation: 0.1775163014032248]
	TIME [epoch: 26.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1729772241805592		[learning rate: 0.0051769]
	Learning Rate: 0.00517685
	LOSS [training: 0.1729772241805592 | validation: 0.17910854940755552]
	TIME [epoch: 26.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17951221234573705		[learning rate: 0.0051585]
	Learning Rate: 0.00515855
	LOSS [training: 0.17951221234573705 | validation: 0.1689196276753578]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17813919606464895		[learning rate: 0.0051403]
	Learning Rate: 0.00514031
	LOSS [training: 0.17813919606464895 | validation: 0.17810279353619393]
	TIME [epoch: 26.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17217706425681303		[learning rate: 0.0051221]
	Learning Rate: 0.00512213
	LOSS [training: 0.17217706425681303 | validation: 0.17406754014757836]
	TIME [epoch: 26.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17330874942027577		[learning rate: 0.005104]
	Learning Rate: 0.00510402
	LOSS [training: 0.17330874942027577 | validation: 0.18434807571255743]
	TIME [epoch: 26.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1756333218409582		[learning rate: 0.005086]
	Learning Rate: 0.00508597
	LOSS [training: 0.1756333218409582 | validation: 0.16282876860805104]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17271088736509907		[learning rate: 0.005068]
	Learning Rate: 0.00506798
	LOSS [training: 0.17271088736509907 | validation: 0.1911967454995865]
	TIME [epoch: 26.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1765926464326799		[learning rate: 0.0050501]
	Learning Rate: 0.00505006
	LOSS [training: 0.1765926464326799 | validation: 0.1853886135802497]
	TIME [epoch: 26.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1700471797769727		[learning rate: 0.0050322]
	Learning Rate: 0.0050322
	LOSS [training: 0.1700471797769727 | validation: 0.163011429790039]
	TIME [epoch: 26.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1686712358243995		[learning rate: 0.0050144]
	Learning Rate: 0.00501441
	LOSS [training: 0.1686712358243995 | validation: 0.19601650991673555]
	TIME [epoch: 26.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18085337759210512		[learning rate: 0.0049967]
	Learning Rate: 0.00499668
	LOSS [training: 0.18085337759210512 | validation: 0.1752889364435832]
	TIME [epoch: 26.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17337647705926879		[learning rate: 0.004979]
	Learning Rate: 0.00497901
	LOSS [training: 0.17337647705926879 | validation: 0.17363399307545752]
	TIME [epoch: 26.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17891230283814788		[learning rate: 0.0049614]
	Learning Rate: 0.0049614
	LOSS [training: 0.17891230283814788 | validation: 0.1880517979473835]
	TIME [epoch: 26.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17715722280849372		[learning rate: 0.0049439]
	Learning Rate: 0.00494386
	LOSS [training: 0.17715722280849372 | validation: 0.18008143741876356]
	TIME [epoch: 26.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17276404661870784		[learning rate: 0.0049264]
	Learning Rate: 0.00492638
	LOSS [training: 0.17276404661870784 | validation: 0.17750134364719977]
	TIME [epoch: 26.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16841699737163188		[learning rate: 0.004909]
	Learning Rate: 0.00490895
	LOSS [training: 0.16841699737163188 | validation: 0.1729822367842432]
	TIME [epoch: 26.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16803226050971637		[learning rate: 0.0048916]
	Learning Rate: 0.0048916
	LOSS [training: 0.16803226050971637 | validation: 0.17712286337984295]
	TIME [epoch: 26.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17144438330823844		[learning rate: 0.0048743]
	Learning Rate: 0.0048743
	LOSS [training: 0.17144438330823844 | validation: 0.17445135886384158]
	TIME [epoch: 26.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1668287078220987		[learning rate: 0.0048571]
	Learning Rate: 0.00485706
	LOSS [training: 0.1668287078220987 | validation: 0.1746691386980101]
	TIME [epoch: 26.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17045475676854963		[learning rate: 0.0048399]
	Learning Rate: 0.00483989
	LOSS [training: 0.17045475676854963 | validation: 0.16947322963852987]
	TIME [epoch: 26.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18125284073712247		[learning rate: 0.0048228]
	Learning Rate: 0.00482277
	LOSS [training: 0.18125284073712247 | validation: 0.17484534769085427]
	TIME [epoch: 26.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17998150180585332		[learning rate: 0.0048057]
	Learning Rate: 0.00480572
	LOSS [training: 0.17998150180585332 | validation: 0.1760537217395809]
	TIME [epoch: 26.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17173298469326567		[learning rate: 0.0047887]
	Learning Rate: 0.00478872
	LOSS [training: 0.17173298469326567 | validation: 0.1780784641426571]
	TIME [epoch: 26.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17158826591821835		[learning rate: 0.0047718]
	Learning Rate: 0.00477179
	LOSS [training: 0.17158826591821835 | validation: 0.1739906852587723]
	TIME [epoch: 26.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1654521625842634		[learning rate: 0.0047549]
	Learning Rate: 0.00475492
	LOSS [training: 0.1654521625842634 | validation: 0.1693331220608702]
	TIME [epoch: 26.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1655815137837177		[learning rate: 0.0047381]
	Learning Rate: 0.0047381
	LOSS [training: 0.1655815137837177 | validation: 0.16311336400462645]
	TIME [epoch: 26.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17415324677610483		[learning rate: 0.0047213]
	Learning Rate: 0.00472135
	LOSS [training: 0.17415324677610483 | validation: 0.18951145894181395]
	TIME [epoch: 26.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1870783684126931		[learning rate: 0.0047047]
	Learning Rate: 0.00470465
	LOSS [training: 0.1870783684126931 | validation: 0.1852856304021399]
	TIME [epoch: 26.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17444487166706063		[learning rate: 0.004688]
	Learning Rate: 0.00468801
	LOSS [training: 0.17444487166706063 | validation: 0.17899830776446443]
	TIME [epoch: 26.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18427314359715605		[learning rate: 0.0046714]
	Learning Rate: 0.00467144
	LOSS [training: 0.18427314359715605 | validation: 0.17537379995131774]
	TIME [epoch: 26.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17325487690555472		[learning rate: 0.0046549]
	Learning Rate: 0.00465492
	LOSS [training: 0.17325487690555472 | validation: 0.17412043427587165]
	TIME [epoch: 26.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17632579437007095		[learning rate: 0.0046385]
	Learning Rate: 0.00463846
	LOSS [training: 0.17632579437007095 | validation: 0.1764280075400752]
	TIME [epoch: 26.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17485748217388516		[learning rate: 0.0046221]
	Learning Rate: 0.00462206
	LOSS [training: 0.17485748217388516 | validation: 0.16313596126539187]
	TIME [epoch: 26.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17084671387399797		[learning rate: 0.0046057]
	Learning Rate: 0.00460571
	LOSS [training: 0.17084671387399797 | validation: 0.17027938476120336]
	TIME [epoch: 26.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17449861214457035		[learning rate: 0.0045894]
	Learning Rate: 0.00458942
	LOSS [training: 0.17449861214457035 | validation: 0.17314521574064673]
	TIME [epoch: 26.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16860829634064614		[learning rate: 0.0045732]
	Learning Rate: 0.0045732
	LOSS [training: 0.16860829634064614 | validation: 0.17309890163292987]
	TIME [epoch: 26.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1640208219288038		[learning rate: 0.004557]
	Learning Rate: 0.00455702
	LOSS [training: 0.1640208219288038 | validation: 0.17024282878799205]
	TIME [epoch: 26.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17569794619939358		[learning rate: 0.0045409]
	Learning Rate: 0.00454091
	LOSS [training: 0.17569794619939358 | validation: 0.1825223866704229]
	TIME [epoch: 26.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17383097350800364		[learning rate: 0.0045249]
	Learning Rate: 0.00452485
	LOSS [training: 0.17383097350800364 | validation: 0.16721607573311825]
	TIME [epoch: 26.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17584246213955		[learning rate: 0.0045089]
	Learning Rate: 0.00450885
	LOSS [training: 0.17584246213955 | validation: 0.18094778542009715]
	TIME [epoch: 26.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16507664945813155		[learning rate: 0.0044929]
	Learning Rate: 0.00449291
	LOSS [training: 0.16507664945813155 | validation: 0.18512772430416352]
	TIME [epoch: 26.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17161116640449045		[learning rate: 0.004477]
	Learning Rate: 0.00447702
	LOSS [training: 0.17161116640449045 | validation: 0.17726516139480958]
	TIME [epoch: 26.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16918891148979118		[learning rate: 0.0044612]
	Learning Rate: 0.00446119
	LOSS [training: 0.16918891148979118 | validation: 0.17106642284017504]
	TIME [epoch: 26.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17195463465444488		[learning rate: 0.0044454]
	Learning Rate: 0.00444541
	LOSS [training: 0.17195463465444488 | validation: 0.18341933131591306]
	TIME [epoch: 26.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16468880863728022		[learning rate: 0.0044297]
	Learning Rate: 0.00442969
	LOSS [training: 0.16468880863728022 | validation: 0.16449507460502985]
	TIME [epoch: 26.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17037571196289103		[learning rate: 0.004414]
	Learning Rate: 0.00441403
	LOSS [training: 0.17037571196289103 | validation: 0.17390499132714843]
	TIME [epoch: 26.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.168863444324663		[learning rate: 0.0043984]
	Learning Rate: 0.00439842
	LOSS [training: 0.168863444324663 | validation: 0.17174704255515136]
	TIME [epoch: 26.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17015631525702185		[learning rate: 0.0043829]
	Learning Rate: 0.00438287
	LOSS [training: 0.17015631525702185 | validation: 0.16955122916240317]
	TIME [epoch: 26.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17407431810142354		[learning rate: 0.0043674]
	Learning Rate: 0.00436737
	LOSS [training: 0.17407431810142354 | validation: 0.17345269190690163]
	TIME [epoch: 26.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17071229611488997		[learning rate: 0.0043519]
	Learning Rate: 0.00435192
	LOSS [training: 0.17071229611488997 | validation: 0.17097240721419904]
	TIME [epoch: 26.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1691179283882614		[learning rate: 0.0043365]
	Learning Rate: 0.00433653
	LOSS [training: 0.1691179283882614 | validation: 0.17584265829377504]
	TIME [epoch: 26.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17030494841734983		[learning rate: 0.0043212]
	Learning Rate: 0.0043212
	LOSS [training: 0.17030494841734983 | validation: 0.17759126470539713]
	TIME [epoch: 26.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16532423865230625		[learning rate: 0.0043059]
	Learning Rate: 0.00430592
	LOSS [training: 0.16532423865230625 | validation: 0.17077248992578056]
	TIME [epoch: 26.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17140898598044263		[learning rate: 0.0042907]
	Learning Rate: 0.00429069
	LOSS [training: 0.17140898598044263 | validation: 0.17531580794366347]
	TIME [epoch: 26.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17210054362944477		[learning rate: 0.0042755]
	Learning Rate: 0.00427552
	LOSS [training: 0.17210054362944477 | validation: 0.16961102708624606]
	TIME [epoch: 26.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17242529871734677		[learning rate: 0.0042604]
	Learning Rate: 0.0042604
	LOSS [training: 0.17242529871734677 | validation: 0.17928713332619078]
	TIME [epoch: 26.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16791869267981643		[learning rate: 0.0042453]
	Learning Rate: 0.00424534
	LOSS [training: 0.16791869267981643 | validation: 0.16298945450956817]
	TIME [epoch: 26.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17322262161452348		[learning rate: 0.0042303]
	Learning Rate: 0.00423032
	LOSS [training: 0.17322262161452348 | validation: 0.1720497751998374]
	TIME [epoch: 26.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16886651788509618		[learning rate: 0.0042154]
	Learning Rate: 0.00421536
	LOSS [training: 0.16886651788509618 | validation: 0.1743164364842419]
	TIME [epoch: 26.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.167609160172104		[learning rate: 0.0042005]
	Learning Rate: 0.00420046
	LOSS [training: 0.167609160172104 | validation: 0.17200214754193566]
	TIME [epoch: 26.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.18034137257636026		[learning rate: 0.0041856]
	Learning Rate: 0.0041856
	LOSS [training: 0.18034137257636026 | validation: 0.1679854794935569]
	TIME [epoch: 26.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1736828251427657		[learning rate: 0.0041708]
	Learning Rate: 0.0041708
	LOSS [training: 0.1736828251427657 | validation: 0.1838394391541918]
	TIME [epoch: 26.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17245059543781108		[learning rate: 0.0041561]
	Learning Rate: 0.00415605
	LOSS [training: 0.17245059543781108 | validation: 0.1667087542796558]
	TIME [epoch: 26.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1717318812542838		[learning rate: 0.0041414]
	Learning Rate: 0.00414136
	LOSS [training: 0.1717318812542838 | validation: 0.1666537826083312]
	TIME [epoch: 26.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17735426665967924		[learning rate: 0.0041267]
	Learning Rate: 0.00412671
	LOSS [training: 0.17735426665967924 | validation: 0.1672063522891618]
	TIME [epoch: 26.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17063706009103935		[learning rate: 0.0041121]
	Learning Rate: 0.00411212
	LOSS [training: 0.17063706009103935 | validation: 0.17916747914197187]
	TIME [epoch: 26.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16896425771980247		[learning rate: 0.0040976]
	Learning Rate: 0.00409758
	LOSS [training: 0.16896425771980247 | validation: 0.17577632679177987]
	TIME [epoch: 26.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16689518249134		[learning rate: 0.0040831]
	Learning Rate: 0.00408309
	LOSS [training: 0.16689518249134 | validation: 0.19151285745180352]
	TIME [epoch: 26.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16956028341122442		[learning rate: 0.0040687]
	Learning Rate: 0.00406865
	LOSS [training: 0.16956028341122442 | validation: 0.1697296835181854]
	TIME [epoch: 26.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17219284695506093		[learning rate: 0.0040543]
	Learning Rate: 0.00405426
	LOSS [training: 0.17219284695506093 | validation: 0.17518137735829356]
	TIME [epoch: 26.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.176979623990336		[learning rate: 0.0040399]
	Learning Rate: 0.00403993
	LOSS [training: 0.176979623990336 | validation: 0.16701743746790523]
	TIME [epoch: 26.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17789842136940276		[learning rate: 0.0040256]
	Learning Rate: 0.00402564
	LOSS [training: 0.17789842136940276 | validation: 0.1650075395296925]
	TIME [epoch: 26.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16760467042208751		[learning rate: 0.0040114]
	Learning Rate: 0.00401141
	LOSS [training: 0.16760467042208751 | validation: 0.17311524625564215]
	TIME [epoch: 26.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1682578899797034		[learning rate: 0.0039972]
	Learning Rate: 0.00399722
	LOSS [training: 0.1682578899797034 | validation: 0.18283588973397122]
	TIME [epoch: 26.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15832601124282222		[learning rate: 0.0039831]
	Learning Rate: 0.00398309
	LOSS [training: 0.15832601124282222 | validation: 0.18519967571399276]
	TIME [epoch: 26.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16935864818752439		[learning rate: 0.003969]
	Learning Rate: 0.003969
	LOSS [training: 0.16935864818752439 | validation: 0.16470202765150793]
	TIME [epoch: 26.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17297551632285488		[learning rate: 0.003955]
	Learning Rate: 0.00395497
	LOSS [training: 0.17297551632285488 | validation: 0.16997134533897182]
	TIME [epoch: 26.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16842010629750867		[learning rate: 0.003941]
	Learning Rate: 0.00394098
	LOSS [training: 0.16842010629750867 | validation: 0.16045940135410855]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.164977275874302		[learning rate: 0.003927]
	Learning Rate: 0.00392705
	LOSS [training: 0.164977275874302 | validation: 0.17532353453132743]
	TIME [epoch: 26.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1716748221537607		[learning rate: 0.0039132]
	Learning Rate: 0.00391316
	LOSS [training: 0.1716748221537607 | validation: 0.17430102230664135]
	TIME [epoch: 26.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16293665480035674		[learning rate: 0.0038993]
	Learning Rate: 0.00389932
	LOSS [training: 0.16293665480035674 | validation: 0.17521789938618046]
	TIME [epoch: 26.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17044956404827596		[learning rate: 0.0038855]
	Learning Rate: 0.00388553
	LOSS [training: 0.17044956404827596 | validation: 0.17439610642485937]
	TIME [epoch: 26.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16877821578314514		[learning rate: 0.0038718]
	Learning Rate: 0.00387179
	LOSS [training: 0.16877821578314514 | validation: 0.16539442019076617]
	TIME [epoch: 26.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17442528310464575		[learning rate: 0.0038581]
	Learning Rate: 0.0038581
	LOSS [training: 0.17442528310464575 | validation: 0.17556482160802878]
	TIME [epoch: 26.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1646999009158757		[learning rate: 0.0038445]
	Learning Rate: 0.00384446
	LOSS [training: 0.1646999009158757 | validation: 0.17141444359596011]
	TIME [epoch: 26.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17016583490768664		[learning rate: 0.0038309]
	Learning Rate: 0.00383086
	LOSS [training: 0.17016583490768664 | validation: 0.17797214302156134]
	TIME [epoch: 26.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.170539667073024		[learning rate: 0.0038173]
	Learning Rate: 0.00381732
	LOSS [training: 0.170539667073024 | validation: 0.1773182610760735]
	TIME [epoch: 26.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16955011187201632		[learning rate: 0.0038038]
	Learning Rate: 0.00380382
	LOSS [training: 0.16955011187201632 | validation: 0.17378649613811836]
	TIME [epoch: 26.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17163469911586832		[learning rate: 0.0037904]
	Learning Rate: 0.00379037
	LOSS [training: 0.17163469911586832 | validation: 0.16006546485602124]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16794482177547707		[learning rate: 0.003777]
	Learning Rate: 0.00377696
	LOSS [training: 0.16794482177547707 | validation: 0.17005913997417496]
	TIME [epoch: 26.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16651590497040855		[learning rate: 0.0037636]
	Learning Rate: 0.00376361
	LOSS [training: 0.16651590497040855 | validation: 0.17834199472718731]
	TIME [epoch: 26.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17158779292086557		[learning rate: 0.0037503]
	Learning Rate: 0.0037503
	LOSS [training: 0.17158779292086557 | validation: 0.17973633513003773]
	TIME [epoch: 26.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1703955312650193		[learning rate: 0.003737]
	Learning Rate: 0.00373704
	LOSS [training: 0.1703955312650193 | validation: 0.16293677066693985]
	TIME [epoch: 26.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16847862641969855		[learning rate: 0.0037238]
	Learning Rate: 0.00372382
	LOSS [training: 0.16847862641969855 | validation: 0.16315524673329787]
	TIME [epoch: 26.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16234672778706474		[learning rate: 0.0037107]
	Learning Rate: 0.00371065
	LOSS [training: 0.16234672778706474 | validation: 0.1684590478616353]
	TIME [epoch: 26.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16675979392351856		[learning rate: 0.0036975]
	Learning Rate: 0.00369753
	LOSS [training: 0.16675979392351856 | validation: 0.17014649089515424]
	TIME [epoch: 26.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.170619800058493		[learning rate: 0.0036845]
	Learning Rate: 0.00368446
	LOSS [training: 0.170619800058493 | validation: 0.16375324546688017]
	TIME [epoch: 26.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16963049695153085		[learning rate: 0.0036714]
	Learning Rate: 0.00367143
	LOSS [training: 0.16963049695153085 | validation: 0.16737165709980628]
	TIME [epoch: 26.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16650865197660222		[learning rate: 0.0036584]
	Learning Rate: 0.00365845
	LOSS [training: 0.16650865197660222 | validation: 0.17039765295497078]
	TIME [epoch: 26.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16854067479872348		[learning rate: 0.0036455]
	Learning Rate: 0.00364551
	LOSS [training: 0.16854067479872348 | validation: 0.16917466934739184]
	TIME [epoch: 26.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16101497276588556		[learning rate: 0.0036326]
	Learning Rate: 0.00363262
	LOSS [training: 0.16101497276588556 | validation: 0.18061273825866928]
	TIME [epoch: 26.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1704608564364685		[learning rate: 0.0036198]
	Learning Rate: 0.00361977
	LOSS [training: 0.1704608564364685 | validation: 0.17034475072690178]
	TIME [epoch: 26.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16481772925181243		[learning rate: 0.003607]
	Learning Rate: 0.00360697
	LOSS [training: 0.16481772925181243 | validation: 0.17817085666882626]
	TIME [epoch: 26.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16253660264718878		[learning rate: 0.0035942]
	Learning Rate: 0.00359422
	LOSS [training: 0.16253660264718878 | validation: 0.16957005789820762]
	TIME [epoch: 26.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17069585973945234		[learning rate: 0.0035815]
	Learning Rate: 0.00358151
	LOSS [training: 0.17069585973945234 | validation: 0.1722142651213701]
	TIME [epoch: 26.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16753130951319592		[learning rate: 0.0035688]
	Learning Rate: 0.00356884
	LOSS [training: 0.16753130951319592 | validation: 0.16859424127922645]
	TIME [epoch: 26.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17638857576789044		[learning rate: 0.0035562]
	Learning Rate: 0.00355622
	LOSS [training: 0.17638857576789044 | validation: 0.1626330180295833]
	TIME [epoch: 26.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16696865606418893		[learning rate: 0.0035436]
	Learning Rate: 0.00354365
	LOSS [training: 0.16696865606418893 | validation: 0.16858245598226881]
	TIME [epoch: 26.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16239870710565382		[learning rate: 0.0035311]
	Learning Rate: 0.00353112
	LOSS [training: 0.16239870710565382 | validation: 0.1757256575071156]
	TIME [epoch: 26.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16161446004459484		[learning rate: 0.0035186]
	Learning Rate: 0.00351863
	LOSS [training: 0.16161446004459484 | validation: 0.16553014924920617]
	TIME [epoch: 26.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16643655688087006		[learning rate: 0.0035062]
	Learning Rate: 0.00350619
	LOSS [training: 0.16643655688087006 | validation: 0.1659899456848668]
	TIME [epoch: 26.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1609045369551721		[learning rate: 0.0034938]
	Learning Rate: 0.00349379
	LOSS [training: 0.1609045369551721 | validation: 0.16713006065929126]
	TIME [epoch: 26.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1708167398193571		[learning rate: 0.0034814]
	Learning Rate: 0.00348143
	LOSS [training: 0.1708167398193571 | validation: 0.16732902131794594]
	TIME [epoch: 26.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16581095728252432		[learning rate: 0.0034691]
	Learning Rate: 0.00346912
	LOSS [training: 0.16581095728252432 | validation: 0.17078740275873003]
	TIME [epoch: 26.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16513472313962874		[learning rate: 0.0034569]
	Learning Rate: 0.00345686
	LOSS [training: 0.16513472313962874 | validation: 0.17074974731894293]
	TIME [epoch: 26.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1726439704560723		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 0.1726439704560723 | validation: 0.17265575157520513]
	TIME [epoch: 26.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16627320254294403		[learning rate: 0.0034325]
	Learning Rate: 0.00343245
	LOSS [training: 0.16627320254294403 | validation: 0.169031967465276]
	TIME [epoch: 26.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16582385180327291		[learning rate: 0.0034203]
	Learning Rate: 0.00342031
	LOSS [training: 0.16582385180327291 | validation: 0.16966287888267675]
	TIME [epoch: 26.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17157809611287783		[learning rate: 0.0034082]
	Learning Rate: 0.00340822
	LOSS [training: 0.17157809611287783 | validation: 0.1671716832842795]
	TIME [epoch: 26.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16548206435611928		[learning rate: 0.0033962]
	Learning Rate: 0.00339617
	LOSS [training: 0.16548206435611928 | validation: 0.16561967642461764]
	TIME [epoch: 26.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1622592210878663		[learning rate: 0.0033842]
	Learning Rate: 0.00338416
	LOSS [training: 0.1622592210878663 | validation: 0.167081795490035]
	TIME [epoch: 26.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16772718440357565		[learning rate: 0.0033722]
	Learning Rate: 0.00337219
	LOSS [training: 0.16772718440357565 | validation: 0.16310605067052603]
	TIME [epoch: 26.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1625130586041649		[learning rate: 0.0033603]
	Learning Rate: 0.00336027
	LOSS [training: 0.1625130586041649 | validation: 0.16932216827000773]
	TIME [epoch: 26.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16271271853623004		[learning rate: 0.0033484]
	Learning Rate: 0.00334838
	LOSS [training: 0.16271271853623004 | validation: 0.1684622688101614]
	TIME [epoch: 26.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16172923463508845		[learning rate: 0.0033365]
	Learning Rate: 0.00333654
	LOSS [training: 0.16172923463508845 | validation: 0.15974101257839016]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16901330804023731		[learning rate: 0.0033247]
	Learning Rate: 0.00332474
	LOSS [training: 0.16901330804023731 | validation: 0.17023348159811116]
	TIME [epoch: 26.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16791028698411187		[learning rate: 0.003313]
	Learning Rate: 0.00331299
	LOSS [training: 0.16791028698411187 | validation: 0.17432228935246627]
	TIME [epoch: 26.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1624651691509999		[learning rate: 0.0033013]
	Learning Rate: 0.00330127
	LOSS [training: 0.1624651691509999 | validation: 0.15724049117333194]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17760292742422618		[learning rate: 0.0032896]
	Learning Rate: 0.0032896
	LOSS [training: 0.17760292742422618 | validation: 0.16692064153774913]
	TIME [epoch: 26.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1682998191548437		[learning rate: 0.003278]
	Learning Rate: 0.00327797
	LOSS [training: 0.1682998191548437 | validation: 0.16116570763907004]
	TIME [epoch: 26.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16328812093717238		[learning rate: 0.0032664]
	Learning Rate: 0.00326637
	LOSS [training: 0.16328812093717238 | validation: 0.17894432822266268]
	TIME [epoch: 26.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16667509692321786		[learning rate: 0.0032548]
	Learning Rate: 0.00325482
	LOSS [training: 0.16667509692321786 | validation: 0.1646546989557818]
	TIME [epoch: 26.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16329752643794218		[learning rate: 0.0032433]
	Learning Rate: 0.00324331
	LOSS [training: 0.16329752643794218 | validation: 0.15984465585039548]
	TIME [epoch: 26.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16960302210806108		[learning rate: 0.0032318]
	Learning Rate: 0.00323185
	LOSS [training: 0.16960302210806108 | validation: 0.16779197535001716]
	TIME [epoch: 26.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16508413778459582		[learning rate: 0.0032204]
	Learning Rate: 0.00322042
	LOSS [training: 0.16508413778459582 | validation: 0.16580102841859592]
	TIME [epoch: 26.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16487370636790197		[learning rate: 0.003209]
	Learning Rate: 0.00320903
	LOSS [training: 0.16487370636790197 | validation: 0.17615067689547456]
	TIME [epoch: 26.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16522371835991229		[learning rate: 0.0031977]
	Learning Rate: 0.00319768
	LOSS [training: 0.16522371835991229 | validation: 0.16986792314508847]
	TIME [epoch: 26.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16634055412559934		[learning rate: 0.0031864]
	Learning Rate: 0.00318637
	LOSS [training: 0.16634055412559934 | validation: 0.17219320836511953]
	TIME [epoch: 26.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16541968138684662		[learning rate: 0.0031751]
	Learning Rate: 0.00317511
	LOSS [training: 0.16541968138684662 | validation: 0.15970431191367987]
	TIME [epoch: 26.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1722849675943692		[learning rate: 0.0031639]
	Learning Rate: 0.00316388
	LOSS [training: 0.1722849675943692 | validation: 0.17045803041557023]
	TIME [epoch: 26.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16153203791462922		[learning rate: 0.0031527]
	Learning Rate: 0.00315269
	LOSS [training: 0.16153203791462922 | validation: 0.16932638246228238]
	TIME [epoch: 26.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16713523005291903		[learning rate: 0.0031415]
	Learning Rate: 0.00314154
	LOSS [training: 0.16713523005291903 | validation: 0.17821117748232485]
	TIME [epoch: 26.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16029941901566636		[learning rate: 0.0031304]
	Learning Rate: 0.00313043
	LOSS [training: 0.16029941901566636 | validation: 0.16978636427407687]
	TIME [epoch: 26.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16047676236354427		[learning rate: 0.0031194]
	Learning Rate: 0.00311936
	LOSS [training: 0.16047676236354427 | validation: 0.16797401633461306]
	TIME [epoch: 26.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16463086635522317		[learning rate: 0.0031083]
	Learning Rate: 0.00310833
	LOSS [training: 0.16463086635522317 | validation: 0.17661737429332008]
	TIME [epoch: 26.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16087938600496324		[learning rate: 0.0030973]
	Learning Rate: 0.00309734
	LOSS [training: 0.16087938600496324 | validation: 0.17559184651971377]
	TIME [epoch: 26.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16883189320285386		[learning rate: 0.0030864]
	Learning Rate: 0.00308639
	LOSS [training: 0.16883189320285386 | validation: 0.16862109378157242]
	TIME [epoch: 26.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1646940429603809		[learning rate: 0.0030755]
	Learning Rate: 0.00307547
	LOSS [training: 0.1646940429603809 | validation: 0.17348584041866222]
	TIME [epoch: 26.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15873443440722151		[learning rate: 0.0030646]
	Learning Rate: 0.0030646
	LOSS [training: 0.15873443440722151 | validation: 0.15978563546151042]
	TIME [epoch: 26.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1622212897709401		[learning rate: 0.0030538]
	Learning Rate: 0.00305376
	LOSS [training: 0.1622212897709401 | validation: 0.17350832719770318]
	TIME [epoch: 26.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16315245790056918		[learning rate: 0.003043]
	Learning Rate: 0.00304296
	LOSS [training: 0.16315245790056918 | validation: 0.1566653941816016]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16487062479457645		[learning rate: 0.0030322]
	Learning Rate: 0.0030322
	LOSS [training: 0.16487062479457645 | validation: 0.17495304644877097]
	TIME [epoch: 26.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.159851299804519		[learning rate: 0.0030215]
	Learning Rate: 0.00302148
	LOSS [training: 0.159851299804519 | validation: 0.16908332504831133]
	TIME [epoch: 26.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1643397168792226		[learning rate: 0.0030108]
	Learning Rate: 0.0030108
	LOSS [training: 0.1643397168792226 | validation: 0.15658474156677255]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1656162299715909		[learning rate: 0.0030001]
	Learning Rate: 0.00300015
	LOSS [training: 0.1656162299715909 | validation: 0.169791572633807]
	TIME [epoch: 26.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16456514672092595		[learning rate: 0.0029895]
	Learning Rate: 0.00298954
	LOSS [training: 0.16456514672092595 | validation: 0.16447320948638572]
	TIME [epoch: 26.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1670472903048888		[learning rate: 0.002979]
	Learning Rate: 0.00297897
	LOSS [training: 0.1670472903048888 | validation: 0.16149053223998697]
	TIME [epoch: 26.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15900597968008712		[learning rate: 0.0029684]
	Learning Rate: 0.00296843
	LOSS [training: 0.15900597968008712 | validation: 0.16715813648483058]
	TIME [epoch: 26.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1625874967521231		[learning rate: 0.0029579]
	Learning Rate: 0.00295794
	LOSS [training: 0.1625874967521231 | validation: 0.16559264730958817]
	TIME [epoch: 26.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1657690392279329		[learning rate: 0.0029475]
	Learning Rate: 0.00294748
	LOSS [training: 0.1657690392279329 | validation: 0.17164824829104308]
	TIME [epoch: 26.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16582204891690067		[learning rate: 0.0029371]
	Learning Rate: 0.00293706
	LOSS [training: 0.16582204891690067 | validation: 0.16851400291601393]
	TIME [epoch: 26.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16021403526244907		[learning rate: 0.0029267]
	Learning Rate: 0.00292667
	LOSS [training: 0.16021403526244907 | validation: 0.17336825369747227]
	TIME [epoch: 26.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15773162254867118		[learning rate: 0.0029163]
	Learning Rate: 0.00291632
	LOSS [training: 0.15773162254867118 | validation: 0.17145511601947688]
	TIME [epoch: 26.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16408589954973615		[learning rate: 0.002906]
	Learning Rate: 0.00290601
	LOSS [training: 0.16408589954973615 | validation: 0.1594382707263391]
	TIME [epoch: 26.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16587993607691803		[learning rate: 0.0028957]
	Learning Rate: 0.00289573
	LOSS [training: 0.16587993607691803 | validation: 0.16148581882419763]
	TIME [epoch: 26.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1533408424162317		[learning rate: 0.0028855]
	Learning Rate: 0.00288549
	LOSS [training: 0.1533408424162317 | validation: 0.16902787689308418]
	TIME [epoch: 26.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1563285805667736		[learning rate: 0.0028753]
	Learning Rate: 0.00287529
	LOSS [training: 0.1563285805667736 | validation: 0.17174770540611828]
	TIME [epoch: 26.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17067219512402482		[learning rate: 0.0028651]
	Learning Rate: 0.00286512
	LOSS [training: 0.17067219512402482 | validation: 0.17475614629092154]
	TIME [epoch: 26.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1627798186254987		[learning rate: 0.002855]
	Learning Rate: 0.00285499
	LOSS [training: 0.1627798186254987 | validation: 0.16538973530017065]
	TIME [epoch: 26.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16609482825771218		[learning rate: 0.0028449]
	Learning Rate: 0.00284489
	LOSS [training: 0.16609482825771218 | validation: 0.16578315921150977]
	TIME [epoch: 26.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16993062653542243		[learning rate: 0.0028348]
	Learning Rate: 0.00283483
	LOSS [training: 0.16993062653542243 | validation: 0.16198719038039938]
	TIME [epoch: 26.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.17139187417193233		[learning rate: 0.0028248]
	Learning Rate: 0.00282481
	LOSS [training: 0.17139187417193233 | validation: 0.17077719726683285]
	TIME [epoch: 26.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16979628342881972		[learning rate: 0.0028148]
	Learning Rate: 0.00281482
	LOSS [training: 0.16979628342881972 | validation: 0.1637565005171375]
	TIME [epoch: 26.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16759601266996077		[learning rate: 0.0028049]
	Learning Rate: 0.00280487
	LOSS [training: 0.16759601266996077 | validation: 0.16201888876021597]
	TIME [epoch: 26.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15946547263259933		[learning rate: 0.0027949]
	Learning Rate: 0.00279495
	LOSS [training: 0.15946547263259933 | validation: 0.16176316612971658]
	TIME [epoch: 26.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16509441536172903		[learning rate: 0.0027851]
	Learning Rate: 0.00278506
	LOSS [training: 0.16509441536172903 | validation: 0.16978298017897975]
	TIME [epoch: 26.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16021117936343285		[learning rate: 0.0027752]
	Learning Rate: 0.00277522
	LOSS [training: 0.16021117936343285 | validation: 0.16238695767938685]
	TIME [epoch: 26.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16755822543774007		[learning rate: 0.0027654]
	Learning Rate: 0.0027654
	LOSS [training: 0.16755822543774007 | validation: 0.1749934436020545]
	TIME [epoch: 26.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16300254320669474		[learning rate: 0.0027556]
	Learning Rate: 0.00275562
	LOSS [training: 0.16300254320669474 | validation: 0.16027886094585686]
	TIME [epoch: 26.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1637309567590682		[learning rate: 0.0027459]
	Learning Rate: 0.00274588
	LOSS [training: 0.1637309567590682 | validation: 0.15885622055078547]
	TIME [epoch: 26.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1649478935131536		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 0.1649478935131536 | validation: 0.1693664649650932]
	TIME [epoch: 26.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16858937115074582		[learning rate: 0.0027265]
	Learning Rate: 0.00272649
	LOSS [training: 0.16858937115074582 | validation: 0.16402645370924152]
	TIME [epoch: 26.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16443995710267473		[learning rate: 0.0027169]
	Learning Rate: 0.00271685
	LOSS [training: 0.16443995710267473 | validation: 0.16180680318880097]
	TIME [epoch: 26.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16669838405524975		[learning rate: 0.0027072]
	Learning Rate: 0.00270724
	LOSS [training: 0.16669838405524975 | validation: 0.1574644554421525]
	TIME [epoch: 26.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16296886954589831		[learning rate: 0.0026977]
	Learning Rate: 0.00269767
	LOSS [training: 0.16296886954589831 | validation: 0.17024654263253425]
	TIME [epoch: 26.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16604863285505336		[learning rate: 0.0026881]
	Learning Rate: 0.00268813
	LOSS [training: 0.16604863285505336 | validation: 0.1801972373587647]
	TIME [epoch: 26.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1665905294290875		[learning rate: 0.0026786]
	Learning Rate: 0.00267863
	LOSS [training: 0.1665905294290875 | validation: 0.16300418133773023]
	TIME [epoch: 26.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1668007054878857		[learning rate: 0.0026692]
	Learning Rate: 0.00266915
	LOSS [training: 0.1668007054878857 | validation: 0.16647346252995932]
	TIME [epoch: 26.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16900876512626367		[learning rate: 0.0026597]
	Learning Rate: 0.00265972
	LOSS [training: 0.16900876512626367 | validation: 0.1678208688693301]
	TIME [epoch: 26.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1602786537181935		[learning rate: 0.0026503]
	Learning Rate: 0.00265031
	LOSS [training: 0.1602786537181935 | validation: 0.16054345341212087]
	TIME [epoch: 26.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16046317734805754		[learning rate: 0.0026409]
	Learning Rate: 0.00264094
	LOSS [training: 0.16046317734805754 | validation: 0.1700923750667111]
	TIME [epoch: 26.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16140419105830262		[learning rate: 0.0026316]
	Learning Rate: 0.0026316
	LOSS [training: 0.16140419105830262 | validation: 0.16552172728364473]
	TIME [epoch: 26.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1626372143426456		[learning rate: 0.0026223]
	Learning Rate: 0.00262229
	LOSS [training: 0.1626372143426456 | validation: 0.16359392391318733]
	TIME [epoch: 26.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15854896339922328		[learning rate: 0.002613]
	Learning Rate: 0.00261302
	LOSS [training: 0.15854896339922328 | validation: 0.17231047406071304]
	TIME [epoch: 26.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16125295075308693		[learning rate: 0.0026038]
	Learning Rate: 0.00260378
	LOSS [training: 0.16125295075308693 | validation: 0.16842926519171855]
	TIME [epoch: 26.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1563868126975709		[learning rate: 0.0025946]
	Learning Rate: 0.00259457
	LOSS [training: 0.1563868126975709 | validation: 0.16626092766963604]
	TIME [epoch: 26.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16357891970177896		[learning rate: 0.0025854]
	Learning Rate: 0.0025854
	LOSS [training: 0.16357891970177896 | validation: 0.15784125973172614]
	TIME [epoch: 26.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15718005157677892		[learning rate: 0.0025763]
	Learning Rate: 0.00257626
	LOSS [training: 0.15718005157677892 | validation: 0.16484529264023434]
	TIME [epoch: 26.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1603366182238373		[learning rate: 0.0025671]
	Learning Rate: 0.00256715
	LOSS [training: 0.1603366182238373 | validation: 0.16815826478003934]
	TIME [epoch: 26.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15450318818548486		[learning rate: 0.0025581]
	Learning Rate: 0.00255807
	LOSS [training: 0.15450318818548486 | validation: 0.17427869402149654]
	TIME [epoch: 26.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1637823273108022		[learning rate: 0.002549]
	Learning Rate: 0.00254902
	LOSS [training: 0.1637823273108022 | validation: 0.15343537725466275]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16203015459273992		[learning rate: 0.00254]
	Learning Rate: 0.00254001
	LOSS [training: 0.16203015459273992 | validation: 0.16075362976422447]
	TIME [epoch: 26.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15788886521861478		[learning rate: 0.002531]
	Learning Rate: 0.00253103
	LOSS [training: 0.15788886521861478 | validation: 0.1766093407214226]
	TIME [epoch: 26.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15961580117960564		[learning rate: 0.0025221]
	Learning Rate: 0.00252208
	LOSS [training: 0.15961580117960564 | validation: 0.16818291616468983]
	TIME [epoch: 26.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16160025660665395		[learning rate: 0.0025132]
	Learning Rate: 0.00251316
	LOSS [training: 0.16160025660665395 | validation: 0.16662676474732202]
	TIME [epoch: 26.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1608885663414649		[learning rate: 0.0025043]
	Learning Rate: 0.00250427
	LOSS [training: 0.1608885663414649 | validation: 0.16433696037050072]
	TIME [epoch: 26.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16419996145056043		[learning rate: 0.0024954]
	Learning Rate: 0.00249542
	LOSS [training: 0.16419996145056043 | validation: 0.16481635283569684]
	TIME [epoch: 26.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16452195398901534		[learning rate: 0.0024866]
	Learning Rate: 0.00248659
	LOSS [training: 0.16452195398901534 | validation: 0.16508638538105244]
	TIME [epoch: 26.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16462378345899029		[learning rate: 0.0024778]
	Learning Rate: 0.0024778
	LOSS [training: 0.16462378345899029 | validation: 0.17361349908679832]
	TIME [epoch: 26.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15815710453273404		[learning rate: 0.002469]
	Learning Rate: 0.00246904
	LOSS [training: 0.15815710453273404 | validation: 0.16501986058808868]
	TIME [epoch: 26.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1512173133308674		[learning rate: 0.0024603]
	Learning Rate: 0.00246031
	LOSS [training: 0.1512173133308674 | validation: 0.16033460917476813]
	TIME [epoch: 26.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1561071973638398		[learning rate: 0.0024516]
	Learning Rate: 0.00245161
	LOSS [training: 0.1561071973638398 | validation: 0.17041921261779164]
	TIME [epoch: 26.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1596315643370742		[learning rate: 0.0024429]
	Learning Rate: 0.00244294
	LOSS [training: 0.1596315643370742 | validation: 0.15832044383976168]
	TIME [epoch: 26.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1599478126417732		[learning rate: 0.0024343]
	Learning Rate: 0.0024343
	LOSS [training: 0.1599478126417732 | validation: 0.16278207236695696]
	TIME [epoch: 26.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1661034461920064		[learning rate: 0.0024257]
	Learning Rate: 0.00242569
	LOSS [training: 0.1661034461920064 | validation: 0.1639265436706024]
	TIME [epoch: 26.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16266157884311264		[learning rate: 0.0024171]
	Learning Rate: 0.00241711
	LOSS [training: 0.16266157884311264 | validation: 0.16117105894100403]
	TIME [epoch: 26.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16361324283345263		[learning rate: 0.0024086]
	Learning Rate: 0.00240856
	LOSS [training: 0.16361324283345263 | validation: 0.16182577634361223]
	TIME [epoch: 26.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.161787733370477		[learning rate: 0.0024]
	Learning Rate: 0.00240005
	LOSS [training: 0.161787733370477 | validation: 0.16185762557896682]
	TIME [epoch: 26.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1578160389850669		[learning rate: 0.0023916]
	Learning Rate: 0.00239156
	LOSS [training: 0.1578160389850669 | validation: 0.16682259938241512]
	TIME [epoch: 26.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16816344640353717		[learning rate: 0.0023831]
	Learning Rate: 0.0023831
	LOSS [training: 0.16816344640353717 | validation: 0.161189732115577]
	TIME [epoch: 26.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15829693553898674		[learning rate: 0.0023747]
	Learning Rate: 0.00237468
	LOSS [training: 0.15829693553898674 | validation: 0.15670690287678643]
	TIME [epoch: 26.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1599143343138871		[learning rate: 0.0023663]
	Learning Rate: 0.00236628
	LOSS [training: 0.1599143343138871 | validation: 0.17404954027478026]
	TIME [epoch: 26.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16093848837416752		[learning rate: 0.0023579]
	Learning Rate: 0.00235791
	LOSS [training: 0.16093848837416752 | validation: 0.1601296022524003]
	TIME [epoch: 26.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1638802819084981		[learning rate: 0.0023496]
	Learning Rate: 0.00234957
	LOSS [training: 0.1638802819084981 | validation: 0.16927177913722719]
	TIME [epoch: 26.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1623815884673979		[learning rate: 0.0023413]
	Learning Rate: 0.00234126
	LOSS [training: 0.1623815884673979 | validation: 0.15881810174243557]
	TIME [epoch: 26.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16490552895822067		[learning rate: 0.002333]
	Learning Rate: 0.00233299
	LOSS [training: 0.16490552895822067 | validation: 0.16712556720782576]
	TIME [epoch: 26.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16074106269263672		[learning rate: 0.0023247]
	Learning Rate: 0.00232474
	LOSS [training: 0.16074106269263672 | validation: 0.1700829384169272]
	TIME [epoch: 26.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16392063922855374		[learning rate: 0.0023165]
	Learning Rate: 0.00231652
	LOSS [training: 0.16392063922855374 | validation: 0.17201470069294528]
	TIME [epoch: 26.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16657618925192286		[learning rate: 0.0023083]
	Learning Rate: 0.00230832
	LOSS [training: 0.16657618925192286 | validation: 0.1679683965316616]
	TIME [epoch: 26.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1517997633763224		[learning rate: 0.0023002]
	Learning Rate: 0.00230016
	LOSS [training: 0.1517997633763224 | validation: 0.1570019677187503]
	TIME [epoch: 26.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15800518231362187		[learning rate: 0.002292]
	Learning Rate: 0.00229203
	LOSS [training: 0.15800518231362187 | validation: 0.16191605832318373]
	TIME [epoch: 26.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15822901660687289		[learning rate: 0.0022839]
	Learning Rate: 0.00228392
	LOSS [training: 0.15822901660687289 | validation: 0.1591652759362688]
	TIME [epoch: 26.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1547344142550293		[learning rate: 0.0022758]
	Learning Rate: 0.00227585
	LOSS [training: 0.1547344142550293 | validation: 0.1585305450096413]
	TIME [epoch: 26.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15724452565290226		[learning rate: 0.0022678]
	Learning Rate: 0.0022678
	LOSS [training: 0.15724452565290226 | validation: 0.1518938152567052]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16157438231013366		[learning rate: 0.0022598]
	Learning Rate: 0.00225978
	LOSS [training: 0.16157438231013366 | validation: 0.1578252229261907]
	TIME [epoch: 26.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16364217671421402		[learning rate: 0.0022518]
	Learning Rate: 0.00225179
	LOSS [training: 0.16364217671421402 | validation: 0.1638545148748709]
	TIME [epoch: 26.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1616117755110336		[learning rate: 0.0022438]
	Learning Rate: 0.00224383
	LOSS [training: 0.1616117755110336 | validation: 0.1621854309960658]
	TIME [epoch: 26.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1657917685783388		[learning rate: 0.0022359]
	Learning Rate: 0.00223589
	LOSS [training: 0.1657917685783388 | validation: 0.16931795825822743]
	TIME [epoch: 26.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15969720821910743		[learning rate: 0.002228]
	Learning Rate: 0.00222798
	LOSS [training: 0.15969720821910743 | validation: 0.17070771030590007]
	TIME [epoch: 26.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1559838398361524		[learning rate: 0.0022201]
	Learning Rate: 0.00222011
	LOSS [training: 0.1559838398361524 | validation: 0.167047505457081]
	TIME [epoch: 26.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16377146755116903		[learning rate: 0.0022123]
	Learning Rate: 0.00221225
	LOSS [training: 0.16377146755116903 | validation: 0.16885678702887522]
	TIME [epoch: 26.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1550009292837136		[learning rate: 0.0022044]
	Learning Rate: 0.00220443
	LOSS [training: 0.1550009292837136 | validation: 0.16940894565848374]
	TIME [epoch: 26.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16452292339802238		[learning rate: 0.0021966]
	Learning Rate: 0.00219664
	LOSS [training: 0.16452292339802238 | validation: 0.16205297560934812]
	TIME [epoch: 26.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16960133470221275		[learning rate: 0.0021889]
	Learning Rate: 0.00218887
	LOSS [training: 0.16960133470221275 | validation: 0.15542081717518208]
	TIME [epoch: 26.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15715987461518796		[learning rate: 0.0021811]
	Learning Rate: 0.00218113
	LOSS [training: 0.15715987461518796 | validation: 0.15939303133103566]
	TIME [epoch: 26.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1607629881582097		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.1607629881582097 | validation: 0.16120517404439347]
	TIME [epoch: 26.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16216543443727574		[learning rate: 0.0021657]
	Learning Rate: 0.00216573
	LOSS [training: 0.16216543443727574 | validation: 0.1653105811938445]
	TIME [epoch: 26.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1591083994108981		[learning rate: 0.0021581]
	Learning Rate: 0.00215807
	LOSS [training: 0.1591083994108981 | validation: 0.16915984003007395]
	TIME [epoch: 26.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1567072008571376		[learning rate: 0.0021504]
	Learning Rate: 0.00215044
	LOSS [training: 0.1567072008571376 | validation: 0.1622032492521899]
	TIME [epoch: 26.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16621149673124552		[learning rate: 0.0021428]
	Learning Rate: 0.00214284
	LOSS [training: 0.16621149673124552 | validation: 0.16560992422559132]
	TIME [epoch: 26.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15790780405688826		[learning rate: 0.0021353]
	Learning Rate: 0.00213526
	LOSS [training: 0.15790780405688826 | validation: 0.1568298097286695]
	TIME [epoch: 26.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15871406049250897		[learning rate: 0.0021277]
	Learning Rate: 0.00212771
	LOSS [training: 0.15871406049250897 | validation: 0.15951923141609178]
	TIME [epoch: 26.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1550090831855729		[learning rate: 0.0021202]
	Learning Rate: 0.00212018
	LOSS [training: 0.1550090831855729 | validation: 0.1687914151331517]
	TIME [epoch: 26.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16329930848383498		[learning rate: 0.0021127]
	Learning Rate: 0.00211269
	LOSS [training: 0.16329930848383498 | validation: 0.1607798662433903]
	TIME [epoch: 26.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15690801408514313		[learning rate: 0.0021052]
	Learning Rate: 0.00210522
	LOSS [training: 0.15690801408514313 | validation: 0.1731831980569654]
	TIME [epoch: 26.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15561905475835772		[learning rate: 0.0020978]
	Learning Rate: 0.00209777
	LOSS [training: 0.15561905475835772 | validation: 0.1665094124514718]
	TIME [epoch: 26.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16362634687119168		[learning rate: 0.0020904]
	Learning Rate: 0.00209035
	LOSS [training: 0.16362634687119168 | validation: 0.1623372519610798]
	TIME [epoch: 26.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1621347494270515		[learning rate: 0.002083]
	Learning Rate: 0.00208296
	LOSS [training: 0.1621347494270515 | validation: 0.1580813841871486]
	TIME [epoch: 26.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16015702905741724		[learning rate: 0.0020756]
	Learning Rate: 0.0020756
	LOSS [training: 0.16015702905741724 | validation: 0.15688988277851734]
	TIME [epoch: 26.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1613917757354129		[learning rate: 0.0020683]
	Learning Rate: 0.00206826
	LOSS [training: 0.1613917757354129 | validation: 0.15859707307072918]
	TIME [epoch: 26.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15438198706357717		[learning rate: 0.0020609]
	Learning Rate: 0.00206094
	LOSS [training: 0.15438198706357717 | validation: 0.16264059115961338]
	TIME [epoch: 26.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16701657006603443		[learning rate: 0.0020537]
	Learning Rate: 0.00205365
	LOSS [training: 0.16701657006603443 | validation: 0.1581966596298835]
	TIME [epoch: 26.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16167218941645592		[learning rate: 0.0020464]
	Learning Rate: 0.00204639
	LOSS [training: 0.16167218941645592 | validation: 0.16649046010089624]
	TIME [epoch: 26.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15530299642579332		[learning rate: 0.0020392]
	Learning Rate: 0.00203916
	LOSS [training: 0.15530299642579332 | validation: 0.1609654285976773]
	TIME [epoch: 26.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16607314764225606		[learning rate: 0.0020319]
	Learning Rate: 0.00203195
	LOSS [training: 0.16607314764225606 | validation: 0.16450825677654846]
	TIME [epoch: 26.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15570969443066243		[learning rate: 0.0020248]
	Learning Rate: 0.00202476
	LOSS [training: 0.15570969443066243 | validation: 0.15859134127933117]
	TIME [epoch: 26.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15563199999107274		[learning rate: 0.0020176]
	Learning Rate: 0.0020176
	LOSS [training: 0.15563199999107274 | validation: 0.16341414617315975]
	TIME [epoch: 26.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1530270172538751		[learning rate: 0.0020105]
	Learning Rate: 0.00201047
	LOSS [training: 0.1530270172538751 | validation: 0.16251248996713236]
	TIME [epoch: 26.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16650959309846347		[learning rate: 0.0020034]
	Learning Rate: 0.00200336
	LOSS [training: 0.16650959309846347 | validation: 0.159028236780002]
	TIME [epoch: 26.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15652455203614707		[learning rate: 0.0019963]
	Learning Rate: 0.00199627
	LOSS [training: 0.15652455203614707 | validation: 0.16239326023378167]
	TIME [epoch: 26.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15602779258274654		[learning rate: 0.0019892]
	Learning Rate: 0.00198921
	LOSS [training: 0.15602779258274654 | validation: 0.15441622932469165]
	TIME [epoch: 26.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15501137298336023		[learning rate: 0.0019822]
	Learning Rate: 0.00198218
	LOSS [training: 0.15501137298336023 | validation: 0.15774804301620032]
	TIME [epoch: 26.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15888304860318758		[learning rate: 0.0019752]
	Learning Rate: 0.00197517
	LOSS [training: 0.15888304860318758 | validation: 0.15187121552498725]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16018156013676604		[learning rate: 0.0019682]
	Learning Rate: 0.00196819
	LOSS [training: 0.16018156013676604 | validation: 0.16284743025194834]
	TIME [epoch: 26.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15975383845134153		[learning rate: 0.0019612]
	Learning Rate: 0.00196123
	LOSS [training: 0.15975383845134153 | validation: 0.15956665214735022]
	TIME [epoch: 26.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16402868644725005		[learning rate: 0.0019543]
	Learning Rate: 0.00195429
	LOSS [training: 0.16402868644725005 | validation: 0.1635000178354988]
	TIME [epoch: 26.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16677668368043475		[learning rate: 0.0019474]
	Learning Rate: 0.00194738
	LOSS [training: 0.16677668368043475 | validation: 0.1555982849465201]
	TIME [epoch: 26.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15990319514064807		[learning rate: 0.0019405]
	Learning Rate: 0.00194049
	LOSS [training: 0.15990319514064807 | validation: 0.15956374897130257]
	TIME [epoch: 26.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1531283470181858		[learning rate: 0.0019336]
	Learning Rate: 0.00193363
	LOSS [training: 0.1531283470181858 | validation: 0.16172863567486268]
	TIME [epoch: 26.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1665250397219956		[learning rate: 0.0019268]
	Learning Rate: 0.00192679
	LOSS [training: 0.1665250397219956 | validation: 0.16196035607963943]
	TIME [epoch: 26.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1626394901280593		[learning rate: 0.00192]
	Learning Rate: 0.00191998
	LOSS [training: 0.1626394901280593 | validation: 0.16320844800609832]
	TIME [epoch: 26.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15394353720023965		[learning rate: 0.0019132]
	Learning Rate: 0.00191319
	LOSS [training: 0.15394353720023965 | validation: 0.15941368850889298]
	TIME [epoch: 26.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15841916937353412		[learning rate: 0.0019064]
	Learning Rate: 0.00190643
	LOSS [training: 0.15841916937353412 | validation: 0.1632933116674223]
	TIME [epoch: 26.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1580245287231214		[learning rate: 0.0018997]
	Learning Rate: 0.00189968
	LOSS [training: 0.1580245287231214 | validation: 0.1585491950537312]
	TIME [epoch: 26.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15640871217633406		[learning rate: 0.001893]
	Learning Rate: 0.00189297
	LOSS [training: 0.15640871217633406 | validation: 0.1514387274281171]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1518868576683244		[learning rate: 0.0018863]
	Learning Rate: 0.00188627
	LOSS [training: 0.1518868576683244 | validation: 0.16282607979916122]
	TIME [epoch: 26.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15448361481567421		[learning rate: 0.0018796]
	Learning Rate: 0.0018796
	LOSS [training: 0.15448361481567421 | validation: 0.15714496070672343]
	TIME [epoch: 26.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15260116208767743		[learning rate: 0.001873]
	Learning Rate: 0.00187296
	LOSS [training: 0.15260116208767743 | validation: 0.15430007697791645]
	TIME [epoch: 26.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16126828265140283		[learning rate: 0.0018663]
	Learning Rate: 0.00186633
	LOSS [training: 0.16126828265140283 | validation: 0.15940637558932544]
	TIME [epoch: 26.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15336988763990048		[learning rate: 0.0018597]
	Learning Rate: 0.00185973
	LOSS [training: 0.15336988763990048 | validation: 0.15932817285607712]
	TIME [epoch: 26.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15591146915650353		[learning rate: 0.0018532]
	Learning Rate: 0.00185316
	LOSS [training: 0.15591146915650353 | validation: 0.1536397830371324]
	TIME [epoch: 26.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15482420688721424		[learning rate: 0.0018466]
	Learning Rate: 0.0018466
	LOSS [training: 0.15482420688721424 | validation: 0.15010847204144878]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15456232938270392		[learning rate: 0.0018401]
	Learning Rate: 0.00184007
	LOSS [training: 0.15456232938270392 | validation: 0.16403728221079686]
	TIME [epoch: 26.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15651345545612552		[learning rate: 0.0018336]
	Learning Rate: 0.00183357
	LOSS [training: 0.15651345545612552 | validation: 0.1685886004621671]
	TIME [epoch: 26.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16086949521310429		[learning rate: 0.0018271]
	Learning Rate: 0.00182708
	LOSS [training: 0.16086949521310429 | validation: 0.16168508140996066]
	TIME [epoch: 26.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16301071271727535		[learning rate: 0.0018206]
	Learning Rate: 0.00182062
	LOSS [training: 0.16301071271727535 | validation: 0.1571889522042463]
	TIME [epoch: 26.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16256797626640626		[learning rate: 0.0018142]
	Learning Rate: 0.00181418
	LOSS [training: 0.16256797626640626 | validation: 0.16019944028213737]
	TIME [epoch: 26.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15668691780657903		[learning rate: 0.0018078]
	Learning Rate: 0.00180777
	LOSS [training: 0.15668691780657903 | validation: 0.14983011002093682]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1603500486261555		[learning rate: 0.0018014]
	Learning Rate: 0.00180138
	LOSS [training: 0.1603500486261555 | validation: 0.15830238035521912]
	TIME [epoch: 26.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15347889630391995		[learning rate: 0.001795]
	Learning Rate: 0.00179501
	LOSS [training: 0.15347889630391995 | validation: 0.1570988281134947]
	TIME [epoch: 26.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15743518902490292		[learning rate: 0.0017887]
	Learning Rate: 0.00178866
	LOSS [training: 0.15743518902490292 | validation: 0.16266951233545054]
	TIME [epoch: 26.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16413527619283128		[learning rate: 0.0017823]
	Learning Rate: 0.00178233
	LOSS [training: 0.16413527619283128 | validation: 0.15887452178549458]
	TIME [epoch: 26.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15825156833824217		[learning rate: 0.001776]
	Learning Rate: 0.00177603
	LOSS [training: 0.15825156833824217 | validation: 0.1574026292951266]
	TIME [epoch: 26.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15035960896244688		[learning rate: 0.0017698]
	Learning Rate: 0.00176975
	LOSS [training: 0.15035960896244688 | validation: 0.1515225046113835]
	TIME [epoch: 26.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15365620561871915		[learning rate: 0.0017635]
	Learning Rate: 0.00176349
	LOSS [training: 0.15365620561871915 | validation: 0.16146959125531585]
	TIME [epoch: 26.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16233703917910627		[learning rate: 0.0017573]
	Learning Rate: 0.00175726
	LOSS [training: 0.16233703917910627 | validation: 0.152866688572416]
	TIME [epoch: 26.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1634191063955079		[learning rate: 0.001751]
	Learning Rate: 0.00175104
	LOSS [training: 0.1634191063955079 | validation: 0.16809400225015025]
	TIME [epoch: 26.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15747811886564844		[learning rate: 0.0017449]
	Learning Rate: 0.00174485
	LOSS [training: 0.15747811886564844 | validation: 0.15342745274013692]
	TIME [epoch: 26.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15522070300614027		[learning rate: 0.0017387]
	Learning Rate: 0.00173868
	LOSS [training: 0.15522070300614027 | validation: 0.1634612240765335]
	TIME [epoch: 26.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15958819510890812		[learning rate: 0.0017325]
	Learning Rate: 0.00173253
	LOSS [training: 0.15958819510890812 | validation: 0.1642425054289609]
	TIME [epoch: 26.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15406510114986474		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.15406510114986474 | validation: 0.15530416585088302]
	TIME [epoch: 26.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15976045847274042		[learning rate: 0.0017203]
	Learning Rate: 0.0017203
	LOSS [training: 0.15976045847274042 | validation: 0.1580379782594046]
	TIME [epoch: 26.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15045753431435083		[learning rate: 0.0017142]
	Learning Rate: 0.00171422
	LOSS [training: 0.15045753431435083 | validation: 0.16810078322865715]
	TIME [epoch: 26.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1573851621973104		[learning rate: 0.0017082]
	Learning Rate: 0.00170816
	LOSS [training: 0.1573851621973104 | validation: 0.15415100308851787]
	TIME [epoch: 26.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15574459417502942		[learning rate: 0.0017021]
	Learning Rate: 0.00170212
	LOSS [training: 0.15574459417502942 | validation: 0.16455560087087684]
	TIME [epoch: 26.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15080536171322706		[learning rate: 0.0016961]
	Learning Rate: 0.0016961
	LOSS [training: 0.15080536171322706 | validation: 0.15982610235212172]
	TIME [epoch: 26.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15961281287392395		[learning rate: 0.0016901]
	Learning Rate: 0.0016901
	LOSS [training: 0.15961281287392395 | validation: 0.15991284004088124]
	TIME [epoch: 26.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1598550170726464		[learning rate: 0.0016841]
	Learning Rate: 0.00168412
	LOSS [training: 0.1598550170726464 | validation: 0.1571208580744175]
	TIME [epoch: 26.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1552196214222026		[learning rate: 0.0016782]
	Learning Rate: 0.00167817
	LOSS [training: 0.1552196214222026 | validation: 0.17120715795077204]
	TIME [epoch: 26.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15881243045552243		[learning rate: 0.0016722]
	Learning Rate: 0.00167223
	LOSS [training: 0.15881243045552243 | validation: 0.16028896881346616]
	TIME [epoch: 26.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15952420418357832		[learning rate: 0.0016663]
	Learning Rate: 0.00166632
	LOSS [training: 0.15952420418357832 | validation: 0.15801316758089082]
	TIME [epoch: 26.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15569603479293312		[learning rate: 0.0016604]
	Learning Rate: 0.00166043
	LOSS [training: 0.15569603479293312 | validation: 0.15900883573164679]
	TIME [epoch: 26.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1499648375176155		[learning rate: 0.0016546]
	Learning Rate: 0.00165456
	LOSS [training: 0.1499648375176155 | validation: 0.16009016344500035]
	TIME [epoch: 26.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15070040889088504		[learning rate: 0.0016487]
	Learning Rate: 0.0016487
	LOSS [training: 0.15070040889088504 | validation: 0.15519261893546987]
	TIME [epoch: 26.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15908185365883615		[learning rate: 0.0016429]
	Learning Rate: 0.00164287
	LOSS [training: 0.15908185365883615 | validation: 0.15930932175195833]
	TIME [epoch: 26.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14749687304660655		[learning rate: 0.0016371]
	Learning Rate: 0.00163706
	LOSS [training: 0.14749687304660655 | validation: 0.1563000077348875]
	TIME [epoch: 26.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1536749750310514		[learning rate: 0.0016313]
	Learning Rate: 0.00163128
	LOSS [training: 0.1536749750310514 | validation: 0.16119108282502476]
	TIME [epoch: 26.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.149415037417057		[learning rate: 0.0016255]
	Learning Rate: 0.00162551
	LOSS [training: 0.149415037417057 | validation: 0.1581515746988864]
	TIME [epoch: 26.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1532950383397718		[learning rate: 0.0016198]
	Learning Rate: 0.00161976
	LOSS [training: 0.1532950383397718 | validation: 0.16182759282718084]
	TIME [epoch: 26.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1546706577914004		[learning rate: 0.001614]
	Learning Rate: 0.00161403
	LOSS [training: 0.1546706577914004 | validation: 0.15921783924768154]
	TIME [epoch: 26.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15280166231192732		[learning rate: 0.0016083]
	Learning Rate: 0.00160832
	LOSS [training: 0.15280166231192732 | validation: 0.16067760172824663]
	TIME [epoch: 26.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15683050434208717		[learning rate: 0.0016026]
	Learning Rate: 0.00160264
	LOSS [training: 0.15683050434208717 | validation: 0.15399244762744665]
	TIME [epoch: 26.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15516929630112894		[learning rate: 0.001597]
	Learning Rate: 0.00159697
	LOSS [training: 0.15516929630112894 | validation: 0.1595088543428128]
	TIME [epoch: 26.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15367563987149113		[learning rate: 0.0015913]
	Learning Rate: 0.00159132
	LOSS [training: 0.15367563987149113 | validation: 0.16610097017625844]
	TIME [epoch: 26.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16098512855652766		[learning rate: 0.0015857]
	Learning Rate: 0.0015857
	LOSS [training: 0.16098512855652766 | validation: 0.15393131686191663]
	TIME [epoch: 26.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15579493089808552		[learning rate: 0.0015801]
	Learning Rate: 0.00158009
	LOSS [training: 0.15579493089808552 | validation: 0.14978361898595288]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1565727454889211		[learning rate: 0.0015745]
	Learning Rate: 0.0015745
	LOSS [training: 0.1565727454889211 | validation: 0.15404301399111697]
	TIME [epoch: 26.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15732232299521393		[learning rate: 0.0015689]
	Learning Rate: 0.00156893
	LOSS [training: 0.15732232299521393 | validation: 0.1608354312733808]
	TIME [epoch: 26.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15600785565287487		[learning rate: 0.0015634]
	Learning Rate: 0.00156338
	LOSS [training: 0.15600785565287487 | validation: 0.16129291884353536]
	TIME [epoch: 26.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15104293894147663		[learning rate: 0.0015579]
	Learning Rate: 0.00155786
	LOSS [training: 0.15104293894147663 | validation: 0.15489629644261757]
	TIME [epoch: 26.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1589969988793817		[learning rate: 0.0015523]
	Learning Rate: 0.00155235
	LOSS [training: 0.1589969988793817 | validation: 0.1551584639557804]
	TIME [epoch: 26.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1580762328900989		[learning rate: 0.0015469]
	Learning Rate: 0.00154686
	LOSS [training: 0.1580762328900989 | validation: 0.1574965683581681]
	TIME [epoch: 26.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15892044091004442		[learning rate: 0.0015414]
	Learning Rate: 0.00154139
	LOSS [training: 0.15892044091004442 | validation: 0.15870501744031207]
	TIME [epoch: 26.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15766788686072422		[learning rate: 0.0015359]
	Learning Rate: 0.00153594
	LOSS [training: 0.15766788686072422 | validation: 0.15067395430768]
	TIME [epoch: 26.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15150997555917928		[learning rate: 0.0015305]
	Learning Rate: 0.00153051
	LOSS [training: 0.15150997555917928 | validation: 0.16366200958274502]
	TIME [epoch: 26.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15976408195048084		[learning rate: 0.0015251]
	Learning Rate: 0.00152509
	LOSS [training: 0.15976408195048084 | validation: 0.15967926266190435]
	TIME [epoch: 26.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15396686915053895		[learning rate: 0.0015197]
	Learning Rate: 0.0015197
	LOSS [training: 0.15396686915053895 | validation: 0.14676951086600612]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16018804071507728		[learning rate: 0.0015143]
	Learning Rate: 0.00151433
	LOSS [training: 0.16018804071507728 | validation: 0.15663069180303468]
	TIME [epoch: 26.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15736822856592725		[learning rate: 0.001509]
	Learning Rate: 0.00150897
	LOSS [training: 0.15736822856592725 | validation: 0.15860768915397658]
	TIME [epoch: 26.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15515746765465874		[learning rate: 0.0015036]
	Learning Rate: 0.00150364
	LOSS [training: 0.15515746765465874 | validation: 0.1532899377024553]
	TIME [epoch: 26.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15834427042352317		[learning rate: 0.0014983]
	Learning Rate: 0.00149832
	LOSS [training: 0.15834427042352317 | validation: 0.15243012759775892]
	TIME [epoch: 26.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15244916911878317		[learning rate: 0.001493]
	Learning Rate: 0.00149302
	LOSS [training: 0.15244916911878317 | validation: 0.15073820456981046]
	TIME [epoch: 26.1 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15091985525750187		[learning rate: 0.0014877]
	Learning Rate: 0.00148774
	LOSS [training: 0.15091985525750187 | validation: 0.15902872673815296]
	TIME [epoch: 26.1 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1581523877830542		[learning rate: 0.0014825]
	Learning Rate: 0.00148248
	LOSS [training: 0.1581523877830542 | validation: 0.15749120612671702]
	TIME [epoch: 26.1 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15934420928187065		[learning rate: 0.0014772]
	Learning Rate: 0.00147724
	LOSS [training: 0.15934420928187065 | validation: 0.1558010337788984]
	TIME [epoch: 26.1 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15625689472859802		[learning rate: 0.001472]
	Learning Rate: 0.00147201
	LOSS [training: 0.15625689472859802 | validation: 0.15060056231588315]
	TIME [epoch: 26.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15284367458531406		[learning rate: 0.0014668]
	Learning Rate: 0.00146681
	LOSS [training: 0.15284367458531406 | validation: 0.1561617882301977]
	TIME [epoch: 26.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15382015562228532		[learning rate: 0.0014616]
	Learning Rate: 0.00146162
	LOSS [training: 0.15382015562228532 | validation: 0.1532828277024279]
	TIME [epoch: 26.1 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15593304274138817		[learning rate: 0.0014565]
	Learning Rate: 0.00145645
	LOSS [training: 0.15593304274138817 | validation: 0.1643474143670166]
	TIME [epoch: 26.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.155482565779599		[learning rate: 0.0014513]
	Learning Rate: 0.0014513
	LOSS [training: 0.155482565779599 | validation: 0.15171567469700736]
	TIME [epoch: 26.1 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16130272851043986		[learning rate: 0.0014462]
	Learning Rate: 0.00144617
	LOSS [training: 0.16130272851043986 | validation: 0.15736427985916296]
	TIME [epoch: 26.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16038562213583937		[learning rate: 0.0014411]
	Learning Rate: 0.00144106
	LOSS [training: 0.16038562213583937 | validation: 0.15690560566678777]
	TIME [epoch: 26.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1584046623940624		[learning rate: 0.001436]
	Learning Rate: 0.00143596
	LOSS [training: 0.1584046623940624 | validation: 0.1601985042835208]
	TIME [epoch: 26.1 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1561906760090396		[learning rate: 0.0014309]
	Learning Rate: 0.00143088
	LOSS [training: 0.1561906760090396 | validation: 0.16022620038636443]
	TIME [epoch: 26.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1566809685381805		[learning rate: 0.0014258]
	Learning Rate: 0.00142582
	LOSS [training: 0.1566809685381805 | validation: 0.1565121110026273]
	TIME [epoch: 26.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.157962458916147		[learning rate: 0.0014208]
	Learning Rate: 0.00142078
	LOSS [training: 0.157962458916147 | validation: 0.1453824220811702]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14977151201850375		[learning rate: 0.0014158]
	Learning Rate: 0.00141576
	LOSS [training: 0.14977151201850375 | validation: 0.15347964514631268]
	TIME [epoch: 26.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15093616346289393		[learning rate: 0.0014108]
	Learning Rate: 0.00141075
	LOSS [training: 0.15093616346289393 | validation: 0.1527100581838694]
	TIME [epoch: 26.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15733051717020752		[learning rate: 0.0014058]
	Learning Rate: 0.00140576
	LOSS [training: 0.15733051717020752 | validation: 0.1662602493101006]
	TIME [epoch: 26.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15322061678946883		[learning rate: 0.0014008]
	Learning Rate: 0.00140079
	LOSS [training: 0.15322061678946883 | validation: 0.15377033922389938]
	TIME [epoch: 26.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1504094454826696		[learning rate: 0.0013958]
	Learning Rate: 0.00139584
	LOSS [training: 0.1504094454826696 | validation: 0.15672718150273696]
	TIME [epoch: 26.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15952484819001692		[learning rate: 0.0013909]
	Learning Rate: 0.0013909
	LOSS [training: 0.15952484819001692 | validation: 0.14351102430557183]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_607.pth
	Model improved!!!
EPOCH 608/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1515878696989931		[learning rate: 0.001386]
	Learning Rate: 0.00138598
	LOSS [training: 0.1515878696989931 | validation: 0.15773299651701744]
	TIME [epoch: 26.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16379323364866938		[learning rate: 0.0013811]
	Learning Rate: 0.00138108
	LOSS [training: 0.16379323364866938 | validation: 0.1511491424114845]
	TIME [epoch: 26.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15614268690018854		[learning rate: 0.0013762]
	Learning Rate: 0.0013762
	LOSS [training: 0.15614268690018854 | validation: 0.15841751873861679]
	TIME [epoch: 26.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15580518942926486		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.15580518942926486 | validation: 0.15431783273730165]
	TIME [epoch: 26.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15340317960233577		[learning rate: 0.0013665]
	Learning Rate: 0.00136648
	LOSS [training: 0.15340317960233577 | validation: 0.1560699710716723]
	TIME [epoch: 26.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15153735175262711		[learning rate: 0.0013617]
	Learning Rate: 0.00136165
	LOSS [training: 0.15153735175262711 | validation: 0.14911798856870218]
	TIME [epoch: 26.1 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15713325696371308		[learning rate: 0.0013568]
	Learning Rate: 0.00135684
	LOSS [training: 0.15713325696371308 | validation: 0.15449074086574016]
	TIME [epoch: 26.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15284946614633382		[learning rate: 0.001352]
	Learning Rate: 0.00135204
	LOSS [training: 0.15284946614633382 | validation: 0.1555192497356308]
	TIME [epoch: 26.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15135805167030164		[learning rate: 0.0013473]
	Learning Rate: 0.00134726
	LOSS [training: 0.15135805167030164 | validation: 0.1566720810826514]
	TIME [epoch: 26.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14924874679337036		[learning rate: 0.0013425]
	Learning Rate: 0.00134249
	LOSS [training: 0.14924874679337036 | validation: 0.15657822059103602]
	TIME [epoch: 26.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15126390370310294		[learning rate: 0.0013377]
	Learning Rate: 0.00133775
	LOSS [training: 0.15126390370310294 | validation: 0.15309964656475072]
	TIME [epoch: 26.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15106193447491928		[learning rate: 0.001333]
	Learning Rate: 0.00133302
	LOSS [training: 0.15106193447491928 | validation: 0.1542816930721794]
	TIME [epoch: 26.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15561821508956544		[learning rate: 0.0013283]
	Learning Rate: 0.0013283
	LOSS [training: 0.15561821508956544 | validation: 0.15655511145254128]
	TIME [epoch: 26.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15600029200663149		[learning rate: 0.0013236]
	Learning Rate: 0.0013236
	LOSS [training: 0.15600029200663149 | validation: 0.15367120180358151]
	TIME [epoch: 26.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16001924126602726		[learning rate: 0.0013189]
	Learning Rate: 0.00131892
	LOSS [training: 0.16001924126602726 | validation: 0.1519587828995107]
	TIME [epoch: 26.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14939428818186645		[learning rate: 0.0013143]
	Learning Rate: 0.00131426
	LOSS [training: 0.14939428818186645 | validation: 0.161246052737055]
	TIME [epoch: 26.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15461224265981238		[learning rate: 0.0013096]
	Learning Rate: 0.00130961
	LOSS [training: 0.15461224265981238 | validation: 0.14700995020478588]
	TIME [epoch: 26.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15972019802907764		[learning rate: 0.001305]
	Learning Rate: 0.00130498
	LOSS [training: 0.15972019802907764 | validation: 0.1570810882598909]
	TIME [epoch: 26.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1571472397357039		[learning rate: 0.0013004]
	Learning Rate: 0.00130037
	LOSS [training: 0.1571472397357039 | validation: 0.15072113387460562]
	TIME [epoch: 26.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15342411635469833		[learning rate: 0.0012958]
	Learning Rate: 0.00129577
	LOSS [training: 0.15342411635469833 | validation: 0.1494555589666965]
	TIME [epoch: 26.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15136942112232998		[learning rate: 0.0012912]
	Learning Rate: 0.00129119
	LOSS [training: 0.15136942112232998 | validation: 0.15724999236210596]
	TIME [epoch: 26.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15419399446729898		[learning rate: 0.0012866]
	Learning Rate: 0.00128662
	LOSS [training: 0.15419399446729898 | validation: 0.16479450493452227]
	TIME [epoch: 26.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16345286552593533		[learning rate: 0.0012821]
	Learning Rate: 0.00128207
	LOSS [training: 0.16345286552593533 | validation: 0.1528060938410094]
	TIME [epoch: 26.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15507155499206413		[learning rate: 0.0012775]
	Learning Rate: 0.00127754
	LOSS [training: 0.15507155499206413 | validation: 0.15454502940799086]
	TIME [epoch: 26.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15434573681570324		[learning rate: 0.001273]
	Learning Rate: 0.00127302
	LOSS [training: 0.15434573681570324 | validation: 0.14811762846893256]
	TIME [epoch: 26.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15536785398830683		[learning rate: 0.0012685]
	Learning Rate: 0.00126852
	LOSS [training: 0.15536785398830683 | validation: 0.15755661927433576]
	TIME [epoch: 26.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15256860511536693		[learning rate: 0.001264]
	Learning Rate: 0.00126403
	LOSS [training: 0.15256860511536693 | validation: 0.15341553902327473]
	TIME [epoch: 26.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15291149908796278		[learning rate: 0.0012596]
	Learning Rate: 0.00125956
	LOSS [training: 0.15291149908796278 | validation: 0.1546733999135849]
	TIME [epoch: 26.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15016015435258917		[learning rate: 0.0012551]
	Learning Rate: 0.00125511
	LOSS [training: 0.15016015435258917 | validation: 0.1490330581300988]
	TIME [epoch: 26.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15938804239500107		[learning rate: 0.0012507]
	Learning Rate: 0.00125067
	LOSS [training: 0.15938804239500107 | validation: 0.15455113166088047]
	TIME [epoch: 26.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15566686621276005		[learning rate: 0.0012462]
	Learning Rate: 0.00124625
	LOSS [training: 0.15566686621276005 | validation: 0.15584064419360122]
	TIME [epoch: 26.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1557558297565386		[learning rate: 0.0012418]
	Learning Rate: 0.00124184
	LOSS [training: 0.1557558297565386 | validation: 0.16519093716112995]
	TIME [epoch: 26.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1523109318002709		[learning rate: 0.0012374]
	Learning Rate: 0.00123745
	LOSS [training: 0.1523109318002709 | validation: 0.16907154875449615]
	TIME [epoch: 26.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1565086837327517		[learning rate: 0.0012331]
	Learning Rate: 0.00123307
	LOSS [training: 0.1565086837327517 | validation: 0.14817470043837686]
	TIME [epoch: 26.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15369837543918835		[learning rate: 0.0012287]
	Learning Rate: 0.00122871
	LOSS [training: 0.15369837543918835 | validation: 0.15715410031330584]
	TIME [epoch: 26.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1602409131240685		[learning rate: 0.0012244]
	Learning Rate: 0.00122437
	LOSS [training: 0.1602409131240685 | validation: 0.15587376508635603]
	TIME [epoch: 26.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16337900658273427		[learning rate: 0.00122]
	Learning Rate: 0.00122004
	LOSS [training: 0.16337900658273427 | validation: 0.15866405221231894]
	TIME [epoch: 26.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15414548778614273		[learning rate: 0.0012157]
	Learning Rate: 0.00121572
	LOSS [training: 0.15414548778614273 | validation: 0.16110679402353545]
	TIME [epoch: 26.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15239833809918807		[learning rate: 0.0012114]
	Learning Rate: 0.00121143
	LOSS [training: 0.15239833809918807 | validation: 0.16413592099514607]
	TIME [epoch: 26.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16253259128290362		[learning rate: 0.0012071]
	Learning Rate: 0.00120714
	LOSS [training: 0.16253259128290362 | validation: 0.1526584103677052]
	TIME [epoch: 26.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14960508173880632		[learning rate: 0.0012029]
	Learning Rate: 0.00120287
	LOSS [training: 0.14960508173880632 | validation: 0.15821560407910354]
	TIME [epoch: 26.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15658557951201718		[learning rate: 0.0011986]
	Learning Rate: 0.00119862
	LOSS [training: 0.15658557951201718 | validation: 0.15822901636840525]
	TIME [epoch: 26.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15283324458687977		[learning rate: 0.0011944]
	Learning Rate: 0.00119438
	LOSS [training: 0.15283324458687977 | validation: 0.15611777949101313]
	TIME [epoch: 26.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1540086529316933		[learning rate: 0.0011902]
	Learning Rate: 0.00119016
	LOSS [training: 0.1540086529316933 | validation: 0.16064113890304993]
	TIME [epoch: 26.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1572584228836981		[learning rate: 0.0011859]
	Learning Rate: 0.00118595
	LOSS [training: 0.1572584228836981 | validation: 0.14997677119008193]
	TIME [epoch: 26.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1530631874415295		[learning rate: 0.0011818]
	Learning Rate: 0.00118175
	LOSS [training: 0.1530631874415295 | validation: 0.15945875145939928]
	TIME [epoch: 26.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15219037230595056		[learning rate: 0.0011776]
	Learning Rate: 0.00117758
	LOSS [training: 0.15219037230595056 | validation: 0.16374362602197456]
	TIME [epoch: 26.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14814856074871305		[learning rate: 0.0011734]
	Learning Rate: 0.00117341
	LOSS [training: 0.14814856074871305 | validation: 0.1523005375324018]
	TIME [epoch: 26.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15246191340442652		[learning rate: 0.0011693]
	Learning Rate: 0.00116926
	LOSS [training: 0.15246191340442652 | validation: 0.1558078065543594]
	TIME [epoch: 26.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15555989569409898		[learning rate: 0.0011651]
	Learning Rate: 0.00116513
	LOSS [training: 0.15555989569409898 | validation: 0.15119676493446643]
	TIME [epoch: 26.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1535284870917199		[learning rate: 0.001161]
	Learning Rate: 0.00116101
	LOSS [training: 0.1535284870917199 | validation: 0.15567677141305372]
	TIME [epoch: 26.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15408669226230348		[learning rate: 0.0011569]
	Learning Rate: 0.0011569
	LOSS [training: 0.15408669226230348 | validation: 0.1563161076522429]
	TIME [epoch: 26.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1555635445684567		[learning rate: 0.0011528]
	Learning Rate: 0.00115281
	LOSS [training: 0.1555635445684567 | validation: 0.15983387858746256]
	TIME [epoch: 26.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1534005757537075		[learning rate: 0.0011487]
	Learning Rate: 0.00114873
	LOSS [training: 0.1534005757537075 | validation: 0.1626004001888159]
	TIME [epoch: 26.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14692579247095008		[learning rate: 0.0011447]
	Learning Rate: 0.00114467
	LOSS [training: 0.14692579247095008 | validation: 0.1557238784591656]
	TIME [epoch: 26.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1573786738285529		[learning rate: 0.0011406]
	Learning Rate: 0.00114062
	LOSS [training: 0.1573786738285529 | validation: 0.16027421775379394]
	TIME [epoch: 26.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16059487269312392		[learning rate: 0.0011366]
	Learning Rate: 0.00113659
	LOSS [training: 0.16059487269312392 | validation: 0.1513437540342284]
	TIME [epoch: 26.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15533681494718427		[learning rate: 0.0011326]
	Learning Rate: 0.00113257
	LOSS [training: 0.15533681494718427 | validation: 0.1459913579038117]
	TIME [epoch: 26.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.147709342227424		[learning rate: 0.0011286]
	Learning Rate: 0.00112857
	LOSS [training: 0.147709342227424 | validation: 0.15122641759589625]
	TIME [epoch: 26.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15144381646097543		[learning rate: 0.0011246]
	Learning Rate: 0.00112458
	LOSS [training: 0.15144381646097543 | validation: 0.15946708791978367]
	TIME [epoch: 26.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15064569755000903		[learning rate: 0.0011206]
	Learning Rate: 0.0011206
	LOSS [training: 0.15064569755000903 | validation: 0.15983905989344344]
	TIME [epoch: 26.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1498493167340469		[learning rate: 0.0011166]
	Learning Rate: 0.00111664
	LOSS [training: 0.1498493167340469 | validation: 0.16252709648927982]
	TIME [epoch: 26.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1579332854219048		[learning rate: 0.0011127]
	Learning Rate: 0.00111269
	LOSS [training: 0.1579332854219048 | validation: 0.14206307927662967]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15888117067898455		[learning rate: 0.0011088]
	Learning Rate: 0.00110875
	LOSS [training: 0.15888117067898455 | validation: 0.1519844539731201]
	TIME [epoch: 26.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14905631301012914		[learning rate: 0.0011048]
	Learning Rate: 0.00110483
	LOSS [training: 0.14905631301012914 | validation: 0.15614170805272165]
	TIME [epoch: 26.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15455575030767266		[learning rate: 0.0011009]
	Learning Rate: 0.00110093
	LOSS [training: 0.15455575030767266 | validation: 0.15603810998483456]
	TIME [epoch: 26.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15122786467212346		[learning rate: 0.001097]
	Learning Rate: 0.00109703
	LOSS [training: 0.15122786467212346 | validation: 0.1531068435286121]
	TIME [epoch: 26.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1497376648671235		[learning rate: 0.0010932]
	Learning Rate: 0.00109315
	LOSS [training: 0.1497376648671235 | validation: 0.15178570976319233]
	TIME [epoch: 26.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15282982786730367		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.15282982786730367 | validation: 0.155132647476874]
	TIME [epoch: 26.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14481437219966528		[learning rate: 0.0010854]
	Learning Rate: 0.00108544
	LOSS [training: 0.14481437219966528 | validation: 0.15361512081768838]
	TIME [epoch: 26.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15309483942623592		[learning rate: 0.0010816]
	Learning Rate: 0.0010816
	LOSS [training: 0.15309483942623592 | validation: 0.14280757371746328]
	TIME [epoch: 26.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1535622639341108		[learning rate: 0.0010778]
	Learning Rate: 0.00107777
	LOSS [training: 0.1535622639341108 | validation: 0.15074994345154905]
	TIME [epoch: 26.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16214568947787056		[learning rate: 0.001074]
	Learning Rate: 0.00107396
	LOSS [training: 0.16214568947787056 | validation: 0.15361026078639842]
	TIME [epoch: 26.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15437916634494145		[learning rate: 0.0010702]
	Learning Rate: 0.00107016
	LOSS [training: 0.15437916634494145 | validation: 0.15244413454101252]
	TIME [epoch: 26.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14847105167907745		[learning rate: 0.0010664]
	Learning Rate: 0.00106638
	LOSS [training: 0.14847105167907745 | validation: 0.16172223285838686]
	TIME [epoch: 26.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15625219489406467		[learning rate: 0.0010626]
	Learning Rate: 0.00106261
	LOSS [training: 0.15625219489406467 | validation: 0.1516355756840088]
	TIME [epoch: 26.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14681889379007948		[learning rate: 0.0010589]
	Learning Rate: 0.00105885
	LOSS [training: 0.14681889379007948 | validation: 0.1575890379741979]
	TIME [epoch: 26.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14773375126582192		[learning rate: 0.0010551]
	Learning Rate: 0.00105511
	LOSS [training: 0.14773375126582192 | validation: 0.15607782451273502]
	TIME [epoch: 26.1 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1544941015295329		[learning rate: 0.0010514]
	Learning Rate: 0.00105138
	LOSS [training: 0.1544941015295329 | validation: 0.16206294652932926]
	TIME [epoch: 26.1 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15589491317457418		[learning rate: 0.0010477]
	Learning Rate: 0.00104766
	LOSS [training: 0.15589491317457418 | validation: 0.158873422186283]
	TIME [epoch: 26.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1569997509969312		[learning rate: 0.001044]
	Learning Rate: 0.00104395
	LOSS [training: 0.1569997509969312 | validation: 0.15683114093404957]
	TIME [epoch: 26.1 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15039942370845774		[learning rate: 0.0010403]
	Learning Rate: 0.00104026
	LOSS [training: 0.15039942370845774 | validation: 0.16328937427957885]
	TIME [epoch: 26.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15024913079724023		[learning rate: 0.0010366]
	Learning Rate: 0.00103658
	LOSS [training: 0.15024913079724023 | validation: 0.1494094101138011]
	TIME [epoch: 26.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14665662854934997		[learning rate: 0.0010329]
	Learning Rate: 0.00103292
	LOSS [training: 0.14665662854934997 | validation: 0.1450853050407756]
	TIME [epoch: 26.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15100288480317497		[learning rate: 0.0010293]
	Learning Rate: 0.00102927
	LOSS [training: 0.15100288480317497 | validation: 0.14861701253677675]
	TIME [epoch: 26.1 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15371615360373786		[learning rate: 0.0010256]
	Learning Rate: 0.00102563
	LOSS [training: 0.15371615360373786 | validation: 0.15680442583030008]
	TIME [epoch: 26.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15485811455588738		[learning rate: 0.001022]
	Learning Rate: 0.001022
	LOSS [training: 0.15485811455588738 | validation: 0.15546946187100763]
	TIME [epoch: 26.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14813502686846913		[learning rate: 0.0010184]
	Learning Rate: 0.00101839
	LOSS [training: 0.14813502686846913 | validation: 0.15758882928574475]
	TIME [epoch: 26.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15025657291002062		[learning rate: 0.0010148]
	Learning Rate: 0.00101478
	LOSS [training: 0.15025657291002062 | validation: 0.15851945441470697]
	TIME [epoch: 26.1 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15049291318415634		[learning rate: 0.0010112]
	Learning Rate: 0.0010112
	LOSS [training: 0.15049291318415634 | validation: 0.15955321813664883]
	TIME [epoch: 26.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1586155287585845		[learning rate: 0.0010076]
	Learning Rate: 0.00100762
	LOSS [training: 0.1586155287585845 | validation: 0.15566457659590027]
	TIME [epoch: 26.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15415295712030855		[learning rate: 0.0010041]
	Learning Rate: 0.00100406
	LOSS [training: 0.15415295712030855 | validation: 0.16461960822600982]
	TIME [epoch: 26.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14191820669044086		[learning rate: 0.0010005]
	Learning Rate: 0.00100051
	LOSS [training: 0.14191820669044086 | validation: 0.14623046248826788]
	TIME [epoch: 26.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14842226594692184		[learning rate: 0.00099697]
	Learning Rate: 0.000996968
	LOSS [training: 0.14842226594692184 | validation: 0.1506483315883476]
	TIME [epoch: 26.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15648035502731444		[learning rate: 0.00099344]
	Learning Rate: 0.000993443
	LOSS [training: 0.15648035502731444 | validation: 0.16006714963298294]
	TIME [epoch: 26.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.153549685283422		[learning rate: 0.00098993]
	Learning Rate: 0.00098993
	LOSS [training: 0.153549685283422 | validation: 0.14404291913319198]
	TIME [epoch: 26.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1578125772476712		[learning rate: 0.00098643]
	Learning Rate: 0.000986429
	LOSS [training: 0.1578125772476712 | validation: 0.1489698698338491]
	TIME [epoch: 26.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15321358016874603		[learning rate: 0.00098294]
	Learning Rate: 0.000982941
	LOSS [training: 0.15321358016874603 | validation: 0.1521848974364215]
	TIME [epoch: 26.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14953610119053978		[learning rate: 0.00097947]
	Learning Rate: 0.000979465
	LOSS [training: 0.14953610119053978 | validation: 0.1544432572741357]
	TIME [epoch: 26.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15184648708492426		[learning rate: 0.000976]
	Learning Rate: 0.000976002
	LOSS [training: 0.15184648708492426 | validation: 0.156892758858108]
	TIME [epoch: 26.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14819664262009685		[learning rate: 0.00097255]
	Learning Rate: 0.00097255
	LOSS [training: 0.14819664262009685 | validation: 0.151816802646458]
	TIME [epoch: 26.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14270016266406108		[learning rate: 0.00096911]
	Learning Rate: 0.000969111
	LOSS [training: 0.14270016266406108 | validation: 0.1546417455306618]
	TIME [epoch: 26.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14939318959546835		[learning rate: 0.00096568]
	Learning Rate: 0.000965684
	LOSS [training: 0.14939318959546835 | validation: 0.16658678963035034]
	TIME [epoch: 26.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1624578337624707		[learning rate: 0.00096227]
	Learning Rate: 0.000962269
	LOSS [training: 0.1624578337624707 | validation: 0.16022475543605946]
	TIME [epoch: 26.1 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14425672002042286		[learning rate: 0.00095887]
	Learning Rate: 0.000958867
	LOSS [training: 0.14425672002042286 | validation: 0.155475459875991]
	TIME [epoch: 26.1 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14886753628603458		[learning rate: 0.00095548]
	Learning Rate: 0.000955476
	LOSS [training: 0.14886753628603458 | validation: 0.1571484351725825]
	TIME [epoch: 26.1 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15939281516425755		[learning rate: 0.0009521]
	Learning Rate: 0.000952097
	LOSS [training: 0.15939281516425755 | validation: 0.14961377802046813]
	TIME [epoch: 26.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15013837196875654		[learning rate: 0.00094873]
	Learning Rate: 0.00094873
	LOSS [training: 0.15013837196875654 | validation: 0.15024922173568334]
	TIME [epoch: 26.1 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1521777272072156		[learning rate: 0.00094538]
	Learning Rate: 0.000945376
	LOSS [training: 0.1521777272072156 | validation: 0.15167327900838626]
	TIME [epoch: 26.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15637559320359326		[learning rate: 0.00094203]
	Learning Rate: 0.000942032
	LOSS [training: 0.15637559320359326 | validation: 0.14804114258688145]
	TIME [epoch: 26.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1457895916264355		[learning rate: 0.0009387]
	Learning Rate: 0.000938701
	LOSS [training: 0.1457895916264355 | validation: 0.1611705285067847]
	TIME [epoch: 26.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1517960755180952		[learning rate: 0.00093538]
	Learning Rate: 0.000935382
	LOSS [training: 0.1517960755180952 | validation: 0.15515449699209463]
	TIME [epoch: 26.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15243886800073245		[learning rate: 0.00093207]
	Learning Rate: 0.000932074
	LOSS [training: 0.15243886800073245 | validation: 0.15584604393769397]
	TIME [epoch: 26.1 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14663029163574032		[learning rate: 0.00092878]
	Learning Rate: 0.000928778
	LOSS [training: 0.14663029163574032 | validation: 0.15654575221172648]
	TIME [epoch: 26.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14657141521110365		[learning rate: 0.00092549]
	Learning Rate: 0.000925494
	LOSS [training: 0.14657141521110365 | validation: 0.15564727745227122]
	TIME [epoch: 26.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15002543156724443		[learning rate: 0.00092222]
	Learning Rate: 0.000922221
	LOSS [training: 0.15002543156724443 | validation: 0.1420344528659419]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14596461576258304		[learning rate: 0.00091896]
	Learning Rate: 0.00091896
	LOSS [training: 0.14596461576258304 | validation: 0.15158113710704377]
	TIME [epoch: 26.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15583059606954475		[learning rate: 0.00091571]
	Learning Rate: 0.00091571
	LOSS [training: 0.15583059606954475 | validation: 0.15553551831154566]
	TIME [epoch: 26.1 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1471643366091688		[learning rate: 0.00091247]
	Learning Rate: 0.000912472
	LOSS [training: 0.1471643366091688 | validation: 0.15866931820563093]
	TIME [epoch: 26.1 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14802711296928237		[learning rate: 0.00090925]
	Learning Rate: 0.000909246
	LOSS [training: 0.14802711296928237 | validation: 0.15520157205672724]
	TIME [epoch: 26.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15389915746576222		[learning rate: 0.00090603]
	Learning Rate: 0.000906031
	LOSS [training: 0.15389915746576222 | validation: 0.16387393796104463]
	TIME [epoch: 26.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1462221582902948		[learning rate: 0.00090283]
	Learning Rate: 0.000902827
	LOSS [training: 0.1462221582902948 | validation: 0.15665389311173]
	TIME [epoch: 26.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15311784852048277		[learning rate: 0.00089963]
	Learning Rate: 0.000899634
	LOSS [training: 0.15311784852048277 | validation: 0.15887988691742264]
	TIME [epoch: 26.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15220967956714485		[learning rate: 0.00089645]
	Learning Rate: 0.000896453
	LOSS [training: 0.15220967956714485 | validation: 0.16031543827949127]
	TIME [epoch: 26.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1520147789229947		[learning rate: 0.00089328]
	Learning Rate: 0.000893283
	LOSS [training: 0.1520147789229947 | validation: 0.15289216284160462]
	TIME [epoch: 26.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15419543744493813		[learning rate: 0.00089012]
	Learning Rate: 0.000890124
	LOSS [training: 0.15419543744493813 | validation: 0.16346057579405812]
	TIME [epoch: 26.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15206791005774573		[learning rate: 0.00088698]
	Learning Rate: 0.000886976
	LOSS [training: 0.15206791005774573 | validation: 0.15110800948879352]
	TIME [epoch: 26.1 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15543522766276371		[learning rate: 0.00088384]
	Learning Rate: 0.00088384
	LOSS [training: 0.15543522766276371 | validation: 0.1552526842284315]
	TIME [epoch: 26.1 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14824874569806373		[learning rate: 0.00088071]
	Learning Rate: 0.000880715
	LOSS [training: 0.14824874569806373 | validation: 0.153177672000354]
	TIME [epoch: 26.1 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14662976628389582		[learning rate: 0.0008776]
	Learning Rate: 0.0008776
	LOSS [training: 0.14662976628389582 | validation: 0.1622761806224748]
	TIME [epoch: 26.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14921944457686206		[learning rate: 0.0008745]
	Learning Rate: 0.000874497
	LOSS [training: 0.14921944457686206 | validation: 0.1467032484413358]
	TIME [epoch: 26.1 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14975018786271507		[learning rate: 0.0008714]
	Learning Rate: 0.000871404
	LOSS [training: 0.14975018786271507 | validation: 0.15035822754092124]
	TIME [epoch: 26.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15693041639061583		[learning rate: 0.00086832]
	Learning Rate: 0.000868323
	LOSS [training: 0.15693041639061583 | validation: 0.14852235134325642]
	TIME [epoch: 26.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15711617876097064		[learning rate: 0.00086525]
	Learning Rate: 0.000865252
	LOSS [training: 0.15711617876097064 | validation: 0.15684326856131825]
	TIME [epoch: 26.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15230023387668026		[learning rate: 0.00086219]
	Learning Rate: 0.000862193
	LOSS [training: 0.15230023387668026 | validation: 0.15028551698452491]
	TIME [epoch: 26.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1523645264255237		[learning rate: 0.00085914]
	Learning Rate: 0.000859144
	LOSS [training: 0.1523645264255237 | validation: 0.1512858883043901]
	TIME [epoch: 26.1 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1563765972498807		[learning rate: 0.00085611]
	Learning Rate: 0.000856106
	LOSS [training: 0.1563765972498807 | validation: 0.15853545240823022]
	TIME [epoch: 26.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15414211395644456		[learning rate: 0.00085308]
	Learning Rate: 0.000853078
	LOSS [training: 0.15414211395644456 | validation: 0.15147769856891904]
	TIME [epoch: 26.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14604742110613053		[learning rate: 0.00085006]
	Learning Rate: 0.000850062
	LOSS [training: 0.14604742110613053 | validation: 0.1541697329877225]
	TIME [epoch: 26.1 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14636803695676745		[learning rate: 0.00084706]
	Learning Rate: 0.000847056
	LOSS [training: 0.14636803695676745 | validation: 0.15881433908751671]
	TIME [epoch: 26.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1523074011681625		[learning rate: 0.00084406]
	Learning Rate: 0.000844061
	LOSS [training: 0.1523074011681625 | validation: 0.15279323020241778]
	TIME [epoch: 26.1 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14578054442328492		[learning rate: 0.00084108]
	Learning Rate: 0.000841076
	LOSS [training: 0.14578054442328492 | validation: 0.15726849280932603]
	TIME [epoch: 26.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1486543023636546		[learning rate: 0.0008381]
	Learning Rate: 0.000838101
	LOSS [training: 0.1486543023636546 | validation: 0.15198299469449303]
	TIME [epoch: 26.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14937494659144868		[learning rate: 0.00083514]
	Learning Rate: 0.000835138
	LOSS [training: 0.14937494659144868 | validation: 0.14841066452004473]
	TIME [epoch: 26.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15366939381824227		[learning rate: 0.00083218]
	Learning Rate: 0.000832185
	LOSS [training: 0.15366939381824227 | validation: 0.16566877698006907]
	TIME [epoch: 26.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14969086063648945		[learning rate: 0.00082924]
	Learning Rate: 0.000829242
	LOSS [training: 0.14969086063648945 | validation: 0.15463134474511997]
	TIME [epoch: 26.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1467802811945488		[learning rate: 0.00082631]
	Learning Rate: 0.00082631
	LOSS [training: 0.1467802811945488 | validation: 0.15829995485349543]
	TIME [epoch: 26.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1502774618849605		[learning rate: 0.00082339]
	Learning Rate: 0.000823388
	LOSS [training: 0.1502774618849605 | validation: 0.15303966149430312]
	TIME [epoch: 26.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.149953981042458		[learning rate: 0.00082048]
	Learning Rate: 0.000820476
	LOSS [training: 0.149953981042458 | validation: 0.1564939046019964]
	TIME [epoch: 26.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1507715575015142		[learning rate: 0.00081757]
	Learning Rate: 0.000817575
	LOSS [training: 0.1507715575015142 | validation: 0.15510152839165667]
	TIME [epoch: 26.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14958910529766636		[learning rate: 0.00081468]
	Learning Rate: 0.000814684
	LOSS [training: 0.14958910529766636 | validation: 0.15942118482825077]
	TIME [epoch: 26.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15386105948530698		[learning rate: 0.0008118]
	Learning Rate: 0.000811803
	LOSS [training: 0.15386105948530698 | validation: 0.15846915711817725]
	TIME [epoch: 26.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14716116829345166		[learning rate: 0.00080893]
	Learning Rate: 0.000808932
	LOSS [training: 0.14716116829345166 | validation: 0.14832631924291914]
	TIME [epoch: 26.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15052095762830228		[learning rate: 0.00080607]
	Learning Rate: 0.000806072
	LOSS [training: 0.15052095762830228 | validation: 0.15962489131110244]
	TIME [epoch: 26.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14530733334830467		[learning rate: 0.00080322]
	Learning Rate: 0.000803221
	LOSS [training: 0.14530733334830467 | validation: 0.16003281392350358]
	TIME [epoch: 26.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15004361838528016		[learning rate: 0.00080038]
	Learning Rate: 0.000800381
	LOSS [training: 0.15004361838528016 | validation: 0.15232420785315756]
	TIME [epoch: 26.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15379119420374623		[learning rate: 0.00079755]
	Learning Rate: 0.000797551
	LOSS [training: 0.15379119420374623 | validation: 0.1462602808358385]
	TIME [epoch: 26.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15260428963648903		[learning rate: 0.00079473]
	Learning Rate: 0.00079473
	LOSS [training: 0.15260428963648903 | validation: 0.14694427062426038]
	TIME [epoch: 26.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14960172279978773		[learning rate: 0.00079192]
	Learning Rate: 0.00079192
	LOSS [training: 0.14960172279978773 | validation: 0.1559492694714227]
	TIME [epoch: 26.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15187630513648212		[learning rate: 0.00078912]
	Learning Rate: 0.00078912
	LOSS [training: 0.15187630513648212 | validation: 0.14928872088828193]
	TIME [epoch: 26.1 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15481871172235104		[learning rate: 0.00078633]
	Learning Rate: 0.000786329
	LOSS [training: 0.15481871172235104 | validation: 0.14447530155509425]
	TIME [epoch: 26.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15033933372397443		[learning rate: 0.00078355]
	Learning Rate: 0.000783549
	LOSS [training: 0.15033933372397443 | validation: 0.15570934194274158]
	TIME [epoch: 26.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14213573183864706		[learning rate: 0.00078078]
	Learning Rate: 0.000780778
	LOSS [training: 0.14213573183864706 | validation: 0.1670186376681969]
	TIME [epoch: 26.1 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14691114354089188		[learning rate: 0.00077802]
	Learning Rate: 0.000778017
	LOSS [training: 0.14691114354089188 | validation: 0.15197877476727598]
	TIME [epoch: 26.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15664642822315106		[learning rate: 0.00077527]
	Learning Rate: 0.000775266
	LOSS [training: 0.15664642822315106 | validation: 0.15633640024295883]
	TIME [epoch: 26.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15531659942070927		[learning rate: 0.00077252]
	Learning Rate: 0.000772524
	LOSS [training: 0.15531659942070927 | validation: 0.1528273434869175]
	TIME [epoch: 26.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.16092950636454048		[learning rate: 0.00076979]
	Learning Rate: 0.000769792
	LOSS [training: 0.16092950636454048 | validation: 0.15588166976006645]
	TIME [epoch: 26.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14592134935933185		[learning rate: 0.00076707]
	Learning Rate: 0.00076707
	LOSS [training: 0.14592134935933185 | validation: 0.15501431396874843]
	TIME [epoch: 26.1 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14795945157868737		[learning rate: 0.00076436]
	Learning Rate: 0.000764358
	LOSS [training: 0.14795945157868737 | validation: 0.15760912470562635]
	TIME [epoch: 26.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14898874789231448		[learning rate: 0.00076165]
	Learning Rate: 0.000761655
	LOSS [training: 0.14898874789231448 | validation: 0.1476543657172539]
	TIME [epoch: 26.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14316410262122245		[learning rate: 0.00075896]
	Learning Rate: 0.000758961
	LOSS [training: 0.14316410262122245 | validation: 0.14664842354741062]
	TIME [epoch: 26.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14947230419992355		[learning rate: 0.00075628]
	Learning Rate: 0.000756278
	LOSS [training: 0.14947230419992355 | validation: 0.15377665851510045]
	TIME [epoch: 26.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15014274613745154		[learning rate: 0.0007536]
	Learning Rate: 0.000753603
	LOSS [training: 0.15014274613745154 | validation: 0.15494724826068246]
	TIME [epoch: 26.1 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14898132153092147		[learning rate: 0.00075094]
	Learning Rate: 0.000750938
	LOSS [training: 0.14898132153092147 | validation: 0.15966095386120865]
	TIME [epoch: 26.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14923961716646642		[learning rate: 0.00074828]
	Learning Rate: 0.000748283
	LOSS [training: 0.14923961716646642 | validation: 0.1505883058494398]
	TIME [epoch: 26.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15456308318691278		[learning rate: 0.00074564]
	Learning Rate: 0.000745637
	LOSS [training: 0.15456308318691278 | validation: 0.14951721716352395]
	TIME [epoch: 26.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14241425073405922		[learning rate: 0.000743]
	Learning Rate: 0.000743
	LOSS [training: 0.14241425073405922 | validation: 0.14999110418559186]
	TIME [epoch: 26.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1539955245749887		[learning rate: 0.00074037]
	Learning Rate: 0.000740373
	LOSS [training: 0.1539955245749887 | validation: 0.15187829580995288]
	TIME [epoch: 26.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14877972309010015		[learning rate: 0.00073775]
	Learning Rate: 0.000737755
	LOSS [training: 0.14877972309010015 | validation: 0.14727636408112738]
	TIME [epoch: 26.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1492661416656856		[learning rate: 0.00073515]
	Learning Rate: 0.000735146
	LOSS [training: 0.1492661416656856 | validation: 0.1642516377040143]
	TIME [epoch: 26.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1477069460600994		[learning rate: 0.00073255]
	Learning Rate: 0.000732546
	LOSS [training: 0.1477069460600994 | validation: 0.15488606659298515]
	TIME [epoch: 26.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15211998107083205		[learning rate: 0.00072996]
	Learning Rate: 0.000729956
	LOSS [training: 0.15211998107083205 | validation: 0.14201003760286363]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_789.pth
	Model improved!!!
EPOCH 790/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1413963164754953		[learning rate: 0.00072737]
	Learning Rate: 0.000727375
	LOSS [training: 0.1413963164754953 | validation: 0.15424397692885095]
	TIME [epoch: 26.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15196175065189935		[learning rate: 0.0007248]
	Learning Rate: 0.000724803
	LOSS [training: 0.15196175065189935 | validation: 0.15513705077231046]
	TIME [epoch: 26.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14829259924723548		[learning rate: 0.00072224]
	Learning Rate: 0.00072224
	LOSS [training: 0.14829259924723548 | validation: 0.15515628410407678]
	TIME [epoch: 26.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1492798866368292		[learning rate: 0.00071969]
	Learning Rate: 0.000719686
	LOSS [training: 0.1492798866368292 | validation: 0.16293053615857972]
	TIME [epoch: 26.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14580351357780683		[learning rate: 0.00071714]
	Learning Rate: 0.000717141
	LOSS [training: 0.14580351357780683 | validation: 0.15150948122932792]
	TIME [epoch: 26.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1507468912373657		[learning rate: 0.0007146]
	Learning Rate: 0.000714605
	LOSS [training: 0.1507468912373657 | validation: 0.15561228626544005]
	TIME [epoch: 26.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15380730923865812		[learning rate: 0.00071208]
	Learning Rate: 0.000712078
	LOSS [training: 0.15380730923865812 | validation: 0.1515635838237471]
	TIME [epoch: 26.1 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14912241333844659		[learning rate: 0.00070956]
	Learning Rate: 0.00070956
	LOSS [training: 0.14912241333844659 | validation: 0.1512238383572181]
	TIME [epoch: 26.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14379788429559845		[learning rate: 0.00070705]
	Learning Rate: 0.000707051
	LOSS [training: 0.14379788429559845 | validation: 0.14226929900233296]
	TIME [epoch: 26.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15342976154949547		[learning rate: 0.00070455]
	Learning Rate: 0.00070455
	LOSS [training: 0.15342976154949547 | validation: 0.14614329702896672]
	TIME [epoch: 26.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1478669385596334		[learning rate: 0.00070206]
	Learning Rate: 0.000702059
	LOSS [training: 0.1478669385596334 | validation: 0.15768790076432157]
	TIME [epoch: 26.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15220940847216177		[learning rate: 0.00069958]
	Learning Rate: 0.000699576
	LOSS [training: 0.15220940847216177 | validation: 0.1536817372143359]
	TIME [epoch: 26.1 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15093132372870152		[learning rate: 0.0006971]
	Learning Rate: 0.000697102
	LOSS [training: 0.15093132372870152 | validation: 0.14290591319211196]
	TIME [epoch: 26.1 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15097832936363634		[learning rate: 0.00069464]
	Learning Rate: 0.000694637
	LOSS [training: 0.15097832936363634 | validation: 0.1560102393273324]
	TIME [epoch: 26.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14876878852084552		[learning rate: 0.00069218]
	Learning Rate: 0.000692181
	LOSS [training: 0.14876878852084552 | validation: 0.14758789698944977]
	TIME [epoch: 26.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1549690421638831		[learning rate: 0.00068973]
	Learning Rate: 0.000689733
	LOSS [training: 0.1549690421638831 | validation: 0.15666325549974056]
	TIME [epoch: 26.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15537206562665298		[learning rate: 0.00068729]
	Learning Rate: 0.000687295
	LOSS [training: 0.15537206562665298 | validation: 0.1529106268191094]
	TIME [epoch: 26.1 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15052841156705873		[learning rate: 0.00068486]
	Learning Rate: 0.000684864
	LOSS [training: 0.15052841156705873 | validation: 0.1522005636968226]
	TIME [epoch: 26.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15450483364572745		[learning rate: 0.00068244]
	Learning Rate: 0.000682442
	LOSS [training: 0.15450483364572745 | validation: 0.15891379060896293]
	TIME [epoch: 26.1 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15085269287843223		[learning rate: 0.00068003]
	Learning Rate: 0.000680029
	LOSS [training: 0.15085269287843223 | validation: 0.15701624984985013]
	TIME [epoch: 26.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14823746056412399		[learning rate: 0.00067762]
	Learning Rate: 0.000677624
	LOSS [training: 0.14823746056412399 | validation: 0.14562373913506058]
	TIME [epoch: 26.1 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14591166649132062		[learning rate: 0.00067523]
	Learning Rate: 0.000675228
	LOSS [training: 0.14591166649132062 | validation: 0.15106048646768222]
	TIME [epoch: 26.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14723325061043616		[learning rate: 0.00067284]
	Learning Rate: 0.00067284
	LOSS [training: 0.14723325061043616 | validation: 0.14880924583174526]
	TIME [epoch: 26.1 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1425918479962819		[learning rate: 0.00067046]
	Learning Rate: 0.000670461
	LOSS [training: 0.1425918479962819 | validation: 0.15124596888630026]
	TIME [epoch: 26.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1560197749317637		[learning rate: 0.00066809]
	Learning Rate: 0.00066809
	LOSS [training: 0.1560197749317637 | validation: 0.15722426366446948]
	TIME [epoch: 26.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15173250202707772		[learning rate: 0.00066573]
	Learning Rate: 0.000665728
	LOSS [training: 0.15173250202707772 | validation: 0.16251322228546172]
	TIME [epoch: 26.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1482207044117755		[learning rate: 0.00066337]
	Learning Rate: 0.000663374
	LOSS [training: 0.1482207044117755 | validation: 0.15641522518457682]
	TIME [epoch: 26.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15179719922206694		[learning rate: 0.00066103]
	Learning Rate: 0.000661028
	LOSS [training: 0.15179719922206694 | validation: 0.15564962955412043]
	TIME [epoch: 26.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14503987272634536		[learning rate: 0.00065869]
	Learning Rate: 0.00065869
	LOSS [training: 0.14503987272634536 | validation: 0.1600172308542538]
	TIME [epoch: 26.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14386064345559643		[learning rate: 0.00065636]
	Learning Rate: 0.000656361
	LOSS [training: 0.14386064345559643 | validation: 0.13877206208623755]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_819.pth
	Model improved!!!
EPOCH 820/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1469425535178794		[learning rate: 0.00065404]
	Learning Rate: 0.00065404
	LOSS [training: 0.1469425535178794 | validation: 0.14904960896997366]
	TIME [epoch: 26.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1466976785073164		[learning rate: 0.00065173]
	Learning Rate: 0.000651727
	LOSS [training: 0.1466976785073164 | validation: 0.1494984087082846]
	TIME [epoch: 26.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15099022519805252		[learning rate: 0.00064942]
	Learning Rate: 0.000649423
	LOSS [training: 0.15099022519805252 | validation: 0.1578782304293262]
	TIME [epoch: 26.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14874739941023926		[learning rate: 0.00064713]
	Learning Rate: 0.000647126
	LOSS [training: 0.14874739941023926 | validation: 0.15443876307701684]
	TIME [epoch: 26.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1494974913857061		[learning rate: 0.00064484]
	Learning Rate: 0.000644838
	LOSS [training: 0.1494974913857061 | validation: 0.15309072562278664]
	TIME [epoch: 26.1 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15607244602391498		[learning rate: 0.00064256]
	Learning Rate: 0.000642558
	LOSS [training: 0.15607244602391498 | validation: 0.14311391649223834]
	TIME [epoch: 26.1 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1515271811606691		[learning rate: 0.00064029]
	Learning Rate: 0.000640285
	LOSS [training: 0.1515271811606691 | validation: 0.15961999708320046]
	TIME [epoch: 26.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1526939686518767		[learning rate: 0.00063802]
	Learning Rate: 0.000638021
	LOSS [training: 0.1526939686518767 | validation: 0.15193825793857227]
	TIME [epoch: 26.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1522838271414198		[learning rate: 0.00063577]
	Learning Rate: 0.000635765
	LOSS [training: 0.1522838271414198 | validation: 0.15583668883310312]
	TIME [epoch: 26.1 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1458118161227751		[learning rate: 0.00063352]
	Learning Rate: 0.000633517
	LOSS [training: 0.1458118161227751 | validation: 0.1524689663097879]
	TIME [epoch: 26.1 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15236919505415789		[learning rate: 0.00063128]
	Learning Rate: 0.000631277
	LOSS [training: 0.15236919505415789 | validation: 0.1472611247613445]
	TIME [epoch: 26.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15360049070222398		[learning rate: 0.00062904]
	Learning Rate: 0.000629044
	LOSS [training: 0.15360049070222398 | validation: 0.15215443859243089]
	TIME [epoch: 26.1 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15117989793370093		[learning rate: 0.00062682]
	Learning Rate: 0.00062682
	LOSS [training: 0.15117989793370093 | validation: 0.15902943588307586]
	TIME [epoch: 26.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14991411617906847		[learning rate: 0.0006246]
	Learning Rate: 0.000624603
	LOSS [training: 0.14991411617906847 | validation: 0.1492434423600374]
	TIME [epoch: 26.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1531288910458868		[learning rate: 0.00062239]
	Learning Rate: 0.000622395
	LOSS [training: 0.1531288910458868 | validation: 0.14311163918924846]
	TIME [epoch: 26.1 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14589665552040945		[learning rate: 0.00062019]
	Learning Rate: 0.000620194
	LOSS [training: 0.14589665552040945 | validation: 0.16379984061897185]
	TIME [epoch: 26.1 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14416758563242274		[learning rate: 0.000618]
	Learning Rate: 0.000618001
	LOSS [training: 0.14416758563242274 | validation: 0.15792756284677847]
	TIME [epoch: 26.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14558692418136726		[learning rate: 0.00061582]
	Learning Rate: 0.000615815
	LOSS [training: 0.14558692418136726 | validation: 0.15361987550813064]
	TIME [epoch: 26.1 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1453712700362588		[learning rate: 0.00061364]
	Learning Rate: 0.000613638
	LOSS [training: 0.1453712700362588 | validation: 0.15036477343971316]
	TIME [epoch: 26.1 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14119393078080736		[learning rate: 0.00061147]
	Learning Rate: 0.000611468
	LOSS [training: 0.14119393078080736 | validation: 0.1485676225948272]
	TIME [epoch: 26.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14742232448185394		[learning rate: 0.00060931]
	Learning Rate: 0.000609306
	LOSS [training: 0.14742232448185394 | validation: 0.15057271630231592]
	TIME [epoch: 26.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14830948472695724		[learning rate: 0.00060715]
	Learning Rate: 0.000607151
	LOSS [training: 0.14830948472695724 | validation: 0.15168117745939746]
	TIME [epoch: 26.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15228641375530882		[learning rate: 0.000605]
	Learning Rate: 0.000605004
	LOSS [training: 0.15228641375530882 | validation: 0.15527747474705497]
	TIME [epoch: 26.1 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15028312091210103		[learning rate: 0.00060286]
	Learning Rate: 0.000602865
	LOSS [training: 0.15028312091210103 | validation: 0.15553310173313029]
	TIME [epoch: 26.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1597683730908115		[learning rate: 0.00060073]
	Learning Rate: 0.000600733
	LOSS [training: 0.1597683730908115 | validation: 0.14974771908086795]
	TIME [epoch: 26.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15090848510287963		[learning rate: 0.00059861]
	Learning Rate: 0.000598608
	LOSS [training: 0.15090848510287963 | validation: 0.15619172615528545]
	TIME [epoch: 26.1 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15231472678043537		[learning rate: 0.00059649]
	Learning Rate: 0.000596492
	LOSS [training: 0.15231472678043537 | validation: 0.1499231847078604]
	TIME [epoch: 26.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1519570073806026		[learning rate: 0.00059438]
	Learning Rate: 0.000594382
	LOSS [training: 0.1519570073806026 | validation: 0.14752871774037504]
	TIME [epoch: 26.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14813722216280237		[learning rate: 0.00059228]
	Learning Rate: 0.000592281
	LOSS [training: 0.14813722216280237 | validation: 0.15885110420775725]
	TIME [epoch: 26.1 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15236555435988866		[learning rate: 0.00059019]
	Learning Rate: 0.000590186
	LOSS [training: 0.15236555435988866 | validation: 0.16238834625294646]
	TIME [epoch: 26.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14440752129251536		[learning rate: 0.0005881]
	Learning Rate: 0.000588099
	LOSS [training: 0.14440752129251536 | validation: 0.15378018651236433]
	TIME [epoch: 26.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15564471563998675		[learning rate: 0.00058602]
	Learning Rate: 0.000586019
	LOSS [training: 0.15564471563998675 | validation: 0.15466012834074747]
	TIME [epoch: 26.1 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1504160240497012		[learning rate: 0.00058395]
	Learning Rate: 0.000583947
	LOSS [training: 0.1504160240497012 | validation: 0.15020576247717463]
	TIME [epoch: 26.1 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1596282160113589		[learning rate: 0.00058188]
	Learning Rate: 0.000581882
	LOSS [training: 0.1596282160113589 | validation: 0.15315190362146702]
	TIME [epoch: 26.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15386611226209526		[learning rate: 0.00057982]
	Learning Rate: 0.000579825
	LOSS [training: 0.15386611226209526 | validation: 0.15438007841257478]
	TIME [epoch: 26.1 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14664451627577937		[learning rate: 0.00057777]
	Learning Rate: 0.000577774
	LOSS [training: 0.14664451627577937 | validation: 0.15644359448650977]
	TIME [epoch: 26.1 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15444587250656786		[learning rate: 0.00057573]
	Learning Rate: 0.000575731
	LOSS [training: 0.15444587250656786 | validation: 0.15323452986591532]
	TIME [epoch: 26.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15331014328172082		[learning rate: 0.0005737]
	Learning Rate: 0.000573695
	LOSS [training: 0.15331014328172082 | validation: 0.14799360525375221]
	TIME [epoch: 26.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1481565844241075		[learning rate: 0.00057167]
	Learning Rate: 0.000571667
	LOSS [training: 0.1481565844241075 | validation: 0.16030739894297524]
	TIME [epoch: 26.1 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14983313070450038		[learning rate: 0.00056965]
	Learning Rate: 0.000569645
	LOSS [training: 0.14983313070450038 | validation: 0.1490861449279809]
	TIME [epoch: 26.1 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15065228061355498		[learning rate: 0.00056763]
	Learning Rate: 0.000567631
	LOSS [training: 0.15065228061355498 | validation: 0.1520159387986943]
	TIME [epoch: 26.1 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1457357088314685		[learning rate: 0.00056562]
	Learning Rate: 0.000565624
	LOSS [training: 0.1457357088314685 | validation: 0.14612151478078234]
	TIME [epoch: 26.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1505440036502009		[learning rate: 0.00056362]
	Learning Rate: 0.000563623
	LOSS [training: 0.1505440036502009 | validation: 0.1543296051241273]
	TIME [epoch: 26.1 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1504254114934491		[learning rate: 0.00056163]
	Learning Rate: 0.00056163
	LOSS [training: 0.1504254114934491 | validation: 0.1513459053428687]
	TIME [epoch: 26.1 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15172804491432482		[learning rate: 0.00055964]
	Learning Rate: 0.000559644
	LOSS [training: 0.15172804491432482 | validation: 0.14702800956977338]
	TIME [epoch: 26.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1443225441316262		[learning rate: 0.00055767]
	Learning Rate: 0.000557665
	LOSS [training: 0.1443225441316262 | validation: 0.16033879711575053]
	TIME [epoch: 26.1 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14399552148639091		[learning rate: 0.00055569]
	Learning Rate: 0.000555693
	LOSS [training: 0.14399552148639091 | validation: 0.15495576534824643]
	TIME [epoch: 26.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14753474897367572		[learning rate: 0.00055373]
	Learning Rate: 0.000553728
	LOSS [training: 0.14753474897367572 | validation: 0.14443931227201742]
	TIME [epoch: 26.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14386799758194477		[learning rate: 0.00055177]
	Learning Rate: 0.00055177
	LOSS [training: 0.14386799758194477 | validation: 0.15176198751013778]
	TIME [epoch: 26.1 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14613804810233819		[learning rate: 0.00054982]
	Learning Rate: 0.000549819
	LOSS [training: 0.14613804810233819 | validation: 0.15761116045058662]
	TIME [epoch: 26.1 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15230009049349807		[learning rate: 0.00054787]
	Learning Rate: 0.000547875
	LOSS [training: 0.15230009049349807 | validation: 0.15415027011566818]
	TIME [epoch: 26.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15200852470384382		[learning rate: 0.00054594]
	Learning Rate: 0.000545937
	LOSS [training: 0.15200852470384382 | validation: 0.15432599268007446]
	TIME [epoch: 26.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1439756505670197		[learning rate: 0.00054401]
	Learning Rate: 0.000544007
	LOSS [training: 0.1439756505670197 | validation: 0.14584314563135195]
	TIME [epoch: 26.1 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1467267652981248		[learning rate: 0.00054208]
	Learning Rate: 0.000542083
	LOSS [training: 0.1467267652981248 | validation: 0.15672895593092925]
	TIME [epoch: 26.1 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14744551438640915		[learning rate: 0.00054017]
	Learning Rate: 0.000540166
	LOSS [training: 0.14744551438640915 | validation: 0.14996371911016307]
	TIME [epoch: 26.1 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15246533989245936		[learning rate: 0.00053826]
	Learning Rate: 0.000538256
	LOSS [training: 0.15246533989245936 | validation: 0.1491173026101509]
	TIME [epoch: 26.1 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14683301157692355		[learning rate: 0.00053635]
	Learning Rate: 0.000536353
	LOSS [training: 0.14683301157692355 | validation: 0.15849912277983302]
	TIME [epoch: 26.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14968229356595142		[learning rate: 0.00053446]
	Learning Rate: 0.000534456
	LOSS [training: 0.14968229356595142 | validation: 0.15661443567638364]
	TIME [epoch: 26.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14864539752647107		[learning rate: 0.00053257]
	Learning Rate: 0.000532566
	LOSS [training: 0.14864539752647107 | validation: 0.13787258507946148]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1510282808117362		[learning rate: 0.00053068]
	Learning Rate: 0.000530683
	LOSS [training: 0.1510282808117362 | validation: 0.1446188036310142]
	TIME [epoch: 26.1 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1500282361389165		[learning rate: 0.00052881]
	Learning Rate: 0.000528806
	LOSS [training: 0.1500282361389165 | validation: 0.1500625023401972]
	TIME [epoch: 26.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.146688316111441		[learning rate: 0.00052694]
	Learning Rate: 0.000526936
	LOSS [training: 0.146688316111441 | validation: 0.15132915611968709]
	TIME [epoch: 26.1 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14694762313109527		[learning rate: 0.00052507]
	Learning Rate: 0.000525073
	LOSS [training: 0.14694762313109527 | validation: 0.15193070888126706]
	TIME [epoch: 26.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14677955092618217		[learning rate: 0.00052322]
	Learning Rate: 0.000523216
	LOSS [training: 0.14677955092618217 | validation: 0.1594778049569408]
	TIME [epoch: 26.1 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1514063057085564		[learning rate: 0.00052137]
	Learning Rate: 0.000521366
	LOSS [training: 0.1514063057085564 | validation: 0.15242937961720224]
	TIME [epoch: 26.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15474043121421405		[learning rate: 0.00051952]
	Learning Rate: 0.000519522
	LOSS [training: 0.15474043121421405 | validation: 0.15199103392677393]
	TIME [epoch: 26.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15424085164595794		[learning rate: 0.00051769]
	Learning Rate: 0.000517685
	LOSS [training: 0.15424085164595794 | validation: 0.16730135463937787]
	TIME [epoch: 26.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14566710552187323		[learning rate: 0.00051585]
	Learning Rate: 0.000515855
	LOSS [training: 0.14566710552187323 | validation: 0.15629573347805067]
	TIME [epoch: 26.1 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15057356235119523		[learning rate: 0.00051403]
	Learning Rate: 0.000514031
	LOSS [training: 0.15057356235119523 | validation: 0.14796590261671538]
	TIME [epoch: 26.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14534462109392038		[learning rate: 0.00051221]
	Learning Rate: 0.000512213
	LOSS [training: 0.14534462109392038 | validation: 0.1545268725533707]
	TIME [epoch: 26.1 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14156312465603463		[learning rate: 0.0005104]
	Learning Rate: 0.000510402
	LOSS [training: 0.14156312465603463 | validation: 0.16071247974322683]
	TIME [epoch: 26.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14548414216661962		[learning rate: 0.0005086]
	Learning Rate: 0.000508597
	LOSS [training: 0.14548414216661962 | validation: 0.1524314484881997]
	TIME [epoch: 26.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1439866683082865		[learning rate: 0.0005068]
	Learning Rate: 0.000506798
	LOSS [training: 0.1439866683082865 | validation: 0.15041468561435295]
	TIME [epoch: 26.1 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14898733157809607		[learning rate: 0.00050501]
	Learning Rate: 0.000505006
	LOSS [training: 0.14898733157809607 | validation: 0.1538365831710789]
	TIME [epoch: 26.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14851761648838832		[learning rate: 0.00050322]
	Learning Rate: 0.00050322
	LOSS [training: 0.14851761648838832 | validation: 0.1556284306646013]
	TIME [epoch: 26.1 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15277336410285497		[learning rate: 0.00050144]
	Learning Rate: 0.000501441
	LOSS [training: 0.15277336410285497 | validation: 0.1602517215034522]
	TIME [epoch: 26.1 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14531410500178202		[learning rate: 0.00049967]
	Learning Rate: 0.000499668
	LOSS [training: 0.14531410500178202 | validation: 0.1506425325849623]
	TIME [epoch: 26.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14459950355315945		[learning rate: 0.0004979]
	Learning Rate: 0.000497901
	LOSS [training: 0.14459950355315945 | validation: 0.15306720829689974]
	TIME [epoch: 26.1 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14451223223119322		[learning rate: 0.00049614]
	Learning Rate: 0.00049614
	LOSS [training: 0.14451223223119322 | validation: 0.14461432951082243]
	TIME [epoch: 26.1 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14965167071640445		[learning rate: 0.00049439]
	Learning Rate: 0.000494386
	LOSS [training: 0.14965167071640445 | validation: 0.15282258527428316]
	TIME [epoch: 26.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14537608633258228		[learning rate: 0.00049264]
	Learning Rate: 0.000492637
	LOSS [training: 0.14537608633258228 | validation: 0.15791519939261162]
	TIME [epoch: 26.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15075405612032208		[learning rate: 0.0004909]
	Learning Rate: 0.000490895
	LOSS [training: 0.15075405612032208 | validation: 0.1498295421698978]
	TIME [epoch: 26.1 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14876508715166356		[learning rate: 0.00048916]
	Learning Rate: 0.000489159
	LOSS [training: 0.14876508715166356 | validation: 0.1538124583785214]
	TIME [epoch: 26.1 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14762616320979868		[learning rate: 0.00048743]
	Learning Rate: 0.00048743
	LOSS [training: 0.14762616320979868 | validation: 0.14992970162649305]
	TIME [epoch: 26.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1491075853400996		[learning rate: 0.00048571]
	Learning Rate: 0.000485706
	LOSS [training: 0.1491075853400996 | validation: 0.15970031639711116]
	TIME [epoch: 26.1 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15193902192892778		[learning rate: 0.00048399]
	Learning Rate: 0.000483989
	LOSS [training: 0.15193902192892778 | validation: 0.1453133670936058]
	TIME [epoch: 26.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15549780317150416		[learning rate: 0.00048228]
	Learning Rate: 0.000482277
	LOSS [training: 0.15549780317150416 | validation: 0.16478015019566003]
	TIME [epoch: 26.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14508836302693287		[learning rate: 0.00048057]
	Learning Rate: 0.000480572
	LOSS [training: 0.14508836302693287 | validation: 0.14131567210153023]
	TIME [epoch: 26.1 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14629976503238837		[learning rate: 0.00047887]
	Learning Rate: 0.000478872
	LOSS [training: 0.14629976503238837 | validation: 0.15024045616844306]
	TIME [epoch: 26.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15072104123691346		[learning rate: 0.00047718]
	Learning Rate: 0.000477179
	LOSS [training: 0.15072104123691346 | validation: 0.15592672170587416]
	TIME [epoch: 26.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1455809326246618		[learning rate: 0.00047549]
	Learning Rate: 0.000475492
	LOSS [training: 0.1455809326246618 | validation: 0.15308147589460686]
	TIME [epoch: 26.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15263492612063637		[learning rate: 0.00047381]
	Learning Rate: 0.00047381
	LOSS [training: 0.15263492612063637 | validation: 0.15286895549235835]
	TIME [epoch: 26.1 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1403220820530187		[learning rate: 0.00047213]
	Learning Rate: 0.000472135
	LOSS [training: 0.1403220820530187 | validation: 0.1513159500474914]
	TIME [epoch: 26.1 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15795533446278884		[learning rate: 0.00047047]
	Learning Rate: 0.000470465
	LOSS [training: 0.15795533446278884 | validation: 0.1536464252891517]
	TIME [epoch: 26.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14336238761256279		[learning rate: 0.0004688]
	Learning Rate: 0.000468801
	LOSS [training: 0.14336238761256279 | validation: 0.15524516893084908]
	TIME [epoch: 26.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15234516911076318		[learning rate: 0.00046714]
	Learning Rate: 0.000467144
	LOSS [training: 0.15234516911076318 | validation: 0.15040528158989278]
	TIME [epoch: 26.1 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1462222777246366		[learning rate: 0.00046549]
	Learning Rate: 0.000465492
	LOSS [training: 0.1462222777246366 | validation: 0.14373810246785257]
	TIME [epoch: 26.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14154533455489696		[learning rate: 0.00046385]
	Learning Rate: 0.000463846
	LOSS [training: 0.14154533455489696 | validation: 0.1462848518994463]
	TIME [epoch: 26.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15481393577169528		[learning rate: 0.00046221]
	Learning Rate: 0.000462205
	LOSS [training: 0.15481393577169528 | validation: 0.1524449636214876]
	TIME [epoch: 26.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1426763040487243		[learning rate: 0.00046057]
	Learning Rate: 0.000460571
	LOSS [training: 0.1426763040487243 | validation: 0.1533100208464863]
	TIME [epoch: 26.1 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14697405595402885		[learning rate: 0.00045894]
	Learning Rate: 0.000458942
	LOSS [training: 0.14697405595402885 | validation: 0.1408830425338028]
	TIME [epoch: 26.1 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15022626933708808		[learning rate: 0.00045732]
	Learning Rate: 0.00045732
	LOSS [training: 0.15022626933708808 | validation: 0.15516360580113533]
	TIME [epoch: 26.1 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14820929191208262		[learning rate: 0.0004557]
	Learning Rate: 0.000455702
	LOSS [training: 0.14820929191208262 | validation: 0.14893234191821705]
	TIME [epoch: 26.1 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14424931604213054		[learning rate: 0.00045409]
	Learning Rate: 0.000454091
	LOSS [training: 0.14424931604213054 | validation: 0.14709481108028505]
	TIME [epoch: 26.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15557252867955307		[learning rate: 0.00045249]
	Learning Rate: 0.000452485
	LOSS [training: 0.15557252867955307 | validation: 0.14613061587667678]
	TIME [epoch: 26.1 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1486534197142915		[learning rate: 0.00045089]
	Learning Rate: 0.000450885
	LOSS [training: 0.1486534197142915 | validation: 0.15370666668254612]
	TIME [epoch: 26.1 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14517534423382256		[learning rate: 0.00044929]
	Learning Rate: 0.000449291
	LOSS [training: 0.14517534423382256 | validation: 0.1489874369649658]
	TIME [epoch: 26.1 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14962288064023546		[learning rate: 0.0004477]
	Learning Rate: 0.000447702
	LOSS [training: 0.14962288064023546 | validation: 0.14877409505963546]
	TIME [epoch: 26.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15332572126328015		[learning rate: 0.00044612]
	Learning Rate: 0.000446119
	LOSS [training: 0.15332572126328015 | validation: 0.1498212174060601]
	TIME [epoch: 26.1 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14485795841299573		[learning rate: 0.00044454]
	Learning Rate: 0.000444541
	LOSS [training: 0.14485795841299573 | validation: 0.14720883595497136]
	TIME [epoch: 26.1 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15231788774115992		[learning rate: 0.00044297]
	Learning Rate: 0.000442969
	LOSS [training: 0.15231788774115992 | validation: 0.150614377879545]
	TIME [epoch: 26.1 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14433017933719502		[learning rate: 0.0004414]
	Learning Rate: 0.000441403
	LOSS [training: 0.14433017933719502 | validation: 0.14898989726845036]
	TIME [epoch: 26.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14645467540555696		[learning rate: 0.00043984]
	Learning Rate: 0.000439842
	LOSS [training: 0.14645467540555696 | validation: 0.14571253784779292]
	TIME [epoch: 26.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14470216868162541		[learning rate: 0.00043829]
	Learning Rate: 0.000438287
	LOSS [training: 0.14470216868162541 | validation: 0.1503752288292126]
	TIME [epoch: 26.1 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15157747196986207		[learning rate: 0.00043674]
	Learning Rate: 0.000436737
	LOSS [training: 0.15157747196986207 | validation: 0.14997846545148927]
	TIME [epoch: 26.1 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1490046965446081		[learning rate: 0.00043519]
	Learning Rate: 0.000435192
	LOSS [training: 0.1490046965446081 | validation: 0.14299296019166047]
	TIME [epoch: 26.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14080324696140428		[learning rate: 0.00043365]
	Learning Rate: 0.000433653
	LOSS [training: 0.14080324696140428 | validation: 0.15314591844885858]
	TIME [epoch: 26.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1529977924782731		[learning rate: 0.00043212]
	Learning Rate: 0.00043212
	LOSS [training: 0.1529977924782731 | validation: 0.15608175991940113]
	TIME [epoch: 26.1 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14956297569456006		[learning rate: 0.00043059]
	Learning Rate: 0.000430592
	LOSS [training: 0.14956297569456006 | validation: 0.1500464076134049]
	TIME [epoch: 26.1 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14459554631598576		[learning rate: 0.00042907]
	Learning Rate: 0.000429069
	LOSS [training: 0.14459554631598576 | validation: 0.14729022587716906]
	TIME [epoch: 26.1 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14747644886918113		[learning rate: 0.00042755]
	Learning Rate: 0.000427552
	LOSS [training: 0.14747644886918113 | validation: 0.1555020826346062]
	TIME [epoch: 26.1 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1439658674167187		[learning rate: 0.00042604]
	Learning Rate: 0.00042604
	LOSS [training: 0.1439658674167187 | validation: 0.14803902451759124]
	TIME [epoch: 26.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14703393831987174		[learning rate: 0.00042453]
	Learning Rate: 0.000424534
	LOSS [training: 0.14703393831987174 | validation: 0.1486471922422814]
	TIME [epoch: 26.1 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1527297450718664		[learning rate: 0.00042303]
	Learning Rate: 0.000423032
	LOSS [training: 0.1527297450718664 | validation: 0.15365783079597287]
	TIME [epoch: 26.1 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14855197099749076		[learning rate: 0.00042154]
	Learning Rate: 0.000421536
	LOSS [training: 0.14855197099749076 | validation: 0.1521806286186795]
	TIME [epoch: 26.1 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14669832595487317		[learning rate: 0.00042005]
	Learning Rate: 0.000420046
	LOSS [training: 0.14669832595487317 | validation: 0.14622739872610724]
	TIME [epoch: 26.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14575212375880642		[learning rate: 0.00041856]
	Learning Rate: 0.00041856
	LOSS [training: 0.14575212375880642 | validation: 0.1453544825633356]
	TIME [epoch: 26.1 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14806615114675184		[learning rate: 0.00041708]
	Learning Rate: 0.00041708
	LOSS [training: 0.14806615114675184 | validation: 0.14976327929482053]
	TIME [epoch: 26.1 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15100600396909045		[learning rate: 0.00041561]
	Learning Rate: 0.000415606
	LOSS [training: 0.15100600396909045 | validation: 0.1544101394351024]
	TIME [epoch: 26.1 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14367827171589193		[learning rate: 0.00041414]
	Learning Rate: 0.000414136
	LOSS [training: 0.14367827171589193 | validation: 0.1541665520911783]
	TIME [epoch: 26.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1522530906907754		[learning rate: 0.00041267]
	Learning Rate: 0.000412671
	LOSS [training: 0.1522530906907754 | validation: 0.15507698333210027]
	TIME [epoch: 26.1 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14455806333871468		[learning rate: 0.00041121]
	Learning Rate: 0.000411212
	LOSS [training: 0.14455806333871468 | validation: 0.159157185585727]
	TIME [epoch: 26.1 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15775693677889824		[learning rate: 0.00040976]
	Learning Rate: 0.000409758
	LOSS [training: 0.15775693677889824 | validation: 0.15412584482656672]
	TIME [epoch: 26.1 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14903649549250847		[learning rate: 0.00040831]
	Learning Rate: 0.000408309
	LOSS [training: 0.14903649549250847 | validation: 0.15466699852086305]
	TIME [epoch: 26.1 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1511746296682139		[learning rate: 0.00040687]
	Learning Rate: 0.000406865
	LOSS [training: 0.1511746296682139 | validation: 0.1452202022120511]
	TIME [epoch: 26.1 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14869993125660336		[learning rate: 0.00040543]
	Learning Rate: 0.000405426
	LOSS [training: 0.14869993125660336 | validation: 0.15388825760733202]
	TIME [epoch: 26.1 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1440584132590601		[learning rate: 0.00040399]
	Learning Rate: 0.000403993
	LOSS [training: 0.1440584132590601 | validation: 0.14798439557943519]
	TIME [epoch: 26.1 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1461369666930991		[learning rate: 0.00040256]
	Learning Rate: 0.000402564
	LOSS [training: 0.1461369666930991 | validation: 0.15078994943889834]
	TIME [epoch: 26.1 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1532212504250461		[learning rate: 0.00040114]
	Learning Rate: 0.000401141
	LOSS [training: 0.1532212504250461 | validation: 0.15241646417027177]
	TIME [epoch: 26.1 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15104491265212033		[learning rate: 0.00039972]
	Learning Rate: 0.000399722
	LOSS [training: 0.15104491265212033 | validation: 0.14691457947810757]
	TIME [epoch: 26.1 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1454849232643151		[learning rate: 0.00039831]
	Learning Rate: 0.000398309
	LOSS [training: 0.1454849232643151 | validation: 0.14729645608218198]
	TIME [epoch: 26.1 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1476929634624525		[learning rate: 0.0003969]
	Learning Rate: 0.0003969
	LOSS [training: 0.1476929634624525 | validation: 0.1446852365931302]
	TIME [epoch: 26.1 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14092208186459318		[learning rate: 0.0003955]
	Learning Rate: 0.000395497
	LOSS [training: 0.14092208186459318 | validation: 0.15322971865251062]
	TIME [epoch: 26.1 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1451477288896765		[learning rate: 0.0003941]
	Learning Rate: 0.000394098
	LOSS [training: 0.1451477288896765 | validation: 0.14450010423199997]
	TIME [epoch: 26.1 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1515049560227699		[learning rate: 0.0003927]
	Learning Rate: 0.000392705
	LOSS [training: 0.1515049560227699 | validation: 0.14973754768038852]
	TIME [epoch: 26.1 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14667144019130104		[learning rate: 0.00039132]
	Learning Rate: 0.000391316
	LOSS [training: 0.14667144019130104 | validation: 0.14769077083355095]
	TIME [epoch: 26.1 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13629990912031334		[learning rate: 0.00038993]
	Learning Rate: 0.000389932
	LOSS [training: 0.13629990912031334 | validation: 0.15456019272662808]
	TIME [epoch: 26.1 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1410538317892168		[learning rate: 0.00038855]
	Learning Rate: 0.000388553
	LOSS [training: 0.1410538317892168 | validation: 0.15147614532632603]
	TIME [epoch: 26.1 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14975868790947594		[learning rate: 0.00038718]
	Learning Rate: 0.000387179
	LOSS [training: 0.14975868790947594 | validation: 0.1448721464172461]
	TIME [epoch: 26.1 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.135808705064065		[learning rate: 0.00038581]
	Learning Rate: 0.00038581
	LOSS [training: 0.135808705064065 | validation: 0.14851192339199462]
	TIME [epoch: 26.1 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.145582649198236		[learning rate: 0.00038445]
	Learning Rate: 0.000384446
	LOSS [training: 0.145582649198236 | validation: 0.14850436658875701]
	TIME [epoch: 26.1 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15250601317420592		[learning rate: 0.00038309]
	Learning Rate: 0.000383086
	LOSS [training: 0.15250601317420592 | validation: 0.15011792192969028]
	TIME [epoch: 26.1 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14413304915436487		[learning rate: 0.00038173]
	Learning Rate: 0.000381732
	LOSS [training: 0.14413304915436487 | validation: 0.14906233763980767]
	TIME [epoch: 26.1 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14938508255284885		[learning rate: 0.00038038]
	Learning Rate: 0.000380382
	LOSS [training: 0.14938508255284885 | validation: 0.14815179180055127]
	TIME [epoch: 26.1 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1499500288008826		[learning rate: 0.00037904]
	Learning Rate: 0.000379037
	LOSS [training: 0.1499500288008826 | validation: 0.16006022825545907]
	TIME [epoch: 26.1 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14532025299680829		[learning rate: 0.0003777]
	Learning Rate: 0.000377696
	LOSS [training: 0.14532025299680829 | validation: 0.14716550043702561]
	TIME [epoch: 26.1 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14699980773532628		[learning rate: 0.00037636]
	Learning Rate: 0.000376361
	LOSS [training: 0.14699980773532628 | validation: 0.14810110679515073]
	TIME [epoch: 26.1 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1452736409285675		[learning rate: 0.00037503]
	Learning Rate: 0.00037503
	LOSS [training: 0.1452736409285675 | validation: 0.14800040831408756]
	TIME [epoch: 26.1 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1502381088629515		[learning rate: 0.0003737]
	Learning Rate: 0.000373704
	LOSS [training: 0.1502381088629515 | validation: 0.14202890214050684]
	TIME [epoch: 26.1 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14238892249951257		[learning rate: 0.00037238]
	Learning Rate: 0.000372382
	LOSS [training: 0.14238892249951257 | validation: 0.14483592197560743]
	TIME [epoch: 26.1 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14674375078958274		[learning rate: 0.00037107]
	Learning Rate: 0.000371065
	LOSS [training: 0.14674375078958274 | validation: 0.15634980412985203]
	TIME [epoch: 26.1 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1468497637995732		[learning rate: 0.00036975]
	Learning Rate: 0.000369753
	LOSS [training: 0.1468497637995732 | validation: 0.14648081382865968]
	TIME [epoch: 26.1 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14526094229151654		[learning rate: 0.00036845]
	Learning Rate: 0.000368446
	LOSS [training: 0.14526094229151654 | validation: 0.1513392510209175]
	TIME [epoch: 26.1 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14617934918214343		[learning rate: 0.00036714]
	Learning Rate: 0.000367143
	LOSS [training: 0.14617934918214343 | validation: 0.15072747866674496]
	TIME [epoch: 26.1 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13976726545360385		[learning rate: 0.00036584]
	Learning Rate: 0.000365845
	LOSS [training: 0.13976726545360385 | validation: 0.15105754807208122]
	TIME [epoch: 26.1 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14250591979276525		[learning rate: 0.00036455]
	Learning Rate: 0.000364551
	LOSS [training: 0.14250591979276525 | validation: 0.15058354998661053]
	TIME [epoch: 26.1 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15227232605773475		[learning rate: 0.00036326]
	Learning Rate: 0.000363262
	LOSS [training: 0.15227232605773475 | validation: 0.16188314829250422]
	TIME [epoch: 26.1 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14908223439286347		[learning rate: 0.00036198]
	Learning Rate: 0.000361977
	LOSS [training: 0.14908223439286347 | validation: 0.14985082955927465]
	TIME [epoch: 26.1 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14690771796586682		[learning rate: 0.0003607]
	Learning Rate: 0.000360697
	LOSS [training: 0.14690771796586682 | validation: 0.15001425989285114]
	TIME [epoch: 26.1 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14821145205887423		[learning rate: 0.00035942]
	Learning Rate: 0.000359422
	LOSS [training: 0.14821145205887423 | validation: 0.1527006284594937]
	TIME [epoch: 26.1 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1510806295305383		[learning rate: 0.00035815]
	Learning Rate: 0.000358151
	LOSS [training: 0.1510806295305383 | validation: 0.15601528996215855]
	TIME [epoch: 26.1 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14634042720570525		[learning rate: 0.00035688]
	Learning Rate: 0.000356884
	LOSS [training: 0.14634042720570525 | validation: 0.15610169722873715]
	TIME [epoch: 26.1 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14338522416386335		[learning rate: 0.00035562]
	Learning Rate: 0.000355622
	LOSS [training: 0.14338522416386335 | validation: 0.14650196301606427]
	TIME [epoch: 26.1 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15017370086695297		[learning rate: 0.00035436]
	Learning Rate: 0.000354365
	LOSS [training: 0.15017370086695297 | validation: 0.14763945852077245]
	TIME [epoch: 26.1 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14208467599546723		[learning rate: 0.00035311]
	Learning Rate: 0.000353112
	LOSS [training: 0.14208467599546723 | validation: 0.1575395564936631]
	TIME [epoch: 26.1 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14495974245830157		[learning rate: 0.00035186]
	Learning Rate: 0.000351863
	LOSS [training: 0.14495974245830157 | validation: 0.13719159280871923]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_995.pth
	Model improved!!!
EPOCH 996/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14581902915055903		[learning rate: 0.00035062]
	Learning Rate: 0.000350619
	LOSS [training: 0.14581902915055903 | validation: 0.1545760474747133]
	TIME [epoch: 26.1 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14931742061119674		[learning rate: 0.00034938]
	Learning Rate: 0.000349379
	LOSS [training: 0.14931742061119674 | validation: 0.1434646400624277]
	TIME [epoch: 26.1 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14805710224995877		[learning rate: 0.00034814]
	Learning Rate: 0.000348143
	LOSS [training: 0.14805710224995877 | validation: 0.15494492436265195]
	TIME [epoch: 26.1 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14947925253390978		[learning rate: 0.00034691]
	Learning Rate: 0.000346912
	LOSS [training: 0.14947925253390978 | validation: 0.15494121392232668]
	TIME [epoch: 26.1 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15261592302254615		[learning rate: 0.00034569]
	Learning Rate: 0.000345686
	LOSS [training: 0.15261592302254615 | validation: 0.1568819496806204]
	TIME [epoch: 26.1 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14927094699338164		[learning rate: 0.00034446]
	Learning Rate: 0.000344463
	LOSS [training: 0.14927094699338164 | validation: 0.14751189286446775]
	TIME [epoch: 26.1 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1475932783565072		[learning rate: 0.00034325]
	Learning Rate: 0.000343245
	LOSS [training: 0.1475932783565072 | validation: 0.15491688227096712]
	TIME [epoch: 26.1 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14720004499009137		[learning rate: 0.00034203]
	Learning Rate: 0.000342031
	LOSS [training: 0.14720004499009137 | validation: 0.14684952951151709]
	TIME [epoch: 26.1 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15132868862343388		[learning rate: 0.00034082]
	Learning Rate: 0.000340822
	LOSS [training: 0.15132868862343388 | validation: 0.15409451409299085]
	TIME [epoch: 26.1 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14553898061551276		[learning rate: 0.00033962]
	Learning Rate: 0.000339617
	LOSS [training: 0.14553898061551276 | validation: 0.15078046865658898]
	TIME [epoch: 26.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1470400621646331		[learning rate: 0.00033842]
	Learning Rate: 0.000338416
	LOSS [training: 0.1470400621646331 | validation: 0.14908661488222535]
	TIME [epoch: 26.1 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14581375240226194		[learning rate: 0.00033722]
	Learning Rate: 0.000337219
	LOSS [training: 0.14581375240226194 | validation: 0.15410074151968955]
	TIME [epoch: 26.1 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1526316204297078		[learning rate: 0.00033603]
	Learning Rate: 0.000336027
	LOSS [training: 0.1526316204297078 | validation: 0.15708200980196393]
	TIME [epoch: 26.1 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15007874127201695		[learning rate: 0.00033484]
	Learning Rate: 0.000334838
	LOSS [training: 0.15007874127201695 | validation: 0.15017462298188716]
	TIME [epoch: 26.1 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14595845611580716		[learning rate: 0.00033365]
	Learning Rate: 0.000333654
	LOSS [training: 0.14595845611580716 | validation: 0.1420005145613085]
	TIME [epoch: 26.1 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14959775627899388		[learning rate: 0.00033247]
	Learning Rate: 0.000332474
	LOSS [training: 0.14959775627899388 | validation: 0.1455775058025513]
	TIME [epoch: 26.1 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14807979174348213		[learning rate: 0.0003313]
	Learning Rate: 0.000331299
	LOSS [training: 0.14807979174348213 | validation: 0.14011483464442936]
	TIME [epoch: 26.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14786394575919437		[learning rate: 0.00033013]
	Learning Rate: 0.000330127
	LOSS [training: 0.14786394575919437 | validation: 0.16044369566953168]
	TIME [epoch: 26.1 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14727428223861813		[learning rate: 0.00032896]
	Learning Rate: 0.00032896
	LOSS [training: 0.14727428223861813 | validation: 0.1528048997169255]
	TIME [epoch: 26.1 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1465242571780278		[learning rate: 0.0003278]
	Learning Rate: 0.000327797
	LOSS [training: 0.1465242571780278 | validation: 0.156655701108799]
	TIME [epoch: 26.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14253383111514192		[learning rate: 0.00032664]
	Learning Rate: 0.000326637
	LOSS [training: 0.14253383111514192 | validation: 0.15261953016094176]
	TIME [epoch: 26.1 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15500173940738307		[learning rate: 0.00032548]
	Learning Rate: 0.000325482
	LOSS [training: 0.15500173940738307 | validation: 0.1503445184874979]
	TIME [epoch: 26.1 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14820775014147672		[learning rate: 0.00032433]
	Learning Rate: 0.000324331
	LOSS [training: 0.14820775014147672 | validation: 0.15649155025703135]
	TIME [epoch: 26.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15597577153718198		[learning rate: 0.00032318]
	Learning Rate: 0.000323184
	LOSS [training: 0.15597577153718198 | validation: 0.15423767227969506]
	TIME [epoch: 26.1 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14215079447533502		[learning rate: 0.00032204]
	Learning Rate: 0.000322042
	LOSS [training: 0.14215079447533502 | validation: 0.15112643434178363]
	TIME [epoch: 26.1 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14707185399871112		[learning rate: 0.0003209]
	Learning Rate: 0.000320903
	LOSS [training: 0.14707185399871112 | validation: 0.15128284824683408]
	TIME [epoch: 26.1 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14248935767369225		[learning rate: 0.00031977]
	Learning Rate: 0.000319768
	LOSS [training: 0.14248935767369225 | validation: 0.14917920673097293]
	TIME [epoch: 26.1 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14708314909233938		[learning rate: 0.00031864]
	Learning Rate: 0.000318637
	LOSS [training: 0.14708314909233938 | validation: 0.15092441706250423]
	TIME [epoch: 26.1 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14914378634402864		[learning rate: 0.00031751]
	Learning Rate: 0.000317511
	LOSS [training: 0.14914378634402864 | validation: 0.15014338614206071]
	TIME [epoch: 26.1 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14718669807582652		[learning rate: 0.00031639]
	Learning Rate: 0.000316388
	LOSS [training: 0.14718669807582652 | validation: 0.14641251609810166]
	TIME [epoch: 26.1 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1427909830085997		[learning rate: 0.00031527]
	Learning Rate: 0.000315269
	LOSS [training: 0.1427909830085997 | validation: 0.15421955556088832]
	TIME [epoch: 26.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14348645713299277		[learning rate: 0.00031415]
	Learning Rate: 0.000314154
	LOSS [training: 0.14348645713299277 | validation: 0.14501339676768146]
	TIME [epoch: 26.1 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14992130204268703		[learning rate: 0.00031304]
	Learning Rate: 0.000313043
	LOSS [training: 0.14992130204268703 | validation: 0.14846548808483928]
	TIME [epoch: 26.1 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1472916890033336		[learning rate: 0.00031194]
	Learning Rate: 0.000311936
	LOSS [training: 0.1472916890033336 | validation: 0.14903093750231475]
	TIME [epoch: 26.1 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14391399741529323		[learning rate: 0.00031083]
	Learning Rate: 0.000310833
	LOSS [training: 0.14391399741529323 | validation: 0.15305503902143622]
	TIME [epoch: 26.1 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14891501720140093		[learning rate: 0.00030973]
	Learning Rate: 0.000309734
	LOSS [training: 0.14891501720140093 | validation: 0.1404828418786727]
	TIME [epoch: 26.1 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1500609224637613		[learning rate: 0.00030864]
	Learning Rate: 0.000308639
	LOSS [training: 0.1500609224637613 | validation: 0.14717056428997682]
	TIME [epoch: 26.1 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14068638548507365		[learning rate: 0.00030755]
	Learning Rate: 0.000307547
	LOSS [training: 0.14068638548507365 | validation: 0.1460406218314612]
	TIME [epoch: 26.1 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13986260820306512		[learning rate: 0.00030646]
	Learning Rate: 0.00030646
	LOSS [training: 0.13986260820306512 | validation: 0.14447132867522497]
	TIME [epoch: 26.1 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14860013591396962		[learning rate: 0.00030538]
	Learning Rate: 0.000305376
	LOSS [training: 0.14860013591396962 | validation: 0.149251625939075]
	TIME [epoch: 26.1 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14699713770156977		[learning rate: 0.0003043]
	Learning Rate: 0.000304296
	LOSS [training: 0.14699713770156977 | validation: 0.1466878608998422]
	TIME [epoch: 26.1 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1461754042430376		[learning rate: 0.00030322]
	Learning Rate: 0.00030322
	LOSS [training: 0.1461754042430376 | validation: 0.1430851030404687]
	TIME [epoch: 26.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15346783585972168		[learning rate: 0.00030215]
	Learning Rate: 0.000302148
	LOSS [training: 0.15346783585972168 | validation: 0.15443747248737427]
	TIME [epoch: 26.1 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14924380461173906		[learning rate: 0.00030108]
	Learning Rate: 0.00030108
	LOSS [training: 0.14924380461173906 | validation: 0.16016294624310706]
	TIME [epoch: 26.1 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15120025607580476		[learning rate: 0.00030001]
	Learning Rate: 0.000300015
	LOSS [training: 0.15120025607580476 | validation: 0.14443361957670053]
	TIME [epoch: 26.1 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1460140782147997		[learning rate: 0.00029895]
	Learning Rate: 0.000298954
	LOSS [training: 0.1460140782147997 | validation: 0.1489369517040874]
	TIME [epoch: 26.1 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1512150029823334		[learning rate: 0.0002979]
	Learning Rate: 0.000297897
	LOSS [training: 0.1512150029823334 | validation: 0.1473238790803386]
	TIME [epoch: 26.1 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14312036119275987		[learning rate: 0.00029684]
	Learning Rate: 0.000296843
	LOSS [training: 0.14312036119275987 | validation: 0.15591878400682924]
	TIME [epoch: 26.1 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1449440670648255		[learning rate: 0.00029579]
	Learning Rate: 0.000295794
	LOSS [training: 0.1449440670648255 | validation: 0.15375605350995072]
	TIME [epoch: 26.1 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.143794193721353		[learning rate: 0.00029475]
	Learning Rate: 0.000294748
	LOSS [training: 0.143794193721353 | validation: 0.14800234678279686]
	TIME [epoch: 26.1 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14840348429385028		[learning rate: 0.00029371]
	Learning Rate: 0.000293705
	LOSS [training: 0.14840348429385028 | validation: 0.1435101280927513]
	TIME [epoch: 26.1 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.151235306126256		[learning rate: 0.00029267]
	Learning Rate: 0.000292667
	LOSS [training: 0.151235306126256 | validation: 0.15255078224701896]
	TIME [epoch: 26.1 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14257884046601974		[learning rate: 0.00029163]
	Learning Rate: 0.000291632
	LOSS [training: 0.14257884046601974 | validation: 0.15031437548920287]
	TIME [epoch: 26.1 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14577436417589867		[learning rate: 0.0002906]
	Learning Rate: 0.000290601
	LOSS [training: 0.14577436417589867 | validation: 0.1527448307402604]
	TIME [epoch: 26.1 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14274323698285246		[learning rate: 0.00028957]
	Learning Rate: 0.000289573
	LOSS [training: 0.14274323698285246 | validation: 0.1452923413697205]
	TIME [epoch: 26.1 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14894613317966268		[learning rate: 0.00028855]
	Learning Rate: 0.000288549
	LOSS [training: 0.14894613317966268 | validation: 0.14724188465707574]
	TIME [epoch: 26.1 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15186143536404564		[learning rate: 0.00028753]
	Learning Rate: 0.000287529
	LOSS [training: 0.15186143536404564 | validation: 0.15574470527868942]
	TIME [epoch: 26.1 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14633622248593164		[learning rate: 0.00028651]
	Learning Rate: 0.000286512
	LOSS [training: 0.14633622248593164 | validation: 0.14610614577322212]
	TIME [epoch: 26.1 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14737256885795288		[learning rate: 0.0002855]
	Learning Rate: 0.000285499
	LOSS [training: 0.14737256885795288 | validation: 0.1526993213164777]
	TIME [epoch: 26.1 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1414650968716143		[learning rate: 0.00028449]
	Learning Rate: 0.000284489
	LOSS [training: 0.1414650968716143 | validation: 0.1471687477939651]
	TIME [epoch: 26.1 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1452497795783896		[learning rate: 0.00028348]
	Learning Rate: 0.000283483
	LOSS [training: 0.1452497795783896 | validation: 0.15050804598273954]
	TIME [epoch: 26.1 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14725703550568742		[learning rate: 0.00028248]
	Learning Rate: 0.000282481
	LOSS [training: 0.14725703550568742 | validation: 0.14996147695853515]
	TIME [epoch: 26.1 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15721041638355504		[learning rate: 0.00028148]
	Learning Rate: 0.000281482
	LOSS [training: 0.15721041638355504 | validation: 0.14392309860075306]
	TIME [epoch: 26.1 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1395835968721336		[learning rate: 0.00028049]
	Learning Rate: 0.000280487
	LOSS [training: 0.1395835968721336 | validation: 0.14906695176554383]
	TIME [epoch: 26.1 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14536256300108505		[learning rate: 0.00027949]
	Learning Rate: 0.000279495
	LOSS [training: 0.14536256300108505 | validation: 0.1421896867292988]
	TIME [epoch: 26.1 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1448005360842441		[learning rate: 0.00027851]
	Learning Rate: 0.000278506
	LOSS [training: 0.1448005360842441 | validation: 0.15656592097607272]
	TIME [epoch: 26.1 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14702717809957935		[learning rate: 0.00027752]
	Learning Rate: 0.000277522
	LOSS [training: 0.14702717809957935 | validation: 0.14279109076504518]
	TIME [epoch: 26.1 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14383890223080156		[learning rate: 0.00027654]
	Learning Rate: 0.00027654
	LOSS [training: 0.14383890223080156 | validation: 0.16438749383850612]
	TIME [epoch: 26.1 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14343999236094246		[learning rate: 0.00027556]
	Learning Rate: 0.000275562
	LOSS [training: 0.14343999236094246 | validation: 0.14576376363585278]
	TIME [epoch: 26.1 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14255772433809072		[learning rate: 0.00027459]
	Learning Rate: 0.000274588
	LOSS [training: 0.14255772433809072 | validation: 0.15021998611340323]
	TIME [epoch: 26.1 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14742475444602418		[learning rate: 0.00027362]
	Learning Rate: 0.000273617
	LOSS [training: 0.14742475444602418 | validation: 0.14628797132535792]
	TIME [epoch: 26.1 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14490838572525352		[learning rate: 0.00027265]
	Learning Rate: 0.000272649
	LOSS [training: 0.14490838572525352 | validation: 0.1480429068248572]
	TIME [epoch: 26.1 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15255437565306088		[learning rate: 0.00027169]
	Learning Rate: 0.000271685
	LOSS [training: 0.15255437565306088 | validation: 0.14603877632821535]
	TIME [epoch: 26.1 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14308381364412145		[learning rate: 0.00027072]
	Learning Rate: 0.000270724
	LOSS [training: 0.14308381364412145 | validation: 0.14872419076862245]
	TIME [epoch: 26.1 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1442308714908991		[learning rate: 0.00026977]
	Learning Rate: 0.000269767
	LOSS [training: 0.1442308714908991 | validation: 0.15063007026724096]
	TIME [epoch: 26.1 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1486445961099156		[learning rate: 0.00026881]
	Learning Rate: 0.000268813
	LOSS [training: 0.1486445961099156 | validation: 0.15688312507781713]
	TIME [epoch: 26.1 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14366046108385871		[learning rate: 0.00026786]
	Learning Rate: 0.000267863
	LOSS [training: 0.14366046108385871 | validation: 0.15325449531989122]
	TIME [epoch: 26.1 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14934538599900554		[learning rate: 0.00026692]
	Learning Rate: 0.000266915
	LOSS [training: 0.14934538599900554 | validation: 0.14600883604085116]
	TIME [epoch: 26.1 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14299321517452768		[learning rate: 0.00026597]
	Learning Rate: 0.000265972
	LOSS [training: 0.14299321517452768 | validation: 0.15931958630322995]
	TIME [epoch: 26.1 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15063693149206156		[learning rate: 0.00026503]
	Learning Rate: 0.000265031
	LOSS [training: 0.15063693149206156 | validation: 0.15759280924182886]
	TIME [epoch: 26.1 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15331200500880932		[learning rate: 0.00026409]
	Learning Rate: 0.000264094
	LOSS [training: 0.15331200500880932 | validation: 0.15320758054628528]
	TIME [epoch: 26.1 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1398437279624988		[learning rate: 0.00026316]
	Learning Rate: 0.00026316
	LOSS [training: 0.1398437279624988 | validation: 0.14893368690866549]
	TIME [epoch: 26.1 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14654682905133123		[learning rate: 0.00026223]
	Learning Rate: 0.000262229
	LOSS [training: 0.14654682905133123 | validation: 0.1587949636770204]
	TIME [epoch: 26.1 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14522392171986986		[learning rate: 0.0002613]
	Learning Rate: 0.000261302
	LOSS [training: 0.14522392171986986 | validation: 0.14999275359032044]
	TIME [epoch: 26.1 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1504210751901859		[learning rate: 0.00026038]
	Learning Rate: 0.000260378
	LOSS [training: 0.1504210751901859 | validation: 0.15412614175081604]
	TIME [epoch: 26.1 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1489342073238825		[learning rate: 0.00025946]
	Learning Rate: 0.000259457
	LOSS [training: 0.1489342073238825 | validation: 0.15352397374736132]
	TIME [epoch: 26.1 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14860238208332896		[learning rate: 0.00025854]
	Learning Rate: 0.00025854
	LOSS [training: 0.14860238208332896 | validation: 0.14449363010417834]
	TIME [epoch: 26.1 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15370649821474672		[learning rate: 0.00025763]
	Learning Rate: 0.000257626
	LOSS [training: 0.15370649821474672 | validation: 0.15289035254642996]
	TIME [epoch: 26.1 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14975883992770495		[learning rate: 0.00025671]
	Learning Rate: 0.000256715
	LOSS [training: 0.14975883992770495 | validation: 0.14713868845660816]
	TIME [epoch: 26.1 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1517452634188677		[learning rate: 0.00025581]
	Learning Rate: 0.000255807
	LOSS [training: 0.1517452634188677 | validation: 0.1464005100558598]
	TIME [epoch: 26.1 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14429638345244764		[learning rate: 0.0002549]
	Learning Rate: 0.000254902
	LOSS [training: 0.14429638345244764 | validation: 0.1497268712200986]
	TIME [epoch: 26.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15315883050562754		[learning rate: 0.000254]
	Learning Rate: 0.000254001
	LOSS [training: 0.15315883050562754 | validation: 0.1369825716504986]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14787926556094222		[learning rate: 0.0002531]
	Learning Rate: 0.000253103
	LOSS [training: 0.14787926556094222 | validation: 0.14410120714161415]
	TIME [epoch: 26.1 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.142250523240699		[learning rate: 0.00025221]
	Learning Rate: 0.000252208
	LOSS [training: 0.142250523240699 | validation: 0.15355694637529504]
	TIME [epoch: 26.1 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1468384568030518		[learning rate: 0.00025132]
	Learning Rate: 0.000251316
	LOSS [training: 0.1468384568030518 | validation: 0.13878554224408507]
	TIME [epoch: 26.1 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14401128795675655		[learning rate: 0.00025043]
	Learning Rate: 0.000250427
	LOSS [training: 0.14401128795675655 | validation: 0.1502725818829824]
	TIME [epoch: 26.1 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14846412732125988		[learning rate: 0.00024954]
	Learning Rate: 0.000249542
	LOSS [training: 0.14846412732125988 | validation: 0.15465400655749922]
	TIME [epoch: 26.1 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14769424378937532		[learning rate: 0.00024866]
	Learning Rate: 0.000248659
	LOSS [training: 0.14769424378937532 | validation: 0.155720067246931]
	TIME [epoch: 26.1 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1470160396217292		[learning rate: 0.00024778]
	Learning Rate: 0.00024778
	LOSS [training: 0.1470160396217292 | validation: 0.1467832641589213]
	TIME [epoch: 26.1 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14611457654011578		[learning rate: 0.0002469]
	Learning Rate: 0.000246904
	LOSS [training: 0.14611457654011578 | validation: 0.14472138177847518]
	TIME [epoch: 26.1 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14564649916329714		[learning rate: 0.00024603]
	Learning Rate: 0.00024603
	LOSS [training: 0.14564649916329714 | validation: 0.1513795744954129]
	TIME [epoch: 26.1 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14033151635779526		[learning rate: 0.00024516]
	Learning Rate: 0.00024516
	LOSS [training: 0.14033151635779526 | validation: 0.14804425259049128]
	TIME [epoch: 26.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14938894371104808		[learning rate: 0.00024429]
	Learning Rate: 0.000244294
	LOSS [training: 0.14938894371104808 | validation: 0.15295842624397735]
	TIME [epoch: 26.1 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1461224973294122		[learning rate: 0.00024343]
	Learning Rate: 0.00024343
	LOSS [training: 0.1461224973294122 | validation: 0.1550752333065448]
	TIME [epoch: 26.1 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1443241755530523		[learning rate: 0.00024257]
	Learning Rate: 0.000242569
	LOSS [training: 0.1443241755530523 | validation: 0.1500953152581983]
	TIME [epoch: 26.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14921014277999706		[learning rate: 0.00024171]
	Learning Rate: 0.000241711
	LOSS [training: 0.14921014277999706 | validation: 0.15432434312548418]
	TIME [epoch: 26.1 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14417543863867818		[learning rate: 0.00024086]
	Learning Rate: 0.000240856
	LOSS [training: 0.14417543863867818 | validation: 0.15109854587838986]
	TIME [epoch: 26.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14219446070356034		[learning rate: 0.00024]
	Learning Rate: 0.000240005
	LOSS [training: 0.14219446070356034 | validation: 0.15911454461962996]
	TIME [epoch: 26.1 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1491361365805483		[learning rate: 0.00023916]
	Learning Rate: 0.000239156
	LOSS [training: 0.1491361365805483 | validation: 0.1432224044671909]
	TIME [epoch: 26.1 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1474805006808257		[learning rate: 0.00023831]
	Learning Rate: 0.00023831
	LOSS [training: 0.1474805006808257 | validation: 0.1501878616833901]
	TIME [epoch: 26.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14885402862394304		[learning rate: 0.00023747]
	Learning Rate: 0.000237468
	LOSS [training: 0.14885402862394304 | validation: 0.1546884379662286]
	TIME [epoch: 26.1 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14564090649876574		[learning rate: 0.00023663]
	Learning Rate: 0.000236628
	LOSS [training: 0.14564090649876574 | validation: 0.14674223305369472]
	TIME [epoch: 26.1 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1385006311129095		[learning rate: 0.00023579]
	Learning Rate: 0.000235791
	LOSS [training: 0.1385006311129095 | validation: 0.1407831397253643]
	TIME [epoch: 26.1 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1471782793463888		[learning rate: 0.00023496]
	Learning Rate: 0.000234957
	LOSS [training: 0.1471782793463888 | validation: 0.15077583660396027]
	TIME [epoch: 26.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14233876759171757		[learning rate: 0.00023413]
	Learning Rate: 0.000234126
	LOSS [training: 0.14233876759171757 | validation: 0.15532452349362225]
	TIME [epoch: 26.1 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15254285087762237		[learning rate: 0.0002333]
	Learning Rate: 0.000233299
	LOSS [training: 0.15254285087762237 | validation: 0.1549562831654168]
	TIME [epoch: 26.1 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1457607927057154		[learning rate: 0.00023247]
	Learning Rate: 0.000232474
	LOSS [training: 0.1457607927057154 | validation: 0.15034885554732644]
	TIME [epoch: 26.1 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14287133618945816		[learning rate: 0.00023165]
	Learning Rate: 0.000231651
	LOSS [training: 0.14287133618945816 | validation: 0.15637625814738107]
	TIME [epoch: 26.1 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14773187358284146		[learning rate: 0.00023083]
	Learning Rate: 0.000230832
	LOSS [training: 0.14773187358284146 | validation: 0.14234182400231893]
	TIME [epoch: 26.1 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14917605188625008		[learning rate: 0.00023002]
	Learning Rate: 0.000230016
	LOSS [training: 0.14917605188625008 | validation: 0.14436095484968656]
	TIME [epoch: 26.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1486367960583232		[learning rate: 0.0002292]
	Learning Rate: 0.000229203
	LOSS [training: 0.1486367960583232 | validation: 0.15051495882000554]
	TIME [epoch: 26.1 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14755023869813264		[learning rate: 0.00022839]
	Learning Rate: 0.000228392
	LOSS [training: 0.14755023869813264 | validation: 0.15217153311186535]
	TIME [epoch: 26.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14468061557052556		[learning rate: 0.00022758]
	Learning Rate: 0.000227585
	LOSS [training: 0.14468061557052556 | validation: 0.14295715913939316]
	TIME [epoch: 26.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15076702892107674		[learning rate: 0.00022678]
	Learning Rate: 0.00022678
	LOSS [training: 0.15076702892107674 | validation: 0.14530734779993895]
	TIME [epoch: 26.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14713302366812164		[learning rate: 0.00022598]
	Learning Rate: 0.000225978
	LOSS [training: 0.14713302366812164 | validation: 0.15027326966318494]
	TIME [epoch: 26.1 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15247748907843667		[learning rate: 0.00022518]
	Learning Rate: 0.000225179
	LOSS [training: 0.15247748907843667 | validation: 0.1530273973853768]
	TIME [epoch: 26.1 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14591751710314477		[learning rate: 0.00022438]
	Learning Rate: 0.000224383
	LOSS [training: 0.14591751710314477 | validation: 0.14189632078364328]
	TIME [epoch: 26.1 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15029954829010125		[learning rate: 0.00022359]
	Learning Rate: 0.000223589
	LOSS [training: 0.15029954829010125 | validation: 0.1479149277727707]
	TIME [epoch: 26.1 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1475971977561599		[learning rate: 0.0002228]
	Learning Rate: 0.000222798
	LOSS [training: 0.1475971977561599 | validation: 0.15185015550643005]
	TIME [epoch: 26.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14214997477199448		[learning rate: 0.00022201]
	Learning Rate: 0.000222011
	LOSS [training: 0.14214997477199448 | validation: 0.15416001316131683]
	TIME [epoch: 26.1 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14798018832595541		[learning rate: 0.00022123]
	Learning Rate: 0.000221225
	LOSS [training: 0.14798018832595541 | validation: 0.1503196411876923]
	TIME [epoch: 26.1 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15025586746088032		[learning rate: 0.00022044]
	Learning Rate: 0.000220443
	LOSS [training: 0.15025586746088032 | validation: 0.14888782138414342]
	TIME [epoch: 26.1 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1426849169799068		[learning rate: 0.00021966]
	Learning Rate: 0.000219664
	LOSS [training: 0.1426849169799068 | validation: 0.14622659331737659]
	TIME [epoch: 26.1 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1521900228297117		[learning rate: 0.00021889]
	Learning Rate: 0.000218887
	LOSS [training: 0.1521900228297117 | validation: 0.14974024459288654]
	TIME [epoch: 26.1 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15246529517183108		[learning rate: 0.00021811]
	Learning Rate: 0.000218113
	LOSS [training: 0.15246529517183108 | validation: 0.14422309746312872]
	TIME [epoch: 26.1 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14244027378507365		[learning rate: 0.00021734]
	Learning Rate: 0.000217342
	LOSS [training: 0.14244027378507365 | validation: 0.14870461021986003]
	TIME [epoch: 26.1 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1453742357299163		[learning rate: 0.00021657]
	Learning Rate: 0.000216573
	LOSS [training: 0.1453742357299163 | validation: 0.15521348542698638]
	TIME [epoch: 26.1 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14854706191286096		[learning rate: 0.00021581]
	Learning Rate: 0.000215807
	LOSS [training: 0.14854706191286096 | validation: 0.15242184996083558]
	TIME [epoch: 26.1 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14340354039264905		[learning rate: 0.00021504]
	Learning Rate: 0.000215044
	LOSS [training: 0.14340354039264905 | validation: 0.14815854792194982]
	TIME [epoch: 26.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14673030287251873		[learning rate: 0.00021428]
	Learning Rate: 0.000214284
	LOSS [training: 0.14673030287251873 | validation: 0.15319658041833564]
	TIME [epoch: 26.1 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14163197203471503		[learning rate: 0.00021353]
	Learning Rate: 0.000213526
	LOSS [training: 0.14163197203471503 | validation: 0.13832710338955256]
	TIME [epoch: 26.1 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13730350878445527		[learning rate: 0.00021277]
	Learning Rate: 0.000212771
	LOSS [training: 0.13730350878445527 | validation: 0.15356768569984452]
	TIME [epoch: 26.1 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14495828033992494		[learning rate: 0.00021202]
	Learning Rate: 0.000212018
	LOSS [training: 0.14495828033992494 | validation: 0.15018476012048998]
	TIME [epoch: 26.1 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13825434450268026		[learning rate: 0.00021127]
	Learning Rate: 0.000211269
	LOSS [training: 0.13825434450268026 | validation: 0.15174667141573067]
	TIME [epoch: 26.1 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14954271394823465		[learning rate: 0.00021052]
	Learning Rate: 0.000210522
	LOSS [training: 0.14954271394823465 | validation: 0.1510423754037562]
	TIME [epoch: 26.1 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14322111233686538		[learning rate: 0.00020978]
	Learning Rate: 0.000209777
	LOSS [training: 0.14322111233686538 | validation: 0.15197575111791883]
	TIME [epoch: 26.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14367062475842254		[learning rate: 0.00020904]
	Learning Rate: 0.000209035
	LOSS [training: 0.14367062475842254 | validation: 0.1383420145025439]
	TIME [epoch: 26.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.143550510077355		[learning rate: 0.0002083]
	Learning Rate: 0.000208296
	LOSS [training: 0.143550510077355 | validation: 0.15403886641837675]
	TIME [epoch: 26.1 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14378863502679354		[learning rate: 0.00020756]
	Learning Rate: 0.00020756
	LOSS [training: 0.14378863502679354 | validation: 0.14964768246105162]
	TIME [epoch: 26.1 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14553651581638202		[learning rate: 0.00020683]
	Learning Rate: 0.000206826
	LOSS [training: 0.14553651581638202 | validation: 0.14859702601753028]
	TIME [epoch: 26.1 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1426836185862512		[learning rate: 0.00020609]
	Learning Rate: 0.000206094
	LOSS [training: 0.1426836185862512 | validation: 0.15294922240915804]
	TIME [epoch: 26.1 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15184011718607518		[learning rate: 0.00020537]
	Learning Rate: 0.000205365
	LOSS [training: 0.15184011718607518 | validation: 0.1450765781923097]
	TIME [epoch: 26.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1514231619050508		[learning rate: 0.00020464]
	Learning Rate: 0.000204639
	LOSS [training: 0.1514231619050508 | validation: 0.1448821141048103]
	TIME [epoch: 26.1 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.140221990716997		[learning rate: 0.00020392]
	Learning Rate: 0.000203916
	LOSS [training: 0.140221990716997 | validation: 0.15252108870104047]
	TIME [epoch: 26.1 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14086944421831799		[learning rate: 0.00020319]
	Learning Rate: 0.000203195
	LOSS [training: 0.14086944421831799 | validation: 0.15311792440915808]
	TIME [epoch: 26.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14267874037904527		[learning rate: 0.00020248]
	Learning Rate: 0.000202476
	LOSS [training: 0.14267874037904527 | validation: 0.14830934662089512]
	TIME [epoch: 26.1 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15176092432351362		[learning rate: 0.00020176]
	Learning Rate: 0.00020176
	LOSS [training: 0.15176092432351362 | validation: 0.14897678806883574]
	TIME [epoch: 26.1 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14635168104626853		[learning rate: 0.00020105]
	Learning Rate: 0.000201047
	LOSS [training: 0.14635168104626853 | validation: 0.14481988852290448]
	TIME [epoch: 26.1 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14732739113150412		[learning rate: 0.00020034]
	Learning Rate: 0.000200336
	LOSS [training: 0.14732739113150412 | validation: 0.1475577934019389]
	TIME [epoch: 26.1 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1431671527702308		[learning rate: 0.00019963]
	Learning Rate: 0.000199627
	LOSS [training: 0.1431671527702308 | validation: 0.15152253748491054]
	TIME [epoch: 26.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15660244397982903		[learning rate: 0.00019892]
	Learning Rate: 0.000198921
	LOSS [training: 0.15660244397982903 | validation: 0.15060602038223186]
	TIME [epoch: 26.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14895826867396295		[learning rate: 0.00019822]
	Learning Rate: 0.000198218
	LOSS [training: 0.14895826867396295 | validation: 0.15342904779071262]
	TIME [epoch: 26.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13813734248269324		[learning rate: 0.00019752]
	Learning Rate: 0.000197517
	LOSS [training: 0.13813734248269324 | validation: 0.15548636578467892]
	TIME [epoch: 26.1 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14260654953494528		[learning rate: 0.00019682]
	Learning Rate: 0.000196818
	LOSS [training: 0.14260654953494528 | validation: 0.15425418148657355]
	TIME [epoch: 26.1 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1493069287240008		[learning rate: 0.00019612]
	Learning Rate: 0.000196122
	LOSS [training: 0.1493069287240008 | validation: 0.15051768847908925]
	TIME [epoch: 26.1 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14722426655320506		[learning rate: 0.00019543]
	Learning Rate: 0.000195429
	LOSS [training: 0.14722426655320506 | validation: 0.1495298492513809]
	TIME [epoch: 26.1 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14927597072490492		[learning rate: 0.00019474]
	Learning Rate: 0.000194738
	LOSS [training: 0.14927597072490492 | validation: 0.14452434232405945]
	TIME [epoch: 26.1 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15235520727962823		[learning rate: 0.00019405]
	Learning Rate: 0.000194049
	LOSS [training: 0.15235520727962823 | validation: 0.1541238723590756]
	TIME [epoch: 26.1 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1524649301214991		[learning rate: 0.00019336]
	Learning Rate: 0.000193363
	LOSS [training: 0.1524649301214991 | validation: 0.1456223214966365]
	TIME [epoch: 26.1 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1429433901189288		[learning rate: 0.00019268]
	Learning Rate: 0.000192679
	LOSS [training: 0.1429433901189288 | validation: 0.14414190386194425]
	TIME [epoch: 26.1 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15522083199166434		[learning rate: 0.000192]
	Learning Rate: 0.000191998
	LOSS [training: 0.15522083199166434 | validation: 0.15137446180251563]
	TIME [epoch: 26.1 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1489794608830144		[learning rate: 0.00019132]
	Learning Rate: 0.000191319
	LOSS [training: 0.1489794608830144 | validation: 0.15604854294474116]
	TIME [epoch: 26.1 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15055407679652996		[learning rate: 0.00019064]
	Learning Rate: 0.000190643
	LOSS [training: 0.15055407679652996 | validation: 0.15395017132026756]
	TIME [epoch: 26.1 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14892060187627681		[learning rate: 0.00018997]
	Learning Rate: 0.000189968
	LOSS [training: 0.14892060187627681 | validation: 0.14895373340063284]
	TIME [epoch: 26.1 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14689738436205255		[learning rate: 0.0001893]
	Learning Rate: 0.000189297
	LOSS [training: 0.14689738436205255 | validation: 0.14706580138286504]
	TIME [epoch: 26.1 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14762303708802557		[learning rate: 0.00018863]
	Learning Rate: 0.000188627
	LOSS [training: 0.14762303708802557 | validation: 0.15052886895744738]
	TIME [epoch: 26.1 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14331687686012856		[learning rate: 0.00018796]
	Learning Rate: 0.00018796
	LOSS [training: 0.14331687686012856 | validation: 0.1417586159003097]
	TIME [epoch: 26.1 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14548059849237358		[learning rate: 0.0001873]
	Learning Rate: 0.000187296
	LOSS [training: 0.14548059849237358 | validation: 0.14035118051668524]
	TIME [epoch: 26.1 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14431997837212704		[learning rate: 0.00018663]
	Learning Rate: 0.000186633
	LOSS [training: 0.14431997837212704 | validation: 0.1486111813562402]
	TIME [epoch: 26.1 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13985575422240484		[learning rate: 0.00018597]
	Learning Rate: 0.000185973
	LOSS [training: 0.13985575422240484 | validation: 0.14624880511209248]
	TIME [epoch: 26.1 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14528086345226368		[learning rate: 0.00018532]
	Learning Rate: 0.000185316
	LOSS [training: 0.14528086345226368 | validation: 0.15046885026864523]
	TIME [epoch: 26.1 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1516171123232175		[learning rate: 0.00018466]
	Learning Rate: 0.00018466
	LOSS [training: 0.1516171123232175 | validation: 0.15147471956755726]
	TIME [epoch: 26.1 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1441248658973949		[learning rate: 0.00018401]
	Learning Rate: 0.000184007
	LOSS [training: 0.1441248658973949 | validation: 0.14175733907908558]
	TIME [epoch: 26.1 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15282285461284403		[learning rate: 0.00018336]
	Learning Rate: 0.000183357
	LOSS [training: 0.15282285461284403 | validation: 0.1513528479950288]
	TIME [epoch: 26.1 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1437162285264924		[learning rate: 0.00018271]
	Learning Rate: 0.000182708
	LOSS [training: 0.1437162285264924 | validation: 0.15228975068355474]
	TIME [epoch: 26.1 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14613970204748097		[learning rate: 0.00018206]
	Learning Rate: 0.000182062
	LOSS [training: 0.14613970204748097 | validation: 0.14504036256213093]
	TIME [epoch: 26.1 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14252165359931826		[learning rate: 0.00018142]
	Learning Rate: 0.000181418
	LOSS [training: 0.14252165359931826 | validation: 0.15014919777883368]
	TIME [epoch: 26.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14265093969597878		[learning rate: 0.00018078]
	Learning Rate: 0.000180777
	LOSS [training: 0.14265093969597878 | validation: 0.15074387316337437]
	TIME [epoch: 26.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14268216524577115		[learning rate: 0.00018014]
	Learning Rate: 0.000180138
	LOSS [training: 0.14268216524577115 | validation: 0.15045309923292036]
	TIME [epoch: 26.1 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1409618973133328		[learning rate: 0.0001795]
	Learning Rate: 0.000179501
	LOSS [training: 0.1409618973133328 | validation: 0.1670983443236475]
	TIME [epoch: 26.1 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14628656367210516		[learning rate: 0.00017887]
	Learning Rate: 0.000178866
	LOSS [training: 0.14628656367210516 | validation: 0.15518116589650566]
	TIME [epoch: 26.1 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15233280581858386		[learning rate: 0.00017823]
	Learning Rate: 0.000178233
	LOSS [training: 0.15233280581858386 | validation: 0.1490212755135112]
	TIME [epoch: 26.1 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14445199179162624		[learning rate: 0.0001776]
	Learning Rate: 0.000177603
	LOSS [training: 0.14445199179162624 | validation: 0.15467269026916708]
	TIME [epoch: 26.1 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15103035653421706		[learning rate: 0.00017698]
	Learning Rate: 0.000176975
	LOSS [training: 0.15103035653421706 | validation: 0.15227426807570527]
	TIME [epoch: 26.1 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14353748808782243		[learning rate: 0.00017635]
	Learning Rate: 0.000176349
	LOSS [training: 0.14353748808782243 | validation: 0.14291507454755575]
	TIME [epoch: 26.1 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1464683404244594		[learning rate: 0.00017573]
	Learning Rate: 0.000175726
	LOSS [training: 0.1464683404244594 | validation: 0.15384386026863575]
	TIME [epoch: 26.1 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14997036310059128		[learning rate: 0.0001751]
	Learning Rate: 0.000175104
	LOSS [training: 0.14997036310059128 | validation: 0.14650241979414333]
	TIME [epoch: 26.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15141565544717064		[learning rate: 0.00017449]
	Learning Rate: 0.000174485
	LOSS [training: 0.15141565544717064 | validation: 0.1416260738915538]
	TIME [epoch: 26.1 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15289562533308693		[learning rate: 0.00017387]
	Learning Rate: 0.000173868
	LOSS [training: 0.15289562533308693 | validation: 0.14551104739271337]
	TIME [epoch: 26.1 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15272704143645277		[learning rate: 0.00017325]
	Learning Rate: 0.000173253
	LOSS [training: 0.15272704143645277 | validation: 0.14877849693702902]
	TIME [epoch: 26.1 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13992587348235982		[learning rate: 0.00017264]
	Learning Rate: 0.000172641
	LOSS [training: 0.13992587348235982 | validation: 0.14304015597463982]
	TIME [epoch: 26.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14700796805850008		[learning rate: 0.00017203]
	Learning Rate: 0.00017203
	LOSS [training: 0.14700796805850008 | validation: 0.14743681179512552]
	TIME [epoch: 26.1 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14827148002356455		[learning rate: 0.00017142]
	Learning Rate: 0.000171422
	LOSS [training: 0.14827148002356455 | validation: 0.1575939486168942]
	TIME [epoch: 26.1 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14708223301479942		[learning rate: 0.00017082]
	Learning Rate: 0.000170816
	LOSS [training: 0.14708223301479942 | validation: 0.15058592320083977]
	TIME [epoch: 26.1 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1504006140675956		[learning rate: 0.00017021]
	Learning Rate: 0.000170211
	LOSS [training: 0.1504006140675956 | validation: 0.14145425472312717]
	TIME [epoch: 26.1 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14674850120866006		[learning rate: 0.00016961]
	Learning Rate: 0.00016961
	LOSS [training: 0.14674850120866006 | validation: 0.1475596889320305]
	TIME [epoch: 26.1 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1437989418704833		[learning rate: 0.00016901]
	Learning Rate: 0.00016901
	LOSS [training: 0.1437989418704833 | validation: 0.14671939507434506]
	TIME [epoch: 26.1 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14567689368710576		[learning rate: 0.00016841]
	Learning Rate: 0.000168412
	LOSS [training: 0.14567689368710576 | validation: 0.14743240067834404]
	TIME [epoch: 26.1 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15277144238128887		[learning rate: 0.00016782]
	Learning Rate: 0.000167817
	LOSS [training: 0.15277144238128887 | validation: 0.15604106531648465]
	TIME [epoch: 26.1 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13813211482023144		[learning rate: 0.00016722]
	Learning Rate: 0.000167223
	LOSS [training: 0.13813211482023144 | validation: 0.15113763667834218]
	TIME [epoch: 26.1 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14067791808399935		[learning rate: 0.00016663]
	Learning Rate: 0.000166632
	LOSS [training: 0.14067791808399935 | validation: 0.15076744602538839]
	TIME [epoch: 26.1 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1446345338492971		[learning rate: 0.00016604]
	Learning Rate: 0.000166043
	LOSS [training: 0.1446345338492971 | validation: 0.15083321334464173]
	TIME [epoch: 26.1 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1448812925779923		[learning rate: 0.00016546]
	Learning Rate: 0.000165456
	LOSS [training: 0.1448812925779923 | validation: 0.14951756281242173]
	TIME [epoch: 26.1 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15075210259221228		[learning rate: 0.00016487]
	Learning Rate: 0.00016487
	LOSS [training: 0.15075210259221228 | validation: 0.15655076645170093]
	TIME [epoch: 26.1 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1469699960354013		[learning rate: 0.00016429]
	Learning Rate: 0.000164287
	LOSS [training: 0.1469699960354013 | validation: 0.14845879435040252]
	TIME [epoch: 26.1 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14935546315376705		[learning rate: 0.00016371]
	Learning Rate: 0.000163707
	LOSS [training: 0.14935546315376705 | validation: 0.14835965387341624]
	TIME [epoch: 26.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14724666192267152		[learning rate: 0.00016313]
	Learning Rate: 0.000163128
	LOSS [training: 0.14724666192267152 | validation: 0.15925909749372325]
	TIME [epoch: 26.1 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1411462104221029		[learning rate: 0.00016255]
	Learning Rate: 0.000162551
	LOSS [training: 0.1411462104221029 | validation: 0.14828508898628448]
	TIME [epoch: 26.1 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14558874177582376		[learning rate: 0.00016198]
	Learning Rate: 0.000161976
	LOSS [training: 0.14558874177582376 | validation: 0.14767776285225295]
	TIME [epoch: 26.1 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14529122590099566		[learning rate: 0.0001614]
	Learning Rate: 0.000161403
	LOSS [training: 0.14529122590099566 | validation: 0.1540331681405845]
	TIME [epoch: 26.1 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14080591828290237		[learning rate: 0.00016083]
	Learning Rate: 0.000160832
	LOSS [training: 0.14080591828290237 | validation: 0.14980045258804725]
	TIME [epoch: 26.1 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1379592443341117		[learning rate: 0.00016026]
	Learning Rate: 0.000160264
	LOSS [training: 0.1379592443341117 | validation: 0.14141150562793875]
	TIME [epoch: 26.1 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14968475917822438		[learning rate: 0.0001597]
	Learning Rate: 0.000159697
	LOSS [training: 0.14968475917822438 | validation: 0.16012083628574528]
	TIME [epoch: 26.1 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15118384890053468		[learning rate: 0.00015913]
	Learning Rate: 0.000159132
	LOSS [training: 0.15118384890053468 | validation: 0.14930814422828298]
	TIME [epoch: 26.1 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14784697117524725		[learning rate: 0.00015857]
	Learning Rate: 0.00015857
	LOSS [training: 0.14784697117524725 | validation: 0.1458191308119746]
	TIME [epoch: 26.1 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14591550179153087		[learning rate: 0.00015801]
	Learning Rate: 0.000158009
	LOSS [training: 0.14591550179153087 | validation: 0.1553356961175108]
	TIME [epoch: 26.1 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14545892272079555		[learning rate: 0.00015745]
	Learning Rate: 0.00015745
	LOSS [training: 0.14545892272079555 | validation: 0.15464849396228914]
	TIME [epoch: 26.1 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14597075329533693		[learning rate: 0.00015689]
	Learning Rate: 0.000156893
	LOSS [training: 0.14597075329533693 | validation: 0.14787193336520932]
	TIME [epoch: 26.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1492892426038719		[learning rate: 0.00015634]
	Learning Rate: 0.000156338
	LOSS [training: 0.1492892426038719 | validation: 0.15296610505993996]
	TIME [epoch: 26.1 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14977823338562551		[learning rate: 0.00015579]
	Learning Rate: 0.000155786
	LOSS [training: 0.14977823338562551 | validation: 0.14514287504013035]
	TIME [epoch: 26.1 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14438472914472086		[learning rate: 0.00015523]
	Learning Rate: 0.000155235
	LOSS [training: 0.14438472914472086 | validation: 0.15884429091120505]
	TIME [epoch: 26.1 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14806447864081723		[learning rate: 0.00015469]
	Learning Rate: 0.000154686
	LOSS [training: 0.14806447864081723 | validation: 0.15281878397647958]
	TIME [epoch: 26.1 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14982669125671563		[learning rate: 0.00015414]
	Learning Rate: 0.000154139
	LOSS [training: 0.14982669125671563 | validation: 0.14647355412843904]
	TIME [epoch: 26.1 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15007573750206665		[learning rate: 0.00015359]
	Learning Rate: 0.000153594
	LOSS [training: 0.15007573750206665 | validation: 0.15493067563032992]
	TIME [epoch: 26.1 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14549984550003195		[learning rate: 0.00015305]
	Learning Rate: 0.000153051
	LOSS [training: 0.14549984550003195 | validation: 0.15772669852287602]
	TIME [epoch: 26.1 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14696589582123348		[learning rate: 0.00015251]
	Learning Rate: 0.000152509
	LOSS [training: 0.14696589582123348 | validation: 0.14618442278960408]
	TIME [epoch: 26.1 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14647343081807057		[learning rate: 0.00015197]
	Learning Rate: 0.00015197
	LOSS [training: 0.14647343081807057 | validation: 0.14302263719743208]
	TIME [epoch: 26.1 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14531992088992185		[learning rate: 0.00015143]
	Learning Rate: 0.000151433
	LOSS [training: 0.14531992088992185 | validation: 0.14827891903299095]
	TIME [epoch: 26.1 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14059583850966056		[learning rate: 0.0001509]
	Learning Rate: 0.000150897
	LOSS [training: 0.14059583850966056 | validation: 0.15048703123801233]
	TIME [epoch: 26.1 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15038696895294354		[learning rate: 0.00015036]
	Learning Rate: 0.000150364
	LOSS [training: 0.15038696895294354 | validation: 0.14039870595699736]
	TIME [epoch: 26.1 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14458128453225733		[learning rate: 0.00014983]
	Learning Rate: 0.000149832
	LOSS [training: 0.14458128453225733 | validation: 0.15072155768848747]
	TIME [epoch: 26.1 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14628309784419596		[learning rate: 0.0001493]
	Learning Rate: 0.000149302
	LOSS [training: 0.14628309784419596 | validation: 0.14905213679179358]
	TIME [epoch: 26.1 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1460101627971011		[learning rate: 0.00014877]
	Learning Rate: 0.000148774
	LOSS [training: 0.1460101627971011 | validation: 0.1474404631268967]
	TIME [epoch: 26.1 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14625438259458942		[learning rate: 0.00014825]
	Learning Rate: 0.000148248
	LOSS [training: 0.14625438259458942 | validation: 0.14051903539400842]
	TIME [epoch: 26.1 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14677302892265207		[learning rate: 0.00014772]
	Learning Rate: 0.000147724
	LOSS [training: 0.14677302892265207 | validation: 0.14805647424726182]
	TIME [epoch: 26.1 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.147682098476424		[learning rate: 0.0001472]
	Learning Rate: 0.000147201
	LOSS [training: 0.147682098476424 | validation: 0.14765861088419427]
	TIME [epoch: 26.1 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14054817385779375		[learning rate: 0.00014668]
	Learning Rate: 0.000146681
	LOSS [training: 0.14054817385779375 | validation: 0.14858662215206356]
	TIME [epoch: 26.1 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1415745849972955		[learning rate: 0.00014616]
	Learning Rate: 0.000146162
	LOSS [training: 0.1415745849972955 | validation: 0.14930531745422304]
	TIME [epoch: 26.1 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1473552728715128		[learning rate: 0.00014565]
	Learning Rate: 0.000145645
	LOSS [training: 0.1473552728715128 | validation: 0.1458471109350521]
	TIME [epoch: 26.1 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1475597558221883		[learning rate: 0.00014513]
	Learning Rate: 0.00014513
	LOSS [training: 0.1475597558221883 | validation: 0.14749290886040495]
	TIME [epoch: 26.1 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1433602089948805		[learning rate: 0.00014462]
	Learning Rate: 0.000144617
	LOSS [training: 0.1433602089948805 | validation: 0.14908191749399421]
	TIME [epoch: 26.1 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14344123513988966		[learning rate: 0.00014411]
	Learning Rate: 0.000144106
	LOSS [training: 0.14344123513988966 | validation: 0.1400063926218849]
	TIME [epoch: 26.1 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14354491227436758		[learning rate: 0.0001436]
	Learning Rate: 0.000143596
	LOSS [training: 0.14354491227436758 | validation: 0.15335439715455076]
	TIME [epoch: 26.1 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13986415184866313		[learning rate: 0.00014309]
	Learning Rate: 0.000143088
	LOSS [training: 0.13986415184866313 | validation: 0.14545648485695636]
	TIME [epoch: 26.1 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.15313264815668165		[learning rate: 0.00014258]
	Learning Rate: 0.000142582
	LOSS [training: 0.15313264815668165 | validation: 0.14855570715362387]
	TIME [epoch: 26.1 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13776353087157678		[learning rate: 0.00014208]
	Learning Rate: 0.000142078
	LOSS [training: 0.13776353087157678 | validation: 0.1472236390646445]
	TIME [epoch: 26.1 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1513880149118598		[learning rate: 0.00014158]
	Learning Rate: 0.000141576
	LOSS [training: 0.1513880149118598 | validation: 0.14794411089296813]
	TIME [epoch: 26.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13884116365961244		[learning rate: 0.00014108]
	Learning Rate: 0.000141075
	LOSS [training: 0.13884116365961244 | validation: 0.1612796929235753]
	TIME [epoch: 26.1 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14399587645172032		[learning rate: 0.00014058]
	Learning Rate: 0.000140576
	LOSS [training: 0.14399587645172032 | validation: 0.15041056506607695]
	TIME [epoch: 26.1 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13987266768212864		[learning rate: 0.00014008]
	Learning Rate: 0.000140079
	LOSS [training: 0.13987266768212864 | validation: 0.15586245976946603]
	TIME [epoch: 26.1 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14630538134775659		[learning rate: 0.00013958]
	Learning Rate: 0.000139584
	LOSS [training: 0.14630538134775659 | validation: 0.14643378147828476]
	TIME [epoch: 26.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14178356284705163		[learning rate: 0.00013909]
	Learning Rate: 0.00013909
	LOSS [training: 0.14178356284705163 | validation: 0.1601990016249215]
	TIME [epoch: 26.1 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14314512322240444		[learning rate: 0.0001386]
	Learning Rate: 0.000138598
	LOSS [training: 0.14314512322240444 | validation: 0.14795665984407233]
	TIME [epoch: 26.1 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1487740928670997		[learning rate: 0.00013811]
	Learning Rate: 0.000138108
	LOSS [training: 0.1487740928670997 | validation: 0.1485728140052909]
	TIME [epoch: 26.1 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14700543420962453		[learning rate: 0.00013762]
	Learning Rate: 0.00013762
	LOSS [training: 0.14700543420962453 | validation: 0.14728758824849938]
	TIME [epoch: 26.1 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14689393331090383		[learning rate: 0.00013713]
	Learning Rate: 0.000137133
	LOSS [training: 0.14689393331090383 | validation: 0.14512896428507144]
	TIME [epoch: 26.1 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13966369963881464		[learning rate: 0.00013665]
	Learning Rate: 0.000136648
	LOSS [training: 0.13966369963881464 | validation: 0.16070772134527214]
	TIME [epoch: 26.1 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14673981767473046		[learning rate: 0.00013617]
	Learning Rate: 0.000136165
	LOSS [training: 0.14673981767473046 | validation: 0.15065696066893844]
	TIME [epoch: 26.1 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.146423235757156		[learning rate: 0.00013568]
	Learning Rate: 0.000135684
	LOSS [training: 0.146423235757156 | validation: 0.15052268773308672]
	TIME [epoch: 26.1 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1496981115386688		[learning rate: 0.0001352]
	Learning Rate: 0.000135204
	LOSS [training: 0.1496981115386688 | validation: 0.14078945144121374]
	TIME [epoch: 26.1 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14704381446592743		[learning rate: 0.00013473]
	Learning Rate: 0.000134726
	LOSS [training: 0.14704381446592743 | validation: 0.14748136084050517]
	TIME [epoch: 26.1 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14206558293392096		[learning rate: 0.00013425]
	Learning Rate: 0.000134249
	LOSS [training: 0.14206558293392096 | validation: 0.14128892556582537]
	TIME [epoch: 26.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1453790211993223		[learning rate: 0.00013377]
	Learning Rate: 0.000133775
	LOSS [training: 0.1453790211993223 | validation: 0.14703116173670353]
	TIME [epoch: 26.1 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14642394590475974		[learning rate: 0.0001333]
	Learning Rate: 0.000133302
	LOSS [training: 0.14642394590475974 | validation: 0.15213757954156956]
	TIME [epoch: 26.1 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1474570655656264		[learning rate: 0.00013283]
	Learning Rate: 0.00013283
	LOSS [training: 0.1474570655656264 | validation: 0.1636707632181756]
	TIME [epoch: 26.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14469304124788412		[learning rate: 0.00013236]
	Learning Rate: 0.00013236
	LOSS [training: 0.14469304124788412 | validation: 0.14987151038583849]
	TIME [epoch: 26.1 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14384813387565915		[learning rate: 0.00013189]
	Learning Rate: 0.000131892
	LOSS [training: 0.14384813387565915 | validation: 0.14888718685010724]
	TIME [epoch: 26.1 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14048412633530546		[learning rate: 0.00013143]
	Learning Rate: 0.000131426
	LOSS [training: 0.14048412633530546 | validation: 0.1439485667013151]
	TIME [epoch: 26.1 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1518913961828387		[learning rate: 0.00013096]
	Learning Rate: 0.000130961
	LOSS [training: 0.1518913961828387 | validation: 0.14836417021531748]
	TIME [epoch: 26.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14537563352752672		[learning rate: 0.0001305]
	Learning Rate: 0.000130498
	LOSS [training: 0.14537563352752672 | validation: 0.15198805435310686]
	TIME [epoch: 26.1 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13799751081634068		[learning rate: 0.00013004]
	Learning Rate: 0.000130037
	LOSS [training: 0.13799751081634068 | validation: 0.14496772214447606]
	TIME [epoch: 26.1 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.13736813920123883		[learning rate: 0.00012958]
	Learning Rate: 0.000129577
	LOSS [training: 0.13736813920123883 | validation: 0.1539336387857942]
	TIME [epoch: 26.1 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14025019916242876		[learning rate: 0.00012912]
	Learning Rate: 0.000129119
	LOSS [training: 0.14025019916242876 | validation: 0.142639219270773]
	TIME [epoch: 26.1 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1481634432010977		[learning rate: 0.00012866]
	Learning Rate: 0.000128662
	LOSS [training: 0.1481634432010977 | validation: 0.15713298562845482]
	TIME [epoch: 26.1 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.137608013108466		[learning rate: 0.00012821]
	Learning Rate: 0.000128207
	LOSS [training: 0.137608013108466 | validation: 0.15028104890135469]
	TIME [epoch: 26.1 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1466511952843733		[learning rate: 0.00012775]
	Learning Rate: 0.000127754
	LOSS [training: 0.1466511952843733 | validation: 0.15275066513349403]
	TIME [epoch: 26.1 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14389588734740485		[learning rate: 0.0001273]
	Learning Rate: 0.000127302
	LOSS [training: 0.14389588734740485 | validation: 0.14636284203887784]
	TIME [epoch: 26.1 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14752279254749645		[learning rate: 0.00012685]
	Learning Rate: 0.000126852
	LOSS [training: 0.14752279254749645 | validation: 0.15225318251056683]
	TIME [epoch: 26.1 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14579735945625805		[learning rate: 0.0001264]
	Learning Rate: 0.000126403
	LOSS [training: 0.14579735945625805 | validation: 0.15188380508588661]
	TIME [epoch: 26.1 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14316573071223418		[learning rate: 0.00012596]
	Learning Rate: 0.000125956
	LOSS [training: 0.14316573071223418 | validation: 0.15621062652328085]
	TIME [epoch: 26.1 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1411111801138842		[learning rate: 0.00012551]
	Learning Rate: 0.000125511
	LOSS [training: 0.1411111801138842 | validation: 0.15098095086142255]
	TIME [epoch: 26.1 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.1417149417769981		[learning rate: 0.00012507]
	Learning Rate: 0.000125067
	LOSS [training: 0.1417149417769981 | validation: 0.15583710884801855]
	TIME [epoch: 26.1 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 7/7] avg loss: 0.14311123574474577		[learning rate: 0.00012462]
	Learning Rate: 0.000124625
	LOSS [training: 0.14311123574474577 | validation: 0.15527143426087656]
	TIME [epoch: 26.1 sec]
	Saving model to: out/model_training/model_transition2_pcs123_v1_20240606_200504/states/model_transition2_pcs123_v1_1288.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 33702.319 seconds.
