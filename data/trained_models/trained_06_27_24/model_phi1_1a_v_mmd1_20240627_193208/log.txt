Args:
Namespace(name='model_phi1_1a_v_mmd1', outdir='out/model_training/model_phi1_1a_v_mmd1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4085859834

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.625974833776762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.625974833776762 | validation: 5.8989200973422715]
	TIME [epoch: 115 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.446799653221285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.446799653221285 | validation: 5.385951949561052]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.796647296358281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.796647296358281 | validation: 5.059954409491232]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164060395949766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164060395949766 | validation: 4.978376951153063]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8899475356475017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8899475356475017 | validation: 4.426634802446386]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6122806008691346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6122806008691346 | validation: 4.252921671253482]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251942906385544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.251942906385544 | validation: 3.8513056968559733]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933448267381839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.933448267381839 | validation: 3.6656794342941144]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0070505048947043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0070505048947043 | validation: 3.541837789088768]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.717825623972549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.717825623972549 | validation: 3.2471881046824724]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5368353222999476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5368353222999476 | validation: 3.08627923478503]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5665871728630156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5665871728630156 | validation: 3.054412355151914]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318978293650619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.318978293650619 | validation: 2.8980988186284447]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2582443759196313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2582443759196313 | validation: 2.9655320635249414]
	TIME [epoch: 7.74 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.144399425349641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.144399425349641 | validation: 2.8914436445397316]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10447381592571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.10447381592571 | validation: 2.6217566929135856]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.982578221646239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.982578221646239 | validation: 2.543348038876479]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.852456454303201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.852456454303201 | validation: 2.311389808355545]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5435972850491193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5435972850491193 | validation: 2.562499419833884]
	TIME [epoch: 7.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6065912447850574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6065912447850574 | validation: 2.3050976573594575]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4517056394161874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4517056394161874 | validation: 2.2414383162258584]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.489619490235144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.489619490235144 | validation: 2.1023736531317856]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4372789741050398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4372789741050398 | validation: 2.1770904640433457]
	TIME [epoch: 7.76 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371223685669683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.371223685669683 | validation: 2.095180104789531]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4505027563145156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4505027563145156 | validation: 2.1292235573976663]
	TIME [epoch: 7.81 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4624420178397424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4624420178397424 | validation: 2.045968797856]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.636009336603503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.636009336603503 | validation: 2.1548221209735443]
	TIME [epoch: 7.79 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4490388973700932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4490388973700932 | validation: 2.0418504932958577]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.340960754642376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.340960754642376 | validation: 2.1911012019384972]
	TIME [epoch: 7.79 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4032672419709813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4032672419709813 | validation: 2.422653511771607]
	TIME [epoch: 7.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4396336633936153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4396336633936153 | validation: 1.9682981887443107]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2609210742835426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2609210742835426 | validation: 1.9847573719600833]
	TIME [epoch: 7.79 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3259200508252058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3259200508252058 | validation: 2.1251351033679544]
	TIME [epoch: 7.78 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3984815139921123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3984815139921123 | validation: 2.167100795988018]
	TIME [epoch: 7.81 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3896802814343268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3896802814343268 | validation: 2.0134787696248466]
	TIME [epoch: 7.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2890196026285357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2890196026285357 | validation: 1.943303043491254]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.390064365025294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.390064365025294 | validation: 2.0475469077337833]
	TIME [epoch: 7.76 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2706830603510761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2706830603510761 | validation: 1.9949418106773034]
	TIME [epoch: 7.78 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2873713043107868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2873713043107868 | validation: 2.0386774554588953]
	TIME [epoch: 7.84 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.459019484979169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.459019484979169 | validation: 1.8478072396923135]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3648969042847503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3648969042847503 | validation: 1.9583679949426998]
	TIME [epoch: 7.79 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3660257717642676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3660257717642676 | validation: 1.97387945648292]
	TIME [epoch: 7.81 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302400586008475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.302400586008475 | validation: 2.2464855169487983]
	TIME [epoch: 7.81 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.421213018456558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.421213018456558 | validation: 1.7993054376230193]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234690435223509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.234690435223509 | validation: 2.0034419386994107]
	TIME [epoch: 7.74 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.430087411079897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.430087411079897 | validation: 1.842452927338178]
	TIME [epoch: 7.75 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3859589558502334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3859589558502334 | validation: 1.929370502188875]
	TIME [epoch: 7.75 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354708866675846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.354708866675846 | validation: 1.7949855818529907]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645493410965374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2645493410965374 | validation: 5.056444947518958]
	TIME [epoch: 7.79 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4274408351336048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4274408351336048 | validation: 2.397448288772957]
	TIME [epoch: 7.78 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8789521427905582		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.8789521427905582 | validation: 2.224952353826018]
	TIME [epoch: 7.77 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6205051634542371		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.6205051634542371 | validation: 2.061343028183641]
	TIME [epoch: 7.75 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3662376138925834		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.3662376138925834 | validation: 1.834297680086485]
	TIME [epoch: 7.82 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271409495219454		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.2271409495219454 | validation: 1.8325086876080898]
	TIME [epoch: 7.78 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2228891136766498		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.2228891136766498 | validation: 1.9337535100159216]
	TIME [epoch: 7.77 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2499654146283252		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.2499654146283252 | validation: 2.0738348606871795]
	TIME [epoch: 7.75 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2383993316141044		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.2383993316141044 | validation: 1.7827242497329197]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2090377411649422		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.2090377411649422 | validation: 1.933771763007094]
	TIME [epoch: 7.83 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.185811675085478		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.185811675085478 | validation: 1.7449494073956087]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2376286864341257		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.2376286864341257 | validation: 1.7269939176265579]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257033889237558		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.257033889237558 | validation: 1.778363706364193]
	TIME [epoch: 7.81 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2089028091933076		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.2089028091933076 | validation: 1.757413061188874]
	TIME [epoch: 7.81 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367308073896027		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.367308073896027 | validation: 1.999441956390729]
	TIME [epoch: 7.83 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2333855347593086		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.2333855347593086 | validation: 1.6697392970132918]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0927163291701216		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.0927163291701216 | validation: 1.5581444124655244]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0091566865715942		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.0091566865715942 | validation: 1.172998734525505]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.953046499807557		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.953046499807557 | validation: 0.8708552946973839]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8580174505146574		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8580174505146574 | validation: 0.797357547133414]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704938033188219		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.6704938033188219 | validation: 0.8127799191251823]
	TIME [epoch: 7.77 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329070938857555		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6329070938857555 | validation: 0.5225765193510645]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109895626459984		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5109895626459984 | validation: 0.8221019882394021]
	TIME [epoch: 7.79 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374188060114861		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.6374188060114861 | validation: 0.7774244006096437]
	TIME [epoch: 7.81 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829753520027228		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5829753520027228 | validation: 0.6319982299425582]
	TIME [epoch: 7.79 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921448784798781		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.4921448784798781 | validation: 0.5270937339524461]
	TIME [epoch: 7.77 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483873094360656		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.483873094360656 | validation: 0.4931120511333221]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47053017497064364		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.47053017497064364 | validation: 0.534332938224402]
	TIME [epoch: 7.83 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43051361343058026		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.43051361343058026 | validation: 0.4618020094065445]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4870771136723619		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.4870771136723619 | validation: 0.48135790509565035]
	TIME [epoch: 7.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021774018304006		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.4021774018304006 | validation: 0.4893879691344689]
	TIME [epoch: 7.79 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010640908381857		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6010640908381857 | validation: 0.538200484801512]
	TIME [epoch: 7.79 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42664305048690815		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.42664305048690815 | validation: 0.39377125619465503]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307515042137477		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.4307515042137477 | validation: 0.5492131788776338]
	TIME [epoch: 7.81 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787277235139357		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.3787277235139357 | validation: 0.42412591820278467]
	TIME [epoch: 7.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42257249196291397		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.42257249196291397 | validation: 0.3907287665801323]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37115656075026565		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.37115656075026565 | validation: 0.8002383106546853]
	TIME [epoch: 7.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45145502934262594		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.45145502934262594 | validation: 0.3744683278894402]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36639412669690974		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.36639412669690974 | validation: 0.31343912321122575]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43650610627663444		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.43650610627663444 | validation: 0.47476096451376354]
	TIME [epoch: 7.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37143353088542036		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.37143353088542036 | validation: 0.3300473337695016]
	TIME [epoch: 7.76 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35663797131059466		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.35663797131059466 | validation: 0.5282509050747507]
	TIME [epoch: 7.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155053217316652		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4155053217316652 | validation: 0.31278885024599606]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36114757572760925		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.36114757572760925 | validation: 0.43114113582618774]
	TIME [epoch: 7.77 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37399085570772916		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.37399085570772916 | validation: 0.6609267231435585]
	TIME [epoch: 7.77 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4534657462932367		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4534657462932367 | validation: 0.30626030032025997]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466597737767932		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.3466597737767932 | validation: 0.4011837734050038]
	TIME [epoch: 7.83 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4030636274314196		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4030636274314196 | validation: 0.38492551173716927]
	TIME [epoch: 7.79 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255824230602242		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.3255824230602242 | validation: 0.5329382098651514]
	TIME [epoch: 7.76 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409157285799557		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3409157285799557 | validation: 0.27447918200303106]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34883442190304104		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.34883442190304104 | validation: 0.32187799258566796]
	TIME [epoch: 7.77 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31536972415427017		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.31536972415427017 | validation: 0.3314404967738156]
	TIME [epoch: 7.83 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813916971916914		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.3813916971916914 | validation: 0.39158008776094344]
	TIME [epoch: 7.79 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152139032960819		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.3152139032960819 | validation: 0.2885976027556555]
	TIME [epoch: 7.76 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3004506825874115		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.3004506825874115 | validation: 0.4880752063077163]
	TIME [epoch: 7.81 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34502473012640394		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.34502473012640394 | validation: 0.4013055156938946]
	TIME [epoch: 7.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35519264088920666		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.35519264088920666 | validation: 0.27151449531744776]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605831470933044		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.2605831470933044 | validation: 0.2992974690128817]
	TIME [epoch: 7.78 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535555093743812		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3535555093743812 | validation: 0.2531204933759422]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3248281855502326		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.3248281855502326 | validation: 0.25214124874863186]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29356052749966566		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.29356052749966566 | validation: 0.3169038810864989]
	TIME [epoch: 7.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36166255767870975		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.36166255767870975 | validation: 0.4595008703227873]
	TIME [epoch: 7.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41180479027208383		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.41180479027208383 | validation: 0.22731074127703998]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23701792933967625		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.23701792933967625 | validation: 0.26082285577988606]
	TIME [epoch: 7.76 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36250354259605944		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.36250354259605944 | validation: 0.28245215551475367]
	TIME [epoch: 7.77 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980408680698444		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.2980408680698444 | validation: 0.30661188313461485]
	TIME [epoch: 7.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239672673069288		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.3239672673069288 | validation: 0.25929766814234395]
	TIME [epoch: 7.77 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886206611496068		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.2886206611496068 | validation: 0.3487812680429613]
	TIME [epoch: 7.76 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908203785906436		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.2908203785906436 | validation: 0.35845443125824594]
	TIME [epoch: 7.76 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33703839689107057		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.33703839689107057 | validation: 0.29591195101942175]
	TIME [epoch: 7.78 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2656546543228576		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.2656546543228576 | validation: 0.26281941837135914]
	TIME [epoch: 7.81 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26275495815591754		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.26275495815591754 | validation: 0.4400002242791555]
	TIME [epoch: 7.77 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318256857034857		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3318256857034857 | validation: 0.27707221155944284]
	TIME [epoch: 7.78 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935653063148743		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.2935653063148743 | validation: 0.3585566855423078]
	TIME [epoch: 7.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33054348831416397		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.33054348831416397 | validation: 0.406395704439966]
	TIME [epoch: 7.82 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303189812435194		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.3303189812435194 | validation: 0.316496000901221]
	TIME [epoch: 7.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29285533730971647		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.29285533730971647 | validation: 0.2885787019109551]
	TIME [epoch: 7.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25030952474707713		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.25030952474707713 | validation: 0.3023818064745547]
	TIME [epoch: 7.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319353286915686		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3319353286915686 | validation: 0.3634681464352081]
	TIME [epoch: 7.77 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315021879328717		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.315021879328717 | validation: 0.23815714634815016]
	TIME [epoch: 7.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25464558929010306		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.25464558929010306 | validation: 0.37082359281925226]
	TIME [epoch: 7.78 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27229501170604176		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.27229501170604176 | validation: 0.31327833815208994]
	TIME [epoch: 7.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144335708082382		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.3144335708082382 | validation: 0.1920071933475792]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25184904888393655		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.25184904888393655 | validation: 0.3091068119529488]
	TIME [epoch: 7.79 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434268411553704		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3434268411553704 | validation: 0.2734661227992835]
	TIME [epoch: 7.84 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.298160943014198		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.298160943014198 | validation: 0.29696383250660185]
	TIME [epoch: 7.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739328174003539		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.2739328174003539 | validation: 0.22747131718586172]
	TIME [epoch: 7.79 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346030321700977		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.2346030321700977 | validation: 0.21548840631711258]
	TIME [epoch: 7.79 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30010466604942654		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.30010466604942654 | validation: 0.24532144387267052]
	TIME [epoch: 7.77 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335453378963504		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.335453378963504 | validation: 0.27776412634574993]
	TIME [epoch: 7.84 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26955098612114914		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.26955098612114914 | validation: 0.22371569516502088]
	TIME [epoch: 7.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259452563279756		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.259452563279756 | validation: 0.2919672320894601]
	TIME [epoch: 7.79 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23039228184568944		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.23039228184568944 | validation: 0.34449505007108405]
	TIME [epoch: 7.79 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671371432699253		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3671371432699253 | validation: 0.21957199443061237]
	TIME [epoch: 7.82 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25134677257393023		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.25134677257393023 | validation: 0.20828709772724988]
	TIME [epoch: 7.85 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29514089652061026		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.29514089652061026 | validation: 0.24432905942398048]
	TIME [epoch: 7.79 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24976436753589432		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.24976436753589432 | validation: 0.28891332788417406]
	TIME [epoch: 7.79 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583211806866691		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.2583211806866691 | validation: 0.18472542021094168]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24474627044084885		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.24474627044084885 | validation: 0.20896956207562392]
	TIME [epoch: 7.84 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536720629597438		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.2536720629597438 | validation: 0.25108550039373567]
	TIME [epoch: 7.79 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25844277469626803		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.25844277469626803 | validation: 0.19898802706917784]
	TIME [epoch: 7.81 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28965199963613664		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.28965199963613664 | validation: 0.37241978529618186]
	TIME [epoch: 7.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33990045702541843		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.33990045702541843 | validation: 0.21889825272095687]
	TIME [epoch: 7.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24270108962936576		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.24270108962936576 | validation: 0.20864360752890154]
	TIME [epoch: 7.84 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23091429816223857		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.23091429816223857 | validation: 0.28431963428547197]
	TIME [epoch: 7.81 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25419855138802333		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.25419855138802333 | validation: 0.2915784853019981]
	TIME [epoch: 7.81 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520559325741375		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.2520559325741375 | validation: 0.30042994698351677]
	TIME [epoch: 7.79 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25823689898797486		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.25823689898797486 | validation: 0.22154410659383988]
	TIME [epoch: 7.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359907889454363		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.2359907889454363 | validation: 0.2960786926207607]
	TIME [epoch: 7.86 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22896705975518955		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.22896705975518955 | validation: 0.29973462139693263]
	TIME [epoch: 7.78 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24738055807105544		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.24738055807105544 | validation: 0.27053271745260465]
	TIME [epoch: 7.79 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885176426341443		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2885176426341443 | validation: 0.18743533471166157]
	TIME [epoch: 7.81 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23791199009663522		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.23791199009663522 | validation: 0.29523277704163386]
	TIME [epoch: 7.82 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441597241148522		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.2441597241148522 | validation: 0.18448649198388112]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19806000436308113		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.19806000436308113 | validation: 0.29549537263629233]
	TIME [epoch: 7.81 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26584120193963345		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.26584120193963345 | validation: 0.2386758588642223]
	TIME [epoch: 7.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25253619875484673		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.25253619875484673 | validation: 0.18058850650514785]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21400068429418728		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.21400068429418728 | validation: 0.2141957880377469]
	TIME [epoch: 7.83 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222253273104523		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3222253273104523 | validation: 0.2291850962757085]
	TIME [epoch: 7.81 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21512038762686958		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.21512038762686958 | validation: 0.18850660952336604]
	TIME [epoch: 7.78 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21658355150320438		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.21658355150320438 | validation: 0.2306237331076556]
	TIME [epoch: 7.81 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27702648954966463		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.27702648954966463 | validation: 0.1812287981807291]
	TIME [epoch: 7.78 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21527971995507336		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.21527971995507336 | validation: 0.2859979085921649]
	TIME [epoch: 7.84 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24534135786526243		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.24534135786526243 | validation: 0.24016931338918662]
	TIME [epoch: 7.77 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26148784713230616		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.26148784713230616 | validation: 0.18375971464631974]
	TIME [epoch: 7.79 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147928864471354		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2147928864471354 | validation: 0.31566982086872186]
	TIME [epoch: 7.79 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24528369221126844		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.24528369221126844 | validation: 0.19416034343036004]
	TIME [epoch: 7.79 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23731616557570934		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.23731616557570934 | validation: 0.20191015938040952]
	TIME [epoch: 7.82 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27352900162043253		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.27352900162043253 | validation: 0.21605268879268086]
	TIME [epoch: 7.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24303781150204024		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.24303781150204024 | validation: 0.2145311446360254]
	TIME [epoch: 7.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24097891643413222		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.24097891643413222 | validation: 0.19041471504767962]
	TIME [epoch: 7.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192938769237029		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2192938769237029 | validation: 0.31604638343191926]
	TIME [epoch: 7.79 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2484112095234028		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.2484112095234028 | validation: 0.24390980551878022]
	TIME [epoch: 7.84 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19909390338211908		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.19909390338211908 | validation: 0.17246991060687134]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832648320372301		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.2832648320372301 | validation: 0.25051713844511425]
	TIME [epoch: 7.78 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23875481584538827		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.23875481584538827 | validation: 0.2868421653341468]
	TIME [epoch: 7.77 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22970086942781642		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.22970086942781642 | validation: 0.2218695776173517]
	TIME [epoch: 7.82 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22954957375865284		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.22954957375865284 | validation: 0.2778449901057833]
	TIME [epoch: 7.83 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273884723457074		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.2273884723457074 | validation: 0.33547090196098805]
	TIME [epoch: 7.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29068987207175256		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.29068987207175256 | validation: 0.2821491269694574]
	TIME [epoch: 7.77 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22835655993895843		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.22835655993895843 | validation: 0.17271498702865504]
	TIME [epoch: 7.79 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861510386676947		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1861510386676947 | validation: 0.25718096831356935]
	TIME [epoch: 7.83 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2306429746727583		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2306429746727583 | validation: 0.2700311703672464]
	TIME [epoch: 7.79 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2565763625098367		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.2565763625098367 | validation: 0.20533196615681548]
	TIME [epoch: 7.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18207737803326957		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.18207737803326957 | validation: 0.1658763810048658]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31469208105886043		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.31469208105886043 | validation: 0.25497157333714343]
	TIME [epoch: 7.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508164595353971		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2508164595353971 | validation: 0.15477971949377956]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19027983231443366		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.19027983231443366 | validation: 0.16108856436708405]
	TIME [epoch: 7.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18668850936415984		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.18668850936415984 | validation: 0.21419973178570997]
	TIME [epoch: 7.77 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2000307446038691		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.2000307446038691 | validation: 0.16386806512541624]
	TIME [epoch: 7.76 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22357310199018515		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.22357310199018515 | validation: 0.20289548366849147]
	TIME [epoch: 7.76 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20991797249752261		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20991797249752261 | validation: 0.2616368009648681]
	TIME [epoch: 7.79 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511539373689242		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.2511539373689242 | validation: 0.18167844497177893]
	TIME [epoch: 7.78 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128174178161532		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.17128174178161532 | validation: 0.1744865246072312]
	TIME [epoch: 7.78 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643717844188227		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.1643717844188227 | validation: 0.2669670821633573]
	TIME [epoch: 7.78 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072507707947929		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.3072507707947929 | validation: 0.33190941489098036]
	TIME [epoch: 7.82 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21054102113626222		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.21054102113626222 | validation: 0.16254214633603237]
	TIME [epoch: 7.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16578819921851468		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.16578819921851468 | validation: 0.2522566315368744]
	TIME [epoch: 7.79 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078777838038849		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.2078777838038849 | validation: 0.24073643069087103]
	TIME [epoch: 7.79 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2567233615033993		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2567233615033993 | validation: 0.3281344858950065]
	TIME [epoch: 7.75 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540674314110926		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2540674314110926 | validation: 0.16287709095748332]
	TIME [epoch: 7.82 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19874461990378223		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19874461990378223 | validation: 0.34978674597123893]
	TIME [epoch: 7.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26796688885930875		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.26796688885930875 | validation: 0.2683931112938581]
	TIME [epoch: 7.79 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22776020432626046		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.22776020432626046 | validation: 0.20334761072285448]
	TIME [epoch: 7.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19694813719031143		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.19694813719031143 | validation: 0.15722805562243708]
	TIME [epoch: 7.78 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16751964337551695		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.16751964337551695 | validation: 0.14295574401381045]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15474564367631202		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.15474564367631202 | validation: 0.2174467411754121]
	TIME [epoch: 7.79 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17008792103573733		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.17008792103573733 | validation: 0.1549332725507367]
	TIME [epoch: 7.79 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19130272092079714		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.19130272092079714 | validation: 0.23360634805559688]
	TIME [epoch: 7.78 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19552362036308676		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.19552362036308676 | validation: 0.24204522196342265]
	TIME [epoch: 7.82 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25065667931244484		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.25065667931244484 | validation: 0.20370894314475413]
	TIME [epoch: 7.82 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18062096724183985		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18062096724183985 | validation: 0.1919851570010962]
	TIME [epoch: 7.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16543288550624335		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.16543288550624335 | validation: 0.19036754987134805]
	TIME [epoch: 7.81 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14941951089792643		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.14941951089792643 | validation: 0.22447513690137633]
	TIME [epoch: 7.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557786227151213		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.557786227151213 | validation: 0.4947792596962248]
	TIME [epoch: 7.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31796226936058825		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.31796226936058825 | validation: 0.3231355856551265]
	TIME [epoch: 7.82 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25868995657461424		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.25868995657461424 | validation: 0.2962322794831712]
	TIME [epoch: 7.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24726441003619395		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.24726441003619395 | validation: 0.27376714239319067]
	TIME [epoch: 7.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22957641840993742		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.22957641840993742 | validation: 0.2741851316680514]
	TIME [epoch: 7.78 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25657904476631077		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.25657904476631077 | validation: 0.24961114586116673]
	TIME [epoch: 7.84 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944754007515769		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.1944754007515769 | validation: 0.15068879349755027]
	TIME [epoch: 7.81 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14397755668661177		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.14397755668661177 | validation: 0.27031105693919455]
	TIME [epoch: 7.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19410773396243775		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.19410773396243775 | validation: 0.15593123968192052]
	TIME [epoch: 7.81 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911903391662588		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.1911903391662588 | validation: 0.19340576708709423]
	TIME [epoch: 7.81 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455067844630042		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.1455067844630042 | validation: 0.19971899732023507]
	TIME [epoch: 7.83 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19141901830327923		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.19141901830327923 | validation: 0.1383033111797183]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472360342869794		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.13472360342869794 | validation: 0.14717936508698695]
	TIME [epoch: 7.81 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589180479690656		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.1589180479690656 | validation: 0.17309418092109358]
	TIME [epoch: 7.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18117434298069193		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.18117434298069193 | validation: 0.17579510130670753]
	TIME [epoch: 7.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23042382239320633		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.23042382239320633 | validation: 0.16471817214957934]
	TIME [epoch: 7.83 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13671567593003578		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.13671567593003578 | validation: 0.1576436835090329]
	TIME [epoch: 7.82 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18822486791810175		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.18822486791810175 | validation: 0.1491354876066256]
	TIME [epoch: 7.78 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910408269988302		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.15910408269988302 | validation: 0.207141634698112]
	TIME [epoch: 7.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17001835321141298		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.17001835321141298 | validation: 0.22101877311488777]
	TIME [epoch: 7.81 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443181957447332		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.1443181957447332 | validation: 0.15774943568391403]
	TIME [epoch: 7.85 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751493261449112		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.1751493261449112 | validation: 0.23803063557534987]
	TIME [epoch: 7.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758513210328321		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1758513210328321 | validation: 0.16297583087468673]
	TIME [epoch: 7.81 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16070626949751357		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.16070626949751357 | validation: 0.2621968594570122]
	TIME [epoch: 7.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20352130377346572		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.20352130377346572 | validation: 0.11122384923247947]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140347307718829		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.1140347307718829 | validation: 0.1390526870037904]
	TIME [epoch: 7.79 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683824412823819		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.1683824412823819 | validation: 0.1724548930756404]
	TIME [epoch: 7.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17475584751014972		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.17475584751014972 | validation: 0.2773965482592441]
	TIME [epoch: 7.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196421793925373		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.196421793925373 | validation: 0.12870510092930926]
	TIME [epoch: 7.79 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259631053218527		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.12259631053218527 | validation: 0.0988339826359804]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12638364181889358		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.12638364181889358 | validation: 0.23699423661621577]
	TIME [epoch: 7.79 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18095798206223432		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.18095798206223432 | validation: 0.25842080337968554]
	TIME [epoch: 7.79 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26777065490420504		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.26777065490420504 | validation: 0.21775735742170177]
	TIME [epoch: 7.78 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462170434301982		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.1462170434301982 | validation: 0.1653424083873758]
	TIME [epoch: 7.82 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460706519819179		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.11460706519819179 | validation: 0.10407996438180933]
	TIME [epoch: 7.85 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11777118627095709		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.11777118627095709 | validation: 0.20277845873269787]
	TIME [epoch: 7.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17948370117576581		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.17948370117576581 | validation: 0.24106044323595605]
	TIME [epoch: 7.81 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730033373340733		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1730033373340733 | validation: 0.1003233573677344]
	TIME [epoch: 7.79 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11782770545932958		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.11782770545932958 | validation: 0.19758721289331732]
	TIME [epoch: 7.81 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20326655538698493		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.20326655538698493 | validation: 0.1835362803393911]
	TIME [epoch: 7.83 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580309577667718		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.1580309577667718 | validation: 0.15977248712302033]
	TIME [epoch: 7.79 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17173075824278133		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.17173075824278133 | validation: 0.1171211896947382]
	TIME [epoch: 7.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713087138387972		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.11713087138387972 | validation: 0.14044058317245428]
	TIME [epoch: 7.81 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867192274687035		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.10867192274687035 | validation: 0.14102776476994183]
	TIME [epoch: 7.83 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355568907648466		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.12355568907648466 | validation: 0.09452922796041638]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129742729692196		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.129742729692196 | validation: 0.09457558789838302]
	TIME [epoch: 7.78 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13795074055005435		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.13795074055005435 | validation: 0.10337082810179743]
	TIME [epoch: 7.81 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13732602154104243		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.13732602154104243 | validation: 0.11109904543958918]
	TIME [epoch: 7.79 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10328981061448986		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.10328981061448986 | validation: 0.14566947937234814]
	TIME [epoch: 7.85 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181446133163905		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.1181446133163905 | validation: 0.08170597342547921]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182805966054671		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.08182805966054671 | validation: 0.11494233130063158]
	TIME [epoch: 7.78 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17526666416813574		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.17526666416813574 | validation: 0.18692397222418933]
	TIME [epoch: 7.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931150695724768		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.14931150695724768 | validation: 0.09012598450926715]
	TIME [epoch: 7.79 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215639387868442		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.12215639387868442 | validation: 0.16778091541581772]
	TIME [epoch: 7.82 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364630455119425		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.13364630455119425 | validation: 0.16344084266772496]
	TIME [epoch: 7.76 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261194403204311		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.1261194403204311 | validation: 0.11756080530705076]
	TIME [epoch: 7.77 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12309025372960802		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.12309025372960802 | validation: 0.08216752647670032]
	TIME [epoch: 7.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723130087692933		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.12723130087692933 | validation: 0.17077940014153226]
	TIME [epoch: 7.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451790307251688		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.1451790307251688 | validation: 0.07909604695857503]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904288684054571		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.0904288684054571 | validation: 0.17411008514020407]
	TIME [epoch: 7.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13512154326448628		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.13512154326448628 | validation: 0.09802250909446178]
	TIME [epoch: 7.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159427087873839		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.12159427087873839 | validation: 0.1298854206182825]
	TIME [epoch: 7.76 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652015787475113		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.09652015787475113 | validation: 0.15515979848466227]
	TIME [epoch: 7.86 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12589629364036492		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.12589629364036492 | validation: 0.1764795998350952]
	TIME [epoch: 7.77 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13832379132361172		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.13832379132361172 | validation: 0.08698683654720599]
	TIME [epoch: 7.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10661666134673486		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.10661666134673486 | validation: 0.08537976838167632]
	TIME [epoch: 7.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987568123806162		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.11987568123806162 | validation: 0.12186774834943384]
	TIME [epoch: 7.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363552997426601		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.11363552997426601 | validation: 0.06878143589751623]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962233401680987		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.09962233401680987 | validation: 0.07566497184557723]
	TIME [epoch: 7.79 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059290225158968		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.1059290225158968 | validation: 0.12382817996185787]
	TIME [epoch: 7.77 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467038678445243		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.1467038678445243 | validation: 0.11788254633256448]
	TIME [epoch: 7.78 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10874426190384417		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.10874426190384417 | validation: 0.08678696114127285]
	TIME [epoch: 7.78 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017466263697222		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.1017466263697222 | validation: 0.12875300963280648]
	TIME [epoch: 7.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298070317893646		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.1298070317893646 | validation: 0.19701936579321383]
	TIME [epoch: 7.77 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660869845729733		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.12660869845729733 | validation: 0.09908390415274186]
	TIME [epoch: 7.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09877206418629679		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.09877206418629679 | validation: 0.08753741183882074]
	TIME [epoch: 7.77 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10607229762020179		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.10607229762020179 | validation: 0.07397922546212232]
	TIME [epoch: 7.78 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394479123495997		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.11394479123495997 | validation: 0.11548264100810188]
	TIME [epoch: 7.82 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104937258571887		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.1104937258571887 | validation: 0.08728407733534785]
	TIME [epoch: 7.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401205085778683		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.08401205085778683 | validation: 0.10230499875430966]
	TIME [epoch: 7.79 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09785242678593324		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.09785242678593324 | validation: 0.09204116132688621]
	TIME [epoch: 7.78 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482282315088947		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.1482282315088947 | validation: 0.25614682610053197]
	TIME [epoch: 7.84 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19794688955466186		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.19794688955466186 | validation: 0.08457129506617572]
	TIME [epoch: 7.79 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100832566665626		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.100832566665626 | validation: 0.2358754177368822]
	TIME [epoch: 7.79 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19180231609277332		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.19180231609277332 | validation: 0.1989756565565106]
	TIME [epoch: 7.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194677926634667		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1194677926634667 | validation: 0.07960858952205685]
	TIME [epoch: 7.78 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08779877726836609		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.08779877726836609 | validation: 0.1811415003032944]
	TIME [epoch: 7.84 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20186856403139153		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.20186856403139153 | validation: 0.15060594510507153]
	TIME [epoch: 7.79 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12012549554276555		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.12012549554276555 | validation: 0.1337519870636366]
	TIME [epoch: 7.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212742852227636		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.1212742852227636 | validation: 0.08041029103548172]
	TIME [epoch: 7.79 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159547921916115		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.08159547921916115 | validation: 0.06761629676296217]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578327284648907		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.07578327284648907 | validation: 0.0869943147216511]
	TIME [epoch: 7.81 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509470130444377		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.09509470130444377 | validation: 0.05920896419961105]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058388832506593		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.07058388832506593 | validation: 0.11127813851521035]
	TIME [epoch: 7.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652100374550033		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.10652100374550033 | validation: 0.2479240520902779]
	TIME [epoch: 7.78 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18502624599349238		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.18502624599349238 | validation: 0.0957348529145018]
	TIME [epoch: 7.81 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07925685981726062		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.07925685981726062 | validation: 0.08734796332424656]
	TIME [epoch: 7.84 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542698097151896		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08542698097151896 | validation: 0.0811633639841442]
	TIME [epoch: 7.79 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760446814844228		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.11760446814844228 | validation: 0.8736192954987803]
	TIME [epoch: 7.78 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672404436588943		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.3672404436588943 | validation: 0.08719853924461948]
	TIME [epoch: 7.79 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10157363707356035		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.10157363707356035 | validation: 0.06854240219738614]
	TIME [epoch: 7.84 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144637091021854		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.08144637091021854 | validation: 0.07776862912734359]
	TIME [epoch: 7.81 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902733384501727		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.07902733384501727 | validation: 0.04826121441764078]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966019290678881		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.05966019290678881 | validation: 0.08204302890678467]
	TIME [epoch: 7.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06765537966764956		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.06765537966764956 | validation: 0.05116658782495542]
	TIME [epoch: 7.79 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934136990369408		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.05934136990369408 | validation: 0.06281399375303723]
	TIME [epoch: 7.83 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750432117537439		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.06750432117537439 | validation: 0.1452580323586494]
	TIME [epoch: 7.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12117826961817779		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.12117826961817779 | validation: 0.08457615397559226]
	TIME [epoch: 7.79 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14498975178393214		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.14498975178393214 | validation: 0.16749177116575792]
	TIME [epoch: 7.78 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13823159550990433		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.13823159550990433 | validation: 0.12960376395850504]
	TIME [epoch: 7.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104227278474159		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.1104227278474159 | validation: 0.10114249900620446]
	TIME [epoch: 7.86 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.077065108937758		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.077065108937758 | validation: 0.07035595156378235]
	TIME [epoch: 7.79 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06653860660889314		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.06653860660889314 | validation: 0.12750515981230498]
	TIME [epoch: 7.78 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289858772408587		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.1289858772408587 | validation: 0.09556248304553785]
	TIME [epoch: 7.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06933847062910711		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.06933847062910711 | validation: 0.06221056771429728]
	TIME [epoch: 7.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701435735513665		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.06701435735513665 | validation: 0.047451727972479686]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056189970674829184		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.056189970674829184 | validation: 0.04795372425651605]
	TIME [epoch: 7.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054185934836507785		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.054185934836507785 | validation: 0.12496564046226345]
	TIME [epoch: 7.77 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409721821254545		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1409721821254545 | validation: 0.14464561923596816]
	TIME [epoch: 7.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918112296454711		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.10918112296454711 | validation: 0.09367734921702267]
	TIME [epoch: 7.81 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09747416206715932		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.09747416206715932 | validation: 0.10404786864612903]
	TIME [epoch: 7.77 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06473808010668212		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.06473808010668212 | validation: 0.0699835717793474]
	TIME [epoch: 7.76 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054106857716955926		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.054106857716955926 | validation: 0.056918748151099985]
	TIME [epoch: 7.78 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346501824788977		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.07346501824788977 | validation: 0.07851194672529585]
	TIME [epoch: 7.76 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08505465677665469		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.08505465677665469 | validation: 0.07271414044922436]
	TIME [epoch: 7.81 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103591534417445		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.103591534417445 | validation: 0.08617458450416432]
	TIME [epoch: 7.77 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452906342633157		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.08452906342633157 | validation: 0.12912616976819155]
	TIME [epoch: 7.77 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11459969999300046		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.11459969999300046 | validation: 0.07782403829959499]
	TIME [epoch: 7.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824149514763112		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.0824149514763112 | validation: 0.05498418967661558]
	TIME [epoch: 7.77 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050335061491727846		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.050335061491727846 | validation: 0.09156931894924149]
	TIME [epoch: 7.82 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936966945033136		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.07936966945033136 | validation: 0.05047350499891397]
	TIME [epoch: 7.77 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05107790259566139		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.05107790259566139 | validation: 0.11101428166599048]
	TIME [epoch: 7.76 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035493276469781		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.10035493276469781 | validation: 0.04448159238078643]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060172734217294896		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.060172734217294896 | validation: 0.05547227269849739]
	TIME [epoch: 7.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204645602167234		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.09204645602167234 | validation: 0.047888364106589906]
	TIME [epoch: 7.77 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950333869312987		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.07950333869312987 | validation: 0.07775405999729931]
	TIME [epoch: 7.76 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701585542493468		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.0701585542493468 | validation: 0.062088385920510754]
	TIME [epoch: 7.75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07616061491060136		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.07616061491060136 | validation: 0.05653929097727939]
	TIME [epoch: 7.77 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05260526261990317		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.05260526261990317 | validation: 0.04520947935692948]
	TIME [epoch: 7.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714061596794138		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.06714061596794138 | validation: 0.05354537584931118]
	TIME [epoch: 7.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052857917340044955		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.052857917340044955 | validation: 0.09879827367823757]
	TIME [epoch: 7.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09635525392003921		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.09635525392003921 | validation: 0.059408260253310155]
	TIME [epoch: 7.75 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050882024279077114		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.050882024279077114 | validation: 0.037573088917570246]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754696413576047		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.04754696413576047 | validation: 0.12900796086341149]
	TIME [epoch: 7.85 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742458142417493		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.08742458142417493 | validation: 0.26095034184439625]
	TIME [epoch: 7.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.208629369944689		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.208629369944689 | validation: 0.21565390532884957]
	TIME [epoch: 7.78 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16013431160805702		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.16013431160805702 | validation: 0.13392683661650406]
	TIME [epoch: 7.79 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10710371831525999		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.10710371831525999 | validation: 0.05127012004744526]
	TIME [epoch: 7.79 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048266224722025575		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.048266224722025575 | validation: 0.09357812317313852]
	TIME [epoch: 7.84 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06958052141948376		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.06958052141948376 | validation: 0.047705689518703784]
	TIME [epoch: 7.79 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506573478089494		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.05506573478089494 | validation: 0.05936227287035323]
	TIME [epoch: 7.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291266155992696		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.06291266155992696 | validation: 0.10034376944766502]
	TIME [epoch: 7.78 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816257645996987		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.06816257645996987 | validation: 0.09428626058917997]
	TIME [epoch: 7.77 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961472905236944		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.06961472905236944 | validation: 0.052335334230859336]
	TIME [epoch: 7.84 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06327745627983561		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.06327745627983561 | validation: 0.042894956819809434]
	TIME [epoch: 7.78 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04664415878168257		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.04664415878168257 | validation: 0.11027265199442526]
	TIME [epoch: 7.79 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05004928901713094		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.05004928901713094 | validation: 0.048915008184069894]
	TIME [epoch: 7.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05189205920742809		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.05189205920742809 | validation: 0.055439271050658157]
	TIME [epoch: 7.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815387252582151		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.04815387252582151 | validation: 0.16792362365708927]
	TIME [epoch: 7.81 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600893438912573		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.1600893438912573 | validation: 0.12545854850936922]
	TIME [epoch: 7.77 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346006595524107		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.08346006595524107 | validation: 0.04399654377894581]
	TIME [epoch: 7.78 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353493083271704		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.06353493083271704 | validation: 0.07085416779432288]
	TIME [epoch: 7.77 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05306994442405927		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.05306994442405927 | validation: 0.0625309282355587]
	TIME [epoch: 7.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05815706296825671		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.05815706296825671 | validation: 0.08131032094106981]
	TIME [epoch: 7.82 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413419160829959		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.04413419160829959 | validation: 0.03287611346600878]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060803257765934385		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.060803257765934385 | validation: 0.030487882203854483]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363743282496018		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.05363743282496018 | validation: 0.04974127073845397]
	TIME [epoch: 7.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683114109631555		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.04683114109631555 | validation: 0.08432676977774506]
	TIME [epoch: 7.83 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05519982770210738		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.05519982770210738 | validation: 0.06857983612404348]
	TIME [epoch: 7.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853578745260025		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.04853578745260025 | validation: 0.04200819035018653]
	TIME [epoch: 7.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055982139335607334		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.055982139335607334 | validation: 0.054886649037077455]
	TIME [epoch: 7.79 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744701530415863		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.06744701530415863 | validation: 0.05690062317431667]
	TIME [epoch: 7.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629745798501713		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.05629745798501713 | validation: 0.04590505959025483]
	TIME [epoch: 7.86 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275348030316169		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.04275348030316169 | validation: 0.03785250610805463]
	TIME [epoch: 7.79 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04525280233725541		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.04525280233725541 | validation: 0.052646439613114916]
	TIME [epoch: 7.79 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05945780554889095		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.05945780554889095 | validation: 0.07763415465279733]
	TIME [epoch: 7.78 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089921532838184		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.09089921532838184 | validation: 0.08007936968132018]
	TIME [epoch: 7.79 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057971779285301		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.06057971779285301 | validation: 0.04707229462383618]
	TIME [epoch: 7.82 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227829005065434		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.03227829005065434 | validation: 0.038459142977042705]
	TIME [epoch: 7.79 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340708215833295		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.03340708215833295 | validation: 0.029714267292125715]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559780826681012		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.04559780826681012 | validation: 0.03720089926479904]
	TIME [epoch: 7.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042556469417635356		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.042556469417635356 | validation: 0.049512304885597075]
	TIME [epoch: 7.87 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061811570409649		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.061811570409649 | validation: 0.03652372676671505]
	TIME [epoch: 7.82 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03950045510483797		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.03950045510483797 | validation: 0.024647043539800684]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882195906259946		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.03882195906259946 | validation: 0.0302799931294973]
	TIME [epoch: 7.77 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058277017951351325		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.058277017951351325 | validation: 0.09088287518994918]
	TIME [epoch: 7.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05800308261985557		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.05800308261985557 | validation: 0.05983033988224693]
	TIME [epoch: 7.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03663237435913773		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.03663237435913773 | validation: 0.028571286563115854]
	TIME [epoch: 7.77 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03501869328360412		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.03501869328360412 | validation: 0.029700296429064188]
	TIME [epoch: 7.76 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685842180951813		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.03685842180951813 | validation: 0.031597597784520315]
	TIME [epoch: 7.77 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902584170130347		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.04902584170130347 | validation: 0.028360050016312546]
	TIME [epoch: 7.78 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03820377506866131		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.03820377506866131 | validation: 0.07966948502200685]
	TIME [epoch: 7.83 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07131690796554685		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.07131690796554685 | validation: 0.027911857303868026]
	TIME [epoch: 7.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05868998828053278		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.05868998828053278 | validation: 0.02925734956846538]
	TIME [epoch: 7.77 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361641272209749		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.03361641272209749 | validation: 0.024764026513806166]
	TIME [epoch: 7.79 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03582266236546637		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.03582266236546637 | validation: 0.03706769542906146]
	TIME [epoch: 7.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659306265881046		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.03659306265881046 | validation: 0.06809408871050458]
	TIME [epoch: 7.81 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07360402103167718		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.07360402103167718 | validation: 0.10986021462593473]
	TIME [epoch: 7.78 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750528198644506		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.06750528198644506 | validation: 0.044443842454635486]
	TIME [epoch: 7.76 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377250716988788		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.0377250716988788 | validation: 0.022767177248027702]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02727702052546946		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.02727702052546946 | validation: 0.035270904620954294]
	TIME [epoch: 7.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229056293786922		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.03229056293786922 | validation: 0.05381483674957961]
	TIME [epoch: 7.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489381657708653		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.03489381657708653 | validation: 0.02509218611807882]
	TIME [epoch: 7.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021926076485505		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.09021926076485505 | validation: 0.126335760047181]
	TIME [epoch: 7.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09845521147170928		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.09845521147170928 | validation: 0.04312721783181936]
	TIME [epoch: 7.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031123557214974083		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.031123557214974083 | validation: 0.02591420449161803]
	TIME [epoch: 7.79 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029095698047711817		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.029095698047711817 | validation: 0.05003518237545217]
	TIME [epoch: 7.77 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050831596965324924		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.050831596965324924 | validation: 0.0744887315287178]
	TIME [epoch: 7.76 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0505961736289561		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.0505961736289561 | validation: 0.028444579336661134]
	TIME [epoch: 7.73 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552456302677903		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.03552456302677903 | validation: 0.03446780605749655]
	TIME [epoch: 7.75 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027165358116630522		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.027165358116630522 | validation: 0.035173662408827064]
	TIME [epoch: 7.81 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05582837769638571		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.05582837769638571 | validation: 0.19268376172330554]
	TIME [epoch: 7.76 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1430148750679912		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1430148750679912 | validation: 0.14697574053938883]
	TIME [epoch: 7.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538360232049909		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.11538360232049909 | validation: 0.04569298643119357]
	TIME [epoch: 7.75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032319092792687416		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.032319092792687416 | validation: 0.032622999886824926]
	TIME [epoch: 7.75 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452229298395487		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.0452229298395487 | validation: 0.04724348832386067]
	TIME [epoch: 7.82 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033302539030438394		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.033302539030438394 | validation: 0.022314299532349376]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05332438546245813		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.05332438546245813 | validation: 0.09588981694029877]
	TIME [epoch: 7.79 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056653653073722395		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.056653653073722395 | validation: 0.0361058632916008]
	TIME [epoch: 7.79 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905174695562681		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.02905174695562681 | validation: 0.019357301458587828]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026600727511009017		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.026600727511009017 | validation: 0.026153098281179704]
	TIME [epoch: 7.81 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773940535685982		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.03773940535685982 | validation: 0.022072276887786603]
	TIME [epoch: 7.79 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035604612815431265		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.035604612815431265 | validation: 0.06523632543036936]
	TIME [epoch: 7.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06108015410160897		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.06108015410160897 | validation: 0.02431329327514542]
	TIME [epoch: 7.79 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545070644943546		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.02545070644943546 | validation: 0.020482644434263994]
	TIME [epoch: 7.82 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02809235763583056		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.02809235763583056 | validation: 0.026476291623498974]
	TIME [epoch: 7.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028894693610659886		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.028894693610659886 | validation: 0.02370493067152365]
	TIME [epoch: 7.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029800201675281118		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.029800201675281118 | validation: 0.04171761887848258]
	TIME [epoch: 7.78 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394340177411392		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.03394340177411392 | validation: 0.024737158519813347]
	TIME [epoch: 7.78 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025529918910515835		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.025529918910515835 | validation: 0.023321524805766408]
	TIME [epoch: 7.83 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668922385036763		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.02668922385036763 | validation: 0.1484631355349176]
	TIME [epoch: 7.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19092975569262904		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.19092975569262904 | validation: 0.08698034118053133]
	TIME [epoch: 7.79 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09401452564662394		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.09401452564662394 | validation: 0.05490974747261289]
	TIME [epoch: 7.82 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03786285019420373		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.03786285019420373 | validation: 0.018230201183647557]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027714776003554403		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.027714776003554403 | validation: 0.026307485774285596]
	TIME [epoch: 7.85 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02868004339293353		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.02868004339293353 | validation: 0.03978033396074954]
	TIME [epoch: 7.79 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032100342549027466		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.032100342549027466 | validation: 0.020919367418306113]
	TIME [epoch: 7.78 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025575820261878005		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.025575820261878005 | validation: 0.026985434940885088]
	TIME [epoch: 7.79 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025745169650525826		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.025745169650525826 | validation: 0.018327325214708555]
	TIME [epoch: 7.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023834310267156503		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.023834310267156503 | validation: 0.018899864156804266]
	TIME [epoch: 7.83 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028018024165977595		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.028018024165977595 | validation: 0.031037102140785186]
	TIME [epoch: 7.79 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03058004422602095		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.03058004422602095 | validation: 0.018474101022581114]
	TIME [epoch: 7.78 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388282628636117		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.0388282628636117 | validation: 0.022838500354103303]
	TIME [epoch: 7.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023670584402302644		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.023670584402302644 | validation: 0.04247281152236159]
	TIME [epoch: 7.84 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025353293524779913		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.025353293524779913 | validation: 0.024436221539051856]
	TIME [epoch: 7.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02683135259148252		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.02683135259148252 | validation: 0.02189179863475071]
	TIME [epoch: 7.79 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026470554300371978		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.026470554300371978 | validation: 0.026828330646554127]
	TIME [epoch: 7.81 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621311541525764		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.03621311541525764 | validation: 0.05914228589424633]
	TIME [epoch: 7.79 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046558037645990674		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.046558037645990674 | validation: 0.06514170376214576]
	TIME [epoch: 7.83 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371557215289502		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.04371557215289502 | validation: 0.02778156846929962]
	TIME [epoch: 7.79 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01897426019889896		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.01897426019889896 | validation: 0.020386897221090966]
	TIME [epoch: 7.79 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018475815193246925		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.018475815193246925 | validation: 0.018594242032892377]
	TIME [epoch: 7.79 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024584635822139364		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.024584635822139364 | validation: 0.0255655074875953]
	TIME [epoch: 7.77 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02968657153764672		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.02968657153764672 | validation: 0.019936220026347578]
	TIME [epoch: 7.86 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939634948102418		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.02939634948102418 | validation: 0.04719219114335174]
	TIME [epoch: 7.79 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033896890825607186		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.033896890825607186 | validation: 0.0234100707302259]
	TIME [epoch: 7.78 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020073658751131394		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.020073658751131394 | validation: 0.042415300393307466]
	TIME [epoch: 7.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966555457006873		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.02966555457006873 | validation: 0.023422531168097633]
	TIME [epoch: 7.81 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025136786047851432		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.025136786047851432 | validation: 0.020111546805180174]
	TIME [epoch: 7.83 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021573394743121158		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.021573394743121158 | validation: 0.04380271671532843]
	TIME [epoch: 7.79 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025015501494802035		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.025015501494802035 | validation: 0.028468973974761717]
	TIME [epoch: 7.79 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036125797048966055		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.036125797048966055 | validation: 0.03002977811345018]
	TIME [epoch: 7.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019518919882541876		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.019518919882541876 | validation: 0.02127933220854264]
	TIME [epoch: 7.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01970369635439739		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.01970369635439739 | validation: 0.057005684046188276]
	TIME [epoch: 7.85 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736587366413354		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.0736587366413354 | validation: 0.04056218494906173]
	TIME [epoch: 7.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049551860046991435		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.049551860046991435 | validation: 0.03968448993921959]
	TIME [epoch: 7.79 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027390655347382664		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.027390655347382664 | validation: 0.019829761774885622]
	TIME [epoch: 7.81 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017009295394968666		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.017009295394968666 | validation: 0.023396853025107307]
	TIME [epoch: 7.87 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016477020027987364		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.016477020027987364 | validation: 0.018534541305198843]
	TIME [epoch: 7.79 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027614084279226882		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.027614084279226882 | validation: 0.02043272879066399]
	TIME [epoch: 7.76 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021192360080729392		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.021192360080729392 | validation: 0.018199284282189174]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026110177827599078		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.026110177827599078 | validation: 0.0407768632803814]
	TIME [epoch: 7.78 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022843747363744824		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.022843747363744824 | validation: 0.023873093425673075]
	TIME [epoch: 7.84 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020818163702091358		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.020818163702091358 | validation: 0.02409536223005341]
	TIME [epoch: 7.79 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01779755345854543		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.01779755345854543 | validation: 0.019039778565815558]
	TIME [epoch: 7.77 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02842002031518901		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.02842002031518901 | validation: 0.03545765021800175]
	TIME [epoch: 7.78 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026300128472424723		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.026300128472424723 | validation: 0.021491229899476102]
	TIME [epoch: 7.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017164311044233674		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.017164311044233674 | validation: 0.03159699532716213]
	TIME [epoch: 7.85 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025077526880392255		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.025077526880392255 | validation: 0.014513325585343859]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022919118718816335		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.022919118718816335 | validation: 0.05885845346523468]
	TIME [epoch: 7.79 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040314007017562575		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.040314007017562575 | validation: 0.03996875627065213]
	TIME [epoch: 7.78 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024238804472482004		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.024238804472482004 | validation: 0.024952144839291833]
	TIME [epoch: 7.81 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026258238298917467		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.026258238298917467 | validation: 0.036001452400365785]
	TIME [epoch: 7.81 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018903363972117893		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.018903363972117893 | validation: 0.01630637652654693]
	TIME [epoch: 7.79 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02257339586326529		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.02257339586326529 | validation: 0.015873042261444842]
	TIME [epoch: 7.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017026719031724234		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.017026719031724234 | validation: 0.015271734265644328]
	TIME [epoch: 8.05 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013521260424847987		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.013521260424847987 | validation: 0.02071544744810875]
	TIME [epoch: 7.77 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020310405130337203		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.020310405130337203 | validation: 0.07317625021389648]
	TIME [epoch: 7.76 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040223551663055884		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.040223551663055884 | validation: 0.031599302663383386]
	TIME [epoch: 7.76 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020140822359848654		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.020140822359848654 | validation: 0.018646581450864896]
	TIME [epoch: 7.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017996531983966127		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.017996531983966127 | validation: 0.017371247104849476]
	TIME [epoch: 7.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002549463858135		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.017002549463858135 | validation: 0.01820171296538064]
	TIME [epoch: 7.81 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014207960268289585		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.014207960268289585 | validation: 0.015482247365391728]
	TIME [epoch: 7.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02774725139925998		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.02774725139925998 | validation: 0.03281651887721765]
	TIME [epoch: 7.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025992241650882132		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.025992241650882132 | validation: 0.033099273926892034]
	TIME [epoch: 7.77 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020115527833294733		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.020115527833294733 | validation: 0.015115335628465575]
	TIME [epoch: 7.75 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017173807077489306		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.017173807077489306 | validation: 0.03555993188014704]
	TIME [epoch: 7.81 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029973042635937176		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.029973042635937176 | validation: 0.02530923997041789]
	TIME [epoch: 7.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017266380963182226		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.017266380963182226 | validation: 0.02027327652980309]
	TIME [epoch: 7.76 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015834580093105014		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.015834580093105014 | validation: 0.026635544278627923]
	TIME [epoch: 7.75 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03827552003071435		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.03827552003071435 | validation: 0.03153860066863226]
	TIME [epoch: 7.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020204180136648906		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.020204180136648906 | validation: 0.01609957545205766]
	TIME [epoch: 7.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581293029167645		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.01581293029167645 | validation: 0.015602164685260914]
	TIME [epoch: 7.77 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013309532981672811		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.013309532981672811 | validation: 0.01741745642108529]
	TIME [epoch: 7.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015831683898151695		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.015831683898151695 | validation: 0.018677871404383588]
	TIME [epoch: 7.75 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018836274577243378		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.018836274577243378 | validation: 0.016879112996864315]
	TIME [epoch: 7.79 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236197554413855		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.02236197554413855 | validation: 0.03819084211889255]
	TIME [epoch: 7.78 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027713513072561473		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.027713513072561473 | validation: 0.03795954609803006]
	TIME [epoch: 7.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023277466547405236		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.023277466547405236 | validation: 0.01797700823919228]
	TIME [epoch: 7.75 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023583132976701594		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.023583132976701594 | validation: 0.03325547084814069]
	TIME [epoch: 7.75 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020472414664315278		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.020472414664315278 | validation: 0.014666261928678299]
	TIME [epoch: 7.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013465905723925248		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.013465905723925248 | validation: 0.019586298606200578]
	TIME [epoch: 7.75 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01582294759623516		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.01582294759623516 | validation: 0.03598375559646555]
	TIME [epoch: 7.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022810827972894104		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.022810827972894104 | validation: 0.017579572033122656]
	TIME [epoch: 7.77 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014247853114725473		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.014247853114725473 | validation: 0.016456684221880322]
	TIME [epoch: 7.76 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945602483820544		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.01945602483820544 | validation: 0.030845072879920332]
	TIME [epoch: 7.81 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020432272332307044		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.020432272332307044 | validation: 0.03535736933668923]
	TIME [epoch: 7.76 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028338617734679314		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.028338617734679314 | validation: 0.01793789554221745]
	TIME [epoch: 7.76 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018871112070968282		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.018871112070968282 | validation: 0.01914401470572609]
	TIME [epoch: 7.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017905498363275776		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.017905498363275776 | validation: 0.033302864189739344]
	TIME [epoch: 7.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018222559827469297		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.018222559827469297 | validation: 0.030665838337097455]
	TIME [epoch: 7.81 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019695124584973363		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.019695124584973363 | validation: 0.018539952876989105]
	TIME [epoch: 7.77 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384926298586835		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08384926298586835 | validation: 0.10766532624028946]
	TIME [epoch: 7.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933990492105196		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.09933990492105196 | validation: 0.0515558240087569]
	TIME [epoch: 7.75 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035459188663227226		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.035459188663227226 | validation: 0.012682481198198644]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_547.pth
	Model improved!!!
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016516687521673096		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.016516687521673096 | validation: 0.01395320086106237]
	TIME [epoch: 7.81 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014223909569065173		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.014223909569065173 | validation: 0.011650321336475835]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012204917445327942		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.012204917445327942 | validation: 0.011729612841461295]
	TIME [epoch: 7.77 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01261280837188513		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.01261280837188513 | validation: 0.012828529339982069]
	TIME [epoch: 7.78 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01255438247885629		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.01255438247885629 | validation: 0.012757935273597783]
	TIME [epoch: 7.81 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020249899954115674		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.020249899954115674 | validation: 0.031387921802894625]
	TIME [epoch: 7.79 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01934503665692281		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.01934503665692281 | validation: 0.012697471391342547]
	TIME [epoch: 7.78 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015404195224775933		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.015404195224775933 | validation: 0.015924306167738003]
	TIME [epoch: 7.78 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01422149212738924		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.01422149212738924 | validation: 0.01565165216729547]
	TIME [epoch: 7.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012803712495037162		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.012803712495037162 | validation: 0.013081720641500979]
	TIME [epoch: 7.83 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01632591749062315		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.01632591749062315 | validation: 0.014026994872632006]
	TIME [epoch: 7.81 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024528729665346114		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.024528729665346114 | validation: 0.020586271746188635]
	TIME [epoch: 7.79 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013868074802456085		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.013868074802456085 | validation: 0.012882780586139404]
	TIME [epoch: 7.79 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018646934187496807		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.018646934187496807 | validation: 0.028537879254514363]
	TIME [epoch: 7.79 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04406803895634721		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.04406803895634721 | validation: 0.024311718555241866]
	TIME [epoch: 7.84 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021449860331898704		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.021449860331898704 | validation: 0.013575166490407426]
	TIME [epoch: 7.76 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012051365001490767		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.012051365001490767 | validation: 0.019742543482919324]
	TIME [epoch: 7.74 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014747252814639395		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.014747252814639395 | validation: 0.015410278530719232]
	TIME [epoch: 7.78 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014750201542805654		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.014750201542805654 | validation: 0.0118887991231244]
	TIME [epoch: 7.78 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010728815868984208		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.010728815868984208 | validation: 0.010397195420995396]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013689086638681106		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.013689086638681106 | validation: 0.02706341487270818]
	TIME [epoch: 7.79 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016977990695992658		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.016977990695992658 | validation: 0.02087952883740161]
	TIME [epoch: 7.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015599879871672427		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.015599879871672427 | validation: 0.012382078850298576]
	TIME [epoch: 7.79 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013347629791718382		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.013347629791718382 | validation: 0.013699491814487728]
	TIME [epoch: 7.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026355216632492164		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.026355216632492164 | validation: 0.019243775187616857]
	TIME [epoch: 7.85 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014519085288658003		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.014519085288658003 | validation: 0.01393841241855422]
	TIME [epoch: 7.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011444887314804033		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.011444887314804033 | validation: 0.01986383904015225]
	TIME [epoch: 7.79 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02266919730082778		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.02266919730082778 | validation: 0.01376418577168068]
	TIME [epoch: 7.79 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01388923106314992		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.01388923106314992 | validation: 0.01269646775925919]
	TIME [epoch: 7.83 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011620994340941616		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.011620994340941616 | validation: 0.019119969879959647]
	TIME [epoch: 7.79 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018961828846021538		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.018961828846021538 | validation: 0.013199223858901446]
	TIME [epoch: 7.79 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011577741476865739		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.011577741476865739 | validation: 0.011754938241212456]
	TIME [epoch: 7.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014137735942931851		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.014137735942931851 | validation: 0.01718210298675658]
	TIME [epoch: 7.79 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020067747209237086		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.020067747209237086 | validation: 0.012450619615156672]
	TIME [epoch: 7.84 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029643418170140233		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.029643418170140233 | validation: 0.014959837214651443]
	TIME [epoch: 7.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000622107457788		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.04000622107457788 | validation: 0.0600239245338568]
	TIME [epoch: 7.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029734203997762932		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.029734203997762932 | validation: 0.015535604845233818]
	TIME [epoch: 7.79 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012568051923505429		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.012568051923505429 | validation: 0.013536304796350557]
	TIME [epoch: 7.78 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010051213520883482		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.010051213520883482 | validation: 0.012571877160047807]
	TIME [epoch: 7.83 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012213196083757894		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.012213196083757894 | validation: 0.013081694074826199]
	TIME [epoch: 7.78 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0132209135525133		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.0132209135525133 | validation: 0.011982620157129255]
	TIME [epoch: 7.79 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011534682460039308		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.011534682460039308 | validation: 0.1145289270232651]
	TIME [epoch: 7.81 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421296587519718		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.1421296587519718 | validation: 0.06860525427940019]
	TIME [epoch: 7.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640001831636328		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.0640001831636328 | validation: 0.03126043984655773]
	TIME [epoch: 7.84 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023451397676883957		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.023451397676883957 | validation: 0.010259573447274713]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013291324846713186		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.013291324846713186 | validation: 0.010824193985562986]
	TIME [epoch: 7.78 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01083900775367061		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.01083900775367061 | validation: 0.01032221105814083]
	TIME [epoch: 7.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010405548693823699		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.010405548693823699 | validation: 0.009658777706048564]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009872914284866103		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.009872914284866103 | validation: 0.01088250466721716]
	TIME [epoch: 7.81 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010941503939980233		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.010941503939980233 | validation: 0.01080599313472774]
	TIME [epoch: 7.79 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011851656832392143		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.011851656832392143 | validation: 0.01689680232886331]
	TIME [epoch: 7.81 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015511417287428846		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.015511417287428846 | validation: 0.01492894116430483]
	TIME [epoch: 7.79 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01252165921816424		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.01252165921816424 | validation: 0.011730650966087473]
	TIME [epoch: 7.83 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010768101781344292		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.010768101781344292 | validation: 0.013554746522504862]
	TIME [epoch: 7.78 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013366716282024686		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.013366716282024686 | validation: 0.016747778154977806]
	TIME [epoch: 7.78 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012000651696022404		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.012000651696022404 | validation: 0.011212441309254337]
	TIME [epoch: 7.79 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012457465977087924		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.012457465977087924 | validation: 0.016701919412052058]
	TIME [epoch: 7.78 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012210808698250373		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.012210808698250373 | validation: 0.020158048658242056]
	TIME [epoch: 7.84 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014486469482189715		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.014486469482189715 | validation: 0.011561783108882905]
	TIME [epoch: 7.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015743650325913083		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.015743650325913083 | validation: 0.016074910718763796]
	TIME [epoch: 7.79 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011062585817688299		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.011062585817688299 | validation: 0.013126308320976878]
	TIME [epoch: 7.79 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012066420896886115		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.012066420896886115 | validation: 0.020449536852133337]
	TIME [epoch: 7.81 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016360088680768315		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.016360088680768315 | validation: 0.014060868329757696]
	TIME [epoch: 7.83 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011333634109357506		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.011333634109357506 | validation: 0.013649252736723811]
	TIME [epoch: 7.78 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010056858982128344		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.010056858982128344 | validation: 0.010453023461387942]
	TIME [epoch: 7.77 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04436604316708546		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.04436604316708546 | validation: 0.09402887137975638]
	TIME [epoch: 7.79 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08826074439550473		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.08826074439550473 | validation: 0.04236729767824885]
	TIME [epoch: 7.84 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029467696706256742		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.029467696706256742 | validation: 0.010707001182402715]
	TIME [epoch: 7.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013145156370788271		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.013145156370788271 | validation: 0.010700373595822368]
	TIME [epoch: 7.79 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011026141932852916		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.011026141932852916 | validation: 0.015846264771903373]
	TIME [epoch: 7.78 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012526583951972477		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.012526583951972477 | validation: 0.010995696194715018]
	TIME [epoch: 7.81 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010137622855979534		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.010137622855979534 | validation: 0.011221568921794997]
	TIME [epoch: 7.84 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011037273306352477		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.011037273306352477 | validation: 0.010797351415222355]
	TIME [epoch: 7.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012502847453320025		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.012502847453320025 | validation: 0.015789449139656634]
	TIME [epoch: 7.79 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011449684041592006		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.011449684041592006 | validation: 0.010810505795486727]
	TIME [epoch: 7.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011672058605323218		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.011672058605323218 | validation: 0.011831986777411211]
	TIME [epoch: 7.77 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01388619731416334		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.01388619731416334 | validation: 0.013099419627389211]
	TIME [epoch: 7.84 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014620914578745554		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.014620914578745554 | validation: 0.027206476893135934]
	TIME [epoch: 7.79 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024027259581036017		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.024027259581036017 | validation: 0.013452568268156322]
	TIME [epoch: 7.81 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011667162808099388		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.011667162808099388 | validation: 0.011359186664263221]
	TIME [epoch: 7.79 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010834920503305812		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.010834920503305812 | validation: 0.011398069682922875]
	TIME [epoch: 7.79 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009922696783922698		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.009922696783922698 | validation: 0.010385636402354709]
	TIME [epoch: 7.84 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01599820024278487		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.01599820024278487 | validation: 0.011467451454624309]
	TIME [epoch: 7.77 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011527674242966766		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.011527674242966766 | validation: 0.01120402686790047]
	TIME [epoch: 7.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01028704442303133		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.01028704442303133 | validation: 0.014723862279040996]
	TIME [epoch: 7.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010877021328998275		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.010877021328998275 | validation: 0.013249971553857539]
	TIME [epoch: 7.82 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009491376187356484		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.009491376187356484 | validation: 0.011964106784210175]
	TIME [epoch: 7.83 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012724819528257898		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.012724819528257898 | validation: 0.014099909555755664]
	TIME [epoch: 7.79 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012817510722645671		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.012817510722645671 | validation: 0.009951214928304423]
	TIME [epoch: 7.79 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013356481918504283		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.013356481918504283 | validation: 0.012298267832960081]
	TIME [epoch: 7.82 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009983215490534905		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.009983215490534905 | validation: 0.014460060841165474]
	TIME [epoch: 7.83 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010097212052055524		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.010097212052055524 | validation: 0.010568949924659315]
	TIME [epoch: 7.83 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011998875162504558		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.011998875162504558 | validation: 0.017127946415827884]
	TIME [epoch: 7.81 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014172286583960473		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.014172286583960473 | validation: 0.012821283498466517]
	TIME [epoch: 7.82 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01139612554285124		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.01139612554285124 | validation: 0.011486571519128306]
	TIME [epoch: 7.79 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010646978944874331		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.010646978944874331 | validation: 0.010092642049919772]
	TIME [epoch: 7.86 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010122630684809225		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.010122630684809225 | validation: 0.014029608226165634]
	TIME [epoch: 7.81 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009952536805597044		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.009952536805597044 | validation: 0.010167446661537695]
	TIME [epoch: 7.81 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010093978978070267		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.010093978978070267 | validation: 0.014899240890358902]
	TIME [epoch: 7.81 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01365889883193271		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.01365889883193271 | validation: 0.012043648903664583]
	TIME [epoch: 7.83 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015639480793006047		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.015639480793006047 | validation: 0.015196914890746416]
	TIME [epoch: 7.86 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01204891295656823		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.01204891295656823 | validation: 0.011100233424430044]
	TIME [epoch: 7.82 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012253342279397518		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.012253342279397518 | validation: 0.010935635316026867]
	TIME [epoch: 7.81 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00888944730228748		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.00888944730228748 | validation: 0.01367152344700371]
	TIME [epoch: 7.82 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009485020307372409		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.009485020307372409 | validation: 0.009191549460233605]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010091294455153197		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.010091294455153197 | validation: 0.011867035155695437]
	TIME [epoch: 7.82 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010862493110794123		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.010862493110794123 | validation: 0.059335380110624586]
	TIME [epoch: 7.76 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02728472726424435		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.02728472726424435 | validation: 0.015334807290598457]
	TIME [epoch: 7.76 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010673720792705226		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.010673720792705226 | validation: 0.010872980615601909]
	TIME [epoch: 7.78 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024241972097296158		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.024241972097296158 | validation: 0.022171954919256602]
	TIME [epoch: 7.79 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012311535028684605		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.012311535028684605 | validation: 0.012991177705392777]
	TIME [epoch: 7.79 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00969966208565928		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.00969966208565928 | validation: 0.011943803982176501]
	TIME [epoch: 7.78 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00890977417094453		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.00890977417094453 | validation: 0.01047818038621569]
	TIME [epoch: 7.78 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00912551487844403		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.00912551487844403 | validation: 0.012424159795162664]
	TIME [epoch: 7.77 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010107930238749962		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.010107930238749962 | validation: 0.018862213844659057]
	TIME [epoch: 7.81 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011853565189932568		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.011853565189932568 | validation: 0.014771141660714464]
	TIME [epoch: 7.81 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028107533261182573		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.028107533261182573 | validation: 0.04151581453379302]
	TIME [epoch: 7.79 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015076413449300932		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.015076413449300932 | validation: 0.011349999673612818]
	TIME [epoch: 7.78 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008765485363826101		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.008765485363826101 | validation: 0.009800510873145919]
	TIME [epoch: 7.77 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008788251302369928		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.008788251302369928 | validation: 0.009570492986266735]
	TIME [epoch: 7.85 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008247228220145342		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.008247228220145342 | validation: 0.009491356463213375]
	TIME [epoch: 7.79 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010308153537403818		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.010308153537403818 | validation: 0.00955553391580511]
	TIME [epoch: 7.78 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01324808036579174		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.01324808036579174 | validation: 0.011051974893283148]
	TIME [epoch: 7.79 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009024898994167503		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.009024898994167503 | validation: 0.009989180355182852]
	TIME [epoch: 7.77 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009637113669093988		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.009637113669093988 | validation: 0.012465587575235361]
	TIME [epoch: 7.82 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00920491978256471		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.00920491978256471 | validation: 0.01080168952353349]
	TIME [epoch: 7.77 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008690437216872349		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.008690437216872349 | validation: 0.011911848728300117]
	TIME [epoch: 7.77 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009864156042284217		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.009864156042284217 | validation: 0.011201726765504473]
	TIME [epoch: 7.78 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010601081893203967		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.010601081893203967 | validation: 0.012281746997173075]
	TIME [epoch: 7.79 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012030298775565575		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.012030298775565575 | validation: 0.010505571508914572]
	TIME [epoch: 7.81 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01109349627883979		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.01109349627883979 | validation: 0.010637517342675675]
	TIME [epoch: 7.77 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009348427605661569		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.009348427605661569 | validation: 0.015530623101797685]
	TIME [epoch: 7.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012689047905768996		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.012689047905768996 | validation: 0.028416619011147837]
	TIME [epoch: 7.79 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011345590916966826		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.011345590916966826 | validation: 0.01000495687647334]
	TIME [epoch: 7.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008115598557682104		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.008115598557682104 | validation: 0.0744378904571103]
	TIME [epoch: 7.81 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029949574389801906		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.029949574389801906 | validation: 0.02901536471954244]
	TIME [epoch: 7.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015347359560122103		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.015347359560122103 | validation: 0.010408048926924027]
	TIME [epoch: 7.79 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009037117651608043		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.009037117651608043 | validation: 0.012035444772975976]
	TIME [epoch: 7.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009383383574394898		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.009383383574394898 | validation: 0.010533387364548072]
	TIME [epoch: 7.82 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009269899025761842		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.009269899025761842 | validation: 0.01728059803577465]
	TIME [epoch: 7.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010826136182581913		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.010826136182581913 | validation: 0.009699998121202251]
	TIME [epoch: 7.79 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008217273947430144		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.008217273947430144 | validation: 0.011068210900149146]
	TIME [epoch: 7.77 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01381124314392258		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.01381124314392258 | validation: 0.010290732762382368]
	TIME [epoch: 7.78 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009301619104399354		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.009301619104399354 | validation: 0.010674240407443105]
	TIME [epoch: 7.85 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008463447507665898		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.008463447507665898 | validation: 0.03660663780114167]
	TIME [epoch: 7.79 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023228805898245688		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.023228805898245688 | validation: 0.0083101856734362]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008760914675997388		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.008760914675997388 | validation: 0.008654410828451536]
	TIME [epoch: 7.79 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009953687919149787		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.009953687919149787 | validation: 0.009443552013280569]
	TIME [epoch: 7.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007962433838307132		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.007962433838307132 | validation: 0.009084824254514694]
	TIME [epoch: 7.82 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011759492720780213		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.011759492720780213 | validation: 0.015617420275614705]
	TIME [epoch: 7.79 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010665944473651408		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.010665944473651408 | validation: 0.013490272916603964]
	TIME [epoch: 7.78 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009438255323318764		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.009438255323318764 | validation: 0.010806450985344457]
	TIME [epoch: 7.79 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009190986523410547		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.009190986523410547 | validation: 0.013197499877632288]
	TIME [epoch: 7.79 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009870717827090697		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.009870717827090697 | validation: 0.009489244391734817]
	TIME [epoch: 7.86 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011228280299054958		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.011228280299054958 | validation: 0.013598236227556052]
	TIME [epoch: 7.81 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012702934844775205		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.012702934844775205 | validation: 0.01164177499978039]
	TIME [epoch: 7.81 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010195474177490541		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.010195474177490541 | validation: 0.010225651190460483]
	TIME [epoch: 7.79 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009284575963284582		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.009284575963284582 | validation: 0.009654947795614752]
	TIME [epoch: 7.85 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009993395057684004		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.009993395057684004 | validation: 0.010566650804881396]
	TIME [epoch: 7.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009148707614983355		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.009148707614983355 | validation: 0.008247909914972618]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008565953501913937		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.008565953501913937 | validation: 0.00932224671225228]
	TIME [epoch: 7.81 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00906246638733971		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.00906246638733971 | validation: 0.008210380600934954]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007682228932906416		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.007682228932906416 | validation: 0.016979089880569252]
	TIME [epoch: 7.86 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015034648948422448		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.015034648948422448 | validation: 0.009891451881719176]
	TIME [epoch: 7.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009502186405082859		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.009502186405082859 | validation: 0.011722428446016096]
	TIME [epoch: 7.79 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008692163495912932		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.008692163495912932 | validation: 0.011231992491190938]
	TIME [epoch: 7.82 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012589750611256294		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.012589750611256294 | validation: 0.007870553140418029]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008971230726480728		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.008971230726480728 | validation: 0.011932417856847262]
	TIME [epoch: 7.84 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010476589350159425		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.010476589350159425 | validation: 0.00811048437148303]
	TIME [epoch: 7.79 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013529094107427376		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.013529094107427376 | validation: 0.01053305621687415]
	TIME [epoch: 7.78 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00960767637533244		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.00960767637533244 | validation: 0.009040756954629392]
	TIME [epoch: 7.79 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009676375529291409		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.009676375529291409 | validation: 0.009872145104447734]
	TIME [epoch: 7.84 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009013239260164738		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.009013239260164738 | validation: 0.008825058031114231]
	TIME [epoch: 7.82 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007772666238288081		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.007772666238288081 | validation: 0.010181501146427964]
	TIME [epoch: 7.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009002502249307764		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.009002502249307764 | validation: 0.007933095072306377]
	TIME [epoch: 7.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007965301089684646		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.007965301089684646 | validation: 0.008682670853015101]
	TIME [epoch: 7.81 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008444076779901208		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.008444076779901208 | validation: 0.010645363194471832]
	TIME [epoch: 7.86 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250984052229202		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.02250984052229202 | validation: 0.03463179007058961]
	TIME [epoch: 7.81 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017549785448687436		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.017549785448687436 | validation: 0.010266242356854438]
	TIME [epoch: 7.82 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012088543153909087		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.012088543153909087 | validation: 0.008827010524190148]
	TIME [epoch: 7.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007639228497960959		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.007639228497960959 | validation: 0.01165979332291614]
	TIME [epoch: 7.82 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007410491084981775		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.007410491084981775 | validation: 0.00945222230847675]
	TIME [epoch: 7.86 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007678863056379574		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.007678863056379574 | validation: 0.012166243530570546]
	TIME [epoch: 7.81 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008846478015776116		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.008846478015776116 | validation: 0.009642000067872254]
	TIME [epoch: 7.81 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008948004298933405		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.008948004298933405 | validation: 0.009865368280188792]
	TIME [epoch: 7.81 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008663871906354752		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.008663871906354752 | validation: 0.009527879620194274]
	TIME [epoch: 7.85 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009200645270886171		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.009200645270886171 | validation: 0.008508143661990264]
	TIME [epoch: 7.85 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009528185171908902		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.009528185171908902 | validation: 0.010396098558959581]
	TIME [epoch: 7.83 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009468250259770671		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.009468250259770671 | validation: 0.009239546425997761]
	TIME [epoch: 7.81 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008118392540185513		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.008118392540185513 | validation: 0.00865810837045066]
	TIME [epoch: 7.84 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009914527568210225		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.009914527568210225 | validation: 0.010950618150789727]
	TIME [epoch: 7.85 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008626596953220872		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.008626596953220872 | validation: 0.007755658856938515]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008555778979297567		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.008555778979297567 | validation: 0.008437261959954229]
	TIME [epoch: 7.81 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007782144071540511		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.007782144071540511 | validation: 0.011645431472886075]
	TIME [epoch: 7.82 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008171506811390767		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.008171506811390767 | validation: 0.009162269000987]
	TIME [epoch: 7.82 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006949093754112675		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.006949093754112675 | validation: 0.009173170749534148]
	TIME [epoch: 7.87 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010639514473391537		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.010639514473391537 | validation: 0.009825334980004036]
	TIME [epoch: 7.84 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614397664183305		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.01614397664183305 | validation: 0.018456950169290363]
	TIME [epoch: 7.81 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01169838329341217		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.01169838329341217 | validation: 0.008803794522164309]
	TIME [epoch: 7.82 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008061464925387186		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.008061464925387186 | validation: 0.009428469176082168]
	TIME [epoch: 7.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008537769975164419		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.008537769975164419 | validation: 0.009803094951644945]
	TIME [epoch: 7.88 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076770010119383775		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.0076770010119383775 | validation: 0.009846158171110446]
	TIME [epoch: 7.82 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074630529434576865		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0074630529434576865 | validation: 0.009517887807196826]
	TIME [epoch: 7.82 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007478411868860795		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.007478411868860795 | validation: 0.009900174604660621]
	TIME [epoch: 7.79 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008136982199552108		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.008136982199552108 | validation: 0.009630610810344303]
	TIME [epoch: 7.83 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00758634450535571		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.00758634450535571 | validation: 0.009934292766069608]
	TIME [epoch: 7.88 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009112912994616187		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.009112912994616187 | validation: 0.00920838924770427]
	TIME [epoch: 7.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008469447670294748		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.008469447670294748 | validation: 0.009819666169095118]
	TIME [epoch: 7.81 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009907630559775702		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.009907630559775702 | validation: 0.00793114494867205]
	TIME [epoch: 7.82 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00835371804164252		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.00835371804164252 | validation: 0.01197565493804372]
	TIME [epoch: 7.86 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00842014594693632		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.00842014594693632 | validation: 0.008559479919004968]
	TIME [epoch: 7.83 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073108711928231845		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0073108711928231845 | validation: 0.009473617470221282]
	TIME [epoch: 7.82 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077535429940926714		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0077535429940926714 | validation: 0.008129631418481994]
	TIME [epoch: 7.82 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009058400348333722		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.009058400348333722 | validation: 0.010654538439876956]
	TIME [epoch: 7.82 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009856897936231426		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.009856897936231426 | validation: 0.010716575187154898]
	TIME [epoch: 7.85 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008023924257740208		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.008023924257740208 | validation: 0.008480706637231213]
	TIME [epoch: 7.82 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00694741586697114		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.00694741586697114 | validation: 0.007538427465789904]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007917158519365612		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.007917158519365612 | validation: 0.008250321041641136]
	TIME [epoch: 7.78 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008060344817683834		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.008060344817683834 | validation: 0.01041489253764461]
	TIME [epoch: 7.77 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008845130424380827		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.008845130424380827 | validation: 0.009341133885516441]
	TIME [epoch: 7.81 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009002973115476291		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.009002973115476291 | validation: 0.009013038278836386]
	TIME [epoch: 7.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00842135210136655		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.00842135210136655 | validation: 0.010665612427661026]
	TIME [epoch: 7.77 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00827281440317656		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.00827281440317656 | validation: 0.008018730292319524]
	TIME [epoch: 7.79 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008892393421422028		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.008892393421422028 | validation: 0.009030436010874075]
	TIME [epoch: 7.79 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007410709176426279		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.007410709176426279 | validation: 0.00945767069825609]
	TIME [epoch: 7.83 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008390028962831234		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.008390028962831234 | validation: 0.015121690892472374]
	TIME [epoch: 7.79 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009015740165023925		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.009015740165023925 | validation: 0.008341568517192522]
	TIME [epoch: 7.78 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013161642444921033		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.013161642444921033 | validation: 0.01401723011623857]
	TIME [epoch: 7.79 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008763559638604018		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.008763559638604018 | validation: 0.00763279297193808]
	TIME [epoch: 7.81 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007473863834576592		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.007473863834576592 | validation: 0.007919605939505383]
	TIME [epoch: 7.82 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007249458265195904		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.007249458265195904 | validation: 0.009812078158440943]
	TIME [epoch: 7.75 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00755236827586852		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.00755236827586852 | validation: 0.009108349400688972]
	TIME [epoch: 7.77 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007103144354257339		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.007103144354257339 | validation: 0.007764095039899789]
	TIME [epoch: 7.79 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009225207230846586		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.009225207230846586 | validation: 0.00936584985869036]
	TIME [epoch: 7.82 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007079441822047391		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.007079441822047391 | validation: 0.008695501713052714]
	TIME [epoch: 7.78 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070959842607830476		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0070959842607830476 | validation: 0.008419045015491658]
	TIME [epoch: 7.79 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00781324733724422		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.00781324733724422 | validation: 0.008320954674814475]
	TIME [epoch: 7.77 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006823603033564984		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.006823603033564984 | validation: 0.03312689634870575]
	TIME [epoch: 7.77 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019401192920920775		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.019401192920920775 | validation: 0.009494600602057446]
	TIME [epoch: 7.83 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007839265803548698		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.007839265803548698 | validation: 0.008856271155146927]
	TIME [epoch: 7.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00680622754641259		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.00680622754641259 | validation: 0.007897903117981586]
	TIME [epoch: 7.78 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007048879690176298		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.007048879690176298 | validation: 0.008405872962540913]
	TIME [epoch: 7.76 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007356696682831057		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.007356696682831057 | validation: 0.008450028504912045]
	TIME [epoch: 7.79 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007154885861641449		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.007154885861641449 | validation: 0.008171607587523652]
	TIME [epoch: 7.84 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008006074402310846		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.008006074402310846 | validation: 0.009983112412498158]
	TIME [epoch: 7.78 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00986451068095075		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.00986451068095075 | validation: 0.011226069567170389]
	TIME [epoch: 7.76 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007847560885194105		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.007847560885194105 | validation: 0.008546353409796039]
	TIME [epoch: 7.78 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007559024562474808		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.007559024562474808 | validation: 0.009964545722678606]
	TIME [epoch: 7.81 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007578978004431203		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.007578978004431203 | validation: 0.008035442302439976]
	TIME [epoch: 7.83 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007075607100652297		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.007075607100652297 | validation: 0.0081569180973393]
	TIME [epoch: 7.76 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007815604836823203		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.007815604836823203 | validation: 0.011981191234030589]
	TIME [epoch: 7.78 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008868914487038441		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.008868914487038441 | validation: 0.00922712884309426]
	TIME [epoch: 7.79 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007687028123734145		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.007687028123734145 | validation: 0.0077864571387595265]
	TIME [epoch: 7.79 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010374567335096011		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.010374567335096011 | validation: 0.011684177870097876]
	TIME [epoch: 7.83 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00853709705422027		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.00853709705422027 | validation: 0.009203106276093852]
	TIME [epoch: 7.82 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007519218100069752		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.007519218100069752 | validation: 0.008915528405614647]
	TIME [epoch: 7.81 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072236515288951215		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0072236515288951215 | validation: 0.008114018782734565]
	TIME [epoch: 7.81 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008517672106695608		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.008517672106695608 | validation: 0.007766870633803394]
	TIME [epoch: 7.84 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007381524905852475		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.007381524905852475 | validation: 0.008738862225145673]
	TIME [epoch: 7.83 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007825046967064207		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.007825046967064207 | validation: 0.008686525217804697]
	TIME [epoch: 7.81 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00639410282583139		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.00639410282583139 | validation: 0.008185148711900594]
	TIME [epoch: 7.81 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008372824067515224		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.008372824067515224 | validation: 0.008163204107007348]
	TIME [epoch: 7.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00704593752651281		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.00704593752651281 | validation: 0.007261154605013843]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006514645625215159		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.006514645625215159 | validation: 0.007519181705958604]
	TIME [epoch: 7.81 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00699774923492052		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.00699774923492052 | validation: 0.014020972235571237]
	TIME [epoch: 7.81 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009836930632540845		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.009836930632540845 | validation: 0.00797388319049871]
	TIME [epoch: 7.82 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00829686344144043		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.00829686344144043 | validation: 0.009072234604118063]
	TIME [epoch: 7.82 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007865907952812601		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.007865907952812601 | validation: 0.007518407364337303]
	TIME [epoch: 7.88 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007039416214692748		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.007039416214692748 | validation: 0.01258346200457168]
	TIME [epoch: 7.81 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008864309606347787		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.008864309606347787 | validation: 0.008832202932636403]
	TIME [epoch: 7.82 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006793796742590114		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.006793796742590114 | validation: 0.00801828678927239]
	TIME [epoch: 7.81 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066537839564579735		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0066537839564579735 | validation: 0.009565683980860882]
	TIME [epoch: 7.85 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007137109800841923		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.007137109800841923 | validation: 0.00921665798360271]
	TIME [epoch: 7.85 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009124794161102937		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.009124794161102937 | validation: 0.007786278291790917]
	TIME [epoch: 7.81 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012456801539439875		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.012456801539439875 | validation: 0.008550680197632986]
	TIME [epoch: 7.81 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007385872659453414		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.007385872659453414 | validation: 0.0068412790366603835]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_823.pth
	Model improved!!!
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006693847011564985		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.006693847011564985 | validation: 0.007701513035483323]
	TIME [epoch: 7.86 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006667049085117999		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.006667049085117999 | validation: 0.008055202492783844]
	TIME [epoch: 7.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006595478112395742		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.006595478112395742 | validation: 0.00684430183642183]
	TIME [epoch: 7.83 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006645274442922556		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.006645274442922556 | validation: 0.008566337120884941]
	TIME [epoch: 7.82 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069579107192808635		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0069579107192808635 | validation: 0.008407992106962508]
	TIME [epoch: 7.81 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006847687980932179		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.006847687980932179 | validation: 0.007777127655750811]
	TIME [epoch: 7.88 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007976432571871764		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.007976432571871764 | validation: 0.008356981178133892]
	TIME [epoch: 7.82 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006563022737989928		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.006563022737989928 | validation: 0.010149844676301109]
	TIME [epoch: 7.83 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00764111148782263		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.00764111148782263 | validation: 0.009800433579201481]
	TIME [epoch: 7.83 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007313340873613939		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.007313340873613939 | validation: 0.009230930223283262]
	TIME [epoch: 7.82 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007171554249928533		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.007171554249928533 | validation: 0.013301808314027438]
	TIME [epoch: 7.87 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00789496619368512		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.00789496619368512 | validation: 0.00785175197989705]
	TIME [epoch: 7.82 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006499579205926691		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.006499579205926691 | validation: 0.00888814903586656]
	TIME [epoch: 7.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065121161331038535		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0065121161331038535 | validation: 0.008408330641072865]
	TIME [epoch: 7.82 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00992238691637842		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.00992238691637842 | validation: 0.009344525082154284]
	TIME [epoch: 7.86 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00687858943684563		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.00687858943684563 | validation: 0.0066403150059436335]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064705750574006165		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0064705750574006165 | validation: 0.007650383677953575]
	TIME [epoch: 7.83 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00711163523296591		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.00711163523296591 | validation: 0.007277474902913063]
	TIME [epoch: 7.84 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006706342103531649		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.006706342103531649 | validation: 0.011116498131486706]
	TIME [epoch: 7.83 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008673129660274231		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.008673129660274231 | validation: 0.0073268855127664265]
	TIME [epoch: 7.87 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006824102950618296		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.006824102950618296 | validation: 0.007632051628596662]
	TIME [epoch: 7.82 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007046859618996289		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.007046859618996289 | validation: 0.008755184988368006]
	TIME [epoch: 7.82 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00743552632677614		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.00743552632677614 | validation: 0.009844175198042758]
	TIME [epoch: 7.81 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00715043138426141		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.00715043138426141 | validation: 0.008287357741719997]
	TIME [epoch: 7.83 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064139373307360754		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0064139373307360754 | validation: 0.008919947033106125]
	TIME [epoch: 7.85 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007137843342451043		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.007137843342451043 | validation: 0.008748830721365435]
	TIME [epoch: 7.81 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008146051263379053		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.008146051263379053 | validation: 0.00820897693607957]
	TIME [epoch: 7.77 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00658961792541123		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.00658961792541123 | validation: 0.009250791720128968]
	TIME [epoch: 7.82 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006189675073249503		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.006189675073249503 | validation: 0.008312863638257298]
	TIME [epoch: 7.81 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00760727725700629		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.00760727725700629 | validation: 0.007925811395264687]
	TIME [epoch: 7.85 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0090534437138199		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0090534437138199 | validation: 0.008497889206803794]
	TIME [epoch: 7.83 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00843776948380958		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.00843776948380958 | validation: 0.009698452581266042]
	TIME [epoch: 7.82 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006430315599384809		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.006430315599384809 | validation: 0.007979138267963641]
	TIME [epoch: 7.82 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006814374810704181		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.006814374810704181 | validation: 0.00826415748065828]
	TIME [epoch: 7.84 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066705574759110264		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0066705574759110264 | validation: 0.008747280075493209]
	TIME [epoch: 7.85 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007145011033429442		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.007145011033429442 | validation: 0.007711411125335241]
	TIME [epoch: 7.82 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007742578645389388		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.007742578645389388 | validation: 0.008040028102219918]
	TIME [epoch: 7.82 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006623866650422108		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.006623866650422108 | validation: 0.008418598559221313]
	TIME [epoch: 7.82 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006574242484460509		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.006574242484460509 | validation: 0.011298444431466005]
	TIME [epoch: 7.84 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00794108284243666		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.00794108284243666 | validation: 0.008188824614196418]
	TIME [epoch: 7.84 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007340215643284725		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.007340215643284725 | validation: 0.008713541752167136]
	TIME [epoch: 7.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007820258569996213		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.007820258569996213 | validation: 0.009792662621083003]
	TIME [epoch: 7.82 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007506035357013479		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.007506035357013479 | validation: 0.007692212290903989]
	TIME [epoch: 7.81 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006604236485049476		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.006604236485049476 | validation: 0.008310942405275206]
	TIME [epoch: 7.86 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062662215698040995		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0062662215698040995 | validation: 0.00738182611321501]
	TIME [epoch: 7.81 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007255800826613612		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.007255800826613612 | validation: 0.007156917082357049]
	TIME [epoch: 7.83 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006306794790484898		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.006306794790484898 | validation: 0.008554175218100958]
	TIME [epoch: 7.81 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006470559037423965		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.006470559037423965 | validation: 0.025821831072360794]
	TIME [epoch: 7.82 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01226554832682553		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.01226554832682553 | validation: 0.007347458897367722]
	TIME [epoch: 7.87 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006711693766398144		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.006711693766398144 | validation: 0.007490321165263045]
	TIME [epoch: 7.81 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006350449754090395		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.006350449754090395 | validation: 0.008542824141041188]
	TIME [epoch: 7.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007755277070260916		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.007755277070260916 | validation: 0.007052358144807257]
	TIME [epoch: 7.82 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006736638722918318		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.006736638722918318 | validation: 0.007838194420572906]
	TIME [epoch: 7.83 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006197703474021299		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.006197703474021299 | validation: 0.006595037834670049]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_877.pth
	Model improved!!!
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006679667873870232		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.006679667873870232 | validation: 0.007486735309930415]
	TIME [epoch: 7.83 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006220033014711327		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.006220033014711327 | validation: 0.007443183324150027]
	TIME [epoch: 7.82 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007080887677176932		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.007080887677176932 | validation: 0.008422274349148023]
	TIME [epoch: 7.83 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006548206134656856		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.006548206134656856 | validation: 0.006768943507125489]
	TIME [epoch: 7.88 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006743424423182798		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.006743424423182798 | validation: 0.008645353834490185]
	TIME [epoch: 7.83 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066727405628221395		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0066727405628221395 | validation: 0.007070409668849954]
	TIME [epoch: 7.81 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00648520084773708		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.00648520084773708 | validation: 0.009407433618140282]
	TIME [epoch: 7.83 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006672486973993154		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.006672486973993154 | validation: 0.0074744304436593426]
	TIME [epoch: 7.82 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007165485521077432		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.007165485521077432 | validation: 0.007141918054750077]
	TIME [epoch: 7.89 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063640502139871566		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0063640502139871566 | validation: 0.007744722395068564]
	TIME [epoch: 7.82 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006071055732728045		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.006071055732728045 | validation: 0.007197727342020097]
	TIME [epoch: 7.84 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006897796824705803		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.006897796824705803 | validation: 0.008992116715715016]
	TIME [epoch: 7.82 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007244893242630862		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.007244893242630862 | validation: 0.007156959803103878]
	TIME [epoch: 7.83 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006068770895424032		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.006068770895424032 | validation: 0.009378252068158524]
	TIME [epoch: 7.87 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007007147927272091		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.007007147927272091 | validation: 0.007161081145244826]
	TIME [epoch: 7.83 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009102033625169719		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.009102033625169719 | validation: 0.007953883230504654]
	TIME [epoch: 7.81 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006211569762965155		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.006211569762965155 | validation: 0.006910594541170602]
	TIME [epoch: 7.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006228606917806675		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.006228606917806675 | validation: 0.0074051911382073095]
	TIME [epoch: 7.85 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006546060346627589		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.006546060346627589 | validation: 0.007808274526960713]
	TIME [epoch: 7.85 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007086274979276376		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.007086274979276376 | validation: 0.01015437593827038]
	TIME [epoch: 7.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007627794139424783		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.007627794139424783 | validation: 0.007015041705133982]
	TIME [epoch: 7.82 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00634047554911034		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.00634047554911034 | validation: 0.0070459898512937385]
	TIME [epoch: 7.82 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006489421371536205		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.006489421371536205 | validation: 0.010396227278155737]
	TIME [epoch: 7.87 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006858233329416484		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.006858233329416484 | validation: 0.007364068721105104]
	TIME [epoch: 7.84 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006106744226289413		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.006106744226289413 | validation: 0.007407986961086413]
	TIME [epoch: 7.82 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061265484916899786		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.0061265484916899786 | validation: 0.007643295961310507]
	TIME [epoch: 7.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006560348257942241		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.006560348257942241 | validation: 0.007364134990451882]
	TIME [epoch: 7.83 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006661849621778979		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.006661849621778979 | validation: 0.0072535219356578105]
	TIME [epoch: 7.88 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008396732980990643		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.008396732980990643 | validation: 0.008323744775426963]
	TIME [epoch: 7.84 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066039826480632		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0066039826480632 | validation: 0.010999135064843155]
	TIME [epoch: 7.81 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008028142559717406		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.008028142559717406 | validation: 0.008285406752245752]
	TIME [epoch: 7.83 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065233026415118705		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.0065233026415118705 | validation: 0.006965976628970025]
	TIME [epoch: 7.83 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007511225027854391		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.007511225027854391 | validation: 0.010975742348967466]
	TIME [epoch: 7.85 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006843906653589866		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.006843906653589866 | validation: 0.007653249672260092]
	TIME [epoch: 7.82 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063230990990925575		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.0063230990990925575 | validation: 0.008073507581869746]
	TIME [epoch: 7.82 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006873301795551452		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.006873301795551452 | validation: 0.00652058866620764]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006140033026699527		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.006140033026699527 | validation: 0.021597120132676104]
	TIME [epoch: 7.82 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010212472140211128		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.010212472140211128 | validation: 0.006473533066063693]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_915.pth
	Model improved!!!
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006456096675809109		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.006456096675809109 | validation: 0.007646231317104972]
	TIME [epoch: 7.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006123278528144485		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.006123278528144485 | validation: 0.007729247925930251]
	TIME [epoch: 7.81 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006136402486128644		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.006136402486128644 | validation: 0.009396437630390749]
	TIME [epoch: 7.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007064013723900727		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.007064013723900727 | validation: 0.007680682343548835]
	TIME [epoch: 7.87 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006193878594543104		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.006193878594543104 | validation: 0.007869074638841955]
	TIME [epoch: 7.76 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006660448210382484		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.006660448210382484 | validation: 0.006954869752229722]
	TIME [epoch: 7.76 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006032102776560463		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.006032102776560463 | validation: 0.007082551572934559]
	TIME [epoch: 7.81 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005893150409410857		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.005893150409410857 | validation: 0.007334617651050262]
	TIME [epoch: 7.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006195001319761145		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.006195001319761145 | validation: 0.0069392143498636545]
	TIME [epoch: 7.84 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006365042186781646		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.006365042186781646 | validation: 0.008147949240832857]
	TIME [epoch: 7.81 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068805262116510835		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0068805262116510835 | validation: 0.011141977108311822]
	TIME [epoch: 7.79 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006963899389336128		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.006963899389336128 | validation: 0.007072103528073527]
	TIME [epoch: 7.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006337526805944092		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.006337526805944092 | validation: 0.008078253197648856]
	TIME [epoch: 7.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006125733192406105		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.006125733192406105 | validation: 0.007466401099631698]
	TIME [epoch: 7.84 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007711638374953099		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.007711638374953099 | validation: 0.007672429706874326]
	TIME [epoch: 7.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006590950646629763		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.006590950646629763 | validation: 0.006478315940452999]
	TIME [epoch: 7.78 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006871350723985033		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.006871350723985033 | validation: 0.006582653475423287]
	TIME [epoch: 7.79 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062003304895686786		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.0062003304895686786 | validation: 0.006960788226229986]
	TIME [epoch: 7.82 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005728575654591483		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.005728575654591483 | validation: 0.006805975212108182]
	TIME [epoch: 7.84 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006288633268779596		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.006288633268779596 | validation: 0.008825562014688326]
	TIME [epoch: 7.81 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00720324260111504		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.00720324260111504 | validation: 0.0071945365930530854]
	TIME [epoch: 7.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062045689904568916		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0062045689904568916 | validation: 0.00770253591882788]
	TIME [epoch: 7.81 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006570426311184479		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.006570426311184479 | validation: 0.008107056771696743]
	TIME [epoch: 7.85 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006549544943518681		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.006549544943518681 | validation: 0.007654542514911444]
	TIME [epoch: 7.81 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062309895467142894		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0062309895467142894 | validation: 0.007774548428726735]
	TIME [epoch: 7.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005925573487794334		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.005925573487794334 | validation: 0.007105428631868321]
	TIME [epoch: 7.81 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006131894354536054		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.006131894354536054 | validation: 0.0065695636494782685]
	TIME [epoch: 7.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006206560338676598		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.006206560338676598 | validation: 0.007016996674438629]
	TIME [epoch: 7.86 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00571798675916937		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.00571798675916937 | validation: 0.007887299675190192]
	TIME [epoch: 7.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006026072410457029		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.006026072410457029 | validation: 0.0071631885343577985]
	TIME [epoch: 7.81 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006184862112266161		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.006184862112266161 | validation: 0.006712356838138132]
	TIME [epoch: 7.81 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006460006329726887		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.006460006329726887 | validation: 0.00777557188495409]
	TIME [epoch: 7.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006336366585681256		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.006336366585681256 | validation: 0.0071542017596638524]
	TIME [epoch: 7.85 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005907074689512205		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.005907074689512205 | validation: 0.007418614096999205]
	TIME [epoch: 7.82 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005642690279329049		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.005642690279329049 | validation: 0.006679928506474915]
	TIME [epoch: 7.81 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065970354135986		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0065970354135986 | validation: 0.006309278186331367]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_951.pth
	Model improved!!!
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006029164732045439		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.006029164732045439 | validation: 0.007174758077156998]
	TIME [epoch: 7.83 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005338745335585893		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.005338745335585893 | validation: 0.0069293985393984615]
	TIME [epoch: 7.87 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006127372632589401		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.006127372632589401 | validation: 0.0066197961639409]
	TIME [epoch: 7.84 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062027807954779515		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0062027807954779515 | validation: 0.007683466179636089]
	TIME [epoch: 7.83 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006095194826040432		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.006095194826040432 | validation: 0.007184478935137559]
	TIME [epoch: 7.82 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006349532514116202		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.006349532514116202 | validation: 0.006458287877620427]
	TIME [epoch: 7.86 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006496050851464844		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.006496050851464844 | validation: 0.006230309743888631]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_958.pth
	Model improved!!!
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064485579459208605		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0064485579459208605 | validation: 0.006242858154023684]
	TIME [epoch: 7.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006474988204995455		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.006474988204995455 | validation: 0.006799453204070617]
	TIME [epoch: 7.82 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006487509386611665		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.006487509386611665 | validation: 0.007590804792593294]
	TIME [epoch: 7.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005944033405786275		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.005944033405786275 | validation: 0.006608858995766733]
	TIME [epoch: 7.88 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006694735145419213		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.006694735145419213 | validation: 0.007373340238828334]
	TIME [epoch: 7.81 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058166990982229235		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.0058166990982229235 | validation: 0.00677947351230859]
	TIME [epoch: 7.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006269813246608778		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.006269813246608778 | validation: 0.00667981619077089]
	TIME [epoch: 7.82 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00607238833994045		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.00607238833994045 | validation: 0.007379332801305925]
	TIME [epoch: 7.83 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006459349680562929		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.006459349680562929 | validation: 0.008412894287809338]
	TIME [epoch: 7.86 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006230687145498774		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.006230687145498774 | validation: 0.008231285536316697]
	TIME [epoch: 7.81 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006356141728281897		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.006356141728281897 | validation: 0.008615994113753252]
	TIME [epoch: 7.81 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005893244085974005		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.005893244085974005 | validation: 0.007201561304906098]
	TIME [epoch: 7.82 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007283196297354409		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.007283196297354409 | validation: 0.010812885525731853]
	TIME [epoch: 7.83 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065377958525439615		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0065377958525439615 | validation: 0.0075190523203973025]
	TIME [epoch: 7.84 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005774214910895146		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.005774214910895146 | validation: 0.006383195450416323]
	TIME [epoch: 7.81 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005832369407307855		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.005832369407307855 | validation: 0.00704701185005186]
	TIME [epoch: 7.81 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006147606884605159		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.006147606884605159 | validation: 0.007016221528959694]
	TIME [epoch: 7.81 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006568574710489338		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.006568574710489338 | validation: 0.006486969097989645]
	TIME [epoch: 7.86 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005948414984873316		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.005948414984873316 | validation: 0.006770549343925583]
	TIME [epoch: 7.83 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005740565654000424		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.005740565654000424 | validation: 0.007089059128985789]
	TIME [epoch: 7.82 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006005741342758058		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.006005741342758058 | validation: 0.008229395371760808]
	TIME [epoch: 7.82 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006251902352731583		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.006251902352731583 | validation: 0.006805435999717824]
	TIME [epoch: 7.83 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005903748845278646		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.005903748845278646 | validation: 0.007002865376824208]
	TIME [epoch: 7.86 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061180863702571565		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0061180863702571565 | validation: 0.00781157893652213]
	TIME [epoch: 7.81 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00601575908077555		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.00601575908077555 | validation: 0.007275443578324931]
	TIME [epoch: 7.81 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006309526211761011		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.006309526211761011 | validation: 0.006562634039739845]
	TIME [epoch: 7.81 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006003363400189964		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.006003363400189964 | validation: 0.007505252425433815]
	TIME [epoch: 7.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006556282048425425		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.006556282048425425 | validation: 0.006822012721901991]
	TIME [epoch: 7.86 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006244941740158189		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.006244941740158189 | validation: 0.006439172787170481]
	TIME [epoch: 7.81 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006009486706198674		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.006009486706198674 | validation: 0.009709408079559464]
	TIME [epoch: 7.82 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005903128972717147		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.005903128972717147 | validation: 0.006339605628965378]
	TIME [epoch: 7.82 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005703694741489268		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.005703694741489268 | validation: 0.007458469121388891]
	TIME [epoch: 7.82 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006644110908922735		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.006644110908922735 | validation: 0.007476396654696356]
	TIME [epoch: 7.85 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005802101376219418		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.005802101376219418 | validation: 0.007349544220068326]
	TIME [epoch: 7.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006046972083137008		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.006046972083137008 | validation: 0.007671239886336703]
	TIME [epoch: 7.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059824707477452894		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0059824707477452894 | validation: 0.006399779213208586]
	TIME [epoch: 7.83 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00563667513367064		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.00563667513367064 | validation: 0.0064745536883737305]
	TIME [epoch: 7.84 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006171622149348139		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.006171622149348139 | validation: 0.007099600988109363]
	TIME [epoch: 7.85 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006108396161121995		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.006108396161121995 | validation: 0.008768967325038754]
	TIME [epoch: 7.81 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005849245170683562		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.005849245170683562 | validation: 0.006684847526819911]
	TIME [epoch: 7.81 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005760995187636807		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.005760995187636807 | validation: 0.007482678095692922]
	TIME [epoch: 7.81 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011509751650275438		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.011509751650275438 | validation: 0.011684602846188167]
	TIME [epoch: 7.89 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008839845837439832		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.008839845837439832 | validation: 0.00678642841690438]
	TIME [epoch: 7.82 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005951616451595044		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.005951616451595044 | validation: 0.006101373057664441]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_1002.pth
	Model improved!!!
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054016271109835305		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0054016271109835305 | validation: 0.0056055297403804156]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056229890466939795		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0056229890466939795 | validation: 0.006726315164246589]
	TIME [epoch: 7.82 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00555164943667869		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.00555164943667869 | validation: 0.005687308897182571]
	TIME [epoch: 7.87 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005726213774045005		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.005726213774045005 | validation: 0.006466595711885573]
	TIME [epoch: 7.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005451065129444403		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.005451065129444403 | validation: 0.006131362002122277]
	TIME [epoch: 7.81 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005974483425526867		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.005974483425526867 | validation: 0.007010278414301968]
	TIME [epoch: 7.82 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005870849534174231		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.005870849534174231 | validation: 0.006576865325172256]
	TIME [epoch: 7.84 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006032644116179484		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.006032644116179484 | validation: 0.006931236840794974]
	TIME [epoch: 7.84 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00586831161446785		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.00586831161446785 | validation: 0.00781938533160558]
	TIME [epoch: 7.82 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005963221207078423		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.005963221207078423 | validation: 0.007558749915210825]
	TIME [epoch: 7.82 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011270585771433445		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.011270585771433445 | validation: 0.01316102719155722]
	TIME [epoch: 7.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009778117808247824		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.009778117808247824 | validation: 0.007506703729254497]
	TIME [epoch: 7.86 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006272727918886168		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.006272727918886168 | validation: 0.00641726738489286]
	TIME [epoch: 7.82 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005988121051310575		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.005988121051310575 | validation: 0.006208532792744586]
	TIME [epoch: 7.82 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005330268138065386		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.005330268138065386 | validation: 0.006613224189737017]
	TIME [epoch: 7.81 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005745905221968646		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.005745905221968646 | validation: 0.0055294334368655405]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_1018.pth
	Model improved!!!
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005326224424721718		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.005326224424721718 | validation: 0.006465055983398445]
	TIME [epoch: 7.83 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005490910125848862		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.005490910125848862 | validation: 0.0065550487413077296]
	TIME [epoch: 7.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005802123693856983		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.005802123693856983 | validation: 0.006861493250937384]
	TIME [epoch: 7.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055704553565150425		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0055704553565150425 | validation: 0.007372002369827374]
	TIME [epoch: 7.79 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006225589551346285		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.006225589551346285 | validation: 0.0066357152170992886]
	TIME [epoch: 7.79 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058531785699114675		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0058531785699114675 | validation: 0.01132049172639787]
	TIME [epoch: 7.83 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007835483236641416		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.007835483236641416 | validation: 0.006329724240100939]
	TIME [epoch: 7.81 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005801677926337912		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.005801677926337912 | validation: 0.006452924084433272]
	TIME [epoch: 7.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005586441135352989		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.005586441135352989 | validation: 0.006654396298831402]
	TIME [epoch: 7.79 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007273734107075869		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.007273734107075869 | validation: 0.007437949666729744]
	TIME [epoch: 7.81 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005951534517955243		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.005951534517955243 | validation: 0.007225314572845908]
	TIME [epoch: 7.82 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005995681872392386		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.005995681872392386 | validation: 0.007163054549727147]
	TIME [epoch: 7.78 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063362951625721		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0063362951625721 | validation: 0.007628952908377801]
	TIME [epoch: 7.78 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005974265572776587		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.005974265572776587 | validation: 0.00722220321294562]
	TIME [epoch: 7.78 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006174758379322045		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.006174758379322045 | validation: 0.007955628185164047]
	TIME [epoch: 7.84 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005202058260213723		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.005202058260213723 | validation: 0.00649555457537692]
	TIME [epoch: 7.78 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006218256298350462		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.006218256298350462 | validation: 0.006748455611181853]
	TIME [epoch: 7.78 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005653871604636302		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.005653871604636302 | validation: 0.0062415339223530625]
	TIME [epoch: 7.78 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053590002045415495		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0053590002045415495 | validation: 0.006398939430933136]
	TIME [epoch: 7.79 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006768446579898545		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.006768446579898545 | validation: 0.007643740816521274]
	TIME [epoch: 7.84 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005787576792896778		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.005787576792896778 | validation: 0.007294073170563553]
	TIME [epoch: 7.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005596256150918424		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.005596256150918424 | validation: 0.006457338045062001]
	TIME [epoch: 7.77 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006007158939228449		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.006007158939228449 | validation: 0.006323096123063814]
	TIME [epoch: 7.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055337430165052		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.0055337430165052 | validation: 0.006347918505575034]
	TIME [epoch: 7.79 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00566668342463757		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.00566668342463757 | validation: 0.006210738612646741]
	TIME [epoch: 7.84 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006353765116661142		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.006353765116661142 | validation: 0.006306812149392747]
	TIME [epoch: 7.78 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006242825998355617		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.006242825998355617 | validation: 0.007801915419904192]
	TIME [epoch: 7.78 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005596125342247892		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.005596125342247892 | validation: 0.006612210002998715]
	TIME [epoch: 7.78 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00531783715232717		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.00531783715232717 | validation: 0.006361885715320139]
	TIME [epoch: 7.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005381453932744423		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.005381453932744423 | validation: 0.006058833191572382]
	TIME [epoch: 7.82 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005551145833143147		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.005551145833143147 | validation: 0.007170672016454303]
	TIME [epoch: 7.78 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005527309094918905		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.005527309094918905 | validation: 0.006763645260115742]
	TIME [epoch: 7.78 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006042349058653918		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.006042349058653918 | validation: 0.006811714396019308]
	TIME [epoch: 7.78 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005559347489393891		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.005559347489393891 | validation: 0.006077816658855722]
	TIME [epoch: 7.82 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005646848731086606		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.005646848731086606 | validation: 0.007114699163749483]
	TIME [epoch: 7.82 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005805495496436622		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.005805495496436622 | validation: 0.0075223211077206625]
	TIME [epoch: 7.77 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007074314326759006		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.007074314326759006 | validation: 0.007734451961898222]
	TIME [epoch: 7.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006219346445256772		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.006219346445256772 | validation: 0.005989634977598924]
	TIME [epoch: 7.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005582815657659113		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.005582815657659113 | validation: 0.007721786710424781]
	TIME [epoch: 7.84 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005505194084434982		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.005505194084434982 | validation: 0.006591866916215065]
	TIME [epoch: 7.81 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005610937244646846		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.005610937244646846 | validation: 0.006666664767870232]
	TIME [epoch: 7.79 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005864546610368563		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.005864546610368563 | validation: 0.006376820025482427]
	TIME [epoch: 7.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005720227305964255		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.005720227305964255 | validation: 0.006298333736517585]
	TIME [epoch: 7.79 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005523806245762723		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.005523806245762723 | validation: 0.006286803786175969]
	TIME [epoch: 7.82 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055119993811128766		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0055119993811128766 | validation: 0.007302053204635705]
	TIME [epoch: 7.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006049263660074565		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.006049263660074565 | validation: 0.007525455725916415]
	TIME [epoch: 7.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005628528076453857		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.005628528076453857 | validation: 0.008063039362853984]
	TIME [epoch: 7.79 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005312115047928775		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.005312115047928775 | validation: 0.007204010702540283]
	TIME [epoch: 7.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011116686391145575		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.011116686391145575 | validation: 0.006758819079026481]
	TIME [epoch: 7.84 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006173137661599723		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.006173137661599723 | validation: 0.0109802279806585]
	TIME [epoch: 7.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006934074510252408		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.006934074510252408 | validation: 0.006489443523747336]
	TIME [epoch: 7.78 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005579647169758789		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.005579647169758789 | validation: 0.006891937846041277]
	TIME [epoch: 7.79 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005616639240653074		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.005616639240653074 | validation: 0.007358129890709502]
	TIME [epoch: 7.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005554600189610938		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.005554600189610938 | validation: 0.006638135197308855]
	TIME [epoch: 7.83 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054157046966222516		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.0054157046966222516 | validation: 0.00642431434969868]
	TIME [epoch: 7.78 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005587143952156682		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.005587143952156682 | validation: 0.006770820469170914]
	TIME [epoch: 7.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005445428313583621		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.005445428313583621 | validation: 0.006386694494665838]
	TIME [epoch: 7.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005485538034880308		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.005485538034880308 | validation: 0.006070245417144336]
	TIME [epoch: 7.81 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005264666338866048		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.005264666338866048 | validation: 0.005762249997684356]
	TIME [epoch: 7.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005487932337845305		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.005487932337845305 | validation: 0.00753974420628305]
	TIME [epoch: 7.79 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005462590159744034		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.005462590159744034 | validation: 0.006935492871286085]
	TIME [epoch: 7.78 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005703995866981973		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.005703995866981973 | validation: 0.006561085742446487]
	TIME [epoch: 7.78 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006013258266086703		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.006013258266086703 | validation: 0.006974701430169664]
	TIME [epoch: 7.81 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055275461628073175		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0055275461628073175 | validation: 0.006525768661152495]
	TIME [epoch: 7.79 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005724205777165935		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.005724205777165935 | validation: 0.007646367177794178]
	TIME [epoch: 7.79 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006375723107796197		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.006375723107796197 | validation: 0.0065511496828467]
	TIME [epoch: 7.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059902972354748665		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0059902972354748665 | validation: 0.006516306871491816]
	TIME [epoch: 7.77 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005361368937964782		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.005361368937964782 | validation: 0.006904443604965992]
	TIME [epoch: 7.84 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005589313973299134		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.005589313973299134 | validation: 0.005682546498577077]
	TIME [epoch: 7.78 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005907523338723188		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.005907523338723188 | validation: 0.005882952530624406]
	TIME [epoch: 7.79 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005422949582804044		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.005422949582804044 | validation: 0.00673350690888344]
	TIME [epoch: 7.77 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005140899794091916		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.005140899794091916 | validation: 0.006496989742028428]
	TIME [epoch: 7.79 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005713268850265446		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.005713268850265446 | validation: 0.006616727997547524]
	TIME [epoch: 7.86 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005449191587188541		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.005449191587188541 | validation: 0.00764299536077067]
	TIME [epoch: 7.79 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005968561457917674		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.005968561457917674 | validation: 0.006780752981067803]
	TIME [epoch: 7.79 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005288969867829113		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.005288969867829113 | validation: 0.006632053321293796]
	TIME [epoch: 7.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005372764855551776		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.005372764855551776 | validation: 0.007107958314272184]
	TIME [epoch: 7.82 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006050148465350268		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.006050148465350268 | validation: 0.006397575669164285]
	TIME [epoch: 7.83 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005532827258031541		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.005532827258031541 | validation: 0.007701202129998925]
	TIME [epoch: 7.78 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055233354421235165		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0055233354421235165 | validation: 0.007054811231730717]
	TIME [epoch: 7.79 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005445689569815267		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.005445689569815267 | validation: 0.0074842983229126215]
	TIME [epoch: 7.78 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005472408148647762		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.005472408148647762 | validation: 0.007106566581611748]
	TIME [epoch: 7.83 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005427138003780037		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.005427138003780037 | validation: 0.008073877023439398]
	TIME [epoch: 7.79 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005995872818230041		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.005995872818230041 | validation: 0.006011230566072905]
	TIME [epoch: 7.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005656553583190224		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.005656553583190224 | validation: 0.006721923389455001]
	TIME [epoch: 7.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005359845896437143		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.005359845896437143 | validation: 0.0066518755488189935]
	TIME [epoch: 7.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005153100232797958		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.005153100232797958 | validation: 0.006110013653315269]
	TIME [epoch: 7.84 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005712862561702073		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.005712862561702073 | validation: 0.0066683502130517255]
	TIME [epoch: 7.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005509414434692901		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.005509414434692901 | validation: 0.006821123947767483]
	TIME [epoch: 7.82 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00582239017836015		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.00582239017836015 | validation: 0.006358317096706761]
	TIME [epoch: 7.79 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007652660033067764		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.007652660033067764 | validation: 0.007491079051747628]
	TIME [epoch: 7.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006251680626595896		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.006251680626595896 | validation: 0.006164575657122529]
	TIME [epoch: 7.84 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005507560394794792		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.005507560394794792 | validation: 0.006757040317478117]
	TIME [epoch: 7.81 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005202623119688365		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.005202623119688365 | validation: 0.007522714390431784]
	TIME [epoch: 7.81 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005533805619226017		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.005533805619226017 | validation: 0.006204824565559869]
	TIME [epoch: 7.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057603338470333144		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0057603338470333144 | validation: 0.007329351748581511]
	TIME [epoch: 7.84 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005719914845877633		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.005719914845877633 | validation: 0.006841811185404405]
	TIME [epoch: 7.84 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005964481056006658		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.005964481056006658 | validation: 0.00687165771964115]
	TIME [epoch: 7.79 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005851082495345238		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.005851082495345238 | validation: 0.0068410328112728505]
	TIME [epoch: 7.78 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058998669887211546		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0058998669887211546 | validation: 0.006944828643228129]
	TIME [epoch: 7.79 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005263702213348018		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.005263702213348018 | validation: 0.007520696591546093]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240627_193208/states/model_phi1_1a_v_mmd1_1119.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 8957.305 seconds.
