Args:
Namespace(name='model_facs_dec2a_2dpca_v2', outdir='out/model_training/model_facs_dec2a_2dpca_v2', training_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1701738539

Training model...

Saving initial model state to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32382691947342923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32382691947342923 | validation: 0.44630703571965763]
	TIME [epoch: 112 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27032859369007234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27032859369007234 | validation: 0.3919317185881769]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527257728658824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2527257728658824 | validation: 0.35542913919372976]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25840058331913834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25840058331913834 | validation: 0.3687615388390224]
	TIME [epoch: 84.4 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2255926471594208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2255926471594208 | validation: 0.3245884627821093]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21603556131079876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21603556131079876 | validation: 0.32093452741803785]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21051458465404985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21051458465404985 | validation: 0.3118225064491026]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20216950774036127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20216950774036127 | validation: 0.2971114534023493]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19179921320719945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19179921320719945 | validation: 0.29375772965797575]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20142015626894386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20142015626894386 | validation: 0.31055034504773676]
	TIME [epoch: 84.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18356149662777915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18356149662777915 | validation: 0.26021604848870183]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16943429982160713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16943429982160713 | validation: 0.2938226931443654]
	TIME [epoch: 84.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737006455415742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1737006455415742 | validation: 0.25395302599599007]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1404929061996055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1404929061996055 | validation: 0.3167608312575212]
	TIME [epoch: 84.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15499415249554574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15499415249554574 | validation: 0.24767037376107576]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15140997829464026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15140997829464026 | validation: 0.2808058257127809]
	TIME [epoch: 84.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14400996407878783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14400996407878783 | validation: 0.2344360335048737]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14153149221047492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14153149221047492 | validation: 0.20480637075348504]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13881290053083548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13881290053083548 | validation: 0.24412097797880933]
	TIME [epoch: 84.4 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1346207927469172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1346207927469172 | validation: 0.21384092949468766]
	TIME [epoch: 84.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13545282232769507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13545282232769507 | validation: 0.2220631157566865]
	TIME [epoch: 84.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379435258900559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1379435258900559 | validation: 0.22860610274554785]
	TIME [epoch: 84.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12592258828245423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12592258828245423 | validation: 0.25334732793251735]
	TIME [epoch: 84.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13620616762689458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13620616762689458 | validation: 0.19612657587430232]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1286800340707685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1286800340707685 | validation: 0.3107452514544063]
	TIME [epoch: 84.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12864331129777107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12864331129777107 | validation: 0.2156937067849338]
	TIME [epoch: 84.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1174635369877592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1174635369877592 | validation: 0.20218191942424793]
	TIME [epoch: 84.4 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12381304428124644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12381304428124644 | validation: 0.18878679410242113]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1293929301371118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1293929301371118 | validation: 0.2162281507882075]
	TIME [epoch: 84.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11989234945921098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11989234945921098 | validation: 0.21147967100299778]
	TIME [epoch: 84.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13415026027063953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13415026027063953 | validation: 0.2014042460386776]
	TIME [epoch: 84.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11310223495751182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11310223495751182 | validation: 0.2087525456237966]
	TIME [epoch: 84.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12782003901676725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12782003901676725 | validation: 0.1997775800788281]
	TIME [epoch: 84.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11963401967307855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11963401967307855 | validation: 0.19368898708997975]
	TIME [epoch: 84.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1089356670161333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1089356670161333 | validation: 0.20426278458347064]
	TIME [epoch: 84.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12216116724023615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12216116724023615 | validation: 0.19050316634410827]
	TIME [epoch: 84.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11691942500447058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11691942500447058 | validation: 0.21902989909281007]
	TIME [epoch: 84.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12852628922724607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12852628922724607 | validation: 0.19409259454993544]
	TIME [epoch: 84.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12272405226292545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12272405226292545 | validation: 0.18638134938611906]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10968484661417692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10968484661417692 | validation: 0.22236560574580666]
	TIME [epoch: 84.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11195048979618157		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.11195048979618157 | validation: 0.19985991443089288]
	TIME [epoch: 84.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10942048805932789		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.10942048805932789 | validation: 0.17671287063964675]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10905247919950523		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.10905247919950523 | validation: 0.18389924419256282]
	TIME [epoch: 84.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11961103773170259		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.11961103773170259 | validation: 0.20911159503271243]
	TIME [epoch: 84.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12254225895021983		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.12254225895021983 | validation: 0.1890051103425862]
	TIME [epoch: 84.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1106145913980064		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.1106145913980064 | validation: 0.19506788417878293]
	TIME [epoch: 84.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10796065530256105		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.10796065530256105 | validation: 0.18930179658543178]
	TIME [epoch: 84.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11535348562881316		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.11535348562881316 | validation: 0.27448512189934193]
	TIME [epoch: 84.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11253038990910672		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.11253038990910672 | validation: 0.20364311961374457]
	TIME [epoch: 84.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11225171758070325		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.11225171758070325 | validation: 0.19129692484127478]
	TIME [epoch: 84.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11953506385938013		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.11953506385938013 | validation: 0.20511783115005608]
	TIME [epoch: 84.4 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11671213610313605		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.11671213610313605 | validation: 0.185466355153481]
	TIME [epoch: 84.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10589200767752356		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.10589200767752356 | validation: 0.2359445585415165]
	TIME [epoch: 84.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11686712436942004		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.11686712436942004 | validation: 0.18381109849102029]
	TIME [epoch: 84.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10501007461374874		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.10501007461374874 | validation: 0.20926740814441164]
	TIME [epoch: 84.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10545929799894127		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.10545929799894127 | validation: 0.1929728682815922]
	TIME [epoch: 84.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1190653954713115		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.1190653954713115 | validation: 0.19540281686883673]
	TIME [epoch: 84.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946856156092595		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.10946856156092595 | validation: 0.18365212650162124]
	TIME [epoch: 84.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10189276551896391		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.10189276551896391 | validation: 0.22207499356211288]
	TIME [epoch: 84.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11591998473647738		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.11591998473647738 | validation: 0.18363431769801739]
	TIME [epoch: 84.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1152053359527282		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.1152053359527282 | validation: 0.1979298437321805]
	TIME [epoch: 84.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10952002411331649		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.10952002411331649 | validation: 0.19516315025419112]
	TIME [epoch: 84.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10730900906546922		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.10730900906546922 | validation: 0.20176168763162783]
	TIME [epoch: 84.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1087754278351376		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1087754278351376 | validation: 0.18813073391451657]
	TIME [epoch: 84.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11009137888073879		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.11009137888073879 | validation: 0.1732701675751895]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10365227605472598		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.10365227605472598 | validation: 0.1728091244434617]
	TIME [epoch: 84.6 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10672877749014564		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.10672877749014564 | validation: 0.20711307785972694]
	TIME [epoch: 84.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10331436575710404		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.10331436575710404 | validation: 0.23281340306467063]
	TIME [epoch: 84.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11218952945308691		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.11218952945308691 | validation: 0.19269088374835003]
	TIME [epoch: 84.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10355569162369342		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.10355569162369342 | validation: 0.17560136145187125]
	TIME [epoch: 84.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10343932471070368		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.10343932471070368 | validation: 0.2066754682195342]
	TIME [epoch: 84.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10462240287364191		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.10462240287364191 | validation: 0.1774308527306662]
	TIME [epoch: 84.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10707599134266992		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.10707599134266992 | validation: 0.17769335936646344]
	TIME [epoch: 84.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11296968706342606		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.11296968706342606 | validation: 0.19759036089506699]
	TIME [epoch: 84.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10731195780167757		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.10731195780167757 | validation: 0.17360459619919288]
	TIME [epoch: 84.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10347003713799904		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.10347003713799904 | validation: 0.1727895780525595]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10458796139053135		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.10458796139053135 | validation: 0.19318594534722044]
	TIME [epoch: 84.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10092179231507252		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.10092179231507252 | validation: 0.19493486338879998]
	TIME [epoch: 84.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10635792556941819		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.10635792556941819 | validation: 0.2054597916835726]
	TIME [epoch: 84.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10473209895204008		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.10473209895204008 | validation: 0.1991543698550503]
	TIME [epoch: 84.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483591107330034		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.10483591107330034 | validation: 0.18131593142447655]
	TIME [epoch: 84.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10266917802041567		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.10266917802041567 | validation: 0.18865634635843453]
	TIME [epoch: 84.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1096934022685803		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.1096934022685803 | validation: 0.1944290569731309]
	TIME [epoch: 84.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10781164327753774		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.10781164327753774 | validation: 0.16431536290324034]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09985525584578217		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.09985525584578217 | validation: 0.18444729422103825]
	TIME [epoch: 84.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446687466459952		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.10446687466459952 | validation: 0.16713551852600736]
	TIME [epoch: 84.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.098460051875449		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.098460051875449 | validation: 0.15992481853648943]
	TIME [epoch: 84.2 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10237560243108997		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.10237560243108997 | validation: 0.17030729728897093]
	TIME [epoch: 84.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09710202417036083		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.09710202417036083 | validation: 0.18300743194721827]
	TIME [epoch: 84.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09971764929661445		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.09971764929661445 | validation: 0.20321214419219297]
	TIME [epoch: 84.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10730950722910162		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.10730950722910162 | validation: 0.16747911432924395]
	TIME [epoch: 84.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10719278065048557		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.10719278065048557 | validation: 0.1636429433213002]
	TIME [epoch: 84.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09977299521242379		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.09977299521242379 | validation: 0.16414722054023095]
	TIME [epoch: 84.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09738206400831606		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.09738206400831606 | validation: 0.1663213673874594]
	TIME [epoch: 84.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10049126418172065		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.10049126418172065 | validation: 0.16788475541863213]
	TIME [epoch: 84.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1045023693918826		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.1045023693918826 | validation: 0.1722246536193048]
	TIME [epoch: 84.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09916377442915744		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.09916377442915744 | validation: 0.20334917452975343]
	TIME [epoch: 84.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990531599834715		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.0990531599834715 | validation: 0.16220125658518844]
	TIME [epoch: 84.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10126572611978302		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.10126572611978302 | validation: 0.1644901874408135]
	TIME [epoch: 84.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09749479628569444		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.09749479628569444 | validation: 0.18065054798584013]
	TIME [epoch: 84.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10435565933912035		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.10435565933912035 | validation: 0.17108373974868918]
	TIME [epoch: 84.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09832886141324149		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.09832886141324149 | validation: 0.16710261962459924]
	TIME [epoch: 84.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10012874593542906		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.10012874593542906 | validation: 0.16274016153355378]
	TIME [epoch: 84.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902913906130648		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.09902913906130648 | validation: 0.1640901367307511]
	TIME [epoch: 84.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10339103938319838		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.10339103938319838 | validation: 0.16096988816778973]
	TIME [epoch: 84.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09782635828582423		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.09782635828582423 | validation: 0.1753939424224896]
	TIME [epoch: 84.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10274671316170988		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.10274671316170988 | validation: 0.17485175846682666]
	TIME [epoch: 84.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10067939553014538		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.10067939553014538 | validation: 0.17106648334985075]
	TIME [epoch: 84.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09952959132362818		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.09952959132362818 | validation: 0.17495047534895738]
	TIME [epoch: 84.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099802418285987		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.099802418285987 | validation: 0.20463386302966452]
	TIME [epoch: 84.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0992989519907294		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.0992989519907294 | validation: 0.1788796769822456]
	TIME [epoch: 84.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10117229487019112		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.10117229487019112 | validation: 0.15757097832359918]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09767903899798852		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.09767903899798852 | validation: 0.16103806115882244]
	TIME [epoch: 84.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09792462342542979		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.09792462342542979 | validation: 0.16701780051144807]
	TIME [epoch: 84.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09815783087820765		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.09815783087820765 | validation: 0.16146679192404978]
	TIME [epoch: 84.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09682111664300416		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.09682111664300416 | validation: 0.16919440386659063]
	TIME [epoch: 84.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831047516824185		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.09831047516824185 | validation: 0.1743188060758993]
	TIME [epoch: 84.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09762599596572279		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.09762599596572279 | validation: 0.15763763619345245]
	TIME [epoch: 84.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09840004371057973		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.09840004371057973 | validation: 0.1683440118350482]
	TIME [epoch: 84.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09739931647235778		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.09739931647235778 | validation: 0.17985756356189783]
	TIME [epoch: 84.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10097317810401356		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.10097317810401356 | validation: 0.16527930358120835]
	TIME [epoch: 84.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09583044289875836		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.09583044289875836 | validation: 0.17980223572705806]
	TIME [epoch: 84.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424944044271419		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.09424944044271419 | validation: 0.17390599398670975]
	TIME [epoch: 84.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09977566687490348		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.09977566687490348 | validation: 0.16199311564326777]
	TIME [epoch: 84.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09588924875672515		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.09588924875672515 | validation: 0.17928581602270907]
	TIME [epoch: 84.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09972286485023261		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.09972286485023261 | validation: 0.15316341616108087]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0959129981002288		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.0959129981002288 | validation: 0.18481182033442453]
	TIME [epoch: 84.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10154155342116719		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.10154155342116719 | validation: 0.17861037338945318]
	TIME [epoch: 84.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09622122850313877		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.09622122850313877 | validation: 0.1823996166622562]
	TIME [epoch: 84.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976932356863631		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.0976932356863631 | validation: 0.1629101503108515]
	TIME [epoch: 84.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831842743123038		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.09831842743123038 | validation: 0.1658200133161716]
	TIME [epoch: 84.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09482537916190369		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.09482537916190369 | validation: 0.16071429551416694]
	TIME [epoch: 84.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09863838824568234		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.09863838824568234 | validation: 0.15915072933699936]
	TIME [epoch: 84.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509638355281935		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.09509638355281935 | validation: 0.1581230223889127]
	TIME [epoch: 84.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09632016289727664		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.09632016289727664 | validation: 0.19283466576463235]
	TIME [epoch: 84.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09547545541818335		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.09547545541818335 | validation: 0.17077056621901637]
	TIME [epoch: 84.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09669701800990269		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.09669701800990269 | validation: 0.16796429003523441]
	TIME [epoch: 84.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09833104320524473		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.09833104320524473 | validation: 0.1641604424729814]
	TIME [epoch: 84.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09573379825800424		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.09573379825800424 | validation: 0.15859302523839577]
	TIME [epoch: 84.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760409963086283		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.09760409963086283 | validation: 0.15296981544357235]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09271195667961016		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.09271195667961016 | validation: 0.1612633690870044]
	TIME [epoch: 84.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0951208193563507		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.0951208193563507 | validation: 0.1616636273999924]
	TIME [epoch: 84.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10188915751775522		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.10188915751775522 | validation: 0.15623973164416421]
	TIME [epoch: 84.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475290139508014		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.09475290139508014 | validation: 0.1589493634446498]
	TIME [epoch: 84.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09785751503903473		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.09785751503903473 | validation: 0.15628893465487015]
	TIME [epoch: 84.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09619117433481314		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.09619117433481314 | validation: 0.17432592987935275]
	TIME [epoch: 84.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09561073508985937		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.09561073508985937 | validation: 0.17553809286832242]
	TIME [epoch: 84.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0983682630682619		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.0983682630682619 | validation: 0.15697023077943212]
	TIME [epoch: 84.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09521229864857314		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.09521229864857314 | validation: 0.18582241080100054]
	TIME [epoch: 84.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09549366894871456		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.09549366894871456 | validation: 0.16789801815537125]
	TIME [epoch: 84.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09455922939414997		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.09455922939414997 | validation: 0.15945022561159194]
	TIME [epoch: 84.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09328641890348072		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.09328641890348072 | validation: 0.16452025061193176]
	TIME [epoch: 84.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751367751933598		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.09751367751933598 | validation: 0.15398803507124367]
	TIME [epoch: 84.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545876752302436		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.09545876752302436 | validation: 0.17714882242211305]
	TIME [epoch: 84.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09537836320649391		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.09537836320649391 | validation: 0.1539236472407851]
	TIME [epoch: 84.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09508205378008172		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.09508205378008172 | validation: 0.15533931010264304]
	TIME [epoch: 84.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09903161666165686		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.09903161666165686 | validation: 0.161073160409933]
	TIME [epoch: 84.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09576526336911635		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.09576526336911635 | validation: 0.16292912078467076]
	TIME [epoch: 84.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0967896364764215		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.0967896364764215 | validation: 0.1584051773456161]
	TIME [epoch: 84.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09572801979869536		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.09572801979869536 | validation: 0.1578168602069126]
	TIME [epoch: 84.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09326137863878223		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.09326137863878223 | validation: 0.1593371633351044]
	TIME [epoch: 84.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09399606210891054		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.09399606210891054 | validation: 0.16799555075123584]
	TIME [epoch: 84.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301058544524236		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.09301058544524236 | validation: 0.17485760968308134]
	TIME [epoch: 84.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09794596243504725		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.09794596243504725 | validation: 0.16576336860306606]
	TIME [epoch: 84.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09862561673590359		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.09862561673590359 | validation: 0.1656687981593572]
	TIME [epoch: 84.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09996642767347812		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.09996642767347812 | validation: 0.17712675504980413]
	TIME [epoch: 84.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09553389907194838		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.09553389907194838 | validation: 0.15927634981971944]
	TIME [epoch: 84.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262479254976669		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.09262479254976669 | validation: 0.16245835302787665]
	TIME [epoch: 84.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0948120351323545		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.0948120351323545 | validation: 0.1750362023593075]
	TIME [epoch: 84.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09891365441892301		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.09891365441892301 | validation: 0.1691304814130498]
	TIME [epoch: 84.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09811897909920256		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.09811897909920256 | validation: 0.16908775893068745]
	TIME [epoch: 84.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.094041696854677		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.094041696854677 | validation: 0.15798808509569415]
	TIME [epoch: 84.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09277623791879183		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.09277623791879183 | validation: 0.16452159269651803]
	TIME [epoch: 84.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09686339163083982		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.09686339163083982 | validation: 0.16586630977291109]
	TIME [epoch: 84.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09449099580860383		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.09449099580860383 | validation: 0.16240031920845127]
	TIME [epoch: 84.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09113189334383212		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.09113189334383212 | validation: 0.16389931265318894]
	TIME [epoch: 84.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09362270314806903		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.09362270314806903 | validation: 0.16069167090560746]
	TIME [epoch: 84.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09500742513938296		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.09500742513938296 | validation: 0.16733089196540538]
	TIME [epoch: 84.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09452617993501511		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.09452617993501511 | validation: 0.17936110879938366]
	TIME [epoch: 84.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09767493086465062		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09767493086465062 | validation: 0.16564332958596395]
	TIME [epoch: 84.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09388613853057169		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.09388613853057169 | validation: 0.1679596641165261]
	TIME [epoch: 84.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09541030745147135		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.09541030745147135 | validation: 0.15556853239639296]
	TIME [epoch: 84.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301579394801195		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.09301579394801195 | validation: 0.1569169774364898]
	TIME [epoch: 84.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09574734850365657		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.09574734850365657 | validation: 0.18280962250953567]
	TIME [epoch: 84.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976605680203453		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.0976605680203453 | validation: 0.1729650855841935]
	TIME [epoch: 84.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09380476253511566		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.09380476253511566 | validation: 0.156843685053255]
	TIME [epoch: 84.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09320928002601701		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.09320928002601701 | validation: 0.16723387297928693]
	TIME [epoch: 84.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09195137866356565		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.09195137866356565 | validation: 0.16749148536346548]
	TIME [epoch: 84.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0943126928057123		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.0943126928057123 | validation: 0.15477271302579235]
	TIME [epoch: 84.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09268239306188147		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.09268239306188147 | validation: 0.16088500309852896]
	TIME [epoch: 84.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09078597525805823		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.09078597525805823 | validation: 0.16392185956364447]
	TIME [epoch: 84.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09491850914369172		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.09491850914369172 | validation: 0.1762613995841373]
	TIME [epoch: 84.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09500812213039825		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.09500812213039825 | validation: 0.15995450401864741]
	TIME [epoch: 84.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0946389328271249		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.0946389328271249 | validation: 0.16475294787431177]
	TIME [epoch: 84.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10044102913355188		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.10044102913355188 | validation: 0.16248784909987343]
	TIME [epoch: 84.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09637131053985437		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.09637131053985437 | validation: 0.1639688648189091]
	TIME [epoch: 84.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0944636393442751		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.0944636393442751 | validation: 0.1667645507971497]
	TIME [epoch: 84.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09290354804406371		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09290354804406371 | validation: 0.18725645108097705]
	TIME [epoch: 84.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09504602678831751		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.09504602678831751 | validation: 0.1608657846645754]
	TIME [epoch: 84.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09401388909397242		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.09401388909397242 | validation: 0.16080095735162114]
	TIME [epoch: 84.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09188409480296433		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.09188409480296433 | validation: 0.1796136715076584]
	TIME [epoch: 84.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09158270394069548		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.09158270394069548 | validation: 0.16669936077538317]
	TIME [epoch: 84.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09592414872303123		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.09592414872303123 | validation: 0.1569042276995967]
	TIME [epoch: 84.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09376029955319502		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.09376029955319502 | validation: 0.1852457075771435]
	TIME [epoch: 84.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09315043894363617		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.09315043894363617 | validation: 0.1545706377635679]
	TIME [epoch: 84.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09111846978995418		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.09111846978995418 | validation: 0.1561614330481158]
	TIME [epoch: 84.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09194124771264096		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.09194124771264096 | validation: 0.14965203218366685]
	TIME [epoch: 84.6 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09160771708494013		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.09160771708494013 | validation: 0.1581802486148749]
	TIME [epoch: 84.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09231426079418296		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.09231426079418296 | validation: 0.17845175196826024]
	TIME [epoch: 84.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09279989276620934		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.09279989276620934 | validation: 0.16960553118443086]
	TIME [epoch: 84.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09290689098253771		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.09290689098253771 | validation: 0.1604250470038309]
	TIME [epoch: 84.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09382334415867767		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09382334415867767 | validation: 0.1558521876400024]
	TIME [epoch: 84.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09081970090146477		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.09081970090146477 | validation: 0.16356664867626858]
	TIME [epoch: 84.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09143471765104938		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.09143471765104938 | validation: 0.15396959325106926]
	TIME [epoch: 84.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09354515146438594		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.09354515146438594 | validation: 0.16355278468432477]
	TIME [epoch: 84.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09182555599236165		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.09182555599236165 | validation: 0.15880299851553858]
	TIME [epoch: 84.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255744832140214		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.09255744832140214 | validation: 0.16877554281607757]
	TIME [epoch: 84.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09523221603127735		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.09523221603127735 | validation: 0.1761042278640227]
	TIME [epoch: 84.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09285992546132113		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.09285992546132113 | validation: 0.1633060420941934]
	TIME [epoch: 84.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09513642740382286		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.09513642740382286 | validation: 0.1786997185491127]
	TIME [epoch: 84.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09366045018530166		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.09366045018530166 | validation: 0.16186081553106524]
	TIME [epoch: 84.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09054549009647213		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.09054549009647213 | validation: 0.1585464744186887]
	TIME [epoch: 84.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09364522811404177		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.09364522811404177 | validation: 0.16722330018637868]
	TIME [epoch: 84.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09151359508143017		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.09151359508143017 | validation: 0.1655870012333534]
	TIME [epoch: 84.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264288646174265		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.09264288646174265 | validation: 0.15657256263974403]
	TIME [epoch: 84.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09302054199410943		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09302054199410943 | validation: 0.16752450292593543]
	TIME [epoch: 84.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09474715129417657		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.09474715129417657 | validation: 0.16156691872652756]
	TIME [epoch: 84.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08978959123352356		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.08978959123352356 | validation: 0.1502530613686309]
	TIME [epoch: 84.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09012357387555107		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.09012357387555107 | validation: 0.15621364613268987]
	TIME [epoch: 84.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09232688551265272		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.09232688551265272 | validation: 0.16073579000224825]
	TIME [epoch: 84.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09109887183903087		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.09109887183903087 | validation: 0.15969335221015954]
	TIME [epoch: 84.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09351109760731037		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.09351109760731037 | validation: 0.16314943828958953]
	TIME [epoch: 84.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09152931844021225		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.09152931844021225 | validation: 0.16638153185739252]
	TIME [epoch: 84.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213185729526623		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.09213185729526623 | validation: 0.1734368998723667]
	TIME [epoch: 84.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935167554990486		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.0935167554990486 | validation: 0.20773962895464385]
	TIME [epoch: 84.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09346653686835862		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09346653686835862 | validation: 0.16545217212685273]
	TIME [epoch: 84.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09214768202737585		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.09214768202737585 | validation: 0.15879411515989952]
	TIME [epoch: 84.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09361235616397615		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.09361235616397615 | validation: 0.1599229314166146]
	TIME [epoch: 84.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072926271057073		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.09072926271057073 | validation: 0.15849544407535054]
	TIME [epoch: 84.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08988185654445914		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.08988185654445914 | validation: 0.15531274115705063]
	TIME [epoch: 84.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09348093620939388		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.09348093620939388 | validation: 0.18637847756435968]
	TIME [epoch: 84.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09222957133634493		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09222957133634493 | validation: 0.18702113790944175]
	TIME [epoch: 84.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09309047861218811		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.09309047861218811 | validation: 0.168984548826644]
	TIME [epoch: 84.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924447159907538		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.0924447159907538 | validation: 0.16641846999392482]
	TIME [epoch: 84.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09087557885188546		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.09087557885188546 | validation: 0.1605696835001959]
	TIME [epoch: 84.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105965231621668		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.09105965231621668 | validation: 0.1684652252103929]
	TIME [epoch: 84.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09127267988681911		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.09127267988681911 | validation: 0.15916459616059989]
	TIME [epoch: 84.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09196410709148105		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.09196410709148105 | validation: 0.16059107453427024]
	TIME [epoch: 84.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09376228246883418		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.09376228246883418 | validation: 0.18146597314201168]
	TIME [epoch: 84.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0940144430499923		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.0940144430499923 | validation: 0.16059185392325054]
	TIME [epoch: 84.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09087674894002357		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.09087674894002357 | validation: 0.15600437088452473]
	TIME [epoch: 84.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0914183424690751		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.0914183424690751 | validation: 0.1557459548931597]
	TIME [epoch: 84.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09149264308947636		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.09149264308947636 | validation: 0.1586473096954036]
	TIME [epoch: 84.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09221194933305167		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.09221194933305167 | validation: 0.1545925458067077]
	TIME [epoch: 84.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09025176920977683		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.09025176920977683 | validation: 0.15745887540675568]
	TIME [epoch: 84.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08944441035909234		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08944441035909234 | validation: 0.15932906649438722]
	TIME [epoch: 84.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09016792097480454		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.09016792097480454 | validation: 0.1537967151886437]
	TIME [epoch: 84.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09082083868455267		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.09082083868455267 | validation: 0.15140507156467292]
	TIME [epoch: 84.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09267272048761564		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.09267272048761564 | validation: 0.165435084074688]
	TIME [epoch: 84.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09111750361130834		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.09111750361130834 | validation: 0.15845721151438263]
	TIME [epoch: 84.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09292805700094098		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.09292805700094098 | validation: 0.16740791438641292]
	TIME [epoch: 84.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09450392316843062		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.09450392316843062 | validation: 0.15789486581150677]
	TIME [epoch: 84.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09227948801269792		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.09227948801269792 | validation: 0.15105629092262446]
	TIME [epoch: 84.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09038377823883728		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.09038377823883728 | validation: 0.15501729704310271]
	TIME [epoch: 84.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924498877852514		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.0924498877852514 | validation: 0.16169600041304555]
	TIME [epoch: 84.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09073200272539843		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.09073200272539843 | validation: 0.14958966657897926]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093181254334351		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09093181254334351 | validation: 0.16294143995594085]
	TIME [epoch: 84.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09164139605145294		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.09164139605145294 | validation: 0.1615993186160502]
	TIME [epoch: 84.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09101884734713192		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.09101884734713192 | validation: 0.1669854325657109]
	TIME [epoch: 84.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09121157988778608		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.09121157988778608 | validation: 0.16035754027675003]
	TIME [epoch: 84.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09112786078719542		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.09112786078719542 | validation: 0.15687415286418752]
	TIME [epoch: 84.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09127336488289028		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09127336488289028 | validation: 0.15173952162247473]
	TIME [epoch: 84.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09130885141056855		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.09130885141056855 | validation: 0.15798040016615206]
	TIME [epoch: 84.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135827951336177		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.09135827951336177 | validation: 0.14988116323940376]
	TIME [epoch: 84.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09229560161516993		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.09229560161516993 | validation: 0.14973742065464918]
	TIME [epoch: 84.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09119347958659106		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.09119347958659106 | validation: 0.1643632693916088]
	TIME [epoch: 84.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899388164396825		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.0899388164396825 | validation: 0.15998645664766778]
	TIME [epoch: 84.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09099702454599722		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09099702454599722 | validation: 0.1771248075855782]
	TIME [epoch: 84.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09126257318103574		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.09126257318103574 | validation: 0.15788626692900948]
	TIME [epoch: 84.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926837464324519		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.08926837464324519 | validation: 0.15441200150486056]
	TIME [epoch: 84.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09097246885374294		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.09097246885374294 | validation: 0.15866989405647441]
	TIME [epoch: 84.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213688737219995		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.09213688737219995 | validation: 0.15913421332123248]
	TIME [epoch: 84.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886087698347907		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.08886087698347907 | validation: 0.1590781917058659]
	TIME [epoch: 84.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08994990496398517		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.08994990496398517 | validation: 0.15203928547416826]
	TIME [epoch: 84.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09123542056894733		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.09123542056894733 | validation: 0.1514396169453117]
	TIME [epoch: 84.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010408367553942		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09010408367553942 | validation: 0.1586781686541772]
	TIME [epoch: 84.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09130205585458435		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.09130205585458435 | validation: 0.15404664134164564]
	TIME [epoch: 84.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09045122299199097		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.09045122299199097 | validation: 0.1618676562757633]
	TIME [epoch: 84.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08982993410622012		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.08982993410622012 | validation: 0.16645756181846022]
	TIME [epoch: 84.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899373067328008		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.0899373067328008 | validation: 0.15670288379673972]
	TIME [epoch: 84.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09171023866509247		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.09171023866509247 | validation: 0.15316578078628829]
	TIME [epoch: 84.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08874081145926477		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.08874081145926477 | validation: 0.15581731985352523]
	TIME [epoch: 84.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09005113661420543		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.09005113661420543 | validation: 0.16209860320986572]
	TIME [epoch: 84.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135224298329633		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.09135224298329633 | validation: 0.15168749143350851]
	TIME [epoch: 84.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09041376389445019		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.09041376389445019 | validation: 0.15158014917413604]
	TIME [epoch: 84.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09112443103194863		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.09112443103194863 | validation: 0.15363148228007562]
	TIME [epoch: 84.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920122891710065		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.0920122891710065 | validation: 0.15136424491937683]
	TIME [epoch: 84.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08916064747537869		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.08916064747537869 | validation: 0.15957689861918928]
	TIME [epoch: 84.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08809437506872594		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.08809437506872594 | validation: 0.15348394649707503]
	TIME [epoch: 84.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871391558742076		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08871391558742076 | validation: 0.164020526160028]
	TIME [epoch: 84.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09071525057795407		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.09071525057795407 | validation: 0.1596238207999352]
	TIME [epoch: 84.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08830381326441379		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.08830381326441379 | validation: 0.16177155689871603]
	TIME [epoch: 84.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08985308503843761		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.08985308503843761 | validation: 0.1564214789064433]
	TIME [epoch: 84.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08963992720314115		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.08963992720314115 | validation: 0.15751865133438345]
	TIME [epoch: 84.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09060310601421305		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.09060310601421305 | validation: 0.15348976017980812]
	TIME [epoch: 84.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795590561861266		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.08795590561861266 | validation: 0.15363181009969853]
	TIME [epoch: 84.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08951420786426295		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.08951420786426295 | validation: 0.16060303875993964]
	TIME [epoch: 84.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08832522335273459		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.08832522335273459 | validation: 0.14794307017628083]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09025771980264923		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.09025771980264923 | validation: 0.15180468793795746]
	TIME [epoch: 84.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08869614993151718		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.08869614993151718 | validation: 0.15080358004102398]
	TIME [epoch: 84.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08938039936049105		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.08938039936049105 | validation: 0.1593497013343787]
	TIME [epoch: 84.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08915723608455235		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08915723608455235 | validation: 0.15963627501455002]
	TIME [epoch: 84.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08841098879772036		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.08841098879772036 | validation: 0.15510786526501402]
	TIME [epoch: 84.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08912478293875514		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.08912478293875514 | validation: 0.15616288634747524]
	TIME [epoch: 84.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09009984607449836		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.09009984607449836 | validation: 0.15977954085773]
	TIME [epoch: 84.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08796258691648876		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.08796258691648876 | validation: 0.15360806080435932]
	TIME [epoch: 84.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958506179696649		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08958506179696649 | validation: 0.15377529224394337]
	TIME [epoch: 84.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08870636761321883		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.08870636761321883 | validation: 0.15094446093661967]
	TIME [epoch: 84.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08943391557325056		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.08943391557325056 | validation: 0.15029317020552047]
	TIME [epoch: 84.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08910497084092403		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.08910497084092403 | validation: 0.1643156311778095]
	TIME [epoch: 84.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08755320984971812		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.08755320984971812 | validation: 0.15688965546636277]
	TIME [epoch: 84.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08814941238165144		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.08814941238165144 | validation: 0.15429136565421062]
	TIME [epoch: 84.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09022690534429698		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.09022690534429698 | validation: 0.15678566305025768]
	TIME [epoch: 84.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857165355712637		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08857165355712637 | validation: 0.16055838164322223]
	TIME [epoch: 84.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08906065658041927		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.08906065658041927 | validation: 0.1558627433384031]
	TIME [epoch: 84.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08947589477527378		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.08947589477527378 | validation: 0.15247077852527194]
	TIME [epoch: 84.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08902922713563866		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.08902922713563866 | validation: 0.16180939977706998]
	TIME [epoch: 84.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08911046760986699		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.08911046760986699 | validation: 0.15349321530254353]
	TIME [epoch: 84.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09014556596567573		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.09014556596567573 | validation: 0.15355842886559007]
	TIME [epoch: 84.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857349144745445		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.08857349144745445 | validation: 0.15671427548231642]
	TIME [epoch: 84.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08878847082341745		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08878847082341745 | validation: 0.16307174175354786]
	TIME [epoch: 84.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937269861421215		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08937269861421215 | validation: 0.15052470331620776]
	TIME [epoch: 84.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08920521093683573		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.08920521093683573 | validation: 0.15787289701631313]
	TIME [epoch: 84.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09069249901603853		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.09069249901603853 | validation: 0.15405529613078042]
	TIME [epoch: 84.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878773135843652		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.0878773135843652 | validation: 0.1485477783667089]
	TIME [epoch: 84.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08949953114464011		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08949953114464011 | validation: 0.15842602909141212]
	TIME [epoch: 84.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0896620019000051		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.0896620019000051 | validation: 0.15850359051530555]
	TIME [epoch: 84.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827519828408424		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.08827519828408424 | validation: 0.15385760876708665]
	TIME [epoch: 84.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08823077505241281		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.08823077505241281 | validation: 0.15345573640661844]
	TIME [epoch: 84.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08757743071552553		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.08757743071552553 | validation: 0.16181859371367016]
	TIME [epoch: 84.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08777947075317474		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.08777947075317474 | validation: 0.1586212081803979]
	TIME [epoch: 84.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08971621844792069		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.08971621844792069 | validation: 0.16517803140655352]
	TIME [epoch: 84.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08952514859116027		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.08952514859116027 | validation: 0.15869931369913526]
	TIME [epoch: 84.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08880371912013144		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08880371912013144 | validation: 0.148754145635834]
	TIME [epoch: 84.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08974335839814031		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08974335839814031 | validation: 0.15257155921820714]
	TIME [epoch: 84.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08968601929286035		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.08968601929286035 | validation: 0.15392402335360914]
	TIME [epoch: 84.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08815649134812809		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.08815649134812809 | validation: 0.15441327587587816]
	TIME [epoch: 84.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08765055162867529		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08765055162867529 | validation: 0.1540169812486692]
	TIME [epoch: 84.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08706083691869707		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.08706083691869707 | validation: 0.15509158001454262]
	TIME [epoch: 84.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08867840919086474		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.08867840919086474 | validation: 0.15524025610503883]
	TIME [epoch: 84.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0893604521331346		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.0893604521331346 | validation: 0.17218045055721815]
	TIME [epoch: 84.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008220507128516		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.09008220507128516 | validation: 0.1562419285227529]
	TIME [epoch: 84.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08836568701723294		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.08836568701723294 | validation: 0.15520562549220376]
	TIME [epoch: 84.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08940510815104144		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.08940510815104144 | validation: 0.15658798196964352]
	TIME [epoch: 84.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08874986632016366		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.08874986632016366 | validation: 0.16310381953622455]
	TIME [epoch: 84.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08790020484998488		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08790020484998488 | validation: 0.15485108935077802]
	TIME [epoch: 84.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0881402699562114		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.0881402699562114 | validation: 0.1500159957288305]
	TIME [epoch: 84.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08748864007562034		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.08748864007562034 | validation: 0.1563738470826932]
	TIME [epoch: 84.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08876262354713785		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.08876262354713785 | validation: 0.1521777305186272]
	TIME [epoch: 84.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827871402364267		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.08827871402364267 | validation: 0.151728627601316]
	TIME [epoch: 84.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08917980232710525		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.08917980232710525 | validation: 0.150206317903966]
	TIME [epoch: 84.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08817562578564273		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.08817562578564273 | validation: 0.15547916770781542]
	TIME [epoch: 84.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08808808256469845		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.08808808256469845 | validation: 0.15623267123994217]
	TIME [epoch: 84.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08706119489905675		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08706119489905675 | validation: 0.15620318684710915]
	TIME [epoch: 84.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08676006681356394		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.08676006681356394 | validation: 0.15464440407347796]
	TIME [epoch: 84.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08790403493855614		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08790403493855614 | validation: 0.15879486308805874]
	TIME [epoch: 84.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08688131441875986		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.08688131441875986 | validation: 0.15583130873028433]
	TIME [epoch: 84.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776092447243809		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.08776092447243809 | validation: 0.1567294185870912]
	TIME [epoch: 84.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08782731481013295		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.08782731481013295 | validation: 0.15900089380815402]
	TIME [epoch: 84.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08737625928346429		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08737625928346429 | validation: 0.1581659206760711]
	TIME [epoch: 84.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08858573592124212		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.08858573592124212 | validation: 0.16635185492518606]
	TIME [epoch: 84.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08930917145531707		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08930917145531707 | validation: 0.15702366166429335]
	TIME [epoch: 84.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0893015783029255		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.0893015783029255 | validation: 0.1548292204818592]
	TIME [epoch: 84.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08709438531143807		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.08709438531143807 | validation: 0.1526472397516787]
	TIME [epoch: 84.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08787394593923632		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08787394593923632 | validation: 0.15340034689397264]
	TIME [epoch: 84.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681688231848396		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08681688231848396 | validation: 0.15443366518475876]
	TIME [epoch: 84.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937538136443168		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08937538136443168 | validation: 0.1545802098073054]
	TIME [epoch: 84.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08796084779176369		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.08796084779176369 | validation: 0.15973710573888955]
	TIME [epoch: 84.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0882581956520406		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.0882581956520406 | validation: 0.15365497935048802]
	TIME [epoch: 84.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886866144525829		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08886866144525829 | validation: 0.1541571191591216]
	TIME [epoch: 84.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752338472761693		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.08752338472761693 | validation: 0.15764297403282215]
	TIME [epoch: 84.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08754803860391967		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.08754803860391967 | validation: 0.15044433139041236]
	TIME [epoch: 84.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08810946770092498		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.08810946770092498 | validation: 0.15531401923334107]
	TIME [epoch: 84.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08729135749750541		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.08729135749750541 | validation: 0.14995673183871167]
	TIME [epoch: 84.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.089013486185441		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.089013486185441 | validation: 0.15374212078938312]
	TIME [epoch: 84.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08717851923340635		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.08717851923340635 | validation: 0.1595272750477766]
	TIME [epoch: 84.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08918851636242257		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08918851636242257 | validation: 0.15532130807537262]
	TIME [epoch: 84.4 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885019377297301		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.0885019377297301 | validation: 0.14886564838581284]
	TIME [epoch: 84.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662748683594412		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.08662748683594412 | validation: 0.1533340479568374]
	TIME [epoch: 84.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08718077232687302		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.08718077232687302 | validation: 0.15142934027388347]
	TIME [epoch: 84.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795785342477606		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08795785342477606 | validation: 0.15609287342071645]
	TIME [epoch: 84.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08838252630984544		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08838252630984544 | validation: 0.15658113249068317]
	TIME [epoch: 84.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08893725283342029		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08893725283342029 | validation: 0.1558416563751894]
	TIME [epoch: 84.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08755830179065663		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08755830179065663 | validation: 0.16054581357081552]
	TIME [epoch: 84.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08808746784270755		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08808746784270755 | validation: 0.1480986349231282]
	TIME [epoch: 84.4 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08671303531838923		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.08671303531838923 | validation: 0.1522097674049176]
	TIME [epoch: 84.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08791996064043532		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.08791996064043532 | validation: 0.15172496887728895]
	TIME [epoch: 84.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08675473089357698		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08675473089357698 | validation: 0.1547921655644239]
	TIME [epoch: 84.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08828970217888307		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.08828970217888307 | validation: 0.15084250953564368]
	TIME [epoch: 84.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795480838940309		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08795480838940309 | validation: 0.15723139350050813]
	TIME [epoch: 84.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08738289955646848		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.08738289955646848 | validation: 0.152004178641914]
	TIME [epoch: 84.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08944330290078881		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.08944330290078881 | validation: 0.15572936112165708]
	TIME [epoch: 84.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08753744379211215		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08753744379211215 | validation: 0.1469917645007715]
	TIME [epoch: 84.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v2_20240627_193037/states/model_facs_dec2a_2dpca_v2_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730494432868978		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08730494432868978 | validation: 0.15067445155830536]
	TIME [epoch: 84.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795492268167171		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08795492268167171 | validation: 0.15377886293920562]
	TIME [epoch: 84.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08873544038175077		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08873544038175077 | validation: 0.15813269467021773]
	TIME [epoch: 84.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08701814757270007		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08701814757270007 | validation: 0.15958423340960162]
	TIME [epoch: 84.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08695747599449784		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.08695747599449784 | validation: 0.15289182713788824]
	TIME [epoch: 84.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871208904199905		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.0871208904199905 | validation: 0.15012174386309282]
	TIME [epoch: 84.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08638856123947171		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08638856123947171 | validation: 0.153367575666514]
	TIME [epoch: 84.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08735978888856614		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08735978888856614 | validation: 0.15087114909684146]
	TIME [epoch: 84.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08836450980689357		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.08836450980689357 | validation: 0.1499988870883059]
	TIME [epoch: 84.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08743005107875552		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.08743005107875552 | validation: 0.14946257267871985]
	TIME [epoch: 84.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08685534725372589		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.08685534725372589 | validation: 0.15085747085227594]
	TIME [epoch: 84.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08758773227207592		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08758773227207592 | validation: 0.15696553005798214]
	TIME [epoch: 84.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871334395751212		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.0871334395751212 | validation: 0.153612122536361]
	TIME [epoch: 84.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088480901401316		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.088480901401316 | validation: 0.15379550917850765]
	TIME [epoch: 84.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08786112284850996		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.08786112284850996 | validation: 0.15437684265174173]
	TIME [epoch: 84.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08820938230208494		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.08820938230208494 | validation: 0.15131132209511333]
	TIME [epoch: 84.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08615187992029363		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.08615187992029363 | validation: 0.15301746006720288]
	TIME [epoch: 84.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08616410302293417		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08616410302293417 | validation: 0.16089641188980208]
	TIME [epoch: 84.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08764566043987368		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.08764566043987368 | validation: 0.14979584013082073]
	TIME [epoch: 84.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08593290119470419		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.08593290119470419 | validation: 0.14887253210628623]
	TIME [epoch: 84.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793894239486642		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08793894239486642 | validation: 0.1523043499534672]
	TIME [epoch: 84.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08695425201393472		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.08695425201393472 | validation: 0.1546836576067165]
	TIME [epoch: 84.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623914183482004		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.08623914183482004 | validation: 0.14962022963373012]
	TIME [epoch: 84.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857839806384977		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.0857839806384977 | validation: 0.14931815306843066]
	TIME [epoch: 84.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08651776051035856		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08651776051035856 | validation: 0.15045185314478107]
	TIME [epoch: 84.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08704077743033958		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.08704077743033958 | validation: 0.15546615148671336]
	TIME [epoch: 84.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879329351048577		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.0879329351048577 | validation: 0.1548509625928049]
	TIME [epoch: 84.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08758394702054337		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.08758394702054337 | validation: 0.15586751802459697]
	TIME [epoch: 84.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0867680248416429		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.0867680248416429 | validation: 0.1484368925821186]
	TIME [epoch: 84.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08588287078068604		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.08588287078068604 | validation: 0.15351605093918835]
	TIME [epoch: 84.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793106023130151		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08793106023130151 | validation: 0.15558111954350723]
	TIME [epoch: 84.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08673581688294243		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.08673581688294243 | validation: 0.1492263993477335]
	TIME [epoch: 84.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08756157683049279		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08756157683049279 | validation: 0.15037200282762225]
	TIME [epoch: 84.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.087611417598826		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.087611417598826 | validation: 0.15597564997433971]
	TIME [epoch: 84.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08697416604612679		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.08697416604612679 | validation: 0.15269309857262053]
	TIME [epoch: 84.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08636270148163808		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.08636270148163808 | validation: 0.1530495207820206]
	TIME [epoch: 84.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859528582723201		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.0859528582723201 | validation: 0.1518362812185197]
	TIME [epoch: 84.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08700128459822723		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08700128459822723 | validation: 0.1548264267553518]
	TIME [epoch: 84.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08798961200874132		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.08798961200874132 | validation: 0.15020994770054]
	TIME [epoch: 84.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563635623434886		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08563635623434886 | validation: 0.15061822910315115]
	TIME [epoch: 84.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08794338131996612		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.08794338131996612 | validation: 0.15627358165989763]
	TIME [epoch: 84.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08773874198714245		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.08773874198714245 | validation: 0.14843192503062946]
	TIME [epoch: 84.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08764345357681824		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08764345357681824 | validation: 0.15333878097773343]
	TIME [epoch: 84.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08694448281087405		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.08694448281087405 | validation: 0.15268438021552302]
	TIME [epoch: 84.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08613844968484152		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08613844968484152 | validation: 0.1503417880283685]
	TIME [epoch: 84.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870739118562158		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.0870739118562158 | validation: 0.15917268407108004]
	TIME [epoch: 84.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08693839924580132		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.08693839924580132 | validation: 0.1543286744580466]
	TIME [epoch: 84.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08774686879112185		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.08774686879112185 | validation: 0.15701250230688155]
	TIME [epoch: 84.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08657593645286374		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.08657593645286374 | validation: 0.1525140964274216]
	TIME [epoch: 84.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08758619431658582		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.08758619431658582 | validation: 0.1566058781527262]
	TIME [epoch: 84.4 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681895727480825		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08681895727480825 | validation: 0.156638633449878]
	TIME [epoch: 84.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086439137371971		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.086439137371971 | validation: 0.15038310693596646]
	TIME [epoch: 84.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08648506226634296		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08648506226634296 | validation: 0.15065852329472673]
	TIME [epoch: 84.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08576508999025359		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.08576508999025359 | validation: 0.1539689571440086]
	TIME [epoch: 84.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0880561540711383		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.0880561540711383 | validation: 0.1531984111936394]
	TIME [epoch: 84.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08704950195630654		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08704950195630654 | validation: 0.15501565031139622]
	TIME [epoch: 84.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08624621525916006		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08624621525916006 | validation: 0.1586829221754267]
	TIME [epoch: 84.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733608657030521		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.08733608657030521 | validation: 0.1527768442843635]
	TIME [epoch: 84.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08695295909777292		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.08695295909777292 | validation: 0.149443954300567]
	TIME [epoch: 84.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0872335786445547		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.0872335786445547 | validation: 0.1499912394718873]
	TIME [epoch: 84.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08784056963451621		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08784056963451621 | validation: 0.15446343927162756]
	TIME [epoch: 84.4 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583576962118869		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.08583576962118869 | validation: 0.14882557785879205]
	TIME [epoch: 84.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08562418410206558		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.08562418410206558 | validation: 0.15343655317148652]
	TIME [epoch: 84.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08655976026200754		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.08655976026200754 | validation: 0.15851048986811422]
	TIME [epoch: 84.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08743285283289363		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08743285283289363 | validation: 0.15124724629617806]
	TIME [epoch: 84.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623081122545935		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08623081122545935 | validation: 0.14895383621038372]
	TIME [epoch: 84.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08738346127015162		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08738346127015162 | validation: 0.14875671407262445]
	TIME [epoch: 84.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08560226674174462		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.08560226674174462 | validation: 0.14706377202352522]
	TIME [epoch: 84.4 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08652109885546934		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08652109885546934 | validation: 0.15521288306685949]
	TIME [epoch: 84.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08617227733987129		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.08617227733987129 | validation: 0.15354689178960035]
	TIME [epoch: 84.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08598207287844502		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.08598207287844502 | validation: 0.14975393485820854]
	TIME [epoch: 84.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08713969301998056		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.08713969301998056 | validation: 0.15070829367623295]
	TIME [epoch: 84.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08676056512851768		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08676056512851768 | validation: 0.15237994673819683]
	TIME [epoch: 84.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870045789769131		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.0870045789769131 | validation: 0.15823739806123485]
	TIME [epoch: 84.4 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08669601345291603		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.08669601345291603 | validation: 0.15236805291022135]
	TIME [epoch: 84.4 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559858115939573		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.08559858115939573 | validation: 0.15444728862862023]
	TIME [epoch: 84.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08500373665720601		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.08500373665720601 | validation: 0.15155958261244903]
	TIME [epoch: 84.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08575708752924362		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.08575708752924362 | validation: 0.15317158356578098]
	TIME [epoch: 84.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599611271103998		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08599611271103998 | validation: 0.150821160088693]
	TIME [epoch: 84.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08493042139207574		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.08493042139207574 | validation: 0.15194262106479584]
	TIME [epoch: 84.4 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681452012917852		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08681452012917852 | validation: 0.15175021825206486]
	TIME [epoch: 84.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776387986385079		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.08776387986385079 | validation: 0.149393109538763]
	TIME [epoch: 84.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08678830910431343		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.08678830910431343 | validation: 0.1514196475043096]
	TIME [epoch: 84.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08516905853178786		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.08516905853178786 | validation: 0.15409441703903004]
	TIME [epoch: 84.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858603684597566		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0858603684597566 | validation: 0.15796013126493474]
	TIME [epoch: 84.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08878287070680789		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08878287070680789 | validation: 0.15859491712042725]
	TIME [epoch: 84.4 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08514286805686419		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.08514286805686419 | validation: 0.15350619789727815]
	TIME [epoch: 84.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08618249923962663		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.08618249923962663 | validation: 0.1505606773009216]
	TIME [epoch: 84.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08600564259952262		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08600564259952262 | validation: 0.15279978906809913]
	TIME [epoch: 84.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08675357676842779		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.08675357676842779 | validation: 0.15727417784711833]
	TIME [epoch: 84.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08679743198360912		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.08679743198360912 | validation: 0.1517720741818502]
	TIME [epoch: 84.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086654898106538		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.086654898106538 | validation: 0.1503897367244228]
	TIME [epoch: 84.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08685128310792134		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08685128310792134 | validation: 0.15129527058275744]
	TIME [epoch: 84.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08627371565943107		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.08627371565943107 | validation: 0.1529953418959595]
	TIME [epoch: 84.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08566251015376992		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.08566251015376992 | validation: 0.1534802806713298]
	TIME [epoch: 84.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08701318985487036		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.08701318985487036 | validation: 0.15092638180877352]
	TIME [epoch: 84.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08603183414055363		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08603183414055363 | validation: 0.15237986989640911]
	TIME [epoch: 84.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08601099535268728		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.08601099535268728 | validation: 0.15212415143737532]
	TIME [epoch: 84.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557488937839042		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.08557488937839042 | validation: 0.14787660226812657]
	TIME [epoch: 84.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08558816885674744		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.08558816885674744 | validation: 0.15248807413312343]
	TIME [epoch: 84.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08528832935930601		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08528832935930601 | validation: 0.1524030595472919]
	TIME [epoch: 84.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08682716985121855		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08682716985121855 | validation: 0.1541695898626152]
	TIME [epoch: 84.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08519009125799348		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.08519009125799348 | validation: 0.1489683114982056]
	TIME [epoch: 84.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599611819160274		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.08599611819160274 | validation: 0.15471923271208865]
	TIME [epoch: 84.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08631725562692741		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.08631725562692741 | validation: 0.15015815154145545]
	TIME [epoch: 84.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862751608504709		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.0862751608504709 | validation: 0.14992533570892025]
	TIME [epoch: 84.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08465550340083573		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.08465550340083573 | validation: 0.15006938070285464]
	TIME [epoch: 84.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08525041468404113		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.08525041468404113 | validation: 0.14971226998387904]
	TIME [epoch: 84.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08678162131107381		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.08678162131107381 | validation: 0.15227874603132407]
	TIME [epoch: 84.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08668906353441803		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.08668906353441803 | validation: 0.15471501318594844]
	TIME [epoch: 84.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859065632012972		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.0859065632012972 | validation: 0.15176607826647404]
	TIME [epoch: 84.5 sec]
EPOCH 515/2000:
	Training over batches...
