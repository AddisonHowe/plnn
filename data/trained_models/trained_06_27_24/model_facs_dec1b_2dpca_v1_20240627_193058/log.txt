Args:
Namespace(name='model_facs_dec1b_2dpca_v1', outdir='out/model_training/model_facs_dec1b_2dpca_v1', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3672355079

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8167088543820427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8167088543820427 | validation: 0.7091382344295358]
	TIME [epoch: 86.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7176263783198825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7176263783198825 | validation: 0.672643586338374]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6674885821582723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6674885821582723 | validation: 0.6011317256989032]
	TIME [epoch: 61.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6201679013985942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6201679013985942 | validation: 0.6232973490895912]
	TIME [epoch: 61.8 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6045449541607918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6045449541607918 | validation: 0.5790663097235604]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5892760398544276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5892760398544276 | validation: 0.547863806268152]
	TIME [epoch: 61.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5277897071474338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5277897071474338 | validation: 0.5074952646694966]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4835104892873628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4835104892873628 | validation: 0.46201982422562854]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4438071678195698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4438071678195698 | validation: 0.4227737046072481]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40393786344801175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40393786344801175 | validation: 0.3718142990643898]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31957823339262487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31957823339262487 | validation: 0.27890772985340095]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2879616166101187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2879616166101187 | validation: 0.29603414266140277]
	TIME [epoch: 61.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2682814012881549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2682814012881549 | validation: 0.21359128111451203]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22249439810842433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22249439810842433 | validation: 0.1971062326787232]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2251905900340505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2251905900340505 | validation: 0.19194714885628558]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20145666688314287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20145666688314287 | validation: 0.17119910153540918]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19296109108945894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19296109108945894 | validation: 0.18119780608745248]
	TIME [epoch: 61.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1745380795258228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1745380795258228 | validation: 0.17208070771610703]
	TIME [epoch: 61.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18271492457508068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18271492457508068 | validation: 0.19256825608176953]
	TIME [epoch: 62 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17420242640979966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17420242640979966 | validation: 0.14739437174663805]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1651776276644764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1651776276644764 | validation: 0.1500481542477276]
	TIME [epoch: 61.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16259611690231732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16259611690231732 | validation: 0.14955050969543665]
	TIME [epoch: 61.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1607376304142757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1607376304142757 | validation: 0.13438574851310633]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15677444866576412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15677444866576412 | validation: 0.13449906747847423]
	TIME [epoch: 61.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1591006902869504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1591006902869504 | validation: 0.14760816248703465]
	TIME [epoch: 61.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1495366727564874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1495366727564874 | validation: 0.13631192260815922]
	TIME [epoch: 61.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14353884409644527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14353884409644527 | validation: 0.1296553189217418]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14869009146176534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14869009146176534 | validation: 0.13316059858586096]
	TIME [epoch: 61.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14071224758583342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14071224758583342 | validation: 0.1311726475715022]
	TIME [epoch: 61.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15273990287138506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15273990287138506 | validation: 0.12411091016432882]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13601122490250925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13601122490250925 | validation: 0.13163767127235457]
	TIME [epoch: 61.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15339030337318427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15339030337318427 | validation: 0.13518264824541085]
	TIME [epoch: 61.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14155837864370396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14155837864370396 | validation: 0.11703823693525488]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1377156202635802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1377156202635802 | validation: 0.12674252041762532]
	TIME [epoch: 61.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13954306488746793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13954306488746793 | validation: 0.12357821913721616]
	TIME [epoch: 61.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1330821346482643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1330821346482643 | validation: 0.13491794162461168]
	TIME [epoch: 61.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1321680261716392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1321680261716392 | validation: 0.13245539670470663]
	TIME [epoch: 61.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12979581490514297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12979581490514297 | validation: 0.13722518960436578]
	TIME [epoch: 61.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1414703194182653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1414703194182653 | validation: 0.1184583358746774]
	TIME [epoch: 61.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12981936197751173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12981936197751173 | validation: 0.12342085990842248]
	TIME [epoch: 61.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13402615161721973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13402615161721973 | validation: 0.11533384963197361]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13300060411164155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13300060411164155 | validation: 0.11916796539751373]
	TIME [epoch: 61.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12815988064086356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12815988064086356 | validation: 0.12565780740725113]
	TIME [epoch: 61.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13235466011403954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13235466011403954 | validation: 0.11674724184089266]
	TIME [epoch: 61.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13064734640410952		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.13064734640410952 | validation: 0.11246259552486992]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12660309597180133		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.12660309597180133 | validation: 0.10980136601839256]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13522199441755423		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.13522199441755423 | validation: 0.12147431871823937]
	TIME [epoch: 61.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13263346486030236		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.13263346486030236 | validation: 0.11035121474445402]
	TIME [epoch: 61.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12044017965214035		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.12044017965214035 | validation: 0.12111473484306641]
	TIME [epoch: 61.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13522525209729394		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.13522525209729394 | validation: 0.11156935662370757]
	TIME [epoch: 61.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12971837042809756		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.12971837042809756 | validation: 0.10968075433762683]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12638275919300013		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.12638275919300013 | validation: 0.11679527494335602]
	TIME [epoch: 61.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12306826285687854		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.12306826285687854 | validation: 0.11271038537760916]
	TIME [epoch: 61.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13175859007941468		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.13175859007941468 | validation: 0.11015589507405274]
	TIME [epoch: 61.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13015054678607557		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.13015054678607557 | validation: 0.11860535106739381]
	TIME [epoch: 61.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12929285733081144		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.12929285733081144 | validation: 0.11787511331262106]
	TIME [epoch: 61.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12567857297365273		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.12567857297365273 | validation: 0.11577128727138794]
	TIME [epoch: 61.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12579477849567702		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.12579477849567702 | validation: 0.11423835025406419]
	TIME [epoch: 61.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12939525701581783		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.12939525701581783 | validation: 0.1226409532288149]
	TIME [epoch: 61.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1301526695606311		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.1301526695606311 | validation: 0.10543685750922524]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12379593624887059		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.12379593624887059 | validation: 0.10605641900346026]
	TIME [epoch: 61.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12712647298312632		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.12712647298312632 | validation: 0.10723836823574548]
	TIME [epoch: 61.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12448766070792223		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.12448766070792223 | validation: 0.11946106653600368]
	TIME [epoch: 61.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12643715874046169		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.12643715874046169 | validation: 0.11504453295690889]
	TIME [epoch: 61.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12056826179234965		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.12056826179234965 | validation: 0.10593696905423262]
	TIME [epoch: 61.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12686148917589687		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.12686148917589687 | validation: 0.11111062808352212]
	TIME [epoch: 61.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1302781208231019		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.1302781208231019 | validation: 0.10209679525126998]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12616738754015475		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.12616738754015475 | validation: 0.11596487663625502]
	TIME [epoch: 61.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12178894991266881		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.12178894991266881 | validation: 0.10570347177383463]
	TIME [epoch: 61.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1258267537209195		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.1258267537209195 | validation: 0.10856838109962927]
	TIME [epoch: 61.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12505907958421608		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.12505907958421608 | validation: 0.10708331013013625]
	TIME [epoch: 61.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12211937759809942		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.12211937759809942 | validation: 0.10955904810258796]
	TIME [epoch: 61.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12099944826547694		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.12099944826547694 | validation: 0.11059057922247247]
	TIME [epoch: 61.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1261210449462499		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.1261210449462499 | validation: 0.09989417420755459]
	TIME [epoch: 61.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11948271364467998		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.11948271364467998 | validation: 0.11966204542978727]
	TIME [epoch: 61.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12557500425120904		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.12557500425120904 | validation: 0.106622282625266]
	TIME [epoch: 61.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1210612264899249		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.1210612264899249 | validation: 0.10824306803051023]
	TIME [epoch: 61.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1187117713131762		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.1187117713131762 | validation: 0.10836417343638712]
	TIME [epoch: 61.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12198933709938757		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.12198933709938757 | validation: 0.11394813283672289]
	TIME [epoch: 61.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12692024074706482		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.12692024074706482 | validation: 0.10852078885494762]
	TIME [epoch: 61.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12351273586831188		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.12351273586831188 | validation: 0.10022960712778059]
	TIME [epoch: 61.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11684758697017093		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.11684758697017093 | validation: 0.1097078069014887]
	TIME [epoch: 61.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12712849796189404		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.12712849796189404 | validation: 0.11838548150908587]
	TIME [epoch: 61.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.125830430517204		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.125830430517204 | validation: 0.09942136956495742]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12066753003622882		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.12066753003622882 | validation: 0.09927970088361791]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11864105969353744		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.11864105969353744 | validation: 0.1201184155308211]
	TIME [epoch: 61.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12466742425631838		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.12466742425631838 | validation: 0.10721155925421381]
	TIME [epoch: 61.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12136937155721385		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.12136937155721385 | validation: 0.12837148396268744]
	TIME [epoch: 61.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12334621778976211		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.12334621778976211 | validation: 0.12394994280184826]
	TIME [epoch: 61.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12638496516226497		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.12638496516226497 | validation: 0.10127099133335482]
	TIME [epoch: 61.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11875259971228076		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.11875259971228076 | validation: 0.11241705823388053]
	TIME [epoch: 61.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11885783901571445		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.11885783901571445 | validation: 0.10255195553658733]
	TIME [epoch: 61.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12116548087287485		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12116548087287485 | validation: 0.0996584679827202]
	TIME [epoch: 61.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12456250291446243		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.12456250291446243 | validation: 0.10431143007860126]
	TIME [epoch: 61.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11827245790041813		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.11827245790041813 | validation: 0.11013092935861853]
	TIME [epoch: 61.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12078763872921439		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.12078763872921439 | validation: 0.10245238224151147]
	TIME [epoch: 61.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11916212935585725		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.11916212935585725 | validation: 0.10034035264756165]
	TIME [epoch: 61.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12070129731498191		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.12070129731498191 | validation: 0.11215099506632686]
	TIME [epoch: 61.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12222924991263387		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.12222924991263387 | validation: 0.10119140614876265]
	TIME [epoch: 61.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11839533558871507		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.11839533558871507 | validation: 0.10142633784661197]
	TIME [epoch: 61.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12075234007983836		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.12075234007983836 | validation: 0.10452134043598545]
	TIME [epoch: 61.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11805948192589717		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.11805948192589717 | validation: 0.10256191851694141]
	TIME [epoch: 61.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11636710721022478		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.11636710721022478 | validation: 0.10010227211267719]
	TIME [epoch: 62.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11599812010269352		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.11599812010269352 | validation: 0.10434635170431841]
	TIME [epoch: 61.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11861309874364527		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.11861309874364527 | validation: 0.1007091581362241]
	TIME [epoch: 61.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1212502072824898		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.1212502072824898 | validation: 0.10375213698413747]
	TIME [epoch: 61.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12370787572087008		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.12370787572087008 | validation: 0.09913865907964083]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11726742399124992		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.11726742399124992 | validation: 0.10686558102042229]
	TIME [epoch: 61.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1226761005182228		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.1226761005182228 | validation: 0.09825755703925462]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11838316581557537		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.11838316581557537 | validation: 0.10351190579345979]
	TIME [epoch: 61.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12095655569808302		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.12095655569808302 | validation: 0.1088559830274575]
	TIME [epoch: 61.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12149774008319342		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.12149774008319342 | validation: 0.09640380038736569]
	TIME [epoch: 61.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11611598789308501		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.11611598789308501 | validation: 0.10259690628175622]
	TIME [epoch: 61.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11705979153467701		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.11705979153467701 | validation: 0.0971770912755945]
	TIME [epoch: 61.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11844158027516677		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.11844158027516677 | validation: 0.09625354429478838]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1169790350037154		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.1169790350037154 | validation: 0.09649072226065329]
	TIME [epoch: 61.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11691428436553715		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.11691428436553715 | validation: 0.10485635776852578]
	TIME [epoch: 61.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11519113140065736		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.11519113140065736 | validation: 0.11215933257396167]
	TIME [epoch: 61.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11966672434569246		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.11966672434569246 | validation: 0.09950328725101029]
	TIME [epoch: 61.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11681616966703331		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.11681616966703331 | validation: 0.11072245488938641]
	TIME [epoch: 61.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11611474913170333		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.11611474913170333 | validation: 0.09855864509622284]
	TIME [epoch: 61.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11772913751477497		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.11772913751477497 | validation: 0.09648883046895292]
	TIME [epoch: 61.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11430998606757783		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.11430998606757783 | validation: 0.10597378820194454]
	TIME [epoch: 61.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12424163793251547		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.12424163793251547 | validation: 0.10930920184042803]
	TIME [epoch: 61.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12325719067698697		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.12325719067698697 | validation: 0.09627844756872253]
	TIME [epoch: 61.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1162404509217734		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.1162404509217734 | validation: 0.0986647476671674]
	TIME [epoch: 61.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11741184456006286		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.11741184456006286 | validation: 0.09819410125315867]
	TIME [epoch: 61.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11550471273314976		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.11550471273314976 | validation: 0.1079502393195263]
	TIME [epoch: 61.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1173624865014208		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.1173624865014208 | validation: 0.09677306063210656]
	TIME [epoch: 61.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11899413879833214		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.11899413879833214 | validation: 0.100984364646539]
	TIME [epoch: 61.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12257481655877517		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.12257481655877517 | validation: 0.10528174292836585]
	TIME [epoch: 61.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11827664753842855		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.11827664753842855 | validation: 0.10021410603714176]
	TIME [epoch: 61.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11494141903782906		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.11494141903782906 | validation: 0.10475564352186736]
	TIME [epoch: 61.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1134689893067659		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.1134689893067659 | validation: 0.10360808010697742]
	TIME [epoch: 61.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12123124781395715		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.12123124781395715 | validation: 0.09754106240652897]
	TIME [epoch: 61.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11798354033789232		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.11798354033789232 | validation: 0.10038990250000379]
	TIME [epoch: 61.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11821757307133078		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.11821757307133078 | validation: 0.09661487002919376]
	TIME [epoch: 61.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280488063328956		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.11280488063328956 | validation: 0.09626090926988537]
	TIME [epoch: 61.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11658011912033674		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.11658011912033674 | validation: 0.0968869711930724]
	TIME [epoch: 61.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11575607995190852		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.11575607995190852 | validation: 0.09625471361004279]
	TIME [epoch: 61.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11497033475864843		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11497033475864843 | validation: 0.10381107023148499]
	TIME [epoch: 61.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11738957484120734		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.11738957484120734 | validation: 0.10037229211252219]
	TIME [epoch: 61.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11305001927872234		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.11305001927872234 | validation: 0.09582297589083116]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11541681543204534		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.11541681543204534 | validation: 0.1050169988776466]
	TIME [epoch: 61.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12039095649250944		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.12039095649250944 | validation: 0.10377430128304029]
	TIME [epoch: 61.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11332148149954722		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.11332148149954722 | validation: 0.10226827564634569]
	TIME [epoch: 61.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11760602479662463		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.11760602479662463 | validation: 0.09992716872014942]
	TIME [epoch: 61.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11479712226521196		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.11479712226521196 | validation: 0.09590621715862818]
	TIME [epoch: 61.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11733002292857031		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.11733002292857031 | validation: 0.10331197990311629]
	TIME [epoch: 61.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.117128816563162		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.117128816563162 | validation: 0.10128196374924578]
	TIME [epoch: 61.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11590325661332918		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11590325661332918 | validation: 0.0988587177409935]
	TIME [epoch: 61.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147449680814927		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.1147449680814927 | validation: 0.09744760761835039]
	TIME [epoch: 61.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11610400921167084		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.11610400921167084 | validation: 0.09807825448230083]
	TIME [epoch: 61.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11777482251877282		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.11777482251877282 | validation: 0.09659580342273205]
	TIME [epoch: 61.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11566388224484253		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.11566388224484253 | validation: 0.10673681893271661]
	TIME [epoch: 61.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11649478516043997		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.11649478516043997 | validation: 0.09382338221726479]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11403372537258195		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.11403372537258195 | validation: 0.09548265616700316]
	TIME [epoch: 61.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11913105789527245		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.11913105789527245 | validation: 0.0985577422702391]
	TIME [epoch: 61.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11217710102729389		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.11217710102729389 | validation: 0.09990424650818822]
	TIME [epoch: 61.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1170202610126296		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.1170202610126296 | validation: 0.09304173210219713]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11249610958722658		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11249610958722658 | validation: 0.10198103541668221]
	TIME [epoch: 61.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11979696756485136		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.11979696756485136 | validation: 0.11563049457942016]
	TIME [epoch: 61.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11919768013679517		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.11919768013679517 | validation: 0.10049922205704345]
	TIME [epoch: 61.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11616451049766913		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.11616451049766913 | validation: 0.09783281929131503]
	TIME [epoch: 61.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11765231073747542		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.11765231073747542 | validation: 0.0978229344388549]
	TIME [epoch: 61.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11251705373045723		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.11251705373045723 | validation: 0.09685920126398567]
	TIME [epoch: 61.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11279638410010238		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.11279638410010238 | validation: 0.10827231725164707]
	TIME [epoch: 61.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11484961238482372		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.11484961238482372 | validation: 0.09838205528962077]
	TIME [epoch: 61.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209542617305186		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.11209542617305186 | validation: 0.09893843218433826]
	TIME [epoch: 61.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11725660429761481		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.11725660429761481 | validation: 0.09512431717339537]
	TIME [epoch: 61.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11247357960553413		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11247357960553413 | validation: 0.09567836708124366]
	TIME [epoch: 61.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11733363348972693		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.11733363348972693 | validation: 0.09679103159156956]
	TIME [epoch: 61.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11530878136329147		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.11530878136329147 | validation: 0.0982177400224771]
	TIME [epoch: 61.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11700690304383321		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.11700690304383321 | validation: 0.0986573024625021]
	TIME [epoch: 61.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11660935199342862		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.11660935199342862 | validation: 0.10098834728407227]
	TIME [epoch: 61.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11514383376840698		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.11514383376840698 | validation: 0.0977064549883293]
	TIME [epoch: 61.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11245279207255882		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.11245279207255882 | validation: 0.09782870661856721]
	TIME [epoch: 61.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11570489147827419		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.11570489147827419 | validation: 0.09707213382499401]
	TIME [epoch: 61.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11445894047222341		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.11445894047222341 | validation: 0.10817901964550429]
	TIME [epoch: 61.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12113599221071739		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.12113599221071739 | validation: 0.09503405486483274]
	TIME [epoch: 61.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11402886092631498		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.11402886092631498 | validation: 0.09730960681089726]
	TIME [epoch: 61.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11479576569096407		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.11479576569096407 | validation: 0.09400261886739447]
	TIME [epoch: 61.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1183887673350797		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1183887673350797 | validation: 0.1018197794277643]
	TIME [epoch: 61.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11725649445453154		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.11725649445453154 | validation: 0.09701051528755138]
	TIME [epoch: 61.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11639846752541		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.11639846752541 | validation: 0.0989142729140288]
	TIME [epoch: 61.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11589258892480678		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.11589258892480678 | validation: 0.103705181620008]
	TIME [epoch: 61.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11769627696982424		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.11769627696982424 | validation: 0.09782673165796876]
	TIME [epoch: 61.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11170605400258905		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.11170605400258905 | validation: 0.10377368694601312]
	TIME [epoch: 61.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11474416922502557		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.11474416922502557 | validation: 0.10407711596422135]
	TIME [epoch: 61.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11320375770117568		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.11320375770117568 | validation: 0.10351607462276233]
	TIME [epoch: 61.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11493399316262407		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11493399316262407 | validation: 0.09795967192603183]
	TIME [epoch: 61.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11672768957895853		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.11672768957895853 | validation: 0.10490155947597408]
	TIME [epoch: 61.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11549587941612655		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.11549587941612655 | validation: 0.0974024958614987]
	TIME [epoch: 61.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11223330925006549		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.11223330925006549 | validation: 0.09984375348938485]
	TIME [epoch: 61.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11532664895629817		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.11532664895629817 | validation: 0.10055129487427968]
	TIME [epoch: 61.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11449817978922122		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.11449817978922122 | validation: 0.09746186106514405]
	TIME [epoch: 61.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11312999954143775		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.11312999954143775 | validation: 0.0974481896839359]
	TIME [epoch: 61.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11071408664357418		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.11071408664357418 | validation: 0.099599813357592]
	TIME [epoch: 61.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11348277321728298		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.11348277321728298 | validation: 0.09536315133538492]
	TIME [epoch: 61.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11333093350238498		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.11333093350238498 | validation: 0.09991842392697943]
	TIME [epoch: 61.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11240248207705557		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11240248207705557 | validation: 0.10845805741226508]
	TIME [epoch: 61.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11305114979266984		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.11305114979266984 | validation: 0.1026048398876637]
	TIME [epoch: 61.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11667696997622418		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.11667696997622418 | validation: 0.10371042570223236]
	TIME [epoch: 61.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11360034280361891		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.11360034280361891 | validation: 0.09774039414625377]
	TIME [epoch: 61.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11358916948363265		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.11358916948363265 | validation: 0.09854425884650911]
	TIME [epoch: 61.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11300201268485616		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.11300201268485616 | validation: 0.10744395437234402]
	TIME [epoch: 61.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11576744537971334		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.11576744537971334 | validation: 0.0954890676422831]
	TIME [epoch: 61.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314997811035049		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.11314997811035049 | validation: 0.10527390281778701]
	TIME [epoch: 61.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1184698256466968		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.1184698256466968 | validation: 0.09908610485727526]
	TIME [epoch: 61.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988939847223533		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.10988939847223533 | validation: 0.09675383169262797]
	TIME [epoch: 61.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11454371786404531		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.11454371786404531 | validation: 0.09523440823625111]
	TIME [epoch: 61.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11323580606928704		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.11323580606928704 | validation: 0.10552152548790301]
	TIME [epoch: 61.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11672793781694374		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.11672793781694374 | validation: 0.09813220582753598]
	TIME [epoch: 61.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1111196947526963		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.1111196947526963 | validation: 0.096919566055984]
	TIME [epoch: 61.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11642215707592198		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11642215707592198 | validation: 0.09554425185050677]
	TIME [epoch: 61.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11499527967586227		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.11499527967586227 | validation: 0.09846737094118689]
	TIME [epoch: 61.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11322358432172147		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.11322358432172147 | validation: 0.09849367366189682]
	TIME [epoch: 61.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11417376600226017		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.11417376600226017 | validation: 0.10220616379503786]
	TIME [epoch: 61.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11450546484092142		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.11450546484092142 | validation: 0.10392497977008135]
	TIME [epoch: 61.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11553338191698037		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.11553338191698037 | validation: 0.09834574305114184]
	TIME [epoch: 61.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11208677406584625		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.11208677406584625 | validation: 0.09852807168926955]
	TIME [epoch: 61.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11493147804786677		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.11493147804786677 | validation: 0.0977112689187155]
	TIME [epoch: 61.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11599323955323625		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.11599323955323625 | validation: 0.10329513432568253]
	TIME [epoch: 61.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11758972801766204		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.11758972801766204 | validation: 0.10196865821640162]
	TIME [epoch: 61.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11215834413146555		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.11215834413146555 | validation: 0.09718668206089136]
	TIME [epoch: 61.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092484744040082		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.11092484744040082 | validation: 0.1008562922775786]
	TIME [epoch: 61.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11382263897652817		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.11382263897652817 | validation: 0.09701880610111882]
	TIME [epoch: 61.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306333944882956		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.11306333944882956 | validation: 0.09542051941462253]
	TIME [epoch: 61.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11685225630100492		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.11685225630100492 | validation: 0.095206791396351]
	TIME [epoch: 61.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11254716235603575		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.11254716235603575 | validation: 0.0961522012023866]
	TIME [epoch: 61.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11671478815673532		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.11671478815673532 | validation: 0.09618467034457553]
	TIME [epoch: 61.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11264503136216092		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.11264503136216092 | validation: 0.09984199094167742]
	TIME [epoch: 61.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11296061738030054		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.11296061738030054 | validation: 0.0970375237939251]
	TIME [epoch: 61.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11394083991511399		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.11394083991511399 | validation: 0.09587300403480548]
	TIME [epoch: 61.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280834819000149		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.11280834819000149 | validation: 0.09782072808194293]
	TIME [epoch: 61.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11584657874205523		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.11584657874205523 | validation: 0.09897567880939691]
	TIME [epoch: 61.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11388804487844507		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.11388804487844507 | validation: 0.0973224298165514]
	TIME [epoch: 61.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11321216969515573		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.11321216969515573 | validation: 0.09715940693971035]
	TIME [epoch: 61.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11482908861974288		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.11482908861974288 | validation: 0.09564682144823763]
	TIME [epoch: 61.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11674093576763579		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.11674093576763579 | validation: 0.09963633483700973]
	TIME [epoch: 61.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11451650019859187		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.11451650019859187 | validation: 0.09796779469024897]
	TIME [epoch: 61.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11281622440892446		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.11281622440892446 | validation: 0.09822904893433185]
	TIME [epoch: 61.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11161824168555737		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.11161824168555737 | validation: 0.09208366586953465]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11187405492779684		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.11187405492779684 | validation: 0.10760693734170639]
	TIME [epoch: 61.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11845547037619092		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.11845547037619092 | validation: 0.09373738709051356]
	TIME [epoch: 61.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11316968885725563		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.11316968885725563 | validation: 0.09539217344742483]
	TIME [epoch: 61.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11025202890669811		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.11025202890669811 | validation: 0.09584759114266594]
	TIME [epoch: 61.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11547491282487105		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.11547491282487105 | validation: 0.09846775912293015]
	TIME [epoch: 61.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11107139858456608		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.11107139858456608 | validation: 0.09659497709734306]
	TIME [epoch: 61.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11475723763693393		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.11475723763693393 | validation: 0.0974687516126181]
	TIME [epoch: 61.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11452347830363349		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11452347830363349 | validation: 0.1004722864181952]
	TIME [epoch: 61.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1115554385080359		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.1115554385080359 | validation: 0.09535350207955444]
	TIME [epoch: 61.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11418304999251222		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.11418304999251222 | validation: 0.09764512041973865]
	TIME [epoch: 61.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11309188584375122		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.11309188584375122 | validation: 0.09626343630038647]
	TIME [epoch: 61.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10936885014650831		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.10936885014650831 | validation: 0.09588341751009741]
	TIME [epoch: 61.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11154452086156796		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.11154452086156796 | validation: 0.0964115991528371]
	TIME [epoch: 61.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11683464171016711		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.11683464171016711 | validation: 0.09967137930939013]
	TIME [epoch: 61.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.109390513747991		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.109390513747991 | validation: 0.09318512691350715]
	TIME [epoch: 61.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118115380203839		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.1118115380203839 | validation: 0.09517688117215946]
	TIME [epoch: 61.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11554720313007488		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.11554720313007488 | validation: 0.10235919468143255]
	TIME [epoch: 61.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11489581834332475		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.11489581834332475 | validation: 0.09501577316659628]
	TIME [epoch: 61.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10998956281666551		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.10998956281666551 | validation: 0.09808709619724108]
	TIME [epoch: 61.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1124395007254502		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.1124395007254502 | validation: 0.10142242642267804]
	TIME [epoch: 61.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147801604525947		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.1147801604525947 | validation: 0.09829093832505338]
	TIME [epoch: 61.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286674665691963		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.11286674665691963 | validation: 0.09541377287038219]
	TIME [epoch: 61.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11531159374937637		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.11531159374937637 | validation: 0.09718205070765648]
	TIME [epoch: 61.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11301140538869665		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.11301140538869665 | validation: 0.09995414429105706]
	TIME [epoch: 61.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11140897236617353		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.11140897236617353 | validation: 0.09893636114121077]
	TIME [epoch: 61.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1122961317831256		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.1122961317831256 | validation: 0.09556468508756844]
	TIME [epoch: 61.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11331236012489608		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.11331236012489608 | validation: 0.09867203117999565]
	TIME [epoch: 61.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442284804145207		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.11442284804145207 | validation: 0.10965960409436644]
	TIME [epoch: 61.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11367768535989385		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.11367768535989385 | validation: 0.09549779216560764]
	TIME [epoch: 61.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126889820115014		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.1126889820115014 | validation: 0.10410078798292095]
	TIME [epoch: 61.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11243450027647867		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.11243450027647867 | validation: 0.0972443414765611]
	TIME [epoch: 61.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092749889700174		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.11092749889700174 | validation: 0.09847295432311146]
	TIME [epoch: 61.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1133337163644659		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.1133337163644659 | validation: 0.09570173650026492]
	TIME [epoch: 61.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11180444885538421		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.11180444885538421 | validation: 0.09612432092040163]
	TIME [epoch: 61.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121392763925391		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.1121392763925391 | validation: 0.09948695242835616]
	TIME [epoch: 61.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11265255056439925		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.11265255056439925 | validation: 0.1011345242947248]
	TIME [epoch: 61.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11175333727311249		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.11175333727311249 | validation: 0.09468357569439631]
	TIME [epoch: 61.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1156634478154396		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1156634478154396 | validation: 0.09997776014627406]
	TIME [epoch: 61.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11259218417600736		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.11259218417600736 | validation: 0.09693589808263706]
	TIME [epoch: 61.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1151428015892701		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.1151428015892701 | validation: 0.09979828846085828]
	TIME [epoch: 61.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179543573409673		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.11179543573409673 | validation: 0.09482342030178398]
	TIME [epoch: 61.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10919811365414456		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.10919811365414456 | validation: 0.09662668240907371]
	TIME [epoch: 61.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11446859124522714		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.11446859124522714 | validation: 0.1001810185971799]
	TIME [epoch: 61.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11073444841784724		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.11073444841784724 | validation: 0.09657524879817098]
	TIME [epoch: 61.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11218155138135212		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.11218155138135212 | validation: 0.0951752677008764]
	TIME [epoch: 61.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11150592929347646		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.11150592929347646 | validation: 0.09720252922034514]
	TIME [epoch: 61.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11165851430062229		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.11165851430062229 | validation: 0.09609387420991705]
	TIME [epoch: 61.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12801790768341512		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.12801790768341512 | validation: 0.09952656275688417]
	TIME [epoch: 61.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11520689882318706		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.11520689882318706 | validation: 0.09523140274325344]
	TIME [epoch: 61.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11386730900155577		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.11386730900155577 | validation: 0.09335462890197674]
	TIME [epoch: 61.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10925989688333278		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.10925989688333278 | validation: 0.0925086284518529]
	TIME [epoch: 61.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11073904250770814		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.11073904250770814 | validation: 0.09564839773309786]
	TIME [epoch: 61.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1129988728164356		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.1129988728164356 | validation: 0.09583489253713955]
	TIME [epoch: 61.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11170917395113317		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.11170917395113317 | validation: 0.09436066255588212]
	TIME [epoch: 61.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999355109878993		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.10999355109878993 | validation: 0.09411308920599386]
	TIME [epoch: 61.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121876072403743		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.1121876072403743 | validation: 0.0950169651897417]
	TIME [epoch: 61.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11194036342769907		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.11194036342769907 | validation: 0.09734293610888983]
	TIME [epoch: 61.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1157359815078932		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1157359815078932 | validation: 0.10371553867934653]
	TIME [epoch: 61.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11404185006135432		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.11404185006135432 | validation: 0.09547842306667978]
	TIME [epoch: 61.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11030195981069707		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.11030195981069707 | validation: 0.09477146496190222]
	TIME [epoch: 61.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1108151737758864		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.1108151737758864 | validation: 0.09550069476283114]
	TIME [epoch: 61.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126691303915718		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.1126691303915718 | validation: 0.09631555166897646]
	TIME [epoch: 61.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11086523947631328		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.11086523947631328 | validation: 0.09939214640074676]
	TIME [epoch: 61.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1106954180220185		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.1106954180220185 | validation: 0.09477297199300808]
	TIME [epoch: 61.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11363268246610075		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.11363268246610075 | validation: 0.09633253876138709]
	TIME [epoch: 61.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132578233146824		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.11132578233146824 | validation: 0.09651400962222972]
	TIME [epoch: 61.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11232754392615811		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.11232754392615811 | validation: 0.09771802649898056]
	TIME [epoch: 61.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11533112041016175		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.11533112041016175 | validation: 0.09544194742112724]
	TIME [epoch: 61.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10633338754409102		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.10633338754409102 | validation: 0.0970154852321736]
	TIME [epoch: 61.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999724607771628		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.10999724607771628 | validation: 0.09556832151693498]
	TIME [epoch: 61.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11203712139848422		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.11203712139848422 | validation: 0.10279983611432852]
	TIME [epoch: 61.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11153891506976171		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.11153891506976171 | validation: 0.09633637649171312]
	TIME [epoch: 61.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11077668877226038		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.11077668877226038 | validation: 0.09759477462934336]
	TIME [epoch: 61.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11398034276741521		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.11398034276741521 | validation: 0.09712115325289594]
	TIME [epoch: 61.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10890466632695278		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.10890466632695278 | validation: 0.10110180707617336]
	TIME [epoch: 61.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11539397515834342		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.11539397515834342 | validation: 0.09748452538881237]
	TIME [epoch: 61.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10925316020153625		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.10925316020153625 | validation: 0.09612178540484291]
	TIME [epoch: 61.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11106949320883783		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11106949320883783 | validation: 0.09406875097030183]
	TIME [epoch: 61.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064522838191596		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.11064522838191596 | validation: 0.09601713209841431]
	TIME [epoch: 61.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975208037115526		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.10975208037115526 | validation: 0.09336404470286569]
	TIME [epoch: 61.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10980183278378397		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.10980183278378397 | validation: 0.09759011482630053]
	TIME [epoch: 61.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11275132223905387		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.11275132223905387 | validation: 0.0943087955817525]
	TIME [epoch: 61.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10983568950557802		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.10983568950557802 | validation: 0.09536184170594215]
	TIME [epoch: 61.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064345272715383		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.11064345272715383 | validation: 0.09771788927024955]
	TIME [epoch: 61.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11358285585442718		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.11358285585442718 | validation: 0.09996205729957668]
	TIME [epoch: 61.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11048568632247786		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.11048568632247786 | validation: 0.09736098562975394]
	TIME [epoch: 61.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11358265880529655		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.11358265880529655 | validation: 0.09809857046904696]
	TIME [epoch: 61.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11076484816097262		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.11076484816097262 | validation: 0.10025633697810592]
	TIME [epoch: 61.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11028658376674834		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.11028658376674834 | validation: 0.09812398337638435]
	TIME [epoch: 61.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11241511061081313		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.11241511061081313 | validation: 0.09821924153084342]
	TIME [epoch: 61.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11234074454015158		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.11234074454015158 | validation: 0.09882539681991326]
	TIME [epoch: 61.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11303580524499693		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.11303580524499693 | validation: 0.09850833485254407]
	TIME [epoch: 61.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11160769130366262		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.11160769130366262 | validation: 0.09803104378347065]
	TIME [epoch: 61.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11009158561207182		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.11009158561207182 | validation: 0.09584421882333277]
	TIME [epoch: 61.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11485206769400134		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.11485206769400134 | validation: 0.09769625181304023]
	TIME [epoch: 61.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11473739474150875		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.11473739474150875 | validation: 0.09410427115246976]
	TIME [epoch: 61.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11158123146790702		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.11158123146790702 | validation: 0.09691239869167637]
	TIME [epoch: 61.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11588146541508301		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.11588146541508301 | validation: 0.0951469923850584]
	TIME [epoch: 61.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11056342191152399		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.11056342191152399 | validation: 0.096702529315568]
	TIME [epoch: 61.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11635531048565327		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.11635531048565327 | validation: 0.09573221277072631]
	TIME [epoch: 61.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11242897525824258		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.11242897525824258 | validation: 0.09832986441094363]
	TIME [epoch: 61.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11190010874631781		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.11190010874631781 | validation: 0.09663608501760503]
	TIME [epoch: 61.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11053851479683671		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.11053851479683671 | validation: 0.09502385489442725]
	TIME [epoch: 61.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132282873079864		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.11132282873079864 | validation: 0.09327729447082558]
	TIME [epoch: 61.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10963836197165051		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.10963836197165051 | validation: 0.0940095445485036]
	TIME [epoch: 61.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255759437684738		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.11255759437684738 | validation: 0.09475819454906466]
	TIME [epoch: 61.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002122059148745		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.11002122059148745 | validation: 0.09647204480083318]
	TIME [epoch: 61.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11108646322565686		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.11108646322565686 | validation: 0.0968644202467243]
	TIME [epoch: 61.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11473099610184954		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.11473099610184954 | validation: 0.09529422196767104]
	TIME [epoch: 61.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10953837665908694		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.10953837665908694 | validation: 0.0959873246318016]
	TIME [epoch: 61.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11171637260565065		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.11171637260565065 | validation: 0.09768147876884409]
	TIME [epoch: 61.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11232844690515413		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.11232844690515413 | validation: 0.09671117036053448]
	TIME [epoch: 61.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11130147354409009		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.11130147354409009 | validation: 0.09412644988771143]
	TIME [epoch: 61.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907246141445721		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.10907246141445721 | validation: 0.09666365323906997]
	TIME [epoch: 61.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10872262737961619		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.10872262737961619 | validation: 0.09475392279442638]
	TIME [epoch: 61.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1103759463861201		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1103759463861201 | validation: 0.09357298335854516]
	TIME [epoch: 61.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116184321071167		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.1116184321071167 | validation: 0.09398364461741229]
	TIME [epoch: 61.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11240526913967797		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.11240526913967797 | validation: 0.09981361401083919]
	TIME [epoch: 61.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10986282820906018		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.10986282820906018 | validation: 0.09616970212970892]
	TIME [epoch: 61.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10800402465270459		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.10800402465270459 | validation: 0.09500397239343314]
	TIME [epoch: 61.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389450151381803		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.11389450151381803 | validation: 0.09936667335852592]
	TIME [epoch: 61.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10997774171316198		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.10997774171316198 | validation: 0.09337201741805165]
	TIME [epoch: 61.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11194403849395301		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.11194403849395301 | validation: 0.09513093315136625]
	TIME [epoch: 61.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11318210806791902		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.11318210806791902 | validation: 0.0980758802789097]
	TIME [epoch: 61.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11226588454237502		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.11226588454237502 | validation: 0.09616399986300003]
	TIME [epoch: 61.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11530938661955842		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.11530938661955842 | validation: 0.09983664275177237]
	TIME [epoch: 61.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10863639318129735		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.10863639318129735 | validation: 0.09649718964005172]
	TIME [epoch: 61.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155094652753138		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.11155094652753138 | validation: 0.09692304636733143]
	TIME [epoch: 61.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11086912722785736		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.11086912722785736 | validation: 0.09681869458126864]
	TIME [epoch: 61.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124101030722394		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.11124101030722394 | validation: 0.09649305332190185]
	TIME [epoch: 61.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181186065553746		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.11181186065553746 | validation: 0.09763195991355388]
	TIME [epoch: 61.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11022741873514826		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.11022741873514826 | validation: 0.09648107688534827]
	TIME [epoch: 61.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11244557404446723		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.11244557404446723 | validation: 0.09404638774122667]
	TIME [epoch: 61.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092377612314151		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.11092377612314151 | validation: 0.09560101670825974]
	TIME [epoch: 61.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11230666875487746		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.11230666875487746 | validation: 0.0961051826263414]
	TIME [epoch: 61.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10853691965777527		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.10853691965777527 | validation: 0.09411699913432264]
	TIME [epoch: 61.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11357000613891005		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.11357000613891005 | validation: 0.09603465395419165]
	TIME [epoch: 61.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11184748643404298		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.11184748643404298 | validation: 0.09571343502687055]
	TIME [epoch: 61.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11254579212455343		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.11254579212455343 | validation: 0.09412097136564271]
	TIME [epoch: 61.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11232484850322923		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.11232484850322923 | validation: 0.09568535286316635]
	TIME [epoch: 61.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181396495110156		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.11181396495110156 | validation: 0.09503345894679183]
	TIME [epoch: 61.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11023106968387801		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.11023106968387801 | validation: 0.09580514441367449]
	TIME [epoch: 61.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11183557219510305		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.11183557219510305 | validation: 0.09760294631136031]
	TIME [epoch: 61.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1107346436643259		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.1107346436643259 | validation: 0.094978064797283]
	TIME [epoch: 61.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126696792242165		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.1126696792242165 | validation: 0.09423768568884879]
	TIME [epoch: 61.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10860172319802254		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.10860172319802254 | validation: 0.09516190672203828]
	TIME [epoch: 61.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11039461094537018		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.11039461094537018 | validation: 0.09605097187215163]
	TIME [epoch: 61.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11362830715657389		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.11362830715657389 | validation: 0.09434139802305028]
	TIME [epoch: 61.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11142676157270287		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.11142676157270287 | validation: 0.0948293044764637]
	TIME [epoch: 61.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113973574868034		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.1113973574868034 | validation: 0.09747085415857035]
	TIME [epoch: 61.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11392893633148882		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.11392893633148882 | validation: 0.0981072021592786]
	TIME [epoch: 61.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1108133591637374		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.1108133591637374 | validation: 0.09486222654330703]
	TIME [epoch: 61.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958397850686108		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.10958397850686108 | validation: 0.0934419630851522]
	TIME [epoch: 61.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11251764914082102		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.11251764914082102 | validation: 0.09495482643086425]
	TIME [epoch: 61.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10833994944289023		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.10833994944289023 | validation: 0.0932871321748509]
	TIME [epoch: 61.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10946849444095252		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.10946849444095252 | validation: 0.09795356339083912]
	TIME [epoch: 61.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10928276038140232		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.10928276038140232 | validation: 0.09794145638341809]
	TIME [epoch: 61.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113568341761338		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1113568341761338 | validation: 0.09878377611351905]
	TIME [epoch: 61.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1101699218712074		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.1101699218712074 | validation: 0.09405985987488177]
	TIME [epoch: 61.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11521368868743766		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.11521368868743766 | validation: 0.09348590762787062]
	TIME [epoch: 61.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1075326741500451		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.1075326741500451 | validation: 0.09363490767860563]
	TIME [epoch: 61.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10921305362226676		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.10921305362226676 | validation: 0.09321848693873096]
	TIME [epoch: 61.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11162079232509534		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.11162079232509534 | validation: 0.09467791593850113]
	TIME [epoch: 61.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11060365572669739		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11060365572669739 | validation: 0.09561348872065377]
	TIME [epoch: 61.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11311343233151774		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.11311343233151774 | validation: 0.1004206933716427]
	TIME [epoch: 61.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988638789527468		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.10988638789527468 | validation: 0.09577653950071695]
	TIME [epoch: 61.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10953401247446132		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.10953401247446132 | validation: 0.09457743064445953]
	TIME [epoch: 61.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1104364613950091		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1104364613950091 | validation: 0.09359947046696189]
	TIME [epoch: 61.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907169331041446		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.10907169331041446 | validation: 0.09381075061280617]
	TIME [epoch: 61.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10850704911803578		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.10850704911803578 | validation: 0.09463602947940168]
	TIME [epoch: 61.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11159058195222182		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.11159058195222182 | validation: 0.09770170523486693]
	TIME [epoch: 61.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1087020658636158		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1087020658636158 | validation: 0.09464824129769392]
	TIME [epoch: 61.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11030143379398147		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.11030143379398147 | validation: 0.09312150938217158]
	TIME [epoch: 61.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11040315408690798		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.11040315408690798 | validation: 0.09445726371817562]
	TIME [epoch: 61.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11040092630335648		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.11040092630335648 | validation: 0.09508535435221292]
	TIME [epoch: 61.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11145284837435561		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.11145284837435561 | validation: 0.0988777739338029]
	TIME [epoch: 61.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10936293642423216		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.10936293642423216 | validation: 0.09585726371869599]
	TIME [epoch: 61.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155477969720959		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.11155477969720959 | validation: 0.09439617652693474]
	TIME [epoch: 61.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11039231776977909		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.11039231776977909 | validation: 0.09649675545290312]
	TIME [epoch: 61.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1114646875005176		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1114646875005176 | validation: 0.09298074871651653]
	TIME [epoch: 61.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10825570455271692		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.10825570455271692 | validation: 0.09776667183073193]
	TIME [epoch: 61.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11078121731602363		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.11078121731602363 | validation: 0.09612747538891198]
	TIME [epoch: 61.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10910734277063247		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.10910734277063247 | validation: 0.09408511070438005]
	TIME [epoch: 61.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11254221195679127		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.11254221195679127 | validation: 0.09673960369951466]
	TIME [epoch: 61.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11203143152498517		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.11203143152498517 | validation: 0.09608711839798996]
	TIME [epoch: 61.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1108869646453975		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.1108869646453975 | validation: 0.09433432142047682]
	TIME [epoch: 61.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11364251515554472		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.11364251515554472 | validation: 0.09588449146747864]
	TIME [epoch: 61.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11075159156535891		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.11075159156535891 | validation: 0.09195117166364053]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_431.pth
	Model improved!!!
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10801227389021788		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.10801227389021788 | validation: 0.0960457631496798]
	TIME [epoch: 61.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098544960744037		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.1098544960744037 | validation: 0.09539037106999702]
	TIME [epoch: 61.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11106140284355621		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.11106140284355621 | validation: 0.09823024408222165]
	TIME [epoch: 61.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10862525757180264		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.10862525757180264 | validation: 0.09342465255246166]
	TIME [epoch: 61.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181768986683438		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.11181768986683438 | validation: 0.09545449867428177]
	TIME [epoch: 61.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11004723334984542		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.11004723334984542 | validation: 0.0981086145867272]
	TIME [epoch: 61.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118639881991314		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.1118639881991314 | validation: 0.0957521880605841]
	TIME [epoch: 61.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121955117815186		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.1121955117815186 | validation: 0.09466265957595424]
	TIME [epoch: 61.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1074958420281434		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.1074958420281434 | validation: 0.09410174578239709]
	TIME [epoch: 61.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010492241595292		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.11010492241595292 | validation: 0.09384388601489817]
	TIME [epoch: 61.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10875545009763682		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.10875545009763682 | validation: 0.09356248584689568]
	TIME [epoch: 61.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10851380980397285		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.10851380980397285 | validation: 0.09447589322334204]
	TIME [epoch: 61.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10929848755498497		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.10929848755498497 | validation: 0.09410082951843388]
	TIME [epoch: 61.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105307395215648		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.1105307395215648 | validation: 0.09417513548516343]
	TIME [epoch: 61.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11472044196113934		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.11472044196113934 | validation: 0.0964809719452625]
	TIME [epoch: 61.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11045174026267615		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.11045174026267615 | validation: 0.09619814985134092]
	TIME [epoch: 61.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10711051007666887		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.10711051007666887 | validation: 0.09555235667739295]
	TIME [epoch: 61.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11102124279984206		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.11102124279984206 | validation: 0.09501029986420842]
	TIME [epoch: 61.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992477231311353		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.10992477231311353 | validation: 0.09351679326834812]
	TIME [epoch: 61.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10806814724995895		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.10806814724995895 | validation: 0.09336563347097854]
	TIME [epoch: 61.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988302154266856		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.10988302154266856 | validation: 0.09487689058032704]
	TIME [epoch: 61.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10938674210148583		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.10938674210148583 | validation: 0.09387410140569943]
	TIME [epoch: 61.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958036814330502		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.10958036814330502 | validation: 0.09408799987367569]
	TIME [epoch: 61.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11150469988587666		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.11150469988587666 | validation: 0.0924114701544599]
	TIME [epoch: 61.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11229580115793353		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.11229580115793353 | validation: 0.09504937875920684]
	TIME [epoch: 61.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11229623090137461		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.11229623090137461 | validation: 0.09381617239036336]
	TIME [epoch: 61.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11185428241864168		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.11185428241864168 | validation: 0.09426871528372627]
	TIME [epoch: 61.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11113304433113526		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.11113304433113526 | validation: 0.09770529805224087]
	TIME [epoch: 61.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10840394360460517		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.10840394360460517 | validation: 0.09249883213134649]
	TIME [epoch: 61.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11133949722390055		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.11133949722390055 | validation: 0.09206086982536446]
	TIME [epoch: 61.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1119060535682157		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.1119060535682157 | validation: 0.09570031468802105]
	TIME [epoch: 61.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11184377167465362		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11184377167465362 | validation: 0.09659022486337307]
	TIME [epoch: 61.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10928677615004793		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.10928677615004793 | validation: 0.09479215229325835]
	TIME [epoch: 61.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992819112350168		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.10992819112350168 | validation: 0.09601095079585789]
	TIME [epoch: 61.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10947788603386903		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.10947788603386903 | validation: 0.0941523611397532]
	TIME [epoch: 61.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11058000043631099		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.11058000043631099 | validation: 0.09392133654501647]
	TIME [epoch: 61.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10678539698464645		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.10678539698464645 | validation: 0.09486351333945739]
	TIME [epoch: 61.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10812096505310295		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.10812096505310295 | validation: 0.09610153762152933]
	TIME [epoch: 61.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1111205207144021		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.1111205207144021 | validation: 0.09437728114532634]
	TIME [epoch: 61.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10978492064851651		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10978492064851651 | validation: 0.09488851065858321]
	TIME [epoch: 61.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112870938260411		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.112870938260411 | validation: 0.09430308944037834]
	TIME [epoch: 61.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10705512021794555		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.10705512021794555 | validation: 0.0980548935883023]
	TIME [epoch: 61.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10743607368239944		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.10743607368239944 | validation: 0.09358341368606067]
	TIME [epoch: 61.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11021149865256051		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.11021149865256051 | validation: 0.09511056384962158]
	TIME [epoch: 61.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10916274708290082		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.10916274708290082 | validation: 0.0961302404213171]
	TIME [epoch: 61.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10880540378400744		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.10880540378400744 | validation: 0.0931577956676155]
	TIME [epoch: 61.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1087967264858643		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.1087967264858643 | validation: 0.09539924512584598]
	TIME [epoch: 61.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10879663628909945		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10879663628909945 | validation: 0.09374779717220413]
	TIME [epoch: 61.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11163971809898286		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.11163971809898286 | validation: 0.09386804314489519]
	TIME [epoch: 61.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10871253433351334		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.10871253433351334 | validation: 0.09360461323682553]
	TIME [epoch: 61.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1058045229114483		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.1058045229114483 | validation: 0.09633788149826619]
	TIME [epoch: 61.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11020530734616758		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.11020530734616758 | validation: 0.09371724009012553]
	TIME [epoch: 61.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10726221844621653		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.10726221844621653 | validation: 0.09204834287407902]
	TIME [epoch: 61.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11214316314950541		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.11214316314950541 | validation: 0.09271364897056723]
	TIME [epoch: 61.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179678629366241		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.11179678629366241 | validation: 0.09304210134456374]
	TIME [epoch: 61.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909670866564805		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10909670866564805 | validation: 0.09435032222690966]
	TIME [epoch: 61.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10842560564841593		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.10842560564841593 | validation: 0.09478699626285084]
	TIME [epoch: 61.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10827638495609646		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.10827638495609646 | validation: 0.09499115707358331]
	TIME [epoch: 61.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10952891846079184		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.10952891846079184 | validation: 0.09348190815815668]
	TIME [epoch: 61.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906481019564145		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.10906481019564145 | validation: 0.0938264055104642]
	TIME [epoch: 61.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096445833743159		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.1096445833743159 | validation: 0.0951230528638483]
	TIME [epoch: 61.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10880630749190534		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.10880630749190534 | validation: 0.09449149496295005]
	TIME [epoch: 61.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11176270375305138		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.11176270375305138 | validation: 0.09040136672113416]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11028092600001539		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.11028092600001539 | validation: 0.09300811099659022]
	TIME [epoch: 61.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10738812592428222		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.10738812592428222 | validation: 0.09475258204572433]
	TIME [epoch: 61.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10881723623318583		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.10881723623318583 | validation: 0.0927966800560591]
	TIME [epoch: 61.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11052618044590869		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.11052618044590869 | validation: 0.09381224456520547]
	TIME [epoch: 61.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098988502410408		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.1098988502410408 | validation: 0.09399958807885427]
	TIME [epoch: 61.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10717307005471052		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.10717307005471052 | validation: 0.09423541679974057]
	TIME [epoch: 61.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896771954174919		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.10896771954174919 | validation: 0.09432411604139901]
	TIME [epoch: 61.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079826844181441		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.1079826844181441 | validation: 0.0928309942182727]
	TIME [epoch: 61.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619935359611446		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.10619935359611446 | validation: 0.09366897514244182]
	TIME [epoch: 61.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11045135118927235		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.11045135118927235 | validation: 0.09407386796109606]
	TIME [epoch: 61.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1093712249072804		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.1093712249072804 | validation: 0.09181903406337227]
	TIME [epoch: 61.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10993162518253048		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.10993162518253048 | validation: 0.09625584717842864]
	TIME [epoch: 61.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11000325850850615		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.11000325850850615 | validation: 0.09662410238707977]
	TIME [epoch: 61.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10787248747441525		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.10787248747441525 | validation: 0.0945334800741633]
	TIME [epoch: 61.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10804584832001354		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.10804584832001354 | validation: 0.09827928685336132]
	TIME [epoch: 61.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11463314533196708		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.11463314533196708 | validation: 0.09238383256837066]
	TIME [epoch: 61.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10967465241034369		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10967465241034369 | validation: 0.09294533201220148]
	TIME [epoch: 61.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10649292596059874		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.10649292596059874 | validation: 0.09200847649756531]
	TIME [epoch: 61.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11126130352810705		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.11126130352810705 | validation: 0.09481051337251446]
	TIME [epoch: 61.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867512225018451		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.10867512225018451 | validation: 0.09335545734054196]
	TIME [epoch: 61.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10969002898264918		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.10969002898264918 | validation: 0.09514508720749845]
	TIME [epoch: 61.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10765278647172517		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.10765278647172517 | validation: 0.09364499984688068]
	TIME [epoch: 61.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100349789064647		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.1100349789064647 | validation: 0.09518877313679665]
	TIME [epoch: 61.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1082668962998885		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.1082668962998885 | validation: 0.09280997764081773]
	TIME [epoch: 61.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1109335873968168		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.1109335873968168 | validation: 0.09281686825803181]
	TIME [epoch: 61.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10797707052234103		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.10797707052234103 | validation: 0.09261736730608547]
	TIME [epoch: 61.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10939908482554515		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.10939908482554515 | validation: 0.09565701474752249]
	TIME [epoch: 61.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896294818948783		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.10896294818948783 | validation: 0.09547795104347037]
	TIME [epoch: 61.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10679003850619496		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.10679003850619496 | validation: 0.094823096990859]
	TIME [epoch: 61.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102111749714354		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.1102111749714354 | validation: 0.09499436830762431]
	TIME [epoch: 61.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11045415521037144		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.11045415521037144 | validation: 0.0937990902729134]
	TIME [epoch: 61.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11212866657318771		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.11212866657318771 | validation: 0.0960422634092146]
	TIME [epoch: 61.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118364194851497		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.11118364194851497 | validation: 0.0936773594799297]
	TIME [epoch: 61.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280678355513953		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.11280678355513953 | validation: 0.09473012840430835]
	TIME [epoch: 61.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10875253547607824		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.10875253547607824 | validation: 0.09427161532250927]
	TIME [epoch: 61.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896172712080633		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.10896172712080633 | validation: 0.0923333792820349]
	TIME [epoch: 61.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11027527505616429		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.11027527505616429 | validation: 0.09516981488595215]
	TIME [epoch: 61.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11192646877943874		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.11192646877943874 | validation: 0.09281350816021333]
	TIME [epoch: 61.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11044374277816066		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.11044374277816066 | validation: 0.09410797443913879]
	TIME [epoch: 61.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11072071771915998		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.11072071771915998 | validation: 0.09532562160893583]
	TIME [epoch: 61.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10798649901651208		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.10798649901651208 | validation: 0.09693138075829628]
	TIME [epoch: 61.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10942683776012599		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.10942683776012599 | validation: 0.09474153151816464]
	TIME [epoch: 61.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11049597071146111		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.11049597071146111 | validation: 0.09326516386320186]
	TIME [epoch: 61.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10903837406444988		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.10903837406444988 | validation: 0.09470084667465524]
	TIME [epoch: 61.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10930394320629173		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.10930394320629173 | validation: 0.09613674766394256]
	TIME [epoch: 61.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174324329569159		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.11174324329569159 | validation: 0.09392786547264695]
	TIME [epoch: 61.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10620383442328202		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.10620383442328202 | validation: 0.09647499205888732]
	TIME [epoch: 61.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10768419324148927		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.10768419324148927 | validation: 0.09640854501572933]
	TIME [epoch: 61.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10745654953875149		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.10745654953875149 | validation: 0.09327369646615295]
	TIME [epoch: 61.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10887375209536487		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.10887375209536487 | validation: 0.09293522898230086]
	TIME [epoch: 61.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10715675060662805		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.10715675060662805 | validation: 0.09436338988191927]
	TIME [epoch: 61.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11160627869237591		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.11160627869237591 | validation: 0.09310759737008464]
	TIME [epoch: 61.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1101103238876242		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.1101103238876242 | validation: 0.09457026741896507]
	TIME [epoch: 61.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999465376644392		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.10999465376644392 | validation: 0.0944908261345357]
	TIME [epoch: 61.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10755973644241515		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.10755973644241515 | validation: 0.09278100121502221]
	TIME [epoch: 61.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10806959620842004		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.10806959620842004 | validation: 0.09361034062952538]
	TIME [epoch: 61.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11266862529782881		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.11266862529782881 | validation: 0.09281093719676464]
	TIME [epoch: 61.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10761844806005903		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.10761844806005903 | validation: 0.09273794590232551]
	TIME [epoch: 61.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10893674358704686		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.10893674358704686 | validation: 0.09389233738629779]
	TIME [epoch: 61.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10794762977901119		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.10794762977901119 | validation: 0.0949492619308324]
	TIME [epoch: 61.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10870097241259437		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.10870097241259437 | validation: 0.09529380692715265]
	TIME [epoch: 61.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11161577302840867		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.11161577302840867 | validation: 0.09406290948522224]
	TIME [epoch: 61.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10627301898871222		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.10627301898871222 | validation: 0.09606814908244274]
	TIME [epoch: 61.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11008005439571121		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.11008005439571121 | validation: 0.09347918290692867]
	TIME [epoch: 61.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11108964917378486		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11108964917378486 | validation: 0.09139260570452144]
	TIME [epoch: 61.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10942203762228662		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.10942203762228662 | validation: 0.09355047242825719]
	TIME [epoch: 61.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10878802809609583		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.10878802809609583 | validation: 0.09424216811148076]
	TIME [epoch: 61.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10751276752341041		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.10751276752341041 | validation: 0.0945221703163818]
	TIME [epoch: 61.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10843375709527614		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.10843375709527614 | validation: 0.09367104457440549]
	TIME [epoch: 61.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11019397633268856		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.11019397633268856 | validation: 0.09505104701082655]
	TIME [epoch: 61.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11018190492693705		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.11018190492693705 | validation: 0.09409028964876251]
	TIME [epoch: 61.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958811071458736		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.10958811071458736 | validation: 0.0962171795817991]
	TIME [epoch: 61.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113544286967871		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1113544286967871 | validation: 0.09329687381970468]
	TIME [epoch: 61.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11083885693058639		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.11083885693058639 | validation: 0.09424683310839281]
	TIME [epoch: 61.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10911311064456358		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.10911311064456358 | validation: 0.09524456723069216]
	TIME [epoch: 61.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10841726729175381		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.10841726729175381 | validation: 0.09335550537185439]
	TIME [epoch: 61.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10760432189912339		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.10760432189912339 | validation: 0.0949205025586966]
	TIME [epoch: 61.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814924715168592		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.10814924715168592 | validation: 0.0937550772567933]
	TIME [epoch: 61.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10763038675027212		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.10763038675027212 | validation: 0.09110341973907828]
	TIME [epoch: 61.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1090108822561357		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.1090108822561357 | validation: 0.09540784885747208]
	TIME [epoch: 61.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10807674094512643		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10807674094512643 | validation: 0.09390094727208112]
	TIME [epoch: 61.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909426819427485		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.10909426819427485 | validation: 0.09405207049420368]
	TIME [epoch: 61.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11205000239023041		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11205000239023041 | validation: 0.09500695739227594]
	TIME [epoch: 61.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10745929195889725		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.10745929195889725 | validation: 0.09432951604611163]
	TIME [epoch: 61.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11285129702010506		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.11285129702010506 | validation: 0.09604011000532128]
	TIME [epoch: 61.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280127857300783		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.11280127857300783 | validation: 0.09089880805789359]
	TIME [epoch: 61.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10727299733148629		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.10727299733148629 | validation: 0.094464191864235]
	TIME [epoch: 61.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10872351177667244		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.10872351177667244 | validation: 0.09380231518569801]
	TIME [epoch: 61.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10880071970201587		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.10880071970201587 | validation: 0.09317293067346102]
	TIME [epoch: 61.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10799142017760081		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.10799142017760081 | validation: 0.0924736557717356]
	TIME [epoch: 61.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10856349960311754		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.10856349960311754 | validation: 0.09461178648539845]
	TIME [epoch: 61.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10880398746267951		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.10880398746267951 | validation: 0.09369478874674883]
	TIME [epoch: 61.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11102062187204208		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.11102062187204208 | validation: 0.09390985654207298]
	TIME [epoch: 61.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1097881362238235		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.1097881362238235 | validation: 0.09073277848057422]
	TIME [epoch: 61.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11038300007629985		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.11038300007629985 | validation: 0.09558308524777445]
	TIME [epoch: 61.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10950040652755996		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.10950040652755996 | validation: 0.09481785693184304]
	TIME [epoch: 61.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10833908380423624		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10833908380423624 | validation: 0.09367312560242862]
	TIME [epoch: 61.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10710663795431169		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.10710663795431169 | validation: 0.0935752295950527]
	TIME [epoch: 61.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10794096195420849		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.10794096195420849 | validation: 0.09434910265734783]
	TIME [epoch: 61.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11043467490747773		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.11043467490747773 | validation: 0.09510750105031077]
	TIME [epoch: 61.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992983706585446		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.10992983706585446 | validation: 0.09478463424152844]
	TIME [epoch: 61.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10950827943338153		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.10950827943338153 | validation: 0.09399487185420985]
	TIME [epoch: 61.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10556419819162104		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.10556419819162104 | validation: 0.09436327599651824]
	TIME [epoch: 61.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10891886462190911		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.10891886462190911 | validation: 0.09227627003276458]
	TIME [epoch: 61.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10866185301751839		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.10866185301751839 | validation: 0.09319043717394125]
	TIME [epoch: 61.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10945619011086052		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.10945619011086052 | validation: 0.09368197869254534]
	TIME [epoch: 61.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10830933244783969		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.10830933244783969 | validation: 0.093374696474788]
	TIME [epoch: 61.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1083581967689533		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.1083581967689533 | validation: 0.09426191325553582]
	TIME [epoch: 61.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10520625449604405		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.10520625449604405 | validation: 0.09517590887715517]
	TIME [epoch: 61.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10654331848219839		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.10654331848219839 | validation: 0.09557955250117094]
	TIME [epoch: 61.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002745282693296		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.11002745282693296 | validation: 0.09287137840526263]
	TIME [epoch: 61.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11016016459073873		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.11016016459073873 | validation: 0.09296051409503683]
	TIME [epoch: 61.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10853576613203769		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10853576613203769 | validation: 0.09372356695281796]
	TIME [epoch: 61.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1093442460304162		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.1093442460304162 | validation: 0.09389472046705223]
	TIME [epoch: 61.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10849317208050509		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.10849317208050509 | validation: 0.09284938272559884]
	TIME [epoch: 61.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11093168915642404		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.11093168915642404 | validation: 0.09311517389351126]
	TIME [epoch: 61.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11060765653457996		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.11060765653457996 | validation: 0.09100554246145896]
	TIME [epoch: 61.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10858448047965895		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.10858448047965895 | validation: 0.09416131209514465]
	TIME [epoch: 61.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10835922458846925		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.10835922458846925 | validation: 0.0931741574531398]
	TIME [epoch: 61.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11168718058262482		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.11168718058262482 | validation: 0.09104955121238331]
	TIME [epoch: 61.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10840014189575442		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.10840014189575442 | validation: 0.09543413789820529]
	TIME [epoch: 61.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108342872781382		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.108342872781382 | validation: 0.09362233335610383]
	TIME [epoch: 61.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10851114301971414		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.10851114301971414 | validation: 0.0948039385164304]
	TIME [epoch: 61.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10876567956010649		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.10876567956010649 | validation: 0.09278668944272746]
	TIME [epoch: 61.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10729091216586166		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.10729091216586166 | validation: 0.09230767474149151]
	TIME [epoch: 61.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067670494513251		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.1067670494513251 | validation: 0.09280331977018995]
	TIME [epoch: 61.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11008294409286722		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.11008294409286722 | validation: 0.09317933159106621]
	TIME [epoch: 61.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10671727970756699		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.10671727970756699 | validation: 0.09208695861035324]
	TIME [epoch: 61.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10665032980732407		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10665032980732407 | validation: 0.09288007456381552]
	TIME [epoch: 61.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10863450452680498		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.10863450452680498 | validation: 0.09473643646395909]
	TIME [epoch: 61.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10783779991802822		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.10783779991802822 | validation: 0.09416111732480467]
	TIME [epoch: 61.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11025940696190324		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.11025940696190324 | validation: 0.09480727225192419]
	TIME [epoch: 61.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10703210341379579		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.10703210341379579 | validation: 0.0924475603593273]
	TIME [epoch: 61.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10819449022381424		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.10819449022381424 | validation: 0.09346239860971034]
	TIME [epoch: 61.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11123022133946796		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.11123022133946796 | validation: 0.09277004986370042]
	TIME [epoch: 61.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10689498924387698		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.10689498924387698 | validation: 0.09358861174407249]
	TIME [epoch: 61.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11137949886288404		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.11137949886288404 | validation: 0.09341066940332597]
	TIME [epoch: 61.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10740365078586148		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.10740365078586148 | validation: 0.09475152286264435]
	TIME [epoch: 61.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10600287214421382		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.10600287214421382 | validation: 0.09486507103540447]
	TIME [epoch: 61.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10582318941054507		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.10582318941054507 | validation: 0.09324251147825284]
	TIME [epoch: 61.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10493764560746352		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.10493764560746352 | validation: 0.09488942492653443]
	TIME [epoch: 61.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10894362554572756		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.10894362554572756 | validation: 0.09419341798662478]
	TIME [epoch: 61.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589898394442442		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.10589898394442442 | validation: 0.09294960583867451]
	TIME [epoch: 61.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1078975405502611		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.1078975405502611 | validation: 0.09186739206367743]
	TIME [epoch: 61.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782080347760845		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.10782080347760845 | validation: 0.09271813492653158]
	TIME [epoch: 61.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1058040051219765		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.1058040051219765 | validation: 0.09141305087977307]
	TIME [epoch: 61.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988643709985828		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.10988643709985828 | validation: 0.09472938228199405]
	TIME [epoch: 61.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10653664119996861		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.10653664119996861 | validation: 0.09446259317584692]
	TIME [epoch: 61.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10665160792993057		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.10665160792993057 | validation: 0.09304898988098231]
	TIME [epoch: 61.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10667175685665277		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.10667175685665277 | validation: 0.0942002005464404]
	TIME [epoch: 61.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10751209387260946		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.10751209387260946 | validation: 0.09293289524304378]
	TIME [epoch: 61.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10904760244678234		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.10904760244678234 | validation: 0.09303742531087746]
	TIME [epoch: 61.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1072381439353108		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1072381439353108 | validation: 0.09392717596664016]
	TIME [epoch: 61.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10763686695440469		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.10763686695440469 | validation: 0.09447516190070773]
	TIME [epoch: 61.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10948170784756793		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.10948170784756793 | validation: 0.09305215543899223]
	TIME [epoch: 61.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10953804200487728		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.10953804200487728 | validation: 0.09293675848207143]
	TIME [epoch: 61.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096518158507171		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.1096518158507171 | validation: 0.09307943064625487]
	TIME [epoch: 61.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1106486205933427		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.1106486205933427 | validation: 0.09304537676632856]
	TIME [epoch: 61.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10819737127970627		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.10819737127970627 | validation: 0.09316301177110102]
	TIME [epoch: 61.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1114252097743617		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.1114252097743617 | validation: 0.09288475043651505]
	TIME [epoch: 61.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10679062293751282		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10679062293751282 | validation: 0.09152602236492828]
	TIME [epoch: 61.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10805475028539387		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.10805475028539387 | validation: 0.09368251730492165]
	TIME [epoch: 61.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10628731956155428		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.10628731956155428 | validation: 0.09116757920290343]
	TIME [epoch: 61.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10653548508694133		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.10653548508694133 | validation: 0.09377095997285925]
	TIME [epoch: 61.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10823797279077269		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.10823797279077269 | validation: 0.09434525503760507]
	TIME [epoch: 61.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10729727890181923		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.10729727890181923 | validation: 0.09146497683924114]
	TIME [epoch: 61.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10667829634702519		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.10667829634702519 | validation: 0.08995801488184334]
	TIME [epoch: 61.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240627_193058/states/model_facs_dec1b_2dpca_v1_661.pth
	Model improved!!!
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10790902539348034		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.10790902539348034 | validation: 0.0930858418151831]
	TIME [epoch: 61.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10855049490640256		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.10855049490640256 | validation: 0.09152743935828425]
	TIME [epoch: 61.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11026268466608438		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.11026268466608438 | validation: 0.0920782938989417]
	TIME [epoch: 61.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11025907113268363		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.11025907113268363 | validation: 0.09212889787209261]
	TIME [epoch: 61.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10908923266174997		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.10908923266174997 | validation: 0.09276497485359005]
	TIME [epoch: 61.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10824618482324294		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.10824618482324294 | validation: 0.09237191204643345]
	TIME [epoch: 61.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095093912103501		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.1095093912103501 | validation: 0.09211097795913818]
	TIME [epoch: 61.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10849847631692634		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.10849847631692634 | validation: 0.09522621576470555]
	TIME [epoch: 61.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10915239864142737		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.10915239864142737 | validation: 0.09632792542382729]
	TIME [epoch: 61.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750323939081834		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10750323939081834 | validation: 0.09246171133060248]
	TIME [epoch: 61.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1071561314789321		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.1071561314789321 | validation: 0.09417753698732743]
	TIME [epoch: 61.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906269823877551		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.10906269823877551 | validation: 0.09288297301698978]
	TIME [epoch: 61.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10681482221853608		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.10681482221853608 | validation: 0.0913526217632052]
	TIME [epoch: 61.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10801246683909313		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.10801246683909313 | validation: 0.09297942444452406]
	TIME [epoch: 61.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10885771936135005		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.10885771936135005 | validation: 0.09279714998346482]
	TIME [epoch: 61.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10923771169646629		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.10923771169646629 | validation: 0.0964384932629266]
	TIME [epoch: 61.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095458078074476		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.1095458078074476 | validation: 0.09302764100480725]
	TIME [epoch: 61.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10821660932745969		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10821660932745969 | validation: 0.09265470049984274]
	TIME [epoch: 61.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10553225814534434		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.10553225814534434 | validation: 0.09295672012917819]
	TIME [epoch: 61.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10799090072993975		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.10799090072993975 | validation: 0.09410743302737012]
	TIME [epoch: 61.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.106124416034823		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.106124416034823 | validation: 0.09280681779428815]
	TIME [epoch: 61.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10861449332276438		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.10861449332276438 | validation: 0.09375034841054236]
	TIME [epoch: 61.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10724621145011848		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.10724621145011848 | validation: 0.09330019869884297]
	TIME [epoch: 61.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1086367254146209		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.1086367254146209 | validation: 0.09320714336010244]
	TIME [epoch: 61.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10664818745880766		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.10664818745880766 | validation: 0.09399946009397774]
	TIME [epoch: 61.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10838746576848746		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.10838746576848746 | validation: 0.09502768414385851]
	TIME [epoch: 61.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1086420955365544		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.1086420955365544 | validation: 0.09212523178921052]
	TIME [epoch: 61.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10587917179098333		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.10587917179098333 | validation: 0.09631145796314707]
	TIME [epoch: 61.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10671543626723835		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.10671543626723835 | validation: 0.09410355015453066]
	TIME [epoch: 61.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1059358967583095		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.1059358967583095 | validation: 0.09284199325142004]
	TIME [epoch: 61.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11166254015379568		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.11166254015379568 | validation: 0.09501455616108019]
	TIME [epoch: 61.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10786145047253043		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.10786145047253043 | validation: 0.09235707179699669]
	TIME [epoch: 61.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10755050690130079		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.10755050690130079 | validation: 0.09351363412474038]
	TIME [epoch: 61.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10872200351553621		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.10872200351553621 | validation: 0.09363111357182699]
	TIME [epoch: 61.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10928235486293819		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.10928235486293819 | validation: 0.09348946363590802]
	TIME [epoch: 61.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10847872152159596		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.10847872152159596 | validation: 0.09205291735932672]
	TIME [epoch: 61.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10491676815841679		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.10491676815841679 | validation: 0.09177439224463722]
	TIME [epoch: 61.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10786906733144508		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.10786906733144508 | validation: 0.09251220158013673]
	TIME [epoch: 61.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10691676406923595		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.10691676406923595 | validation: 0.09349681111069821]
	TIME [epoch: 61.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11321196444911306		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.11321196444911306 | validation: 0.09395114786713692]
	TIME [epoch: 61.8 sec]
EPOCH 702/2000:
	Training over batches...
