Args:
Namespace(name='model_facs_dec2b_2dpca_v2', outdir='out/model_training/model_facs_dec2b_2dpca_v2', training_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4232857119

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8833981135332356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8833981135332356 | validation: 0.5895940738457648]
	TIME [epoch: 111 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4167738942876179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4167738942876179 | validation: 0.4506648984592844]
	TIME [epoch: 84.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3551465455277209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3551465455277209 | validation: 0.4324103553227143]
	TIME [epoch: 84.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3451617509634245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3451617509634245 | validation: 0.4166510883805682]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3385669886684607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3385669886684607 | validation: 0.4090719867381718]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31614990211390753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31614990211390753 | validation: 0.40755176765388074]
	TIME [epoch: 84.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3193415017577471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3193415017577471 | validation: 0.4183393138190208]
	TIME [epoch: 84.3 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32167966336187676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32167966336187676 | validation: 0.36324562282428585]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2730448662049306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2730448662049306 | validation: 0.4184930664877303]
	TIME [epoch: 84.2 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.324699262326471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.324699262326471 | validation: 0.3274113719892878]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25741347417136723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25741347417136723 | validation: 0.31288698585131125]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2544358911238388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2544358911238388 | validation: 0.31342005846951576]
	TIME [epoch: 84.3 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23486495970861357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23486495970861357 | validation: 0.30908387235834656]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2333981327283406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2333981327283406 | validation: 0.3117963451076588]
	TIME [epoch: 84.3 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22510076166011186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22510076166011186 | validation: 0.2936549429501605]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.228138169983736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.228138169983736 | validation: 0.2814396072871931]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19652462604051374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19652462604051374 | validation: 0.26050717591239636]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18817894644021751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18817894644021751 | validation: 0.3655667989820257]
	TIME [epoch: 84.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2114949934233638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2114949934233638 | validation: 0.2751528263156568]
	TIME [epoch: 84.4 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18483589112183613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18483589112183613 | validation: 0.2537947321109192]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19644057151154856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19644057151154856 | validation: 0.2806753114548406]
	TIME [epoch: 84.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18049278264838023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18049278264838023 | validation: 0.23620540010754612]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17954818568778966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17954818568778966 | validation: 0.2886433336615907]
	TIME [epoch: 84.3 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17423617972931543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17423617972931543 | validation: 0.22228824909156938]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1729782992522943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1729782992522943 | validation: 0.23715789312835223]
	TIME [epoch: 84.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1697539716139024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1697539716139024 | validation: 0.24436457231162917]
	TIME [epoch: 84.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601486512022253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1601486512022253 | validation: 0.22306721357977283]
	TIME [epoch: 84.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16288322963738733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16288322963738733 | validation: 0.22483651651718745]
	TIME [epoch: 84.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14665847345895225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14665847345895225 | validation: 0.23551219726540482]
	TIME [epoch: 84.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18357629740533069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18357629740533069 | validation: 0.23852165987214624]
	TIME [epoch: 84.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14729408644884903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14729408644884903 | validation: 0.22074119699454725]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18009529033204225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18009529033204225 | validation: 0.21331912447520646]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13786971760893216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13786971760893216 | validation: 0.22797292497548016]
	TIME [epoch: 84.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16796512522574664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16796512522574664 | validation: 0.20302368362172718]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13307899000331172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13307899000331172 | validation: 0.22180059949496422]
	TIME [epoch: 84.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15336641244288363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15336641244288363 | validation: 0.1936735773091492]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14011384810089672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14011384810089672 | validation: 0.21469696449064754]
	TIME [epoch: 84.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1691787163265125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1691787163265125 | validation: 0.2625866130194673]
	TIME [epoch: 84.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13396360375405789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13396360375405789 | validation: 0.20503997960950482]
	TIME [epoch: 84.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14050368206137315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14050368206137315 | validation: 0.19364437502396534]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1361566036673281		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.1361566036673281 | validation: 0.23949915956268736]
	TIME [epoch: 84.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16726441849219484		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.16726441849219484 | validation: 0.19925590876582705]
	TIME [epoch: 84.4 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12547309696345843		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.12547309696345843 | validation: 0.21562174506299722]
	TIME [epoch: 84.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13816116848646845		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.13816116848646845 | validation: 0.22267457863533735]
	TIME [epoch: 84.4 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15301356116295622		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.15301356116295622 | validation: 0.19685253003513725]
	TIME [epoch: 84.4 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14416399367130808		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.14416399367130808 | validation: 0.20049567896665815]
	TIME [epoch: 84.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15512592058670074		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.15512592058670074 | validation: 0.1975165907022434]
	TIME [epoch: 84.4 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1375702602434459		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.1375702602434459 | validation: 0.20819406090954257]
	TIME [epoch: 84.4 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12684550581331952		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.12684550581331952 | validation: 0.2044723315676131]
	TIME [epoch: 84.4 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495529239065116		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.1495529239065116 | validation: 0.18553102561143567]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1282462894729292		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.1282462894729292 | validation: 0.17562133857859658]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14233813578273447		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.14233813578273447 | validation: 0.21351977289723115]
	TIME [epoch: 84.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14263978730365873		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.14263978730365873 | validation: 0.19075700544019392]
	TIME [epoch: 84.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13592124761702046		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.13592124761702046 | validation: 0.18470318650651746]
	TIME [epoch: 84.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1277229212790751		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.1277229212790751 | validation: 0.227453699059203]
	TIME [epoch: 84.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720573684012596		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.1720573684012596 | validation: 0.20236493147240797]
	TIME [epoch: 84.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13441252670960363		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.13441252670960363 | validation: 0.20360364526335564]
	TIME [epoch: 84.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13075991367067358		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.13075991367067358 | validation: 0.1795183515620719]
	TIME [epoch: 84.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12996411740188593		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.12996411740188593 | validation: 0.3089573634005095]
	TIME [epoch: 84.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14335074516102533		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.14335074516102533 | validation: 0.19573019280373521]
	TIME [epoch: 84.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1247941936045617		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.1247941936045617 | validation: 0.2651461908937604]
	TIME [epoch: 84.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1439180804614733		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.1439180804614733 | validation: 0.19671988016656947]
	TIME [epoch: 84.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12319243110602304		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.12319243110602304 | validation: 0.2100576989260421]
	TIME [epoch: 84.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13776308896009673		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.13776308896009673 | validation: 0.1715545962071895]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1266613194959207		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.1266613194959207 | validation: 0.17038118456384319]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11487769318807547		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.11487769318807547 | validation: 0.18480359399436402]
	TIME [epoch: 84.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.126878519807699		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.126878519807699 | validation: 0.2055530619537539]
	TIME [epoch: 84.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12171359146798214		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.12171359146798214 | validation: 0.1714646773824453]
	TIME [epoch: 84.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11861916639004319		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.11861916639004319 | validation: 0.2065784826173639]
	TIME [epoch: 84.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13474582323328543		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.13474582323328543 | validation: 0.18328426116925656]
	TIME [epoch: 84.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1313853463124013		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1313853463124013 | validation: 0.22531259582678767]
	TIME [epoch: 84.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1352665500513463		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.1352665500513463 | validation: 0.19488104938044462]
	TIME [epoch: 84.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13458724999958702		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.13458724999958702 | validation: 0.1934575883509944]
	TIME [epoch: 84.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11915713409461959		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.11915713409461959 | validation: 0.22167271533280816]
	TIME [epoch: 84.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11594584956126633		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.11594584956126633 | validation: 0.17342365552491715]
	TIME [epoch: 84.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11077582711521228		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.11077582711521228 | validation: 0.22865662117053034]
	TIME [epoch: 84.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13774015878833845		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.13774015878833845 | validation: 0.21531952710485724]
	TIME [epoch: 84.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429238375898855		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.10429238375898855 | validation: 0.1969468467038178]
	TIME [epoch: 84.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12055799994065412		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.12055799994065412 | validation: 0.2148949604899949]
	TIME [epoch: 84.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12334018163325693		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.12334018163325693 | validation: 0.19860875743084175]
	TIME [epoch: 84.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11276200444150838		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.11276200444150838 | validation: 0.15319206287770318]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10412877699667544		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.10412877699667544 | validation: 0.21188589684071532]
	TIME [epoch: 84.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12166490920979119		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.12166490920979119 | validation: 0.17994144872815238]
	TIME [epoch: 84.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11900977190393147		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.11900977190393147 | validation: 0.16893058124128751]
	TIME [epoch: 84.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10892791140919851		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.10892791140919851 | validation: 0.15981814904125016]
	TIME [epoch: 84.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10811330302615844		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.10811330302615844 | validation: 0.16311613322264357]
	TIME [epoch: 84.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10197763590317163		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.10197763590317163 | validation: 0.1962646966971651]
	TIME [epoch: 84.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12310794610982523		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.12310794610982523 | validation: 0.2348855165872854]
	TIME [epoch: 84.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11493743782944925		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.11493743782944925 | validation: 0.1694517120414247]
	TIME [epoch: 84.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10091346595256434		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.10091346595256434 | validation: 0.1907258077052534]
	TIME [epoch: 84.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10586441103191206		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.10586441103191206 | validation: 0.29930973500509883]
	TIME [epoch: 84.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11702276879150846		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.11702276879150846 | validation: 0.181806870854612]
	TIME [epoch: 84.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10453113823412359		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.10453113823412359 | validation: 0.18675723441639558]
	TIME [epoch: 84.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10880278729305523		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.10880278729305523 | validation: 0.23281245649024776]
	TIME [epoch: 84.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11744888286104582		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.11744888286104582 | validation: 0.16086585419540583]
	TIME [epoch: 84.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0970174971697424		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.0970174971697424 | validation: 0.16950584868305046]
	TIME [epoch: 84.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09881197313649531		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.09881197313649531 | validation: 0.17882646610619474]
	TIME [epoch: 84.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10934987778433625		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.10934987778433625 | validation: 0.1783463423374409]
	TIME [epoch: 84.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10394209531466067		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.10394209531466067 | validation: 0.16614355711222592]
	TIME [epoch: 84.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19134486135312567		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.19134486135312567 | validation: 0.25829120574489284]
	TIME [epoch: 84.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19105795416195084		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.19105795416195084 | validation: 0.21955718418928738]
	TIME [epoch: 84.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824149239568086		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.15824149239568086 | validation: 0.23195772807577478]
	TIME [epoch: 84.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13556344676077037		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.13556344676077037 | validation: 0.19064913662127894]
	TIME [epoch: 84.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11441924015052693		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.11441924015052693 | validation: 0.20014752085400783]
	TIME [epoch: 84.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13003434053840474		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.13003434053840474 | validation: 0.21246675236976323]
	TIME [epoch: 84.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11177521365007274		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.11177521365007274 | validation: 0.1607983874357738]
	TIME [epoch: 84.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1155193074707253		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.1155193074707253 | validation: 0.15775600525126482]
	TIME [epoch: 84.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11208556187656586		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.11208556187656586 | validation: 0.17279126702826086]
	TIME [epoch: 84.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10965455533399301		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.10965455533399301 | validation: 0.17235678728451015]
	TIME [epoch: 84.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778038269037734		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.09778038269037734 | validation: 0.18396718934570244]
	TIME [epoch: 84.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10835685465378278		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.10835685465378278 | validation: 0.1483047660930782]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09392377571624135		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.09392377571624135 | validation: 0.16100049431089203]
	TIME [epoch: 84.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14249123893211008		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.14249123893211008 | validation: 0.1765251862699922]
	TIME [epoch: 84.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12753195727937486		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.12753195727937486 | validation: 0.22806824973753528]
	TIME [epoch: 84.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17094112603699005		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.17094112603699005 | validation: 0.21024097265357974]
	TIME [epoch: 84.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14757988083517737		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.14757988083517737 | validation: 0.21017104451160912]
	TIME [epoch: 84.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12779955258671513		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.12779955258671513 | validation: 0.1706060016231308]
	TIME [epoch: 84.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11756299539632038		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.11756299539632038 | validation: 0.18673606748756866]
	TIME [epoch: 84.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11452226056464906		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.11452226056464906 | validation: 0.1749035596704291]
	TIME [epoch: 84.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10955700973425457		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.10955700973425457 | validation: 0.16821135551942915]
	TIME [epoch: 84.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10497316042447277		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.10497316042447277 | validation: 0.17250776760297276]
	TIME [epoch: 84.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09601455595238549		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.09601455595238549 | validation: 0.15863468090821983]
	TIME [epoch: 84.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10560294487564079		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.10560294487564079 | validation: 0.18679306530049078]
	TIME [epoch: 84.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11366090750995868		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.11366090750995868 | validation: 0.15652283930865515]
	TIME [epoch: 84.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09681255759758682		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.09681255759758682 | validation: 0.15551087884198328]
	TIME [epoch: 84.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09477046031969531		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.09477046031969531 | validation: 0.1698015901162523]
	TIME [epoch: 84.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10006685011905012		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.10006685011905012 | validation: 0.16696653785921253]
	TIME [epoch: 84.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11551481198973199		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.11551481198973199 | validation: 0.1900317470043266]
	TIME [epoch: 84.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1136960813208133		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1136960813208133 | validation: 0.15029181715617573]
	TIME [epoch: 84.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09956803264607286		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.09956803264607286 | validation: 0.15420522966008357]
	TIME [epoch: 84.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10100409210363656		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.10100409210363656 | validation: 0.16133822615384932]
	TIME [epoch: 84.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10495198956945587		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.10495198956945587 | validation: 0.18567458728343744]
	TIME [epoch: 84.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10754382124403031		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.10754382124403031 | validation: 0.15283472237180337]
	TIME [epoch: 84.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0923056604252166		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.0923056604252166 | validation: 0.16827395298586922]
	TIME [epoch: 84.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09808049423187022		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.09808049423187022 | validation: 0.16993810609431328]
	TIME [epoch: 84.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10234245695028947		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.10234245695028947 | validation: 0.15889611679097854]
	TIME [epoch: 84.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09689303203436665		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.09689303203436665 | validation: 0.1578991288631884]
	TIME [epoch: 84.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10654889470448829		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.10654889470448829 | validation: 0.17047221725807116]
	TIME [epoch: 84.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615983343809263		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.10615983343809263 | validation: 0.14889763874046774]
	TIME [epoch: 84.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10068254921251177		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.10068254921251177 | validation: 0.18396356813078069]
	TIME [epoch: 84.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10104573829310955		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.10104573829310955 | validation: 0.15822470090423274]
	TIME [epoch: 84.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10003300554659059		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.10003300554659059 | validation: 0.1641116475751829]
	TIME [epoch: 84.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10902995511323588		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.10902995511323588 | validation: 0.19100344804886224]
	TIME [epoch: 84.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09710665356265666		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.09710665356265666 | validation: 0.1519138630992708]
	TIME [epoch: 84.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09519787424097761		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.09519787424097761 | validation: 0.16148589595510715]
	TIME [epoch: 84.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11027269602485763		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.11027269602485763 | validation: 0.14897925934690878]
	TIME [epoch: 84.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09821890383465451		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.09821890383465451 | validation: 0.15430001911084087]
	TIME [epoch: 84.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09242294281486804		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.09242294281486804 | validation: 0.15111923850119208]
	TIME [epoch: 84.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09218871586188453		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.09218871586188453 | validation: 0.17287823798528168]
	TIME [epoch: 84.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10604621598378369		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.10604621598378369 | validation: 0.16976041283186216]
	TIME [epoch: 84.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09664777993505476		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.09664777993505476 | validation: 0.19117009185233663]
	TIME [epoch: 84.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181831801269469		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.09181831801269469 | validation: 0.16319005687477223]
	TIME [epoch: 84.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09277916089467986		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.09277916089467986 | validation: 0.16137436110249712]
	TIME [epoch: 84.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09690298381028531		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.09690298381028531 | validation: 0.15291917795440674]
	TIME [epoch: 84.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349599824725095		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.09349599824725095 | validation: 0.1711426822337708]
	TIME [epoch: 84.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0944934793729821		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.0944934793729821 | validation: 0.16112130547390024]
	TIME [epoch: 84.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384004919153646		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.09384004919153646 | validation: 0.16718418159045684]
	TIME [epoch: 84.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467434456690851		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.09467434456690851 | validation: 0.14808743437607003]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0961418905999114		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.0961418905999114 | validation: 0.16775283312239203]
	TIME [epoch: 84.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10543941562595091		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.10543941562595091 | validation: 0.23326754584036458]
	TIME [epoch: 84.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11925576968733935		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.11925576968733935 | validation: 0.16627802447816958]
	TIME [epoch: 84.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09327879325980658		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.09327879325980658 | validation: 0.1605525145856287]
	TIME [epoch: 84.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09115657508844939		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.09115657508844939 | validation: 0.15895904036261238]
	TIME [epoch: 84.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09318503430699088		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.09318503430699088 | validation: 0.16279739543652666]
	TIME [epoch: 84.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09519456819972827		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.09519456819972827 | validation: 0.14692444302816016]
	TIME [epoch: 84.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10142199917826966		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.10142199917826966 | validation: 0.16774292606470045]
	TIME [epoch: 84.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09326680088624095		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.09326680088624095 | validation: 0.16503303759912935]
	TIME [epoch: 84.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09189282444498086		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.09189282444498086 | validation: 0.14923900877688315]
	TIME [epoch: 84.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10603358455387861		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.10603358455387861 | validation: 0.15217496708197875]
	TIME [epoch: 84.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0918511530330384		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.0918511530330384 | validation: 0.1452754231162087]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09550580706605201		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.09550580706605201 | validation: 0.15513139973307177]
	TIME [epoch: 84.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09488835759217384		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.09488835759217384 | validation: 0.14422077252594254]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09606943724218875		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.09606943724218875 | validation: 0.15426968988770678]
	TIME [epoch: 84.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09786195490385208		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.09786195490385208 | validation: 0.19337319009843545]
	TIME [epoch: 84.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09789169148772639		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.09789169148772639 | validation: 0.15122345043300872]
	TIME [epoch: 84.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09552674949341118		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.09552674949341118 | validation: 0.17855907251618308]
	TIME [epoch: 84.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09013863600148195		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.09013863600148195 | validation: 0.1463648888979898]
	TIME [epoch: 84.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09773242543003277		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.09773242543003277 | validation: 0.14716823629886205]
	TIME [epoch: 84.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192732843500093		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.09192732843500093 | validation: 0.1496028767338595]
	TIME [epoch: 84.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09610404334461106		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09610404334461106 | validation: 0.1520891341526766]
	TIME [epoch: 84.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08758483713903895		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.08758483713903895 | validation: 0.14886196623342715]
	TIME [epoch: 84.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09101130682323735		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.09101130682323735 | validation: 0.16915324063024545]
	TIME [epoch: 84.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09291279544104605		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.09291279544104605 | validation: 0.14920066138775534]
	TIME [epoch: 84.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09476648587947084		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.09476648587947084 | validation: 0.15847167493261283]
	TIME [epoch: 84.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384205243653057		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.09384205243653057 | validation: 0.18702431810101122]
	TIME [epoch: 84.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09229953352295574		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.09229953352295574 | validation: 0.1765051969566535]
	TIME [epoch: 84.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09102559705727967		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.09102559705727967 | validation: 0.149017777822093]
	TIME [epoch: 84.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0872953682861913		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.0872953682861913 | validation: 0.152962796335824]
	TIME [epoch: 84.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08972283571833609		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.08972283571833609 | validation: 0.1642749549660986]
	TIME [epoch: 84.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08796485181827934		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.08796485181827934 | validation: 0.16424872451810674]
	TIME [epoch: 84.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08790715588469941		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.08790715588469941 | validation: 0.15021780324168804]
	TIME [epoch: 84.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0886034891312679		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.0886034891312679 | validation: 0.14704738780336862]
	TIME [epoch: 84.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901252570409342		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.0901252570409342 | validation: 0.16309095535473878]
	TIME [epoch: 84.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0892971598104784		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.0892971598104784 | validation: 0.1715083304088375]
	TIME [epoch: 84.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09466988783781125		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.09466988783781125 | validation: 0.16530956167962807]
	TIME [epoch: 84.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0893845865575585		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.0893845865575585 | validation: 0.14701179064530473]
	TIME [epoch: 84.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08861840675115742		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.08861840675115742 | validation: 0.15956916868178161]
	TIME [epoch: 84.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09295021807704353		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09295021807704353 | validation: 0.14974283504565825]
	TIME [epoch: 84.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09041742305545512		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.09041742305545512 | validation: 0.16745496665243254]
	TIME [epoch: 84.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08775480614643723		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.08775480614643723 | validation: 0.14305570532654133]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08964444381062217		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.08964444381062217 | validation: 0.15050773816165372]
	TIME [epoch: 84.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08677125258208318		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.08677125258208318 | validation: 0.16250829347380813]
	TIME [epoch: 84.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728688878372688		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.08728688878372688 | validation: 0.163601083304653]
	TIME [epoch: 84.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09718543741649303		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.09718543741649303 | validation: 0.1458764194786728]
	TIME [epoch: 84.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08959942423968537		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.08959942423968537 | validation: 0.14465266480342873]
	TIME [epoch: 84.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08741984371301337		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.08741984371301337 | validation: 0.1743841459860399]
	TIME [epoch: 84.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08594441998696795		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.08594441998696795 | validation: 0.1454214269364936]
	TIME [epoch: 84.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10387205517333428		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10387205517333428 | validation: 0.15835007870733958]
	TIME [epoch: 84.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09216048137986604		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.09216048137986604 | validation: 0.17374275067971096]
	TIME [epoch: 84.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09011663373968606		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.09011663373968606 | validation: 0.15320754429092143]
	TIME [epoch: 84.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08811923772766446		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.08811923772766446 | validation: 0.1632327473289364]
	TIME [epoch: 84.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08837252732139576		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.08837252732139576 | validation: 0.15635615001343975]
	TIME [epoch: 84.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901412565542977		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.0901412565542977 | validation: 0.15105792591027484]
	TIME [epoch: 84.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08575207335341832		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.08575207335341832 | validation: 0.15812499738789335]
	TIME [epoch: 84.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793339997299261		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.08793339997299261 | validation: 0.14470786334292293]
	TIME [epoch: 84.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09003032931845407		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.09003032931845407 | validation: 0.15699430947308574]
	TIME [epoch: 84.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08933117504576782		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.08933117504576782 | validation: 0.1556902909768073]
	TIME [epoch: 84.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402810473955322		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.08402810473955322 | validation: 0.15088632915242464]
	TIME [epoch: 84.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568786417847565		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.08568786417847565 | validation: 0.15012170388914492]
	TIME [epoch: 84.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08803614392485906		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.08803614392485906 | validation: 0.14711235990446248]
	TIME [epoch: 84.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656152865800561		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.08656152865800561 | validation: 0.147803017597843]
	TIME [epoch: 84.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728771114881374		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.08728771114881374 | validation: 0.14690402399922345]
	TIME [epoch: 84.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475148933393575		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.08475148933393575 | validation: 0.14414045481251536]
	TIME [epoch: 84.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08527954386392138		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.08527954386392138 | validation: 0.1677665100920311]
	TIME [epoch: 84.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559182908374903		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.08559182908374903 | validation: 0.16231018700138083]
	TIME [epoch: 84.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08631907151133406		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.08631907151133406 | validation: 0.1555828680205222]
	TIME [epoch: 84.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0850585879266081		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.0850585879266081 | validation: 0.1501802557652729]
	TIME [epoch: 84.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666634605774155		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.08666634605774155 | validation: 0.18105617706966048]
	TIME [epoch: 84.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08982045035638464		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.08982045035638464 | validation: 0.1528966918810542]
	TIME [epoch: 84.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08699954397037155		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.08699954397037155 | validation: 0.16560621440039747]
	TIME [epoch: 84.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888204667074359		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.08888204667074359 | validation: 0.1649157760301499]
	TIME [epoch: 84.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08763655007554716		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.08763655007554716 | validation: 0.14822605792803714]
	TIME [epoch: 84.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08537262560742034		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.08537262560742034 | validation: 0.15118913138391704]
	TIME [epoch: 84.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08638119073653684		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.08638119073653684 | validation: 0.1553823504422211]
	TIME [epoch: 84.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08678671878447201		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.08678671878447201 | validation: 0.15192480107682282]
	TIME [epoch: 84.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08411892005142038		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.08411892005142038 | validation: 0.14752685989734932]
	TIME [epoch: 84.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08580471884115892		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.08580471884115892 | validation: 0.15950357774245547]
	TIME [epoch: 84.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666594093109295		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.08666594093109295 | validation: 0.15625889680746044]
	TIME [epoch: 84.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592420203532442		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.08592420203532442 | validation: 0.14839670638861832]
	TIME [epoch: 84.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08864785346469864		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.08864785346469864 | validation: 0.16008335885839528]
	TIME [epoch: 84.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0892224721498552		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.0892224721498552 | validation: 0.16795670212458738]
	TIME [epoch: 84.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851106945014596		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.0851106945014596 | validation: 0.16060887726779413]
	TIME [epoch: 84.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08296218868209101		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.08296218868209101 | validation: 0.1708011210879004]
	TIME [epoch: 84.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0832057552610687		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.0832057552610687 | validation: 0.15868584820659568]
	TIME [epoch: 84.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08661475044634862		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.08661475044634862 | validation: 0.14327185769514997]
	TIME [epoch: 84.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08302799017237492		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.08302799017237492 | validation: 0.14238684381522268]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08617071144948338		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.08617071144948338 | validation: 0.15590156091789217]
	TIME [epoch: 84.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08669554389384923		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.08669554389384923 | validation: 0.14288857940025668]
	TIME [epoch: 84.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08157445714861808		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.08157445714861808 | validation: 0.15413055346861848]
	TIME [epoch: 84.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347347653263323		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.08347347653263323 | validation: 0.14902249254298439]
	TIME [epoch: 84.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08539538172421512		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.08539538172421512 | validation: 0.15811075672404107]
	TIME [epoch: 84.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08971346761217133		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.08971346761217133 | validation: 0.13898088599067462]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271505309403639		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.08271505309403639 | validation: 0.1471475235173595]
	TIME [epoch: 84.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08419218374602834		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.08419218374602834 | validation: 0.15400505781340432]
	TIME [epoch: 84.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779798220068219		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.08779798220068219 | validation: 0.14501056416818223]
	TIME [epoch: 84.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08647660440917151		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08647660440917151 | validation: 0.1573086022526137]
	TIME [epoch: 84.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730562277370782		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.08730562277370782 | validation: 0.16567629260501726]
	TIME [epoch: 84.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08520444056453584		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.08520444056453584 | validation: 0.15493426595458987]
	TIME [epoch: 84.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0868979190167303		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.0868979190167303 | validation: 0.14450291902578855]
	TIME [epoch: 84.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08288062098782627		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.08288062098782627 | validation: 0.1479713648709194]
	TIME [epoch: 84.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279205714316913		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.08279205714316913 | validation: 0.14171505994577185]
	TIME [epoch: 84.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08415050345589356		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.08415050345589356 | validation: 0.14501323392805254]
	TIME [epoch: 84.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08679200762192987		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.08679200762192987 | validation: 0.15806360252496301]
	TIME [epoch: 84.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08602843645650403		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.08602843645650403 | validation: 0.17208289634116397]
	TIME [epoch: 84.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900331484591567		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.08900331484591567 | validation: 0.13950893545073859]
	TIME [epoch: 84.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08380471735540004		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.08380471735540004 | validation: 0.14526649586182425]
	TIME [epoch: 84.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828388243992065		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.0828388243992065 | validation: 0.16164867586233564]
	TIME [epoch: 84.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08532114574905829		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.08532114574905829 | validation: 0.15110478572359973]
	TIME [epoch: 84.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858887221335661		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.0858887221335661 | validation: 0.16006711558033368]
	TIME [epoch: 84.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623275032477973		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.08623275032477973 | validation: 0.15003031825023153]
	TIME [epoch: 84.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776096822083722		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.08776096822083722 | validation: 0.16017023604345867]
	TIME [epoch: 84.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592453335658949		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.08592453335658949 | validation: 0.14951521564571224]
	TIME [epoch: 84.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08364316801305542		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.08364316801305542 | validation: 0.14300115755400183]
	TIME [epoch: 84.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08436270987711916		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.08436270987711916 | validation: 0.13873115507061468]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811475563439161		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.0811475563439161 | validation: 0.14639235584818575]
	TIME [epoch: 84.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08382146652081698		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.08382146652081698 | validation: 0.14730216325691428]
	TIME [epoch: 84.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08338740820491439		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.08338740820491439 | validation: 0.1550936819093163]
	TIME [epoch: 84.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453116500830868		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.08453116500830868 | validation: 0.14183565783742738]
	TIME [epoch: 84.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08211997259238532		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.08211997259238532 | validation: 0.14428572073807666]
	TIME [epoch: 84.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08435549543152294		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.08435549543152294 | validation: 0.15089692918264397]
	TIME [epoch: 84.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08236634144289663		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.08236634144289663 | validation: 0.15835873581500598]
	TIME [epoch: 84.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360576918734969		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.08360576918734969 | validation: 0.1595101693404952]
	TIME [epoch: 84.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08335094575199968		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.08335094575199968 | validation: 0.14187201035554933]
	TIME [epoch: 84.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08072330908913003		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.08072330908913003 | validation: 0.14868358377649002]
	TIME [epoch: 84.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08960131632315887		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.08960131632315887 | validation: 0.1432225284740707]
	TIME [epoch: 84.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08383505643473693		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.08383505643473693 | validation: 0.14672487960708858]
	TIME [epoch: 84.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08148089058584693		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.08148089058584693 | validation: 0.1423369046866132]
	TIME [epoch: 84.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08596571539827212		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.08596571539827212 | validation: 0.14723194769023543]
	TIME [epoch: 84.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812879308348618		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.0812879308348618 | validation: 0.14674311642303078]
	TIME [epoch: 84.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08137211779588263		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.08137211779588263 | validation: 0.14904945285826543]
	TIME [epoch: 84.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286393457432265		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.08286393457432265 | validation: 0.1498348836375212]
	TIME [epoch: 84.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08218915803824015		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.08218915803824015 | validation: 0.1505813203954999]
	TIME [epoch: 84.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08380515006321858		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.08380515006321858 | validation: 0.1654224523146918]
	TIME [epoch: 84.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08514733020640883		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.08514733020640883 | validation: 0.14458497192700406]
	TIME [epoch: 84.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08406402421039302		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.08406402421039302 | validation: 0.1401250697122176]
	TIME [epoch: 84.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08296198562104123		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.08296198562104123 | validation: 0.13739676388276376]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08081809303856283		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.08081809303856283 | validation: 0.14549015973257776]
	TIME [epoch: 84.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08007863528337163		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.08007863528337163 | validation: 0.1493028683384653]
	TIME [epoch: 84.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08449213397119579		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.08449213397119579 | validation: 0.14148166047638056]
	TIME [epoch: 84.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08204859732680654		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08204859732680654 | validation: 0.13876990890182198]
	TIME [epoch: 84.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08231743887421372		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.08231743887421372 | validation: 0.13669323511428594]
	TIME [epoch: 84.3 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453436151234903		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.08453436151234903 | validation: 0.1384279275363171]
	TIME [epoch: 84.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08463769524431627		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.08463769524431627 | validation: 0.15313278519951162]
	TIME [epoch: 84.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08319504277186332		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.08319504277186332 | validation: 0.1446647652389278]
	TIME [epoch: 84.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07968496585726804		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.07968496585726804 | validation: 0.1501746257675523]
	TIME [epoch: 84.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08122062303957168		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.08122062303957168 | validation: 0.15663078143956513]
	TIME [epoch: 84.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08337826323107243		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.08337826323107243 | validation: 0.13959332483660827]
	TIME [epoch: 84.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08203629554482214		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.08203629554482214 | validation: 0.14433149811344684]
	TIME [epoch: 84.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08223131222137368		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.08223131222137368 | validation: 0.14722686744241148]
	TIME [epoch: 84.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169887049792995		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.08169887049792995 | validation: 0.14286231986685163]
	TIME [epoch: 84.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08560723960223555		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.08560723960223555 | validation: 0.14283826739921807]
	TIME [epoch: 84.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08306995465071214		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08306995465071214 | validation: 0.14818157429192827]
	TIME [epoch: 84.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08088177884487553		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.08088177884487553 | validation: 0.1446391816809339]
	TIME [epoch: 84.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08236824342623675		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.08236824342623675 | validation: 0.14478248544810127]
	TIME [epoch: 84.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08176232933507747		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.08176232933507747 | validation: 0.14678639249507844]
	TIME [epoch: 84.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08043350037575893		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.08043350037575893 | validation: 0.14918700245158478]
	TIME [epoch: 84.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08311126394392303		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08311126394392303 | validation: 0.16371026525084337]
	TIME [epoch: 84.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08119823659947645		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.08119823659947645 | validation: 0.14265175203530722]
	TIME [epoch: 84.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169618257644065		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.08169618257644065 | validation: 0.14516458032100873]
	TIME [epoch: 84.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08190586114407923		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.08190586114407923 | validation: 0.1543365281565029]
	TIME [epoch: 84.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828865856724997		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.0828865856724997 | validation: 0.14492846938500747]
	TIME [epoch: 84.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826146715195574		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.0826146715195574 | validation: 0.15373762170720223]
	TIME [epoch: 84.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08168049924327092		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.08168049924327092 | validation: 0.14852561799880695]
	TIME [epoch: 84.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340900433742415		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08340900433742415 | validation: 0.15309589832436746]
	TIME [epoch: 84.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08151916791051005		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.08151916791051005 | validation: 0.14189125271055503]
	TIME [epoch: 84.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08221290565799402		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.08221290565799402 | validation: 0.1510737846470512]
	TIME [epoch: 84.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08162813459184498		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.08162813459184498 | validation: 0.14964187667319293]
	TIME [epoch: 84.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08071217549182716		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.08071217549182716 | validation: 0.15132040372426242]
	TIME [epoch: 84.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811942098067446		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.0811942098067446 | validation: 0.14619971581376542]
	TIME [epoch: 84.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08184355528342976		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.08184355528342976 | validation: 0.16114881864974234]
	TIME [epoch: 84.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08220615194449252		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08220615194449252 | validation: 0.15171096401311407]
	TIME [epoch: 84.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08417351640541662		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08417351640541662 | validation: 0.14366723486580066]
	TIME [epoch: 84.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08246134978487538		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.08246134978487538 | validation: 0.1532943880950311]
	TIME [epoch: 84.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08320820487826827		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08320820487826827 | validation: 0.15688571927230754]
	TIME [epoch: 84.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08409131321190248		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.08409131321190248 | validation: 0.1468172744986857]
	TIME [epoch: 84.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08199366142230917		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08199366142230917 | validation: 0.14420808564495752]
	TIME [epoch: 84.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08220344952512251		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.08220344952512251 | validation: 0.14109749761792562]
	TIME [epoch: 84.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08232161981013417		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.08232161981013417 | validation: 0.1447634848702174]
	TIME [epoch: 84.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08144251127629853		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.08144251127629853 | validation: 0.15275401692671164]
	TIME [epoch: 84.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07982723581991015		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.07982723581991015 | validation: 0.14412356389695735]
	TIME [epoch: 84.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08156882343997712		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.08156882343997712 | validation: 0.14811727683458928]
	TIME [epoch: 84.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0869142293599929		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.0869142293599929 | validation: 0.1452215043267344]
	TIME [epoch: 84.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08535492699139735		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.08535492699139735 | validation: 0.1427404264398168]
	TIME [epoch: 84.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08237329543985149		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08237329543985149 | validation: 0.1517066703054412]
	TIME [epoch: 84.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08289545186596894		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08289545186596894 | validation: 0.15437760006931198]
	TIME [epoch: 84.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08001583104491072		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.08001583104491072 | validation: 0.16048134561575556]
	TIME [epoch: 84.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08146070571441487		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.08146070571441487 | validation: 0.14178395078020906]
	TIME [epoch: 84.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08257802830468189		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08257802830468189 | validation: 0.14644694071516037]
	TIME [epoch: 84.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08120733646963242		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.08120733646963242 | validation: 0.1464069053176521]
	TIME [epoch: 84.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08131915234515166		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.08131915234515166 | validation: 0.17543193868643722]
	TIME [epoch: 84.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08324617099759438		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.08324617099759438 | validation: 0.14703102453192005]
	TIME [epoch: 84.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07976530254423221		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.07976530254423221 | validation: 0.14964357900408154]
	TIME [epoch: 84.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08187565782474451		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.08187565782474451 | validation: 0.1469127589836417]
	TIME [epoch: 84.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08133597854435647		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.08133597854435647 | validation: 0.1460714224295259]
	TIME [epoch: 84.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0840068548976485		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.0840068548976485 | validation: 0.14714299455176658]
	TIME [epoch: 84.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08225067899128478		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08225067899128478 | validation: 0.1415777411952843]
	TIME [epoch: 84.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07979843987404803		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.07979843987404803 | validation: 0.14676664344929133]
	TIME [epoch: 84.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863784560182879		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.0863784560182879 | validation: 0.15291303248322824]
	TIME [epoch: 84.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08128809031715303		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.08128809031715303 | validation: 0.15116164374619775]
	TIME [epoch: 84.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07919086650615877		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.07919086650615877 | validation: 0.1520680591501892]
	TIME [epoch: 84.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08309888487672276		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.08309888487672276 | validation: 0.14459594648062282]
	TIME [epoch: 84.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08065286007256331		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.08065286007256331 | validation: 0.1530764939258001]
	TIME [epoch: 84.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07936459415973877		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.07936459415973877 | validation: 0.14991133721385036]
	TIME [epoch: 84.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08000590350847095		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08000590350847095 | validation: 0.15316541742936546]
	TIME [epoch: 84.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08215188736718183		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.08215188736718183 | validation: 0.14530882394081046]
	TIME [epoch: 84.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08148925763689888		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08148925763689888 | validation: 0.15688466515554123]
	TIME [epoch: 84.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08262469909168368		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.08262469909168368 | validation: 0.15440627773950266]
	TIME [epoch: 84.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813145977159316		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.0813145977159316 | validation: 0.1518215217655106]
	TIME [epoch: 84.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969922405538797		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.07969922405538797 | validation: 0.15312904996842808]
	TIME [epoch: 84.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08163495402489936		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08163495402489936 | validation: 0.1671144199073354]
	TIME [epoch: 84.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08359374677046144		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.08359374677046144 | validation: 0.14413062038313693]
	TIME [epoch: 84.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0799686884709519		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.0799686884709519 | validation: 0.14754439183545195]
	TIME [epoch: 84.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08059909892903587		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.08059909892903587 | validation: 0.14579097795384752]
	TIME [epoch: 84.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08045808023307374		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.08045808023307374 | validation: 0.14837874395009487]
	TIME [epoch: 84.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08068154572556177		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08068154572556177 | validation: 0.14830786464693443]
	TIME [epoch: 84.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08233062428614676		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08233062428614676 | validation: 0.14834670988265106]
	TIME [epoch: 84.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08338712090661438		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08338712090661438 | validation: 0.1534038563928277]
	TIME [epoch: 84.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08202124576707805		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.08202124576707805 | validation: 0.14947535742956122]
	TIME [epoch: 84.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08139652368099422		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.08139652368099422 | validation: 0.1462821578277541]
	TIME [epoch: 84.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08150076170315326		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08150076170315326 | validation: 0.14498331088301697]
	TIME [epoch: 84.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08130469887316333		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.08130469887316333 | validation: 0.1441510426462172]
	TIME [epoch: 84.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07738675420008254		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.07738675420008254 | validation: 0.14851484352394634]
	TIME [epoch: 84.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07924026528262382		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.07924026528262382 | validation: 0.15305128698617743]
	TIME [epoch: 84.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.081749501653266		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.081749501653266 | validation: 0.14763031816991695]
	TIME [epoch: 84.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0817962425729086		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.0817962425729086 | validation: 0.14470540902148904]
	TIME [epoch: 84.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07800177824194571		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.07800177824194571 | validation: 0.14234159114844394]
	TIME [epoch: 84.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08105657890650471		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08105657890650471 | validation: 0.14551300588929952]
	TIME [epoch: 84.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08104701467311852		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08104701467311852 | validation: 0.1545017232146503]
	TIME [epoch: 84.4 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07997283134072128		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.07997283134072128 | validation: 0.14895138249068451]
	TIME [epoch: 84.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08239691710554427		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.08239691710554427 | validation: 0.15141531707708678]
	TIME [epoch: 84.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08070324234462226		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08070324234462226 | validation: 0.14379653589191824]
	TIME [epoch: 84.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08087265271296287		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08087265271296287 | validation: 0.15690866241039308]
	TIME [epoch: 84.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08109583683711467		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08109583683711467 | validation: 0.15960039571489923]
	TIME [epoch: 84.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08073897091354486		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08073897091354486 | validation: 0.1549845998263769]
	TIME [epoch: 84.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08163972139974328		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08163972139974328 | validation: 0.14702813858420302]
	TIME [epoch: 84.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0797634167400305		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.0797634167400305 | validation: 0.14902361186988336]
	TIME [epoch: 84.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08048731005253704		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.08048731005253704 | validation: 0.1505610371201158]
	TIME [epoch: 84.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08229242213440188		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08229242213440188 | validation: 0.14648813020337362]
	TIME [epoch: 84.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08179805924724262		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.08179805924724262 | validation: 0.14223047351573276]
	TIME [epoch: 84.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07981775102660094		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.07981775102660094 | validation: 0.14534808074003647]
	TIME [epoch: 84.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07975491236875401		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.07975491236875401 | validation: 0.14340063989747664]
	TIME [epoch: 84.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08369486832750031		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.08369486832750031 | validation: 0.14378340550360888]
	TIME [epoch: 84.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08132280218780666		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08132280218780666 | validation: 0.14453225741293996]
	TIME [epoch: 84.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08116139560923961		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08116139560923961 | validation: 0.14653535654856029]
	TIME [epoch: 84.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08033184002602264		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08033184002602264 | validation: 0.14341346785753575]
	TIME [epoch: 84.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08095023990883159		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08095023990883159 | validation: 0.15367411648245283]
	TIME [epoch: 84.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0809989603679048		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.0809989603679048 | validation: 0.1475448694098497]
	TIME [epoch: 84.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08201196118243731		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.08201196118243731 | validation: 0.14549091384954616]
	TIME [epoch: 84.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07967320687534182		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.07967320687534182 | validation: 0.14369323504585793]
	TIME [epoch: 84.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08085031113330438		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08085031113330438 | validation: 0.14397180399017723]
	TIME [epoch: 84.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08207617981847928		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08207617981847928 | validation: 0.15776099395719556]
	TIME [epoch: 84.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08041300065236709		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.08041300065236709 | validation: 0.14843697711793358]
	TIME [epoch: 84.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820425115703629		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.07820425115703629 | validation: 0.1438435459296111]
	TIME [epoch: 84.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0795703637921191		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.0795703637921191 | validation: 0.13912934828199935]
	TIME [epoch: 84.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08123026449558382		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08123026449558382 | validation: 0.15277486450812144]
	TIME [epoch: 84.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08159643701796793		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08159643701796793 | validation: 0.1444772107037047]
	TIME [epoch: 84.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08200113763634913		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.08200113763634913 | validation: 0.14966592097371553]
	TIME [epoch: 84.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07988259380317453		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.07988259380317453 | validation: 0.1487513085038387]
	TIME [epoch: 84.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07891512529396942		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.07891512529396942 | validation: 0.145297194487459]
	TIME [epoch: 84.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969717689074918		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.07969717689074918 | validation: 0.13812075685403283]
	TIME [epoch: 84.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0789993330153456		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.0789993330153456 | validation: 0.1432713395611629]
	TIME [epoch: 84.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08135589549697267		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.08135589549697267 | validation: 0.14269471713870427]
	TIME [epoch: 84.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07906966489803736		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.07906966489803736 | validation: 0.14582480809907872]
	TIME [epoch: 84.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08125443054680895		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08125443054680895 | validation: 0.14040720080915442]
	TIME [epoch: 84.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07988920558731259		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.07988920558731259 | validation: 0.14771485125740538]
	TIME [epoch: 84.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07971290694202612		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.07971290694202612 | validation: 0.14732630775558414]
	TIME [epoch: 84.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07913389291746238		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.07913389291746238 | validation: 0.14469532287434694]
	TIME [epoch: 84.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901377387066891		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.07901377387066891 | validation: 0.1408024473004207]
	TIME [epoch: 84.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08014293276034978		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.08014293276034978 | validation: 0.14840050737699048]
	TIME [epoch: 84.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08019003303834074		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.08019003303834074 | validation: 0.1458207308694345]
	TIME [epoch: 84.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07836026738534137		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.07836026738534137 | validation: 0.1409340118258692]
	TIME [epoch: 84.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07952966341631977		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.07952966341631977 | validation: 0.14363387265409863]
	TIME [epoch: 84.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07883200184935445		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.07883200184935445 | validation: 0.14701671702328223]
	TIME [epoch: 84.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796893480743511		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.0796893480743511 | validation: 0.1555891157644808]
	TIME [epoch: 84.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08022533867696616		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.08022533867696616 | validation: 0.15331889574452126]
	TIME [epoch: 84.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07954815138720049		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.07954815138720049 | validation: 0.15074313510703471]
	TIME [epoch: 84.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07902029638979814		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.07902029638979814 | validation: 0.14150731949366852]
	TIME [epoch: 84.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07823571760861303		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.07823571760861303 | validation: 0.1411716912255471]
	TIME [epoch: 84.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08086138665600234		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.08086138665600234 | validation: 0.14500431682246342]
	TIME [epoch: 84.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07921605804353601		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.07921605804353601 | validation: 0.14161785666414783]
	TIME [epoch: 84.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07917280455474202		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.07917280455474202 | validation: 0.14509583920526103]
	TIME [epoch: 84.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08030239946633004		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.08030239946633004 | validation: 0.14510700836368737]
	TIME [epoch: 84.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08106887287603974		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08106887287603974 | validation: 0.14995868689928013]
	TIME [epoch: 84.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969162923389675		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.07969162923389675 | validation: 0.14305122158751943]
	TIME [epoch: 84.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07853126952088424		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.07853126952088424 | validation: 0.1522337705597977]
	TIME [epoch: 84.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07848012023817394		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.07848012023817394 | validation: 0.14668301498162012]
	TIME [epoch: 84.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07833730589626108		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.07833730589626108 | validation: 0.14468478573263877]
	TIME [epoch: 84.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07941522373197968		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07941522373197968 | validation: 0.14622923924322756]
	TIME [epoch: 84.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964746305729528		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.07964746305729528 | validation: 0.14491227650830368]
	TIME [epoch: 84.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07957247383375132		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.07957247383375132 | validation: 0.1508835687814695]
	TIME [epoch: 84.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07813795638665003		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.07813795638665003 | validation: 0.14761596833358312]
	TIME [epoch: 84.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07960595425643996		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.07960595425643996 | validation: 0.14367029624442312]
	TIME [epoch: 84.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0791092439236066		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.0791092439236066 | validation: 0.1510815513098256]
	TIME [epoch: 84.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0775698736115057		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.0775698736115057 | validation: 0.14461141112422835]
	TIME [epoch: 84.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813458300125565		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.0813458300125565 | validation: 0.14371646641660152]
	TIME [epoch: 84.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792883883130113		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0792883883130113 | validation: 0.14093014740210086]
	TIME [epoch: 84.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08024721347120604		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.08024721347120604 | validation: 0.13900528883790378]
	TIME [epoch: 84.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07902833936771472		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.07902833936771472 | validation: 0.14586657333236094]
	TIME [epoch: 84.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07873881971090087		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.07873881971090087 | validation: 0.14881714145096167]
	TIME [epoch: 84.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07784330890245583		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.07784330890245583 | validation: 0.1450950092942657]
	TIME [epoch: 84.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0779558147103713		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.0779558147103713 | validation: 0.14259835641815086]
	TIME [epoch: 84.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796499867971908		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.0796499867971908 | validation: 0.14935362590915535]
	TIME [epoch: 84.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08059181815178093		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.08059181815178093 | validation: 0.14942987634413965]
	TIME [epoch: 84.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07920031491486992		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.07920031491486992 | validation: 0.1455940928269861]
	TIME [epoch: 84.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796995323826062		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.0796995323826062 | validation: 0.1443298742319034]
	TIME [epoch: 84.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07860450312743542		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.07860450312743542 | validation: 0.1414729866182766]
	TIME [epoch: 84.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07903920511284765		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.07903920511284765 | validation: 0.14829702723445026]
	TIME [epoch: 84.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964753531581033		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.07964753531581033 | validation: 0.1431022018765258]
	TIME [epoch: 84.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08096739970622609		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08096739970622609 | validation: 0.14055800502014948]
	TIME [epoch: 84.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07956649283794745		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.07956649283794745 | validation: 0.14262308671334376]
	TIME [epoch: 84.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07866231876705318		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.07866231876705318 | validation: 0.14928893118265865]
	TIME [epoch: 84.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07950878004862573		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.07950878004862573 | validation: 0.15123970220512983]
	TIME [epoch: 84.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07852847498610036		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.07852847498610036 | validation: 0.14530066571796393]
	TIME [epoch: 84.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07934761363612305		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.07934761363612305 | validation: 0.14895165256654794]
	TIME [epoch: 84.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07795517248449481		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.07795517248449481 | validation: 0.14597878019716565]
	TIME [epoch: 84.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0786082266067051		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0786082266067051 | validation: 0.14563701862375258]
	TIME [epoch: 84.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08013854539565482		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.08013854539565482 | validation: 0.1511339451086167]
	TIME [epoch: 84.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08028915301781994		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.08028915301781994 | validation: 0.14501520882820645]
	TIME [epoch: 84.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820508361136606		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.07820508361136606 | validation: 0.14337856089737389]
	TIME [epoch: 84.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0797341858168101		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0797341858168101 | validation: 0.14636234746656723]
	TIME [epoch: 84.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07809063288688664		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.07809063288688664 | validation: 0.14332674931872993]
	TIME [epoch: 84.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08001705390310695		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08001705390310695 | validation: 0.14830407160217607]
	TIME [epoch: 84.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07910732386584222		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.07910732386584222 | validation: 0.14326376132142862]
	TIME [epoch: 84.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08024234100306303		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08024234100306303 | validation: 0.1482607628592325]
	TIME [epoch: 84.4 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07959690862634672		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.07959690862634672 | validation: 0.1460941023247834]
	TIME [epoch: 84.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07971292986588158		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.07971292986588158 | validation: 0.1494168563289668]
	TIME [epoch: 84.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07843010114568391		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.07843010114568391 | validation: 0.14055605547885425]
	TIME [epoch: 84.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0782976461967309		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0782976461967309 | validation: 0.14173889011691165]
	TIME [epoch: 84.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08047586794160691		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08047586794160691 | validation: 0.1525295282814251]
	TIME [epoch: 84.4 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07994357783315323		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.07994357783315323 | validation: 0.1466994197825714]
	TIME [epoch: 84.4 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07834170466872792		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.07834170466872792 | validation: 0.14581493150130123]
	TIME [epoch: 84.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07850696517633507		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.07850696517633507 | validation: 0.1438807591178448]
	TIME [epoch: 84.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07773061488484412		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.07773061488484412 | validation: 0.14826937305363094]
	TIME [epoch: 84.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08016707097880602		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.08016707097880602 | validation: 0.14701975739815668]
	TIME [epoch: 84.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07763881197088955		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.07763881197088955 | validation: 0.15007863376199232]
	TIME [epoch: 84.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08003333309334539		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08003333309334539 | validation: 0.1428618631704803]
	TIME [epoch: 84.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07918718588600152		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.07918718588600152 | validation: 0.1471057310205848]
	TIME [epoch: 84.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07937877259633379		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.07937877259633379 | validation: 0.14278883016336386]
	TIME [epoch: 84.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07934525355393077		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.07934525355393077 | validation: 0.1458451170831168]
	TIME [epoch: 84.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07847352455745671		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.07847352455745671 | validation: 0.14648550501320137]
	TIME [epoch: 84.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07913679084061083		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.07913679084061083 | validation: 0.1480369113242461]
	TIME [epoch: 84.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07840051925655278		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.07840051925655278 | validation: 0.14755724909710508]
	TIME [epoch: 84.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v2_20240627_193216/states/model_facs_dec2b_2dpca_v2_502.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 42404.856 seconds.
