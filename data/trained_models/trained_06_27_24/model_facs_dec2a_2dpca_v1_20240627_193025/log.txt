Args:
Namespace(name='model_facs_dec2a_2dpca_v1', outdir='out/model_training/model_facs_dec2a_2dpca_v1', training_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 779998251

Training model...

Saving initial model state to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4653746192372957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4653746192372957 | validation: 0.3757511721243715]
	TIME [epoch: 61.6 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2810411230413524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2810411230413524 | validation: 0.34852908674087096]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24420937979442012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24420937979442012 | validation: 0.3589237524741566]
	TIME [epoch: 36.6 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24274219138401162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24274219138401162 | validation: 0.3469746878227555]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2370742500963917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2370742500963917 | validation: 0.3613164980549706]
	TIME [epoch: 36.5 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22920716891765824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22920716891765824 | validation: 0.31430648338152173]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22787510235201108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22787510235201108 | validation: 0.30755198259849903]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20957893292390928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20957893292390928 | validation: 0.2910126732898117]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23537575182807494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23537575182807494 | validation: 0.3765901215605488]
	TIME [epoch: 36.4 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22288981056737045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22288981056737045 | validation: 0.29538379157910966]
	TIME [epoch: 36.4 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18975662729859433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18975662729859433 | validation: 0.2914992741874524]
	TIME [epoch: 36.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18521844596731904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18521844596731904 | validation: 0.28514536363945014]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18672163051754864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18672163051754864 | validation: 0.2681274593268094]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17367985625471985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17367985625471985 | validation: 0.2484289386323023]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17717611917888762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17717611917888762 | validation: 0.2551859452945644]
	TIME [epoch: 36.4 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1662187957287035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1662187957287035 | validation: 0.24639762377156113]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15464750617517956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15464750617517956 | validation: 0.2425012332299068]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17369650977733403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17369650977733403 | validation: 0.2541023765822511]
	TIME [epoch: 36.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602162657709377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1602162657709377 | validation: 0.24127633986154154]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15271906503392801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15271906503392801 | validation: 0.23968835682025005]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784994109602501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15784994109602501 | validation: 0.23567225461249192]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15995240543841885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15995240543841885 | validation: 0.22904495861988128]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14903760296460827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14903760296460827 | validation: 0.23739346469694747]
	TIME [epoch: 36.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14047054014478516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14047054014478516 | validation: 0.22567005223124573]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475296722499308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1475296722499308 | validation: 0.2264389676990394]
	TIME [epoch: 36.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14265373352742503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14265373352742503 | validation: 0.22044746591496667]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1340122570434517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1340122570434517 | validation: 0.22549839761961205]
	TIME [epoch: 36.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14788597280150378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14788597280150378 | validation: 0.21795473871621063]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13522317046792343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13522317046792343 | validation: 0.23503888175824184]
	TIME [epoch: 36.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14587400926915967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14587400926915967 | validation: 0.220639050906458]
	TIME [epoch: 36.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13445010055221038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13445010055221038 | validation: 0.21624738681856365]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12634341194442128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12634341194442128 | validation: 0.19870920913152265]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13013564843304554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13013564843304554 | validation: 0.2110640884715656]
	TIME [epoch: 36.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12071522590234374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12071522590234374 | validation: 0.22740020285987406]
	TIME [epoch: 36.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12657893386658678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12657893386658678 | validation: 0.1997671879768552]
	TIME [epoch: 36.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1274869968566033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1274869968566033 | validation: 0.19663355581999503]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11937327863226983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11937327863226983 | validation: 0.19746881740262393]
	TIME [epoch: 36.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12281537734925248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12281537734925248 | validation: 0.20402675681901492]
	TIME [epoch: 36.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12020995510207114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12020995510207114 | validation: 0.19043121164028515]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12316455758728853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12316455758728853 | validation: 0.20109340719470487]
	TIME [epoch: 36.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12318761750420289		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.12318761750420289 | validation: 0.22599106027419194]
	TIME [epoch: 36.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1211678838327614		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.1211678838327614 | validation: 0.22515700591751514]
	TIME [epoch: 36.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12091805274238496		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.12091805274238496 | validation: 0.18583243982320738]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11021878205503408		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.11021878205503408 | validation: 0.19081042032764478]
	TIME [epoch: 36.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11821428312092779		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.11821428312092779 | validation: 0.2130121665577942]
	TIME [epoch: 36.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11827390317699742		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.11827390317699742 | validation: 0.1978871702524749]
	TIME [epoch: 36.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11893625865464688		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.11893625865464688 | validation: 0.20309088205145195]
	TIME [epoch: 36.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1107833901438626		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.1107833901438626 | validation: 0.1814334914895367]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11230289869523351		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.11230289869523351 | validation: 0.19993896428013566]
	TIME [epoch: 36.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11316023430785838		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.11316023430785838 | validation: 0.17617104390191302]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1119240301882746		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.1119240301882746 | validation: 0.2109053453588517]
	TIME [epoch: 36.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10589265798074739		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.10589265798074739 | validation: 0.16853626018354909]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11617783344803792		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.11617783344803792 | validation: 0.18337897861852068]
	TIME [epoch: 36.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11330638307781093		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.11330638307781093 | validation: 0.17292421418705534]
	TIME [epoch: 36.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10718234572264776		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.10718234572264776 | validation: 0.1846769066850023]
	TIME [epoch: 36.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10917404350291729		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.10917404350291729 | validation: 0.22304419499365696]
	TIME [epoch: 36.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1111999818119807		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.1111999818119807 | validation: 0.18228350493956313]
	TIME [epoch: 36.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111724286235989		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.111724286235989 | validation: 0.18572848491463012]
	TIME [epoch: 36.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1120283671092761		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.1120283671092761 | validation: 0.1881096649513909]
	TIME [epoch: 36.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10915599504968476		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.10915599504968476 | validation: 0.1779900233492252]
	TIME [epoch: 36.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11037228541714024		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.11037228541714024 | validation: 0.20369410762810475]
	TIME [epoch: 36.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10884384694042981		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.10884384694042981 | validation: 0.17200675203781596]
	TIME [epoch: 36.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10575714376594636		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.10575714376594636 | validation: 0.16831341286453513]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10612646595512236		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.10612646595512236 | validation: 0.18687047828203449]
	TIME [epoch: 36.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10649788308329286		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.10649788308329286 | validation: 0.20059894918797083]
	TIME [epoch: 36.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11351185763251888		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.11351185763251888 | validation: 0.18555607377046793]
	TIME [epoch: 36.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10731740829821808		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.10731740829821808 | validation: 0.21424185612665572]
	TIME [epoch: 36.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11755035074941986		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.11755035074941986 | validation: 0.1769154922115018]
	TIME [epoch: 36.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966191684938577		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.09966191684938577 | validation: 0.17505618287858382]
	TIME [epoch: 36.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1045230583308026		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.1045230583308026 | validation: 0.17335477577163214]
	TIME [epoch: 36.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10776140825628462		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.10776140825628462 | validation: 0.19640211233909455]
	TIME [epoch: 36.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10847910427001435		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.10847910427001435 | validation: 0.17821997082223753]
	TIME [epoch: 36.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000248876250944		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.1000248876250944 | validation: 0.1938229719879215]
	TIME [epoch: 36.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10410214520898461		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.10410214520898461 | validation: 0.1853667182488694]
	TIME [epoch: 36.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10610393916967706		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.10610393916967706 | validation: 0.1833150685960493]
	TIME [epoch: 36.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10131368778166165		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.10131368778166165 | validation: 0.1862231742256597]
	TIME [epoch: 36.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10991241529893662		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.10991241529893662 | validation: 0.1951846158622496]
	TIME [epoch: 36.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10288842308024737		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.10288842308024737 | validation: 0.1882227629187208]
	TIME [epoch: 36.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10529186130575607		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.10529186130575607 | validation: 0.18165229227622173]
	TIME [epoch: 36.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10869829311478607		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.10869829311478607 | validation: 0.18656568916232477]
	TIME [epoch: 36.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10909759621298887		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.10909759621298887 | validation: 0.18049691825453285]
	TIME [epoch: 36.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10355149710881797		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.10355149710881797 | validation: 0.1864839435994705]
	TIME [epoch: 36.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10434939052885724		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.10434939052885724 | validation: 0.17585372807418134]
	TIME [epoch: 36.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10472186990506205		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.10472186990506205 | validation: 0.166359276290032]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10409086699295092		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.10409086699295092 | validation: 0.1668428530041764]
	TIME [epoch: 36.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10371225935863682		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.10371225935863682 | validation: 0.16943025646152157]
	TIME [epoch: 36.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019641563375044		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.1019641563375044 | validation: 0.17111279785564465]
	TIME [epoch: 36.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09855269010439327		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.09855269010439327 | validation: 0.1756262515531456]
	TIME [epoch: 36.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10340830579540639		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.10340830579540639 | validation: 0.17908013726011307]
	TIME [epoch: 36.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10450271621252234		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.10450271621252234 | validation: 0.17339869353486512]
	TIME [epoch: 36.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09866633119890592		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.09866633119890592 | validation: 0.21698113837938915]
	TIME [epoch: 36.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10595542759077614		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.10595542759077614 | validation: 0.17206170349076164]
	TIME [epoch: 36.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10147041110251949		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.10147041110251949 | validation: 0.17142661623975247]
	TIME [epoch: 36.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09945111106254083		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.09945111106254083 | validation: 0.20807941980097788]
	TIME [epoch: 36.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10513800101688639		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.10513800101688639 | validation: 0.1748065191308002]
	TIME [epoch: 36.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0980241459203687		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.0980241459203687 | validation: 0.16884438099431118]
	TIME [epoch: 36.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10633546222334		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.10633546222334 | validation: 0.17236047153195166]
	TIME [epoch: 36.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09972757374747653		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.09972757374747653 | validation: 0.17537958014357663]
	TIME [epoch: 36.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10160188951635343		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.10160188951635343 | validation: 0.1684358203003066]
	TIME [epoch: 36.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10089232355078422		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.10089232355078422 | validation: 0.17953575852902076]
	TIME [epoch: 36.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09897820874994934		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.09897820874994934 | validation: 0.17750728483004324]
	TIME [epoch: 36.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09787263611952442		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.09787263611952442 | validation: 0.20485366939697194]
	TIME [epoch: 36.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10139352718033852		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.10139352718033852 | validation: 0.16797361649901132]
	TIME [epoch: 36.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09854534043906929		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.09854534043906929 | validation: 0.16568203216012706]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10071199683055262		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.10071199683055262 | validation: 0.16774796063240272]
	TIME [epoch: 36.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09772938229457635		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.09772938229457635 | validation: 0.18424626460170546]
	TIME [epoch: 36.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0985889404847182		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.0985889404847182 | validation: 0.16796050180927247]
	TIME [epoch: 36.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0985744777214009		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.0985744777214009 | validation: 0.18467679422538955]
	TIME [epoch: 36.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10185123761308042		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.10185123761308042 | validation: 0.1683381000908914]
	TIME [epoch: 36.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10501254744844946		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.10501254744844946 | validation: 0.17544078492342033]
	TIME [epoch: 36.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09772467951080159		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.09772467951080159 | validation: 0.2610556416981362]
	TIME [epoch: 36.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10100037029258528		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.10100037029258528 | validation: 0.20419841797791716]
	TIME [epoch: 36.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10109922664281215		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.10109922664281215 | validation: 0.17951224000900956]
	TIME [epoch: 36.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09826284557253509		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.09826284557253509 | validation: 0.19310222417015419]
	TIME [epoch: 36.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09879895780012764		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.09879895780012764 | validation: 0.16089442471534993]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09633068078747434		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.09633068078747434 | validation: 0.17525472488534444]
	TIME [epoch: 36.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09746309551145546		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.09746309551145546 | validation: 0.1838890554253923]
	TIME [epoch: 36.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10059806279468822		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.10059806279468822 | validation: 0.19182154840562263]
	TIME [epoch: 36.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09519470981260936		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.09519470981260936 | validation: 0.18062413101072286]
	TIME [epoch: 36.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09807054701945317		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.09807054701945317 | validation: 0.1710892158355644]
	TIME [epoch: 36.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1016656876768562		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.1016656876768562 | validation: 0.20466368980996955]
	TIME [epoch: 36.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10453016207031547		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.10453016207031547 | validation: 0.17851690369330367]
	TIME [epoch: 36.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09706560895519502		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.09706560895519502 | validation: 0.19017407467642594]
	TIME [epoch: 36.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09913265971523728		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.09913265971523728 | validation: 0.17138982461536362]
	TIME [epoch: 36.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539124313892068		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.09539124313892068 | validation: 0.1820950858389877]
	TIME [epoch: 36.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09671381343447151		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.09671381343447151 | validation: 0.2155443890359237]
	TIME [epoch: 36.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09877942423813094		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.09877942423813094 | validation: 0.16723536238320816]
	TIME [epoch: 36.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0943803046995954		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.0943803046995954 | validation: 0.17652738689133352]
	TIME [epoch: 36.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09707343506138617		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.09707343506138617 | validation: 0.16354280576135125]
	TIME [epoch: 36.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09599638339540525		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.09599638339540525 | validation: 0.17785475630669248]
	TIME [epoch: 36.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09953652307916575		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.09953652307916575 | validation: 0.17787244279652953]
	TIME [epoch: 36.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10078331298938284		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.10078331298938284 | validation: 0.16381797182045144]
	TIME [epoch: 36.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09695430508344485		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.09695430508344485 | validation: 0.16784501872824698]
	TIME [epoch: 36.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10003304037884116		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.10003304037884116 | validation: 0.1617805071256778]
	TIME [epoch: 36.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09207796181814534		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.09207796181814534 | validation: 0.16942417000603327]
	TIME [epoch: 36.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09853865570675222		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.09853865570675222 | validation: 0.19750291251958746]
	TIME [epoch: 36.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10078680006095384		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.10078680006095384 | validation: 0.17609693934599585]
	TIME [epoch: 36.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09534968747999464		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.09534968747999464 | validation: 0.1655120536998398]
	TIME [epoch: 36.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0968578082792961		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.0968578082792961 | validation: 0.16675078227166168]
	TIME [epoch: 36.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09806015159190937		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.09806015159190937 | validation: 0.1726079054712297]
	TIME [epoch: 36.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09453480401282909		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.09453480401282909 | validation: 0.17599470387743749]
	TIME [epoch: 36.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09325157428616275		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.09325157428616275 | validation: 0.16081327370582815]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09698651920418999		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.09698651920418999 | validation: 0.1591307113963103]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09450007335776393		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.09450007335776393 | validation: 0.15862568429329177]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09340895025457727		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.09340895025457727 | validation: 0.15989670088503502]
	TIME [epoch: 36.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09990579496031789		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.09990579496031789 | validation: 0.18221469248818248]
	TIME [epoch: 36.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952352080998483		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.0952352080998483 | validation: 0.1894371394677532]
	TIME [epoch: 36.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09987479457827979		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.09987479457827979 | validation: 0.17650810135176337]
	TIME [epoch: 36.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09567008671902036		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.09567008671902036 | validation: 0.1969945574749609]
	TIME [epoch: 36.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09685300576539624		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.09685300576539624 | validation: 0.176760939643391]
	TIME [epoch: 36.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0937887774807844		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.0937887774807844 | validation: 0.1642720319103896]
	TIME [epoch: 36.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966170550432893		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.09966170550432893 | validation: 0.16866420385518022]
	TIME [epoch: 36.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09304284455479558		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.09304284455479558 | validation: 0.1594535885566789]
	TIME [epoch: 36.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343994906594451		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.09343994906594451 | validation: 0.16852244289978005]
	TIME [epoch: 36.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09732874146326546		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.09732874146326546 | validation: 0.1648945569333029]
	TIME [epoch: 36.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09487003554512721		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.09487003554512721 | validation: 0.1705326365928536]
	TIME [epoch: 36.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09605740614285603		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.09605740614285603 | validation: 0.17234128057224044]
	TIME [epoch: 36.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09408010975767167		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.09408010975767167 | validation: 0.15849035426318336]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09465838788161358		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.09465838788161358 | validation: 0.16547017562493546]
	TIME [epoch: 36.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645813871840715		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.09645813871840715 | validation: 0.1668744249211563]
	TIME [epoch: 36.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09319329539337484		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.09319329539337484 | validation: 0.17221535457700746]
	TIME [epoch: 36.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09704128950896784		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.09704128950896784 | validation: 0.1706040062146918]
	TIME [epoch: 36.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264642973953081		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.09264642973953081 | validation: 0.15793704184580065]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09099150673924646		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.09099150673924646 | validation: 0.16577689925267358]
	TIME [epoch: 36.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09195329703434527		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.09195329703434527 | validation: 0.16662410520269433]
	TIME [epoch: 36.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09697521769642956		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.09697521769642956 | validation: 0.17265944169349595]
	TIME [epoch: 36.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09628876777752664		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.09628876777752664 | validation: 0.16090179511237834]
	TIME [epoch: 36.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09755541875992449		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.09755541875992449 | validation: 0.15869418465689938]
	TIME [epoch: 36.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09431373681682417		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.09431373681682417 | validation: 0.17761242513616657]
	TIME [epoch: 36.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09510395825164066		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.09510395825164066 | validation: 0.16319444922518403]
	TIME [epoch: 36.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09197261451916895		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.09197261451916895 | validation: 0.1611296554165698]
	TIME [epoch: 36.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09617799390148395		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.09617799390148395 | validation: 0.16900539128792885]
	TIME [epoch: 36.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09315237812628882		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.09315237812628882 | validation: 0.1625011355220853]
	TIME [epoch: 36.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10057887143445735		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.10057887143445735 | validation: 0.206552543296674]
	TIME [epoch: 36.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12102466751182257		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.12102466751182257 | validation: 0.17880635954542978]
	TIME [epoch: 36.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09907199789298335		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.09907199789298335 | validation: 0.18851083270991215]
	TIME [epoch: 36.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645435919953718		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.09645435919953718 | validation: 0.16861632874672805]
	TIME [epoch: 36.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09451548818686106		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.09451548818686106 | validation: 0.16518110129462846]
	TIME [epoch: 36.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09586983201543434		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.09586983201543434 | validation: 0.1754557682997065]
	TIME [epoch: 36.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09376193962819543		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09376193962819543 | validation: 0.1828344634171501]
	TIME [epoch: 36.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09319820490217544		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.09319820490217544 | validation: 0.16808076721720172]
	TIME [epoch: 36.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349388860803645		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.09349388860803645 | validation: 0.17316504548572242]
	TIME [epoch: 36.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0948742988771725		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.0948742988771725 | validation: 0.1729673931365835]
	TIME [epoch: 36.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09218137969708573		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.09218137969708573 | validation: 0.17915528888969706]
	TIME [epoch: 36.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976455262735203		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.0976455262735203 | validation: 0.18401551411535275]
	TIME [epoch: 36.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0948013198427388		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.0948013198427388 | validation: 0.16345351293737234]
	TIME [epoch: 36.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287560709182968		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.09287560709182968 | validation: 0.17336116042789376]
	TIME [epoch: 36.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0922204031151278		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.0922204031151278 | validation: 0.16895749647187402]
	TIME [epoch: 36.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941595619765937		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.0941595619765937 | validation: 0.16502333379602588]
	TIME [epoch: 36.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09420850220955554		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.09420850220955554 | validation: 0.16555560180329762]
	TIME [epoch: 36.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252005739801947		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.09252005739801947 | validation: 0.17025703859897526]
	TIME [epoch: 36.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09503401506841133		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.09503401506841133 | validation: 0.16307285635389465]
	TIME [epoch: 36.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942875593740238		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.0942875593740238 | validation: 0.1797299183405935]
	TIME [epoch: 36.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09776276253916336		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.09776276253916336 | validation: 0.16971638136862707]
	TIME [epoch: 36.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09269093058342506		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.09269093058342506 | validation: 0.18440732055078146]
	TIME [epoch: 36.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09190750708601748		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.09190750708601748 | validation: 0.2008322368972026]
	TIME [epoch: 36.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09592850107930506		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.09592850107930506 | validation: 0.16512721546515347]
	TIME [epoch: 36.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09307885335385876		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09307885335385876 | validation: 0.18238104478275477]
	TIME [epoch: 36.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09410157273389057		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.09410157273389057 | validation: 0.16521861248578207]
	TIME [epoch: 36.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09540865433524441		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.09540865433524441 | validation: 0.1650849743472222]
	TIME [epoch: 36.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09315942998672659		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.09315942998672659 | validation: 0.16079131309960365]
	TIME [epoch: 36.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09243595844272262		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.09243595844272262 | validation: 0.15539885611648468]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930825127667561		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.0930825127667561 | validation: 0.16700895874125388]
	TIME [epoch: 36.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008798657174302		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.09008798657174302 | validation: 0.16380561742911853]
	TIME [epoch: 36.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09402674786198466		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.09402674786198466 | validation: 0.17103627334327903]
	TIME [epoch: 36.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09598215407889563		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.09598215407889563 | validation: 0.17547005072952393]
	TIME [epoch: 36.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09431118353680457		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.09431118353680457 | validation: 0.15644233622080803]
	TIME [epoch: 36.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09106263783672222		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.09106263783672222 | validation: 0.15912483398155514]
	TIME [epoch: 36.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262527848606207		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.09262527848606207 | validation: 0.16173266883423096]
	TIME [epoch: 36.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09393388795934585		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.09393388795934585 | validation: 0.15951799326852292]
	TIME [epoch: 36.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349677870205053		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.09349677870205053 | validation: 0.1587413821716036]
	TIME [epoch: 36.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08854726225604777		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.08854726225604777 | validation: 0.1578293335290114]
	TIME [epoch: 36.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09013558761159621		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.09013558761159621 | validation: 0.15789800809090349]
	TIME [epoch: 36.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161526545466066		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.09161526545466066 | validation: 0.1655301976410442]
	TIME [epoch: 36.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08853692836822247		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.08853692836822247 | validation: 0.18365297448563284]
	TIME [epoch: 36.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09177140574766296		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.09177140574766296 | validation: 0.15347306441138392]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287780719450778		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.09287780719450778 | validation: 0.1582576446438063]
	TIME [epoch: 36.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958725395480256		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.08958725395480256 | validation: 0.17317553472295602]
	TIME [epoch: 36.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899731807596297		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.0899731807596297 | validation: 0.17046108302872845]
	TIME [epoch: 36.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09114480770100811		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.09114480770100811 | validation: 0.16121635411163687]
	TIME [epoch: 36.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09058226579269282		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.09058226579269282 | validation: 0.1703189712993493]
	TIME [epoch: 36.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09337609229404223		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.09337609229404223 | validation: 0.17317991037930136]
	TIME [epoch: 36.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08945478883021689		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.08945478883021689 | validation: 0.19312955456074857]
	TIME [epoch: 36.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0928718394280447		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.0928718394280447 | validation: 0.17330422776167004]
	TIME [epoch: 36.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265142440057043		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.09265142440057043 | validation: 0.15603875955701377]
	TIME [epoch: 36.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09279569397943904		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09279569397943904 | validation: 0.15885207789277392]
	TIME [epoch: 36.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898967899483226		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.08898967899483226 | validation: 0.1551091706286484]
	TIME [epoch: 36.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09484945479683153		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.09484945479683153 | validation: 0.16245531191497048]
	TIME [epoch: 36.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08997077451808223		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.08997077451808223 | validation: 0.16332562704661194]
	TIME [epoch: 36.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08852644861082504		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.08852644861082504 | validation: 0.17019969139693253]
	TIME [epoch: 36.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09174695526243275		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.09174695526243275 | validation: 0.15628665527522173]
	TIME [epoch: 36.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09091914699469336		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.09091914699469336 | validation: 0.17097513430747413]
	TIME [epoch: 36.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08801305094144607		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.08801305094144607 | validation: 0.16232096518457959]
	TIME [epoch: 36.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08962017890885307		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.08962017890885307 | validation: 0.16106913651298294]
	TIME [epoch: 36.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08940642143897351		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.08940642143897351 | validation: 0.15608636205102597]
	TIME [epoch: 36.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086609747614889		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09086609747614889 | validation: 0.17345453801300445]
	TIME [epoch: 36.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09271181526787384		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.09271181526787384 | validation: 0.15557408288911362]
	TIME [epoch: 36.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08823091880213625		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.08823091880213625 | validation: 0.15413181307898768]
	TIME [epoch: 36.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09158309757655732		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.09158309757655732 | validation: 0.16646898372329214]
	TIME [epoch: 36.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08865332220714901		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.08865332220714901 | validation: 0.18558916329593922]
	TIME [epoch: 36.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09168154505720313		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.09168154505720313 | validation: 0.16466403501393362]
	TIME [epoch: 36.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09340001704955021		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09340001704955021 | validation: 0.16252327630441507]
	TIME [epoch: 36.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0913481799276397		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.0913481799276397 | validation: 0.15331904523714596]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09098698858400643		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.09098698858400643 | validation: 0.16929795023651373]
	TIME [epoch: 36.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010394813663353		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.09010394813663353 | validation: 0.16169234869747423]
	TIME [epoch: 36.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09246398343830214		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.09246398343830214 | validation: 0.15463562035953057]
	TIME [epoch: 36.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08988958143633001		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.08988958143633001 | validation: 0.15104457685614986]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958211385867933		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.08958211385867933 | validation: 0.1541187116131908]
	TIME [epoch: 36.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559934724463923		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.08559934724463923 | validation: 0.1584235973559251]
	TIME [epoch: 36.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08978844280998707		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.08978844280998707 | validation: 0.16668185861183105]
	TIME [epoch: 36.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08956091737720837		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.08956091737720837 | validation: 0.1559736927922667]
	TIME [epoch: 36.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008767260662369		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.09008767260662369 | validation: 0.15352485559836773]
	TIME [epoch: 36.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09016407135996815		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.09016407135996815 | validation: 0.16284668839469338]
	TIME [epoch: 36.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08817173320899559		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.08817173320899559 | validation: 0.16213737287194352]
	TIME [epoch: 36.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08594943663741562		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.08594943663741562 | validation: 0.16277738743650155]
	TIME [epoch: 36.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08792612191104397		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08792612191104397 | validation: 0.1632809723284835]
	TIME [epoch: 36.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09059600712198236		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.09059600712198236 | validation: 0.1667925360392919]
	TIME [epoch: 36.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0874108712163564		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.0874108712163564 | validation: 0.15728438357152968]
	TIME [epoch: 36.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08828165798307927		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.08828165798307927 | validation: 0.15569956295868337]
	TIME [epoch: 36.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08836814916940189		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.08836814916940189 | validation: 0.1545396646284301]
	TIME [epoch: 36.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072677337135068		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.09072677337135068 | validation: 0.15545676694250188]
	TIME [epoch: 36.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09212749299288968		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.09212749299288968 | validation: 0.1534230716996911]
	TIME [epoch: 36.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09064144979628976		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.09064144979628976 | validation: 0.15371604774097547]
	TIME [epoch: 36.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630141973832002		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.08630141973832002 | validation: 0.16538869962606945]
	TIME [epoch: 36.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986282689131678		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.08986282689131678 | validation: 0.1562954514789934]
	TIME [epoch: 36.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487055485697524		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.08487055485697524 | validation: 0.1612767106661493]
	TIME [epoch: 36.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09001245535034202		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09001245535034202 | validation: 0.16157114687091398]
	TIME [epoch: 36.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09294837507137563		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.09294837507137563 | validation: 0.15889660216627036]
	TIME [epoch: 36.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167587409916954		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.09167587409916954 | validation: 0.15502059920033723]
	TIME [epoch: 36.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752146043352019		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.08752146043352019 | validation: 0.15626363292521925]
	TIME [epoch: 36.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986161501958093		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.08986161501958093 | validation: 0.1502364099448013]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08736243236769496		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.08736243236769496 | validation: 0.15702138932855983]
	TIME [epoch: 36.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0895931724460687		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.0895931724460687 | validation: 0.1566486396759309]
	TIME [epoch: 36.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08979384389065952		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.08979384389065952 | validation: 0.1641810074366744]
	TIME [epoch: 36.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871378033793634		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.08871378033793634 | validation: 0.16933193931732052]
	TIME [epoch: 36.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08930133113103524		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.08930133113103524 | validation: 0.16748808889508462]
	TIME [epoch: 36.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09104322977526616		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.09104322977526616 | validation: 0.169266826110534]
	TIME [epoch: 36.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09015815576510369		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09015815576510369 | validation: 0.15661191261001467]
	TIME [epoch: 36.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08911322487728603		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.08911322487728603 | validation: 0.1568680084755471]
	TIME [epoch: 36.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0868727079922404		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.0868727079922404 | validation: 0.1535686671442652]
	TIME [epoch: 36.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09006616846452738		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.09006616846452738 | validation: 0.1648486937476001]
	TIME [epoch: 36.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990051696682985		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.08990051696682985 | validation: 0.14940408146186807]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870819993306071		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.0870819993306071 | validation: 0.15057161875897557]
	TIME [epoch: 36.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898353496573219		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.08898353496573219 | validation: 0.1560411996701052]
	TIME [epoch: 36.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870005090809825		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.0870005090809825 | validation: 0.15562064711963833]
	TIME [epoch: 36.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0888449064906244		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.0888449064906244 | validation: 0.15745579862357545]
	TIME [epoch: 36.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630170869198966		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.08630170869198966 | validation: 0.15704366659781793]
	TIME [epoch: 36.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08921155706613354		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.08921155706613354 | validation: 0.15425295774380826]
	TIME [epoch: 36.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0884479456455978		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.0884479456455978 | validation: 0.14788326612855546]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08866021147134175		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.08866021147134175 | validation: 0.15357372577988487]
	TIME [epoch: 36.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871354168159337		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.0871354168159337 | validation: 0.1560857688793756]
	TIME [epoch: 36.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0891884311498453		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.0891884311498453 | validation: 0.1500651607325482]
	TIME [epoch: 36.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900669734969059		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.08900669734969059 | validation: 0.1675402049829814]
	TIME [epoch: 36.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08904769992989565		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.08904769992989565 | validation: 0.1588963492007216]
	TIME [epoch: 36.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0835363565994966		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.0835363565994966 | validation: 0.15410536031318228]
	TIME [epoch: 36.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730466909382936		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.08730466909382936 | validation: 0.1545672484188636]
	TIME [epoch: 36.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857105143770606		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.08857105143770606 | validation: 0.17143795607953718]
	TIME [epoch: 36.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0888184854749033		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.0888184854749033 | validation: 0.16180411284145962]
	TIME [epoch: 36.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08595979641303382		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.08595979641303382 | validation: 0.15726149589784016]
	TIME [epoch: 36.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08694274443669836		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08694274443669836 | validation: 0.15100938279005824]
	TIME [epoch: 36.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09138504293985635		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.09138504293985635 | validation: 0.15564164155232407]
	TIME [epoch: 36.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09068629126702145		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.09068629126702145 | validation: 0.15658662508930324]
	TIME [epoch: 36.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08806145106904407		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.08806145106904407 | validation: 0.15242845723605186]
	TIME [epoch: 36.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08866074753775402		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.08866074753775402 | validation: 0.1598478979979404]
	TIME [epoch: 36.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662929174676356		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.08662929174676356 | validation: 0.1693087396156212]
	TIME [epoch: 36.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689985653833786		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.08689985653833786 | validation: 0.16088107936179166]
	TIME [epoch: 36.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926011298928008		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.08926011298928008 | validation: 0.1646077157516856]
	TIME [epoch: 36.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783037902410336		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.08783037902410336 | validation: 0.15914355782307013]
	TIME [epoch: 36.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08973076632254083		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.08973076632254083 | validation: 0.17057273394414346]
	TIME [epoch: 36.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08659137288460243		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.08659137288460243 | validation: 0.15732574340814104]
	TIME [epoch: 36.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08950080407147779		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.08950080407147779 | validation: 0.16651198502064363]
	TIME [epoch: 36.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857246363523931		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.0857246363523931 | validation: 0.16099377774909943]
	TIME [epoch: 36.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08877552562801203		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.08877552562801203 | validation: 0.15503922367589643]
	TIME [epoch: 36.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08598379555993649		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.08598379555993649 | validation: 0.15480849469121896]
	TIME [epoch: 36.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0832471634038803		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.0832471634038803 | validation: 0.16869058199570716]
	TIME [epoch: 36.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08992534013802182		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.08992534013802182 | validation: 0.15437454693193559]
	TIME [epoch: 36.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08790956878981336		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08790956878981336 | validation: 0.1704592501551006]
	TIME [epoch: 36.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09363407789552722		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.09363407789552722 | validation: 0.15272252303645786]
	TIME [epoch: 36.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09106340190327264		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.09106340190327264 | validation: 0.16468163171924147]
	TIME [epoch: 36.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08668695939331067		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.08668695939331067 | validation: 0.16868704024013184]
	TIME [epoch: 36.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08545563125226334		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.08545563125226334 | validation: 0.1602089948033045]
	TIME [epoch: 36.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871721083216084		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.0871721083216084 | validation: 0.15827877575680416]
	TIME [epoch: 36.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08600493731704385		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.08600493731704385 | validation: 0.15548966718778956]
	TIME [epoch: 36.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08715533817947951		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08715533817947951 | validation: 0.16542394282164377]
	TIME [epoch: 36.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08478980173650283		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.08478980173650283 | validation: 0.15919992932671467]
	TIME [epoch: 36.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09540854824338467		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.09540854824338467 | validation: 0.15661862802489251]
	TIME [epoch: 36.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09066933944125227		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.09066933944125227 | validation: 0.16482029433746642]
	TIME [epoch: 36.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08610156130576634		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.08610156130576634 | validation: 0.1696830369207673]
	TIME [epoch: 36.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08814700942589293		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.08814700942589293 | validation: 0.1638742261658893]
	TIME [epoch: 36.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879379076000191		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.0879379076000191 | validation: 0.1604550380444829]
	TIME [epoch: 36.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703995419851732		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08703995419851732 | validation: 0.15478828820416748]
	TIME [epoch: 36.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0881758823954294		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.0881758823954294 | validation: 0.16339304418161382]
	TIME [epoch: 36.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08858291977178431		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.08858291977178431 | validation: 0.15903768837298016]
	TIME [epoch: 36.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0860385652240682		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.0860385652240682 | validation: 0.16627764335476666]
	TIME [epoch: 36.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08903655080348107		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.08903655080348107 | validation: 0.1687433387880032]
	TIME [epoch: 36.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692082328994391		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08692082328994391 | validation: 0.1574066291618596]
	TIME [epoch: 36.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08787279325023603		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.08787279325023603 | validation: 0.1602467347537561]
	TIME [epoch: 36.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08971290759165933		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.08971290759165933 | validation: 0.16347486737235428]
	TIME [epoch: 36.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827927364827128		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.08827927364827128 | validation: 0.15950099444701837]
	TIME [epoch: 36.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08591518938688189		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.08591518938688189 | validation: 0.1530739548759059]
	TIME [epoch: 36.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0868549780944426		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.0868549780944426 | validation: 0.16081176094363142]
	TIME [epoch: 36.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0887928351282724		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.0887928351282724 | validation: 0.1519314962997059]
	TIME [epoch: 36.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09004905728158683		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.09004905728158683 | validation: 0.15087922225890096]
	TIME [epoch: 36.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08834549908359937		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08834549908359937 | validation: 0.15651499615449965]
	TIME [epoch: 36.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899815163931377		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08899815163931377 | validation: 0.166742415789091]
	TIME [epoch: 36.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08846668341989236		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.08846668341989236 | validation: 0.14903482409237467]
	TIME [epoch: 36.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08759869815759036		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.08759869815759036 | validation: 0.15409992594240127]
	TIME [epoch: 36.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08608932635555105		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08608932635555105 | validation: 0.1541155524712154]
	TIME [epoch: 36.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08492978747264703		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.08492978747264703 | validation: 0.1623268661292154]
	TIME [epoch: 36.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08727529799862825		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.08727529799862825 | validation: 0.15663163833563581]
	TIME [epoch: 36.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08696300989872166		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.08696300989872166 | validation: 0.1548395451781232]
	TIME [epoch: 36.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08686148300929844		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.08686148300929844 | validation: 0.15867996430662906]
	TIME [epoch: 36.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08447419117680013		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.08447419117680013 | validation: 0.15380659578905218]
	TIME [epoch: 36.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09028267266591972		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.09028267266591972 | validation: 0.15545605585119973]
	TIME [epoch: 36.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771698237455643		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.08771698237455643 | validation: 0.15663900627360897]
	TIME [epoch: 36.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857987133365939		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.0857987133365939 | validation: 0.1638218134202121]
	TIME [epoch: 36.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08319069560230438		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.08319069560230438 | validation: 0.1616746252698204]
	TIME [epoch: 36.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08690309878442941		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.08690309878442941 | validation: 0.17091339454869714]
	TIME [epoch: 36.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08902430529232237		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.08902430529232237 | validation: 0.15511470371941238]
	TIME [epoch: 36.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08605566999228635		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.08605566999228635 | validation: 0.153509608568219]
	TIME [epoch: 36.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0873328042023863		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.0873328042023863 | validation: 0.1555277548724689]
	TIME [epoch: 36.4 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08638541598913307		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.08638541598913307 | validation: 0.16121924225428141]
	TIME [epoch: 36.4 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776216509722973		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.08776216509722973 | validation: 0.1577025392904735]
	TIME [epoch: 36.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0887664248051723		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.0887664248051723 | validation: 0.16144633504945208]
	TIME [epoch: 36.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08804414728395585		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.08804414728395585 | validation: 0.15584008120962878]
	TIME [epoch: 36.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08663061035053334		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08663061035053334 | validation: 0.1538745892852199]
	TIME [epoch: 36.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08536632614003584		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.08536632614003584 | validation: 0.15906148062593833]
	TIME [epoch: 36.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453635845448296		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.08453635845448296 | validation: 0.15531829620601662]
	TIME [epoch: 36.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08661616715938837		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.08661616715938837 | validation: 0.15850757510607466]
	TIME [epoch: 36.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08479879880885774		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08479879880885774 | validation: 0.15983125025811024]
	TIME [epoch: 36.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08772012575649382		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.08772012575649382 | validation: 0.1551895552374976]
	TIME [epoch: 36.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08540230229599041		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08540230229599041 | validation: 0.16198338721658617]
	TIME [epoch: 36.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08669990717644059		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.08669990717644059 | validation: 0.15551112183150112]
	TIME [epoch: 36.4 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464687585447653		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.08464687585447653 | validation: 0.15305558702590877]
	TIME [epoch: 36.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656429271503065		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08656429271503065 | validation: 0.1535932631801494]
	TIME [epoch: 36.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08924171033525678		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08924171033525678 | validation: 0.1530554211515799]
	TIME [epoch: 36.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08657192422871209		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08657192422871209 | validation: 0.16730975562110642]
	TIME [epoch: 36.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08711212556468553		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.08711212556468553 | validation: 0.15548359418354818]
	TIME [epoch: 36.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879923537948601		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.0879923537948601 | validation: 0.15280565443859961]
	TIME [epoch: 36.4 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623756468002286		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08623756468002286 | validation: 0.15355276855541306]
	TIME [epoch: 36.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08801504548384086		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.08801504548384086 | validation: 0.14953097963853518]
	TIME [epoch: 36.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08552454673657858		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.08552454673657858 | validation: 0.1523211145323434]
	TIME [epoch: 36.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08731324798361788		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.08731324798361788 | validation: 0.15198398749526743]
	TIME [epoch: 36.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08799369833568615		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.08799369833568615 | validation: 0.1607140958587822]
	TIME [epoch: 36.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08803427356316681		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.08803427356316681 | validation: 0.1584308602787882]
	TIME [epoch: 36.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658124038102931		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.08658124038102931 | validation: 0.16063005692477939]
	TIME [epoch: 36.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08699767996730265		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08699767996730265 | validation: 0.1601490137216911]
	TIME [epoch: 36.4 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08275755171443906		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08275755171443906 | validation: 0.15878306796129274]
	TIME [epoch: 36.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0861540038823306		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.0861540038823306 | validation: 0.15297627888047416]
	TIME [epoch: 36.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863114056495411		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.0863114056495411 | validation: 0.15550463430170952]
	TIME [epoch: 36.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08624825483093315		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08624825483093315 | validation: 0.15244338147679848]
	TIME [epoch: 36.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630239081217306		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08630239081217306 | validation: 0.15179480163322479]
	TIME [epoch: 36.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08621913296300396		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08621913296300396 | validation: 0.15422992376108874]
	TIME [epoch: 36.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08601403983471553		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08601403983471553 | validation: 0.15594604740232154]
	TIME [epoch: 36.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08829019164417254		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08829019164417254 | validation: 0.1578192597206828]
	TIME [epoch: 36.4 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08634907177413788		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.08634907177413788 | validation: 0.15499400816273418]
	TIME [epoch: 36.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08602276118511028		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.08602276118511028 | validation: 0.15624403377612]
	TIME [epoch: 36.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08451724778578074		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08451724778578074 | validation: 0.152987768272709]
	TIME [epoch: 36.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858927225367977		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.0858927225367977 | validation: 0.15192211508557565]
	TIME [epoch: 36.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853715533747063		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.0853715533747063 | validation: 0.1543613475291583]
	TIME [epoch: 36.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08292433665760574		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.08292433665760574 | validation: 0.15621310498393698]
	TIME [epoch: 36.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08522347993943684		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.08522347993943684 | validation: 0.16345339999390854]
	TIME [epoch: 36.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656066587883424		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08656066587883424 | validation: 0.15625429545037373]
	TIME [epoch: 36.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692939953978103		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08692939953978103 | validation: 0.15488822754158715]
	TIME [epoch: 36.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08799724410198227		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08799724410198227 | validation: 0.15828202592598434]
	TIME [epoch: 36.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08602313170509068		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08602313170509068 | validation: 0.15308438332166344]
	TIME [epoch: 36.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08549507919077334		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08549507919077334 | validation: 0.15681781050705335]
	TIME [epoch: 36.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08608594476067458		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.08608594476067458 | validation: 0.16220562960400112]
	TIME [epoch: 36.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08461331271482622		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.08461331271482622 | validation: 0.15823776298244632]
	TIME [epoch: 36.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08647901218834637		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08647901218834637 | validation: 0.1600523139372748]
	TIME [epoch: 36.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08684166530976964		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08684166530976964 | validation: 0.15500000503574946]
	TIME [epoch: 36.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0840725190175873		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.0840725190175873 | validation: 0.15228178806395976]
	TIME [epoch: 36.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08624543639584228		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.08624543639584228 | validation: 0.15010333498925332]
	TIME [epoch: 36.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08588233096581371		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.08588233096581371 | validation: 0.15658741200329446]
	TIME [epoch: 36.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08715110434715505		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08715110434715505 | validation: 0.15256972199722343]
	TIME [epoch: 36.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08633204267738416		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08633204267738416 | validation: 0.1574761558166259]
	TIME [epoch: 36.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08800163215367023		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.08800163215367023 | validation: 0.15872204894995065]
	TIME [epoch: 36.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08499120898306414		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.08499120898306414 | validation: 0.16616398563362847]
	TIME [epoch: 36.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08648291871056364		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.08648291871056364 | validation: 0.1588385628623604]
	TIME [epoch: 36.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08517382906109308		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.08517382906109308 | validation: 0.15280625403537512]
	TIME [epoch: 36.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08542317160668662		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08542317160668662 | validation: 0.15400684186743904]
	TIME [epoch: 36.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08750618129378758		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.08750618129378758 | validation: 0.16235461876605814]
	TIME [epoch: 36.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845659040713818		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.0845659040713818 | validation: 0.15613480565214657]
	TIME [epoch: 36.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279427490518873		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08279427490518873 | validation: 0.1547912038039672]
	TIME [epoch: 36.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0860957083057831		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.0860957083057831 | validation: 0.15577679882167914]
	TIME [epoch: 36.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08792060054308826		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.08792060054308826 | validation: 0.153511231651966]
	TIME [epoch: 36.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08620293756210903		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.08620293756210903 | validation: 0.15160317323709796]
	TIME [epoch: 36.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689856481396355		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08689856481396355 | validation: 0.15472183406742965]
	TIME [epoch: 36.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857013282764705		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.0857013282764705 | validation: 0.1588758775905073]
	TIME [epoch: 36.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08332276299519258		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.08332276299519258 | validation: 0.1820632361821426]
	TIME [epoch: 36.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08684348469990774		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.08684348469990774 | validation: 0.1537112589776632]
	TIME [epoch: 36.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733755687933728		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08733755687933728 | validation: 0.1559555843351805]
	TIME [epoch: 36.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08416321288042845		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.08416321288042845 | validation: 0.15401407674319734]
	TIME [epoch: 36.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08628441587505312		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08628441587505312 | validation: 0.15843756174813015]
	TIME [epoch: 36.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08512411577996408		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.08512411577996408 | validation: 0.1545279546421296]
	TIME [epoch: 36.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08669989934386489		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08669989934386489 | validation: 0.1506335827896211]
	TIME [epoch: 36.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08822177178348667		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.08822177178348667 | validation: 0.15021761212297574]
	TIME [epoch: 36.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08649306958232615		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.08649306958232615 | validation: 0.1478018899584414]
	TIME [epoch: 36.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08434200885382706		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.08434200885382706 | validation: 0.15085018386062815]
	TIME [epoch: 36.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08301885425775292		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.08301885425775292 | validation: 0.15879958836658215]
	TIME [epoch: 36.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666653382702427		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08666653382702427 | validation: 0.15423014019053846]
	TIME [epoch: 36.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08698113127818244		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.08698113127818244 | validation: 0.15312095714583515]
	TIME [epoch: 36.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08471368427790302		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08471368427790302 | validation: 0.15758376661020043]
	TIME [epoch: 36.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08238297282844648		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.08238297282844648 | validation: 0.15296679959383377]
	TIME [epoch: 36.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08518026388431113		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.08518026388431113 | validation: 0.15188825335395584]
	TIME [epoch: 36.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458080463047757		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08458080463047757 | validation: 0.15517978832779442]
	TIME [epoch: 36.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607967905332273		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.08607967905332273 | validation: 0.1509361343764401]
	TIME [epoch: 36.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0861240891225858		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.0861240891225858 | validation: 0.1569349164609362]
	TIME [epoch: 36.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08443756650691552		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.08443756650691552 | validation: 0.15175065253666292]
	TIME [epoch: 36.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08373145709718018		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.08373145709718018 | validation: 0.15943650376470858]
	TIME [epoch: 36.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08633327027296948		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.08633327027296948 | validation: 0.15912405237045402]
	TIME [epoch: 36.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453606120859629		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.08453606120859629 | validation: 0.15484725158622806]
	TIME [epoch: 36.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08777206321144476		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.08777206321144476 | validation: 0.15723613368527425]
	TIME [epoch: 36.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08550838511777713		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08550838511777713 | validation: 0.1531420849217701]
	TIME [epoch: 36.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630946498144064		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.08630946498144064 | validation: 0.14925625451046035]
	TIME [epoch: 36.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862426123368997		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0862426123368997 | validation: 0.150291591159308]
	TIME [epoch: 36.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557003512566115		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.08557003512566115 | validation: 0.1517594406710169]
	TIME [epoch: 36.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482237576578133		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.08482237576578133 | validation: 0.15187716089108516]
	TIME [epoch: 36.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08593178998794138		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08593178998794138 | validation: 0.1584888620165728]
	TIME [epoch: 36.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08523559517009795		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08523559517009795 | validation: 0.15465628021857605]
	TIME [epoch: 36.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08498162957417425		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.08498162957417425 | validation: 0.15020039240648606]
	TIME [epoch: 36.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845429184986407		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.0845429184986407 | validation: 0.15018834562828653]
	TIME [epoch: 36.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09070285738733437		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.09070285738733437 | validation: 0.15630809234544366]
	TIME [epoch: 36.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08766169019184529		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08766169019184529 | validation: 0.15165208732195515]
	TIME [epoch: 36.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.087157462582294		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.087157462582294 | validation: 0.1542517871475067]
	TIME [epoch: 36.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853842039515141		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.0853842039515141 | validation: 0.15496808802420448]
	TIME [epoch: 36.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08410177229960109		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.08410177229960109 | validation: 0.15621871915929178]
	TIME [epoch: 36.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703933834758547		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08703933834758547 | validation: 0.1559900372303355]
	TIME [epoch: 36.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0869064760816049		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.0869064760816049 | validation: 0.1529410922597347]
	TIME [epoch: 36.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08423373461851316		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08423373461851316 | validation: 0.1514918697801103]
	TIME [epoch: 36.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08321624215313093		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.08321624215313093 | validation: 0.15524400815949183]
	TIME [epoch: 36.4 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340829392088653		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08340829392088653 | validation: 0.1584932255614404]
	TIME [epoch: 36.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08446093595651431		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.08446093595651431 | validation: 0.15164633697244256]
	TIME [epoch: 36.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290391618975687		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.08290391618975687 | validation: 0.14945806534522732]
	TIME [epoch: 36.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08452898880215573		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.08452898880215573 | validation: 0.15674914188413397]
	TIME [epoch: 36.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734013237194213		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08734013237194213 | validation: 0.16342965274859225]
	TIME [epoch: 36.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08626488064743593		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.08626488064743593 | validation: 0.1499370298340862]
	TIME [epoch: 36.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08536457222885227		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.08536457222885227 | validation: 0.15495720279534642]
	TIME [epoch: 36.4 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845435648446921		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.0845435648446921 | validation: 0.15424913759064296]
	TIME [epoch: 36.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08477489898395463		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.08477489898395463 | validation: 0.15580442005659226]
	TIME [epoch: 36.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577322989367832		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.08577322989367832 | validation: 0.15293290854729275]
	TIME [epoch: 36.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703292095866444		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08703292095866444 | validation: 0.15605211475056835]
	TIME [epoch: 36.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0844496390222873		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.0844496390222873 | validation: 0.1578609196835804]
	TIME [epoch: 36.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08483363689091931		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08483363689091931 | validation: 0.15147616413952047]
	TIME [epoch: 36.4 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08741045281056142		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.08741045281056142 | validation: 0.15378750919347509]
	TIME [epoch: 36.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08485076976160397		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.08485076976160397 | validation: 0.15408084042509745]
	TIME [epoch: 36.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848622836750501		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.0848622836750501 | validation: 0.15330360890794076]
	TIME [epoch: 36.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577130178204871		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08577130178204871 | validation: 0.15864570142318138]
	TIME [epoch: 36.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08201342558214257		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08201342558214257 | validation: 0.15789249432098734]
	TIME [epoch: 36.4 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08262944397103984		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.08262944397103984 | validation: 0.1551560532735485]
	TIME [epoch: 36.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08550843704301389		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.08550843704301389 | validation: 0.15398513460993202]
	TIME [epoch: 36.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08603208288335931		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08603208288335931 | validation: 0.15157075883371282]
	TIME [epoch: 36.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086695374454985		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.086695374454985 | validation: 0.1514409799364773]
	TIME [epoch: 36.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08410670039675797		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.08410670039675797 | validation: 0.15864894603037394]
	TIME [epoch: 36.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429105583906		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.08429105583906 | validation: 0.15362792781228732]
	TIME [epoch: 36.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08586580726561907		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08586580726561907 | validation: 0.1541968807159113]
	TIME [epoch: 36.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08452094585939145		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.08452094585939145 | validation: 0.15118262782349565]
	TIME [epoch: 36.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08470868931065402		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.08470868931065402 | validation: 0.15340247121053874]
	TIME [epoch: 36.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0839314588809553		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.0839314588809553 | validation: 0.1556170765683596]
	TIME [epoch: 36.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487781575419857		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08487781575419857 | validation: 0.15295797405467615]
	TIME [epoch: 36.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0856487072248887		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.0856487072248887 | validation: 0.1514865965434491]
	TIME [epoch: 36.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559482311159769		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.08559482311159769 | validation: 0.15790609981597642]
	TIME [epoch: 36.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08447011145160628		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.08447011145160628 | validation: 0.15441365487368103]
	TIME [epoch: 36.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453945125405574		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08453945125405574 | validation: 0.15616459237649213]
	TIME [epoch: 36.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08261829565916715		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08261829565916715 | validation: 0.15712752750036735]
	TIME [epoch: 36.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08550045336621666		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.08550045336621666 | validation: 0.15489891847238574]
	TIME [epoch: 36.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08224451022751694		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.08224451022751694 | validation: 0.15329159235762443]
	TIME [epoch: 36.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0849325263868653		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0849325263868653 | validation: 0.15128500825644525]
	TIME [epoch: 36.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08593457033128281		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.08593457033128281 | validation: 0.1539906065835244]
	TIME [epoch: 36.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863692821814524		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.0863692821814524 | validation: 0.15810224756970723]
	TIME [epoch: 36.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.085360121574014		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.085360121574014 | validation: 0.16189455840716066]
	TIME [epoch: 36.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08481827843224024		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.08481827843224024 | validation: 0.15869265628796586]
	TIME [epoch: 36.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08459161485286347		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.08459161485286347 | validation: 0.15094154826919026]
	TIME [epoch: 36.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862928076175856		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.0862928076175856 | validation: 0.16356964994503528]
	TIME [epoch: 36.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08764303885277112		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.08764303885277112 | validation: 0.15993164094660664]
	TIME [epoch: 36.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0866448687124117		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0866448687124117 | validation: 0.15319285002766425]
	TIME [epoch: 36.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597031025225949		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.08597031025225949 | validation: 0.15688478230541292]
	TIME [epoch: 36.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08265927333920356		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.08265927333920356 | validation: 0.15792459455841248]
	TIME [epoch: 36.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847516267846716		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.0847516267846716 | validation: 0.15136324915859176]
	TIME [epoch: 36.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08349992144182322		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08349992144182322 | validation: 0.15412615831004]
	TIME [epoch: 36.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08639912091730917		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.08639912091730917 | validation: 0.15063388236342695]
	TIME [epoch: 36.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08533927337117175		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.08533927337117175 | validation: 0.15138646861683996]
	TIME [epoch: 36.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08404111563600877		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.08404111563600877 | validation: 0.15653754821099042]
	TIME [epoch: 36.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08301312233858922		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.08301312233858922 | validation: 0.155271544225625]
	TIME [epoch: 36.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08582903896855451		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.08582903896855451 | validation: 0.15752762211353877]
	TIME [epoch: 36.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08444931601869857		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.08444931601869857 | validation: 0.15257415923521875]
	TIME [epoch: 36.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08674094015943178		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.08674094015943178 | validation: 0.15154108674823372]
	TIME [epoch: 36.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08575163812354648		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08575163812354648 | validation: 0.15307704475441972]
	TIME [epoch: 36.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578910089264387		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08578910089264387 | validation: 0.15640416261381324]
	TIME [epoch: 36.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848931870347146		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.0848931870347146 | validation: 0.15361903388450532]
	TIME [epoch: 36.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458138209246344		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.08458138209246344 | validation: 0.1557163624328483]
	TIME [epoch: 36.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08438090784522938		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.08438090784522938 | validation: 0.15449487648742388]
	TIME [epoch: 36.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08506636251658509		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.08506636251658509 | validation: 0.16085351092508504]
	TIME [epoch: 36.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475899915855471		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.08475899915855471 | validation: 0.15213046012713322]
	TIME [epoch: 36.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08624490891909659		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.08624490891909659 | validation: 0.15619991493512347]
	TIME [epoch: 36.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08558017418370426		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08558017418370426 | validation: 0.15354232155774392]
	TIME [epoch: 36.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08513874522823109		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.08513874522823109 | validation: 0.14669959357632967]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851544679300237		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.0851544679300237 | validation: 0.15128303090074818]
	TIME [epoch: 36.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862078449691093		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.0862078449691093 | validation: 0.15184094153812724]
	TIME [epoch: 36.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08412767426449835		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.08412767426449835 | validation: 0.15315609477822795]
	TIME [epoch: 36.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08404446867204732		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.08404446867204732 | validation: 0.15108846712339827]
	TIME [epoch: 36.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401770633937307		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.08401770633937307 | validation: 0.152679630934033]
	TIME [epoch: 36.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08355222273103738		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.08355222273103738 | validation: 0.15112344488173754]
	TIME [epoch: 36.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08594850951793451		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08594850951793451 | validation: 0.15114476551015588]
	TIME [epoch: 36.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08538010458360765		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.08538010458360765 | validation: 0.1539407925665286]
	TIME [epoch: 36.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08394887182904534		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.08394887182904534 | validation: 0.15465893357785332]
	TIME [epoch: 36.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08529619389619096		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08529619389619096 | validation: 0.15148318831889676]
	TIME [epoch: 36.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08283827959406508		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.08283827959406508 | validation: 0.1562870725735946]
	TIME [epoch: 36.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08413283192246193		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.08413283192246193 | validation: 0.15214139644689775]
	TIME [epoch: 36.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08533257805390468		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.08533257805390468 | validation: 0.15569417652469242]
	TIME [epoch: 36.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08323887691890404		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.08323887691890404 | validation: 0.15331491565158803]
	TIME [epoch: 36.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08505231369967388		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.08505231369967388 | validation: 0.15586346306162674]
	TIME [epoch: 36.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08626054771381124		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.08626054771381124 | validation: 0.16075191338423717]
	TIME [epoch: 36.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08606806146355014		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.08606806146355014 | validation: 0.14801524211415218]
	TIME [epoch: 36.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08509568284220581		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.08509568284220581 | validation: 0.1555938112824392]
	TIME [epoch: 36.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360348498769757		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.08360348498769757 | validation: 0.15548400628506234]
	TIME [epoch: 36.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828246660692931		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.0828246660692931 | validation: 0.15767908713727527]
	TIME [epoch: 36.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577575631474718		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.08577575631474718 | validation: 0.15526839220571909]
	TIME [epoch: 36.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08547178125719032		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.08547178125719032 | validation: 0.159287674554415]
	TIME [epoch: 36.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08427656222073251		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.08427656222073251 | validation: 0.15155130130884828]
	TIME [epoch: 36.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08403104088515245		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.08403104088515245 | validation: 0.15565914369725498]
	TIME [epoch: 36.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08570829655824816		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.08570829655824816 | validation: 0.15115969487963415]
	TIME [epoch: 36.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08579938163233089		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.08579938163233089 | validation: 0.15838371771171147]
	TIME [epoch: 36.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599848769578922		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.08599848769578922 | validation: 0.15216022299669607]
	TIME [epoch: 36.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08566953289604716		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.08566953289604716 | validation: 0.15123091972158745]
	TIME [epoch: 36.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08463863653634304		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.08463863653634304 | validation: 0.15958801762787322]
	TIME [epoch: 36.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482019997286624		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.08482019997286624 | validation: 0.15258088000604336]
	TIME [epoch: 36.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577146575474096		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08577146575474096 | validation: 0.15316868075807968]
	TIME [epoch: 36.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0850651782034489		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.0850651782034489 | validation: 0.15213020953945297]
	TIME [epoch: 36.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08616700097508738		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.08616700097508738 | validation: 0.1532978042978161]
	TIME [epoch: 36.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482434981501495		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.08482434981501495 | validation: 0.15966985631185165]
	TIME [epoch: 36.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0852973544562173		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0852973544562173 | validation: 0.14960815271769076]
	TIME [epoch: 36.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08490527122900006		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08490527122900006 | validation: 0.15485160010217794]
	TIME [epoch: 36.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458543888061545		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.08458543888061545 | validation: 0.15561914458010298]
	TIME [epoch: 36.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08676109223615061		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.08676109223615061 | validation: 0.15399788743887186]
	TIME [epoch: 36.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08526307037802437		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08526307037802437 | validation: 0.15141732821895718]
	TIME [epoch: 36.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08496962881919445		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.08496962881919445 | validation: 0.15417566767184937]
	TIME [epoch: 36.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08250287920220153		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.08250287920220153 | validation: 0.158910878829105]
	TIME [epoch: 36.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08454061493094446		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.08454061493094446 | validation: 0.15272952468694406]
	TIME [epoch: 36.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08317916099452825		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.08317916099452825 | validation: 0.15663150964478326]
	TIME [epoch: 36.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08685919527313138		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.08685919527313138 | validation: 0.15337909036095596]
	TIME [epoch: 36.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08738932375714456		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.08738932375714456 | validation: 0.15562367079514705]
	TIME [epoch: 36.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384879897530766		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.08384879897530766 | validation: 0.15277447616533804]
	TIME [epoch: 36.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0852593833487622		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.0852593833487622 | validation: 0.15375238451008463]
	TIME [epoch: 36.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08555426679563181		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.08555426679563181 | validation: 0.1582774087604649]
	TIME [epoch: 36.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08463050343161697		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08463050343161697 | validation: 0.1507473109032822]
	TIME [epoch: 36.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08247745070292638		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.08247745070292638 | validation: 0.1497587863167706]
	TIME [epoch: 36.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487174702195296		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08487174702195296 | validation: 0.15224500495470805]
	TIME [epoch: 36.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857110735732747		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.0857110735732747 | validation: 0.15514173285076144]
	TIME [epoch: 36.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08310412416305908		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.08310412416305908 | validation: 0.15227048019644449]
	TIME [epoch: 36.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559644297790167		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.08559644297790167 | validation: 0.1581516508528315]
	TIME [epoch: 36.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08376456025602588		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08376456025602588 | validation: 0.15176377441715197]
	TIME [epoch: 36.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08304533713993703		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.08304533713993703 | validation: 0.15472563780979168]
	TIME [epoch: 36.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08538081653684085		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.08538081653684085 | validation: 0.1527815888745506]
	TIME [epoch: 36.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08551711170122123		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.08551711170122123 | validation: 0.15105922483135686]
	TIME [epoch: 36.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08802667366701208		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.08802667366701208 | validation: 0.1492968049436887]
	TIME [epoch: 36.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08643470004491356		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.08643470004491356 | validation: 0.153702909439487]
	TIME [epoch: 36.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08289861700243399		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.08289861700243399 | validation: 0.18404096955415164]
	TIME [epoch: 36.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728324662945666		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.08728324662945666 | validation: 0.15678393273427096]
	TIME [epoch: 36.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0852382763664283		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0852382763664283 | validation: 0.15648824427480085]
	TIME [epoch: 36.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396397280351918		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.08396397280351918 | validation: 0.1538825298967325]
	TIME [epoch: 36.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08601327676105804		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.08601327676105804 | validation: 0.16098729201210804]
	TIME [epoch: 36.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0846713396350883		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.0846713396350883 | validation: 0.15167975069999326]
	TIME [epoch: 36.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448551436285337		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.08448551436285337 | validation: 0.15384280366041064]
	TIME [epoch: 36.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08371339483411067		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.08371339483411067 | validation: 0.15587207716572687]
	TIME [epoch: 36.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08544350154963648		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.08544350154963648 | validation: 0.1544916642469649]
	TIME [epoch: 36.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0829408448483778		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.0829408448483778 | validation: 0.15189239732599658]
	TIME [epoch: 36.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845177618715591		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0845177618715591 | validation: 0.15359841884971343]
	TIME [epoch: 36.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08585601992050897		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.08585601992050897 | validation: 0.14758887674766613]
	TIME [epoch: 36.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08527295905582873		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.08527295905582873 | validation: 0.15513595747096073]
	TIME [epoch: 36.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08694087835308094		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.08694087835308094 | validation: 0.1548199750762509]
	TIME [epoch: 36.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08382611417757355		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08382611417757355 | validation: 0.15308613707045615]
	TIME [epoch: 36.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08386211409334177		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.08386211409334177 | validation: 0.1535777668813034]
	TIME [epoch: 36.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0835562442039321		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.0835562442039321 | validation: 0.15439429847404754]
	TIME [epoch: 36.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851675788518288		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.0851675788518288 | validation: 0.1529295672869114]
	TIME [epoch: 36.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08462570316343757		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.08462570316343757 | validation: 0.15225490680282205]
	TIME [epoch: 36.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08361595206844667		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.08361595206844667 | validation: 0.1511012853961704]
	TIME [epoch: 36.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439848635586818		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.08439848635586818 | validation: 0.15013704895375665]
	TIME [epoch: 36.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08388795945043355		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.08388795945043355 | validation: 0.15017356633105683]
	TIME [epoch: 36.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08351338357092188		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08351338357092188 | validation: 0.15628273771411239]
	TIME [epoch: 36.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0845685051178837		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.0845685051178837 | validation: 0.1542736859316385]
	TIME [epoch: 36.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0822555498215594		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.0822555498215594 | validation: 0.15253546094978254]
	TIME [epoch: 36.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08393333274232936		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.08393333274232936 | validation: 0.15376736644324987]
	TIME [epoch: 36.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08489781116769188		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.08489781116769188 | validation: 0.15811557862447254]
	TIME [epoch: 36.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08343825084839221		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.08343825084839221 | validation: 0.15414546950930308]
	TIME [epoch: 36.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08466415567805807		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.08466415567805807 | validation: 0.16149501674572142]
	TIME [epoch: 36.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08377489824159048		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.08377489824159048 | validation: 0.15185117855655722]
	TIME [epoch: 36.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08424867113044894		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.08424867113044894 | validation: 0.1539833594710555]
	TIME [epoch: 36.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681077331950737		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.08681077331950737 | validation: 0.15474402169447915]
	TIME [epoch: 36.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08468321448535654		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.08468321448535654 | validation: 0.15259647640986945]
	TIME [epoch: 36.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597731580847529		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.08597731580847529 | validation: 0.15240694862560483]
	TIME [epoch: 36.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0856363528720671		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0856363528720671 | validation: 0.154465453069487]
	TIME [epoch: 36.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0866551201327543		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.0866551201327543 | validation: 0.1557329750831991]
	TIME [epoch: 36.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439075705253009		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.08439075705253009 | validation: 0.1579967047452318]
	TIME [epoch: 36.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285807080610803		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.08285807080610803 | validation: 0.1537413392765441]
	TIME [epoch: 36.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08452836562061039		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.08452836562061039 | validation: 0.14782928604691495]
	TIME [epoch: 36.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577892143494902		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.08577892143494902 | validation: 0.15293324960043356]
	TIME [epoch: 36.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08398249262494231		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.08398249262494231 | validation: 0.15530278988877058]
	TIME [epoch: 36.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08313258288798558		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.08313258288798558 | validation: 0.15335393338133005]
	TIME [epoch: 36.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577815556293159		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.08577815556293159 | validation: 0.1532176579488655]
	TIME [epoch: 36.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08125289470319044		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.08125289470319044 | validation: 0.14924786187248879]
	TIME [epoch: 36.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08441773996392524		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.08441773996392524 | validation: 0.1500347830292908]
	TIME [epoch: 36.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367001717006026		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.08367001717006026 | validation: 0.1536661654213051]
	TIME [epoch: 36.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08586137225445882		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.08586137225445882 | validation: 0.15468365725253128]
	TIME [epoch: 36.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08508820256093953		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.08508820256093953 | validation: 0.15447372382086555]
	TIME [epoch: 36.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08366598689873853		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.08366598689873853 | validation: 0.15138082800083658]
	TIME [epoch: 36.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08451274031124964		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.08451274031124964 | validation: 0.15819843851978915]
	TIME [epoch: 36.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583914933872513		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08583914933872513 | validation: 0.1541231409938869]
	TIME [epoch: 36.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666016794843734		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.08666016794843734 | validation: 0.15034843798455486]
	TIME [epoch: 36.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08492464029386819		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.08492464029386819 | validation: 0.1485710327775754]
	TIME [epoch: 36.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0839699925038809		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.0839699925038809 | validation: 0.15508346642866266]
	TIME [epoch: 36.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08363794006937653		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08363794006937653 | validation: 0.1519002584768513]
	TIME [epoch: 36.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08449725795251285		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.08449725795251285 | validation: 0.15222573534396205]
	TIME [epoch: 36.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08386422603960533		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.08386422603960533 | validation: 0.15228115051307634]
	TIME [epoch: 36.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08152869509951402		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.08152869509951402 | validation: 0.1546913743964896]
	TIME [epoch: 36.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367977739086264		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.08367977739086264 | validation: 0.1531041353345313]
	TIME [epoch: 36.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08405146724877		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.08405146724877 | validation: 0.15323810110075317]
	TIME [epoch: 36.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290381090761145		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.08290381090761145 | validation: 0.1513477604457236]
	TIME [epoch: 36.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08368129660769112		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.08368129660769112 | validation: 0.1535728328233755]
	TIME [epoch: 36.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0832845562354583		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0832845562354583 | validation: 0.15111881664179003]
	TIME [epoch: 36.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08496122538156911		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.08496122538156911 | validation: 0.15654399541903927]
	TIME [epoch: 36.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464372595928057		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.08464372595928057 | validation: 0.15076833135870166]
	TIME [epoch: 36.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08457146285336889		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.08457146285336889 | validation: 0.15658621250593555]
	TIME [epoch: 36.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08354990977171971		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.08354990977171971 | validation: 0.14988376953814908]
	TIME [epoch: 36.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08437652427687617		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.08437652427687617 | validation: 0.15553988637078914]
	TIME [epoch: 36.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08508026752106539		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.08508026752106539 | validation: 0.1529247075138338]
	TIME [epoch: 36.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08502531418556389		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.08502531418556389 | validation: 0.15344431346230628]
	TIME [epoch: 36.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08425109912869812		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08425109912869812 | validation: 0.15237271721989]
	TIME [epoch: 36.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08512894768336683		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.08512894768336683 | validation: 0.15599824071015544]
	TIME [epoch: 36.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779227790831054		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.08779227790831054 | validation: 0.15683011940266764]
	TIME [epoch: 36.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0844795741200025		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.0844795741200025 | validation: 0.1562173499956996]
	TIME [epoch: 36.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08252932951613796		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08252932951613796 | validation: 0.1549853149379281]
	TIME [epoch: 36.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402282441321142		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.08402282441321142 | validation: 0.16341514003167518]
	TIME [epoch: 36.4 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08256716675769848		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.08256716675769848 | validation: 0.15218876453802638]
	TIME [epoch: 36.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08349667436908181		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.08349667436908181 | validation: 0.15566961890751357]
	TIME [epoch: 36.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08501836067668682		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08501836067668682 | validation: 0.1574290839627802]
	TIME [epoch: 36.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285936071897879		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.08285936071897879 | validation: 0.15202863733335603]
	TIME [epoch: 36.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08542429327555157		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.08542429327555157 | validation: 0.15162739938011183]
	TIME [epoch: 36.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08269998685134891		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.08269998685134891 | validation: 0.15624965206422936]
	TIME [epoch: 36.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197289321146206		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08197289321146206 | validation: 0.15067671482606754]
	TIME [epoch: 36.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08395792821408153		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.08395792821408153 | validation: 0.1532151125564425]
	TIME [epoch: 36.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0838003867287953		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.0838003867287953 | validation: 0.15660198666727393]
	TIME [epoch: 36.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08414417458923903		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.08414417458923903 | validation: 0.15794254985603814]
	TIME [epoch: 36.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08211485649721047		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08211485649721047 | validation: 0.15195438711849377]
	TIME [epoch: 36.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08586143577403796		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.08586143577403796 | validation: 0.15685797006856259]
	TIME [epoch: 36.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08327882434073906		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.08327882434073906 | validation: 0.15444667235008164]
	TIME [epoch: 36.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279447454893714		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.08279447454893714 | validation: 0.15245277914396663]
	TIME [epoch: 36.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08372199054842464		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08372199054842464 | validation: 0.15782482678763468]
	TIME [epoch: 36.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858956506696669		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.0858956506696669 | validation: 0.15432114101029043]
	TIME [epoch: 36.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08319607007438304		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.08319607007438304 | validation: 0.151929610035065]
	TIME [epoch: 36.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08315805871783023		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.08315805871783023 | validation: 0.1519842167080426]
	TIME [epoch: 36.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08407987111339112		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08407987111339112 | validation: 0.15087925197691598]
	TIME [epoch: 36.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08344572896725701		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.08344572896725701 | validation: 0.15093900620857473]
	TIME [epoch: 36.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08408382596624316		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.08408382596624316 | validation: 0.14908055657680175]
	TIME [epoch: 36.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08312760512172095		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.08312760512172095 | validation: 0.15448111709239282]
	TIME [epoch: 36.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487396605355735		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08487396605355735 | validation: 0.15311874350061006]
	TIME [epoch: 36.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08238004334197493		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.08238004334197493 | validation: 0.15059764029717498]
	TIME [epoch: 36.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08219893534174513		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.08219893534174513 | validation: 0.15932007357633976]
	TIME [epoch: 36.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08359877668990809		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.08359877668990809 | validation: 0.1553240092566677]
	TIME [epoch: 36.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08066148063139164		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08066148063139164 | validation: 0.15189442416706328]
	TIME [epoch: 36.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08388711387062482		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.08388711387062482 | validation: 0.1543469978960259]
	TIME [epoch: 36.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862416736507021		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.0862416736507021 | validation: 0.1533269422178118]
	TIME [epoch: 36.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08238197085628093		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.08238197085628093 | validation: 0.151248578808289]
	TIME [epoch: 36.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08478257464896999		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.08478257464896999 | validation: 0.15407219942522132]
	TIME [epoch: 36.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623740240727502		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.08623740240727502 | validation: 0.1543049228065946]
	TIME [epoch: 36.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08332465111756361		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.08332465111756361 | validation: 0.1542239497067904]
	TIME [epoch: 36.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08357186923594646		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.08357186923594646 | validation: 0.15774691653472928]
	TIME [epoch: 36.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08423955715064738		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.08423955715064738 | validation: 0.15771549406351587]
	TIME [epoch: 36.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08503364937079501		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.08503364937079501 | validation: 0.15118668418483272]
	TIME [epoch: 36.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08368904153253225		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.08368904153253225 | validation: 0.14934018633950152]
	TIME [epoch: 36.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0834012439209031		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.0834012439209031 | validation: 0.14941868818899415]
	TIME [epoch: 36.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08215925243684716		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08215925243684716 | validation: 0.15724528705082141]
	TIME [epoch: 36.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08293852926278257		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.08293852926278257 | validation: 0.15365517082685567]
	TIME [epoch: 36.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08483477817435761		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.08483477817435761 | validation: 0.15471416258645787]
	TIME [epoch: 36.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08471518947519413		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.08471518947519413 | validation: 0.15343556866959912]
	TIME [epoch: 36.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290474876819331		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.08290474876819331 | validation: 0.14980326424321916]
	TIME [epoch: 36.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08248342741084458		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.08248342741084458 | validation: 0.15642326971172582]
	TIME [epoch: 36.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0823397640182997		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.0823397640182997 | validation: 0.14922357350856852]
	TIME [epoch: 36.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08467273262218913		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.08467273262218913 | validation: 0.15550543131505506]
	TIME [epoch: 36.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08644204687969734		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.08644204687969734 | validation: 0.15473469997399097]
	TIME [epoch: 36.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08343446561239938		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.08343446561239938 | validation: 0.15317600321170088]
	TIME [epoch: 36.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08516686661499548		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.08516686661499548 | validation: 0.14557841623301213]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_722.pth
	Model improved!!!
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0834739102147666		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.0834739102147666 | validation: 0.15134521376989854]
	TIME [epoch: 36.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08609610117352612		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08609610117352612 | validation: 0.15427411838392155]
	TIME [epoch: 36.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197222463473794		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.08197222463473794 | validation: 0.15515468714172256]
	TIME [epoch: 36.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08469365774300744		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.08469365774300744 | validation: 0.15538819213268093]
	TIME [epoch: 36.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08513032998017547		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.08513032998017547 | validation: 0.15400835379173186]
	TIME [epoch: 36.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08442656493239395		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.08442656493239395 | validation: 0.15351291589564128]
	TIME [epoch: 36.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08333261540071679		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.08333261540071679 | validation: 0.15514266350037786]
	TIME [epoch: 36.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08649888150785216		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.08649888150785216 | validation: 0.15579560583775345]
	TIME [epoch: 36.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08436111128942365		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.08436111128942365 | validation: 0.1577873212532321]
	TIME [epoch: 36.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08333497071278877		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.08333497071278877 | validation: 0.15246592668399883]
	TIME [epoch: 36.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08393097233204276		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.08393097233204276 | validation: 0.15441790408974543]
	TIME [epoch: 36.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384794828035418		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.08384794828035418 | validation: 0.15508762628577438]
	TIME [epoch: 36.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08404941553020939		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.08404941553020939 | validation: 0.15181504991293038]
	TIME [epoch: 36.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0817903906591591		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.0817903906591591 | validation: 0.15225750348301337]
	TIME [epoch: 36.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464670231839858		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.08464670231839858 | validation: 0.15611727770031628]
	TIME [epoch: 36.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08536269076963664		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.08536269076963664 | validation: 0.14999229589440177]
	TIME [epoch: 36.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.083832141093566		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.083832141093566 | validation: 0.15559533098920256]
	TIME [epoch: 36.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08346362825006207		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.08346362825006207 | validation: 0.15407259781462834]
	TIME [epoch: 36.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08262802415831794		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.08262802415831794 | validation: 0.15132967678592235]
	TIME [epoch: 36.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08443183712487712		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.08443183712487712 | validation: 0.15469485190203294]
	TIME [epoch: 36.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08343503162789431		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.08343503162789431 | validation: 0.15151420772144095]
	TIME [epoch: 36.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08196916532849674		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.08196916532849674 | validation: 0.15757338687300515]
	TIME [epoch: 36.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08389183383806326		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.08389183383806326 | validation: 0.15688678875548445]
	TIME [epoch: 36.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597798796940663		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.08597798796940663 | validation: 0.15476014143843997]
	TIME [epoch: 36.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08341934298363768		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.08341934298363768 | validation: 0.14969829830547704]
	TIME [epoch: 36.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08370816018432473		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.08370816018432473 | validation: 0.15241191293528014]
	TIME [epoch: 36.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08392733828683858		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.08392733828683858 | validation: 0.1517436614835768]
	TIME [epoch: 36.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08416293883453792		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.08416293883453792 | validation: 0.15474741188770616]
	TIME [epoch: 36.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08437942181057805		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.08437942181057805 | validation: 0.1553495351777277]
	TIME [epoch: 36.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08131724163903913		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.08131724163903913 | validation: 0.15206670158032087]
	TIME [epoch: 36.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0837438141517608		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.0837438141517608 | validation: 0.1528137158488304]
	TIME [epoch: 36.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0833076448443924		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.0833076448443924 | validation: 0.15313814400268957]
	TIME [epoch: 36.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08397603844954812		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.08397603844954812 | validation: 0.15196004547847933]
	TIME [epoch: 36.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08376586013845799		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.08376586013845799 | validation: 0.14806049034977212]
	TIME [epoch: 36.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08262906036325168		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.08262906036325168 | validation: 0.15665167924560885]
	TIME [epoch: 36.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583110262177751		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.08583110262177751 | validation: 0.15663530263781678]
	TIME [epoch: 36.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08732677972822818		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.08732677972822818 | validation: 0.15376220779027178]
	TIME [epoch: 36.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08450140330738931		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.08450140330738931 | validation: 0.1526799715963024]
	TIME [epoch: 36.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08608314559527193		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.08608314559527193 | validation: 0.1551827439773253]
	TIME [epoch: 36.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0803302060033513		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.0803302060033513 | validation: 0.15680773739299872]
	TIME [epoch: 36.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08425183729072847		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.08425183729072847 | validation: 0.1590353224762449]
	TIME [epoch: 36.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08266588157172816		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.08266588157172816 | validation: 0.15420596218348803]
	TIME [epoch: 36.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384764977459695		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.08384764977459695 | validation: 0.15574317527829204]
	TIME [epoch: 36.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08339188928660107		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.08339188928660107 | validation: 0.15378793599358226]
	TIME [epoch: 36.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08076110482753769		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.08076110482753769 | validation: 0.1569208510704326]
	TIME [epoch: 36.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08428517129101662		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.08428517129101662 | validation: 0.15663724898743597]
	TIME [epoch: 36.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08341108698920732		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.08341108698920732 | validation: 0.15840202087833244]
	TIME [epoch: 36.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08307703530902665		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.08307703530902665 | validation: 0.15238144597370673]
	TIME [epoch: 36.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08381848901143285		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.08381848901143285 | validation: 0.15446100154733966]
	TIME [epoch: 36.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08273521429022948		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08273521429022948 | validation: 0.15460230899476413]
	TIME [epoch: 36.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08274854812890395		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.08274854812890395 | validation: 0.1518476549543346]
	TIME [epoch: 36.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563759049769806		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.08563759049769806 | validation: 0.1531770358103301]
	TIME [epoch: 36.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347447353487131		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.08347447353487131 | validation: 0.1487928592237025]
	TIME [epoch: 36.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0831767086704975		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0831767086704975 | validation: 0.150400424259828]
	TIME [epoch: 36.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853959854763655		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.0853959854763655 | validation: 0.15305355350466382]
	TIME [epoch: 36.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08164657038595254		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.08164657038595254 | validation: 0.14909968920882616]
	TIME [epoch: 36.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347997183544567		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.08347997183544567 | validation: 0.15315269367604936]
	TIME [epoch: 36.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563015687592554		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08563015687592554 | validation: 0.1553562328303317]
	TIME [epoch: 36.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08238986907523835		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.08238986907523835 | validation: 0.15756003072843464]
	TIME [epoch: 36.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08499497110087914		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.08499497110087914 | validation: 0.15229188397767893]
	TIME [epoch: 36.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08460383616584152		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.08460383616584152 | validation: 0.1540351265937619]
	TIME [epoch: 36.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08283275636879342		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.08283275636879342 | validation: 0.1545027382313542]
	TIME [epoch: 36.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08414447915425984		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.08414447915425984 | validation: 0.15057541516603637]
	TIME [epoch: 36.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08356118960164209		[learning rate: 0.00036793]
	Learning Rate: 0.000367933
	LOSS [training: 0.08356118960164209 | validation: 0.1536928815669095]
	TIME [epoch: 36.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842007863092932		[learning rate: 0.00036631]
	Learning Rate: 0.000366308
	LOSS [training: 0.0842007863092932 | validation: 0.15591182216403895]
	TIME [epoch: 36.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08194379449296565		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.08194379449296565 | validation: 0.1526319525260608]
	TIME [epoch: 36.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286375146701427		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.08286375146701427 | validation: 0.15508949052916787]
	TIME [epoch: 36.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08473691310838888		[learning rate: 0.00036147]
	Learning Rate: 0.000361474
	LOSS [training: 0.08473691310838888 | validation: 0.15387005691937367]
	TIME [epoch: 36.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08223052653148603		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 0.08223052653148603 | validation: 0.15875585539221215]
	TIME [epoch: 36.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08678690696033313		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.08678690696033313 | validation: 0.15518534004068976]
	TIME [epoch: 36.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08525161402910991		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.08525161402910991 | validation: 0.14916917325313359]
	TIME [epoch: 36.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08545540318219204		[learning rate: 0.00035513]
	Learning Rate: 0.000355128
	LOSS [training: 0.08545540318219204 | validation: 0.15099328474102688]
	TIME [epoch: 36.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08431089561701982		[learning rate: 0.00035356]
	Learning Rate: 0.000353559
	LOSS [training: 0.08431089561701982 | validation: 0.15654545079819018]
	TIME [epoch: 36.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0835394477771226		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0835394477771226 | validation: 0.1522322886213667]
	TIME [epoch: 36.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08311595263848637		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.08311595263848637 | validation: 0.15233066949605573]
	TIME [epoch: 36.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08452286993135244		[learning rate: 0.00034889]
	Learning Rate: 0.000348893
	LOSS [training: 0.08452286993135244 | validation: 0.1532327954418764]
	TIME [epoch: 36.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08335814114143913		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.08335814114143913 | validation: 0.1553067865711215]
	TIME [epoch: 36.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08348660160217314		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08348660160217314 | validation: 0.15785617901015614]
	TIME [epoch: 36.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08342314647895008		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.08342314647895008 | validation: 0.15438152164316662]
	TIME [epoch: 36.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08460316124057711		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.08460316124057711 | validation: 0.15501623895706154]
	TIME [epoch: 36.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857854260733091		[learning rate: 0.00034125]
	Learning Rate: 0.000341253
	LOSS [training: 0.0857854260733091 | validation: 0.15446263436793542]
	TIME [epoch: 36.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08189739256937333		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.08189739256937333 | validation: 0.14716822693146184]
	TIME [epoch: 36.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08164839550787964		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.08164839550787964 | validation: 0.15364607220685159]
	TIME [epoch: 36.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08387256718787336		[learning rate: 0.00033675]
	Learning Rate: 0.00033675
	LOSS [training: 0.08387256718787336 | validation: 0.154337183523884]
	TIME [epoch: 36.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08188644654857494		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.08188644654857494 | validation: 0.1507910805537316]
	TIME [epoch: 36.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429807980326617		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.08429807980326617 | validation: 0.14898376701732535]
	TIME [epoch: 36.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458589174463974		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.08458589174463974 | validation: 0.15621014978316153]
	TIME [epoch: 36.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0827324409626286		[learning rate: 0.00033084]
	Learning Rate: 0.000330838
	LOSS [training: 0.0827324409626286 | validation: 0.15143117233814438]
	TIME [epoch: 36.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279978551042816		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.08279978551042816 | validation: 0.15036669914276948]
	TIME [epoch: 36.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08366685881562727		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08366685881562727 | validation: 0.15310948569581873]
	TIME [epoch: 36.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08500344232631771		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.08500344232631771 | validation: 0.15204908024287178]
	TIME [epoch: 36.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08281942743082611		[learning rate: 0.00032503]
	Learning Rate: 0.00032503
	LOSS [training: 0.08281942743082611 | validation: 0.15573091228706062]
	TIME [epoch: 36.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08124562173087728		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: 0.08124562173087728 | validation: 0.15638876108460797]
	TIME [epoch: 36.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08542268335485981		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08542268335485981 | validation: 0.15383379735400335]
	TIME [epoch: 36.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08284385640121851		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.08284385640121851 | validation: 0.15393684910032893]
	TIME [epoch: 36.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08221579641195877		[learning rate: 0.00031932]
	Learning Rate: 0.000319323
	LOSS [training: 0.08221579641195877 | validation: 0.1550770105361282]
	TIME [epoch: 36.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08511136825070005		[learning rate: 0.00031791]
	Learning Rate: 0.000317913
	LOSS [training: 0.08511136825070005 | validation: 0.1557207532822607]
	TIME [epoch: 36.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08372688353780142		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08372688353780142 | validation: 0.1534416113435673]
	TIME [epoch: 36.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08324539402406746		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.08324539402406746 | validation: 0.1484982581734634]
	TIME [epoch: 36.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448057113673958		[learning rate: 0.00031372]
	Learning Rate: 0.000313717
	LOSS [training: 0.08448057113673958 | validation: 0.15013704308386489]
	TIME [epoch: 36.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08562627875366333		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: 0.08562627875366333 | validation: 0.15033708238289661]
	TIME [epoch: 36.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08305166440146383		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.08305166440146383 | validation: 0.1523335128787063]
	TIME [epoch: 36.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286769577097866		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.08286769577097866 | validation: 0.1491671921366667]
	TIME [epoch: 36.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666951877235807		[learning rate: 0.00030821]
	Learning Rate: 0.00030821
	LOSS [training: 0.08666951877235807 | validation: 0.15256760212049555]
	TIME [epoch: 36.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271377976857179		[learning rate: 0.00030685]
	Learning Rate: 0.000306848
	LOSS [training: 0.08271377976857179 | validation: 0.14922634682037011]
	TIME [epoch: 36.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08422683147178986		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08422683147178986 | validation: 0.15537919916419135]
	TIME [epoch: 36.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08267551882915827		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.08267551882915827 | validation: 0.1563020107755786]
	TIME [epoch: 36.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08261827947095782		[learning rate: 0.0003028]
	Learning Rate: 0.000302799
	LOSS [training: 0.08261827947095782 | validation: 0.1533494579043898]
	TIME [epoch: 36.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08300788168192304		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: 0.08300788168192304 | validation: 0.15329987841621273]
	TIME [epoch: 36.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08382186974000637		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.08382186974000637 | validation: 0.15171761305611012]
	TIME [epoch: 36.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0837799569566616		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.0837799569566616 | validation: 0.15513499698570019]
	TIME [epoch: 36.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086233812675925		[learning rate: 0.00029748]
	Learning Rate: 0.000297483
	LOSS [training: 0.086233812675925 | validation: 0.15567198557649758]
	TIME [epoch: 36.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592369172701368		[learning rate: 0.00029617]
	Learning Rate: 0.000296168
	LOSS [training: 0.08592369172701368 | validation: 0.1538509669822802]
	TIME [epoch: 36.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08276409707254062		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08276409707254062 | validation: 0.15422529353842251]
	TIME [epoch: 36.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08234630716439713		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.08234630716439713 | validation: 0.15490546554994333]
	TIME [epoch: 36.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08324156121748079		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.08324156121748079 | validation: 0.15334178096209178]
	TIME [epoch: 36.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08409796074329574		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: 0.08409796074329574 | validation: 0.15340008295463442]
	TIME [epoch: 36.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0832020585047415		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0832020585047415 | validation: 0.14769675848853964]
	TIME [epoch: 36.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08256977911187109		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.08256977911187109 | validation: 0.15213892958825123]
	TIME [epoch: 36.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08178129030908896		[learning rate: 0.00028713]
	Learning Rate: 0.000287129
	LOSS [training: 0.08178129030908896 | validation: 0.15204725083118864]
	TIME [epoch: 36.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08513941141326302		[learning rate: 0.00028586]
	Learning Rate: 0.00028586
	LOSS [training: 0.08513941141326302 | validation: 0.15066668186689303]
	TIME [epoch: 36.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08370376365254553		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08370376365254553 | validation: 0.15601190929988185]
	TIME [epoch: 36.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08459257661022442		[learning rate: 0.00028334]
	Learning Rate: 0.00028334
	LOSS [training: 0.08459257661022442 | validation: 0.15226659145936888]
	TIME [epoch: 36.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08189839089545903		[learning rate: 0.00028209]
	Learning Rate: 0.000282088
	LOSS [training: 0.08189839089545903 | validation: 0.15313798193311245]
	TIME [epoch: 36.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08403970977176281		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.08403970977176281 | validation: 0.15628969264652878]
	TIME [epoch: 36.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08447485192819021		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.08447485192819021 | validation: 0.1583766407948405]
	TIME [epoch: 36.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08317143300996857		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.08317143300996857 | validation: 0.1577837621232704]
	TIME [epoch: 36.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08249909141287079		[learning rate: 0.00027714]
	Learning Rate: 0.000277136
	LOSS [training: 0.08249909141287079 | validation: 0.1541028297846705]
	TIME [epoch: 36.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402680750431091		[learning rate: 0.00027591]
	Learning Rate: 0.000275911
	LOSS [training: 0.08402680750431091 | validation: 0.15089867605858145]
	TIME [epoch: 36.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08432695901029168		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.08432695901029168 | validation: 0.1507594874332837]
	TIME [epoch: 36.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439819453126264		[learning rate: 0.00027348]
	Learning Rate: 0.000273479
	LOSS [training: 0.08439819453126264 | validation: 0.15460580803823828]
	TIME [epoch: 36.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0838015594923063		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.0838015594923063 | validation: 0.15015205279454283]
	TIME [epoch: 36.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08408624067335693		[learning rate: 0.00027107]
	Learning Rate: 0.000271067
	LOSS [training: 0.08408624067335693 | validation: 0.15324528760284653]
	TIME [epoch: 36.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08471612063302174		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08471612063302174 | validation: 0.15227808589457204]
	TIME [epoch: 36.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08336118049388898		[learning rate: 0.00026868]
	Learning Rate: 0.000268677
	LOSS [training: 0.08336118049388898 | validation: 0.15730177846103863]
	TIME [epoch: 36.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08153831666594212		[learning rate: 0.00026749]
	Learning Rate: 0.00026749
	LOSS [training: 0.08153831666594212 | validation: 0.15192879843485857]
	TIME [epoch: 36.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08334351160901013		[learning rate: 0.00026631]
	Learning Rate: 0.000266308
	LOSS [training: 0.08334351160901013 | validation: 0.15634630123104581]
	TIME [epoch: 36.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396688668953135		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08396688668953135 | validation: 0.1559637105342535]
	TIME [epoch: 36.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08587063042259475		[learning rate: 0.00026396]
	Learning Rate: 0.00026396
	LOSS [training: 0.08587063042259475 | validation: 0.15277271994467378]
	TIME [epoch: 36.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08547039257323373		[learning rate: 0.00026279]
	Learning Rate: 0.000262794
	LOSS [training: 0.08547039257323373 | validation: 0.1520651355768026]
	TIME [epoch: 36.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08078376150048312		[learning rate: 0.00026163]
	Learning Rate: 0.000261633
	LOSS [training: 0.08078376150048312 | validation: 0.15487938978756535]
	TIME [epoch: 36.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08328264779458157		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.08328264779458157 | validation: 0.15357830424221036]
	TIME [epoch: 36.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08112877667429631		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.08112877667429631 | validation: 0.1521248369488468]
	TIME [epoch: 36.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08378961724865522		[learning rate: 0.00025818]
	Learning Rate: 0.00025818
	LOSS [training: 0.08378961724865522 | validation: 0.1485588628544261]
	TIME [epoch: 36.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592590163331199		[learning rate: 0.00025704]
	Learning Rate: 0.00025704
	LOSS [training: 0.08592590163331199 | validation: 0.15201769654228145]
	TIME [epoch: 36.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08372178006874728		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08372178006874728 | validation: 0.1528441409256049]
	TIME [epoch: 36.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271979566563938		[learning rate: 0.00025477]
	Learning Rate: 0.000254773
	LOSS [training: 0.08271979566563938 | validation: 0.15957870300440485]
	TIME [epoch: 36.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08496594952205302		[learning rate: 0.00025365]
	Learning Rate: 0.000253648
	LOSS [training: 0.08496594952205302 | validation: 0.15371135241397016]
	TIME [epoch: 36.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08570578439778934		[learning rate: 0.00025253]
	Learning Rate: 0.000252527
	LOSS [training: 0.08570578439778934 | validation: 0.1527178473736289]
	TIME [epoch: 36.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0843703204503273		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0843703204503273 | validation: 0.15500273535256892]
	TIME [epoch: 36.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475024265067228		[learning rate: 0.0002503]
	Learning Rate: 0.0002503
	LOSS [training: 0.08475024265067228 | validation: 0.15008089530887214]
	TIME [epoch: 36.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08263544040299844		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.08263544040299844 | validation: 0.15216654097794996]
	TIME [epoch: 36.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08435528178911485		[learning rate: 0.00024809]
	Learning Rate: 0.000248094
	LOSS [training: 0.08435528178911485 | validation: 0.1552072855945996]
	TIME [epoch: 36.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08344968738662716		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.08344968738662716 | validation: 0.15248752020385203]
	TIME [epoch: 36.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367029126868668		[learning rate: 0.00024591]
	Learning Rate: 0.000245906
	LOSS [training: 0.08367029126868668 | validation: 0.15106627091675626]
	TIME [epoch: 36.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08443557811673326		[learning rate: 0.00024482]
	Learning Rate: 0.00024482
	LOSS [training: 0.08443557811673326 | validation: 0.15186463360610405]
	TIME [epoch: 36.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08297566947449991		[learning rate: 0.00024374]
	Learning Rate: 0.000243738
	LOSS [training: 0.08297566947449991 | validation: 0.15443136734612342]
	TIME [epoch: 36.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08421778579106524		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.08421778579106524 | validation: 0.14989288076332224]
	TIME [epoch: 36.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08483495168480387		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.08483495168480387 | validation: 0.15801011296788103]
	TIME [epoch: 36.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08362071840184716		[learning rate: 0.00024052]
	Learning Rate: 0.000240521
	LOSS [training: 0.08362071840184716 | validation: 0.15710743111776582]
	TIME [epoch: 36.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0818008554494741		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.0818008554494741 | validation: 0.1504734547434548]
	TIME [epoch: 36.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0855493698360113		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0855493698360113 | validation: 0.15520888477728126]
	TIME [epoch: 36.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08309264894597601		[learning rate: 0.00023735]
	Learning Rate: 0.000237348
	LOSS [training: 0.08309264894597601 | validation: 0.15131871803575675]
	TIME [epoch: 36.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08348779223711154		[learning rate: 0.0002363]
	Learning Rate: 0.000236299
	LOSS [training: 0.08348779223711154 | validation: 0.15490667420850546]
	TIME [epoch: 36.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08480647519027555		[learning rate: 0.00023525]
	Learning Rate: 0.000235255
	LOSS [training: 0.08480647519027555 | validation: 0.15423206630781786]
	TIME [epoch: 36.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396516945334373		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.08396516945334373 | validation: 0.15265259402575948]
	TIME [epoch: 36.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08184768669961594		[learning rate: 0.00023318]
	Learning Rate: 0.000233181
	LOSS [training: 0.08184768669961594 | validation: 0.15055212316417835]
	TIME [epoch: 36.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08477701770304265		[learning rate: 0.00023215]
	Learning Rate: 0.00023215
	LOSS [training: 0.08477701770304265 | validation: 0.15096305329252294]
	TIME [epoch: 36.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08603480936292046		[learning rate: 0.00023112]
	Learning Rate: 0.000231125
	LOSS [training: 0.08603480936292046 | validation: 0.15481374255645486]
	TIME [epoch: 36.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08334999258084676		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08334999258084676 | validation: 0.15041549501633092]
	TIME [epoch: 36.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08299885380093339		[learning rate: 0.00022909]
	Learning Rate: 0.000229087
	LOSS [training: 0.08299885380093339 | validation: 0.1531435587119659]
	TIME [epoch: 36.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08406182107619554		[learning rate: 0.00022807]
	Learning Rate: 0.000228075
	LOSS [training: 0.08406182107619554 | validation: 0.150960664431099]
	TIME [epoch: 36.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08318478668586374		[learning rate: 0.00022707]
	Learning Rate: 0.000227067
	LOSS [training: 0.08318478668586374 | validation: 0.15703867968459131]
	TIME [epoch: 36.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285163578705694		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.08285163578705694 | validation: 0.15202166865050798]
	TIME [epoch: 36.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08273238801787189		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.08273238801787189 | validation: 0.15310831893101262]
	TIME [epoch: 36.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08379533787618754		[learning rate: 0.00022407]
	Learning Rate: 0.00022407
	LOSS [training: 0.08379533787618754 | validation: 0.15151527832532033]
	TIME [epoch: 36.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08427719195933588		[learning rate: 0.00022308]
	Learning Rate: 0.000223081
	LOSS [training: 0.08427719195933588 | validation: 0.15285410107353284]
	TIME [epoch: 36.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08163013376315502		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.08163013376315502 | validation: 0.15067047254056287]
	TIME [epoch: 36.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08400885060479316		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.08400885060479316 | validation: 0.15092270515135892]
	TIME [epoch: 36.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08352888836173447		[learning rate: 0.00022014]
	Learning Rate: 0.000220137
	LOSS [training: 0.08352888836173447 | validation: 0.15130532529713733]
	TIME [epoch: 36.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08423654980445819		[learning rate: 0.00021916]
	Learning Rate: 0.000219164
	LOSS [training: 0.08423654980445819 | validation: 0.14691000443312918]
	TIME [epoch: 36.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08460546711321192		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.08460546711321192 | validation: 0.15148652107870475]
	TIME [epoch: 36.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842978489488492		[learning rate: 0.00021723]
	Learning Rate: 0.000217232
	LOSS [training: 0.0842978489488492 | validation: 0.15497265222792314]
	TIME [epoch: 36.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08158431331525995		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.08158431331525995 | validation: 0.15214963456469718]
	TIME [epoch: 36.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08362338409175721		[learning rate: 0.00021532]
	Learning Rate: 0.000215316
	LOSS [training: 0.08362338409175721 | validation: 0.15449280976589586]
	TIME [epoch: 36.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.082310479971369		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.082310479971369 | validation: 0.15395579449800278]
	TIME [epoch: 36.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08492916002422048		[learning rate: 0.00021342]
	Learning Rate: 0.000213418
	LOSS [training: 0.08492916002422048 | validation: 0.15857833188290352]
	TIME [epoch: 36.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08511426579845364		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.08511426579845364 | validation: 0.15508132998684465]
	TIME [epoch: 36.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0820410095823805		[learning rate: 0.00021154]
	Learning Rate: 0.000211536
	LOSS [training: 0.0820410095823805 | validation: 0.15044563378043083]
	TIME [epoch: 36.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08483761209421029		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.08483761209421029 | validation: 0.14917953259865735]
	TIME [epoch: 36.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08151178987445135		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.08151178987445135 | validation: 0.15466524224897815]
	TIME [epoch: 36.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08573354731229207		[learning rate: 0.00020874]
	Learning Rate: 0.000208745
	LOSS [training: 0.08573354731229207 | validation: 0.1473020822304632]
	TIME [epoch: 36.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260633995784311		[learning rate: 0.00020782]
	Learning Rate: 0.000207822
	LOSS [training: 0.08260633995784311 | validation: 0.15094009373392844]
	TIME [epoch: 36.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08217403553905735		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08217403553905735 | validation: 0.15193606906602866]
	TIME [epoch: 36.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08407588867757522		[learning rate: 0.00020599]
	Learning Rate: 0.00020599
	LOSS [training: 0.08407588867757522 | validation: 0.1516356529546127]
	TIME [epoch: 36.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08459333494390356		[learning rate: 0.00020508]
	Learning Rate: 0.00020508
	LOSS [training: 0.08459333494390356 | validation: 0.15193748771977794]
	TIME [epoch: 36.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826807659348836		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.0826807659348836 | validation: 0.15638786593487392]
	TIME [epoch: 36.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08414071934271507		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.08414071934271507 | validation: 0.15486159911668712]
	TIME [epoch: 36.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08505154404561759		[learning rate: 0.00020237]
	Learning Rate: 0.000202374
	LOSS [training: 0.08505154404561759 | validation: 0.15516977124402673]
	TIME [epoch: 36.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08298343932376159		[learning rate: 0.00020148]
	Learning Rate: 0.000201479
	LOSS [training: 0.08298343932376159 | validation: 0.1541563929145375]
	TIME [epoch: 36.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285487433970454		[learning rate: 0.00020059]
	Learning Rate: 0.000200589
	LOSS [training: 0.08285487433970454 | validation: 0.15290735319074358]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2a_2dpca_v1_20240627_193025/states/model_facs_dec2a_2dpca_v1_923.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 33757.288 seconds.
