Args:
Namespace(name='model_phiq_1a_v_mmd1', outdir='out/model_training/model_phiq_1a_v_mmd1', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.01, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1728419547

Training model...

Saving initial model state to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.262078272580564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.262078272580564 | validation: 4.508294945543822]
	TIME [epoch: 102 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.273648407325297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.273648407325297 | validation: 4.109915943532636]
	TIME [epoch: 8.56 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9586827135379217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9586827135379217 | validation: 3.989309965191097]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.854581032683898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.854581032683898 | validation: 3.9376426792282944]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.7906089484236203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7906089484236203 | validation: 3.8650251755506644]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.757904860062401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.757904860062401 | validation: 3.7787372980491885]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.5317388060232258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5317388060232258 | validation: 3.518650064349208]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3460783101210807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3460783101210807 | validation: 3.549152349117165]
	TIME [epoch: 8.33 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.245722416097873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.245722416097873 | validation: 3.235969452449586]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.996055185649468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.996055185649468 | validation: 3.209287296917897]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9710773763050504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9710773763050504 | validation: 2.971157703794761]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8879946377093573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8879946377093573 | validation: 2.9494385362770936]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.758812776490683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.758812776490683 | validation: 2.8524220656445083]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.678613059995533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.678613059995533 | validation: 2.716381092335138]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5718006851220756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5718006851220756 | validation: 2.62306362120699]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.57299778596945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.57299778596945 | validation: 2.6109601960997804]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.457807002568074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.457807002568074 | validation: 2.503734002742213]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4116346108571785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4116346108571785 | validation: 2.414550058643095]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.315595751506932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.315595751506932 | validation: 2.352049423415001]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.316406432941784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.316406432941784 | validation: 2.326893213284814]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.20902195663559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.20902195663559 | validation: 2.2277148748519973]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.168540666447367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.168540666447367 | validation: 2.1715615893223683]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0749587171884047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0749587171884047 | validation: 2.159446074616585]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0472652031444722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0472652031444722 | validation: 2.066017402435654]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0073460287269906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0073460287269906 | validation: 1.9841362082994234]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9317108711572484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9317108711572484 | validation: 2.135335230559132]
	TIME [epoch: 8.32 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9579052478613839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9579052478613839 | validation: 1.881997232430187]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8337565079856857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8337565079856857 | validation: 1.797745950755251]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7931637551123198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7931637551123198 | validation: 1.7551893074633838]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7569125131846066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7569125131846066 | validation: 1.6877309333844939]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.701940842903844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.701940842903844 | validation: 1.7805389511749659]
	TIME [epoch: 8.33 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7263749572483444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7263749572483444 | validation: 1.668917793316365]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6224503263499428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6224503263499428 | validation: 1.6035519612695945]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5867701913931893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5867701913931893 | validation: 1.5762290730195057]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5544597405288811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5544597405288811 | validation: 1.5598217767018894]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5155642217160579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5155642217160579 | validation: 1.5049542947016206]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4757853131909817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4757853131909817 | validation: 1.489042199509182]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3989461039676119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3989461039676119 | validation: 1.4295262502776938]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5070043511364821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5070043511364821 | validation: 1.4399434068297499]
	TIME [epoch: 8.45 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3940298403754847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3940298403754847 | validation: 1.3784758063190345]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3206162113269386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3206162113269386 | validation: 1.3569109025061172]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.338815478854416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.338815478854416 | validation: 1.4024034370184388]
	TIME [epoch: 8.42 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3987654897078616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3987654897078616 | validation: 1.3407337035396185]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3283505353816578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3283505353816578 | validation: 1.3206779538768627]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3069432515589674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3069432515589674 | validation: 1.3052576575928938]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2729727643000666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2729727643000666 | validation: 1.2853985251240616]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2436482787675587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2436482787675587 | validation: 1.4507447294357536]
	TIME [epoch: 8.42 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117836799470617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3117836799470617 | validation: 1.2511970345663488]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2227424573189831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2227424573189831 | validation: 1.256558441248544]
	TIME [epoch: 8.46 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.227354721241545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.227354721241545 | validation: 1.1840491885910593]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1946796947623013		[learning rate: 0.0099456]
	Learning Rate: 0.00994561
	LOSS [training: 1.1946796947623013 | validation: 1.1685237329863036]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2100124874064133		[learning rate: 0.0098736]
	Learning Rate: 0.00987356
	LOSS [training: 1.2100124874064133 | validation: 1.1900886034091172]
	TIME [epoch: 8.44 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1740464965035962		[learning rate: 0.009802]
	Learning Rate: 0.00980202
	LOSS [training: 1.1740464965035962 | validation: 1.1616870391224223]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.187392569059364		[learning rate: 0.009731]
	Learning Rate: 0.00973101
	LOSS [training: 1.187392569059364 | validation: 1.120258053936959]
	TIME [epoch: 8.49 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1582377617962982		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.1582377617962982 | validation: 1.1327402888664553]
	TIME [epoch: 8.45 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1851073682941389		[learning rate: 0.0095905]
	Learning Rate: 0.00959052
	LOSS [training: 1.1851073682941389 | validation: 1.1151343148013755]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1330774106751318		[learning rate: 0.009521]
	Learning Rate: 0.00952104
	LOSS [training: 1.1330774106751318 | validation: 1.106928628740754]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1655731737739765		[learning rate: 0.0094521]
	Learning Rate: 0.00945206
	LOSS [training: 1.1655731737739765 | validation: 1.154391193080314]
	TIME [epoch: 8.42 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379141381613949		[learning rate: 0.0093836]
	Learning Rate: 0.00938358
	LOSS [training: 1.1379141381613949 | validation: 1.172257371810797]
	TIME [epoch: 8.36 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1290462131858194		[learning rate: 0.0093156]
	Learning Rate: 0.00931559
	LOSS [training: 1.1290462131858194 | validation: 1.0249699458047932]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1300019600472564		[learning rate: 0.0092481]
	Learning Rate: 0.0092481
	LOSS [training: 1.1300019600472564 | validation: 1.0921027433956079]
	TIME [epoch: 8.4 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362776742483685		[learning rate: 0.0091811]
	Learning Rate: 0.0091811
	LOSS [training: 1.1362776742483685 | validation: 1.1217639055266408]
	TIME [epoch: 8.33 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0782976330910907		[learning rate: 0.0091146]
	Learning Rate: 0.00911458
	LOSS [training: 1.0782976330910907 | validation: 1.0167864105949098]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1260723098550431		[learning rate: 0.0090485]
	Learning Rate: 0.00904855
	LOSS [training: 1.1260723098550431 | validation: 1.0814611553865763]
	TIME [epoch: 8.46 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629679147141626		[learning rate: 0.008983]
	Learning Rate: 0.00898299
	LOSS [training: 1.0629679147141626 | validation: 1.1118157580484054]
	TIME [epoch: 8.38 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1540418259524425		[learning rate: 0.0089179]
	Learning Rate: 0.00891791
	LOSS [training: 1.1540418259524425 | validation: 1.1359088401566924]
	TIME [epoch: 8.33 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0803418678265526		[learning rate: 0.0088533]
	Learning Rate: 0.0088533
	LOSS [training: 1.0803418678265526 | validation: 0.9971681902450016]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0916067012367752		[learning rate: 0.0087892]
	Learning Rate: 0.00878916
	LOSS [training: 1.0916067012367752 | validation: 1.0131110893651845]
	TIME [epoch: 8.41 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0441786870018308		[learning rate: 0.0087255]
	Learning Rate: 0.00872548
	LOSS [training: 1.0441786870018308 | validation: 0.9985515410432437]
	TIME [epoch: 8.33 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655339052459565		[learning rate: 0.0086623]
	Learning Rate: 0.00866227
	LOSS [training: 1.0655339052459565 | validation: 1.016742933719777]
	TIME [epoch: 8.39 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.060483748451305		[learning rate: 0.0085995]
	Learning Rate: 0.00859951
	LOSS [training: 1.060483748451305 | validation: 0.9481726349529289]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9967200235621967		[learning rate: 0.0085372]
	Learning Rate: 0.00853721
	LOSS [training: 0.9967200235621967 | validation: 0.9576965419909895]
	TIME [epoch: 8.43 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0678468485445118		[learning rate: 0.0084754]
	Learning Rate: 0.00847535
	LOSS [training: 1.0678468485445118 | validation: 1.0771448835978794]
	TIME [epoch: 8.34 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648711862320408		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.0648711862320408 | validation: 1.0119113901110945]
	TIME [epoch: 8.33 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612498477704528		[learning rate: 0.008353]
	Learning Rate: 0.00835299
	LOSS [training: 1.0612498477704528 | validation: 0.9543077436583434]
	TIME [epoch: 8.36 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0431896091878412		[learning rate: 0.0082925]
	Learning Rate: 0.00829248
	LOSS [training: 1.0431896091878412 | validation: 1.082647764519327]
	TIME [epoch: 8.36 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0131792480665904		[learning rate: 0.0082324]
	Learning Rate: 0.0082324
	LOSS [training: 1.0131792480665904 | validation: 0.9279635747225979]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.121603409015543		[learning rate: 0.0081728]
	Learning Rate: 0.00817275
	LOSS [training: 1.121603409015543 | validation: 1.0220285673773186]
	TIME [epoch: 8.42 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256267472828562		[learning rate: 0.0081135]
	Learning Rate: 0.00811354
	LOSS [training: 1.0256267472828562 | validation: 0.8990964503812546]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.974892917667906		[learning rate: 0.0080548]
	Learning Rate: 0.00805476
	LOSS [training: 0.974892917667906 | validation: 1.318402296012235]
	TIME [epoch: 8.42 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1054170803113907		[learning rate: 0.0079964]
	Learning Rate: 0.0079964
	LOSS [training: 1.1054170803113907 | validation: 0.965493484436843]
	TIME [epoch: 8.36 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9387390242311371		[learning rate: 0.0079385]
	Learning Rate: 0.00793847
	LOSS [training: 0.9387390242311371 | validation: 1.0004306240031897]
	TIME [epoch: 8.32 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575926764089185		[learning rate: 0.007881]
	Learning Rate: 0.00788096
	LOSS [training: 1.0575926764089185 | validation: 1.0287490145955456]
	TIME [epoch: 8.31 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9697908151015265		[learning rate: 0.0078239]
	Learning Rate: 0.00782386
	LOSS [training: 0.9697908151015265 | validation: 1.0885535869457257]
	TIME [epoch: 8.33 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0445831526811677		[learning rate: 0.0077672]
	Learning Rate: 0.00776718
	LOSS [training: 1.0445831526811677 | validation: 1.0600873689921197]
	TIME [epoch: 8.32 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.053981709538438		[learning rate: 0.0077109]
	Learning Rate: 0.0077109
	LOSS [training: 1.053981709538438 | validation: 0.9548286149482822]
	TIME [epoch: 8.35 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9342415763479269		[learning rate: 0.007655]
	Learning Rate: 0.00765504
	LOSS [training: 0.9342415763479269 | validation: 0.922347688516965]
	TIME [epoch: 8.33 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9645791419830503		[learning rate: 0.0075996]
	Learning Rate: 0.00759958
	LOSS [training: 0.9645791419830503 | validation: 1.083137310603342]
	TIME [epoch: 8.31 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0119701749020282		[learning rate: 0.0075445]
	Learning Rate: 0.00754452
	LOSS [training: 1.0119701749020282 | validation: 0.9191599227714405]
	TIME [epoch: 8.33 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9920550480097172		[learning rate: 0.0074899]
	Learning Rate: 0.00748986
	LOSS [training: 0.9920550480097172 | validation: 0.8972428496061211]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9792402580977576		[learning rate: 0.0074356]
	Learning Rate: 0.0074356
	LOSS [training: 0.9792402580977576 | validation: 1.1878078440782283]
	TIME [epoch: 8.4 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554132745350283		[learning rate: 0.0073817]
	Learning Rate: 0.00738173
	LOSS [training: 1.1554132745350283 | validation: 1.0276351189790218]
	TIME [epoch: 8.38 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9980621900970003		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9980621900970003 | validation: 0.9147462943141482]
	TIME [epoch: 8.34 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100617858397446		[learning rate: 0.0072752]
	Learning Rate: 0.00727515
	LOSS [training: 0.9100617858397446 | validation: 1.0821849510133883]
	TIME [epoch: 8.33 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604479602902332		[learning rate: 0.0072224]
	Learning Rate: 0.00722244
	LOSS [training: 1.0604479602902332 | validation: 0.8579386594212253]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8640097787933425		[learning rate: 0.0071701]
	Learning Rate: 0.00717012
	LOSS [training: 0.8640097787933425 | validation: 0.892713061641276]
	TIME [epoch: 8.4 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9019013285778543		[learning rate: 0.0071182]
	Learning Rate: 0.00711817
	LOSS [training: 0.9019013285778543 | validation: 1.1116288328087744]
	TIME [epoch: 8.36 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0173410176173472		[learning rate: 0.0070666]
	Learning Rate: 0.0070666
	LOSS [training: 1.0173410176173472 | validation: 0.8665918307137555]
	TIME [epoch: 8.34 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8261183722154077		[learning rate: 0.0070154]
	Learning Rate: 0.0070154
	LOSS [training: 0.8261183722154077 | validation: 0.9123164237062509]
	TIME [epoch: 8.33 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9307527589206825		[learning rate: 0.0069646]
	Learning Rate: 0.00696458
	LOSS [training: 0.9307527589206825 | validation: 0.9075589848045307]
	TIME [epoch: 8.33 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9286129960887968		[learning rate: 0.0069141]
	Learning Rate: 0.00691412
	LOSS [training: 0.9286129960887968 | validation: 0.8160103045322935]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8735184844838038		[learning rate: 0.006864]
	Learning Rate: 0.00686403
	LOSS [training: 0.8735184844838038 | validation: 0.8616751049559466]
	TIME [epoch: 8.34 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9456703582392806		[learning rate: 0.0068143]
	Learning Rate: 0.0068143
	LOSS [training: 0.9456703582392806 | validation: 0.8742765172257897]
	TIME [epoch: 8.37 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816277047659737		[learning rate: 0.0067649]
	Learning Rate: 0.00676493
	LOSS [training: 0.8816277047659737 | validation: 0.8009688714442573]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9744774161851176		[learning rate: 0.0067159]
	Learning Rate: 0.00671592
	LOSS [training: 0.9744774161851176 | validation: 1.047154528121913]
	TIME [epoch: 8.35 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231143633891042		[learning rate: 0.0066673]
	Learning Rate: 0.00666726
	LOSS [training: 1.0231143633891042 | validation: 0.944857524438003]
	TIME [epoch: 8.35 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9037987482449379		[learning rate: 0.006619]
	Learning Rate: 0.00661896
	LOSS [training: 0.9037987482449379 | validation: 0.7877908182736604]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8236183322727494		[learning rate: 0.006571]
	Learning Rate: 0.006571
	LOSS [training: 0.8236183322727494 | validation: 0.938250540697172]
	TIME [epoch: 8.39 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9746835859312033		[learning rate: 0.0065234]
	Learning Rate: 0.00652339
	LOSS [training: 0.9746835859312033 | validation: 0.889248048327657]
	TIME [epoch: 8.35 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9255572149652318		[learning rate: 0.0064761]
	Learning Rate: 0.00647613
	LOSS [training: 0.9255572149652318 | validation: 0.874085922948276]
	TIME [epoch: 8.34 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753840188939177		[learning rate: 0.0064292]
	Learning Rate: 0.00642921
	LOSS [training: 0.8753840188939177 | validation: 0.9923899788445079]
	TIME [epoch: 8.33 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9656902137422511		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.9656902137422511 | validation: 0.7897426085785909]
	TIME [epoch: 8.34 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0170076416490883		[learning rate: 0.0063364]
	Learning Rate: 0.00633639
	LOSS [training: 1.0170076416490883 | validation: 0.9554709945747811]
	TIME [epoch: 8.35 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9736516685812537		[learning rate: 0.0062905]
	Learning Rate: 0.00629049
	LOSS [training: 0.9736516685812537 | validation: 0.9174072186330242]
	TIME [epoch: 8.38 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9321911212382503		[learning rate: 0.0062449]
	Learning Rate: 0.00624491
	LOSS [training: 0.9321911212382503 | validation: 0.8645252744496643]
	TIME [epoch: 8.35 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.896163073524809		[learning rate: 0.0061997]
	Learning Rate: 0.00619967
	LOSS [training: 0.896163073524809 | validation: 0.8044864171053279]
	TIME [epoch: 8.34 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7599580473197679		[learning rate: 0.0061548]
	Learning Rate: 0.00615475
	LOSS [training: 0.7599580473197679 | validation: 1.1138172542404057]
	TIME [epoch: 8.34 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0442279591345955		[learning rate: 0.0061102]
	Learning Rate: 0.00611016
	LOSS [training: 1.0442279591345955 | validation: 0.9300588053102226]
	TIME [epoch: 8.34 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8678178228755238		[learning rate: 0.0060659]
	Learning Rate: 0.00606589
	LOSS [training: 0.8678178228755238 | validation: 0.9360595370319214]
	TIME [epoch: 8.39 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8664899391285656		[learning rate: 0.0060219]
	Learning Rate: 0.00602195
	LOSS [training: 0.8664899391285656 | validation: 0.7746195319274083]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_120.pth
	Model improved!!!
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485681288781593		[learning rate: 0.0059783]
	Learning Rate: 0.00597832
	LOSS [training: 0.7485681288781593 | validation: 0.9802283736749685]
	TIME [epoch: 8.35 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8835137023079493		[learning rate: 0.005935]
	Learning Rate: 0.005935
	LOSS [training: 0.8835137023079493 | validation: 0.7198464150623038]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607462514134831		[learning rate: 0.005892]
	Learning Rate: 0.00589201
	LOSS [training: 0.7607462514134831 | validation: 0.866976929296261]
	TIME [epoch: 8.34 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.89607603722427		[learning rate: 0.0058493]
	Learning Rate: 0.00584932
	LOSS [training: 0.89607603722427 | validation: 0.9204059388828366]
	TIME [epoch: 8.35 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9175836858356547		[learning rate: 0.0058069]
	Learning Rate: 0.00580694
	LOSS [training: 0.9175836858356547 | validation: 0.8065853829187158]
	TIME [epoch: 8.37 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750243952414542		[learning rate: 0.0057649]
	Learning Rate: 0.00576487
	LOSS [training: 0.7750243952414542 | validation: 0.8962113144055165]
	TIME [epoch: 8.33 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191048655546183		[learning rate: 0.0057231]
	Learning Rate: 0.0057231
	LOSS [training: 0.8191048655546183 | validation: 0.6598248561567917]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7150798094915154		[learning rate: 0.0056816]
	Learning Rate: 0.00568164
	LOSS [training: 0.7150798094915154 | validation: 0.8898733497778619]
	TIME [epoch: 8.34 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104998282939786		[learning rate: 0.0056405]
	Learning Rate: 0.00564048
	LOSS [training: 0.8104998282939786 | validation: 0.8029684824197285]
	TIME [epoch: 8.33 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7969297210685148		[learning rate: 0.0055996]
	Learning Rate: 0.00559961
	LOSS [training: 0.7969297210685148 | validation: 1.0690165625156507]
	TIME [epoch: 8.36 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108164568782356		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8108164568782356 | validation: 0.7585345266127734]
	TIME [epoch: 8.35 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734398181238062		[learning rate: 0.0055188]
	Learning Rate: 0.00551877
	LOSS [training: 0.7734398181238062 | validation: 0.8131303959692122]
	TIME [epoch: 8.33 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692814368528808		[learning rate: 0.0054788]
	Learning Rate: 0.00547878
	LOSS [training: 0.7692814368528808 | validation: 0.7535110112946721]
	TIME [epoch: 8.34 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837973427766884		[learning rate: 0.0054391]
	Learning Rate: 0.00543909
	LOSS [training: 0.6837973427766884 | validation: 0.8780576528172437]
	TIME [epoch: 8.33 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7785920544131247		[learning rate: 0.0053997]
	Learning Rate: 0.00539968
	LOSS [training: 0.7785920544131247 | validation: 0.6867338394679378]
	TIME [epoch: 8.34 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042834943203353		[learning rate: 0.0053606]
	Learning Rate: 0.00536056
	LOSS [training: 0.7042834943203353 | validation: 0.943489554553085]
	TIME [epoch: 8.38 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582913282164604		[learning rate: 0.0053217]
	Learning Rate: 0.00532173
	LOSS [training: 0.8582913282164604 | validation: 0.7926085933530127]
	TIME [epoch: 8.33 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8241996443406419		[learning rate: 0.0052832]
	Learning Rate: 0.00528317
	LOSS [training: 0.8241996443406419 | validation: 0.6591534213812567]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700405798393328		[learning rate: 0.0052449]
	Learning Rate: 0.0052449
	LOSS [training: 0.7700405798393328 | validation: 0.827085112371393]
	TIME [epoch: 8.33 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846564695860178		[learning rate: 0.0052069]
	Learning Rate: 0.0052069
	LOSS [training: 0.7846564695860178 | validation: 0.71211303697381]
	TIME [epoch: 8.33 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6674282300568845		[learning rate: 0.0051692]
	Learning Rate: 0.00516917
	LOSS [training: 0.6674282300568845 | validation: 0.869433209161965]
	TIME [epoch: 8.36 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590652975344353		[learning rate: 0.0051317]
	Learning Rate: 0.00513172
	LOSS [training: 0.7590652975344353 | validation: 0.738838780709978]
	TIME [epoch: 8.34 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376143363211441		[learning rate: 0.0050945]
	Learning Rate: 0.00509454
	LOSS [training: 0.7376143363211441 | validation: 0.9663755919693607]
	TIME [epoch: 8.32 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0024752939543142		[learning rate: 0.0050576]
	Learning Rate: 0.00505763
	LOSS [training: 1.0024752939543142 | validation: 0.902416264991667]
	TIME [epoch: 8.32 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7924431925359658		[learning rate: 0.005021]
	Learning Rate: 0.00502099
	LOSS [training: 0.7924431925359658 | validation: 0.6506377668025458]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191787111684156		[learning rate: 0.0049846]
	Learning Rate: 0.00498461
	LOSS [training: 0.7191787111684156 | validation: 0.8922481536260964]
	TIME [epoch: 8.33 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6759827589984172		[learning rate: 0.0049485]
	Learning Rate: 0.0049485
	LOSS [training: 0.6759827589984172 | validation: 0.7388252498941309]
	TIME [epoch: 8.37 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723086176088825		[learning rate: 0.0049126]
	Learning Rate: 0.00491265
	LOSS [training: 0.6723086176088825 | validation: 0.7545399386650874]
	TIME [epoch: 8.33 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293738430984453		[learning rate: 0.0048771]
	Learning Rate: 0.00487706
	LOSS [training: 0.7293738430984453 | validation: 0.7485943904967374]
	TIME [epoch: 8.33 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874995799852281		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6874995799852281 | validation: 0.7076172592429814]
	TIME [epoch: 8.34 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704421133315442		[learning rate: 0.0048066]
	Learning Rate: 0.00480665
	LOSS [training: 0.6704421133315442 | validation: 0.6627309311930718]
	TIME [epoch: 8.33 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7136422543113038		[learning rate: 0.0047718]
	Learning Rate: 0.00477182
	LOSS [training: 0.7136422543113038 | validation: 0.8536219432774592]
	TIME [epoch: 8.37 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100071499801703		[learning rate: 0.0047373]
	Learning Rate: 0.00473725
	LOSS [training: 0.7100071499801703 | validation: 0.6863179845231395]
	TIME [epoch: 8.35 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.66144199290352		[learning rate: 0.0047029]
	Learning Rate: 0.00470293
	LOSS [training: 0.66144199290352 | validation: 0.6821174955369775]
	TIME [epoch: 8.33 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785561819397657		[learning rate: 0.0046689]
	Learning Rate: 0.00466886
	LOSS [training: 0.6785561819397657 | validation: 0.8908104162972943]
	TIME [epoch: 8.32 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273366185134877		[learning rate: 0.004635]
	Learning Rate: 0.00463503
	LOSS [training: 0.7273366185134877 | validation: 0.6061044478781255]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_156.pth
	Model improved!!!
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209815786306094		[learning rate: 0.0046015]
	Learning Rate: 0.00460145
	LOSS [training: 0.7209815786306094 | validation: 0.7763933465608428]
	TIME [epoch: 8.35 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280371502900508		[learning rate: 0.0045681]
	Learning Rate: 0.00456811
	LOSS [training: 0.7280371502900508 | validation: 0.6247882363201227]
	TIME [epoch: 8.39 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468850246365383		[learning rate: 0.004535]
	Learning Rate: 0.00453502
	LOSS [training: 0.6468850246365383 | validation: 1.0713698604615725]
	TIME [epoch: 8.35 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451386953456834		[learning rate: 0.0045022]
	Learning Rate: 0.00450216
	LOSS [training: 0.7451386953456834 | validation: 0.5898896614875793]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_160.pth
	Model improved!!!
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046708300796422		[learning rate: 0.0044695]
	Learning Rate: 0.00446954
	LOSS [training: 0.6046708300796422 | validation: 0.5642870727821502]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370625080596437		[learning rate: 0.0044372]
	Learning Rate: 0.00443716
	LOSS [training: 0.6370625080596437 | validation: 0.5717359591549269]
	TIME [epoch: 8.34 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975141143162979		[learning rate: 0.004405]
	Learning Rate: 0.00440501
	LOSS [training: 0.5975141143162979 | validation: 0.7791587191296303]
	TIME [epoch: 8.39 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961113087679336		[learning rate: 0.0043731]
	Learning Rate: 0.0043731
	LOSS [training: 0.6961113087679336 | validation: 0.5663300634587687]
	TIME [epoch: 8.36 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329224746386394		[learning rate: 0.0043414]
	Learning Rate: 0.00434142
	LOSS [training: 0.5329224746386394 | validation: 1.3009896617004442]
	TIME [epoch: 8.33 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8316231034905119		[learning rate: 0.00431]
	Learning Rate: 0.00430996
	LOSS [training: 0.8316231034905119 | validation: 0.6803894063545338]
	TIME [epoch: 8.35 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597583244745896		[learning rate: 0.0042787]
	Learning Rate: 0.00427874
	LOSS [training: 0.6597583244745896 | validation: 0.7641847480878711]
	TIME [epoch: 8.35 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942080205915509		[learning rate: 0.0042477]
	Learning Rate: 0.00424774
	LOSS [training: 0.5942080205915509 | validation: 0.5234971590676958]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.756997709977983		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.756997709977983 | validation: 0.940019200859036]
	TIME [epoch: 8.38 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8286684299788389		[learning rate: 0.0041864]
	Learning Rate: 0.00418641
	LOSS [training: 0.8286684299788389 | validation: 0.6757760752962945]
	TIME [epoch: 8.34 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6499228611398792		[learning rate: 0.0041561]
	Learning Rate: 0.00415608
	LOSS [training: 0.6499228611398792 | validation: 0.6479736170119756]
	TIME [epoch: 8.32 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6079514350176004		[learning rate: 0.004126]
	Learning Rate: 0.00412597
	LOSS [training: 0.6079514350176004 | validation: 0.8097927835290872]
	TIME [epoch: 8.33 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7919499276906952		[learning rate: 0.0040961]
	Learning Rate: 0.00409608
	LOSS [training: 0.7919499276906952 | validation: 0.6286545458503723]
	TIME [epoch: 8.32 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6024978791692347		[learning rate: 0.0040664]
	Learning Rate: 0.0040664
	LOSS [training: 0.6024978791692347 | validation: 0.5671989901367087]
	TIME [epoch: 8.36 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832072564931365		[learning rate: 0.0040369]
	Learning Rate: 0.00403694
	LOSS [training: 0.5832072564931365 | validation: 0.9218956166967112]
	TIME [epoch: 8.34 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.550192742657681		[learning rate: 0.0040077]
	Learning Rate: 0.0040077
	LOSS [training: 0.550192742657681 | validation: 0.7095245931025731]
	TIME [epoch: 8.32 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088909864251828		[learning rate: 0.0039787]
	Learning Rate: 0.00397866
	LOSS [training: 0.6088909864251828 | validation: 0.6475934039912956]
	TIME [epoch: 8.32 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.651549679507236		[learning rate: 0.0039498]
	Learning Rate: 0.00394984
	LOSS [training: 0.651549679507236 | validation: 0.6981430117308731]
	TIME [epoch: 8.33 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157283213006506		[learning rate: 0.0039212]
	Learning Rate: 0.00392122
	LOSS [training: 0.6157283213006506 | validation: 0.8086558661179397]
	TIME [epoch: 8.35 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.698304298740761		[learning rate: 0.0038928]
	Learning Rate: 0.00389281
	LOSS [training: 0.698304298740761 | validation: 0.6500265567797501]
	TIME [epoch: 8.36 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820768115252126		[learning rate: 0.0038646]
	Learning Rate: 0.00386461
	LOSS [training: 0.5820768115252126 | validation: 0.6614638450612519]
	TIME [epoch: 8.33 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327384298990741		[learning rate: 0.0038366]
	Learning Rate: 0.00383661
	LOSS [training: 0.6327384298990741 | validation: 0.5577497518221926]
	TIME [epoch: 8.32 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365066471323577		[learning rate: 0.0038088]
	Learning Rate: 0.00380881
	LOSS [training: 0.6365066471323577 | validation: 0.6703241451365645]
	TIME [epoch: 8.32 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011431666854397		[learning rate: 0.0037812]
	Learning Rate: 0.00378122
	LOSS [training: 0.7011431666854397 | validation: 0.5984078010480312]
	TIME [epoch: 8.33 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203422560944017		[learning rate: 0.0037538]
	Learning Rate: 0.00375382
	LOSS [training: 0.5203422560944017 | validation: 0.818484013354183]
	TIME [epoch: 8.36 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934648451479483		[learning rate: 0.0037266]
	Learning Rate: 0.00372663
	LOSS [training: 0.6934648451479483 | validation: 0.590829562739706]
	TIME [epoch: 8.35 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5539107897972078		[learning rate: 0.0036996]
	Learning Rate: 0.00369963
	LOSS [training: 0.5539107897972078 | validation: 0.6446982351489131]
	TIME [epoch: 8.32 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418892573514848		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6418892573514848 | validation: 0.5624337334558709]
	TIME [epoch: 8.32 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028945565871964		[learning rate: 0.0036462]
	Learning Rate: 0.00364621
	LOSS [training: 0.5028945565871964 | validation: 0.8384527220698141]
	TIME [epoch: 8.32 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597437957451091		[learning rate: 0.0036198]
	Learning Rate: 0.0036198
	LOSS [training: 0.7597437957451091 | validation: 0.6962113014269142]
	TIME [epoch: 8.33 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413563019536332		[learning rate: 0.0035936]
	Learning Rate: 0.00359357
	LOSS [training: 0.5413563019536332 | validation: 0.5038942789856748]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558041554088284		[learning rate: 0.0035675]
	Learning Rate: 0.00356754
	LOSS [training: 0.5558041554088284 | validation: 0.6375606955003918]
	TIME [epoch: 8.34 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300957957707671		[learning rate: 0.0035417]
	Learning Rate: 0.00354169
	LOSS [training: 0.6300957957707671 | validation: 0.5228079027282985]
	TIME [epoch: 8.33 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323484413822074		[learning rate: 0.003516]
	Learning Rate: 0.00351603
	LOSS [training: 0.6323484413822074 | validation: 0.529784223309272]
	TIME [epoch: 8.33 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49161839760686277		[learning rate: 0.0034906]
	Learning Rate: 0.00349056
	LOSS [training: 0.49161839760686277 | validation: 0.899579067711493]
	TIME [epoch: 8.33 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005850054062905		[learning rate: 0.0034653]
	Learning Rate: 0.00346527
	LOSS [training: 0.7005850054062905 | validation: 0.7858647839265515]
	TIME [epoch: 8.36 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021887686563548		[learning rate: 0.0034402]
	Learning Rate: 0.00344016
	LOSS [training: 0.7021887686563548 | validation: 0.5988965319737161]
	TIME [epoch: 8.34 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317602016836356		[learning rate: 0.0034152]
	Learning Rate: 0.00341524
	LOSS [training: 0.5317602016836356 | validation: 0.5696440514868534]
	TIME [epoch: 8.33 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340244176021447		[learning rate: 0.0033905]
	Learning Rate: 0.0033905
	LOSS [training: 0.5340244176021447 | validation: 0.49532630714032955]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49850481390231316		[learning rate: 0.0033659]
	Learning Rate: 0.00336593
	LOSS [training: 0.49850481390231316 | validation: 0.5477388807731212]
	TIME [epoch: 8.4 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153653651643989		[learning rate: 0.0033415]
	Learning Rate: 0.00334155
	LOSS [training: 0.6153653651643989 | validation: 0.5581917084048004]
	TIME [epoch: 8.31 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6009732531268084		[learning rate: 0.0033173]
	Learning Rate: 0.00331734
	LOSS [training: 0.6009732531268084 | validation: 0.7185966791162782]
	TIME [epoch: 8.37 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438675815011799		[learning rate: 0.0032933]
	Learning Rate: 0.0032933
	LOSS [training: 0.5438675815011799 | validation: 0.6289481075673198]
	TIME [epoch: 8.33 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213958960713668		[learning rate: 0.0032694]
	Learning Rate: 0.00326944
	LOSS [training: 0.5213958960713668 | validation: 0.5881075465274487]
	TIME [epoch: 8.33 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446370063273888		[learning rate: 0.0032458]
	Learning Rate: 0.00324576
	LOSS [training: 0.5446370063273888 | validation: 0.6650417005602178]
	TIME [epoch: 8.34 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429417631957473		[learning rate: 0.0032222]
	Learning Rate: 0.00322224
	LOSS [training: 0.5429417631957473 | validation: 0.5353662537219006]
	TIME [epoch: 8.34 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200662425437521		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5200662425437521 | validation: 0.6224807647216322]
	TIME [epoch: 8.38 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949200984056134		[learning rate: 0.0031757]
	Learning Rate: 0.00317572
	LOSS [training: 0.5949200984056134 | validation: 0.6765360228063453]
	TIME [epoch: 8.35 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161758221771828		[learning rate: 0.0031527]
	Learning Rate: 0.00315271
	LOSS [training: 0.5161758221771828 | validation: 0.7714540791457112]
	TIME [epoch: 8.34 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141873465971998		[learning rate: 0.0031299]
	Learning Rate: 0.00312987
	LOSS [training: 0.6141873465971998 | validation: 0.48214769168447474]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_210.pth
	Model improved!!!
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47995762604858744		[learning rate: 0.0031072]
	Learning Rate: 0.00310719
	LOSS [training: 0.47995762604858744 | validation: 0.7150813625458061]
	TIME [epoch: 8.44 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125101711504615		[learning rate: 0.0030847]
	Learning Rate: 0.00308468
	LOSS [training: 0.5125101711504615 | validation: 0.4477848870227991]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_212.pth
	Model improved!!!
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47018886437028795		[learning rate: 0.0030623]
	Learning Rate: 0.00306233
	LOSS [training: 0.47018886437028795 | validation: 0.5562154163967904]
	TIME [epoch: 8.46 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.531853438346648		[learning rate: 0.0030401]
	Learning Rate: 0.00304015
	LOSS [training: 0.531853438346648 | validation: 0.6625647104656955]
	TIME [epoch: 8.33 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638820405347735		[learning rate: 0.0030181]
	Learning Rate: 0.00301812
	LOSS [training: 0.4638820405347735 | validation: 0.46525968156539654]
	TIME [epoch: 8.33 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442471012561396		[learning rate: 0.0029963]
	Learning Rate: 0.00299626
	LOSS [training: 0.5442471012561396 | validation: 0.4704614009599999]
	TIME [epoch: 8.34 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4911613345143174		[learning rate: 0.0029745]
	Learning Rate: 0.00297455
	LOSS [training: 0.4911613345143174 | validation: 0.549588280522233]
	TIME [epoch: 8.34 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876467272678326		[learning rate: 0.002953]
	Learning Rate: 0.002953
	LOSS [training: 0.4876467272678326 | validation: 0.6650253954832346]
	TIME [epoch: 8.37 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819581614117222		[learning rate: 0.0029316]
	Learning Rate: 0.0029316
	LOSS [training: 0.5819581614117222 | validation: 0.5993008006699536]
	TIME [epoch: 8.35 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43936631001104776		[learning rate: 0.0029104]
	Learning Rate: 0.00291036
	LOSS [training: 0.43936631001104776 | validation: 0.5356788384079314]
	TIME [epoch: 8.33 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5248208740464959		[learning rate: 0.0028893]
	Learning Rate: 0.00288928
	LOSS [training: 0.5248208740464959 | validation: 0.5468203861175969]
	TIME [epoch: 8.34 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939772096104676		[learning rate: 0.0028683]
	Learning Rate: 0.00286835
	LOSS [training: 0.5939772096104676 | validation: 0.5392767441270161]
	TIME [epoch: 8.34 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748488365240577		[learning rate: 0.0028476]
	Learning Rate: 0.00284757
	LOSS [training: 0.4748488365240577 | validation: 0.6115854075639046]
	TIME [epoch: 8.34 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.48443461452423503		[learning rate: 0.0028269]
	Learning Rate: 0.00282693
	LOSS [training: 0.48443461452423503 | validation: 0.46370537560799435]
	TIME [epoch: 8.37 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41996277259902703		[learning rate: 0.0028065]
	Learning Rate: 0.00280645
	LOSS [training: 0.41996277259902703 | validation: 0.5058159526776744]
	TIME [epoch: 8.34 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563999485548144		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.6563999485548144 | validation: 0.6760504265006754]
	TIME [epoch: 8.33 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.54454303980722		[learning rate: 0.0027659]
	Learning Rate: 0.00276594
	LOSS [training: 0.54454303980722 | validation: 0.4954846220339893]
	TIME [epoch: 8.33 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083784893617761		[learning rate: 0.0027459]
	Learning Rate: 0.0027459
	LOSS [training: 0.5083784893617761 | validation: 0.5381398907747477]
	TIME [epoch: 8.34 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965235474389414		[learning rate: 0.002726]
	Learning Rate: 0.002726
	LOSS [training: 0.5965235474389414 | validation: 0.6724186272727617]
	TIME [epoch: 8.37 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044628342349587		[learning rate: 0.0027063]
	Learning Rate: 0.00270625
	LOSS [training: 0.6044628342349587 | validation: 0.4697607590703621]
	TIME [epoch: 8.36 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4546376257424789		[learning rate: 0.0026866]
	Learning Rate: 0.00268665
	LOSS [training: 0.4546376257424789 | validation: 0.7066334968569281]
	TIME [epoch: 8.33 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228759393934979		[learning rate: 0.0026672]
	Learning Rate: 0.00266718
	LOSS [training: 0.5228759393934979 | validation: 0.4943514583588907]
	TIME [epoch: 8.34 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4396898793429775		[learning rate: 0.0026479]
	Learning Rate: 0.00264786
	LOSS [training: 0.4396898793429775 | validation: 0.580125265442997]
	TIME [epoch: 8.33 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507328213525448		[learning rate: 0.0026287]
	Learning Rate: 0.00262867
	LOSS [training: 0.5507328213525448 | validation: 0.7724975835950556]
	TIME [epoch: 8.34 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669561192173981		[learning rate: 0.0026096]
	Learning Rate: 0.00260963
	LOSS [training: 0.6669561192173981 | validation: 0.46566106121126616]
	TIME [epoch: 8.38 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141809662263019		[learning rate: 0.0025907]
	Learning Rate: 0.00259072
	LOSS [training: 0.4141809662263019 | validation: 0.44060916047739773]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42568698045165015		[learning rate: 0.002572]
	Learning Rate: 0.00257195
	LOSS [training: 0.42568698045165015 | validation: 0.572745417178799]
	TIME [epoch: 8.41 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41247190741403716		[learning rate: 0.0025533]
	Learning Rate: 0.00255332
	LOSS [training: 0.41247190741403716 | validation: 0.6857304831519087]
	TIME [epoch: 8.31 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840629542894823		[learning rate: 0.0025348]
	Learning Rate: 0.00253482
	LOSS [training: 0.5840629542894823 | validation: 0.5887120096571447]
	TIME [epoch: 8.32 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44655562627503287		[learning rate: 0.0025165]
	Learning Rate: 0.00251646
	LOSS [training: 0.44655562627503287 | validation: 0.7286808563068432]
	TIME [epoch: 8.35 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44281446604460906		[learning rate: 0.0024982]
	Learning Rate: 0.00249823
	LOSS [training: 0.44281446604460906 | validation: 0.5900292869689052]
	TIME [epoch: 8.36 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295663260108691		[learning rate: 0.0024801]
	Learning Rate: 0.00248013
	LOSS [training: 0.5295663260108691 | validation: 0.4650422216708119]
	TIME [epoch: 8.33 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865254709160786		[learning rate: 0.0024622]
	Learning Rate: 0.00246216
	LOSS [training: 0.4865254709160786 | validation: 0.4516349838272198]
	TIME [epoch: 8.34 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45985116297537015		[learning rate: 0.0024443]
	Learning Rate: 0.00244432
	LOSS [training: 0.45985116297537015 | validation: 0.46366040034439526]
	TIME [epoch: 8.33 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42251526021240277		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.42251526021240277 | validation: 0.4581652551855793]
	TIME [epoch: 8.33 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492757902621406		[learning rate: 0.002409]
	Learning Rate: 0.00240903
	LOSS [training: 0.4492757902621406 | validation: 0.40331269403222025]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_phiq_1a_v_mmd1_20240520_124806/states/model_phiq_1a_v_mmd1_246.pth
	Model improved!!!
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4354616345250931		[learning rate: 0.0023916]
	Learning Rate: 0.00239158
	LOSS [training: 0.4354616345250931 | validation: 0.513965206480507]
	TIME [epoch: 8.44 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41946290362538197		[learning rate: 0.0023742]
	Learning Rate: 0.00237425
	LOSS [training: 0.41946290362538197 | validation: 0.409763891242307]
	TIME [epoch: 8.32 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736785781017062		[learning rate: 0.002357]
	Learning Rate: 0.00235705
	LOSS [training: 0.6736785781017062 | validation: 0.8622248715157932]
	TIME [epoch: 8.32 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418843025628472		[learning rate: 0.00234]
	Learning Rate: 0.00233997
	LOSS [training: 0.6418843025628472 | validation: 0.5022107393143319]
	TIME [epoch: 8.32 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800070769972914		[learning rate: 0.002323]
	Learning Rate: 0.00232302
	LOSS [training: 0.5800070769972914 | validation: 0.5663176463101577]
	TIME [epoch: 8.36 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5338078834134266		[learning rate: 0.0023062]
	Learning Rate: 0.00230619
	LOSS [training: 0.5338078834134266 | validation: 0.4809998270695791]
	TIME [epoch: 8.35 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.563094064339827		[learning rate: 0.0022895]
	Learning Rate: 0.00228948
	LOSS [training: 0.563094064339827 | validation: 0.4394440779307406]
	TIME [epoch: 8.33 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4119155348842257		[learning rate: 0.0022729]
	Learning Rate: 0.00227289
	LOSS [training: 0.4119155348842257 | validation: 0.4238856287794457]
	TIME [epoch: 8.33 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203488663210693		[learning rate: 0.0022564]
	Learning Rate: 0.00225643
	LOSS [training: 0.7203488663210693 | validation: 1.0493724695262876]
	TIME [epoch: 8.32 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900976153694033		[learning rate: 0.0022401]
	Learning Rate: 0.00224008
	LOSS [training: 0.8900976153694033 | validation: 1.006386307805574]
	TIME [epoch: 8.33 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7473968692593047		[learning rate: 0.0022238]
	Learning Rate: 0.00222385
	LOSS [training: 0.7473968692593047 | validation: 0.9144768137217476]
	TIME [epoch: 8.37 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851157990550812		[learning rate: 0.0022077]
	Learning Rate: 0.00220774
	LOSS [training: 0.6851157990550812 | validation: 0.6591336197139026]
	TIME [epoch: 8.34 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853377206516834		[learning rate: 0.0021917]
	Learning Rate: 0.00219174
	LOSS [training: 0.5853377206516834 | validation: 0.6284170765920307]
	TIME [epoch: 8.33 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923306897130033		[learning rate: 0.0021759]
	Learning Rate: 0.00217586
	LOSS [training: 0.6923306897130033 | validation: 1.1587245250304248]
	TIME [epoch: 8.33 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4115986909835587		[learning rate: 0.0021601]
	Learning Rate: 0.0021601
	LOSS [training: 1.4115986909835587 | validation: 1.7476363107262287]
	TIME [epoch: 8.32 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8877802791084868		[learning rate: 0.0021444]
	Learning Rate: 0.00214445
	LOSS [training: 1.8877802791084868 | validation: 2.0703262738947243]
	TIME [epoch: 8.34 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8276050668208002		[learning rate: 0.0021289]
	Learning Rate: 0.00212891
	LOSS [training: 1.8276050668208002 | validation: 1.6257929951426204]
	TIME [epoch: 8.36 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4894481912423818		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.4894481912423818 | validation: 1.175551296145053]
	TIME [epoch: 8.32 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.278669918897191		[learning rate: 0.0020982]
	Learning Rate: 0.00209818
	LOSS [training: 1.278669918897191 | validation: 1.0773498172329863]
	TIME [epoch: 8.33 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4223703449736045		[learning rate: 0.002083]
	Learning Rate: 0.00208298
	LOSS [training: 1.4223703449736045 | validation: 1.2590018426210943]
	TIME [epoch: 8.33 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6339438190330893		[learning rate: 0.0020679]
	Learning Rate: 0.00206788
	LOSS [training: 1.6339438190330893 | validation: 1.4065753773996716]
	TIME [epoch: 8.33 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9135970017331236		[learning rate: 0.0020529]
	Learning Rate: 0.0020529
	LOSS [training: 1.9135970017331236 | validation: 1.5721759730927334]
	TIME [epoch: 8.37 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9126418343476175		[learning rate: 0.002038]
	Learning Rate: 0.00203803
	LOSS [training: 1.9126418343476175 | validation: 1.460217496837116]
	TIME [epoch: 8.33 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.795986372557073		[learning rate: 0.0020233]
	Learning Rate: 0.00202326
	LOSS [training: 1.795986372557073 | validation: 1.494747452168562]
	TIME [epoch: 8.32 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.732571237301672		[learning rate: 0.0020086]
	Learning Rate: 0.00200861
	LOSS [training: 1.732571237301672 | validation: 1.6732187451798974]
	TIME [epoch: 8.32 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8394273236063912		[learning rate: 0.0019941]
	Learning Rate: 0.00199405
	LOSS [training: 1.8394273236063912 | validation: 1.5780538529468335]
	TIME [epoch: 8.32 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7957527232966206		[learning rate: 0.0019796]
	Learning Rate: 0.00197961
	LOSS [training: 1.7957527232966206 | validation: 1.4233106285121735]
	TIME [epoch: 8.33 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6797592711698826		[learning rate: 0.0019653]
	Learning Rate: 0.00196527
	LOSS [training: 1.6797592711698826 | validation: 1.4873305386656237]
	TIME [epoch: 8.37 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.62643939349865		[learning rate: 0.001951]
	Learning Rate: 0.00195103
	LOSS [training: 1.62643939349865 | validation: 1.3672564593537828]
	TIME [epoch: 8.32 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5559005598812268		[learning rate: 0.0019369]
	Learning Rate: 0.00193689
	LOSS [training: 1.5559005598812268 | validation: 1.4688205285142586]
	TIME [epoch: 8.32 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5316128717735702		[learning rate: 0.0019229]
	Learning Rate: 0.00192286
	LOSS [training: 1.5316128717735702 | validation: 1.5186694257497657]
	TIME [epoch: 8.32 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5250099026218873		[learning rate: 0.0019089]
	Learning Rate: 0.00190893
	LOSS [training: 1.5250099026218873 | validation: 1.3911583359379258]
	TIME [epoch: 8.33 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5769845025416946		[learning rate: 0.0018951]
	Learning Rate: 0.0018951
	LOSS [training: 1.5769845025416946 | validation: 1.4939974089680144]
	TIME [epoch: 8.36 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.605930711257225		[learning rate: 0.0018814]
	Learning Rate: 0.00188137
	LOSS [training: 1.605930711257225 | validation: 1.419715967615708]
	TIME [epoch: 8.35 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5965975683980635		[learning rate: 0.0018677]
	Learning Rate: 0.00186774
	LOSS [training: 1.5965975683980635 | validation: 1.4081865327536836]
	TIME [epoch: 8.33 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6389435517125355		[learning rate: 0.0018542]
	Learning Rate: 0.00185421
	LOSS [training: 1.6389435517125355 | validation: 1.4847184690540176]
	TIME [epoch: 8.33 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6663227839893033		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.6663227839893033 | validation: 1.4989995213504845]
	TIME [epoch: 8.33 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6677413070387057		[learning rate: 0.0018274]
	Learning Rate: 0.00182744
	LOSS [training: 1.6677413070387057 | validation: 1.511795839403884]
	TIME [epoch: 8.33 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7254713435350442		[learning rate: 0.0018142]
	Learning Rate: 0.0018142
	LOSS [training: 1.7254713435350442 | validation: 1.481430754313286]
	TIME [epoch: 8.37 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7790446568233214		[learning rate: 0.0018011]
	Learning Rate: 0.00180105
	LOSS [training: 1.7790446568233214 | validation: 1.542524885184652]
	TIME [epoch: 8.33 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.824606715552703		[learning rate: 0.001788]
	Learning Rate: 0.001788
	LOSS [training: 1.824606715552703 | validation: 1.578641814163528]
	TIME [epoch: 8.33 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7982250711129621		[learning rate: 0.001775]
	Learning Rate: 0.00177505
	LOSS [training: 1.7982250711129621 | validation: 1.5629079715745395]
	TIME [epoch: 8.33 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7104433003981034		[learning rate: 0.0017622]
	Learning Rate: 0.00176219
	LOSS [training: 1.7104433003981034 | validation: 1.5514958080849217]
	TIME [epoch: 8.32 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6863250695404142		[learning rate: 0.0017494]
	Learning Rate: 0.00174942
	LOSS [training: 1.6863250695404142 | validation: 1.5768343164928176]
	TIME [epoch: 8.35 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.732050012639521		[learning rate: 0.0017367]
	Learning Rate: 0.00173675
	LOSS [training: 1.732050012639521 | validation: 1.5183407187752787]
	TIME [epoch: 8.35 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6232162901984961		[learning rate: 0.0017242]
	Learning Rate: 0.00172417
	LOSS [training: 1.6232162901984961 | validation: 1.433209467811619]
	TIME [epoch: 8.33 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6127295700688764		[learning rate: 0.0017117]
	Learning Rate: 0.00171167
	LOSS [training: 1.6127295700688764 | validation: 1.6521577963317413]
	TIME [epoch: 8.33 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.646575457677343		[learning rate: 0.0016993]
	Learning Rate: 0.00169927
	LOSS [training: 1.646575457677343 | validation: 1.6252024010073303]
	TIME [epoch: 8.34 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6299495952664218		[learning rate: 0.001687]
	Learning Rate: 0.00168696
	LOSS [training: 1.6299495952664218 | validation: 1.6596871144616934]
	TIME [epoch: 8.33 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6398926744029987		[learning rate: 0.0016747]
	Learning Rate: 0.00167474
	LOSS [training: 1.6398926744029987 | validation: 1.6144898509950596]
	TIME [epoch: 8.39 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7140571020086488		[learning rate: 0.0016626]
	Learning Rate: 0.00166261
	LOSS [training: 1.7140571020086488 | validation: 1.6843189954935356]
	TIME [epoch: 8.34 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8490045718989316		[learning rate: 0.0016506]
	Learning Rate: 0.00165056
	LOSS [training: 1.8490045718989316 | validation: 1.777549600110233]
	TIME [epoch: 8.33 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8987525719936797		[learning rate: 0.0016386]
	Learning Rate: 0.0016386
	LOSS [training: 1.8987525719936797 | validation: 1.7303883612493798]
	TIME [epoch: 8.33 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.854603860208798		[learning rate: 0.0016267]
	Learning Rate: 0.00162673
	LOSS [training: 1.854603860208798 | validation: 1.7296822285333093]
	TIME [epoch: 8.33 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8623762479556563		[learning rate: 0.0016149]
	Learning Rate: 0.00161495
	LOSS [training: 1.8623762479556563 | validation: 1.7006948275065508]
	TIME [epoch: 8.36 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.881749770764082		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.881749770764082 | validation: 1.7404366175333172]
	TIME [epoch: 8.42 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9454984876429982		[learning rate: 0.0015916]
	Learning Rate: 0.00159163
	LOSS [training: 1.9454984876429982 | validation: 1.796003980177197]
	TIME [epoch: 8.31 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0992965619686665		[learning rate: 0.0015801]
	Learning Rate: 0.0015801
	LOSS [training: 2.0992965619686665 | validation: 2.0249354554283174]
	TIME [epoch: 8.32 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0965373726474477		[learning rate: 0.0015687]
	Learning Rate: 0.00156865
	LOSS [training: 2.0965373726474477 | validation: 1.9650109341340931]
	TIME [epoch: 8.32 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525954369159534		[learning rate: 0.0015573]
	Learning Rate: 0.00155729
	LOSS [training: 2.0525954369159534 | validation: 1.9380597270411388]
	TIME [epoch: 8.34 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9650540508405052		[learning rate: 0.001546]
	Learning Rate: 0.001546
	LOSS [training: 1.9650540508405052 | validation: 1.7647242567276016]
	TIME [epoch: 8.38 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8082437131320868		[learning rate: 0.0015348]
	Learning Rate: 0.0015348
	LOSS [training: 1.8082437131320868 | validation: 1.5296123240527417]
	TIME [epoch: 8.34 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6739394722604484		[learning rate: 0.0015237]
	Learning Rate: 0.00152368
	LOSS [training: 1.6739394722604484 | validation: 1.3607775196176908]
	TIME [epoch: 8.32 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6019296378330763		[learning rate: 0.0015126]
	Learning Rate: 0.00151264
	LOSS [training: 1.6019296378330763 | validation: 1.4863608840886986]
	TIME [epoch: 8.34 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.64798390517984		[learning rate: 0.0015017]
	Learning Rate: 0.00150169
	LOSS [training: 1.64798390517984 | validation: 1.4630300582041027]
	TIME [epoch: 8.33 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5961185481105473		[learning rate: 0.0014908]
	Learning Rate: 0.00149081
	LOSS [training: 1.5961185481105473 | validation: 1.39479948887655]
	TIME [epoch: 8.34 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5313535784625563		[learning rate: 0.00148]
	Learning Rate: 0.00148001
	LOSS [training: 1.5313535784625563 | validation: 1.3205133560045306]
	TIME [epoch: 8.37 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4240633093199349		[learning rate: 0.0014693]
	Learning Rate: 0.00146928
	LOSS [training: 1.4240633093199349 | validation: 1.2063144656308114]
	TIME [epoch: 8.33 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3799377801274573		[learning rate: 0.0014586]
	Learning Rate: 0.00145864
	LOSS [training: 1.3799377801274573 | validation: 1.3019271860835602]
	TIME [epoch: 8.34 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3702975518304878		[learning rate: 0.0014481]
	Learning Rate: 0.00144807
	LOSS [training: 1.3702975518304878 | validation: 1.2368861445442363]
	TIME [epoch: 8.33 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.332095581677562		[learning rate: 0.0014376]
	Learning Rate: 0.00143758
	LOSS [training: 1.332095581677562 | validation: 1.178400953863197]
	TIME [epoch: 8.34 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2972671917032077		[learning rate: 0.0014272]
	Learning Rate: 0.00142716
	LOSS [training: 1.2972671917032077 | validation: 1.1445127374864765]
	TIME [epoch: 8.36 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2776279340723846		[learning rate: 0.0014168]
	Learning Rate: 0.00141682
	LOSS [training: 1.2776279340723846 | validation: 1.108442896042439]
	TIME [epoch: 8.34 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.243330977097042		[learning rate: 0.0014066]
	Learning Rate: 0.00140656
	LOSS [training: 1.243330977097042 | validation: 1.068438157263317]
	TIME [epoch: 8.33 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1971237613686596		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.1971237613686596 | validation: 1.0423211228157507]
	TIME [epoch: 8.32 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1999244180998112		[learning rate: 0.0013863]
	Learning Rate: 0.00138625
	LOSS [training: 1.1999244180998112 | validation: 1.0620874124859145]
	TIME [epoch: 8.33 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1833216993633804		[learning rate: 0.0013762]
	Learning Rate: 0.00137621
	LOSS [training: 1.1833216993633804 | validation: 1.037328471745277]
	TIME [epoch: 8.33 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1681112514556367		[learning rate: 0.0013662]
	Learning Rate: 0.00136624
	LOSS [training: 1.1681112514556367 | validation: 1.0112502528134615]
	TIME [epoch: 8.37 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.15488659833368		[learning rate: 0.0013563]
	Learning Rate: 0.00135634
	LOSS [training: 1.15488659833368 | validation: 0.9608679208545792]
	TIME [epoch: 8.32 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0731034640026382		[learning rate: 0.0013465]
	Learning Rate: 0.00134651
	LOSS [training: 1.0731034640026382 | validation: 1.1413294733041377]
	TIME [epoch: 8.33 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3538765699181847		[learning rate: 0.0013368]
	Learning Rate: 0.00133676
	LOSS [training: 1.3538765699181847 | validation: 1.208221864002793]
	TIME [epoch: 8.33 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.23318178173592		[learning rate: 0.0013271]
	Learning Rate: 0.00132707
	LOSS [training: 1.23318178173592 | validation: 1.1093062207140458]
	TIME [epoch: 8.33 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1811729287789976		[learning rate: 0.0013175]
	Learning Rate: 0.00131746
	LOSS [training: 1.1811729287789976 | validation: 1.0899430962307866]
	TIME [epoch: 8.37 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1793178659796266		[learning rate: 0.0013079]
	Learning Rate: 0.00130791
	LOSS [training: 1.1793178659796266 | validation: 1.041187049869821]
	TIME [epoch: 8.35 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.151885197539397		[learning rate: 0.0012984]
	Learning Rate: 0.00129844
	LOSS [training: 1.151885197539397 | validation: 1.0250539481094891]
	TIME [epoch: 8.33 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1529561858656803		[learning rate: 0.001289]
	Learning Rate: 0.00128903
	LOSS [training: 1.1529561858656803 | validation: 1.040240302833484]
	TIME [epoch: 8.32 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1409137756348244		[learning rate: 0.0012797]
	Learning Rate: 0.00127969
	LOSS [training: 1.1409137756348244 | validation: 1.0215496377826918]
	TIME [epoch: 8.33 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1540365260143477		[learning rate: 0.0012704]
	Learning Rate: 0.00127042
	LOSS [training: 1.1540365260143477 | validation: 1.0326020570771552]
	TIME [epoch: 8.33 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398458123311388		[learning rate: 0.0012612]
	Learning Rate: 0.00126122
	LOSS [training: 1.1398458123311388 | validation: 1.0157741187074438]
	TIME [epoch: 8.38 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1185706157592528		[learning rate: 0.0012521]
	Learning Rate: 0.00125208
	LOSS [training: 1.1185706157592528 | validation: 0.9998321058197641]
	TIME [epoch: 8.33 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1207936208279712		[learning rate: 0.001243]
	Learning Rate: 0.00124301
	LOSS [training: 1.1207936208279712 | validation: 1.0867832199622276]
	TIME [epoch: 8.33 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1339159036565234		[learning rate: 0.001234]
	Learning Rate: 0.001234
	LOSS [training: 1.1339159036565234 | validation: 1.0411706267306295]
	TIME [epoch: 8.33 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1165040057544013		[learning rate: 0.0012251]
	Learning Rate: 0.00122506
	LOSS [training: 1.1165040057544013 | validation: 1.0486889717862897]
	TIME [epoch: 8.33 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1248083231976755		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.1248083231976755 | validation: 0.9924248001472167]
	TIME [epoch: 8.36 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1114780848907928		[learning rate: 0.0012074]
	Learning Rate: 0.00120737
	LOSS [training: 1.1114780848907928 | validation: 0.9892758025399022]
	TIME [epoch: 8.34 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133158987479967		[learning rate: 0.0011986]
	Learning Rate: 0.00119863
	LOSS [training: 1.1133158987479967 | validation: 0.9510531934821871]
	TIME [epoch: 8.33 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9714105474763146		[learning rate: 0.0011899]
	Learning Rate: 0.00118994
	LOSS [training: 0.9714105474763146 | validation: 0.8354323175345717]
	TIME [epoch: 8.33 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.055376124262963		[learning rate: 0.0011813]
	Learning Rate: 0.00118132
	LOSS [training: 1.055376124262963 | validation: 1.0228648657975856]
	TIME [epoch: 8.32 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1300737865234436		[learning rate: 0.0011728]
	Learning Rate: 0.00117276
	LOSS [training: 1.1300737865234436 | validation: 0.9175064778732074]
	TIME [epoch: 8.32 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.12801485202275		[learning rate: 0.0011643]
	Learning Rate: 0.00116427
	LOSS [training: 1.12801485202275 | validation: 0.9638089793139633]
	TIME [epoch: 8.38 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.112440572193582		[learning rate: 0.0011558]
	Learning Rate: 0.00115583
	LOSS [training: 1.112440572193582 | validation: 0.9614568067198833]
	TIME [epoch: 8.33 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.109965371712396		[learning rate: 0.0011475]
	Learning Rate: 0.00114746
	LOSS [training: 1.109965371712396 | validation: 1.0421411411267192]
	TIME [epoch: 8.32 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403502381065431		[learning rate: 0.0011391]
	Learning Rate: 0.00113914
	LOSS [training: 1.1403502381065431 | validation: 1.0967187852918228]
	TIME [epoch: 8.33 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1954426275316608		[learning rate: 0.0011309]
	Learning Rate: 0.00113089
	LOSS [training: 1.1954426275316608 | validation: 1.0679168680590867]
	TIME [epoch: 8.34 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1435509146850444		[learning rate: 0.0011227]
	Learning Rate: 0.0011227
	LOSS [training: 1.1435509146850444 | validation: 1.0440296530096296]
	TIME [epoch: 8.36 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1078148085532433		[learning rate: 0.0011146]
	Learning Rate: 0.00111456
	LOSS [training: 1.1078148085532433 | validation: 1.0364806579222536]
	TIME [epoch: 8.36 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0912311448878667		[learning rate: 0.0011065]
	Learning Rate: 0.00110649
	LOSS [training: 1.0912311448878667 | validation: 1.0313620124247274]
	TIME [epoch: 8.33 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.107390942406549		[learning rate: 0.0010985]
	Learning Rate: 0.00109847
	LOSS [training: 1.107390942406549 | validation: 1.0702372387759924]
	TIME [epoch: 8.33 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461916292760297		[learning rate: 0.0010905]
	Learning Rate: 0.00109051
	LOSS [training: 1.1461916292760297 | validation: 1.113411137977466]
	TIME [epoch: 8.32 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635719140334344		[learning rate: 0.0010826]
	Learning Rate: 0.00108261
	LOSS [training: 1.1635719140334344 | validation: 1.1961573396130767]
	TIME [epoch: 8.33 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2113166604835643		[learning rate: 0.0010748]
	Learning Rate: 0.00107477
	LOSS [training: 1.2113166604835643 | validation: 1.2896682519985079]
	TIME [epoch: 8.37 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.280051454167059		[learning rate: 0.001067]
	Learning Rate: 0.00106698
	LOSS [training: 1.280051454167059 | validation: 1.3597222886755604]
	TIME [epoch: 8.34 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2632872941752427		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.2632872941752427 | validation: 1.3645671998496867]
	TIME [epoch: 8.33 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.27106455541351		[learning rate: 0.0010516]
	Learning Rate: 0.00105158
	LOSS [training: 1.27106455541351 | validation: 1.3651747119224096]
	TIME [epoch: 8.33 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2593514694202512		[learning rate: 0.001044]
	Learning Rate: 0.00104396
	LOSS [training: 1.2593514694202512 | validation: 1.420969544950959]
	TIME [epoch: 8.33 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.322351132802334		[learning rate: 0.0010364]
	Learning Rate: 0.0010364
	LOSS [training: 1.322351132802334 | validation: 1.518914791728869]
	TIME [epoch: 8.34 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3711718573256264		[learning rate: 0.0010289]
	Learning Rate: 0.00102889
	LOSS [training: 1.3711718573256264 | validation: 1.459573947206898]
	TIME [epoch: 8.37 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3378385903870307		[learning rate: 0.0010214]
	Learning Rate: 0.00102143
	LOSS [training: 1.3378385903870307 | validation: 1.4368561169248504]
	TIME [epoch: 8.35 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3528287201404956		[learning rate: 0.001014]
	Learning Rate: 0.00101403
	LOSS [training: 1.3528287201404956 | validation: 1.423547862871812]
	TIME [epoch: 8.34 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.374942941943391		[learning rate: 0.0010067]
	Learning Rate: 0.00100669
	LOSS [training: 1.374942941943391 | validation: 1.367320805848174]
	TIME [epoch: 8.34 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3059303746238522		[learning rate: 0.00099939]
	Learning Rate: 0.000999394
	LOSS [training: 1.3059303746238522 | validation: 1.334462589667874]
	TIME [epoch: 8.33 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.220503596998675		[learning rate: 0.00099215]
	Learning Rate: 0.000992154
	LOSS [training: 1.220503596998675 | validation: 1.3093776062243614]
	TIME [epoch: 8.37 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1730223962702162		[learning rate: 0.00098497]
	Learning Rate: 0.000984966
	LOSS [training: 1.1730223962702162 | validation: 1.257778578000614]
	TIME [epoch: 8.34 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1896115018085587		[learning rate: 0.00097783]
	Learning Rate: 0.00097783
	LOSS [training: 1.1896115018085587 | validation: 1.2366382888881586]
	TIME [epoch: 8.32 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1908736642158628		[learning rate: 0.00097075]
	Learning Rate: 0.000970745
	LOSS [training: 1.1908736642158628 | validation: 1.3149147177244838]
	TIME [epoch: 8.33 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2483043184171674		[learning rate: 0.00096371]
	Learning Rate: 0.000963712
	LOSS [training: 1.2483043184171674 | validation: 1.4146996923362642]
	TIME [epoch: 8.33 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2997181634267936		[learning rate: 0.00095673]
	Learning Rate: 0.00095673
	LOSS [training: 1.2997181634267936 | validation: 1.4081746710624448]
	TIME [epoch: 8.34 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3003294546410702		[learning rate: 0.0009498]
	Learning Rate: 0.000949799
	LOSS [training: 1.3003294546410702 | validation: 1.3737121870235054]
	TIME [epoch: 8.37 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888586926669876		[learning rate: 0.00094292]
	Learning Rate: 0.000942918
	LOSS [training: 1.2888586926669876 | validation: 1.3736570960270966]
	TIME [epoch: 8.33 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.29917817998528		[learning rate: 0.00093609]
	Learning Rate: 0.000936086
	LOSS [training: 1.29917817998528 | validation: 1.3647559519889834]
	TIME [epoch: 8.34 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2474650639186462		[learning rate: 0.0009293]
	Learning Rate: 0.000929304
	LOSS [training: 1.2474650639186462 | validation: 1.3069121956327234]
	TIME [epoch: 8.34 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2384185471496778		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.2384185471496778 | validation: 1.3439293599239002]
	TIME [epoch: 8.34 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2613043783246185		[learning rate: 0.00091589]
	Learning Rate: 0.000915888
	LOSS [training: 1.2613043783246185 | validation: 1.3696540307099225]
	TIME [epoch: 8.37 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3012316695562958		[learning rate: 0.00090925]
	Learning Rate: 0.000909252
	LOSS [training: 1.3012316695562958 | validation: 1.3721247646157968]
	TIME [epoch: 8.36 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.292023241302784		[learning rate: 0.00090266]
	Learning Rate: 0.000902664
	LOSS [training: 1.292023241302784 | validation: 1.3453829406591062]
	TIME [epoch: 8.33 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.269738569721079		[learning rate: 0.00089612]
	Learning Rate: 0.000896125
	LOSS [training: 1.269738569721079 | validation: 1.3630335868857029]
	TIME [epoch: 8.34 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2883501257208958		[learning rate: 0.00088963]
	Learning Rate: 0.000889632
	LOSS [training: 1.2883501257208958 | validation: 1.4186616094800617]
	TIME [epoch: 8.33 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3486188980094433		[learning rate: 0.00088319]
	Learning Rate: 0.000883187
	LOSS [training: 1.3486188980094433 | validation: 1.4692501991743727]
	TIME [epoch: 8.34 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4022782791557282		[learning rate: 0.00087679]
	Learning Rate: 0.000876788
	LOSS [training: 1.4022782791557282 | validation: 1.5634483740051173]
	TIME [epoch: 8.38 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4182044606005815		[learning rate: 0.00087044]
	Learning Rate: 0.000870436
	LOSS [training: 1.4182044606005815 | validation: 1.5199361423033242]
	TIME [epoch: 8.34 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3853492321796588		[learning rate: 0.00086413]
	Learning Rate: 0.00086413
	LOSS [training: 1.3853492321796588 | validation: 1.4295890884551146]
	TIME [epoch: 8.33 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.315852529807954		[learning rate: 0.00085787]
	Learning Rate: 0.000857869
	LOSS [training: 1.315852529807954 | validation: 1.4285930372039708]
	TIME [epoch: 8.34 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.324366700100772		[learning rate: 0.00085165]
	Learning Rate: 0.000851654
	LOSS [training: 1.324366700100772 | validation: 1.4136824825282943]
	TIME [epoch: 8.33 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3504373940422585		[learning rate: 0.00084548]
	Learning Rate: 0.000845484
	LOSS [training: 1.3504373940422585 | validation: 1.4603330103958714]
	TIME [epoch: 8.36 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.37492689587171		[learning rate: 0.00083936]
	Learning Rate: 0.000839358
	LOSS [training: 1.37492689587171 | validation: 1.4080265023768679]
	TIME [epoch: 8.36 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3424474343077946		[learning rate: 0.00083328]
	Learning Rate: 0.000833277
	LOSS [training: 1.3424474343077946 | validation: 1.4086412943825524]
	TIME [epoch: 8.34 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3470590874168118		[learning rate: 0.00082724]
	Learning Rate: 0.00082724
	LOSS [training: 1.3470590874168118 | validation: 1.42383847446097]
	TIME [epoch: 8.34 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3325101519476008		[learning rate: 0.00082125]
	Learning Rate: 0.000821247
	LOSS [training: 1.3325101519476008 | validation: 1.4146329638256026]
	TIME [epoch: 8.34 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355116389964132		[learning rate: 0.0008153]
	Learning Rate: 0.000815297
	LOSS [training: 1.3355116389964132 | validation: 1.3971527443484912]
	TIME [epoch: 8.33 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2985235588304516		[learning rate: 0.00080939]
	Learning Rate: 0.00080939
	LOSS [training: 1.2985235588304516 | validation: 1.3174132763675295]
	TIME [epoch: 8.38 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2929574626809623		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.2929574626809623 | validation: 1.3066130661626283]
	TIME [epoch: 8.34 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3083319498264172		[learning rate: 0.0007977]
	Learning Rate: 0.000797705
	LOSS [training: 1.3083319498264172 | validation: 1.3693125513355329]
	TIME [epoch: 8.34 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3404229710539388		[learning rate: 0.00079193]
	Learning Rate: 0.000791925
	LOSS [training: 1.3404229710539388 | validation: 1.3461313834582134]
	TIME [epoch: 8.34 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.394406303065646		[learning rate: 0.00078619]
	Learning Rate: 0.000786188
	LOSS [training: 1.394406303065646 | validation: 1.3692406579568694]
	TIME [epoch: 8.33 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4029907274319418		[learning rate: 0.00078049]
	Learning Rate: 0.000780492
	LOSS [training: 1.4029907274319418 | validation: 1.398810512213319]
	TIME [epoch: 8.36 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4759737268311945		[learning rate: 0.00077484]
	Learning Rate: 0.000774838
	LOSS [training: 1.4759737268311945 | validation: 1.4194760982030556]
	TIME [epoch: 8.47 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.48324916744816		[learning rate: 0.00076922]
	Learning Rate: 0.000769224
	LOSS [training: 1.48324916744816 | validation: 1.4451271741762772]
	TIME [epoch: 8.31 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5387369911028461		[learning rate: 0.00076365]
	Learning Rate: 0.000763651
	LOSS [training: 1.5387369911028461 | validation: 1.5029919648349312]
	TIME [epoch: 8.33 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.622710667768005		[learning rate: 0.00075812]
	Learning Rate: 0.000758118
	LOSS [training: 1.622710667768005 | validation: 1.4702483438733496]
	TIME [epoch: 8.33 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.644381382397757		[learning rate: 0.00075263]
	Learning Rate: 0.000752626
	LOSS [training: 1.644381382397757 | validation: 1.481087647344712]
	TIME [epoch: 8.33 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6717212927234024		[learning rate: 0.00074717]
	Learning Rate: 0.000747173
	LOSS [training: 1.6717212927234024 | validation: 1.4929705745943007]
	TIME [epoch: 8.38 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6896148292475608		[learning rate: 0.00074176]
	Learning Rate: 0.00074176
	LOSS [training: 1.6896148292475608 | validation: 1.4839150177546858]
	TIME [epoch: 8.33 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6920732115862722		[learning rate: 0.00073639]
	Learning Rate: 0.000736386
	LOSS [training: 1.6920732115862722 | validation: 1.4655812889746178]
	TIME [epoch: 8.33 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7071603738954304		[learning rate: 0.00073105]
	Learning Rate: 0.000731051
	LOSS [training: 1.7071603738954304 | validation: 1.5346928415267904]
	TIME [epoch: 8.33 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7433454092894867		[learning rate: 0.00072575]
	Learning Rate: 0.000725754
	LOSS [training: 1.7433454092894867 | validation: 1.5518899837018576]
	TIME [epoch: 8.32 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7443504883639744		[learning rate: 0.0007205]
	Learning Rate: 0.000720496
	LOSS [training: 1.7443504883639744 | validation: 1.6848755764930066]
	TIME [epoch: 8.35 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8286576503350036		[learning rate: 0.00071528]
	Learning Rate: 0.000715276
	LOSS [training: 1.8286576503350036 | validation: 1.7285495824926689]
	TIME [epoch: 8.37 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8565733402325737		[learning rate: 0.00071009]
	Learning Rate: 0.000710094
	LOSS [training: 1.8565733402325737 | validation: 1.7007172996893956]
	TIME [epoch: 8.33 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8264505961836282		[learning rate: 0.00070495]
	Learning Rate: 0.000704949
	LOSS [training: 1.8264505961836282 | validation: 1.6837481516870425]
	TIME [epoch: 8.33 sec]
EPOCH 416/1000:
	Training over batches...
	Encountered nan in loss. Reverting update and performing model surgery (1/4).
		New model confinement_factor: 0.001
		[batch 4/4] avg loss: 2.4481512409743864		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.4481512409743864 | validation: 2.641637727092968]
	TIME [epoch: 180 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.644706435595629		[learning rate: 0.00069477]
	Learning Rate: 0.000694772
	LOSS [training: 2.644706435595629 | validation: 2.6144597267625977]
	TIME [epoch: 8.41 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6294221806019866		[learning rate: 0.00068974]
	Learning Rate: 0.000689738
	LOSS [training: 2.6294221806019866 | validation: 2.5980954978744744]
	TIME [epoch: 8.34 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.608589225345311		[learning rate: 0.00068474]
	Learning Rate: 0.000684741
	LOSS [training: 2.608589225345311 | validation: 2.5624704228391018]
	TIME [epoch: 8.33 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5804744574631195		[learning rate: 0.00067978]
	Learning Rate: 0.00067978
	LOSS [training: 2.5804744574631195 | validation: 2.5322634537849984]
	TIME [epoch: 8.34 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5515173323111466		[learning rate: 0.00067486]
	Learning Rate: 0.000674855
	LOSS [training: 2.5515173323111466 | validation: 2.4979819485565162]
	TIME [epoch: 8.34 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5171977438757827		[learning rate: 0.00066997]
	Learning Rate: 0.000669966
	LOSS [training: 2.5171977438757827 | validation: 2.47915518315528]
	TIME [epoch: 8.39 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4855752196441188		[learning rate: 0.00066511]
	Learning Rate: 0.000665112
	LOSS [training: 2.4855752196441188 | validation: 2.4400605987004926]
	TIME [epoch: 8.35 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.453543890953414		[learning rate: 0.00066029]
	Learning Rate: 0.000660293
	LOSS [training: 2.453543890953414 | validation: 2.4309893190043352]
	TIME [epoch: 8.34 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4358730684233594		[learning rate: 0.00065551]
	Learning Rate: 0.00065551
	LOSS [training: 2.4358730684233594 | validation: 2.410182927580623]
	TIME [epoch: 8.34 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.406762209722574		[learning rate: 0.00065076]
	Learning Rate: 0.00065076
	LOSS [training: 2.406762209722574 | validation: 2.38334744704923]
	TIME [epoch: 8.33 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.379966753967567		[learning rate: 0.00064605]
	Learning Rate: 0.000646046
	LOSS [training: 2.379966753967567 | validation: 2.370382250784793]
	TIME [epoch: 8.35 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.356221452290913		[learning rate: 0.00064137]
	Learning Rate: 0.000641365
	LOSS [training: 2.356221452290913 | validation: 2.3313612120882263]
	TIME [epoch: 8.38 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.333723267463262		[learning rate: 0.00063672]
	Learning Rate: 0.000636718
	LOSS [training: 2.333723267463262 | validation: 2.306897562391639]
	TIME [epoch: 8.36 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.314642755710573		[learning rate: 0.00063211]
	Learning Rate: 0.000632105
	LOSS [training: 2.314642755710573 | validation: 2.288053215180841]
	TIME [epoch: 8.35 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3069873757941064		[learning rate: 0.00062753]
	Learning Rate: 0.000627526
	LOSS [training: 2.3069873757941064 | validation: 2.260740366894489]
	TIME [epoch: 8.35 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2920703814374783		[learning rate: 0.00062298]
	Learning Rate: 0.000622979
	LOSS [training: 2.2920703814374783 | validation: 2.245581069500568]
	TIME [epoch: 8.35 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2831025744870805		[learning rate: 0.00061847]
	Learning Rate: 0.000618466
	LOSS [training: 2.2831025744870805 | validation: 2.228449858057651]
	TIME [epoch: 8.37 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.265722134804888		[learning rate: 0.00061399]
	Learning Rate: 0.000613985
	LOSS [training: 2.265722134804888 | validation: 2.221102503658125]
	TIME [epoch: 8.38 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2495632712902887		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.2495632712902887 | validation: 2.20270972036223]
	TIME [epoch: 8.35 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.234847885662158		[learning rate: 0.00060512]
	Learning Rate: 0.000605121
	LOSS [training: 2.234847885662158 | validation: 2.188445152504274]
	TIME [epoch: 8.35 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2280144831100763		[learning rate: 0.00060074]
	Learning Rate: 0.000600737
	LOSS [training: 2.2280144831100763 | validation: 2.1786591325598534]
	TIME [epoch: 8.35 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.223757736945145		[learning rate: 0.00059638]
	Learning Rate: 0.000596384
	LOSS [training: 2.223757736945145 | validation: 2.16987465148317]
	TIME [epoch: 8.35 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2080460141074396		[learning rate: 0.00059206]
	Learning Rate: 0.000592064
	LOSS [training: 2.2080460141074396 | validation: 2.1620355375489595]
	TIME [epoch: 8.38 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.184941266092795		[learning rate: 0.00058777]
	Learning Rate: 0.000587774
	LOSS [training: 2.184941266092795 | validation: 2.1471918276431436]
	TIME [epoch: 8.38 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.168632592541555		[learning rate: 0.00058352]
	Learning Rate: 0.000583516
	LOSS [training: 2.168632592541555 | validation: 2.134744524039212]
	TIME [epoch: 8.34 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.153169722234974		[learning rate: 0.00057929]
	Learning Rate: 0.000579288
	LOSS [training: 2.153169722234974 | validation: 2.118553038978504]
	TIME [epoch: 8.34 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1353421072278715		[learning rate: 0.00057509]
	Learning Rate: 0.000575091
	LOSS [training: 2.1353421072278715 | validation: 2.0992711982985037]
	TIME [epoch: 8.35 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1211630664421834		[learning rate: 0.00057093]
	Learning Rate: 0.000570925
	LOSS [training: 2.1211630664421834 | validation: 2.073081157739276]
	TIME [epoch: 8.35 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.103062621258063		[learning rate: 0.00056679]
	Learning Rate: 0.000566789
	LOSS [training: 2.103062621258063 | validation: 2.0574165156524336]
	TIME [epoch: 8.4 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0866801151886545		[learning rate: 0.00056268]
	Learning Rate: 0.000562682
	LOSS [training: 2.0866801151886545 | validation: 2.029136789994684]
	TIME [epoch: 8.36 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0599101839524248		[learning rate: 0.00055861]
	Learning Rate: 0.000558606
	LOSS [training: 2.0599101839524248 | validation: 1.996496078489889]
	TIME [epoch: 8.34 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0344092250555863		[learning rate: 0.00055456]
	Learning Rate: 0.000554559
	LOSS [training: 2.0344092250555863 | validation: 1.9785350869280114]
	TIME [epoch: 8.35 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.008973024046636		[learning rate: 0.00055054]
	Learning Rate: 0.000550541
	LOSS [training: 2.008973024046636 | validation: 1.9411766192076918]
	TIME [epoch: 8.35 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9921581744517227		[learning rate: 0.00054655]
	Learning Rate: 0.000546552
	LOSS [training: 1.9921581744517227 | validation: 1.9409717939120181]
	TIME [epoch: 8.37 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9761841319383486		[learning rate: 0.00054259]
	Learning Rate: 0.000542592
	LOSS [training: 1.9761841319383486 | validation: 1.9223675167797918]
	TIME [epoch: 8.38 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9547731737584368		[learning rate: 0.00053866]
	Learning Rate: 0.000538661
	LOSS [training: 1.9547731737584368 | validation: 1.8959669345013452]
	TIME [epoch: 8.35 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9257812520212911		[learning rate: 0.00053476]
	Learning Rate: 0.000534759
	LOSS [training: 1.9257812520212911 | validation: 1.8851024690631826]
	TIME [epoch: 8.34 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9100236695925057		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.9100236695925057 | validation: 1.8815719143272172]
	TIME [epoch: 8.35 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8983861482502136		[learning rate: 0.00052704]
	Learning Rate: 0.000527038
	LOSS [training: 1.8983861482502136 | validation: 1.8663533601254993]
	TIME [epoch: 8.35 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8710378757799648		[learning rate: 0.00052322]
	Learning Rate: 0.00052322
	LOSS [training: 1.8710378757799648 | validation: 1.8510282677947336]
	TIME [epoch: 8.38 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8440798911391563		[learning rate: 0.00051943]
	Learning Rate: 0.000519429
	LOSS [training: 1.8440798911391563 | validation: 1.8465754173956546]
	TIME [epoch: 8.39 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8322089652985183		[learning rate: 0.00051567]
	Learning Rate: 0.000515666
	LOSS [training: 1.8322089652985183 | validation: 1.8337782049936213]
	TIME [epoch: 8.35 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8227458926876885		[learning rate: 0.00051193]
	Learning Rate: 0.00051193
	LOSS [training: 1.8227458926876885 | validation: 1.8385966411577366]
	TIME [epoch: 8.35 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8110166464867117		[learning rate: 0.00050822]
	Learning Rate: 0.000508221
	LOSS [training: 1.8110166464867117 | validation: 1.8096241865264724]
	TIME [epoch: 8.34 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7960454511594162		[learning rate: 0.00050454]
	Learning Rate: 0.000504539
	LOSS [training: 1.7960454511594162 | validation: 1.8076186420955351]
	TIME [epoch: 8.35 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7878609408625057		[learning rate: 0.00050088]
	Learning Rate: 0.000500884
	LOSS [training: 1.7878609408625057 | validation: 1.8056745514806412]
	TIME [epoch: 8.38 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7756701657725054		[learning rate: 0.00049725]
	Learning Rate: 0.000497255
	LOSS [training: 1.7756701657725054 | validation: 1.7886282397907654]
	TIME [epoch: 8.38 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7600167081732265		[learning rate: 0.00049365]
	Learning Rate: 0.000493652
	LOSS [training: 1.7600167081732265 | validation: 1.7795659291287462]
	TIME [epoch: 8.34 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7475237773720242		[learning rate: 0.00049008]
	Learning Rate: 0.000490076
	LOSS [training: 1.7475237773720242 | validation: 1.7693349002882757]
	TIME [epoch: 8.35 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7369689145451515		[learning rate: 0.00048653]
	Learning Rate: 0.000486525
	LOSS [training: 1.7369689145451515 | validation: 1.7622408425058498]
	TIME [epoch: 8.35 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7247575394091588		[learning rate: 0.000483]
	Learning Rate: 0.000483
	LOSS [training: 1.7247575394091588 | validation: 1.7466430980962828]
	TIME [epoch: 8.35 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7087530541392		[learning rate: 0.0004795]
	Learning Rate: 0.000479501
	LOSS [training: 1.7087530541392 | validation: 1.7301391360911866]
	TIME [epoch: 8.4 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6823177739179704		[learning rate: 0.00047603]
	Learning Rate: 0.000476027
	LOSS [training: 1.6823177739179704 | validation: 1.7126815557998984]
	TIME [epoch: 8.35 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6688727302773418		[learning rate: 0.00047258]
	Learning Rate: 0.000472578
	LOSS [training: 1.6688727302773418 | validation: 1.7063344675316876]
	TIME [epoch: 8.35 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6550368673599853		[learning rate: 0.00046915]
	Learning Rate: 0.000469154
	LOSS [training: 1.6550368673599853 | validation: 1.6941029152697902]
	TIME [epoch: 8.35 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6437145991513233		[learning rate: 0.00046576]
	Learning Rate: 0.000465755
	LOSS [training: 1.6437145991513233 | validation: 1.6825977967674817]
	TIME [epoch: 8.35 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6334378212108003		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.6334378212108003 | validation: 1.6731325900018297]
	TIME [epoch: 8.36 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6292677366638375		[learning rate: 0.00045903]
	Learning Rate: 0.000459031
	LOSS [training: 1.6292677366638375 | validation: 1.6579531131977792]
	TIME [epoch: 8.39 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6176446649058807		[learning rate: 0.00045571]
	Learning Rate: 0.000455706
	LOSS [training: 1.6176446649058807 | validation: 1.6430426874915351]
	TIME [epoch: 8.36 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6001695667294724		[learning rate: 0.0004524]
	Learning Rate: 0.000452404
	LOSS [training: 1.6001695667294724 | validation: 1.6148268485787916]
	TIME [epoch: 8.34 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5793671328769063		[learning rate: 0.00044913]
	Learning Rate: 0.000449126
	LOSS [training: 1.5793671328769063 | validation: 1.593040529297991]
	TIME [epoch: 8.36 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5637911503871824		[learning rate: 0.00044587]
	Learning Rate: 0.000445872
	LOSS [training: 1.5637911503871824 | validation: 1.579196999926293]
	TIME [epoch: 8.35 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5518607331892165		[learning rate: 0.00044264]
	Learning Rate: 0.000442642
	LOSS [training: 1.5518607331892165 | validation: 1.5664933954491072]
	TIME [epoch: 8.38 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5365184898512387		[learning rate: 0.00043944]
	Learning Rate: 0.000439435
	LOSS [training: 1.5365184898512387 | validation: 1.5374937159577642]
	TIME [epoch: 8.37 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5198562324837308		[learning rate: 0.00043625]
	Learning Rate: 0.000436251
	LOSS [training: 1.5198562324837308 | validation: 1.520823637281394]
	TIME [epoch: 8.35 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5063546868119626		[learning rate: 0.00043309]
	Learning Rate: 0.000433091
	LOSS [training: 1.5063546868119626 | validation: 1.503359127060171]
	TIME [epoch: 8.35 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4908005155434176		[learning rate: 0.00042995]
	Learning Rate: 0.000429953
	LOSS [training: 1.4908005155434176 | validation: 1.476799868622268]
	TIME [epoch: 8.35 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4716934192625395		[learning rate: 0.00042684]
	Learning Rate: 0.000426838
	LOSS [training: 1.4716934192625395 | validation: 1.4554999884041266]
	TIME [epoch: 8.36 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4535355196048942		[learning rate: 0.00042375]
	Learning Rate: 0.000423746
	LOSS [training: 1.4535355196048942 | validation: 1.4230693215923043]
	TIME [epoch: 8.39 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.429954159692557		[learning rate: 0.00042068]
	Learning Rate: 0.000420676
	LOSS [training: 1.429954159692557 | validation: 1.3951084611601519]
	TIME [epoch: 8.38 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4076849962563123		[learning rate: 0.00041763]
	Learning Rate: 0.000417628
	LOSS [training: 1.4076849962563123 | validation: 1.3653703446625243]
	TIME [epoch: 8.35 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.386643003505259		[learning rate: 0.0004146]
	Learning Rate: 0.000414602
	LOSS [training: 1.386643003505259 | validation: 1.3433019592937558]
	TIME [epoch: 8.35 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3631639320173503		[learning rate: 0.0004116]
	Learning Rate: 0.000411598
	LOSS [training: 1.3631639320173503 | validation: 1.3169651169789152]
	TIME [epoch: 8.35 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3396312900274747		[learning rate: 0.00040862]
	Learning Rate: 0.000408616
	LOSS [training: 1.3396312900274747 | validation: 1.301061640303014]
	TIME [epoch: 8.36 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.316223743883441		[learning rate: 0.00040566]
	Learning Rate: 0.000405656
	LOSS [training: 1.316223743883441 | validation: 1.2635566799534157]
	TIME [epoch: 8.4 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2939275938248047		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.2939275938248047 | validation: 1.2421472648843026]
	TIME [epoch: 8.36 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.280816260097298		[learning rate: 0.0003998]
	Learning Rate: 0.000399799
	LOSS [training: 1.280816260097298 | validation: 1.235920454208839]
	TIME [epoch: 8.35 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2715897707707873		[learning rate: 0.0003969]
	Learning Rate: 0.000396903
	LOSS [training: 1.2715897707707873 | validation: 1.2236404376439112]
	TIME [epoch: 8.36 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.256716221178911		[learning rate: 0.00039403]
	Learning Rate: 0.000394027
	LOSS [training: 1.256716221178911 | validation: 1.2192647342188292]
	TIME [epoch: 8.34 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.251339578996633		[learning rate: 0.00039117]
	Learning Rate: 0.000391173
	LOSS [training: 1.251339578996633 | validation: 1.21807135926102]
	TIME [epoch: 8.36 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2390345797024451		[learning rate: 0.00038834]
	Learning Rate: 0.000388339
	LOSS [training: 1.2390345797024451 | validation: 1.21496458446653]
	TIME [epoch: 8.38 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270678408182967		[learning rate: 0.00038553]
	Learning Rate: 0.000385525
	LOSS [training: 1.2270678408182967 | validation: 1.2034038344083333]
	TIME [epoch: 8.35 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.213832632819034		[learning rate: 0.00038273]
	Learning Rate: 0.000382732
	LOSS [training: 1.213832632819034 | validation: 1.1985942803928495]
	TIME [epoch: 8.35 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.203630291761439		[learning rate: 0.00037996]
	Learning Rate: 0.000379959
	LOSS [training: 1.203630291761439 | validation: 1.1984572126104087]
	TIME [epoch: 8.36 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1929137130273597		[learning rate: 0.00037721]
	Learning Rate: 0.000377206
	LOSS [training: 1.1929137130273597 | validation: 1.195401629057101]
	TIME [epoch: 8.36 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.182030026732208		[learning rate: 0.00037447]
	Learning Rate: 0.000374474
	LOSS [training: 1.182030026732208 | validation: 1.1911672356080745]
	TIME [epoch: 8.46 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1772624531438385		[learning rate: 0.00037176]
	Learning Rate: 0.00037176
	LOSS [training: 1.1772624531438385 | validation: 1.2115681009843073]
	TIME [epoch: 8.36 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1763180782779206		[learning rate: 0.00036907]
	Learning Rate: 0.000369067
	LOSS [training: 1.1763180782779206 | validation: 1.2073097696112995]
	TIME [epoch: 8.34 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.168282694207065		[learning rate: 0.00036639]
	Learning Rate: 0.000366393
	LOSS [training: 1.168282694207065 | validation: 1.2074119094164395]
	TIME [epoch: 8.35 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1651817551306807		[learning rate: 0.00036374]
	Learning Rate: 0.000363739
	LOSS [training: 1.1651817551306807 | validation: 1.207218103165098]
	TIME [epoch: 8.34 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1627735777687263		[learning rate: 0.0003611]
	Learning Rate: 0.000361103
	LOSS [training: 1.1627735777687263 | validation: 1.1974091637740005]
	TIME [epoch: 8.35 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.162276386138919		[learning rate: 0.00035849]
	Learning Rate: 0.000358487
	LOSS [training: 1.162276386138919 | validation: 1.1949458042690577]
	TIME [epoch: 8.4 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1538371358548105		[learning rate: 0.00035589]
	Learning Rate: 0.00035589
	LOSS [training: 1.1538371358548105 | validation: 1.1929216130297449]
	TIME [epoch: 8.36 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1505578892323067		[learning rate: 0.00035331]
	Learning Rate: 0.000353312
	LOSS [training: 1.1505578892323067 | validation: 1.2006294637482904]
	TIME [epoch: 8.35 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484398386459087		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.1484398386459087 | validation: 1.2004928947407623]
	TIME [epoch: 8.36 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417840901846488		[learning rate: 0.00034821]
	Learning Rate: 0.000348211
	LOSS [training: 1.1417840901846488 | validation: 1.1937078517997666]
	TIME [epoch: 8.36 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386643308890396		[learning rate: 0.00034569]
	Learning Rate: 0.000345688
	LOSS [training: 1.1386643308890396 | validation: 1.1986000292997923]
	TIME [epoch: 8.36 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367654225869603		[learning rate: 0.00034318]
	Learning Rate: 0.000343183
	LOSS [training: 1.1367654225869603 | validation: 1.2069490943924372]
	TIME [epoch: 8.4 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.139013323392873		[learning rate: 0.0003407]
	Learning Rate: 0.000340697
	LOSS [training: 1.139013323392873 | validation: 1.196816346894571]
	TIME [epoch: 8.35 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1309393455694547		[learning rate: 0.00033823]
	Learning Rate: 0.000338229
	LOSS [training: 1.1309393455694547 | validation: 1.196043441026446]
	TIME [epoch: 8.36 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1223507090912719		[learning rate: 0.00033578]
	Learning Rate: 0.000335778
	LOSS [training: 1.1223507090912719 | validation: 1.194592794672055]
	TIME [epoch: 8.35 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194513538285018		[learning rate: 0.00033335]
	Learning Rate: 0.000333346
	LOSS [training: 1.1194513538285018 | validation: 1.1913911238045727]
	TIME [epoch: 8.36 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1117576825692703		[learning rate: 0.00033093]
	Learning Rate: 0.000330931
	LOSS [training: 1.1117576825692703 | validation: 1.184561585453166]
	TIME [epoch: 8.37 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1036412093380765		[learning rate: 0.00032853]
	Learning Rate: 0.000328533
	LOSS [training: 1.1036412093380765 | validation: 1.1825856946571558]
	TIME [epoch: 8.37 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1027398724648767		[learning rate: 0.00032615]
	Learning Rate: 0.000326153
	LOSS [training: 1.1027398724648767 | validation: 1.1897627646230284]
	TIME [epoch: 8.35 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.098522507270583		[learning rate: 0.00032379]
	Learning Rate: 0.00032379
	LOSS [training: 1.098522507270583 | validation: 1.179341989513591]
	TIME [epoch: 8.35 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1007050029361096		[learning rate: 0.00032144]
	Learning Rate: 0.000321444
	LOSS [training: 1.1007050029361096 | validation: 1.1869129717258708]
	TIME [epoch: 8.35 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1015813144158075		[learning rate: 0.00031912]
	Learning Rate: 0.000319115
	LOSS [training: 1.1015813144158075 | validation: 1.1849905325229937]
	TIME [epoch: 8.34 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867735417530313		[learning rate: 0.0003168]
	Learning Rate: 0.000316803
	LOSS [training: 1.0867735417530313 | validation: 1.1769961178552202]
	TIME [epoch: 8.38 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0746575923289772		[learning rate: 0.00031451]
	Learning Rate: 0.000314508
	LOSS [training: 1.0746575923289772 | validation: 1.1769010732469465]
	TIME [epoch: 8.38 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903480515436381		[learning rate: 0.00031223]
	Learning Rate: 0.000312229
	LOSS [training: 1.0903480515436381 | validation: 1.198943504579884]
	TIME [epoch: 8.35 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1162887472862675		[learning rate: 0.00030997]
	Learning Rate: 0.000309967
	LOSS [training: 1.1162887472862675 | validation: 1.1917470165517217]
	TIME [epoch: 8.34 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.10296413241009		[learning rate: 0.00030772]
	Learning Rate: 0.000307722
	LOSS [training: 1.10296413241009 | validation: 1.1885134477572918]
	TIME [epoch: 8.34 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982092334167768		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.0982092334167768 | validation: 1.1809813663921163]
	TIME [epoch: 8.36 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902581434621232		[learning rate: 0.00030328]
	Learning Rate: 0.000303279
	LOSS [training: 1.0902581434621232 | validation: 1.1839154741232165]
	TIME [epoch: 8.39 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0858235741516906		[learning rate: 0.00030108]
	Learning Rate: 0.000301082
	LOSS [training: 1.0858235741516906 | validation: 1.1723288483909948]
	TIME [epoch: 8.35 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0679870781676208		[learning rate: 0.0002989]
	Learning Rate: 0.0002989
	LOSS [training: 1.0679870781676208 | validation: 1.1533150954496487]
	TIME [epoch: 8.34 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0541933655021531		[learning rate: 0.00029673]
	Learning Rate: 0.000296735
	LOSS [training: 1.0541933655021531 | validation: 1.154305322133871]
	TIME [epoch: 8.35 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604185897644611		[learning rate: 0.00029458]
	Learning Rate: 0.000294585
	LOSS [training: 1.0604185897644611 | validation: 1.1643793002186043]
	TIME [epoch: 8.34 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632673925296763		[learning rate: 0.00029245]
	Learning Rate: 0.000292451
	LOSS [training: 1.0632673925296763 | validation: 1.163345716283108]
	TIME [epoch: 8.35 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0527173513021963		[learning rate: 0.00029033]
	Learning Rate: 0.000290332
	LOSS [training: 1.0527173513021963 | validation: 1.148202763785715]
	TIME [epoch: 8.38 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0410531174192559		[learning rate: 0.00028823]
	Learning Rate: 0.000288228
	LOSS [training: 1.0410531174192559 | validation: 1.1360407146458302]
	TIME [epoch: 8.34 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0387997363850157		[learning rate: 0.00028614]
	Learning Rate: 0.00028614
	LOSS [training: 1.0387997363850157 | validation: 1.1368884738228913]
	TIME [epoch: 8.34 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0360531069080547		[learning rate: 0.00028407]
	Learning Rate: 0.000284067
	LOSS [training: 1.0360531069080547 | validation: 1.1404665805082224]
	TIME [epoch: 8.35 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.036206684748876		[learning rate: 0.00028201]
	Learning Rate: 0.000282009
	LOSS [training: 1.036206684748876 | validation: 1.1321021309835022]
	TIME [epoch: 8.35 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0364921465632952		[learning rate: 0.00027997]
	Learning Rate: 0.000279966
	LOSS [training: 1.0364921465632952 | validation: 1.1341785244405627]
	TIME [epoch: 8.37 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.028429628744894		[learning rate: 0.00027794]
	Learning Rate: 0.000277938
	LOSS [training: 1.028429628744894 | validation: 1.1181723289256045]
	TIME [epoch: 8.37 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.012884026140011		[learning rate: 0.00027592]
	Learning Rate: 0.000275924
	LOSS [training: 1.012884026140011 | validation: 1.0897543599211041]
	TIME [epoch: 8.34 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0061253897554736		[learning rate: 0.00027392]
	Learning Rate: 0.000273925
	LOSS [training: 1.0061253897554736 | validation: 1.0628245748404084]
	TIME [epoch: 8.33 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9886655371396772		[learning rate: 0.00027194]
	Learning Rate: 0.00027194
	LOSS [training: 0.9886655371396772 | validation: 1.0496938714559638]
	TIME [epoch: 8.33 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9850078298378716		[learning rate: 0.00026997]
	Learning Rate: 0.00026997
	LOSS [training: 0.9850078298378716 | validation: 1.0474220612321319]
	TIME [epoch: 8.34 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9859653189510441		[learning rate: 0.00026801]
	Learning Rate: 0.000268014
	LOSS [training: 0.9859653189510441 | validation: 1.0593852393246408]
	TIME [epoch: 8.37 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822530060936437		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.9822530060936437 | validation: 1.0206197855254038]
	TIME [epoch: 8.35 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597395767774044		[learning rate: 0.00026414]
	Learning Rate: 0.000264145
	LOSS [training: 0.9597395767774044 | validation: 1.0116419855318322]
	TIME [epoch: 8.34 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519797978436031		[learning rate: 0.00026223]
	Learning Rate: 0.000262231
	LOSS [training: 0.9519797978436031 | validation: 1.009923583361283]
	TIME [epoch: 8.34 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9499831574236108		[learning rate: 0.00026033]
	Learning Rate: 0.000260331
	LOSS [training: 0.9499831574236108 | validation: 1.0090086524279056]
	TIME [epoch: 8.34 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9481101122256412		[learning rate: 0.00025845]
	Learning Rate: 0.000258445
	LOSS [training: 0.9481101122256412 | validation: 0.9866336611332308]
	TIME [epoch: 8.37 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9314130359405017		[learning rate: 0.00025657]
	Learning Rate: 0.000256573
	LOSS [training: 0.9314130359405017 | validation: 0.9781217275603]
	TIME [epoch: 8.4 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267702408642028		[learning rate: 0.00025471]
	Learning Rate: 0.000254714
	LOSS [training: 0.9267702408642028 | validation: 0.9856031532256356]
	TIME [epoch: 8.35 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179248582290542		[learning rate: 0.00025287]
	Learning Rate: 0.000252868
	LOSS [training: 0.9179248582290542 | validation: 0.9573615977003471]
	TIME [epoch: 8.35 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9090340564692673		[learning rate: 0.00025104]
	Learning Rate: 0.000251037
	LOSS [training: 0.9090340564692673 | validation: 0.9561876726518423]
	TIME [epoch: 8.36 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9062587621633093		[learning rate: 0.00024922]
	Learning Rate: 0.000249218
	LOSS [training: 0.9062587621633093 | validation: 0.9539593636780936]
	TIME [epoch: 8.35 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8996433670292464		[learning rate: 0.00024741]
	Learning Rate: 0.000247412
	LOSS [training: 0.8996433670292464 | validation: 0.9398775356741899]
	TIME [epoch: 8.36 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8939972592252888		[learning rate: 0.00024562]
	Learning Rate: 0.00024562
	LOSS [training: 0.8939972592252888 | validation: 0.9380640451535933]
	TIME [epoch: 8.38 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8863385336026991		[learning rate: 0.00024384]
	Learning Rate: 0.00024384
	LOSS [training: 0.8863385336026991 | validation: 0.9326973057670179]
	TIME [epoch: 8.36 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805252281160005		[learning rate: 0.00024207]
	Learning Rate: 0.000242074
	LOSS [training: 0.8805252281160005 | validation: 0.9274506669739242]
	TIME [epoch: 8.32 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8756245046956608		[learning rate: 0.00024032]
	Learning Rate: 0.00024032
	LOSS [training: 0.8756245046956608 | validation: 0.9289578559818764]
	TIME [epoch: 8.34 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782600661704549		[learning rate: 0.00023858]
	Learning Rate: 0.000238579
	LOSS [training: 0.8782600661704549 | validation: 0.9146393013065774]
	TIME [epoch: 8.34 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8701732316666515		[learning rate: 0.00023685]
	Learning Rate: 0.00023685
	LOSS [training: 0.8701732316666515 | validation: 0.9094256547103619]
	TIME [epoch: 8.37 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8667461179010536		[learning rate: 0.00023513]
	Learning Rate: 0.000235134
	LOSS [training: 0.8667461179010536 | validation: 0.9095623440199561]
	TIME [epoch: 8.36 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8643942485200121		[learning rate: 0.00023343]
	Learning Rate: 0.000233431
	LOSS [training: 0.8643942485200121 | validation: 0.9041665653335156]
	TIME [epoch: 8.34 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8553018288417703		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.8553018288417703 | validation: 0.8901283882044174]
	TIME [epoch: 8.35 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8505365965440086		[learning rate: 0.00023006]
	Learning Rate: 0.000230061
	LOSS [training: 0.8505365965440086 | validation: 0.8747913784917136]
	TIME [epoch: 8.35 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425917563099395		[learning rate: 0.00022839]
	Learning Rate: 0.000228394
	LOSS [training: 0.8425917563099395 | validation: 0.8660847149875481]
	TIME [epoch: 8.35 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8294822053897078		[learning rate: 0.00022674]
	Learning Rate: 0.000226739
	LOSS [training: 0.8294822053897078 | validation: 0.8568691672249604]
	TIME [epoch: 8.39 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229890488747031		[learning rate: 0.0002251]
	Learning Rate: 0.000225096
	LOSS [training: 0.8229890488747031 | validation: 0.8429072140034076]
	TIME [epoch: 8.36 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8166361799616748		[learning rate: 0.00022347]
	Learning Rate: 0.000223466
	LOSS [training: 0.8166361799616748 | validation: 0.83386458136426]
	TIME [epoch: 8.34 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8130646064675204		[learning rate: 0.00022185]
	Learning Rate: 0.000221847
	LOSS [training: 0.8130646064675204 | validation: 0.827773739377949]
	TIME [epoch: 8.34 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8042092999664306		[learning rate: 0.00022024]
	Learning Rate: 0.000220239
	LOSS [training: 0.8042092999664306 | validation: 0.8181590413697462]
	TIME [epoch: 8.34 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037069452321716		[learning rate: 0.00021864]
	Learning Rate: 0.000218644
	LOSS [training: 0.8037069452321716 | validation: 0.816758880589207]
	TIME [epoch: 8.35 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8010404455922269		[learning rate: 0.00021706]
	Learning Rate: 0.00021706
	LOSS [training: 0.8010404455922269 | validation: 0.8016936523702559]
	TIME [epoch: 8.39 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7848196324091714		[learning rate: 0.00021549]
	Learning Rate: 0.000215487
	LOSS [training: 0.7848196324091714 | validation: 0.7842064243959459]
	TIME [epoch: 8.34 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7754287437863805		[learning rate: 0.00021393]
	Learning Rate: 0.000213926
	LOSS [training: 0.7754287437863805 | validation: 0.7770265653212134]
	TIME [epoch: 8.34 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7560037599307567		[learning rate: 0.00021238]
	Learning Rate: 0.000212376
	LOSS [training: 0.7560037599307567 | validation: 0.7542587100520362]
	TIME [epoch: 8.34 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307151698395624		[learning rate: 0.00021084]
	Learning Rate: 0.000210837
	LOSS [training: 0.7307151698395624 | validation: 0.7443440636314367]
	TIME [epoch: 8.33 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137109999245719		[learning rate: 0.00020931]
	Learning Rate: 0.00020931
	LOSS [training: 0.7137109999245719 | validation: 0.7348379208705395]
	TIME [epoch: 8.37 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061951772824429		[learning rate: 0.00020779]
	Learning Rate: 0.000207793
	LOSS [training: 0.7061951772824429 | validation: 0.7217318704800553]
	TIME [epoch: 8.38 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931593222644494		[learning rate: 0.00020629]
	Learning Rate: 0.000206288
	LOSS [training: 0.6931593222644494 | validation: 0.7163565636798195]
	TIME [epoch: 8.34 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859585734669273		[learning rate: 0.00020479]
	Learning Rate: 0.000204793
	LOSS [training: 0.6859585734669273 | validation: 0.7031667406778238]
	TIME [epoch: 8.34 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771326133837527		[learning rate: 0.00020331]
	Learning Rate: 0.00020331
	LOSS [training: 0.6771326133837527 | validation: 0.6934973218134455]
	TIME [epoch: 8.34 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678329196444256		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.6678329196444256 | validation: 0.6935293577908637]
	TIME [epoch: 8.34 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615900560480599		[learning rate: 0.00020037]
	Learning Rate: 0.000200374
	LOSS [training: 0.6615900560480599 | validation: 0.6784141163639315]
	TIME [epoch: 8.37 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535745653790721		[learning rate: 0.00019892]
	Learning Rate: 0.000198923
	LOSS [training: 0.6535745653790721 | validation: 0.6724395542819734]
	TIME [epoch: 8.36 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428759089289156		[learning rate: 0.00019748]
	Learning Rate: 0.000197482
	LOSS [training: 0.6428759089289156 | validation: 0.6617768213976853]
	TIME [epoch: 8.33 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6362670650836583		[learning rate: 0.00019605]
	Learning Rate: 0.000196051
	LOSS [training: 0.6362670650836583 | validation: 0.6559765068382908]
	TIME [epoch: 8.34 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.626198765218195		[learning rate: 0.00019463]
	Learning Rate: 0.00019463
	LOSS [training: 0.626198765218195 | validation: 0.6414363650926589]
	TIME [epoch: 8.34 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6181694954074104		[learning rate: 0.00019322]
	Learning Rate: 0.00019322
	LOSS [training: 0.6181694954074104 | validation: 0.641226092802923]
	TIME [epoch: 8.34 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100481652734355		[learning rate: 0.00019182]
	Learning Rate: 0.00019182
	LOSS [training: 0.6100481652734355 | validation: 0.6306984732008729]
	TIME [epoch: 8.38 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6036725412227885		[learning rate: 0.00019043]
	Learning Rate: 0.000190431
	LOSS [training: 0.6036725412227885 | validation: 0.6300003553122815]
	TIME [epoch: 8.35 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974864928325956		[learning rate: 0.00018905]
	Learning Rate: 0.000189051
	LOSS [training: 0.5974864928325956 | validation: 0.6274575174165917]
	TIME [epoch: 8.34 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893218822284466		[learning rate: 0.00018768]
	Learning Rate: 0.000187681
	LOSS [training: 0.5893218822284466 | validation: 0.6232215732551085]
	TIME [epoch: 8.34 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5861321426570485		[learning rate: 0.00018632]
	Learning Rate: 0.000186322
	LOSS [training: 0.5861321426570485 | validation: 0.6104663448510363]
	TIME [epoch: 8.34 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815097782233916		[learning rate: 0.00018497]
	Learning Rate: 0.000184972
	LOSS [training: 0.5815097782233916 | validation: 0.6098362584267241]
	TIME [epoch: 8.36 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726329295847123		[learning rate: 0.00018363]
	Learning Rate: 0.000183632
	LOSS [training: 0.5726329295847123 | validation: 0.6035926494930848]
	TIME [epoch: 8.39 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5702951785612348		[learning rate: 0.0001823]
	Learning Rate: 0.000182301
	LOSS [training: 0.5702951785612348 | validation: 0.6066283638865276]
	TIME [epoch: 8.33 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665050101692243		[learning rate: 0.00018098]
	Learning Rate: 0.00018098
	LOSS [training: 0.5665050101692243 | validation: 0.5996225101804233]
	TIME [epoch: 8.4 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644644366594002		[learning rate: 0.00017967]
	Learning Rate: 0.000179669
	LOSS [training: 0.5644644366594002 | validation: 0.5988369839805694]
	TIME [epoch: 8.33 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.559501223824852		[learning rate: 0.00017837]
	Learning Rate: 0.000178368
	LOSS [training: 0.559501223824852 | validation: 0.5851762986389368]
	TIME [epoch: 8.34 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569470518687406		[learning rate: 0.00017708]
	Learning Rate: 0.000177075
	LOSS [training: 0.5569470518687406 | validation: 0.5884371072856467]
	TIME [epoch: 8.38 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565544211975071		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.5565544211975071 | validation: 0.5951480493180685]
	TIME [epoch: 8.37 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5504234744006664		[learning rate: 0.00017452]
	Learning Rate: 0.000174519
	LOSS [training: 0.5504234744006664 | validation: 0.5891346179057175]
	TIME [epoch: 8.35 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5479468050738969		[learning rate: 0.00017325]
	Learning Rate: 0.000173254
	LOSS [training: 0.5479468050738969 | validation: 0.5846281536067575]
	TIME [epoch: 8.33 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450828407612885		[learning rate: 0.000172]
	Learning Rate: 0.000171999
	LOSS [training: 0.5450828407612885 | validation: 0.5771857592421998]
	TIME [epoch: 8.35 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5391197875665725		[learning rate: 0.00017075]
	Learning Rate: 0.000170753
	LOSS [training: 0.5391197875665725 | validation: 0.5837157348314441]
	TIME [epoch: 8.35 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.538522977406124		[learning rate: 0.00016952]
	Learning Rate: 0.000169516
	LOSS [training: 0.538522977406124 | validation: 0.5773756484469841]
	TIME [epoch: 8.38 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373545442965786		[learning rate: 0.00016829]
	Learning Rate: 0.000168288
	LOSS [training: 0.5373545442965786 | validation: 0.5736516793713231]
	TIME [epoch: 8.36 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355908894275239		[learning rate: 0.00016707]
	Learning Rate: 0.000167069
	LOSS [training: 0.5355908894275239 | validation: 0.564995930501709]
	TIME [epoch: 8.35 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322204804558119		[learning rate: 0.00016586]
	Learning Rate: 0.000165858
	LOSS [training: 0.5322204804558119 | validation: 0.5716957527847324]
	TIME [epoch: 8.34 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301614928905672		[learning rate: 0.00016466]
	Learning Rate: 0.000164657
	LOSS [training: 0.5301614928905672 | validation: 0.5650011683470177]
	TIME [epoch: 8.34 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316434457859116		[learning rate: 0.00016346]
	Learning Rate: 0.000163464
	LOSS [training: 0.5316434457859116 | validation: 0.5607447429499788]
	TIME [epoch: 8.34 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5267883995298573		[learning rate: 0.00016228]
	Learning Rate: 0.000162279
	LOSS [training: 0.5267883995298573 | validation: 0.5643959368164138]
	TIME [epoch: 8.39 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272265768530202		[learning rate: 0.0001611]
	Learning Rate: 0.000161104
	LOSS [training: 0.5272265768530202 | validation: 0.5652722575779392]
	TIME [epoch: 8.35 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.524811493764086		[learning rate: 0.00015994]
	Learning Rate: 0.000159936
	LOSS [training: 0.524811493764086 | validation: 0.5578541733034809]
	TIME [epoch: 8.34 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5221438329986962		[learning rate: 0.00015878]
	Learning Rate: 0.000158778
	LOSS [training: 0.5221438329986962 | validation: 0.5517046569377841]
	TIME [epoch: 8.35 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.520415529205273		[learning rate: 0.00015763]
	Learning Rate: 0.000157627
	LOSS [training: 0.520415529205273 | validation: 0.5591189993863975]
	TIME [epoch: 8.35 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184671438315647		[learning rate: 0.00015649]
	Learning Rate: 0.000156485
	LOSS [training: 0.5184671438315647 | validation: 0.5512874663152405]
	TIME [epoch: 8.34 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193268858092068		[learning rate: 0.00015535]
	Learning Rate: 0.000155352
	LOSS [training: 0.5193268858092068 | validation: 0.5545872088151071]
	TIME [epoch: 8.39 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176086353822287		[learning rate: 0.00015423]
	Learning Rate: 0.000154226
	LOSS [training: 0.5176086353822287 | validation: 0.5549053813485783]
	TIME [epoch: 8.34 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5156857473744811		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.5156857473744811 | validation: 0.5497431898925372]
	TIME [epoch: 8.34 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140414397302799		[learning rate: 0.000152]
	Learning Rate: 0.000152
	LOSS [training: 0.5140414397302799 | validation: 0.5494744112636438]
	TIME [epoch: 8.34 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.514305766873448		[learning rate: 0.0001509]
	Learning Rate: 0.000150898
	LOSS [training: 0.514305766873448 | validation: 0.5466745600871519]
	TIME [epoch: 8.34 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.51061723213547		[learning rate: 0.00014981]
	Learning Rate: 0.000149805
	LOSS [training: 0.51061723213547 | validation: 0.5474434475833788]
	TIME [epoch: 8.36 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088569549638668		[learning rate: 0.00014872]
	Learning Rate: 0.00014872
	LOSS [training: 0.5088569549638668 | validation: 0.54174228484954]
	TIME [epoch: 8.36 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5114029690937465		[learning rate: 0.00014764]
	Learning Rate: 0.000147642
	LOSS [training: 0.5114029690937465 | validation: 0.5374305568699751]
	TIME [epoch: 8.33 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074595031312814		[learning rate: 0.00014657]
	Learning Rate: 0.000146573
	LOSS [training: 0.5074595031312814 | validation: 0.546196568038078]
	TIME [epoch: 8.33 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5061452792699561		[learning rate: 0.00014551]
	Learning Rate: 0.000145511
	LOSS [training: 0.5061452792699561 | validation: 0.5363009797939048]
	TIME [epoch: 8.33 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5053228350789047		[learning rate: 0.00014446]
	Learning Rate: 0.000144456
	LOSS [training: 0.5053228350789047 | validation: 0.5406313093258048]
	TIME [epoch: 8.34 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5058792294838463		[learning rate: 0.00014341]
	Learning Rate: 0.00014341
	LOSS [training: 0.5058792294838463 | validation: 0.5352574802119183]
	TIME [epoch: 8.37 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004664623072612		[learning rate: 0.00014237]
	Learning Rate: 0.000142371
	LOSS [training: 0.5004664623072612 | validation: 0.5350138936606885]
	TIME [epoch: 8.36 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013763241127145		[learning rate: 0.00014134]
	Learning Rate: 0.000141339
	LOSS [training: 0.5013763241127145 | validation: 0.5273839330328586]
	TIME [epoch: 8.34 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973634282357674		[learning rate: 0.00014032]
	Learning Rate: 0.000140315
	LOSS [training: 0.4973634282357674 | validation: 0.5279927039252154]
	TIME [epoch: 8.34 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986863592805929		[learning rate: 0.0001393]
	Learning Rate: 0.000139299
	LOSS [training: 0.4986863592805929 | validation: 0.5245631300053669]
	TIME [epoch: 8.34 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4959886302771165		[learning rate: 0.00013829]
	Learning Rate: 0.00013829
	LOSS [training: 0.4959886302771165 | validation: 0.524786789963321]
	TIME [epoch: 8.35 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49933888696235934		[learning rate: 0.00013729]
	Learning Rate: 0.000137288
	LOSS [training: 0.49933888696235934 | validation: 0.5240544035927406]
	TIME [epoch: 8.38 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49704581715576257		[learning rate: 0.00013629]
	Learning Rate: 0.000136293
	LOSS [training: 0.49704581715576257 | validation: 0.5299438824364984]
	TIME [epoch: 8.34 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49396619144216375		[learning rate: 0.00013531]
	Learning Rate: 0.000135306
	LOSS [training: 0.49396619144216375 | validation: 0.5236700873878501]
	TIME [epoch: 8.33 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.494264481598809		[learning rate: 0.00013433]
	Learning Rate: 0.000134325
	LOSS [training: 0.494264481598809 | validation: 0.5219327506234048]
	TIME [epoch: 8.33 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4942535149744899		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.4942535149744899 | validation: 0.5258468749264662]
	TIME [epoch: 8.33 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938264005409684		[learning rate: 0.00013239]
	Learning Rate: 0.000132386
	LOSS [training: 0.4938264005409684 | validation: 0.5231216378657677]
	TIME [epoch: 8.36 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888873079529497		[learning rate: 0.00013143]
	Learning Rate: 0.000131427
	LOSS [training: 0.4888873079529497 | validation: 0.5258329789194501]
	TIME [epoch: 8.39 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.49083811849774894		[learning rate: 0.00013047]
	Learning Rate: 0.000130475
	LOSS [training: 0.49083811849774894 | validation: 0.5205558533794825]
	TIME [epoch: 8.35 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868487958259894		[learning rate: 0.00012953]
	Learning Rate: 0.000129529
	LOSS [training: 0.4868487958259894 | validation: 0.5238074890314914]
	TIME [epoch: 8.35 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880480113778717		[learning rate: 0.00012859]
	Learning Rate: 0.000128591
	LOSS [training: 0.4880480113778717 | validation: 0.5229016690163859]
	TIME [epoch: 8.34 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904318444304022		[learning rate: 0.00012766]
	Learning Rate: 0.000127659
	LOSS [training: 0.4904318444304022 | validation: 0.5123072763182055]
	TIME [epoch: 8.34 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881888398716497		[learning rate: 0.00012673]
	Learning Rate: 0.000126735
	LOSS [training: 0.4881888398716497 | validation: 0.5135836107834291]
	TIME [epoch: 8.36 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4855856492529972		[learning rate: 0.00012582]
	Learning Rate: 0.000125816
	LOSS [training: 0.4855856492529972 | validation: 0.5178459910531937]
	TIME [epoch: 8.37 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.48214574456482306		[learning rate: 0.0001249]
	Learning Rate: 0.000124905
	LOSS [training: 0.48214574456482306 | validation: 0.5179946954147546]
	TIME [epoch: 8.34 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832124954918931		[learning rate: 0.000124]
	Learning Rate: 0.000124
	LOSS [training: 0.4832124954918931 | validation: 0.5180337212290999]
	TIME [epoch: 8.34 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4825928927535821		[learning rate: 0.0001231]
	Learning Rate: 0.000123101
	LOSS [training: 0.4825928927535821 | validation: 0.5134863499568334]
	TIME [epoch: 8.34 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812044273918257		[learning rate: 0.00012221]
	Learning Rate: 0.00012221
	LOSS [training: 0.4812044273918257 | validation: 0.5152947592357566]
	TIME [epoch: 8.33 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4796912945879927		[learning rate: 0.00012132]
	Learning Rate: 0.000121324
	LOSS [training: 0.4796912945879927 | validation: 0.5146633219802591]
	TIME [epoch: 8.38 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823126885836965		[learning rate: 0.00012045]
	Learning Rate: 0.000120445
	LOSS [training: 0.4823126885836965 | validation: 0.5122974224470757]
	TIME [epoch: 8.34 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4788958402520893		[learning rate: 0.00011957]
	Learning Rate: 0.000119573
	LOSS [training: 0.4788958402520893 | validation: 0.50948631177323]
	TIME [epoch: 8.34 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4784235720625653		[learning rate: 0.00011871]
	Learning Rate: 0.000118706
	LOSS [training: 0.4784235720625653 | validation: 0.5079685873460736]
	TIME [epoch: 8.33 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.477675589154692		[learning rate: 0.00011785]
	Learning Rate: 0.000117846
	LOSS [training: 0.477675589154692 | validation: 0.5021852769499433]
	TIME [epoch: 8.33 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47933904671339034		[learning rate: 0.00011699]
	Learning Rate: 0.000116992
	LOSS [training: 0.47933904671339034 | validation: 0.5070578050942733]
	TIME [epoch: 8.34 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47722892135624295		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.47722892135624295 | validation: 0.5054587412542255]
	TIME [epoch: 8.37 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740989377781794		[learning rate: 0.0001153]
	Learning Rate: 0.000115303
	LOSS [training: 0.4740989377781794 | validation: 0.5083998114779017]
	TIME [epoch: 8.34 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750442658308327		[learning rate: 0.00011447]
	Learning Rate: 0.000114468
	LOSS [training: 0.4750442658308327 | validation: 0.5051180107357688]
	TIME [epoch: 8.33 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4733869533656213		[learning rate: 0.00011364]
	Learning Rate: 0.000113639
	LOSS [training: 0.4733869533656213 | validation: 0.5120501689358606]
	TIME [epoch: 8.33 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47461453196936165		[learning rate: 0.00011282]
	Learning Rate: 0.000112815
	LOSS [training: 0.47461453196936165 | validation: 0.50467394449907]
	TIME [epoch: 8.33 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47224664978709546		[learning rate: 0.000112]
	Learning Rate: 0.000111998
	LOSS [training: 0.47224664978709546 | validation: 0.5024919876772149]
	TIME [epoch: 8.35 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47204892853942476		[learning rate: 0.00011119]
	Learning Rate: 0.000111187
	LOSS [training: 0.47204892853942476 | validation: 0.5052462631618726]
	TIME [epoch: 8.38 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709779235908855		[learning rate: 0.00011038]
	Learning Rate: 0.000110381
	LOSS [training: 0.4709779235908855 | validation: 0.5007689548459588]
	TIME [epoch: 8.33 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.47177391386462264		[learning rate: 0.00010958]
	Learning Rate: 0.000109581
	LOSS [training: 0.47177391386462264 | validation: 0.4935474492310268]
	TIME [epoch: 8.33 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46991603642177926		[learning rate: 0.00010879]
	Learning Rate: 0.000108787
	LOSS [training: 0.46991603642177926 | validation: 0.49877009660294835]
	TIME [epoch: 8.34 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711421440106879		[learning rate: 0.000108]
	Learning Rate: 0.000107999
	LOSS [training: 0.4711421440106879 | validation: 0.500700551715379]
	TIME [epoch: 8.33 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667959803498874		[learning rate: 0.00010722]
	Learning Rate: 0.000107217
	LOSS [training: 0.4667959803498874 | validation: 0.4974310743784864]
	TIME [epoch: 8.36 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701045102775134		[learning rate: 0.00010644]
	Learning Rate: 0.00010644
	LOSS [training: 0.4701045102775134 | validation: 0.4952715196594307]
	TIME [epoch: 8.36 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698139548162129		[learning rate: 0.00010567]
	Learning Rate: 0.000105669
	LOSS [training: 0.4698139548162129 | validation: 0.4958869644459516]
	TIME [epoch: 8.33 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.465520965575264		[learning rate: 0.0001049]
	Learning Rate: 0.000104903
	LOSS [training: 0.465520965575264 | validation: 0.4948294771603333]
	TIME [epoch: 8.33 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.467368856341642		[learning rate: 0.00010414]
	Learning Rate: 0.000104143
	LOSS [training: 0.467368856341642 | validation: 0.4966941396529819]
	TIME [epoch: 8.33 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657421500016092		[learning rate: 0.00010339]
	Learning Rate: 0.000103389
	LOSS [training: 0.4657421500016092 | validation: 0.494244745110337]
	TIME [epoch: 8.34 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664949845339746		[learning rate: 0.00010264]
	Learning Rate: 0.00010264
	LOSS [training: 0.4664949845339746 | validation: 0.4950937120555713]
	TIME [epoch: 8.38 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46278249706507857		[learning rate: 0.0001019]
	Learning Rate: 0.000101896
	LOSS [training: 0.46278249706507857 | validation: 0.4944245159948367]
	TIME [epoch: 8.36 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46443853449270506		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.46443853449270506 | validation: 0.4920727306242464]
	TIME [epoch: 8.34 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46325889339605636		[learning rate: 0.00010043]
	Learning Rate: 0.000100425
	LOSS [training: 0.46325889339605636 | validation: 0.49049186486372126]
	TIME [epoch: 8.34 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46116983108099757		[learning rate: 9.9697e-05]
	Learning Rate: 9.96975e-05
	LOSS [training: 0.46116983108099757 | validation: 0.48919729310311333]
	TIME [epoch: 8.34 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.46274022379022556		[learning rate: 9.8975e-05]
	Learning Rate: 9.89752e-05
	LOSS [training: 0.46274022379022556 | validation: 0.487772702720011]
	TIME [epoch: 8.34 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.458551470279914		[learning rate: 9.8258e-05]
	Learning Rate: 9.82581e-05
	LOSS [training: 0.458551470279914 | validation: 0.4840475835711595]
	TIME [epoch: 8.39 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604879895742933		[learning rate: 9.7546e-05]
	Learning Rate: 9.75463e-05
	LOSS [training: 0.4604879895742933 | validation: 0.48748629059419]
	TIME [epoch: 8.34 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560167140626632		[learning rate: 9.684e-05]
	Learning Rate: 9.68396e-05
	LOSS [training: 0.4560167140626632 | validation: 0.48358581888178176]
	TIME [epoch: 8.34 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589506344860193		[learning rate: 9.6138e-05]
	Learning Rate: 9.61379e-05
	LOSS [training: 0.4589506344860193 | validation: 0.4801915909250223]
	TIME [epoch: 8.34 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4584833731985372		[learning rate: 9.5441e-05]
	Learning Rate: 9.54414e-05
	LOSS [training: 0.4584833731985372 | validation: 0.49161072495971736]
	TIME [epoch: 8.33 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45734220882485854		[learning rate: 9.475e-05]
	Learning Rate: 9.475e-05
	LOSS [training: 0.45734220882485854 | validation: 0.48425670559810896]
	TIME [epoch: 8.35 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45796100382505667		[learning rate: 9.4064e-05]
	Learning Rate: 9.40635e-05
	LOSS [training: 0.45796100382505667 | validation: 0.4857828297168255]
	TIME [epoch: 8.37 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45612459389955384		[learning rate: 9.3382e-05]
	Learning Rate: 9.3382e-05
	LOSS [training: 0.45612459389955384 | validation: 0.4878149503646069]
	TIME [epoch: 8.34 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45472759966053944		[learning rate: 9.2705e-05]
	Learning Rate: 9.27055e-05
	LOSS [training: 0.45472759966053944 | validation: 0.4846934975806882]
	TIME [epoch: 8.33 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.456337369987025		[learning rate: 9.2034e-05]
	Learning Rate: 9.20338e-05
	LOSS [training: 0.456337369987025 | validation: 0.4751941209092848]
	TIME [epoch: 8.34 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45674641508281855		[learning rate: 9.1367e-05]
	Learning Rate: 9.13671e-05
	LOSS [training: 0.45674641508281855 | validation: 0.48113793590736764]
	TIME [epoch: 8.34 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45386545473542383		[learning rate: 9.0705e-05]
	Learning Rate: 9.07051e-05
	LOSS [training: 0.45386545473542383 | validation: 0.4758740485136461]
	TIME [epoch: 8.36 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4520600419635671		[learning rate: 9.0048e-05]
	Learning Rate: 9.00479e-05
	LOSS [training: 0.4520600419635671 | validation: 0.47533674195872855]
	TIME [epoch: 8.36 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526900640726497		[learning rate: 8.9396e-05]
	Learning Rate: 8.93955e-05
	LOSS [training: 0.4526900640726497 | validation: 0.4774447229156513]
	TIME [epoch: 8.33 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545843667293908		[learning rate: 8.8748e-05]
	Learning Rate: 8.87479e-05
	LOSS [training: 0.4545843667293908 | validation: 0.48241286283418494]
	TIME [epoch: 8.34 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45402549857213537		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.45402549857213537 | validation: 0.4787603367633354]
	TIME [epoch: 8.33 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44993373892207256		[learning rate: 8.7467e-05]
	Learning Rate: 8.74666e-05
	LOSS [training: 0.44993373892207256 | validation: 0.48026939919394407]
	TIME [epoch: 8.44 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.45113140964733767		[learning rate: 8.6833e-05]
	Learning Rate: 8.68329e-05
	LOSS [training: 0.45113140964733767 | validation: 0.47650746848986203]
	TIME [epoch: 8.36 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.451737200953899		[learning rate: 8.6204e-05]
	Learning Rate: 8.62038e-05
	LOSS [training: 0.451737200953899 | validation: 0.47903509941137723]
	TIME [epoch: 8.33 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4507819927085436		[learning rate: 8.5579e-05]
	Learning Rate: 8.55793e-05
	LOSS [training: 0.4507819927085436 | validation: 0.4740020307085532]
	TIME [epoch: 8.33 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44927952326614073		[learning rate: 8.4959e-05]
	Learning Rate: 8.49592e-05
	LOSS [training: 0.44927952326614073 | validation: 0.47276498213251583]
	TIME [epoch: 8.33 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510455518501255		[learning rate: 8.4344e-05]
	Learning Rate: 8.43437e-05
	LOSS [training: 0.4510455518501255 | validation: 0.4723698911554963]
	TIME [epoch: 8.34 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4493645163231014		[learning rate: 8.3733e-05]
	Learning Rate: 8.37327e-05
	LOSS [training: 0.4493645163231014 | validation: 0.4703328512153649]
	TIME [epoch: 8.36 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487369801957516		[learning rate: 8.3126e-05]
	Learning Rate: 8.3126e-05
	LOSS [training: 0.4487369801957516 | validation: 0.4707586771976232]
	TIME [epoch: 8.39 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44812639334804094		[learning rate: 8.2524e-05]
	Learning Rate: 8.25238e-05
	LOSS [training: 0.44812639334804094 | validation: 0.4730613359662521]
	TIME [epoch: 8.35 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500642088393215		[learning rate: 8.1926e-05]
	Learning Rate: 8.19259e-05
	LOSS [training: 0.4500642088393215 | validation: 0.4714267205305257]
	TIME [epoch: 8.34 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44751114374918444		[learning rate: 8.1332e-05]
	Learning Rate: 8.13323e-05
	LOSS [training: 0.44751114374918444 | validation: 0.47642766072157694]
	TIME [epoch: 8.33 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449683519882234		[learning rate: 8.0743e-05]
	Learning Rate: 8.07431e-05
	LOSS [training: 0.4449683519882234 | validation: 0.4743846529015928]
	TIME [epoch: 8.32 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44471311125270097		[learning rate: 8.0158e-05]
	Learning Rate: 8.01581e-05
	LOSS [training: 0.44471311125270097 | validation: 0.46972816360304614]
	TIME [epoch: 8.35 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.444284944501747		[learning rate: 7.9577e-05]
	Learning Rate: 7.95774e-05
	LOSS [training: 0.444284944501747 | validation: 0.4709949919576671]
	TIME [epoch: 8.36 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44612690540898303		[learning rate: 7.9001e-05]
	Learning Rate: 7.90008e-05
	LOSS [training: 0.44612690540898303 | validation: 0.47268205831350907]
	TIME [epoch: 8.33 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4466766575965545		[learning rate: 7.8428e-05]
	Learning Rate: 7.84285e-05
	LOSS [training: 0.4466766575965545 | validation: 0.46935498533954834]
	TIME [epoch: 8.33 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44327466182089126		[learning rate: 7.786e-05]
	Learning Rate: 7.78603e-05
	LOSS [training: 0.44327466182089126 | validation: 0.479509286417093]
	TIME [epoch: 8.33 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430991939463654		[learning rate: 7.7296e-05]
	Learning Rate: 7.72962e-05
	LOSS [training: 0.4430991939463654 | validation: 0.47684428562070713]
	TIME [epoch: 8.33 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4443399160013942		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.4443399160013942 | validation: 0.4706859427667071]
	TIME [epoch: 8.36 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430422422664728		[learning rate: 7.618e-05]
	Learning Rate: 7.61802e-05
	LOSS [training: 0.4430422422664728 | validation: 0.4685959964270631]
	TIME [epoch: 8.36 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415415317787661		[learning rate: 7.5628e-05]
	Learning Rate: 7.56283e-05
	LOSS [training: 0.4415415317787661 | validation: 0.4660291176175224]
	TIME [epoch: 8.34 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44124511831877117		[learning rate: 7.508e-05]
	Learning Rate: 7.50804e-05
	LOSS [training: 0.44124511831877117 | validation: 0.4625432765366819]
	TIME [epoch: 8.34 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43933885482189927		[learning rate: 7.4536e-05]
	Learning Rate: 7.45364e-05
	LOSS [training: 0.43933885482189927 | validation: 0.4679188992144906]
	TIME [epoch: 8.34 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43870646241508776		[learning rate: 7.3996e-05]
	Learning Rate: 7.39964e-05
	LOSS [training: 0.43870646241508776 | validation: 0.4687939214092762]
	TIME [epoch: 8.34 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.44133770526146515		[learning rate: 7.346e-05]
	Learning Rate: 7.34603e-05
	LOSS [training: 0.44133770526146515 | validation: 0.46757918304521284]
	TIME [epoch: 8.37 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4397693049969611		[learning rate: 7.2928e-05]
	Learning Rate: 7.29281e-05
	LOSS [training: 0.4397693049969611 | validation: 0.46624841253088695]
	TIME [epoch: 8.33 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413926394678375		[learning rate: 7.24e-05]
	Learning Rate: 7.23997e-05
	LOSS [training: 0.4413926394678375 | validation: 0.4670504705528014]
	TIME [epoch: 8.33 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4408215280531168		[learning rate: 7.1875e-05]
	Learning Rate: 7.18752e-05
	LOSS [training: 0.4408215280531168 | validation: 0.46254073148328023]
	TIME [epoch: 8.33 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4385863514407533		[learning rate: 7.1354e-05]
	Learning Rate: 7.13545e-05
	LOSS [training: 0.4385863514407533 | validation: 0.4715305300407767]
	TIME [epoch: 8.33 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4385466320989461		[learning rate: 7.0838e-05]
	Learning Rate: 7.08375e-05
	LOSS [training: 0.4385466320989461 | validation: 0.46422418900298873]
	TIME [epoch: 8.34 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43926101558836717		[learning rate: 7.0324e-05]
	Learning Rate: 7.03243e-05
	LOSS [training: 0.43926101558836717 | validation: 0.45963296900445083]
	TIME [epoch: 8.37 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387372573080847		[learning rate: 6.9815e-05]
	Learning Rate: 6.98148e-05
	LOSS [training: 0.4387372573080847 | validation: 0.4659073881900282]
	TIME [epoch: 8.33 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43547054809223035		[learning rate: 6.9309e-05]
	Learning Rate: 6.9309e-05
	LOSS [training: 0.43547054809223035 | validation: 0.45931452928323746]
	TIME [epoch: 8.32 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43872545200743895		[learning rate: 6.8807e-05]
	Learning Rate: 6.88069e-05
	LOSS [training: 0.43872545200743895 | validation: 0.46223904450304265]
	TIME [epoch: 8.33 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43479862953166226		[learning rate: 6.8308e-05]
	Learning Rate: 6.83084e-05
	LOSS [training: 0.43479862953166226 | validation: 0.46033857962607927]
	TIME [epoch: 8.33 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4394024866086528		[learning rate: 6.7813e-05]
	Learning Rate: 6.78134e-05
	LOSS [training: 0.4394024866086528 | validation: 0.46209160503894076]
	TIME [epoch: 8.36 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43655634831599577		[learning rate: 6.7322e-05]
	Learning Rate: 6.73221e-05
	LOSS [training: 0.43655634831599577 | validation: 0.45946778954328227]
	TIME [epoch: 8.35 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43521654490636075		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.43521654490636075 | validation: 0.46109488192748116]
	TIME [epoch: 8.34 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4337277833260596		[learning rate: 6.635e-05]
	Learning Rate: 6.63502e-05
	LOSS [training: 0.4337277833260596 | validation: 0.45983033263509665]
	TIME [epoch: 8.32 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43288737531924826		[learning rate: 6.587e-05]
	Learning Rate: 6.58695e-05
	LOSS [training: 0.43288737531924826 | validation: 0.4623903537167276]
	TIME [epoch: 8.33 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43397587138741633		[learning rate: 6.5392e-05]
	Learning Rate: 6.53923e-05
	LOSS [training: 0.43397587138741633 | validation: 0.4583578541578668]
	TIME [epoch: 8.33 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4342760737676654		[learning rate: 6.4919e-05]
	Learning Rate: 6.49185e-05
	LOSS [training: 0.4342760737676654 | validation: 0.45589872111398255]
	TIME [epoch: 8.36 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312971688016108		[learning rate: 6.4448e-05]
	Learning Rate: 6.44482e-05
	LOSS [training: 0.4312971688016108 | validation: 0.46044159079296454]
	TIME [epoch: 8.35 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43353717409245424		[learning rate: 6.3981e-05]
	Learning Rate: 6.39813e-05
	LOSS [training: 0.43353717409245424 | validation: 0.461505095879603]
	TIME [epoch: 8.32 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340469996411512		[learning rate: 6.3518e-05]
	Learning Rate: 6.35177e-05
	LOSS [training: 0.4340469996411512 | validation: 0.46228173301785114]
	TIME [epoch: 8.34 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323227727572273		[learning rate: 6.3058e-05]
	Learning Rate: 6.30575e-05
	LOSS [training: 0.4323227727572273 | validation: 0.4621449998706342]
	TIME [epoch: 8.32 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328188372481365		[learning rate: 6.2601e-05]
	Learning Rate: 6.26007e-05
	LOSS [training: 0.4328188372481365 | validation: 0.451400566490577]
	TIME [epoch: 8.33 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42916206545287766		[learning rate: 6.2147e-05]
	Learning Rate: 6.21471e-05
	LOSS [training: 0.42916206545287766 | validation: 0.46387572998337934]
	TIME [epoch: 8.37 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4310973384055406		[learning rate: 6.1697e-05]
	Learning Rate: 6.16969e-05
	LOSS [training: 0.4310973384055406 | validation: 0.45361829156882594]
	TIME [epoch: 8.34 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327664229212272		[learning rate: 6.125e-05]
	Learning Rate: 6.12499e-05
	LOSS [training: 0.4327664229212272 | validation: 0.45411215379396674]
	TIME [epoch: 8.33 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43119184545088607		[learning rate: 6.0806e-05]
	Learning Rate: 6.08061e-05
	LOSS [training: 0.43119184545088607 | validation: 0.45352083327439285]
	TIME [epoch: 8.33 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43101031426718517		[learning rate: 6.0366e-05]
	Learning Rate: 6.03656e-05
	LOSS [training: 0.43101031426718517 | validation: 0.45317965651299874]
	TIME [epoch: 8.33 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.43065576071415523		[learning rate: 5.9928e-05]
	Learning Rate: 5.99283e-05
	LOSS [training: 0.43065576071415523 | validation: 0.4558865202778229]
	TIME [epoch: 8.34 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42765240685065237		[learning rate: 5.9494e-05]
	Learning Rate: 5.94941e-05
	LOSS [training: 0.42765240685065237 | validation: 0.45787451975217597]
	TIME [epoch: 8.38 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42996066484399886		[learning rate: 5.9063e-05]
	Learning Rate: 5.9063e-05
	LOSS [training: 0.42996066484399886 | validation: 0.45306972025229597]
	TIME [epoch: 8.33 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42647834494674536		[learning rate: 5.8635e-05]
	Learning Rate: 5.86351e-05
	LOSS [training: 0.42647834494674536 | validation: 0.45060281614388]
	TIME [epoch: 8.33 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42670906562437005		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.42670906562437005 | validation: 0.4531394808585562]
	TIME [epoch: 8.33 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291576940277763		[learning rate: 5.7789e-05]
	Learning Rate: 5.77886e-05
	LOSS [training: 0.4291576940277763 | validation: 0.44612847941763306]
	TIME [epoch: 8.33 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4262197326518391		[learning rate: 5.737e-05]
	Learning Rate: 5.73699e-05
	LOSS [training: 0.4262197326518391 | validation: 0.4481446646498197]
	TIME [epoch: 8.35 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278987447264825		[learning rate: 5.6954e-05]
	Learning Rate: 5.69543e-05
	LOSS [training: 0.4278987447264825 | validation: 0.44733508473272765]
	TIME [epoch: 8.35 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258288201185071		[learning rate: 5.6542e-05]
	Learning Rate: 5.65417e-05
	LOSS [training: 0.4258288201185071 | validation: 0.4518207784307095]
	TIME [epoch: 8.33 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42657344686892384		[learning rate: 5.6132e-05]
	Learning Rate: 5.6132e-05
	LOSS [training: 0.42657344686892384 | validation: 0.4452435234954064]
	TIME [epoch: 8.33 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4240165274216848		[learning rate: 5.5725e-05]
	Learning Rate: 5.57253e-05
	LOSS [training: 0.4240165274216848 | validation: 0.44947108183524187]
	TIME [epoch: 8.34 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42683186054548194		[learning rate: 5.5322e-05]
	Learning Rate: 5.53216e-05
	LOSS [training: 0.42683186054548194 | validation: 0.44798679957263743]
	TIME [epoch: 8.33 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224465972582682		[learning rate: 5.4921e-05]
	Learning Rate: 5.49208e-05
	LOSS [training: 0.4224465972582682 | validation: 0.4509522909574969]
	TIME [epoch: 8.37 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226309722916268		[learning rate: 5.4523e-05]
	Learning Rate: 5.45229e-05
	LOSS [training: 0.4226309722916268 | validation: 0.4481027145271008]
	TIME [epoch: 8.35 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42517252940634637		[learning rate: 5.4128e-05]
	Learning Rate: 5.41279e-05
	LOSS [training: 0.42517252940634637 | validation: 0.44797515082196565]
	TIME [epoch: 8.33 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4245303290135838		[learning rate: 5.3736e-05]
	Learning Rate: 5.37357e-05
	LOSS [training: 0.4245303290135838 | validation: 0.45342439862839345]
	TIME [epoch: 8.32 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42495129747522675		[learning rate: 5.3346e-05]
	Learning Rate: 5.33464e-05
	LOSS [training: 0.42495129747522675 | validation: 0.44685038199228544]
	TIME [epoch: 8.32 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4235564125875977		[learning rate: 5.296e-05]
	Learning Rate: 5.29599e-05
	LOSS [training: 0.4235564125875977 | validation: 0.44851663289183064]
	TIME [epoch: 8.33 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226668634936728		[learning rate: 5.2576e-05]
	Learning Rate: 5.25762e-05
	LOSS [training: 0.4226668634936728 | validation: 0.45168885516751955]
	TIME [epoch: 8.37 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232718904713173		[learning rate: 5.2195e-05]
	Learning Rate: 5.21953e-05
	LOSS [training: 0.4232718904713173 | validation: 0.4507862544217246]
	TIME [epoch: 8.32 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217406602227982		[learning rate: 5.1817e-05]
	Learning Rate: 5.18172e-05
	LOSS [training: 0.4217406602227982 | validation: 0.4394209400967617]
	TIME [epoch: 8.33 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231970222984751		[learning rate: 5.1442e-05]
	Learning Rate: 5.14418e-05
	LOSS [training: 0.4231970222984751 | validation: 0.44231987660886585]
	TIME [epoch: 8.33 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224638370876841		[learning rate: 5.1069e-05]
	Learning Rate: 5.10691e-05
	LOSS [training: 0.4224638370876841 | validation: 0.4438246280115816]
	TIME [epoch: 8.34 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.42231555596854325		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.42231555596854325 | validation: 0.4466930584327008]
	TIME [epoch: 8.34 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4195126078993058		[learning rate: 5.0332e-05]
	Learning Rate: 5.03318e-05
	LOSS [training: 0.4195126078993058 | validation: 0.44217288843359914]
	TIME [epoch: 8.37 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.421552135310403		[learning rate: 4.9967e-05]
	Learning Rate: 4.99671e-05
	LOSS [training: 0.421552135310403 | validation: 0.4441269507298173]
	TIME [epoch: 8.34 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4219297989988088		[learning rate: 4.9605e-05]
	Learning Rate: 4.96051e-05
	LOSS [training: 0.4219297989988088 | validation: 0.4456920058935827]
	TIME [epoch: 8.34 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221080964421916		[learning rate: 4.9246e-05]
	Learning Rate: 4.92457e-05
	LOSS [training: 0.4221080964421916 | validation: 0.44154570482080363]
	TIME [epoch: 8.33 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217198253862045		[learning rate: 4.8889e-05]
	Learning Rate: 4.88889e-05
	LOSS [training: 0.4217198253862045 | validation: 0.4415604490914481]
	TIME [epoch: 8.34 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206271163365852		[learning rate: 4.8535e-05]
	Learning Rate: 4.85347e-05
	LOSS [training: 0.4206271163365852 | validation: 0.4418332241348268]
	TIME [epoch: 8.36 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.421672669563301		[learning rate: 4.8183e-05]
	Learning Rate: 4.81831e-05
	LOSS [training: 0.421672669563301 | validation: 0.4484592089571686]
	TIME [epoch: 8.36 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.422726119864955		[learning rate: 4.7834e-05]
	Learning Rate: 4.7834e-05
	LOSS [training: 0.422726119864955 | validation: 0.43814633048672313]
	TIME [epoch: 8.34 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41956588912047466		[learning rate: 4.7487e-05]
	Learning Rate: 4.74875e-05
	LOSS [training: 0.41956588912047466 | validation: 0.4455364118343327]
	TIME [epoch: 8.35 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171078062657049		[learning rate: 4.7143e-05]
	Learning Rate: 4.71434e-05
	LOSS [training: 0.4171078062657049 | validation: 0.4414633200027991]
	TIME [epoch: 8.34 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182033144389141		[learning rate: 4.6802e-05]
	Learning Rate: 4.68019e-05
	LOSS [training: 0.4182033144389141 | validation: 0.4430664205087234]
	TIME [epoch: 8.33 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179659896104325		[learning rate: 4.6463e-05]
	Learning Rate: 4.64628e-05
	LOSS [training: 0.4179659896104325 | validation: 0.4368011533449253]
	TIME [epoch: 8.37 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41861587483699764		[learning rate: 4.6126e-05]
	Learning Rate: 4.61262e-05
	LOSS [training: 0.41861587483699764 | validation: 0.4426376472495801]
	TIME [epoch: 8.35 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4195944877423706		[learning rate: 4.5792e-05]
	Learning Rate: 4.5792e-05
	LOSS [training: 0.4195944877423706 | validation: 0.4446939925563033]
	TIME [epoch: 8.34 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41896569915347603		[learning rate: 4.546e-05]
	Learning Rate: 4.54602e-05
	LOSS [training: 0.41896569915347603 | validation: 0.44157135936774655]
	TIME [epoch: 8.32 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41770970078958586		[learning rate: 4.5131e-05]
	Learning Rate: 4.51309e-05
	LOSS [training: 0.41770970078958586 | validation: 0.44072315697255915]
	TIME [epoch: 8.34 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41585835373107555		[learning rate: 4.4804e-05]
	Learning Rate: 4.48039e-05
	LOSS [training: 0.41585835373107555 | validation: 0.44312619047069446]
	TIME [epoch: 8.34 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41669377645766387		[learning rate: 4.4479e-05]
	Learning Rate: 4.44793e-05
	LOSS [training: 0.41669377645766387 | validation: 0.4427440712633934]
	TIME [epoch: 8.38 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173475256674727		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.4173475256674727 | validation: 0.4392442691986985]
	TIME [epoch: 8.34 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4176297999297968		[learning rate: 4.3837e-05]
	Learning Rate: 4.38371e-05
	LOSS [training: 0.4176297999297968 | validation: 0.44201737907194094]
	TIME [epoch: 8.34 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41502181989285825		[learning rate: 4.352e-05]
	Learning Rate: 4.35195e-05
	LOSS [training: 0.41502181989285825 | validation: 0.43647175786368875]
	TIME [epoch: 8.33 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.417149480045361		[learning rate: 4.3204e-05]
	Learning Rate: 4.32042e-05
	LOSS [training: 0.417149480045361 | validation: 0.437623124330652]
	TIME [epoch: 8.33 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4184680322306631		[learning rate: 4.2891e-05]
	Learning Rate: 4.28912e-05
	LOSS [training: 0.4184680322306631 | validation: 0.43829186582350754]
	TIME [epoch: 8.36 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152403276884125		[learning rate: 4.258e-05]
	Learning Rate: 4.25805e-05
	LOSS [training: 0.4152403276884125 | validation: 0.4368175348256619]
	TIME [epoch: 8.36 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41587511036388447		[learning rate: 4.2272e-05]
	Learning Rate: 4.2272e-05
	LOSS [training: 0.41587511036388447 | validation: 0.4355574357825911]
	TIME [epoch: 8.43 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41771245922961375		[learning rate: 4.1966e-05]
	Learning Rate: 4.19657e-05
	LOSS [training: 0.41771245922961375 | validation: 0.4377553981742694]
	TIME [epoch: 8.32 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41628713612795476		[learning rate: 4.1662e-05]
	Learning Rate: 4.16617e-05
	LOSS [training: 0.41628713612795476 | validation: 0.44100856400153793]
	TIME [epoch: 8.32 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4162449104266145		[learning rate: 4.136e-05]
	Learning Rate: 4.13599e-05
	LOSS [training: 0.4162449104266145 | validation: 0.44059271931353094]
	TIME [epoch: 8.33 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4146427514023941		[learning rate: 4.106e-05]
	Learning Rate: 4.10602e-05
	LOSS [training: 0.4146427514023941 | validation: 0.4371300056454092]
	TIME [epoch: 8.36 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41408720476131433		[learning rate: 4.0763e-05]
	Learning Rate: 4.07627e-05
	LOSS [training: 0.41408720476131433 | validation: 0.44130862447451424]
	TIME [epoch: 8.36 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41481227579685925		[learning rate: 4.0467e-05]
	Learning Rate: 4.04674e-05
	LOSS [training: 0.41481227579685925 | validation: 0.4337189842111566]
	TIME [epoch: 8.34 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137462251102321		[learning rate: 4.0174e-05]
	Learning Rate: 4.01742e-05
	LOSS [training: 0.4137462251102321 | validation: 0.43591849404394223]
	TIME [epoch: 8.34 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4138956154691241		[learning rate: 3.9883e-05]
	Learning Rate: 3.98832e-05
	LOSS [training: 0.4138956154691241 | validation: 0.4376843639230467]
	TIME [epoch: 8.35 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124469919132201		[learning rate: 3.9594e-05]
	Learning Rate: 3.95942e-05
	LOSS [training: 0.4124469919132201 | validation: 0.43298001500893557]
	TIME [epoch: 8.34 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41279441444651077		[learning rate: 3.9307e-05]
	Learning Rate: 3.93074e-05
	LOSS [training: 0.41279441444651077 | validation: 0.43485377709545214]
	TIME [epoch: 8.38 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130026010198715		[learning rate: 3.9023e-05]
	Learning Rate: 3.90226e-05
	LOSS [training: 0.4130026010198715 | validation: 0.4350905226758026]
	TIME [epoch: 8.34 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131383014184998		[learning rate: 3.874e-05]
	Learning Rate: 3.87399e-05
	LOSS [training: 0.4131383014184998 | validation: 0.4382872242535643]
	TIME [epoch: 8.33 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41422978590746856		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.41422978590746856 | validation: 0.4343278437618827]
	TIME [epoch: 8.33 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106904659826168		[learning rate: 3.8181e-05]
	Learning Rate: 3.81806e-05
	LOSS [training: 0.4106904659826168 | validation: 0.43008832286293275]
	TIME [epoch: 8.33 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.412705176610637		[learning rate: 3.7904e-05]
	Learning Rate: 3.79039e-05
	LOSS [training: 0.412705176610637 | validation: 0.4362040663013266]
	TIME [epoch: 8.33 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131835588215017		[learning rate: 3.7629e-05]
	Learning Rate: 3.76293e-05
	LOSS [training: 0.4131835588215017 | validation: 0.43071055925729634]
	TIME [epoch: 8.37 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4144818566422639		[learning rate: 3.7357e-05]
	Learning Rate: 3.73567e-05
	LOSS [training: 0.4144818566422639 | validation: 0.43566426179218554]
	TIME [epoch: 8.33 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41258657896635126		[learning rate: 3.7086e-05]
	Learning Rate: 3.70861e-05
	LOSS [training: 0.41258657896635126 | validation: 0.4288108116225371]
	TIME [epoch: 8.33 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41176190828476933		[learning rate: 3.6817e-05]
	Learning Rate: 3.68174e-05
	LOSS [training: 0.41176190828476933 | validation: 0.43902042420553444]
	TIME [epoch: 8.33 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41387548999227364		[learning rate: 3.6551e-05]
	Learning Rate: 3.65506e-05
	LOSS [training: 0.41387548999227364 | validation: 0.4339652659700146]
	TIME [epoch: 8.33 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41071182815800933		[learning rate: 3.6286e-05]
	Learning Rate: 3.62858e-05
	LOSS [training: 0.41071182815800933 | validation: 0.4355066973048979]
	TIME [epoch: 8.36 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108878428998783		[learning rate: 3.6023e-05]
	Learning Rate: 3.60229e-05
	LOSS [training: 0.4108878428998783 | validation: 0.429206072090503]
	TIME [epoch: 8.36 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4109623525173601		[learning rate: 3.5762e-05]
	Learning Rate: 3.57619e-05
	LOSS [training: 0.4109623525173601 | validation: 0.4334135633041646]
	TIME [epoch: 8.33 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40973019280764084		[learning rate: 3.5503e-05]
	Learning Rate: 3.55029e-05
	LOSS [training: 0.40973019280764084 | validation: 0.4287662252139155]
	TIME [epoch: 8.33 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41167796225043785		[learning rate: 3.5246e-05]
	Learning Rate: 3.52456e-05
	LOSS [training: 0.41167796225043785 | validation: 0.4294303676631397]
	TIME [epoch: 8.33 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096028968045712		[learning rate: 3.499e-05]
	Learning Rate: 3.49903e-05
	LOSS [training: 0.4096028968045712 | validation: 0.4333293242693014]
	TIME [epoch: 8.33 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088566760083905		[learning rate: 3.4737e-05]
	Learning Rate: 3.47368e-05
	LOSS [training: 0.4088566760083905 | validation: 0.42874341840618324]
	TIME [epoch: 8.35 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40903424244557074		[learning rate: 3.4485e-05]
	Learning Rate: 3.44851e-05
	LOSS [training: 0.40903424244557074 | validation: 0.4318511568078287]
	TIME [epoch: 8.36 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086980832978502		[learning rate: 3.4235e-05]
	Learning Rate: 3.42353e-05
	LOSS [training: 0.4086980832978502 | validation: 0.4322196252688252]
	TIME [epoch: 8.33 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.41141803839163876		[learning rate: 3.3987e-05]
	Learning Rate: 3.39872e-05
	LOSS [training: 0.41141803839163876 | validation: 0.43087893100109764]
	TIME [epoch: 8.32 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094091234801701		[learning rate: 3.3741e-05]
	Learning Rate: 3.3741e-05
	LOSS [training: 0.4094091234801701 | validation: 0.4337282494049597]
	TIME [epoch: 8.32 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40949079221919255		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.40949079221919255 | validation: 0.43175634488084025]
	TIME [epoch: 8.33 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40751198157564505		[learning rate: 3.3254e-05]
	Learning Rate: 3.32539e-05
	LOSS [training: 0.40751198157564505 | validation: 0.43607716426061316]
	TIME [epoch: 8.38 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089613768990861		[learning rate: 3.3013e-05]
	Learning Rate: 3.3013e-05
	LOSS [training: 0.4089613768990861 | validation: 0.43625313094576607]
	TIME [epoch: 8.34 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40911227133962536		[learning rate: 3.2774e-05]
	Learning Rate: 3.27738e-05
	LOSS [training: 0.40911227133962536 | validation: 0.431892014746238]
	TIME [epoch: 8.33 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4080330888007404		[learning rate: 3.2536e-05]
	Learning Rate: 3.25363e-05
	LOSS [training: 0.4080330888007404 | validation: 0.4341475563965671]
	TIME [epoch: 8.33 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081030438986728		[learning rate: 3.2301e-05]
	Learning Rate: 3.23006e-05
	LOSS [training: 0.4081030438986728 | validation: 0.43914685531591785]
	TIME [epoch: 8.33 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40827182292347736		[learning rate: 3.2067e-05]
	Learning Rate: 3.20666e-05
	LOSS [training: 0.40827182292347736 | validation: 0.4356009934078936]
	TIME [epoch: 8.34 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40971227734503		[learning rate: 3.1834e-05]
	Learning Rate: 3.18343e-05
	LOSS [training: 0.40971227734503 | validation: 0.4352148870420066]
	TIME [epoch: 8.37 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40950346595447945		[learning rate: 3.1604e-05]
	Learning Rate: 3.16036e-05
	LOSS [training: 0.40950346595447945 | validation: 0.42831955958889323]
	TIME [epoch: 8.34 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077747480448324		[learning rate: 3.1375e-05]
	Learning Rate: 3.13747e-05
	LOSS [training: 0.4077747480448324 | validation: 0.4303035091230039]
	TIME [epoch: 8.33 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069290679453109		[learning rate: 3.1147e-05]
	Learning Rate: 3.11474e-05
	LOSS [training: 0.4069290679453109 | validation: 0.4291434830498234]
	TIME [epoch: 8.34 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075507397417334		[learning rate: 3.0922e-05]
	Learning Rate: 3.09217e-05
	LOSS [training: 0.4075507397417334 | validation: 0.43028515107059406]
	TIME [epoch: 8.32 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074848008616408		[learning rate: 3.0698e-05]
	Learning Rate: 3.06977e-05
	LOSS [training: 0.4074848008616408 | validation: 0.4268103401377923]
	TIME [epoch: 8.36 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059163335901598		[learning rate: 3.0475e-05]
	Learning Rate: 3.04753e-05
	LOSS [training: 0.4059163335901598 | validation: 0.42967215140211024]
	TIME [epoch: 8.35 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40517582066618923		[learning rate: 3.0254e-05]
	Learning Rate: 3.02545e-05
	LOSS [training: 0.40517582066618923 | validation: 0.4330938856934089]
	TIME [epoch: 8.34 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068043192591831		[learning rate: 3.0035e-05]
	Learning Rate: 3.00353e-05
	LOSS [training: 0.4068043192591831 | validation: 0.43333821669518435]
	TIME [epoch: 8.33 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056044816210104		[learning rate: 2.9818e-05]
	Learning Rate: 2.98177e-05
	LOSS [training: 0.4056044816210104 | validation: 0.4209433542772365]
	TIME [epoch: 8.33 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4063085040209915		[learning rate: 2.9602e-05]
	Learning Rate: 2.96017e-05
	LOSS [training: 0.4063085040209915 | validation: 0.43355027057356543]
	TIME [epoch: 8.34 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40816425293535513		[learning rate: 2.9387e-05]
	Learning Rate: 2.93872e-05
	LOSS [training: 0.40816425293535513 | validation: 0.428641116842874]
	TIME [epoch: 8.36 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053416347326019		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.4053416347326019 | validation: 0.429601456268446]
	TIME [epoch: 8.35 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40779218665172634		[learning rate: 2.8963e-05]
	Learning Rate: 2.89629e-05
	LOSS [training: 0.40779218665172634 | validation: 0.4331747310059292]
	TIME [epoch: 8.33 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058397655471314		[learning rate: 2.8753e-05]
	Learning Rate: 2.87531e-05
	LOSS [training: 0.4058397655471314 | validation: 0.42628901862608504]
	TIME [epoch: 8.33 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40501045343722153		[learning rate: 2.8545e-05]
	Learning Rate: 2.85448e-05
	LOSS [training: 0.40501045343722153 | validation: 0.4231524915751878]
	TIME [epoch: 8.32 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40361091334547755		[learning rate: 2.8338e-05]
	Learning Rate: 2.8338e-05
	LOSS [training: 0.40361091334547755 | validation: 0.4256919406657586]
	TIME [epoch: 8.33 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043461889661893		[learning rate: 2.8133e-05]
	Learning Rate: 2.81327e-05
	LOSS [training: 0.4043461889661893 | validation: 0.42250256034247824]
	TIME [epoch: 8.37 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4047592677116824		[learning rate: 2.7929e-05]
	Learning Rate: 2.79288e-05
	LOSS [training: 0.4047592677116824 | validation: 0.42665118308855726]
	TIME [epoch: 8.33 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40547545914128336		[learning rate: 2.7726e-05]
	Learning Rate: 2.77265e-05
	LOSS [training: 0.40547545914128336 | validation: 0.4244474695224405]
	TIME [epoch: 8.33 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40587704807394753		[learning rate: 2.7526e-05]
	Learning Rate: 2.75256e-05
	LOSS [training: 0.40587704807394753 | validation: 0.4224236630094315]
	TIME [epoch: 8.33 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022405393254734		[learning rate: 2.7326e-05]
	Learning Rate: 2.73262e-05
	LOSS [training: 0.4022405393254734 | validation: 0.4249275639714367]
	TIME [epoch: 8.33 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40453077351754363		[learning rate: 2.7128e-05]
	Learning Rate: 2.71282e-05
	LOSS [training: 0.40453077351754363 | validation: 0.42399961896751714]
	TIME [epoch: 8.34 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034599438160621		[learning rate: 2.6932e-05]
	Learning Rate: 2.69317e-05
	LOSS [training: 0.4034599438160621 | validation: 0.4225159279738657]
	TIME [epoch: 8.37 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024031629173014		[learning rate: 2.6737e-05]
	Learning Rate: 2.67365e-05
	LOSS [training: 0.4024031629173014 | validation: 0.42808429675816984]
	TIME [epoch: 8.33 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036531868057843		[learning rate: 2.6543e-05]
	Learning Rate: 2.65428e-05
	LOSS [training: 0.4036531868057843 | validation: 0.4232791124825831]
	TIME [epoch: 8.33 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40513637040542294		[learning rate: 2.6351e-05]
	Learning Rate: 2.63505e-05
	LOSS [training: 0.40513637040542294 | validation: 0.42564741766652014]
	TIME [epoch: 8.33 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056609759474979		[learning rate: 2.616e-05]
	Learning Rate: 2.61596e-05
	LOSS [training: 0.4056609759474979 | validation: 0.42391554851998237]
	TIME [epoch: 8.32 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40412249310023024		[learning rate: 2.597e-05]
	Learning Rate: 2.59701e-05
	LOSS [training: 0.40412249310023024 | validation: 0.42521061585611486]
	TIME [epoch: 8.35 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025599489176608		[learning rate: 2.5782e-05]
	Learning Rate: 2.5782e-05
	LOSS [training: 0.4025599489176608 | validation: 0.42493299556550823]
	TIME [epoch: 8.35 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037946472198012		[learning rate: 2.5595e-05]
	Learning Rate: 2.55952e-05
	LOSS [training: 0.4037946472198012 | validation: 0.4195196205210793]
	TIME [epoch: 8.32 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4057834477068585		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.4057834477068585 | validation: 0.42445620338294776]
	TIME [epoch: 8.32 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40165887833269714		[learning rate: 2.5226e-05]
	Learning Rate: 2.52256e-05
	LOSS [training: 0.40165887833269714 | validation: 0.42363474217533137]
	TIME [epoch: 8.33 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.403487907804194		[learning rate: 2.5043e-05]
	Learning Rate: 2.50429e-05
	LOSS [training: 0.403487907804194 | validation: 0.42589283413697976]
	TIME [epoch: 8.33 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005890060553148		[learning rate: 2.4861e-05]
	Learning Rate: 2.48614e-05
	LOSS [training: 0.4005890060553148 | validation: 0.42330560948911455]
	TIME [epoch: 8.35 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4032801011882191		[learning rate: 2.4681e-05]
	Learning Rate: 2.46813e-05
	LOSS [training: 0.4032801011882191 | validation: 0.421396583835674]
	TIME [epoch: 8.35 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033237793258182		[learning rate: 2.4503e-05]
	Learning Rate: 2.45025e-05
	LOSS [training: 0.4033237793258182 | validation: 0.42488617641734416]
	TIME [epoch: 8.33 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4020156599257246		[learning rate: 2.4325e-05]
	Learning Rate: 2.4325e-05
	LOSS [training: 0.4020156599257246 | validation: 0.43095944259135044]
	TIME [epoch: 8.33 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031789866335531		[learning rate: 2.4149e-05]
	Learning Rate: 2.41488e-05
	LOSS [training: 0.4031789866335531 | validation: 0.42483158916050645]
	TIME [epoch: 8.33 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034838052823527		[learning rate: 2.3974e-05]
	Learning Rate: 2.39738e-05
	LOSS [training: 0.4034838052823527 | validation: 0.4221935154157786]
	TIME [epoch: 8.34 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.401614340337086		[learning rate: 2.38e-05]
	Learning Rate: 2.38001e-05
	LOSS [training: 0.401614340337086 | validation: 0.42534416480889203]
	TIME [epoch: 8.37 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40091451513683896		[learning rate: 2.3628e-05]
	Learning Rate: 2.36277e-05
	LOSS [training: 0.40091451513683896 | validation: 0.4290673748711209]
	TIME [epoch: 8.34 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40239557734671255		[learning rate: 2.3457e-05]
	Learning Rate: 2.34565e-05
	LOSS [training: 0.40239557734671255 | validation: 0.4235853953463121]
	TIME [epoch: 8.32 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40569100759370597		[learning rate: 2.3287e-05]
	Learning Rate: 2.32866e-05
	LOSS [training: 0.40569100759370597 | validation: 0.42137865990787204]
	TIME [epoch: 8.32 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40162930443157685		[learning rate: 2.3118e-05]
	Learning Rate: 2.31179e-05
	LOSS [training: 0.40162930443157685 | validation: 0.4209407398434942]
	TIME [epoch: 8.33 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4035966640140467		[learning rate: 2.295e-05]
	Learning Rate: 2.29504e-05
	LOSS [training: 0.4035966640140467 | validation: 0.4309298347525111]
	TIME [epoch: 8.34 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018095365211649		[learning rate: 2.2784e-05]
	Learning Rate: 2.27841e-05
	LOSS [training: 0.4018095365211649 | validation: 0.4184560428685167]
	TIME [epoch: 8.37 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40350565409078687		[learning rate: 2.2619e-05]
	Learning Rate: 2.2619e-05
	LOSS [training: 0.40350565409078687 | validation: 0.41987141452884724]
	TIME [epoch: 8.33 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40091508580959945		[learning rate: 2.2455e-05]
	Learning Rate: 2.24551e-05
	LOSS [training: 0.40091508580959945 | validation: 0.42512791227852603]
	TIME [epoch: 8.33 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3999052478528034		[learning rate: 2.2292e-05]
	Learning Rate: 2.22925e-05
	LOSS [training: 0.3999052478528034 | validation: 0.41894730773791616]
	TIME [epoch: 8.33 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005433368216797		[learning rate: 2.2131e-05]
	Learning Rate: 2.2131e-05
	LOSS [training: 0.4005433368216797 | validation: 0.4253162785307584]
	TIME [epoch: 8.33 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014462785464412		[learning rate: 2.1971e-05]
	Learning Rate: 2.19706e-05
	LOSS [training: 0.4014462785464412 | validation: 0.4180676114076799]
	TIME [epoch: 8.35 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006752881949028		[learning rate: 2.1811e-05]
	Learning Rate: 2.18114e-05
	LOSS [training: 0.4006752881949028 | validation: 0.42649844475255927]
	TIME [epoch: 8.36 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39801049258492815		[learning rate: 2.1653e-05]
	Learning Rate: 2.16534e-05
	LOSS [training: 0.39801049258492815 | validation: 0.4254182072795953]
	TIME [epoch: 8.33 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39875113114769123		[learning rate: 2.1497e-05]
	Learning Rate: 2.14965e-05
	LOSS [training: 0.39875113114769123 | validation: 0.4180338593406671]
	TIME [epoch: 8.33 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3998166324316472		[learning rate: 2.1341e-05]
	Learning Rate: 2.13408e-05
	LOSS [training: 0.3998166324316472 | validation: 0.4230282828854163]
	TIME [epoch: 8.33 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989846214639787		[learning rate: 2.1186e-05]
	Learning Rate: 2.11862e-05
	LOSS [training: 0.3989846214639787 | validation: 0.4209279494720682]
	TIME [epoch: 8.33 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3998761013288912		[learning rate: 2.1033e-05]
	Learning Rate: 2.10327e-05
	LOSS [training: 0.3998761013288912 | validation: 0.42097844418322194]
	TIME [epoch: 8.37 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006742740586591		[learning rate: 2.088e-05]
	Learning Rate: 2.08803e-05
	LOSS [training: 0.4006742740586591 | validation: 0.41849885097309814]
	TIME [epoch: 8.34 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39979300656416994		[learning rate: 2.0729e-05]
	Learning Rate: 2.0729e-05
	LOSS [training: 0.39979300656416994 | validation: 0.42329058722960583]
	TIME [epoch: 8.33 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39916990259146196		[learning rate: 2.0579e-05]
	Learning Rate: 2.05789e-05
	LOSS [training: 0.39916990259146196 | validation: 0.4229790754088334]
	TIME [epoch: 8.33 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40008033977687985		[learning rate: 2.043e-05]
	Learning Rate: 2.04298e-05
	LOSS [training: 0.40008033977687985 | validation: 0.4159510489808227]
	TIME [epoch: 8.4 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990452200880644		[learning rate: 2.0282e-05]
	Learning Rate: 2.02818e-05
	LOSS [training: 0.3990452200880644 | validation: 0.4199939653398367]
	TIME [epoch: 8.33 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39897770697259766		[learning rate: 2.0135e-05]
	Learning Rate: 2.01348e-05
	LOSS [training: 0.39897770697259766 | validation: 0.41454802522825035]
	TIME [epoch: 8.36 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980982676953818		[learning rate: 1.9989e-05]
	Learning Rate: 1.99889e-05
	LOSS [training: 0.3980982676953818 | validation: 0.41873097281298516]
	TIME [epoch: 8.33 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990724455042235		[learning rate: 1.9844e-05]
	Learning Rate: 1.98441e-05
	LOSS [training: 0.3990724455042235 | validation: 0.4210143850436947]
	TIME [epoch: 8.32 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40178414882245395		[learning rate: 1.97e-05]
	Learning Rate: 1.97003e-05
	LOSS [training: 0.40178414882245395 | validation: 0.4203731032518273]
	TIME [epoch: 8.33 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994630386568502		[learning rate: 1.9558e-05]
	Learning Rate: 1.95576e-05
	LOSS [training: 0.3994630386568502 | validation: 0.4213628793287916]
	TIME [epoch: 8.33 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982907766564282		[learning rate: 1.9416e-05]
	Learning Rate: 1.94159e-05
	LOSS [training: 0.3982907766564282 | validation: 0.4165966786834937]
	TIME [epoch: 8.35 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990935016325145		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.3990935016325145 | validation: 0.41624776294217647]
	TIME [epoch: 8.35 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39730425495221977		[learning rate: 1.9136e-05]
	Learning Rate: 1.91356e-05
	LOSS [training: 0.39730425495221977 | validation: 0.41655417867737665]
	TIME [epoch: 8.32 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980441598406743		[learning rate: 1.8997e-05]
	Learning Rate: 1.8997e-05
	LOSS [training: 0.3980441598406743 | validation: 0.42197045713481895]
	TIME [epoch: 8.33 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39928740323204676		[learning rate: 1.8859e-05]
	Learning Rate: 1.88593e-05
	LOSS [training: 0.39928740323204676 | validation: 0.41558264199188416]
	TIME [epoch: 8.33 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974551046850303		[learning rate: 1.8723e-05]
	Learning Rate: 1.87227e-05
	LOSS [training: 0.3974551046850303 | validation: 0.41809628603682086]
	TIME [epoch: 8.33 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39694753745476574		[learning rate: 1.8587e-05]
	Learning Rate: 1.85871e-05
	LOSS [training: 0.39694753745476574 | validation: 0.41610761878138447]
	TIME [epoch: 8.35 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992862423827864		[learning rate: 1.8452e-05]
	Learning Rate: 1.84524e-05
	LOSS [training: 0.3992862423827864 | validation: 0.4207157872519032]
	TIME [epoch: 8.35 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974349164886158		[learning rate: 1.8319e-05]
	Learning Rate: 1.83187e-05
	LOSS [training: 0.3974349164886158 | validation: 0.4158517182461258]
	TIME [epoch: 8.33 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001209092795418		[learning rate: 1.8186e-05]
	Learning Rate: 1.8186e-05
	LOSS [training: 0.4001209092795418 | validation: 0.422340174378282]
	TIME [epoch: 8.33 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39952911479727976		[learning rate: 1.8054e-05]
	Learning Rate: 1.80542e-05
	LOSS [training: 0.39952911479727976 | validation: 0.4113066082814886]
	TIME [epoch: 8.34 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978006612145066		[learning rate: 1.7923e-05]
	Learning Rate: 1.79234e-05
	LOSS [training: 0.3978006612145066 | validation: 0.4181308504425875]
	TIME [epoch: 8.33 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39831225511342666		[learning rate: 1.7794e-05]
	Learning Rate: 1.77936e-05
	LOSS [training: 0.39831225511342666 | validation: 0.4195793166252579]
	TIME [epoch: 8.38 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3964913982868431		[learning rate: 1.7665e-05]
	Learning Rate: 1.76647e-05
	LOSS [training: 0.3964913982868431 | validation: 0.4117986543235744]
	TIME [epoch: 8.33 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3949634437670121		[learning rate: 1.7537e-05]
	Learning Rate: 1.75367e-05
	LOSS [training: 0.3949634437670121 | validation: 0.4167676761700547]
	TIME [epoch: 8.33 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39809553935413716		[learning rate: 1.741e-05]
	Learning Rate: 1.74096e-05
	LOSS [training: 0.39809553935413716 | validation: 0.4159203705331683]
	TIME [epoch: 8.32 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961201065989245		[learning rate: 1.7284e-05]
	Learning Rate: 1.72835e-05
	LOSS [training: 0.3961201065989245 | validation: 0.4198088423215345]
	TIME [epoch: 8.32 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3959784377987017		[learning rate: 1.7158e-05]
	Learning Rate: 1.71583e-05
	LOSS [training: 0.3959784377987017 | validation: 0.41488472643808894]
	TIME [epoch: 8.33 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39754192376251524		[learning rate: 1.7034e-05]
	Learning Rate: 1.7034e-05
	LOSS [training: 0.39754192376251524 | validation: 0.41856413490102806]
	TIME [epoch: 8.37 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3967399627843986		[learning rate: 1.6911e-05]
	Learning Rate: 1.69106e-05
	LOSS [training: 0.3967399627843986 | validation: 0.41344428090506624]
	TIME [epoch: 8.33 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39483987734043924		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.39483987734043924 | validation: 0.4149608465489153]
	TIME [epoch: 8.33 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3985330429238744		[learning rate: 1.6666e-05]
	Learning Rate: 1.66664e-05
	LOSS [training: 0.3985330429238744 | validation: 0.41969029902678207]
	TIME [epoch: 8.33 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39581219239999466		[learning rate: 1.6546e-05]
	Learning Rate: 1.65457e-05
	LOSS [training: 0.39581219239999466 | validation: 0.4156205105502192]
	TIME [epoch: 8.32 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990535378266048		[learning rate: 1.6426e-05]
	Learning Rate: 1.64258e-05
	LOSS [training: 0.3990535378266048 | validation: 0.41385031908476677]
	TIME [epoch: 8.35 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39687009392599615		[learning rate: 1.6307e-05]
	Learning Rate: 1.63068e-05
	LOSS [training: 0.39687009392599615 | validation: 0.41473509958139165]
	TIME [epoch: 8.36 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39560128870014527		[learning rate: 1.6189e-05]
	Learning Rate: 1.61887e-05
	LOSS [training: 0.39560128870014527 | validation: 0.41873111333521573]
	TIME [epoch: 8.33 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39584769018834676		[learning rate: 1.6071e-05]
	Learning Rate: 1.60714e-05
	LOSS [training: 0.39584769018834676 | validation: 0.41842048326890613]
	TIME [epoch: 8.33 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3960330763921264		[learning rate: 1.5955e-05]
	Learning Rate: 1.59549e-05
	LOSS [training: 0.3960330763921264 | validation: 0.4159767183442481]
	TIME [epoch: 8.33 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3962773703064049		[learning rate: 1.5839e-05]
	Learning Rate: 1.58393e-05
	LOSS [training: 0.3962773703064049 | validation: 0.41238656113118355]
	TIME [epoch: 8.33 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944549515475116		[learning rate: 1.5725e-05]
	Learning Rate: 1.57246e-05
	LOSS [training: 0.3944549515475116 | validation: 0.4141122403288089]
	TIME [epoch: 8.35 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3963511030923578		[learning rate: 1.5611e-05]
	Learning Rate: 1.56107e-05
	LOSS [training: 0.3963511030923578 | validation: 0.4200382543639495]
	TIME [epoch: 8.36 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39556349137058944		[learning rate: 1.5498e-05]
	Learning Rate: 1.54976e-05
	LOSS [training: 0.39556349137058944 | validation: 0.41865524125294656]
	TIME [epoch: 8.34 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39712542253090316		[learning rate: 1.5385e-05]
	Learning Rate: 1.53853e-05
	LOSS [training: 0.39712542253090316 | validation: 0.423628977502815]
	TIME [epoch: 8.33 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958744530389784		[learning rate: 1.5274e-05]
	Learning Rate: 1.52738e-05
	LOSS [training: 0.3958744530389784 | validation: 0.4179652304412726]
	TIME [epoch: 8.33 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974614585120201		[learning rate: 1.5163e-05]
	Learning Rate: 1.51632e-05
	LOSS [training: 0.3974614585120201 | validation: 0.41731344900820083]
	TIME [epoch: 8.32 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938781208286973		[learning rate: 1.5053e-05]
	Learning Rate: 1.50533e-05
	LOSS [training: 0.3938781208286973 | validation: 0.4122449674919812]
	TIME [epoch: 8.37 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3968051087909367		[learning rate: 1.4944e-05]
	Learning Rate: 1.49442e-05
	LOSS [training: 0.3968051087909367 | validation: 0.4173804087461057]
	TIME [epoch: 8.33 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39483573300356933		[learning rate: 1.4836e-05]
	Learning Rate: 1.4836e-05
	LOSS [training: 0.39483573300356933 | validation: 0.41598329265932826]
	TIME [epoch: 8.33 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.394361672694715		[learning rate: 1.4728e-05]
	Learning Rate: 1.47285e-05
	LOSS [training: 0.394361672694715 | validation: 0.419683965662501]
	TIME [epoch: 8.33 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944291451142129		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.3944291451142129 | validation: 0.41605152961558484]
	TIME [epoch: 8.33 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951827866687455		[learning rate: 1.4516e-05]
	Learning Rate: 1.45158e-05
	LOSS [training: 0.3951827866687455 | validation: 0.40985658605210773]
	TIME [epoch: 8.34 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945410650901609		[learning rate: 1.4411e-05]
	Learning Rate: 1.44107e-05
	LOSS [training: 0.3945410650901609 | validation: 0.4138443228124169]
	TIME [epoch: 8.37 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39530010750770767		[learning rate: 1.4306e-05]
	Learning Rate: 1.43063e-05
	LOSS [training: 0.39530010750770767 | validation: 0.4181452257165904]
	TIME [epoch: 8.33 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39483903445861385		[learning rate: 1.4203e-05]
	Learning Rate: 1.42026e-05
	LOSS [training: 0.39483903445861385 | validation: 0.41746602455892123]
	TIME [epoch: 8.32 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39381636007512144		[learning rate: 1.41e-05]
	Learning Rate: 1.40997e-05
	LOSS [training: 0.39381636007512144 | validation: 0.41625781800321515]
	TIME [epoch: 8.33 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3953693783295839		[learning rate: 1.3998e-05]
	Learning Rate: 1.39976e-05
	LOSS [training: 0.3953693783295839 | validation: 0.4193315090456098]
	TIME [epoch: 8.33 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39881843302565523		[learning rate: 1.3896e-05]
	Learning Rate: 1.38962e-05
	LOSS [training: 0.39881843302565523 | validation: 0.4147796173666804]
	TIME [epoch: 8.35 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945397373820539		[learning rate: 1.3795e-05]
	Learning Rate: 1.37955e-05
	LOSS [training: 0.3945397373820539 | validation: 0.41625527937621926]
	TIME [epoch: 8.35 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39351059096942365		[learning rate: 1.3696e-05]
	Learning Rate: 1.36955e-05
	LOSS [training: 0.39351059096942365 | validation: 0.41490176100864745]
	TIME [epoch: 8.33 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933617917056492		[learning rate: 1.3596e-05]
	Learning Rate: 1.35963e-05
	LOSS [training: 0.3933617917056492 | validation: 0.4160500824665492]
	TIME [epoch: 8.32 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934146032617396		[learning rate: 1.3498e-05]
	Learning Rate: 1.34978e-05
	LOSS [training: 0.3934146032617396 | validation: 0.4100705236236482]
	TIME [epoch: 8.33 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39493975915753976		[learning rate: 1.34e-05]
	Learning Rate: 1.34e-05
	LOSS [training: 0.39493975915753976 | validation: 0.42108171234097314]
	TIME [epoch: 8.34 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943417873340913		[learning rate: 1.3303e-05]
	Learning Rate: 1.33029e-05
	LOSS [training: 0.3943417873340913 | validation: 0.41523035907819383]
	TIME [epoch: 8.36 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954889431173564		[learning rate: 1.3207e-05]
	Learning Rate: 1.32066e-05
	LOSS [training: 0.3954889431173564 | validation: 0.41920828622545925]
	TIME [epoch: 8.36 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39638846633982006		[learning rate: 1.3111e-05]
	Learning Rate: 1.31109e-05
	LOSS [training: 0.39638846633982006 | validation: 0.41020817345071403]
	TIME [epoch: 8.33 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39228457693637203		[learning rate: 1.3016e-05]
	Learning Rate: 1.30159e-05
	LOSS [training: 0.39228457693637203 | validation: 0.413354450597499]
	TIME [epoch: 8.34 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39411106412526975		[learning rate: 1.2922e-05]
	Learning Rate: 1.29216e-05
	LOSS [training: 0.39411106412526975 | validation: 0.4162791521537009]
	TIME [epoch: 8.33 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913326618498996		[learning rate: 1.2828e-05]
	Learning Rate: 1.2828e-05
	LOSS [training: 0.3913326618498996 | validation: 0.41281930715351006]
	TIME [epoch: 8.34 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3962622208951938		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.3962622208951938 | validation: 0.4123655658768636]
	TIME [epoch: 8.37 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948498696881203		[learning rate: 1.2643e-05]
	Learning Rate: 1.26428e-05
	LOSS [training: 0.3948498696881203 | validation: 0.41462548892740114]
	TIME [epoch: 8.34 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39118224543096736		[learning rate: 1.2551e-05]
	Learning Rate: 1.25512e-05
	LOSS [training: 0.39118224543096736 | validation: 0.41751416550505094]
	TIME [epoch: 8.33 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39467825361982223		[learning rate: 1.246e-05]
	Learning Rate: 1.24602e-05
	LOSS [training: 0.39467825361982223 | validation: 0.41976978092130146]
	TIME [epoch: 8.33 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3937060273949167		[learning rate: 1.237e-05]
	Learning Rate: 1.237e-05
	LOSS [training: 0.3937060273949167 | validation: 0.4092897382030328]
	TIME [epoch: 8.32 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39291169398969805		[learning rate: 1.228e-05]
	Learning Rate: 1.22803e-05
	LOSS [training: 0.39291169398969805 | validation: 0.42161676620746846]
	TIME [epoch: 8.34 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39323126678052844		[learning rate: 1.2191e-05]
	Learning Rate: 1.21914e-05
	LOSS [training: 0.39323126678052844 | validation: 0.41455630391738985]
	TIME [epoch: 8.37 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3912831361345484		[learning rate: 1.2103e-05]
	Learning Rate: 1.21031e-05
	LOSS [training: 0.3912831361345484 | validation: 0.4092693275038642]
	TIME [epoch: 8.32 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39527586828480404		[learning rate: 1.2015e-05]
	Learning Rate: 1.20154e-05
	LOSS [training: 0.39527586828480404 | validation: 0.4092421312746104]
	TIME [epoch: 8.33 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39169605226377563		[learning rate: 1.1928e-05]
	Learning Rate: 1.19283e-05
	LOSS [training: 0.39169605226377563 | validation: 0.41406274073239996]
	TIME [epoch: 8.34 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943362398105635		[learning rate: 1.1842e-05]
	Learning Rate: 1.18419e-05
	LOSS [training: 0.3943362398105635 | validation: 0.4122050017328165]
	TIME [epoch: 8.32 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930804737074738		[learning rate: 1.1756e-05]
	Learning Rate: 1.17561e-05
	LOSS [training: 0.3930804737074738 | validation: 0.41534246449736434]
	TIME [epoch: 8.35 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914966448936712		[learning rate: 1.1671e-05]
	Learning Rate: 1.16709e-05
	LOSS [training: 0.3914966448936712 | validation: 0.41167909881080356]
	TIME [epoch: 8.35 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926995900315561		[learning rate: 1.1586e-05]
	Learning Rate: 1.15864e-05
	LOSS [training: 0.3926995900315561 | validation: 0.41063875555608437]
	TIME [epoch: 8.32 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932403457845155		[learning rate: 1.1502e-05]
	Learning Rate: 1.15024e-05
	LOSS [training: 0.3932403457845155 | validation: 0.4122911564258813]
	TIME [epoch: 8.33 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39184965777723807		[learning rate: 1.1419e-05]
	Learning Rate: 1.14191e-05
	LOSS [training: 0.39184965777723807 | validation: 0.4093916742000598]
	TIME [epoch: 8.32 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921123080213151		[learning rate: 1.1336e-05]
	Learning Rate: 1.13364e-05
	LOSS [training: 0.3921123080213151 | validation: 0.41474060273264757]
	TIME [epoch: 8.33 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39360962385585485		[learning rate: 1.1254e-05]
	Learning Rate: 1.12542e-05
	LOSS [training: 0.39360962385585485 | validation: 0.41208887932386135]
	TIME [epoch: 8.36 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39303669397967333		[learning rate: 1.1173e-05]
	Learning Rate: 1.11727e-05
	LOSS [training: 0.39303669397967333 | validation: 0.4103035587917766]
	TIME [epoch: 8.35 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941261786350386		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.3941261786350386 | validation: 0.4130214378374839]
	TIME [epoch: 8.33 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39090350569308113		[learning rate: 1.1011e-05]
	Learning Rate: 1.10114e-05
	LOSS [training: 0.39090350569308113 | validation: 0.4108456976789221]
	TIME [epoch: 8.33 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39248356816724084		[learning rate: 1.0932e-05]
	Learning Rate: 1.09316e-05
	LOSS [training: 0.39248356816724084 | validation: 0.41184227440918786]
	TIME [epoch: 8.32 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39209395825747406		[learning rate: 1.0852e-05]
	Learning Rate: 1.08524e-05
	LOSS [training: 0.39209395825747406 | validation: 0.41583997824832586]
	TIME [epoch: 8.34 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901074437758941		[learning rate: 1.0774e-05]
	Learning Rate: 1.07738e-05
	LOSS [training: 0.3901074437758941 | validation: 0.4117355965711019]
	TIME [epoch: 8.38 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39138418068394915		[learning rate: 1.0696e-05]
	Learning Rate: 1.06957e-05
	LOSS [training: 0.39138418068394915 | validation: 0.41340079085944664]
	TIME [epoch: 8.35 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931485685900331		[learning rate: 1.0618e-05]
	Learning Rate: 1.06182e-05
	LOSS [training: 0.3931485685900331 | validation: 0.41106613766070366]
	TIME [epoch: 8.34 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39302931322782153		[learning rate: 1.0541e-05]
	Learning Rate: 1.05413e-05
	LOSS [training: 0.39302931322782153 | validation: 0.41379023264571946]
	TIME [epoch: 8.33 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39342873360077585		[learning rate: 1.0465e-05]
	Learning Rate: 1.04649e-05
	LOSS [training: 0.39342873360077585 | validation: 0.4112663451441151]
	TIME [epoch: 8.33 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39200893554582594		[learning rate: 1.0389e-05]
	Learning Rate: 1.03891e-05
	LOSS [training: 0.39200893554582594 | validation: 0.4128867294400075]
	TIME [epoch: 8.34 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911751877006553		[learning rate: 1.0314e-05]
	Learning Rate: 1.03139e-05
	LOSS [training: 0.3911751877006553 | validation: 0.41017974963808235]
	TIME [epoch: 8.36 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925682717249943		[learning rate: 1.0239e-05]
	Learning Rate: 1.02391e-05
	LOSS [training: 0.3925682717249943 | validation: 0.4131112508862708]
	TIME [epoch: 8.32 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918081030169813		[learning rate: 1.0165e-05]
	Learning Rate: 1.0165e-05
	LOSS [training: 0.3918081030169813 | validation: 0.411819299076815]
	TIME [epoch: 8.33 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926347441764423		[learning rate: 1.0091e-05]
	Learning Rate: 1.00913e-05
	LOSS [training: 0.3926347441764423 | validation: 0.407785259589989]
	TIME [epoch: 8.33 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.39252836954761594		[learning rate: 1.0018e-05]
	Learning Rate: 1.00182e-05
	LOSS [training: 0.39252836954761594 | validation: 0.4145686651454383]
	TIME [epoch: 8.33 sec]
Finished training in 9908.368 seconds.
