Args:
Namespace(name='model_phi1_3a_v_mmd1', outdir='out/model_training/model_phi1_3a_v_mmd1', training_data='data/training_data/data_phi1_3a/training', validation_data='data/training_data/data_phi1_3a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4217809173

Training model...

Saving initial model state to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.437370722399585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.437370722399585 | validation: 5.747316343339836]
	TIME [epoch: 24.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.276414000270401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.276414000270401 | validation: 5.096380958575487]
	TIME [epoch: 0.98 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.1040289428074015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1040289428074015 | validation: 5.790838555956681]
	TIME [epoch: 0.921 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.582662953617625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.582662953617625 | validation: 6.467179253036969]
	TIME [epoch: 0.923 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.4125323424855605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4125323424855605 | validation: 5.39669877557257]
	TIME [epoch: 0.92 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.973781259434253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.973781259434253 | validation: 4.62070979494076]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.036762918608123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.036762918608123 | validation: 4.770610027923462]
	TIME [epoch: 0.941 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.447329020781675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.447329020781675 | validation: 4.628595758576724]
	TIME [epoch: 0.927 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.080613010356437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.080613010356437 | validation: 4.538020698263604]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8065416216986194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8065416216986194 | validation: 4.594657880414063]
	TIME [epoch: 0.926 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.801544038450935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.801544038450935 | validation: 4.596696960336596]
	TIME [epoch: 0.927 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8107082786366604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8107082786366604 | validation: 4.554742734323027]
	TIME [epoch: 0.921 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8164784650900914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8164784650900914 | validation: 4.488215560170619]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7418315798650084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7418315798650084 | validation: 4.460003908779433]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6637890021775883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6637890021775883 | validation: 4.428380715743697]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6094044423425915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6094044423425915 | validation: 4.448646812016202]
	TIME [epoch: 0.921 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6186780573102215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6186780573102215 | validation: 4.41115894515887]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.626609112792893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.626609112792893 | validation: 4.432396191146488]
	TIME [epoch: 0.92 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6362560551359753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6362560551359753 | validation: 4.319640157675659]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5111787020959286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5111787020959286 | validation: 4.341360132738131]
	TIME [epoch: 0.926 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4668667685692687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4668667685692687 | validation: 4.2871598347236874]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.454239142102222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.454239142102222 | validation: 4.338553604614399]
	TIME [epoch: 0.915 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4942208831238912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4942208831238912 | validation: 4.263477523708869]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4677819349151706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4677819349151706 | validation: 4.2923246658459275]
	TIME [epoch: 0.916 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4455970023707567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4455970023707567 | validation: 4.208462655283904]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3720131989231796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3720131989231796 | validation: 4.240937389452536]
	TIME [epoch: 0.919 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3613220592875828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3613220592875828 | validation: 4.1760648772267235]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3481449600909197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3481449600909197 | validation: 4.2163306403675085]
	TIME [epoch: 0.922 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3704916116953103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3704916116953103 | validation: 4.140687419355354]
	TIME [epoch: 0.931 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.327603005701707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.327603005701707 | validation: 4.180112785488866]
	TIME [epoch: 0.919 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3225037043878265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3225037043878265 | validation: 4.1088173874329526]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.281968300852377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.281968300852377 | validation: 4.13945080433951]
	TIME [epoch: 0.92 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2797512288367456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2797512288367456 | validation: 4.061111002604001]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2470623059773964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2470623059773964 | validation: 4.090776680039824]
	TIME [epoch: 0.923 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.245907331582306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.245907331582306 | validation: 4.030576648070629]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2136253534751824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2136253534751824 | validation: 4.05829979092742]
	TIME [epoch: 0.914 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.215643547267311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.215643547267311 | validation: 4.014583297075149]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1915906736651287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1915906736651287 | validation: 4.033093179580297]
	TIME [epoch: 0.917 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1959498810283016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1959498810283016 | validation: 3.976106011824871]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.170151888653621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.170151888653621 | validation: 3.981838865476734]
	TIME [epoch: 0.918 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1630755334161593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1630755334161593 | validation: 3.9293383184825075]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1298187351563307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1298187351563307 | validation: 3.944588586985337]
	TIME [epoch: 0.917 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.124710494035266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.124710494035266 | validation: 3.886055312642631]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.102894841284536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.102894841284536 | validation: 3.9229378110669977]
	TIME [epoch: 0.922 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1086879099174283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1086879099174283 | validation: 3.856473601720346]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.082653629559939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.082653629559939 | validation: 3.8827818506542258]
	TIME [epoch: 0.925 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.079108698384632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.079108698384632 | validation: 3.814303102159034]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0490776766140777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0490776766140777 | validation: 3.838379112384894]
	TIME [epoch: 0.919 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.043723165714311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.043723165714311 | validation: 3.783942667579563]
	TIME [epoch: 0.912 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0127357736764155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0127357736764155 | validation: 3.7962397328196946]
	TIME [epoch: 0.919 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0047740931028217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0047740931028217 | validation: 3.752541161075598]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9954069036456774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9954069036456774 | validation: 3.788154692977406]
	TIME [epoch: 0.919 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0085711817356433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0085711817356433 | validation: 3.7293986736561795]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9924071180021707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9924071180021707 | validation: 3.7561989318768627]
	TIME [epoch: 0.922 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.007896108641731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.007896108641731 | validation: 3.683647026036093]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.954144261285247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.954144261285247 | validation: 3.7002463636705905]
	TIME [epoch: 0.922 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9339888658456683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9339888658456683 | validation: 3.6216677662991827]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9198795443522245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9198795443522245 | validation: 3.690741880689771]
	TIME [epoch: 0.914 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9110366431587913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9110366431587913 | validation: 3.587299987004255]
	TIME [epoch: 0.912 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9093803624337427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9093803624337427 | validation: 3.662181633852022]
	TIME [epoch: 0.917 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.89907490483916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.89907490483916 | validation: 3.5526783194334715]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.874365504694018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.874365504694018 | validation: 3.579929752936378]
	TIME [epoch: 0.92 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8532590046956727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8532590046956727 | validation: 3.5316412117180978]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.835112846578809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.835112846578809 | validation: 3.5511252366604844]
	TIME [epoch: 0.935 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.835015022955155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.835015022955155 | validation: 3.5395165214018807]
	TIME [epoch: 0.928 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8530099358000305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8530099358000305 | validation: 3.584815537737622]
	TIME [epoch: 0.92 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.951295184182845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.951295184182845 | validation: 3.522018499706686]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.861998376295042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.861998376295042 | validation: 3.5551744159549603]
	TIME [epoch: 0.926 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8491049237792185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8491049237792185 | validation: 3.4265930862418976]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8143458271814996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8143458271814996 | validation: 3.526327847991806]
	TIME [epoch: 0.919 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.797067276982095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.797067276982095 | validation: 3.402023041765994]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7840883991132874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7840883991132874 | validation: 3.423213985184188]
	TIME [epoch: 0.915 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7556424109147297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7556424109147297 | validation: 3.3936472723068594]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.741259271781737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.741259271781737 | validation: 3.3821425185008867]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7329608779453163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7329608779453163 | validation: 3.3498830144489804]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7292079183001277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7292079183001277 | validation: 3.3726135283356102]
	TIME [epoch: 0.914 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.728679576524186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.728679576524186 | validation: 3.3382511862034114]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7711795600011304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7711795600011304 | validation: 3.545204051925491]
	TIME [epoch: 0.916 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.889119798167911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.889119798167911 | validation: 3.297551693144996]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7478610961560315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7478610961560315 | validation: 3.296135121756624]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.688679585060013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.688679585060013 | validation: 3.338838600351796]
	TIME [epoch: 0.915 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6965727049430708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6965727049430708 | validation: 3.2678032171032285]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6851842688977428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6851842688977428 | validation: 3.270259090770038]
	TIME [epoch: 0.918 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6760526189900693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6760526189900693 | validation: 3.250636034793095]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.67434029682188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.67434029682188 | validation: 3.2576950252922]
	TIME [epoch: 0.918 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.662210575437026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.662210575437026 | validation: 3.212656607756334]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.660391894611881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.660391894611881 | validation: 3.2542707298124456]
	TIME [epoch: 0.923 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6700513199289686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6700513199289686 | validation: 3.200867035331834]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6947300928709486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6947300928709486 | validation: 3.32122480035434]
	TIME [epoch: 0.914 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.736216593830239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.736216593830239 | validation: 3.1521424178258]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.626445269858079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.626445269858079 | validation: 3.149579006623096]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6182400330493674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6182400330493674 | validation: 3.1766271865176727]
	TIME [epoch: 0.92 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6149923241849886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6149923241849886 | validation: 3.129733677171558]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.610314944038554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.610314944038554 | validation: 3.1518349190660935]
	TIME [epoch: 0.917 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5981866739500696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5981866739500696 | validation: 3.0952808090830595]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.584025569718094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.584025569718094 | validation: 3.1023272525598498]
	TIME [epoch: 0.912 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.578138981285424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.578138981285424 | validation: 3.046266788076812]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5751921509216764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5751921509216764 | validation: 3.1085283606989536]
	TIME [epoch: 0.919 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5838890635646616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5838890635646616 | validation: 2.9700511575494875]
	TIME [epoch: 0.933 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5272715683926936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5272715683926936 | validation: 2.8758473863707623]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.450737960852813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.450737960852813 | validation: 2.6891685118588144]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3209171471550123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3209171471550123 | validation: 2.5994792255995565]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2466221634759522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2466221634759522 | validation: 2.5686402767850183]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1930979547545415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1930979547545415 | validation: 2.4452856230282407]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1485355114223834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1485355114223834 | validation: 2.540550742467269]
	TIME [epoch: 0.917 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.216728057025733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.216728057025733 | validation: 1.5584236031201777]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.80361556684373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.80361556684373 | validation: 1.4251710073706148]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6721164224512484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6721164224512484 | validation: 2.572293809393633]
	TIME [epoch: 0.916 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1876197934650015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1876197934650015 | validation: 2.515398029638339]
	TIME [epoch: 0.917 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.125384974342709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.125384974342709 | validation: 2.0647757891755503]
	TIME [epoch: 0.916 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.771546193540482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.771546193540482 | validation: 1.2415030346082254]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2570750188250015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2570750188250015 | validation: 1.6513829284733577]
	TIME [epoch: 0.922 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8359087172282031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8359087172282031 | validation: 1.211879608818195]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1982389778110456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1982389778110456 | validation: 1.167596819228768]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1116638533104137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1116638533104137 | validation: 0.9982871784105897]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0772468079938928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0772468079938928 | validation: 0.9700545179861888]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0135087018589521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0135087018589521 | validation: 0.9666463842308822]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.006039831152102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.006039831152102 | validation: 0.9255665794436315]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9871382742815729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9871382742815729 | validation: 0.9487888717828415]
	TIME [epoch: 0.916 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9691217285063514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9691217285063514 | validation: 0.9001608742322486]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9498329363965035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9498329363965035 | validation: 0.8851214612908752]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9290084822642541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9290084822642541 | validation: 0.8855698643759449]
	TIME [epoch: 0.919 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9384533001798104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9384533001798104 | validation: 0.9104160160037242]
	TIME [epoch: 0.918 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9288428916426239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9288428916426239 | validation: 0.8683184825934985]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9270453247168263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9270453247168263 | validation: 0.9484607330648629]
	TIME [epoch: 0.917 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9391521031585717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9391521031585717 | validation: 0.9120067074425908]
	TIME [epoch: 0.92 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9684644030779416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9684644030779416 | validation: 1.1236273445450224]
	TIME [epoch: 0.923 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0404495670452647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0404495670452647 | validation: 0.8860485774645483]
	TIME [epoch: 0.922 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9253432596425049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9253432596425049 | validation: 0.8755554890122466]
	TIME [epoch: 0.919 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9031411963468109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9031411963468109 | validation: 0.9053199639386229]
	TIME [epoch: 0.924 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9317247942303845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9317247942303845 | validation: 0.8440503649679041]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8829379644496044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8829379644496044 | validation: 0.8948778670826812]
	TIME [epoch: 0.918 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8852382526061249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8852382526061249 | validation: 0.8524127065854913]
	TIME [epoch: 0.916 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8957873994334492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8957873994334492 | validation: 0.9776462598177016]
	TIME [epoch: 0.92 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9389306942729817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9389306942729817 | validation: 0.8669267763672265]
	TIME [epoch: 0.931 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9076525210055997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9076525210055997 | validation: 0.9398812301054094]
	TIME [epoch: 0.917 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9092866077457717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9092866077457717 | validation: 0.84323827320298]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8838400328787279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8838400328787279 | validation: 0.8753309633350818]
	TIME [epoch: 0.924 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8861704437928706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8861704437928706 | validation: 0.8516988571293118]
	TIME [epoch: 0.922 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8726110849723449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8726110849723449 | validation: 0.827587371616677]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.851271615326195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.851271615326195 | validation: 0.8708663070351563]
	TIME [epoch: 0.922 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8580909400775605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8580909400775605 | validation: 0.8184332407219955]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8489159694416621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8489159694416621 | validation: 0.9190202064115516]
	TIME [epoch: 0.924 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.888861715903858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.888861715903858 | validation: 0.8592406001076388]
	TIME [epoch: 0.924 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9072020840305983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9072020840305983 | validation: 1.0372731392632744]
	TIME [epoch: 0.922 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.940991479281001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.940991479281001 | validation: 0.8179012046238099]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.832709790031111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.832709790031111 | validation: 0.8156927996546544]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8112948984286017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8112948984286017 | validation: 0.8271654697162831]
	TIME [epoch: 0.924 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8165350566676989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8165350566676989 | validation: 0.8318267210933737]
	TIME [epoch: 0.924 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8372681266734325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8372681266734325 | validation: 0.8831308140210228]
	TIME [epoch: 0.925 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9075622921873056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9075622921873056 | validation: 0.8581583557398661]
	TIME [epoch: 0.923 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8405053859869485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8405053859869485 | validation: 0.8687339870715809]
	TIME [epoch: 0.925 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8607877404822424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8607877404822424 | validation: 1.0236479978360522]
	TIME [epoch: 0.924 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9345065477457299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9345065477457299 | validation: 0.8207787113833739]
	TIME [epoch: 0.923 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8496437340266934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8496437340266934 | validation: 0.8810041880567566]
	TIME [epoch: 0.922 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8332702422880724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8332702422880724 | validation: 0.8028557743555642]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.806604109795436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.806604109795436 | validation: 0.8300329827248544]
	TIME [epoch: 0.919 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.822079122029594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.822079122029594 | validation: 0.8000391611240977]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.837662253126417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.837662253126417 | validation: 0.8865169928581236]
	TIME [epoch: 0.924 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8889370983496037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8889370983496037 | validation: 0.8066159325748914]
	TIME [epoch: 0.921 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8040846709673707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8040846709673707 | validation: 0.8272715740217358]
	TIME [epoch: 0.92 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7983023674250234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7983023674250234 | validation: 0.9473642150118249]
	TIME [epoch: 0.915 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8645305459373875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8645305459373875 | validation: 0.9028645597818464]
	TIME [epoch: 0.913 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9272687079676478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9272687079676478 | validation: 0.9958105786656075]
	TIME [epoch: 0.915 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9210453357423852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9210453357423852 | validation: 0.811391280638352]
	TIME [epoch: 0.917 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7875848312001787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7875848312001787 | validation: 0.7971588652539441]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8205481590223711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8205481590223711 | validation: 0.9109124836309818]
	TIME [epoch: 0.924 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8733354069976337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8733354069976337 | validation: 0.7943814834241361]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8248243821532256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8248243821532256 | validation: 0.8550335612929119]
	TIME [epoch: 0.935 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8521325022571266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8521325022571266 | validation: 0.872342048914068]
	TIME [epoch: 0.922 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8376922001200638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8376922001200638 | validation: 0.8336920201056821]
	TIME [epoch: 0.922 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8252983981031501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8252983981031501 | validation: 0.860131995848221]
	TIME [epoch: 0.918 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8180358250526821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8180358250526821 | validation: 0.7981485386063414]
	TIME [epoch: 0.919 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7847542818658999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7847542818658999 | validation: 0.8024850739695486]
	TIME [epoch: 0.919 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7851609137106891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7851609137106891 | validation: 0.7887389460252425]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7912996870612716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7912996870612716 | validation: 0.8285295028935574]
	TIME [epoch: 0.931 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7998002161680963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7998002161680963 | validation: 0.8452854384927838]
	TIME [epoch: 0.92 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8341412599606812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8341412599606812 | validation: 0.8937907179282818]
	TIME [epoch: 0.92 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8633177271037548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8633177271037548 | validation: 0.8662288190570996]
	TIME [epoch: 0.919 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8630504173592116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8630504173592116 | validation: 0.8339459886285792]
	TIME [epoch: 0.926 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8038800358493601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8038800358493601 | validation: 0.8018645307146063]
	TIME [epoch: 0.924 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8098040941990626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8098040941990626 | validation: 0.9009095277028767]
	TIME [epoch: 0.921 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.874522278136206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.874522278136206 | validation: 0.7957399475529909]
	TIME [epoch: 0.919 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8197871169234556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8197871169234556 | validation: 0.8238663205704833]
	TIME [epoch: 0.917 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.79307927976055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.79307927976055 | validation: 0.7611139044109899]
	TIME [epoch: 0.912 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7609968847464903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7609968847464903 | validation: 0.7868977465998604]
	TIME [epoch: 0.915 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7599443037092705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7599443037092705 | validation: 0.7733750622823495]
	TIME [epoch: 0.915 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7699157029395689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7699157029395689 | validation: 0.8416792174088944]
	TIME [epoch: 0.915 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.798488726627113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.798488726627113 | validation: 0.8540357023841548]
	TIME [epoch: 0.92 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8232570234623223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8232570234623223 | validation: 0.9286856930302476]
	TIME [epoch: 0.921 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8681482828178649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8681482828178649 | validation: 0.8705372354225827]
	TIME [epoch: 0.915 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8781526619553965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8781526619553965 | validation: 0.8030603047043509]
	TIME [epoch: 0.924 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8035010072517345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8035010072517345 | validation: 0.8054126155111727]
	TIME [epoch: 0.919 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7885799399779415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7885799399779415 | validation: 0.791146392559151]
	TIME [epoch: 0.922 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.792170615159811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.792170615159811 | validation: 0.8451199386350823]
	TIME [epoch: 0.919 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.812459029706219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.812459029706219 | validation: 0.760739692280104]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7737603234996044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7737603234996044 | validation: 0.7589622666271713]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7552624268238485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7552624268238485 | validation: 0.7514590710780821]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7550893970781656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7550893970781656 | validation: 0.7762465417983422]
	TIME [epoch: 0.924 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7852190500839679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7852190500839679 | validation: 0.7808300109304934]
	TIME [epoch: 0.921 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8047692530346723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8047692530346723 | validation: 0.8285027974899727]
	TIME [epoch: 23.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.829485443908647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.829485443908647 | validation: 0.7710924930247262]
	TIME [epoch: 1.81 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.747992000549468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.747992000549468 | validation: 0.7461161149273794]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.739537779051791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.739537779051791 | validation: 0.7514252785799781]
	TIME [epoch: 1.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7445063882610146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7445063882610146 | validation: 0.9119482070152038]
	TIME [epoch: 1.81 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8356862796754365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8356862796754365 | validation: 0.9360229751200979]
	TIME [epoch: 1.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9272225298586517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9272225298586517 | validation: 0.7984704072394884]
	TIME [epoch: 1.81 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7766375887215975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7766375887215975 | validation: 0.740998097018827]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7454334918565243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7454334918565243 | validation: 0.7154029890276842]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7772309035561397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7772309035561397 | validation: 0.7843781251914046]
	TIME [epoch: 1.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8012249625791992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8012249625791992 | validation: 0.777238973486294]
	TIME [epoch: 1.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7725710044456169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7725710044456169 | validation: 0.7352439952715404]
	TIME [epoch: 1.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7431642287555128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7431642287555128 | validation: 0.7048553718311751]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7122087338578441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7122087338578441 | validation: 0.6902942969834911]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7136767805514047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7136767805514047 | validation: 0.6979407118650331]
	TIME [epoch: 1.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7037968493880454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7037968493880454 | validation: 0.6794687670837178]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7000733587568126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7000733587568126 | validation: 0.6989748199866007]
	TIME [epoch: 1.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6999098616778582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6999098616778582 | validation: 0.805233494024392]
	TIME [epoch: 1.81 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8120042826194588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8120042826194588 | validation: 0.9645260837776555]
	TIME [epoch: 1.81 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9208334614967048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9208334614967048 | validation: 0.7689756565816608]
	TIME [epoch: 1.81 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8321475318082706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8321475318082706 | validation: 0.7041272223524492]
	TIME [epoch: 1.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7356134331992544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7356134331992544 | validation: 0.7516503543921433]
	TIME [epoch: 1.79 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7614959463586339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7614959463586339 | validation: 0.6933301389803085]
	TIME [epoch: 1.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7127889401871726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7127889401871726 | validation: 0.652241163292993]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6963006419141016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6963006419141016 | validation: 0.6695587189077464]
	TIME [epoch: 1.81 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6972665578191664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6972665578191664 | validation: 0.6361906047778579]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6762795214257404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6762795214257404 | validation: 0.6377785010253768]
	TIME [epoch: 1.81 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6713925829263573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6713925829263573 | validation: 0.6384020184001061]
	TIME [epoch: 1.81 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6827324393640674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6827324393640674 | validation: 0.7311538554212207]
	TIME [epoch: 1.82 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7543140299685532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7543140299685532 | validation: 0.8711079196812481]
	TIME [epoch: 1.82 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9337785348833325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9337785348833325 | validation: 0.7907637908294533]
	TIME [epoch: 1.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7645928481087435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7645928481087435 | validation: 0.6474713450297856]
	TIME [epoch: 1.79 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6637716007234511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6637716007234511 | validation: 0.6523362220768165]
	TIME [epoch: 1.81 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6719027215870148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6719027215870148 | validation: 0.642358101372331]
	TIME [epoch: 1.81 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.667607835714149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.667607835714149 | validation: 0.6216713662511454]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6507338070229723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6507338070229723 | validation: 0.6222018358912655]
	TIME [epoch: 1.81 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6480194477009582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6480194477009582 | validation: 0.5868372447177882]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6314765710973518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6314765710973518 | validation: 0.5996857778827718]
	TIME [epoch: 1.81 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6396866056419321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6396866056419321 | validation: 0.6453461736987278]
	TIME [epoch: 1.81 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6858076803949161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6858076803949161 | validation: 0.6791823699515458]
	TIME [epoch: 1.81 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7616338634813404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7616338634813404 | validation: 0.6873686629851289]
	TIME [epoch: 1.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7048116545403974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7048116545403974 | validation: 0.5738000446108412]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6261069665384983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6261069665384983 | validation: 0.6603043581543574]
	TIME [epoch: 1.81 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6998079342620475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6998079342620475 | validation: 0.8162701900963545]
	TIME [epoch: 1.81 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.773373526676718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.773373526676718 | validation: 0.5653710199269449]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6229002088448774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6229002088448774 | validation: 0.6037136354520056]
	TIME [epoch: 1.82 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6440392920327755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6440392920327755 | validation: 0.6562553284218955]
	TIME [epoch: 1.81 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6683239877794886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6683239877794886 | validation: 0.6752967672743098]
	TIME [epoch: 1.81 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7986419832153807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7986419832153807 | validation: 0.9584376380619016]
	TIME [epoch: 1.81 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.904612547148431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.904612547148431 | validation: 0.5878684461418396]
	TIME [epoch: 1.81 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6255452707604706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6255452707604706 | validation: 0.5803661162298919]
	TIME [epoch: 1.81 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6403644590979376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6403644590979376 | validation: 0.5840889206376563]
	TIME [epoch: 1.81 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6324828701060069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6324828701060069 | validation: 0.541386169975729]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5990461457892488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5990461457892488 | validation: 0.5552509562202754]
	TIME [epoch: 1.83 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5896346221140472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5896346221140472 | validation: 0.5037071206155249]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.583144280059061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.583144280059061 | validation: 0.6782662042024628]
	TIME [epoch: 1.81 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6402767461842194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6402767461842194 | validation: 0.635744004445087]
	TIME [epoch: 1.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7751326461601901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7751326461601901 | validation: 0.88630231757375]
	TIME [epoch: 1.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7831518017998006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7831518017998006 | validation: 0.5986145180819324]
	TIME [epoch: 1.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6316946917770273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6316946917770273 | validation: 0.5987213275009243]
	TIME [epoch: 1.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6887403607606837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6887403607606837 | validation: 0.5215793403136495]
	TIME [epoch: 1.79 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5844876115071003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5844876115071003 | validation: 0.5651284115971853]
	TIME [epoch: 1.81 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5740851499537379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5740851499537379 | validation: 0.48971631242824776]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5729677065880243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5729677065880243 | validation: 0.5693109883212378]
	TIME [epoch: 1.81 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5759226593394505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5759226593394505 | validation: 0.55551635147623]
	TIME [epoch: 1.81 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6390891393279173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6390891393279173 | validation: 0.8247216867539988]
	TIME [epoch: 1.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7947774109082772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7947774109082772 | validation: 0.6092299006988061]
	TIME [epoch: 1.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6627189930645975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6627189930645975 | validation: 0.531845353454018]
	TIME [epoch: 1.81 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5473190152827488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5473190152827488 | validation: 0.48057654731370913]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5613896523160251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5613896523160251 | validation: 0.6228909316777003]
	TIME [epoch: 1.81 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5983750918312852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5983750918312852 | validation: 0.4950638851000957]
	TIME [epoch: 1.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6023413989101388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6023413989101388 | validation: 0.6575529455701519]
	TIME [epoch: 1.81 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6125728220001518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6125728220001518 | validation: 0.5340380512450692]
	TIME [epoch: 1.79 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6318721506707441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6318721506707441 | validation: 0.7839995123876543]
	TIME [epoch: 1.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7436092710252007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7436092710252007 | validation: 0.5783906119601755]
	TIME [epoch: 1.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6329987995433725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6329987995433725 | validation: 0.5203387143577745]
	TIME [epoch: 1.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5244195969271163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5244195969271163 | validation: 0.4425510916667847]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5312046434644491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5312046434644491 | validation: 0.5046065483169425]
	TIME [epoch: 1.81 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49383502474815544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49383502474815544 | validation: 0.4523661071195615]
	TIME [epoch: 1.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5106969774463406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5106969774463406 | validation: 0.7086204934947804]
	TIME [epoch: 1.81 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.635288589156689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.635288589156689 | validation: 0.6444278670682424]
	TIME [epoch: 1.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7939410139382986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7939410139382986 | validation: 0.6767251705772113]
	TIME [epoch: 1.79 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6129088094774429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6129088094774429 | validation: 0.5135417318259701]
	TIME [epoch: 1.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5025596428455615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5025596428455615 | validation: 0.4421282094523001]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5014033980537684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5014033980537684 | validation: 0.4709553024699833]
	TIME [epoch: 1.81 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5052576667992874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5052576667992874 | validation: 0.47612613460809705]
	TIME [epoch: 1.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5271181486586521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5271181486586521 | validation: 0.519293253877526]
	TIME [epoch: 1.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6092590200873155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6092590200873155 | validation: 0.493282145030404]
	TIME [epoch: 1.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4983921303960516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4983921303960516 | validation: 0.3950098831575713]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43845551905415336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43845551905415336 | validation: 0.6509079098543]
	TIME [epoch: 1.81 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5803428849111079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5803428849111079 | validation: 0.7538988047575246]
	TIME [epoch: 1.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9443434955453998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9443434955453998 | validation: 0.642349436452542]
	TIME [epoch: 1.81 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5927952135664196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5927952135664196 | validation: 0.5498007610859553]
	TIME [epoch: 1.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5388626109631449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5388626109631449 | validation: 0.4688054488089928]
	TIME [epoch: 1.81 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5090630806592986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5090630806592986 | validation: 0.49479375979130724]
	TIME [epoch: 1.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45330854633113377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45330854633113377 | validation: 0.42899663403781496]
	TIME [epoch: 1.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45304693398620727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45304693398620727 | validation: 0.46116499808797706]
	TIME [epoch: 1.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4446371921405083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4446371921405083 | validation: 0.39324881730591443]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4272625634285956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4272625634285956 | validation: 0.468416543162798]
	TIME [epoch: 1.81 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42952607149352134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42952607149352134 | validation: 0.37675506774441686]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4533311854154933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4533311854154933 | validation: 0.7526868939907904]
	TIME [epoch: 1.83 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6562275435148022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6562275435148022 | validation: 0.7072923948134098]
	TIME [epoch: 1.82 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7712540054446287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7712540054446287 | validation: 0.6344098297404361]
	TIME [epoch: 1.81 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6092497922837512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6092497922837512 | validation: 0.5003524836989434]
	TIME [epoch: 1.81 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5110912020063075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5110912020063075 | validation: 0.44320803244979007]
	TIME [epoch: 1.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43516043122732884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43516043122732884 | validation: 0.38374309258228473]
	TIME [epoch: 1.82 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3991568348232118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3991568348232118 | validation: 0.36042538857856826]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3828016411923141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3828016411923141 | validation: 0.3638272280416702]
	TIME [epoch: 1.81 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38300482749658044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38300482749658044 | validation: 0.46475556287176395]
	TIME [epoch: 1.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4421061851067125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4421061851067125 | validation: 0.6964958131201198]
	TIME [epoch: 1.81 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.87147247725877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.87147247725877 | validation: 0.7247852475329639]
	TIME [epoch: 1.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6071960285391603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6071960285391603 | validation: 0.44869919739258723]
	TIME [epoch: 1.81 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4099653460017775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4099653460017775 | validation: 0.47115130569960173]
	TIME [epoch: 1.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49421826842601707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49421826842601707 | validation: 0.4232316008777291]
	TIME [epoch: 1.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3917223324967756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3917223324967756 | validation: 0.36785643140758595]
	TIME [epoch: 1.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35741660446006907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35741660446006907 | validation: 0.34967805259094364]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3737521210809349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3737521210809349 | validation: 0.4157879063898342]
	TIME [epoch: 1.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3806852850040221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3806852850040221 | validation: 0.35048626726257437]
	TIME [epoch: 1.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37213242112746914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37213242112746914 | validation: 0.46376544160270283]
	TIME [epoch: 1.81 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45747839501810544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45747839501810544 | validation: 0.9225514140118986]
	TIME [epoch: 1.81 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7934330826336526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7934330826336526 | validation: 0.41379922712780054]
	TIME [epoch: 1.81 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43611164994185836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43611164994185836 | validation: 0.4291333921468521]
	TIME [epoch: 1.82 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3869091724694833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3869091724694833 | validation: 0.4232192068224496]
	TIME [epoch: 1.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.388656904349526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.388656904349526 | validation: 0.46399286469435935]
	TIME [epoch: 1.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47310190668951196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47310190668951196 | validation: 0.6665396548126674]
	TIME [epoch: 1.81 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5691759654943964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5691759654943964 | validation: 0.3756634743705927]
	TIME [epoch: 1.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3359522725158473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3359522725158473 | validation: 0.4202037206244679]
	TIME [epoch: 1.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3881604050825353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3881604050825353 | validation: 0.5031834911504559]
	TIME [epoch: 1.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4310685414187337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4310685414187337 | validation: 0.38766393914163955]
	TIME [epoch: 1.81 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32841647199993107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32841647199993107 | validation: 0.38271879511628293]
	TIME [epoch: 1.81 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39216844984547616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39216844984547616 | validation: 0.40124247620857845]
	TIME [epoch: 1.81 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35973108504169105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35973108504169105 | validation: 0.2978273856985589]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2868461410637035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2868461410637035 | validation: 0.3533125471810116]
	TIME [epoch: 1.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32725100135179097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32725100135179097 | validation: 0.7464493475826867]
	TIME [epoch: 1.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6172179488470968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6172179488470968 | validation: 0.6567945782811492]
	TIME [epoch: 1.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6634464185928262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6634464185928262 | validation: 0.5082184469508996]
	TIME [epoch: 1.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.454838009926697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.454838009926697 | validation: 0.34497981214287715]
	TIME [epoch: 1.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3036829674292565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3036829674292565 | validation: 0.4229911487330175]
	TIME [epoch: 1.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35890858308257434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35890858308257434 | validation: 0.38057361464436124]
	TIME [epoch: 1.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37028185057975493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37028185057975493 | validation: 0.36309967823775025]
	TIME [epoch: 1.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3552530092337052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3552530092337052 | validation: 0.5032976909671423]
	TIME [epoch: 1.81 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42662494134047135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42662494134047135 | validation: 0.3418104871652552]
	TIME [epoch: 1.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2963038701366583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2963038701366583 | validation: 0.3147999679104104]
	TIME [epoch: 1.81 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2836270564991819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2836270564991819 | validation: 0.35911848933521073]
	TIME [epoch: 1.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2995809545829902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2995809545829902 | validation: 0.321156546891987]
	TIME [epoch: 1.81 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3239761292791842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3239761292791842 | validation: 0.3765942061686398]
	TIME [epoch: 1.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3318198938697038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3318198938697038 | validation: 0.5576937139383087]
	TIME [epoch: 1.81 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48923763804149845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48923763804149845 | validation: 0.7020987523196244]
	TIME [epoch: 1.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7754021048570752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7754021048570752 | validation: 0.5589792554507411]
	TIME [epoch: 1.82 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46126687928922594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46126687928922594 | validation: 0.42332528089220905]
	TIME [epoch: 1.82 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3448593951504998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3448593951504998 | validation: 0.44467037139179183]
	TIME [epoch: 1.82 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4020313999679561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4020313999679561 | validation: 0.360179628659026]
	TIME [epoch: 1.81 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3102633673557526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3102633673557526 | validation: 0.32571700604885234]
	TIME [epoch: 1.81 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28697042012649915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28697042012649915 | validation: 0.35219747194407686]
	TIME [epoch: 1.81 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30736595160404995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30736595160404995 | validation: 0.3415056238391376]
	TIME [epoch: 1.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2792028304455367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2792028304455367 | validation: 0.28861522246868687]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2496752230068523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2496752230068523 | validation: 0.29533676493152566]
	TIME [epoch: 1.81 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2684868144859793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2684868144859793 | validation: 0.47310528911634697]
	TIME [epoch: 1.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4321682771050297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4321682771050297 | validation: 0.6261106288668291]
	TIME [epoch: 1.81 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5719742525621285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5719742525621285 | validation: 0.3523930358504118]
	TIME [epoch: 1.81 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3068411676279362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3068411676279362 | validation: 0.4546387293651938]
	TIME [epoch: 1.81 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36599156666831634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36599156666831634 | validation: 0.27477050199575725]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25607094674904723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25607094674904723 | validation: 0.3707720724571812]
	TIME [epoch: 1.81 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.333696536435078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.333696536435078 | validation: 0.5988578608226114]
	TIME [epoch: 1.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5238824782049731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5238824782049731 | validation: 0.42948843367607936]
	TIME [epoch: 1.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35174956454930917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35174956454930917 | validation: 0.3353937573710162]
	TIME [epoch: 1.79 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31919809274989797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31919809274989797 | validation: 0.3009773784299412]
	TIME [epoch: 1.79 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24614081490538503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24614081490538503 | validation: 0.2449016194434492]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2229431917112195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2229431917112195 | validation: 0.2545293364299424]
	TIME [epoch: 1.82 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23090404386105115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23090404386105115 | validation: 0.2958164797424773]
	TIME [epoch: 1.82 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23409383556050828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23409383556050828 | validation: 0.23811998617509192]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20731176267006965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20731176267006965 | validation: 0.34201169316976165]
	TIME [epoch: 1.82 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2655895270656519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2655895270656519 | validation: 0.4577391595923068]
	TIME [epoch: 1.82 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5441528489666336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5441528489666336 | validation: 1.0939501557384614]
	TIME [epoch: 1.82 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8584803016104608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8584803016104608 | validation: 0.48731479590757765]
	TIME [epoch: 1.82 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39030985216856756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39030985216856756 | validation: 0.49299771042757223]
	TIME [epoch: 1.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5140475282688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5140475282688 | validation: 0.47524301971928795]
	TIME [epoch: 1.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37983325957318753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37983325957318753 | validation: 0.39295839345469286]
	TIME [epoch: 1.81 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3313645660634736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3313645660634736 | validation: 0.28063527447925596]
	TIME [epoch: 1.81 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25767515036923383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25767515036923383 | validation: 0.275410845432976]
	TIME [epoch: 1.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23549967359972412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23549967359972412 | validation: 0.30117984076613236]
	TIME [epoch: 1.82 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22634179866563153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22634179866563153 | validation: 0.23676872741954105]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20541452521755893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20541452521755893 | validation: 0.22850514844677436]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18873627995327993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18873627995327993 | validation: 0.22537086974361875]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17767823644775824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17767823644775824 | validation: 0.22326612206769442]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1812356294331778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1812356294331778 | validation: 0.2891880410701152]
	TIME [epoch: 1.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2430440875452289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2430440875452289 | validation: 0.4677558244975945]
	TIME [epoch: 1.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5746740360739447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5746740360739447 | validation: 0.5280398692049445]
	TIME [epoch: 1.79 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39599836698991014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39599836698991014 | validation: 0.3760917018621771]
	TIME [epoch: 1.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30251134297156584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30251134297156584 | validation: 0.4383289465418099]
	TIME [epoch: 1.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3499109130141963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3499109130141963 | validation: 0.2814318976775215]
	TIME [epoch: 1.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23070015895292595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23070015895292595 | validation: 0.3669377233447582]
	TIME [epoch: 1.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3174582234980504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3174582234980504 | validation: 0.4483299333072786]
	TIME [epoch: 1.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3511091040483156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3511091040483156 | validation: 0.32025927571190693]
	TIME [epoch: 1.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2552819340797473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2552819340797473 | validation: 0.25512209180438533]
	TIME [epoch: 1.81 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22376595091434864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22376595091434864 | validation: 0.286978854929593]
	TIME [epoch: 1.79 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21971630673140186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21971630673140186 | validation: 0.22670512067717574]
	TIME [epoch: 1.81 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19169051211950525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19169051211950525 | validation: 0.29904215878326795]
	TIME [epoch: 1.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24749201102175108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24749201102175108 | validation: 0.3262033817351887]
	TIME [epoch: 1.81 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33329512618414214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33329512618414214 | validation: 0.4204954880145416]
	TIME [epoch: 1.79 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.313845674698011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.313845674698011 | validation: 0.25614034213771397]
	TIME [epoch: 1.81 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21067956962346115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21067956962346115 | validation: 0.222641816887164]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1708432442961517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1708432442961517 | validation: 0.2125926598757304]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1651152005209432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1651152005209432 | validation: 0.2811738838157174]
	TIME [epoch: 1.81 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19868056505074072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19868056505074072 | validation: 0.21211848695131225]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1792804683950882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1792804683950882 | validation: 0.33250577818143306]
	TIME [epoch: 1.82 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26616868984757086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26616868984757086 | validation: 0.329630554515757]
	TIME [epoch: 1.81 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2804977791065357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2804977791065357 | validation: 0.445911668835859]
	TIME [epoch: 1.81 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3464176700193972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3464176700193972 | validation: 0.2803325768265383]
	TIME [epoch: 1.82 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2646193832114935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2646193832114935 | validation: 0.32872375742453236]
	TIME [epoch: 1.82 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27846723964654685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27846723964654685 | validation: 0.32289215501852564]
	TIME [epoch: 1.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26689595153570705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26689595153570705 | validation: 0.18839851972159122]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14406200705990638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14406200705990638 | validation: 0.2699277230307686]
	TIME [epoch: 1.81 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21235744577698412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21235744577698412 | validation: 0.42720177806246923]
	TIME [epoch: 1.81 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.314452730664884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.314452730664884 | validation: 0.23107586906838218]
	TIME [epoch: 1.81 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19899728547140158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19899728547140158 | validation: 0.2874456173831676]
	TIME [epoch: 1.81 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25642158784972713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25642158784972713 | validation: 0.20775621709859218]
	TIME [epoch: 1.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19100072543325014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19100072543325014 | validation: 0.2792171542154147]
	TIME [epoch: 1.81 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19505503765167467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19505503765167467 | validation: 0.1989378879146323]
	TIME [epoch: 1.81 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1771609006090064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1771609006090064 | validation: 0.3075021377030381]
	TIME [epoch: 1.81 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23766913144052987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23766913144052987 | validation: 0.31221238717473837]
	TIME [epoch: 1.81 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35485050114651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35485050114651 | validation: 0.4279863708436799]
	TIME [epoch: 1.83 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3210150340624259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3210150340624259 | validation: 0.175097161292367]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13697532145515495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13697532145515495 | validation: 0.18841355445252797]
	TIME [epoch: 1.81 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16449733533154287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16449733533154287 | validation: 0.19426546068534045]
	TIME [epoch: 1.81 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14480822805621646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14480822805621646 | validation: 0.16872064807650491]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1301531083980283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1301531083980283 | validation: 0.1577687280066288]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11494186528321834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11494186528321834 | validation: 0.1426197053597634]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12080764254112783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12080764254112783 | validation: 0.24504450013556955]
	TIME [epoch: 1.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1828710594620206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1828710594620206 | validation: 0.41340568479236195]
	TIME [epoch: 1.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4095220648755536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4095220648755536 | validation: 0.5272953758019406]
	TIME [epoch: 1.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36632756924644055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36632756924644055 | validation: 0.23647693489444663]
	TIME [epoch: 1.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17620004157079794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17620004157079794 | validation: 0.27055261945470627]
	TIME [epoch: 1.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.297242616980641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.297242616980641 | validation: 0.1978784977623947]
	TIME [epoch: 1.81 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1456219999901652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1456219999901652 | validation: 0.22262871242579757]
	TIME [epoch: 1.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16937232866403598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16937232866403598 | validation: 0.23950099726926566]
	TIME [epoch: 1.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21121535933132238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21121535933132238 | validation: 0.15378992873303488]
	TIME [epoch: 1.81 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1307468203421116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1307468203421116 | validation: 0.19865144867269843]
	TIME [epoch: 1.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17410377654887207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17410377654887207 | validation: 0.340147406152108]
	TIME [epoch: 1.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27971819143200255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27971819143200255 | validation: 0.1623677717153339]
	TIME [epoch: 1.81 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1356527163332191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1356527163332191 | validation: 0.21361820217246927]
	TIME [epoch: 1.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14932911224688142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14932911224688142 | validation: 0.19653065746880682]
	TIME [epoch: 1.81 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16518021602629396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16518021602629396 | validation: 0.22525379937744192]
	TIME [epoch: 1.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16414017481116677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16414017481116677 | validation: 0.2241166125917892]
	TIME [epoch: 1.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1834515497180177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1834515497180177 | validation: 0.39275921123793955]
	TIME [epoch: 1.81 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26557165627661866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26557165627661866 | validation: 0.1843620268534843]
	TIME [epoch: 1.81 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.182818987150701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.182818987150701 | validation: 0.23086095304365264]
	TIME [epoch: 1.81 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18061898580813363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18061898580813363 | validation: 0.1643111434686865]
	TIME [epoch: 1.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15206258232353087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15206258232353087 | validation: 0.13927675899695702]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10874337247382862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10874337247382862 | validation: 0.13860221523160732]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10149238690875928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10149238690875928 | validation: 0.16684519018070693]
	TIME [epoch: 1.81 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11948358667064422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11948358667064422 | validation: 0.29130620767999144]
	TIME [epoch: 1.81 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20796871546904608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20796871546904608 | validation: 0.2803729381275993]
	TIME [epoch: 1.92 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27266952313681686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27266952313681686 | validation: 0.4673215206404918]
	TIME [epoch: 1.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.345651279882281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.345651279882281 | validation: 0.14307380056910998]
	TIME [epoch: 1.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12438660029169973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12438660029169973 | validation: 0.22850033007164683]
	TIME [epoch: 1.81 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16359820801961916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16359820801961916 | validation: 0.23981193370942366]
	TIME [epoch: 1.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18414418599074928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18414418599074928 | validation: 0.17723852560836223]
	TIME [epoch: 1.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13921765651471538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13921765651471538 | validation: 0.12516127000938596]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09963280101382069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09963280101382069 | validation: 0.1566645394671359]
	TIME [epoch: 1.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11793727146886795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11793727146886795 | validation: 0.14483733196512608]
	TIME [epoch: 1.81 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1326526922415872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1326526922415872 | validation: 0.27292561043661767]
	TIME [epoch: 1.81 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2085454400079776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2085454400079776 | validation: 0.23227822235312123]
	TIME [epoch: 1.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2126616732478093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2126616732478093 | validation: 0.2980162974522676]
	TIME [epoch: 1.81 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20110782783514417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20110782783514417 | validation: 0.15681137456065694]
	TIME [epoch: 1.81 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15734026500271742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15734026500271742 | validation: 0.2476101599675003]
	TIME [epoch: 1.81 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18716513360416426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18716513360416426 | validation: 0.24129833701476647]
	TIME [epoch: 1.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20221182287748454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20221182287748454 | validation: 0.09750275729664992]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08768532776356715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08768532776356715 | validation: 0.135227316380786]
	TIME [epoch: 1.81 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11223990825341532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11223990825341532 | validation: 0.1694736632098736]
	TIME [epoch: 1.79 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11753366246579067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11753366246579067 | validation: 0.13999543590933444]
	TIME [epoch: 1.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12243651718153972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12243651718153972 | validation: 0.3410442645475537]
	TIME [epoch: 1.81 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23450172889668872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23450172889668872 | validation: 0.2759147091844695]
	TIME [epoch: 1.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3056030368081495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3056030368081495 | validation: 0.29575216424634804]
	TIME [epoch: 1.81 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2143430000198866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2143430000198866 | validation: 0.11831543213978701]
	TIME [epoch: 1.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11306022792557524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11306022792557524 | validation: 0.14197135015189885]
	TIME [epoch: 1.79 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12987773065904404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12987773065904404 | validation: 0.15655361698902018]
	TIME [epoch: 1.79 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11846106863185908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11846106863185908 | validation: 0.12944813956633694]
	TIME [epoch: 1.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0997952521283689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0997952521283689 | validation: 0.09835794722616979]
	TIME [epoch: 1.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0819407866267282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0819407866267282 | validation: 0.12806061627835819]
	TIME [epoch: 1.81 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09103861257076803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09103861257076803 | validation: 0.2234413618096748]
	TIME [epoch: 1.81 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17849728633801382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17849728633801382 | validation: 0.5334118123507608]
	TIME [epoch: 1.81 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3974163663741934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3974163663741934 | validation: 0.17017091707870255]
	TIME [epoch: 1.81 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1759888428970419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1759888428970419 | validation: 0.28053242971864356]
	TIME [epoch: 1.79 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23523700890124322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23523700890124322 | validation: 0.1811794269341241]
	TIME [epoch: 1.79 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12520579629747944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12520579629747944 | validation: 0.10872230712090432]
	TIME [epoch: 1.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1006425350567185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1006425350567185 | validation: 0.14936908967202328]
	TIME [epoch: 1.81 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1268142587003954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1268142587003954 | validation: 0.14458648299969895]
	TIME [epoch: 1.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12464773523782775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12464773523782775 | validation: 0.15765528683331045]
	TIME [epoch: 1.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11612306185927988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11612306185927988 | validation: 0.13103899156443707]
	TIME [epoch: 1.81 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1185511458461927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1185511458461927 | validation: 0.23948352091932407]
	TIME [epoch: 1.81 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1627954855484658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1627954855484658 | validation: 0.20012127902269616]
	TIME [epoch: 1.81 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1985267285807756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1985267285807756 | validation: 0.28041930887857774]
	TIME [epoch: 1.82 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21421276800076514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21421276800076514 | validation: 0.10816388520951659]
	TIME [epoch: 1.81 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12684714060840285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12684714060840285 | validation: 0.1232988327037228]
	TIME [epoch: 1.81 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09794082940199683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09794082940199683 | validation: 0.16783685864690787]
	TIME [epoch: 1.84 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11509549034826025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11509549034826025 | validation: 0.11527259168134148]
	TIME [epoch: 1.81 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08963283173140744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08963283173140744 | validation: 0.09924687068720417]
	TIME [epoch: 1.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07352739167185807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07352739167185807 | validation: 0.11059276922021813]
	TIME [epoch: 1.81 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08651750238123133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08651750238123133 | validation: 0.10230677136689495]
	TIME [epoch: 1.81 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08021343868817281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08021343868817281 | validation: 0.15929620124040472]
	TIME [epoch: 25.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11519011847169776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11519011847169776 | validation: 0.3022123399942037]
	TIME [epoch: 3.55 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3061946082611894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3061946082611894 | validation: 0.5895834238655435]
	TIME [epoch: 3.56 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4523351471962178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4523351471962178 | validation: 0.10097136556039357]
	TIME [epoch: 3.59 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0831651111570781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0831651111570781 | validation: 0.24134616359504224]
	TIME [epoch: 3.57 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20071568394844586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20071568394844586 | validation: 0.24513017917561283]
	TIME [epoch: 3.56 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20225021463556794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20225021463556794 | validation: 0.11314660450820241]
	TIME [epoch: 3.57 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0853467619083434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0853467619083434 | validation: 0.0924590188721723]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09826022954918702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09826022954918702 | validation: 0.12249753299065945]
	TIME [epoch: 3.57 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10200353142675894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10200353142675894 | validation: 0.11004257737807506]
	TIME [epoch: 3.56 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0808878340845681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0808878340845681 | validation: 0.1015449047940898]
	TIME [epoch: 3.56 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09628424345112482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09628424345112482 | validation: 0.12738641939125506]
	TIME [epoch: 3.56 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0934966743342057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0934966743342057 | validation: 0.11496420832118548]
	TIME [epoch: 3.57 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09366587985496212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09366587985496212 | validation: 0.10061926185597628]
	TIME [epoch: 3.56 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08363089260112588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08363089260112588 | validation: 0.12042029476431695]
	TIME [epoch: 3.57 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09524170537402273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09524170537402273 | validation: 0.16303540126490385]
	TIME [epoch: 3.58 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1737369222599017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1737369222599017 | validation: 0.38567111376172725]
	TIME [epoch: 3.58 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30161470779764443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30161470779764443 | validation: 0.20332081062847715]
	TIME [epoch: 3.56 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18601402536992237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18601402536992237 | validation: 0.17390073891548746]
	TIME [epoch: 3.58 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11786076928780263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11786076928780263 | validation: 0.10681317356932463]
	TIME [epoch: 3.55 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08685202489618898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08685202489618898 | validation: 0.09964439021656601]
	TIME [epoch: 3.56 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0842072222761531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0842072222761531 | validation: 0.11194072515352188]
	TIME [epoch: 3.55 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10618254055080284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10618254055080284 | validation: 0.10506689637356328]
	TIME [epoch: 3.57 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08962720568580505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08962720568580505 | validation: 0.08791262479245561]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.066903050348983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.066903050348983 | validation: 0.08442785794513973]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0645545848575925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0645545848575925 | validation: 0.11349869493875381]
	TIME [epoch: 3.59 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10224342682510341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10224342682510341 | validation: 0.17301934133491848]
	TIME [epoch: 3.59 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15336981372342176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15336981372342176 | validation: 0.14835512091057743]
	TIME [epoch: 3.56 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1436513569610395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1436513569610395 | validation: 0.10381400579314258]
	TIME [epoch: 3.56 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09396887254314405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09396887254314405 | validation: 0.12332518683416745]
	TIME [epoch: 3.59 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0974958270993534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0974958270993534 | validation: 0.23517828633833845]
	TIME [epoch: 3.58 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19735739619750764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19735739619750764 | validation: 0.5175804320229126]
	TIME [epoch: 3.57 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3878055386475785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3878055386475785 | validation: 0.1151813823788263]
	TIME [epoch: 3.56 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11866994212288465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11866994212288465 | validation: 0.20827618697325181]
	TIME [epoch: 3.56 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16569257849663172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16569257849663172 | validation: 0.20750866788738428]
	TIME [epoch: 3.56 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1688988096165015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1688988096165015 | validation: 0.06843833242363309]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06052237833725489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06052237833725489 | validation: 0.0793620027357595]
	TIME [epoch: 3.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06557961179578149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06557961179578149 | validation: 0.10161851376837028]
	TIME [epoch: 3.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07077405224490868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07077405224490868 | validation: 0.06349014745954673]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_539.pth
	Model improved!!!
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049492052126488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049492052126488 | validation: 0.058913466474882895]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042251825142688645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042251825142688645 | validation: 0.07233715940314177]
	TIME [epoch: 3.57 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046379674526994395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046379674526994395 | validation: 0.10277375501571542]
	TIME [epoch: 3.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08498813959649815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08498813959649815 | validation: 0.23647565433873652]
	TIME [epoch: 3.57 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23122361374654118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23122361374654118 | validation: 0.2798318804821815]
	TIME [epoch: 3.57 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26075459760095443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26075459760095443 | validation: 0.1267528141668902]
	TIME [epoch: 3.59 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09621216955176082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09621216955176082 | validation: 0.1392124763282611]
	TIME [epoch: 3.59 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10230147033253605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10230147033253605 | validation: 0.1978263478682753]
	TIME [epoch: 3.57 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17580212133399978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17580212133399978 | validation: 0.21467498158246823]
	TIME [epoch: 3.57 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16268222432202165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16268222432202165 | validation: 0.09861816096987158]
	TIME [epoch: 3.56 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10036290237442569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10036290237442569 | validation: 0.10285842968995994]
	TIME [epoch: 3.59 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08086611369078373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08086611369078373 | validation: 0.08492290241220732]
	TIME [epoch: 3.56 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06545109467026565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06545109467026565 | validation: 0.08997421014265537]
	TIME [epoch: 3.55 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07257889560625402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07257889560625402 | validation: 0.11017306609779819]
	TIME [epoch: 3.56 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07527258935770205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07527258935770205 | validation: 0.09698067302542472]
	TIME [epoch: 3.58 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08390050977272541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08390050977272541 | validation: 0.1810018877764563]
	TIME [epoch: 3.59 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1296999827112306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1296999827112306 | validation: 0.242878545326387]
	TIME [epoch: 3.58 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2025097949036575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2025097949036575 | validation: 0.35331591317454836]
	TIME [epoch: 3.58 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28300081244574693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28300081244574693 | validation: 0.07918676301722251]
	TIME [epoch: 3.56 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08987084941196447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08987084941196447 | validation: 0.14031161555304084]
	TIME [epoch: 3.57 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1178449670312271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1178449670312271 | validation: 0.1267246573400267]
	TIME [epoch: 3.58 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09406232373675605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09406232373675605 | validation: 0.058978924905553454]
	TIME [epoch: 3.56 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0466995771089783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0466995771089783 | validation: 0.05943544261464308]
	TIME [epoch: 3.55 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04688621721099589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04688621721099589 | validation: 0.09460777604674675]
	TIME [epoch: 3.56 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05778436687293983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05778436687293983 | validation: 0.09650933007273793]
	TIME [epoch: 3.56 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08748895642794391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08748895642794391 | validation: 0.23415929634341692]
	TIME [epoch: 3.58 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18148613337793187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18148613337793187 | validation: 0.16579330398632114]
	TIME [epoch: 3.58 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18032075642333645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18032075642333645 | validation: 0.14836133440297275]
	TIME [epoch: 3.58 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10472841859993681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10472841859993681 | validation: 0.06528118966500639]
	TIME [epoch: 3.57 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06197030525683017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06197030525683017 | validation: 0.10352509914528399]
	TIME [epoch: 3.57 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1030257935462018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1030257935462018 | validation: 0.16171385720203496]
	TIME [epoch: 3.57 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15628942334487225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15628942334487225 | validation: 0.13488962482819503]
	TIME [epoch: 3.55 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14199986824136843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14199986824136843 | validation: 0.06856137131136018]
	TIME [epoch: 3.55 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05409655703449008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05409655703449008 | validation: 0.06487872601520465]
	TIME [epoch: 3.57 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04456605094445498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04456605094445498 | validation: 0.06796087552801289]
	TIME [epoch: 3.57 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05497917474571553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05497917474571553 | validation: 0.08859690409113447]
	TIME [epoch: 3.58 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06096731289483686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06096731289483686 | validation: 0.07391112830006848]
	TIME [epoch: 3.56 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06785236480292026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06785236480292026 | validation: 0.1528645037276574]
	TIME [epoch: 3.57 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10833091433934687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10833091433934687 | validation: 0.3330099160523502]
	TIME [epoch: 3.57 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3155681830976392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3155681830976392 | validation: 0.38995487499993386]
	TIME [epoch: 3.58 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3300759610413398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3300759610413398 | validation: 0.12757168814226447]
	TIME [epoch: 3.56 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10056407641052716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10056407641052716 | validation: 0.12492983329824806]
	TIME [epoch: 3.55 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10964659339894568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10964659339894568 | validation: 0.11512775333113297]
	TIME [epoch: 3.56 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11489724476008267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11489724476008267 | validation: 0.09952160087289169]
	TIME [epoch: 3.57 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07780957798724618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07780957798724618 | validation: 0.07953697557613613]
	TIME [epoch: 3.58 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08688828904492507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08688828904492507 | validation: 0.08196587841735807]
	TIME [epoch: 3.58 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0725577618368418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0725577618368418 | validation: 0.09287107404095057]
	TIME [epoch: 3.57 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06309610032237714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06309610032237714 | validation: 0.06853275015578629]
	TIME [epoch: 3.57 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05386761400502325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05386761400502325 | validation: 0.06270887495838827]
	TIME [epoch: 3.56 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04167629213597607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04167629213597607 | validation: 0.06054706999918496]
	TIME [epoch: 3.55 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04390363817345784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04390363817345784 | validation: 0.07235475073168443]
	TIME [epoch: 3.58 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04968013614624055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04968013614624055 | validation: 0.0970648709375292]
	TIME [epoch: 3.55 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08292815919541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08292815919541 | validation: 0.17260265982797615]
	TIME [epoch: 3.56 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12818509427332214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12818509427332214 | validation: 0.1549080231494227]
	TIME [epoch: 3.56 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1620287283257502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1620287283257502 | validation: 0.18425931956131694]
	TIME [epoch: 3.59 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16636773694339305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16636773694339305 | validation: 0.13279053190166645]
	TIME [epoch: 3.58 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12182983234461454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12182983234461454 | validation: 0.08458092057325395]
	TIME [epoch: 3.57 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07687319854243757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07687319854243757 | validation: 0.07659810229634029]
	TIME [epoch: 3.56 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06359313344411134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06359313344411134 | validation: 0.09087013015982173]
	TIME [epoch: 3.57 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0929894913924047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0929894913924047 | validation: 0.14676179387605354]
	TIME [epoch: 3.56 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12630376849275463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12630376849275463 | validation: 0.16775653371099558]
	TIME [epoch: 3.59 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15050889302156092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15050889302156092 | validation: 0.24249455867904432]
	TIME [epoch: 3.61 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17294758282154069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17294758282154069 | validation: 0.1046749849970769]
	TIME [epoch: 3.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09707351440702869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09707351440702869 | validation: 0.09561949702028227]
	TIME [epoch: 3.57 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07557071749725834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07557071749725834 | validation: 0.08069548791222132]
	TIME [epoch: 3.61 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06466375098900075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06466375098900075 | validation: 0.06777108976243289]
	TIME [epoch: 3.59 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05173881407785082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05173881407785082 | validation: 0.06739470306256772]
	TIME [epoch: 3.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050797792959921824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050797792959921824 | validation: 0.06663010302263657]
	TIME [epoch: 3.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06492088467817275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06492088467817275 | validation: 0.10734579850143713]
	TIME [epoch: 3.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08977519594788876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08977519594788876 | validation: 0.0790443903861948]
	TIME [epoch: 3.59 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08040598106907125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08040598106907125 | validation: 0.12223070871111559]
	TIME [epoch: 3.58 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09357372417706693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09357372417706693 | validation: 0.10977226332678294]
	TIME [epoch: 3.57 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10795949826390874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10795949826390874 | validation: 0.16458632436008452]
	TIME [epoch: 3.59 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11740098864588529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11740098864588529 | validation: 0.10229106312487374]
	TIME [epoch: 3.57 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08222813632787065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08222813632787065 | validation: 0.1336280137865428]
	TIME [epoch: 3.57 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10469996000959865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10469996000959865 | validation: 0.1526276859509762]
	TIME [epoch: 3.57 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1640049434659756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1640049434659756 | validation: 0.1703134302529916]
	TIME [epoch: 3.59 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14264202082407024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14264202082407024 | validation: 0.13103363510240704]
	TIME [epoch: 3.58 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11592526190633595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11592526190633595 | validation: 0.08097445002638107]
	TIME [epoch: 3.57 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08009410814341993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08009410814341993 | validation: 0.07510213737217128]
	TIME [epoch: 3.59 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049023140963493805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049023140963493805 | validation: 0.05412680051469879]
	TIME [epoch: 3.59 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036698448269535174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036698448269535174 | validation: 0.04734189045709916]
	TIME [epoch: 3.6 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03424897105622834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03424897105622834 | validation: 0.053666331204159534]
	TIME [epoch: 3.57 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038007141591132394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038007141591132394 | validation: 0.06728235831946452]
	TIME [epoch: 3.55 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062063312759559126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.062063312759559126 | validation: 0.1332999380272209]
	TIME [epoch: 3.56 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13210045138489382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13210045138489382 | validation: 0.15605766717353178]
	TIME [epoch: 3.57 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15664370925865423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15664370925865423 | validation: 0.11785373347918959]
	TIME [epoch: 3.54 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10390842301184443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10390842301184443 | validation: 0.0620084961847877]
	TIME [epoch: 3.55 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054923935016907954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054923935016907954 | validation: 0.10149916257817404]
	TIME [epoch: 3.55 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06765874943138882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06765874943138882 | validation: 0.20460794448936226]
	TIME [epoch: 3.58 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16008882278794268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16008882278794268 | validation: 0.3356667284381854]
	TIME [epoch: 3.56 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28290210981755975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28290210981755975 | validation: 0.07909391580208158]
	TIME [epoch: 3.57 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.097999617750123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.097999617750123 | validation: 0.10878386863813168]
	TIME [epoch: 3.56 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07633529409382978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07633529409382978 | validation: 0.10167699647769997]
	TIME [epoch: 3.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07243018857059362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07243018857059362 | validation: 0.04095054843834593]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04445018282675933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04445018282675933 | validation: 0.05011820890903618]
	TIME [epoch: 3.57 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03491801481302147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03491801481302147 | validation: 0.050206683767748686]
	TIME [epoch: 3.57 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033227871866698955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033227871866698955 | validation: 0.04493579463564895]
	TIME [epoch: 3.59 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038133347141907976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038133347141907976 | validation: 0.0752878245866403]
	TIME [epoch: 3.57 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06701507821413888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06701507821413888 | validation: 0.14595746816178284]
	TIME [epoch: 3.57 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1420154193033547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1420154193033547 | validation: 0.22204099878355468]
	TIME [epoch: 3.61 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19773560792151945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19773560792151945 | validation: 0.1258005880130955]
	TIME [epoch: 3.59 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10973742331250001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10973742331250001 | validation: 0.13558734031291692]
	TIME [epoch: 3.58 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1033371487363946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1033371487363946 | validation: 0.10063728134868773]
	TIME [epoch: 3.57 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10466093318877402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10466093318877402 | validation: 0.0633238952800092]
	TIME [epoch: 3.57 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05781580864835219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05781580864835219 | validation: 0.04333510353837434]
	TIME [epoch: 3.59 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03240733812798542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03240733812798542 | validation: 0.04188322827984353]
	TIME [epoch: 3.58 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029235010583384975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029235010583384975 | validation: 0.043192954097034934]
	TIME [epoch: 3.56 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03251918905928765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03251918905928765 | validation: 0.06526783668849415]
	TIME [epoch: 3.56 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0552735603655089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0552735603655089 | validation: 0.10711716615454914]
	TIME [epoch: 3.56 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09020387703515305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09020387703515305 | validation: 0.15451482090438062]
	TIME [epoch: 3.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13516618507864453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13516618507864453 | validation: 0.11123413580557476]
	TIME [epoch: 3.57 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10643483082072877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10643483082072877 | validation: 0.154437191364153]
	TIME [epoch: 3.58 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13839738834320037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13839738834320037 | validation: 0.26371342723659935]
	TIME [epoch: 3.56 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20188027514797566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20188027514797566 | validation: 0.19349517186528442]
	TIME [epoch: 3.57 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1539137263388816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1539137263388816 | validation: 0.07928546261347451]
	TIME [epoch: 3.56 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.092836774855895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.092836774855895 | validation: 0.10561883142515366]
	TIME [epoch: 3.57 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07779366117087591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07779366117087591 | validation: 0.05081017295118406]
	TIME [epoch: 3.57 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0450180330594341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0450180330594341 | validation: 0.05021430234531563]
	TIME [epoch: 3.56 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04212878588175966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04212878588175966 | validation: 0.05914568809435297]
	TIME [epoch: 3.56 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042265889317881104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042265889317881104 | validation: 0.0927229150112663]
	TIME [epoch: 3.59 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06515655106687963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06515655106687963 | validation: 0.10329078875249537]
	TIME [epoch: 3.56 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07634619360175132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07634619360175132 | validation: 0.09751543521304194]
	TIME [epoch: 3.57 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10495099009713935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10495099009713935 | validation: 0.11142020052958022]
	TIME [epoch: 3.57 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11564401331374277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11564401331374277 | validation: 0.08666242921538504]
	TIME [epoch: 3.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0749493615519626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0749493615519626 | validation: 0.056223656042351536]
	TIME [epoch: 3.57 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04262466484118406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04262466484118406 | validation: 0.04733245075058911]
	TIME [epoch: 3.59 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031734360792849664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031734360792849664 | validation: 0.056146767539888655]
	TIME [epoch: 3.56 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04614431198819688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04614431198819688 | validation: 0.09972628130786687]
	TIME [epoch: 3.56 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08489777472864284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08489777472864284 | validation: 0.15156511088251023]
	TIME [epoch: 3.59 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16316712116045445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16316712116045445 | validation: 0.18081583425354794]
	TIME [epoch: 3.59 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15212749016215052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15212749016215052 | validation: 0.13339299666466817]
	TIME [epoch: 3.58 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11973687507219996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11973687507219996 | validation: 0.15116871253678865]
	TIME [epoch: 3.58 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1199152585277839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1199152585277839 | validation: 0.07347796846258049]
	TIME [epoch: 3.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06430602902573238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06430602902573238 | validation: 0.054271251930217757]
	TIME [epoch: 3.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039737797700654456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039737797700654456 | validation: 0.0649748173783334]
	TIME [epoch: 3.56 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05442696217209613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05442696217209613 | validation: 0.07660226583058838]
	TIME [epoch: 3.58 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07840743597595409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07840743597595409 | validation: 0.08841992779579218]
	TIME [epoch: 3.55 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09265866153912121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09265866153912121 | validation: 0.07008356371339339]
	TIME [epoch: 3.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060821427658495505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060821427658495505 | validation: 0.04879537372662368]
	TIME [epoch: 3.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04378846177507516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04378846177507516 | validation: 0.060052357770648546]
	TIME [epoch: 3.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04837596451126747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04837596451126747 | validation: 0.08643884134967023]
	TIME [epoch: 3.59 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0779625215117433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0779625215117433 | validation: 0.1456450287232431]
	TIME [epoch: 3.58 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12716529785632485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12716529785632485 | validation: 0.08833398589522161]
	TIME [epoch: 3.59 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08203173524018077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08203173524018077 | validation: 0.07130228214194279]
	TIME [epoch: 3.62 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059037875647235116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059037875647235116 | validation: 0.042963310486409806]
	TIME [epoch: 3.59 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04960011142932386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04960011142932386 | validation: 0.07098707789987663]
	TIME [epoch: 3.57 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05784473331202898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05784473331202898 | validation: 0.09679935494491598]
	TIME [epoch: 3.59 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0960667571602459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0960667571602459 | validation: 0.13469133196554214]
	TIME [epoch: 3.58 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10588404221212488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10588404221212488 | validation: 0.0962445007257206]
	TIME [epoch: 3.59 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0784297238319354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0784297238319354 | validation: 0.0889322934665537]
	TIME [epoch: 3.59 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08859649131288677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08859649131288677 | validation: 0.08324568072809711]
	TIME [epoch: 3.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08093479968908222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08093479968908222 | validation: 0.05272830843599381]
	TIME [epoch: 3.61 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0444723358112077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0444723358112077 | validation: 0.0475487820094139]
	TIME [epoch: 3.58 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03201144905902755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03201144905902755 | validation: 0.042607937631377026]
	TIME [epoch: 3.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039681936526842945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039681936526842945 | validation: 0.07725591208989281]
	TIME [epoch: 3.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0738384682509986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0738384682509986 | validation: 0.12236838846121141]
	TIME [epoch: 3.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12855958345002894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12855958345002894 | validation: 0.1287493886711674]
	TIME [epoch: 3.59 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10399669365735673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10399669365735673 | validation: 0.10161237838732383]
	TIME [epoch: 3.61 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08018239250203188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08018239250203188 | validation: 0.10706473008021532]
	TIME [epoch: 3.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09880213779625438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09880213779625438 | validation: 0.13822102622036134]
	TIME [epoch: 3.61 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10113255849809942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10113255849809942 | validation: 0.08085137972945755]
	TIME [epoch: 3.58 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06613403052996272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06613403052996272 | validation: 0.05790903808262589]
	TIME [epoch: 3.58 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051128270579293464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051128270579293464 | validation: 0.061573955235269144]
	TIME [epoch: 3.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05398913024315041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05398913024315041 | validation: 0.05882446659088763]
	TIME [epoch: 3.59 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05348123937382623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05348123937382623 | validation: 0.06179037703097615]
	TIME [epoch: 3.59 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06076912385504492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06076912385504492 | validation: 0.12591092868700376]
	TIME [epoch: 3.57 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11945192213080935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11945192213080935 | validation: 0.13968940849249734]
	TIME [epoch: 3.57 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15121619530981978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15121619530981978 | validation: 0.10375745257893461]
	TIME [epoch: 3.61 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08749595981496583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08749595981496583 | validation: 0.09214477345150562]
	TIME [epoch: 3.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09075331390902054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09075331390902054 | validation: 0.059620045500369104]
	TIME [epoch: 3.61 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055949223666515606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055949223666515606 | validation: 0.05260735424142876]
	TIME [epoch: 3.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03988359195202561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03988359195202561 | validation: 0.06704193247257789]
	TIME [epoch: 3.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04685193430523438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04685193430523438 | validation: 0.08285097052540441]
	TIME [epoch: 3.61 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05432459883923768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05432459883923768 | validation: 0.07206504559131859]
	TIME [epoch: 3.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0527274487903942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0527274487903942 | validation: 0.06326662908311097]
	TIME [epoch: 3.61 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04379938595447124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04379938595447124 | validation: 0.04582467306247029]
	TIME [epoch: 3.59 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042124475894500496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042124475894500496 | validation: 0.06350728863339385]
	TIME [epoch: 3.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06220699076719372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06220699076719372 | validation: 0.13897818804431103]
	TIME [epoch: 3.58 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1620919578124049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1620919578124049 | validation: 0.2674711845482244]
	TIME [epoch: 3.59 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22318354537164437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22318354537164437 | validation: 0.13476071326360228]
	TIME [epoch: 3.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14902900365457158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14902900365457158 | validation: 0.0828306732603953]
	TIME [epoch: 3.62 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06977967286404259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06977967286404259 | validation: 0.07087018814224498]
	TIME [epoch: 3.58 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05720275981013865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05720275981013865 | validation: 0.058635695404540424]
	TIME [epoch: 3.62 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05544868449824216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05544868449824216 | validation: 0.06601753801568477]
	TIME [epoch: 3.59 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05882527964304621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05882527964304621 | validation: 0.09482571556823559]
	TIME [epoch: 3.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06732327019924364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06732327019924364 | validation: 0.07108258326119352]
	TIME [epoch: 3.61 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0716209199493296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0716209199493296 | validation: 0.07958653664427404]
	TIME [epoch: 3.61 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07057848869043018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07057848869043018 | validation: 0.0644026016469886]
	TIME [epoch: 3.61 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06890721144569835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06890721144569835 | validation: 0.06396756504501029]
	TIME [epoch: 3.57 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06580021721721366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06580021721721366 | validation: 0.05720695111432122]
	TIME [epoch: 3.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05974569203665119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05974569203665119 | validation: 0.05889058430443264]
	TIME [epoch: 3.57 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060949652369215616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060949652369215616 | validation: 0.08834003666185881]
	TIME [epoch: 3.61 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07621983040705722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07621983040705722 | validation: 0.11050076112442267]
	TIME [epoch: 3.58 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10041135597845355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10041135597845355 | validation: 0.1079291148950544]
	TIME [epoch: 3.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08910927080290687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08910927080290687 | validation: 0.06218242716271776]
	TIME [epoch: 3.59 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172634/states/model_phi1_3a_v_mmd1_735.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1742.466 seconds.
