Args:
Namespace(name='model_phi1_1a_v_kl4', outdir='out/model_training/model_phi1_1a_v_kl4', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1177534651

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.614841458018134		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 10.614841458018134 | validation: 10.480619356805489]
	TIME [epoch: 98.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.97493708388308		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 9.97493708388308 | validation: 9.540043867514768]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.09947759523821		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 9.09947759523821 | validation: 10.11522300926863]
	TIME [epoch: 8.39 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.758628869828971		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 8.758628869828971 | validation: 9.898481270849567]
	TIME [epoch: 8.39 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.01890571937012		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 9.01890571937012 | validation: 8.994831923564497]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.18770646173926		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 8.18770646173926 | validation: 10.338466522874775]
	TIME [epoch: 8.38 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.879886379137112		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 8.879886379137112 | validation: 9.752341757522963]
	TIME [epoch: 8.44 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.347493515872456		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 8.347493515872456 | validation: 8.77817035367693]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.452790905713186		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 8.452790905713186 | validation: 10.616861859368836]
	TIME [epoch: 8.39 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.540302361993179		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 8.540302361993179 | validation: 8.717612925135679]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.389048514649506		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 8.389048514649506 | validation: 9.013155879124822]
	TIME [epoch: 8.42 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.979299372633755		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 7.979299372633755 | validation: 9.404232864812384]
	TIME [epoch: 8.43 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.737294703771489		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 7.737294703771489 | validation: 8.946201469414632]
	TIME [epoch: 8.41 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.120431026367742		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 8.120431026367742 | validation: 8.593160457339176]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.753288809111279		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 7.753288809111279 | validation: 8.61201188777823]
	TIME [epoch: 8.42 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.735829569911341		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 7.735829569911341 | validation: 8.985096074678246]
	TIME [epoch: 8.43 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.79252565245457		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 7.79252565245457 | validation: 8.761402991812826]
	TIME [epoch: 8.43 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.872538969133356		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 7.872538969133356 | validation: 8.371858753992608]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.447763558077333		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 7.447763558077333 | validation: 8.5549513897685]
	TIME [epoch: 8.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.258057597672861		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 7.258057597672861 | validation: 10.034923540404463]
	TIME [epoch: 8.44 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.556455520566987		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 7.556455520566987 | validation: 8.431400988540354]
	TIME [epoch: 8.43 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.298729715559274		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 7.298729715559274 | validation: 8.74939938369452]
	TIME [epoch: 8.43 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.083999067158582		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 7.083999067158582 | validation: 8.189195100473356]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.063297475508833		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 7.063297475508833 | validation: 9.071960742728136]
	TIME [epoch: 8.43 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.223276956002207		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 7.223276956002207 | validation: 7.895712595887769]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.736436027549672		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 6.736436027549672 | validation: 7.839281822736112]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.608762414343699		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 6.608762414343699 | validation: 7.5173103177445295]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.390680464590345		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 6.390680464590345 | validation: 7.5088683156394485]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.463268309531121		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 6.463268309531121 | validation: 7.642590822530897]
	TIME [epoch: 8.43 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.438316855808921		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 6.438316855808921 | validation: 7.224734859902781]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.377176792848678		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 6.377176792848678 | validation: 7.247694117095141]
	TIME [epoch: 8.43 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.217145731309848		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 6.217145731309848 | validation: 7.068845280292537]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163015826652528		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 6.163015826652528 | validation: 7.186602249120951]
	TIME [epoch: 8.45 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046466714187208		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 6.046466714187208 | validation: 7.310924585289065]
	TIME [epoch: 8.45 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.246301351514102		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 6.246301351514102 | validation: 6.947657946204426]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.980835951045285		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 5.980835951045285 | validation: 6.64552074189494]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.778506401270211		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 5.778506401270211 | validation: 6.405418718865676]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7950408876665875		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 5.7950408876665875 | validation: 6.3767898397318925]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7424461675647525		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 5.7424461675647525 | validation: 5.97314722382248]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.323168092840206		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 5.323168092840206 | validation: 5.704075115493772]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.427976444391204		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 5.427976444391204 | validation: 6.1890903170413285]
	TIME [epoch: 8.32 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.455025300122399		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 5.455025300122399 | validation: 5.44907897531304]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939444932994532		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 4.939444932994532 | validation: 5.10263381375699]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.353764200737647		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 5.353764200737647 | validation: 5.016450597543654]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.729630392374992		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 4.729630392374992 | validation: 4.644286219669407]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.263738827607502		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 4.263738827607502 | validation: 5.2557180972495825]
	TIME [epoch: 8.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713611135238398		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 4.713611135238398 | validation: 4.7702618780052335]
	TIME [epoch: 8.27 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.381328053948383		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 4.381328053948383 | validation: 4.642744538612121]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.313099064543998		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 4.313099064543998 | validation: 4.452318003397565]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.117453443533506		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 4.117453443533506 | validation: 4.3732489448304115]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.172278460365821		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 4.172278460365821 | validation: 3.8750702059369595]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.466461990986238		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 3.466461990986238 | validation: 4.431956133832479]
	TIME [epoch: 8.28 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.181874747456283		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 4.181874747456283 | validation: 3.9138735933533115]
	TIME [epoch: 8.28 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4491153398263394		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 3.4491153398263394 | validation: 3.2546060108990282]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.152175151306		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 4.152175151306 | validation: 4.415899958212912]
	TIME [epoch: 8.32 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.534734888493316		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 3.534734888493316 | validation: 6.541527368738717]
	TIME [epoch: 8.27 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.292017064399697		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 4.292017064399697 | validation: 3.617231374652113]
	TIME [epoch: 8.27 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9952471635560007		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 2.9952471635560007 | validation: 4.1012841293907645]
	TIME [epoch: 8.28 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1777397284575617		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 3.1777397284575617 | validation: 4.5033892408353084]
	TIME [epoch: 8.27 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.147813970176521		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 4.147813970176521 | validation: 3.6363541333366927]
	TIME [epoch: 8.31 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3728568821506317		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 3.3728568821506317 | validation: 3.5700620300088817]
	TIME [epoch: 8.29 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1120813653530837		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 3.1120813653530837 | validation: 3.539633859596499]
	TIME [epoch: 8.27 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.157387729788597		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 3.157387729788597 | validation: 3.018276155433586]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0252000695024397		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 3.0252000695024397 | validation: 2.4321384569304625]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.788119404734453		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 2.788119404734453 | validation: 2.4960206685214374]
	TIME [epoch: 8.29 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0003788147376		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 3.0003788147376 | validation: 3.406220016016017]
	TIME [epoch: 8.33 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.042292147861647		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 3.042292147861647 | validation: 2.8180925447864325]
	TIME [epoch: 8.27 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9193983576193245		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 2.9193983576193245 | validation: 3.138776369465446]
	TIME [epoch: 8.28 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8527654579607797		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 2.8527654579607797 | validation: 3.041041233349286]
	TIME [epoch: 8.28 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8846643278455923		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 2.8846643278455923 | validation: 3.0899770080373865]
	TIME [epoch: 8.27 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6223695268323914		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 2.6223695268323914 | validation: 4.247479069298443]
	TIME [epoch: 8.31 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7323095696664654		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 2.7323095696664654 | validation: 3.141218273577927]
	TIME [epoch: 8.28 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5628791685226497		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 2.5628791685226497 | validation: 3.5617156618111263]
	TIME [epoch: 8.27 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.652839994793193		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 2.652839994793193 | validation: 2.8836984032002206]
	TIME [epoch: 8.28 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6088925754049415		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 2.6088925754049415 | validation: 3.447758057340228]
	TIME [epoch: 8.28 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6084219286847548		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 2.6084219286847548 | validation: 3.7911102375358396]
	TIME [epoch: 8.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.722220267114854		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 2.722220267114854 | validation: 2.624283513565514]
	TIME [epoch: 8.45 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5819330781850907		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 2.5819330781850907 | validation: 2.4003283389452066]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365672241422327		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 2.365672241422327 | validation: 2.2304139522456303]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.425514992582468		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 2.425514992582468 | validation: 2.499059681866888]
	TIME [epoch: 8.37 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.548936028740827		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 2.548936028740827 | validation: 2.1796432036042104]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5352067931710587		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 2.5352067931710587 | validation: 3.0745211242458454]
	TIME [epoch: 8.44 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5584459991117425		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 2.5584459991117425 | validation: 2.242455842154553]
	TIME [epoch: 8.41 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.18014448790376		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 2.18014448790376 | validation: 3.0301864435760364]
	TIME [epoch: 8.38 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.237367485321512		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 2.237367485321512 | validation: 2.7561072730442078]
	TIME [epoch: 8.38 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.62404670137582		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 2.62404670137582 | validation: 2.3287229821331836]
	TIME [epoch: 8.38 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2999366242057997		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 2.2999366242057997 | validation: 2.178949272287906]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1272577259076697		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 2.1272577259076697 | validation: 2.150331450467365]
	TIME [epoch: 8.48 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096082418502561		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 2.096082418502561 | validation: 3.119775451585724]
	TIME [epoch: 8.43 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5016748235613453		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 2.5016748235613453 | validation: 2.1000962390807434]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253696934587753		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 2.253696934587753 | validation: 2.541792661105398]
	TIME [epoch: 8.42 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.210005960414998		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 2.210005960414998 | validation: 2.698079016497436]
	TIME [epoch: 8.43 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091923753191262		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 2.091923753191262 | validation: 2.224139792661546]
	TIME [epoch: 8.46 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9169978690566962		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 1.9169978690566962 | validation: 2.354590446384625]
	TIME [epoch: 8.41 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5374702495488286		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 3.5374702495488286 | validation: 3.398967019244151]
	TIME [epoch: 8.42 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6022369543207926		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 2.6022369543207926 | validation: 2.5116259450063314]
	TIME [epoch: 8.42 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0504931999721334		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 2.0504931999721334 | validation: 2.1477925347574396]
	TIME [epoch: 8.43 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8566875336237953		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 1.8566875336237953 | validation: 2.741948091671241]
	TIME [epoch: 8.46 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.185281649633425		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 2.185281649633425 | validation: 2.5643856807939156]
	TIME [epoch: 8.44 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.201564546761497		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 2.201564546761497 | validation: 1.7780339496994197]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9746237988434485		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 1.9746237988434485 | validation: 1.7107313121287777]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8321008449100415		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 1.8321008449100415 | validation: 1.8981552624875766]
	TIME [epoch: 8.41 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074328785675086		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 2.074328785675086 | validation: 3.1849169568256155]
	TIME [epoch: 8.41 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.419117320942976		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 2.419117320942976 | validation: 2.0686844515061926]
	TIME [epoch: 8.44 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133617735669802		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 2.133617735669802 | validation: 2.3406304176917647]
	TIME [epoch: 8.42 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9048197827188982		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 1.9048197827188982 | validation: 2.969394760851599]
	TIME [epoch: 8.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0417608470785398		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 2.0417608470785398 | validation: 1.883721566951996]
	TIME [epoch: 8.41 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8128465838399723		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 1.8128465838399723 | validation: 2.394070413149724]
	TIME [epoch: 8.41 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.935680329474221		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 1.935680329474221 | validation: 1.949938155365893]
	TIME [epoch: 8.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2544501167124915		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 2.2544501167124915 | validation: 1.717498498500816]
	TIME [epoch: 8.43 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.725606692587308		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 1.725606692587308 | validation: 2.3476361554163505]
	TIME [epoch: 8.42 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.967791415749074		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 1.967791415749074 | validation: 1.9231058231487836]
	TIME [epoch: 8.43 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0009204459345		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 2.0009204459345 | validation: 1.9626742128231793]
	TIME [epoch: 8.42 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8196442703083524		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 1.8196442703083524 | validation: 2.5262357551240777]
	TIME [epoch: 8.41 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8025384202867532		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 1.8025384202867532 | validation: 2.7718556122641336]
	TIME [epoch: 8.43 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0589906264094964		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 2.0589906264094964 | validation: 2.4167684403506304]
	TIME [epoch: 8.33 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8295275804723026		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 1.8295275804723026 | validation: 2.525241077504053]
	TIME [epoch: 8.29 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8975184484120828		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 1.8975184484120828 | validation: 2.1909292865678087]
	TIME [epoch: 8.31 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8015277889012613		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 1.8015277889012613 | validation: 2.0758755263612207]
	TIME [epoch: 8.32 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.765903580557135		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 1.765903580557135 | validation: 2.151608101314035]
	TIME [epoch: 8.34 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.817056733669278		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 1.817056733669278 | validation: 2.2849565293700724]
	TIME [epoch: 8.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8854804947539203		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 1.8854804947539203 | validation: 1.9453008942800492]
	TIME [epoch: 8.28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9368506521918518		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 1.9368506521918518 | validation: 1.8650996746092898]
	TIME [epoch: 8.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6861583426908417		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 1.6861583426908417 | validation: 2.1424107299161426]
	TIME [epoch: 8.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320456617441344		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 1.7320456617441344 | validation: 1.9279853255399828]
	TIME [epoch: 8.31 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6005681738668456		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 1.6005681738668456 | validation: 2.5274647321438524]
	TIME [epoch: 8.32 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6774209094540586		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 1.6774209094540586 | validation: 1.8759719223523688]
	TIME [epoch: 8.28 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.688842928544803		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 1.688842928544803 | validation: 1.6919155080973702]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.663228227422228		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 1.663228227422228 | validation: 1.7842547304146161]
	TIME [epoch: 8.27 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344203157822546		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 1.7344203157822546 | validation: 1.639187009661227]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6903660288115887		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 1.6903660288115887 | validation: 1.6115960449062792]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7216726116866319		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 1.7216726116866319 | validation: 2.3263950257173507]
	TIME [epoch: 8.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8998205570820204		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 1.8998205570820204 | validation: 2.1925230903912807]
	TIME [epoch: 8.28 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6794752871249377		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 1.6794752871249377 | validation: 2.2246063858750693]
	TIME [epoch: 8.27 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6711945534970007		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 1.6711945534970007 | validation: 1.8669451730282363]
	TIME [epoch: 8.27 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6930887231230294		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 1.6930887231230294 | validation: 1.4442992002203765]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4406179710629976		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 1.4406179710629976 | validation: 2.1482670109497155]
	TIME [epoch: 8.32 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7097315536511413		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 1.7097315536511413 | validation: 1.437122536662795]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4805688354708046		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 1.4805688354708046 | validation: 1.693097657263969]
	TIME [epoch: 8.28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.852458678731994		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 1.852458678731994 | validation: 1.6464978322346338]
	TIME [epoch: 8.27 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6427384505426024		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 1.6427384505426024 | validation: 1.9529050212367336]
	TIME [epoch: 8.27 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8616197508843153		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 1.8616197508843153 | validation: 1.672187098778396]
	TIME [epoch: 8.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5238136442299872		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 1.5238136442299872 | validation: 1.6116231769004796]
	TIME [epoch: 8.29 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266266064654076		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 1.266266064654076 | validation: 1.130786816494064]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7049368574213222		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 1.7049368574213222 | validation: 2.038782552856099]
	TIME [epoch: 8.27 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5020616028318534		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 1.5020616028318534 | validation: 1.417390449127753]
	TIME [epoch: 8.26 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7114875479138048		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 1.7114875479138048 | validation: 1.5937978593234212]
	TIME [epoch: 8.27 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4335682970945354		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 1.4335682970945354 | validation: 1.2694946316253373]
	TIME [epoch: 8.31 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6934011337249044		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 1.6934011337249044 | validation: 1.5046930600204176]
	TIME [epoch: 8.27 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4060336811617808		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 1.4060336811617808 | validation: 1.8279362492609252]
	TIME [epoch: 8.26 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5750133969371534		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 1.5750133969371534 | validation: 1.2682669148455452]
	TIME [epoch: 8.27 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1693731953619662		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 1.1693731953619662 | validation: 1.3377523944614684]
	TIME [epoch: 8.27 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.596931577149418		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 1.596931577149418 | validation: 1.8636086525357412]
	TIME [epoch: 8.29 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4944929830066336		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 1.4944929830066336 | validation: 1.452784021814581]
	TIME [epoch: 8.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4538937890516612		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 1.4538937890516612 | validation: 1.8547061566873424]
	TIME [epoch: 8.27 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5377966855823746		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 1.5377966855823746 | validation: 1.2406368677385287]
	TIME [epoch: 8.27 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.540380415322974		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 1.540380415322974 | validation: 1.2427885201349986]
	TIME [epoch: 8.27 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.93911863361467		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 1.93911863361467 | validation: 1.9698642749421016]
	TIME [epoch: 8.27 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48965540491521		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 1.48965540491521 | validation: 1.480702325838257]
	TIME [epoch: 8.31 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4534849714820466		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 1.4534849714820466 | validation: 1.8876308392919776]
	TIME [epoch: 8.27 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4124806339802218		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 1.4124806339802218 | validation: 2.001667611830904]
	TIME [epoch: 8.27 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6551194266338385		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 1.6551194266338385 | validation: 1.2721731646070977]
	TIME [epoch: 8.27 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3285325765583818		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 1.3285325765583818 | validation: 1.6642532320040102]
	TIME [epoch: 8.27 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4226896083749225		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 1.4226896083749225 | validation: 1.291081508244952]
	TIME [epoch: 8.28 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4255729911941208		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 1.4255729911941208 | validation: 1.8068606113201446]
	TIME [epoch: 8.32 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6775845155204174		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 1.6775845155204174 | validation: 1.2032185171223313]
	TIME [epoch: 8.27 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2159513757547318		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 1.2159513757547318 | validation: 1.6155775237129457]
	TIME [epoch: 8.27 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5441445023762335		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 1.5441445023762335 | validation: 1.7296378414080933]
	TIME [epoch: 8.27 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.532476958756935		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 1.532476958756935 | validation: 1.5419842748301522]
	TIME [epoch: 8.27 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.508263882999751		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 1.508263882999751 | validation: 1.5487923726955322]
	TIME [epoch: 8.31 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3567074860033481		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 1.3567074860033481 | validation: 1.7003572935874278]
	TIME [epoch: 8.28 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5131815557375634		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 1.5131815557375634 | validation: 1.2864177827493468]
	TIME [epoch: 8.27 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112019024164003		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 1.3112019024164003 | validation: 1.341982960027198]
	TIME [epoch: 8.27 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.454779112622138		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 1.454779112622138 | validation: 1.1600840675124882]
	TIME [epoch: 8.26 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.428035916204516		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 1.428035916204516 | validation: 1.2523121012011182]
	TIME [epoch: 8.27 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2863838063195128		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 1.2863838063195128 | validation: 1.4346893339866695]
	TIME [epoch: 8.31 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2685961692474153		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 1.2685961692474153 | validation: 0.9723885539254982]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.309447997035316		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 1.309447997035316 | validation: 1.6204603144932683]
	TIME [epoch: 8.27 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.429874445263526		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 1.429874445263526 | validation: 1.453521262296174]
	TIME [epoch: 8.26 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436298959387023		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 1.436298959387023 | validation: 1.5269507794796577]
	TIME [epoch: 8.26 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3545723967668597		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 1.3545723967668597 | validation: 1.6667435159150634]
	TIME [epoch: 8.29 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.284786322880374		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 1.284786322880374 | validation: 1.490157506640992]
	TIME [epoch: 8.27 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4961300557183794		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 1.4961300557183794 | validation: 1.259577049527441]
	TIME [epoch: 8.27 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3620799951742144		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 1.3620799951742144 | validation: 1.61980514538804]
	TIME [epoch: 8.26 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3326753028271514		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 1.3326753028271514 | validation: 1.680661683843096]
	TIME [epoch: 8.26 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3527165548336293		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 1.3527165548336293 | validation: 1.4190325684224128]
	TIME [epoch: 8.26 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3959398184361445		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 1.3959398184361445 | validation: 1.244924054682253]
	TIME [epoch: 8.31 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2313774744530885		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 1.2313774744530885 | validation: 1.3267632793316546]
	TIME [epoch: 8.26 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1541368432499475		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 1.1541368432499475 | validation: 1.9743923797273388]
	TIME [epoch: 8.26 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.469938921259416		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 1.469938921259416 | validation: 1.4975640440086297]
	TIME [epoch: 8.27 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2947236122153165		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 1.2947236122153165 | validation: 1.6730719859983632]
	TIME [epoch: 8.26 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.312691075761623		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 1.312691075761623 | validation: 1.1272849443811006]
	TIME [epoch: 8.28 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3084857993955483		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 1.3084857993955483 | validation: 1.3750624999861443]
	TIME [epoch: 8.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2892593074494632		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 1.2892593074494632 | validation: 2.411308412737716]
	TIME [epoch: 8.27 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6635980103517394		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 1.6635980103517394 | validation: 1.1834906239370255]
	TIME [epoch: 8.26 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3343230771428782		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 1.3343230771428782 | validation: 1.126364415394471]
	TIME [epoch: 8.26 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730154029143055		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 1.2730154029143055 | validation: 1.982832766770223]
	TIME [epoch: 8.27 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4270336016862584		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 1.4270336016862584 | validation: 1.255486469229988]
	TIME [epoch: 8.31 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.439745585009625		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 1.439745585009625 | validation: 1.8020118611806353]
	TIME [epoch: 8.27 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438239099468308		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 1.438239099468308 | validation: 1.0276893610553794]
	TIME [epoch: 8.26 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2040186267994126		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 1.2040186267994126 | validation: 1.6292555049000819]
	TIME [epoch: 8.27 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386387510550814		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 1.386387510550814 | validation: 1.6710091502838011]
	TIME [epoch: 8.27 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228172489131648		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 1.228172489131648 | validation: 1.1796097976659836]
	TIME [epoch: 8.27 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174267800487492		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 1.174267800487492 | validation: 1.0105756620582191]
	TIME [epoch: 8.32 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359634728815285		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 1.359634728815285 | validation: 1.3483579988398375]
	TIME [epoch: 8.27 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227476474608526		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 1.227476474608526 | validation: 1.1507985855054192]
	TIME [epoch: 8.26 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2710619585254004		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 1.2710619585254004 | validation: 1.4925589821412406]
	TIME [epoch: 8.26 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3378998758765772		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 1.3378998758765772 | validation: 1.8540256379606235]
	TIME [epoch: 8.27 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3241284835516574		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 1.3241284835516574 | validation: 1.4107172958866725]
	TIME [epoch: 8.32 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3110346376128992		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 1.3110346376128992 | validation: 1.0388834826092732]
	TIME [epoch: 8.28 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1164543321707168		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 1.1164543321707168 | validation: 1.122146704411017]
	TIME [epoch: 8.28 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1574960881834662		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 1.1574960881834662 | validation: 1.5216973567023198]
	TIME [epoch: 8.27 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2817647454157877		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 1.2817647454157877 | validation: 1.376986241858221]
	TIME [epoch: 8.27 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2513989524512887		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 1.2513989524512887 | validation: 1.5222294284187337]
	TIME [epoch: 8.27 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.216824632131713		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 1.216824632131713 | validation: 0.9616488254702205]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3298690574304386		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 1.3298690574304386 | validation: 0.8645078324577515]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1216822322470705		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 1.1216822322470705 | validation: 0.9104009486382385]
	TIME [epoch: 8.28 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2403653899658567		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 1.2403653899658567 | validation: 2.02032198815082]
	TIME [epoch: 8.27 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2772971779554185		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 1.2772971779554185 | validation: 1.1943835559345626]
	TIME [epoch: 8.28 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371340976838121		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 1.371340976838121 | validation: 1.4945840635291323]
	TIME [epoch: 8.31 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2417483160038103		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 1.2417483160038103 | validation: 1.1746419190352113]
	TIME [epoch: 8.29 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1639128171482995		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 1.1639128171482995 | validation: 0.8327955299555356]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0118178671845655		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 1.0118178671845655 | validation: 1.2364609753080877]
	TIME [epoch: 8.27 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3342706665568034		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 1.3342706665568034 | validation: 1.2820164981137712]
	TIME [epoch: 8.26 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067176522622914		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 1.067176522622914 | validation: 1.676097451666764]
	TIME [epoch: 8.27 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1255366271063583		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 1.1255366271063583 | validation: 2.106229843327415]
	TIME [epoch: 8.32 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4134638938590858		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 1.4134638938590858 | validation: 1.0085519348457634]
	TIME [epoch: 8.27 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1768527742914163		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 1.1768527742914163 | validation: 1.2707773927552837]
	TIME [epoch: 8.27 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1231641339767087		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 1.1231641339767087 | validation: 1.428348903504935]
	TIME [epoch: 8.27 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2027853274842024		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 1.2027853274842024 | validation: 1.0181926431092483]
	TIME [epoch: 8.27 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1203123681586915		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 1.1203123681586915 | validation: 1.058537731577077]
	TIME [epoch: 8.31 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639591599907356		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 1.0639591599907356 | validation: 0.9217923501239009]
	TIME [epoch: 8.28 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1903981975273603		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 1.1903981975273603 | validation: 0.8755568845684517]
	TIME [epoch: 8.27 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3037235981143267		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 1.3037235981143267 | validation: 0.9224600073887796]
	TIME [epoch: 8.27 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3628982600120696		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 1.3628982600120696 | validation: 1.6442465853127697]
	TIME [epoch: 8.26 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2604736405263517		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 1.2604736405263517 | validation: 1.112712899453918]
	TIME [epoch: 8.26 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1218142990453428		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 1.1218142990453428 | validation: 1.2497654407708514]
	TIME [epoch: 8.32 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1876526763585797		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 1.1876526763585797 | validation: 1.2424867828850976]
	TIME [epoch: 8.27 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1307328859674501		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 1.1307328859674501 | validation: 1.1585291214347313]
	TIME [epoch: 8.27 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1192133728773612		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 1.1192133728773612 | validation: 1.3583265693207232]
	TIME [epoch: 8.27 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2614907686591867		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 1.2614907686591867 | validation: 1.0680970810939567]
	TIME [epoch: 8.27 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.278846924200677		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 1.278846924200677 | validation: 0.7273581442697497]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237067651929436		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 1.237067651929436 | validation: 1.36976393897493]
	TIME [epoch: 8.31 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2769212556774048		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 1.2769212556774048 | validation: 1.18755173458749]
	TIME [epoch: 8.27 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154140092833622		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 1.154140092833622 | validation: 0.7604376364404983]
	TIME [epoch: 8.26 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0136238253265268		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 1.0136238253265268 | validation: 1.5867845295536298]
	TIME [epoch: 8.26 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353148436149523		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 1.1353148436149523 | validation: 1.4849109863000332]
	TIME [epoch: 8.26 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4423176975131653		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 1.4423176975131653 | validation: 1.0844633862096593]
	TIME [epoch: 8.32 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2310801192846024		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 1.2310801192846024 | validation: 1.0010755485734482]
	TIME [epoch: 8.28 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1767764483065282		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 1.1767764483065282 | validation: 1.1526761661133405]
	TIME [epoch: 8.27 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0852822886796751		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 1.0852822886796751 | validation: 1.2418695282380492]
	TIME [epoch: 8.28 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2066339450518802		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 1.2066339450518802 | validation: 0.9507296047688638]
	TIME [epoch: 8.28 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647976995076866		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.9647976995076866 | validation: 1.187800546505723]
	TIME [epoch: 8.28 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1039344030594753		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 1.1039344030594753 | validation: 1.0370624472185708]
	TIME [epoch: 8.32 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037795601693354		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 1.1037795601693354 | validation: 2.1111714542210507]
	TIME [epoch: 8.28 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3565049228590522		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 1.3565049228590522 | validation: 1.1658221702574747]
	TIME [epoch: 8.27 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568215183059987		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 1.1568215183059987 | validation: 1.3059501810922491]
	TIME [epoch: 8.26 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2275951393767868		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.2275951393767868 | validation: 1.3165405652731839]
	TIME [epoch: 8.27 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0523097375803063		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 1.0523097375803063 | validation: 1.0504552360367896]
	TIME [epoch: 8.31 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0759687621245257		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 1.0759687621245257 | validation: 0.9869061177010989]
	TIME [epoch: 8.29 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0482651291390122		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 1.0482651291390122 | validation: 1.5294138188833206]
	TIME [epoch: 8.27 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2168662171316056		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 1.2168662171316056 | validation: 1.8253847088650925]
	TIME [epoch: 8.28 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2794047930539088		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 1.2794047930539088 | validation: 1.0905024412547966]
	TIME [epoch: 8.27 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3617849249412346		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 1.3617849249412346 | validation: 1.904718457684413]
	TIME [epoch: 8.26 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2221001920602164		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 1.2221001920602164 | validation: 1.3366080107710276]
	TIME [epoch: 8.32 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0826263714863817		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 1.0826263714863817 | validation: 1.1752046763912212]
	TIME [epoch: 8.28 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146829070343277		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 1.146829070343277 | validation: 1.197180969055338]
	TIME [epoch: 8.27 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1562866531530192		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 1.1562866531530192 | validation: 1.4495221738594202]
	TIME [epoch: 8.27 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1452734399658477		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 1.1452734399658477 | validation: 0.8573264871714394]
	TIME [epoch: 8.27 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783946400529294		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.9783946400529294 | validation: 1.1265951958889007]
	TIME [epoch: 8.29 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1697071142225028		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 1.1697071142225028 | validation: 1.1209264286365497]
	TIME [epoch: 8.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.089995261172725		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 1.089995261172725 | validation: 2.830292653523456]
	TIME [epoch: 8.26 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5033083404028296		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 1.5033083404028296 | validation: 1.1219899475114317]
	TIME [epoch: 8.28 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1915798785635234		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 1.1915798785635234 | validation: 1.0694137656437883]
	TIME [epoch: 8.27 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093330973869757		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 1.093330973869757 | validation: 1.0131745281149778]
	TIME [epoch: 8.27 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0739172937945998		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 1.0739172937945998 | validation: 1.0377614534848272]
	TIME [epoch: 8.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0357962842306379		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 1.0357962842306379 | validation: 1.1329747805521948]
	TIME [epoch: 8.28 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.19615548110161		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 1.19615548110161 | validation: 1.3037264981655112]
	TIME [epoch: 8.27 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0067618423014377		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 1.0067618423014377 | validation: 0.7302710709451119]
	TIME [epoch: 8.27 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301743461820108		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 1.1301743461820108 | validation: 0.9777158713160012]
	TIME [epoch: 8.27 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9586409911806351		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.9586409911806351 | validation: 1.456525896664736]
	TIME [epoch: 8.27 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1875999926377794		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 1.1875999926377794 | validation: 0.8979021466791239]
	TIME [epoch: 8.31 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026127390734014		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 1.0026127390734014 | validation: 0.9851606984502197]
	TIME [epoch: 8.27 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620604611454476		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 1.0620604611454476 | validation: 0.9001122658840572]
	TIME [epoch: 8.27 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044557045857624		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 1.044557045857624 | validation: 1.1737464808909297]
	TIME [epoch: 8.26 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901301824024942		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.9901301824024942 | validation: 1.2221915801757075]
	TIME [epoch: 8.26 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0401560947248416		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 1.0401560947248416 | validation: 0.9104776292255086]
	TIME [epoch: 8.31 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0868683044518859		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 1.0868683044518859 | validation: 1.2633314370910806]
	TIME [epoch: 8.28 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0037468786142576		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 1.0037468786142576 | validation: 0.836290828982218]
	TIME [epoch: 8.26 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032873411349372		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 1.032873411349372 | validation: 1.3984265748631228]
	TIME [epoch: 8.26 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148869453932547		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 1.0148869453932547 | validation: 1.4962910745863622]
	TIME [epoch: 8.27 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420089268878844		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 1.1420089268878844 | validation: 0.9889839170911462]
	TIME [epoch: 8.26 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1203765816910385		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 1.1203765816910385 | validation: 0.9631290995202888]
	TIME [epoch: 8.31 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9997015905262692		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.9997015905262692 | validation: 2.0141281548903436]
	TIME [epoch: 8.28 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0471453801184467		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 1.0471453801184467 | validation: 1.1874082153756886]
	TIME [epoch: 8.28 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028309966908486		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 1.028309966908486 | validation: 1.0718977183913174]
	TIME [epoch: 8.27 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902387685819257		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 1.0902387685819257 | validation: 1.0784351783695045]
	TIME [epoch: 8.27 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.938980672535086		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.938980672535086 | validation: 0.838281348955059]
	TIME [epoch: 8.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9699636984351828		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.9699636984351828 | validation: 1.1548568232141831]
	TIME [epoch: 8.31 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1476642678821856		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 1.1476642678821856 | validation: 0.9902825050417663]
	TIME [epoch: 8.27 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0775878239726717		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 1.0775878239726717 | validation: 0.8192256389159174]
	TIME [epoch: 8.28 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.891274555044258		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.891274555044258 | validation: 1.1285796584811698]
	TIME [epoch: 8.27 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867285436075866		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 1.0867285436075866 | validation: 1.087980773776564]
	TIME [epoch: 8.27 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030502764684575		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 1.030502764684575 | validation: 1.1538850699952226]
	TIME [epoch: 8.31 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1111233518345462		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 1.1111233518345462 | validation: 1.2117643082798784]
	TIME [epoch: 8.28 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0396304038142214		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 1.0396304038142214 | validation: 1.055443950984635]
	TIME [epoch: 8.27 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9987799254039221		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.9987799254039221 | validation: 1.305790958953725]
	TIME [epoch: 8.26 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0454382272438523		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 1.0454382272438523 | validation: 0.883553793408296]
	TIME [epoch: 8.26 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9902827992299134		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.9902827992299134 | validation: 1.3576723824705124]
	TIME [epoch: 8.28 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0136930937031245		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 1.0136930937031245 | validation: 0.875333133808113]
	TIME [epoch: 8.31 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9864593618136008		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.9864593618136008 | validation: 1.0852457138828526]
	TIME [epoch: 8.27 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100159417975549		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 1.100159417975549 | validation: 1.0542193271803642]
	TIME [epoch: 8.27 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0523649511609499		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 1.0523649511609499 | validation: 1.125175728854941]
	TIME [epoch: 8.27 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9848601644727266		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.9848601644727266 | validation: 1.0886751671484505]
	TIME [epoch: 8.26 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9868693021153261		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.9868693021153261 | validation: 0.9735953804824371]
	TIME [epoch: 8.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044623504039595		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 1.044623504039595 | validation: 0.8936396488304392]
	TIME [epoch: 8.28 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9766318145600017		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.9766318145600017 | validation: 1.0235383579516624]
	TIME [epoch: 8.27 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0017270338246234		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 1.0017270338246234 | validation: 0.6855802158113714]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9458339387909398		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.9458339387909398 | validation: 0.9285204776066369]
	TIME [epoch: 8.26 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0376797074908544		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 1.0376797074908544 | validation: 0.7936714434312693]
	TIME [epoch: 8.27 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0110433593398893		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 1.0110433593398893 | validation: 0.9708397129160158]
	TIME [epoch: 8.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0201665447760297		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 1.0201665447760297 | validation: 1.1869095776269818]
	TIME [epoch: 8.26 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1025993469459994		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 1.1025993469459994 | validation: 0.9721019247608811]
	TIME [epoch: 8.26 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732046978972724		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.8732046978972724 | validation: 0.8848497209512216]
	TIME [epoch: 8.26 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0158402172237555		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 1.0158402172237555 | validation: 1.0199519216944017]
	TIME [epoch: 8.26 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608629057127609		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.9608629057127609 | validation: 1.2666790936422012]
	TIME [epoch: 8.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0457946627105896		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 1.0457946627105896 | validation: 1.050615012353244]
	TIME [epoch: 8.28 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8528022463123532		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.8528022463123532 | validation: 1.2145665589364882]
	TIME [epoch: 8.26 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03962037611164		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 1.03962037611164 | validation: 1.0295385309356866]
	TIME [epoch: 8.26 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014098007680802		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 1.014098007680802 | validation: 1.3663474628380126]
	TIME [epoch: 8.26 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0734370616679876		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 1.0734370616679876 | validation: 0.7452885219062315]
	TIME [epoch: 8.27 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283724418394067		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 1.0283724418394067 | validation: 0.7590274164709794]
	TIME [epoch: 8.31 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9747368803397609		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.9747368803397609 | validation: 0.7177033950866674]
	TIME [epoch: 8.27 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9363633683553416		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.9363633683553416 | validation: 1.0534679985910476]
	TIME [epoch: 8.26 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9697958445219801		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.9697958445219801 | validation: 1.2096214169277026]
	TIME [epoch: 8.26 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9997168271895611		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.9997168271895611 | validation: 0.7216923675170488]
	TIME [epoch: 8.25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8874582396768385		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.8874582396768385 | validation: 1.0367642589907946]
	TIME [epoch: 8.27 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640489030000633		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 1.0640489030000633 | validation: 0.8737370067208374]
	TIME [epoch: 8.31 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316013446110488		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 1.0316013446110488 | validation: 1.4939005314947449]
	TIME [epoch: 8.27 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0192748046885827		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 1.0192748046885827 | validation: 0.8569540924048784]
	TIME [epoch: 8.27 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9823895571353207		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.9823895571353207 | validation: 0.9395657105954255]
	TIME [epoch: 8.27 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005829143794689		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 1.005829143794689 | validation: 0.8077076865872288]
	TIME [epoch: 8.27 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8676015679261682		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.8676015679261682 | validation: 0.8887607585637021]
	TIME [epoch: 8.31 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0886483635442452		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 1.0886483635442452 | validation: 1.2219707054543658]
	TIME [epoch: 8.27 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9944701280590327		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.9944701280590327 | validation: 0.983059860753036]
	TIME [epoch: 8.27 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.429712995533212		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 1.429712995533212 | validation: 1.423999207412257]
	TIME [epoch: 8.27 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624200783219058		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 1.0624200783219058 | validation: 1.0033518946795383]
	TIME [epoch: 8.26 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759798852979824		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.9759798852979824 | validation: 0.9281384747558156]
	TIME [epoch: 8.27 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.879628338693121		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.879628338693121 | validation: 0.870298814594463]
	TIME [epoch: 8.31 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9247406020213049		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.9247406020213049 | validation: 1.0115812089388616]
	TIME [epoch: 8.27 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8311192805582963		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.8311192805582963 | validation: 1.1174321705175594]
	TIME [epoch: 8.27 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563095085221021		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 1.0563095085221021 | validation: 0.8552129087073702]
	TIME [epoch: 8.27 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.933948526909496		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.933948526909496 | validation: 0.85750732803141]
	TIME [epoch: 8.26 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9955215099987371		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.9955215099987371 | validation: 1.0445440349763335]
	TIME [epoch: 8.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9991017002767282		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.9991017002767282 | validation: 1.5812831549243593]
	TIME [epoch: 8.28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9800749825876857		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.9800749825876857 | validation: 0.8865959221102322]
	TIME [epoch: 8.27 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9313742787209781		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.9313742787209781 | validation: 0.9381409821088188]
	TIME [epoch: 8.26 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9465500976683939		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.9465500976683939 | validation: 0.7800466380575962]
	TIME [epoch: 8.27 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872763758289139		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.872763758289139 | validation: 0.7535465326042107]
	TIME [epoch: 8.26 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0147794373833006		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 1.0147794373833006 | validation: 0.823899101610664]
	TIME [epoch: 8.32 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9428096833249802		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.9428096833249802 | validation: 1.238179946690944]
	TIME [epoch: 8.26 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760107456994399		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 1.0760107456994399 | validation: 0.9476154828372122]
	TIME [epoch: 8.27 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0297165335029206		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 1.0297165335029206 | validation: 0.7811475758598729]
	TIME [epoch: 8.27 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8989594770696212		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.8989594770696212 | validation: 1.0945530956034248]
	TIME [epoch: 8.26 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9655001050078262		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.9655001050078262 | validation: 0.9582348811680879]
	TIME [epoch: 8.28 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878242447994298		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.9878242447994298 | validation: 1.0118734192028538]
	TIME [epoch: 8.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0085027437190668		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 1.0085027437190668 | validation: 0.7505265232053664]
	TIME [epoch: 8.27 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0348166304302322		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 1.0348166304302322 | validation: 1.3347812270919677]
	TIME [epoch: 8.26 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9414747038019785		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.9414747038019785 | validation: 0.8346469869952229]
	TIME [epoch: 8.26 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0442177458042305		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 1.0442177458042305 | validation: 0.9444507801802191]
	TIME [epoch: 8.26 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9930210738063356		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.9930210738063356 | validation: 0.8255310734270229]
	TIME [epoch: 8.32 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0027164489385871		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 1.0027164489385871 | validation: 1.652372465883953]
	TIME [epoch: 8.27 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004802818623717		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 1.004802818623717 | validation: 0.817576636697937]
	TIME [epoch: 8.26 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9792005006924889		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.9792005006924889 | validation: 0.8648571607163187]
	TIME [epoch: 8.27 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8929569874621903		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.8929569874621903 | validation: 0.8309169711106459]
	TIME [epoch: 8.26 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064559042967757		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 1.064559042967757 | validation: 0.9555818461167345]
	TIME [epoch: 8.27 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9612085439962411		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.9612085439962411 | validation: 1.275342251020234]
	TIME [epoch: 8.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010801317881783		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 1.010801317881783 | validation: 0.9576067351270965]
	TIME [epoch: 8.27 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0987715924562789		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 1.0987715924562789 | validation: 0.8638971226858879]
	TIME [epoch: 8.27 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9705976242068052		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.9705976242068052 | validation: 1.112174291734344]
	TIME [epoch: 8.27 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2625396067133572		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 1.2625396067133572 | validation: 0.9159166196026283]
	TIME [epoch: 8.27 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0452829555685008		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 1.0452829555685008 | validation: 0.9982484218352852]
	TIME [epoch: 8.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0072084062679758		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 1.0072084062679758 | validation: 0.7948726296334445]
	TIME [epoch: 8.28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855406405593433		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.855406405593433 | validation: 0.945063333867792]
	TIME [epoch: 8.26 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0115472020945515		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 1.0115472020945515 | validation: 0.9563449366976744]
	TIME [epoch: 8.27 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199424679624363		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 1.0199424679624363 | validation: 0.6531007724296225]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.016181449811336		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 1.016181449811336 | validation: 0.6664842005368173]
	TIME [epoch: 8.28 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619346610142273		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.8619346610142273 | validation: 0.7486117374387227]
	TIME [epoch: 8.31 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9665973567133896		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.9665973567133896 | validation: 1.001130607086375]
	TIME [epoch: 8.27 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.989578578554996		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.989578578554996 | validation: 1.4152317887330848]
	TIME [epoch: 8.26 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1722329717854716		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 1.1722329717854716 | validation: 0.9245921714678469]
	TIME [epoch: 8.26 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9820525370381239		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.9820525370381239 | validation: 1.1770613526694778]
	TIME [epoch: 8.26 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1162744988623208		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 1.1162744988623208 | validation: 1.2026515136681137]
	TIME [epoch: 8.28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9657269250725924		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.9657269250725924 | validation: 1.1908626815898828]
	TIME [epoch: 8.29 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9787770695376861		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.9787770695376861 | validation: 1.1465908781539562]
	TIME [epoch: 8.26 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9312534656802531		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.9312534656802531 | validation: 1.2635248304775226]
	TIME [epoch: 8.27 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1045296647176057		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 1.1045296647176057 | validation: 0.7830853116120834]
	TIME [epoch: 8.26 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9638093769029057		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.9638093769029057 | validation: 0.8434262738769227]
	TIME [epoch: 8.26 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04350910588069		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 1.04350910588069 | validation: 0.6256214342374695]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8823528639498299		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.8823528639498299 | validation: 1.3406231059032954]
	TIME [epoch: 8.28 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1170081056790608		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 1.1170081056790608 | validation: 1.0263527499289666]
	TIME [epoch: 8.27 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0173652486062654		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.0173652486062654 | validation: 0.9269284779464964]
	TIME [epoch: 8.26 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430237210653891		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.9430237210653891 | validation: 1.0083328138532102]
	TIME [epoch: 8.27 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0033610968526891		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 1.0033610968526891 | validation: 1.0386366285631154]
	TIME [epoch: 8.29 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9534689611383425		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.9534689611383425 | validation: 0.8494626263864213]
	TIME [epoch: 8.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9586148667946766		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.9586148667946766 | validation: 1.0859544011443614]
	TIME [epoch: 8.27 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0752467271282096		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 1.0752467271282096 | validation: 1.1897884269817691]
	TIME [epoch: 8.27 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0472053514600226		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 1.0472053514600226 | validation: 0.9007848643753094]
	TIME [epoch: 8.26 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0156553893680584		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 1.0156553893680584 | validation: 1.0181487699825829]
	TIME [epoch: 8.27 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9600937834915578		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.9600937834915578 | validation: 1.0196160685680677]
	TIME [epoch: 8.32 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9170295370007627		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.9170295370007627 | validation: 0.9438894013426644]
	TIME [epoch: 8.27 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071661279709759		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 1.071661279709759 | validation: 0.8302764855381597]
	TIME [epoch: 8.27 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9949945631861195		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.9949945631861195 | validation: 1.1724820151468993]
	TIME [epoch: 8.27 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.10916900592896		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 1.10916900592896 | validation: 0.7561608165194402]
	TIME [epoch: 8.28 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8906934332939803		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.8906934332939803 | validation: 0.8660334998046417]
	TIME [epoch: 8.27 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287521792413132		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 1.0287521792413132 | validation: 1.112405556325043]
	TIME [epoch: 8.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0269268874452235		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 1.0269268874452235 | validation: 1.1123746736504636]
	TIME [epoch: 8.27 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9499738932670888		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.9499738932670888 | validation: 0.7836360077674941]
	TIME [epoch: 8.27 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.930824591125917		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.930824591125917 | validation: 1.118513543403806]
	TIME [epoch: 8.27 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842112920973124		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 1.0842112920973124 | validation: 0.8482841333340012]
	TIME [epoch: 8.27 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9294433855487758		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.9294433855487758 | validation: 0.9305162063899453]
	TIME [epoch: 8.31 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045381330774635		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 1.045381330774635 | validation: 0.8928421651836176]
	TIME [epoch: 8.28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.953973648442262		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.953973648442262 | validation: 0.91785941134448]
	TIME [epoch: 8.28 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9469014126035333		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.9469014126035333 | validation: 1.3726606651980884]
	TIME [epoch: 8.27 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094018423660057		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 1.1094018423660057 | validation: 1.185363541597936]
	TIME [epoch: 8.27 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8977593879491917		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.8977593879491917 | validation: 1.231507819689297]
	TIME [epoch: 8.27 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9107195235626794		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.9107195235626794 | validation: 0.9767696673697879]
	TIME [epoch: 8.31 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140767547465781		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 1.140767547465781 | validation: 0.9801221282943182]
	TIME [epoch: 8.28 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9971401451423451		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.9971401451423451 | validation: 1.0696536186372962]
	TIME [epoch: 8.27 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1500566078738639		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 1.1500566078738639 | validation: 0.7501274752867857]
	TIME [epoch: 8.26 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9997764201071353		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.9997764201071353 | validation: 0.7349412005049581]
	TIME [epoch: 8.26 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8699944071901433		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.8699944071901433 | validation: 1.1615882020985409]
	TIME [epoch: 8.29 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9359577109647259		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.9359577109647259 | validation: 1.0584032294648602]
	TIME [epoch: 8.29 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9196872623132631		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.9196872623132631 | validation: 0.8937112798251031]
	TIME [epoch: 8.26 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8839876729781652		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.8839876729781652 | validation: 0.824088994554705]
	TIME [epoch: 8.27 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.952602221134479		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.952602221134479 | validation: 0.91286111228103]
	TIME [epoch: 8.27 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0294285629992117		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 1.0294285629992117 | validation: 0.9440636470996032]
	TIME [epoch: 8.27 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037775631592139		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 1.037775631592139 | validation: 0.8667621580927511]
	TIME [epoch: 8.31 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9239908954483294		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.9239908954483294 | validation: 0.8894609409160333]
	TIME [epoch: 8.28 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0134912734731556		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 1.0134912734731556 | validation: 1.1636059456293562]
	TIME [epoch: 8.27 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9366731916342121		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.9366731916342121 | validation: 1.0543003631948262]
	TIME [epoch: 8.27 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1219228696092465		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 1.1219228696092465 | validation: 1.1348905797829447]
	TIME [epoch: 8.27 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9827511555510826		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.9827511555510826 | validation: 1.2407063771503]
	TIME [epoch: 8.29 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.990396303151886		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.990396303151886 | validation: 1.4890897834182768]
	TIME [epoch: 8.31 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0462994651982462		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 1.0462994651982462 | validation: 1.0125197374420516]
	TIME [epoch: 8.27 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385321639769396		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.8385321639769396 | validation: 0.788088116634239]
	TIME [epoch: 8.27 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9698600703874976		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.9698600703874976 | validation: 1.211510440663249]
	TIME [epoch: 8.27 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9387824530936174		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.9387824530936174 | validation: 1.252030907255957]
	TIME [epoch: 8.27 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9699923111787988		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.9699923111787988 | validation: 1.020722448010258]
	TIME [epoch: 8.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0132299960315563		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 1.0132299960315563 | validation: 1.0179096902590616]
	TIME [epoch: 8.29 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.932922897446738		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.932922897446738 | validation: 1.024042785812047]
	TIME [epoch: 8.27 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.953760998517461		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.953760998517461 | validation: 0.9094692445835498]
	TIME [epoch: 8.26 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371332317588078		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 1.0371332317588078 | validation: 1.0440584889549984]
	TIME [epoch: 8.27 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034040742455024		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.9034040742455024 | validation: 1.1060186024879797]
	TIME [epoch: 8.28 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9860031436918805		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.9860031436918805 | validation: 0.8936739628341154]
	TIME [epoch: 8.31 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028293931962059		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 1.028293931962059 | validation: 0.9884957071868061]
	TIME [epoch: 8.27 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9590638291340752		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.9590638291340752 | validation: 1.0214154063789274]
	TIME [epoch: 8.28 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9862976630843061		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.9862976630843061 | validation: 1.2091277457338516]
	TIME [epoch: 8.27 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0830023578384984		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 1.0830023578384984 | validation: 0.9348499292993809]
	TIME [epoch: 8.26 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9022579876830155		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.9022579876830155 | validation: 1.0549434585102715]
	TIME [epoch: 8.29 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8788402052889491		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.8788402052889491 | validation: 1.03965586741523]
	TIME [epoch: 8.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0914281895097009		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 1.0914281895097009 | validation: 1.2448262353990303]
	TIME [epoch: 8.27 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9811758861258886		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.9811758861258886 | validation: 0.7002567968297417]
	TIME [epoch: 8.27 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0463318432767945		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 1.0463318432767945 | validation: 0.980755218088847]
	TIME [epoch: 8.27 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9631297851737761		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.9631297851737761 | validation: 1.0510147246511186]
	TIME [epoch: 8.27 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9310007824200357		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.9310007824200357 | validation: 1.6217685344410822]
	TIME [epoch: 8.32 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9991209078875003		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.9991209078875003 | validation: 1.5179798171288015]
	TIME [epoch: 8.27 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9764099407223353		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.9764099407223353 | validation: 0.9026525799447256]
	TIME [epoch: 8.27 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8300417734130157		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.8300417734130157 | validation: 1.3128874533692552]
	TIME [epoch: 8.27 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0048993265514106		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 1.0048993265514106 | validation: 0.9728698581916462]
	TIME [epoch: 8.27 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2119563673108718		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 1.2119563673108718 | validation: 1.646309057913399]
	TIME [epoch: 8.28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1724824199391757		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 1.1724824199391757 | validation: 1.654193847061316]
	TIME [epoch: 8.31 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1058415811537583		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 1.1058415811537583 | validation: 0.8364418281941082]
	TIME [epoch: 8.27 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.968860115102333		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.968860115102333 | validation: 1.0117718902563484]
	TIME [epoch: 8.27 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0377213440467405		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 1.0377213440467405 | validation: 1.0168877484997267]
	TIME [epoch: 8.27 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9456707449667272		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.9456707449667272 | validation: 1.0843004607458702]
	TIME [epoch: 8.27 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9416700546252327		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.9416700546252327 | validation: 0.8556793783848119]
	TIME [epoch: 8.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687082206066332		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.8687082206066332 | validation: 0.8962249099636923]
	TIME [epoch: 8.28 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582460592251755		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 1.0582460592251755 | validation: 0.957631808773769]
	TIME [epoch: 8.28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.934446259806612		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.934446259806612 | validation: 0.892834146446698]
	TIME [epoch: 8.27 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9328777820511913		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.9328777820511913 | validation: 0.7758746427785513]
	TIME [epoch: 8.26 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1184000397669842		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 1.1184000397669842 | validation: 1.220075920947742]
	TIME [epoch: 8.27 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0382223858108701		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 1.0382223858108701 | validation: 0.9445218778991767]
	TIME [epoch: 8.31 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9571554187592718		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.9571554187592718 | validation: 1.0481284612523747]
	TIME [epoch: 8.27 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936370580761061		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.936370580761061 | validation: 0.8738070198396121]
	TIME [epoch: 8.27 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497705930692091		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.8497705930692091 | validation: 0.8794501273104538]
	TIME [epoch: 8.28 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016675260939641		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 1.1016675260939641 | validation: 1.1851187402900916]
	TIME [epoch: 8.27 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9451799828839574		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.9451799828839574 | validation: 0.9736512673602571]
	TIME [epoch: 8.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.864230809647238		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.864230809647238 | validation: 1.0696704136345097]
	TIME [epoch: 8.28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0292763393267694		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 1.0292763393267694 | validation: 1.25297454363792]
	TIME [epoch: 8.27 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9550766453823867		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.9550766453823867 | validation: 0.9518992215422521]
	TIME [epoch: 8.27 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9343464952774397		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.9343464952774397 | validation: 1.095387001511122]
	TIME [epoch: 8.26 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.318263898409545		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 1.318263898409545 | validation: 0.7381239811219635]
	TIME [epoch: 8.28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.959290614769486		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.959290614769486 | validation: 0.7295826983757626]
	TIME [epoch: 8.32 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0952370326399679		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 1.0952370326399679 | validation: 0.8611984976776003]
	TIME [epoch: 8.27 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9994237630388428		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.9994237630388428 | validation: 0.7666808309553033]
	TIME [epoch: 8.26 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9733698222772963		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.9733698222772963 | validation: 0.8221159586374072]
	TIME [epoch: 8.27 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9562738146517753		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.9562738146517753 | validation: 1.0237101709597838]
	TIME [epoch: 8.27 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9527799198640841		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.9527799198640841 | validation: 0.9447794974022893]
	TIME [epoch: 8.28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9711973855544818		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.9711973855544818 | validation: 1.275854917960999]
	TIME [epoch: 8.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207371294594552		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 1.0207371294594552 | validation: 0.9727198232663692]
	TIME [epoch: 8.27 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9424382403305529		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.9424382403305529 | validation: 0.891510285291532]
	TIME [epoch: 8.26 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8443982255495766		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.8443982255495766 | validation: 0.781249790092808]
	TIME [epoch: 8.26 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0683188939433292		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 1.0683188939433292 | validation: 1.269287633210512]
	TIME [epoch: 8.26 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9184166622738004		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.9184166622738004 | validation: 0.7575207311897925]
	TIME [epoch: 8.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9084571096187326		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.9084571096187326 | validation: 1.2956497077551223]
	TIME [epoch: 8.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0349913530770207		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 1.0349913530770207 | validation: 0.6497863837107183]
	TIME [epoch: 8.26 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683111958222148		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.8683111958222148 | validation: 0.7634799779755937]
	TIME [epoch: 8.26 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9804366817341312		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.9804366817341312 | validation: 0.8734641679943029]
	TIME [epoch: 8.26 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0707140032416245		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 1.0707140032416245 | validation: 0.8839744739361772]
	TIME [epoch: 8.27 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02366687991139		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 1.02366687991139 | validation: 0.7972293342028547]
	TIME [epoch: 8.31 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582997499330742		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.8582997499330742 | validation: 0.9281231160972787]
	TIME [epoch: 8.27 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061558106908377		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 1.061558106908377 | validation: 0.9080734015104537]
	TIME [epoch: 8.26 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9419505624865949		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.9419505624865949 | validation: 0.7470869829939271]
	TIME [epoch: 8.26 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9019541435132765		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.9019541435132765 | validation: 1.3449514381124752]
	TIME [epoch: 8.27 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.107081016809182		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 1.107081016809182 | validation: 0.8819238894664302]
	TIME [epoch: 8.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8773003207258083		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.8773003207258083 | validation: 0.6418873573502242]
	TIME [epoch: 8.28 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9174835285504179		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.9174835285504179 | validation: 0.9425619650027113]
	TIME [epoch: 8.27 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0041551200886532		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 1.0041551200886532 | validation: 1.3834836148086864]
	TIME [epoch: 8.27 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260669894196313		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 1.0260669894196313 | validation: 0.9068247243765011]
	TIME [epoch: 8.27 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9205937795223483		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.9205937795223483 | validation: 0.9054151361354532]
	TIME [epoch: 8.27 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9188976012176271		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.9188976012176271 | validation: 0.8971097790319351]
	TIME [epoch: 8.32 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2032558485540505		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 1.2032558485540505 | validation: 1.034123333698361]
	TIME [epoch: 8.27 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9053927422372131		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.9053927422372131 | validation: 0.7869977425826609]
	TIME [epoch: 8.26 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9247209092856314		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.9247209092856314 | validation: 0.77047484898611]
	TIME [epoch: 8.26 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9403793939033965		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.9403793939033965 | validation: 0.9420998601337491]
	TIME [epoch: 8.27 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8372738378943427		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.8372738378943427 | validation: 0.862973084359561]
	TIME [epoch: 8.28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612393844703966		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.8612393844703966 | validation: 1.1441007065744158]
	TIME [epoch: 8.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9260407907699957		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.9260407907699957 | validation: 0.7821763152976231]
	TIME [epoch: 8.27 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027212116235939		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 1.027212116235939 | validation: 0.924890531381058]
	TIME [epoch: 8.26 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8843937062738038		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.8843937062738038 | validation: 0.8858579413203771]
	TIME [epoch: 8.27 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8623677943999032		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.8623677943999032 | validation: 0.9925009951004955]
	TIME [epoch: 8.26 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9192141862988887		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.9192141862988887 | validation: 0.8664050585238419]
	TIME [epoch: 8.31 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8073586221756909		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.8073586221756909 | validation: 0.9560041895671155]
	TIME [epoch: 8.27 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9319529406587486		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.9319529406587486 | validation: 1.022301598690453]
	TIME [epoch: 8.27 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8802585047572867		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.8802585047572867 | validation: 0.994302531073221]
	TIME [epoch: 8.26 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8505439581632713		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.8505439581632713 | validation: 0.8208634951622868]
	TIME [epoch: 8.27 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057922728341456		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.8057922728341456 | validation: 1.1408244769660343]
	TIME [epoch: 8.27 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9580545822737334		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.9580545822737334 | validation: 1.07875149775414]
	TIME [epoch: 8.31 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8572108296590792		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.8572108296590792 | validation: 2.754995635546682]
	TIME [epoch: 8.27 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2695467475419362		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 1.2695467475419362 | validation: 0.9978119425906016]
	TIME [epoch: 8.26 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8730585624363874		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.8730585624363874 | validation: 1.2163951707668301]
	TIME [epoch: 8.26 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9148119343228236		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.9148119343228236 | validation: 0.9019871982636956]
	TIME [epoch: 8.26 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217584351233235		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.8217584351233235 | validation: 0.873478973341649]
	TIME [epoch: 8.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8919982264029807		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.8919982264029807 | validation: 1.0413338490828266]
	TIME [epoch: 8.28 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7686496016079869		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.7686496016079869 | validation: 0.8628821940005122]
	TIME [epoch: 8.27 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9014439329514581		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.9014439329514581 | validation: 0.8951096544545443]
	TIME [epoch: 8.27 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.829526087975021		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.829526087975021 | validation: 1.01544046203633]
	TIME [epoch: 8.27 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752417775864332		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.8752417775864332 | validation: 1.096760674128054]
	TIME [epoch: 8.27 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9507964284902896		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.9507964284902896 | validation: 1.0188053345341397]
	TIME [epoch: 8.31 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8492423197690487		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.8492423197690487 | validation: 0.6168004992220946]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7330228451366504		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.7330228451366504 | validation: 1.1873815680786892]
	TIME [epoch: 8.27 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752479886789488		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.8752479886789488 | validation: 1.1033734465692349]
	TIME [epoch: 8.27 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8608741931433709		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.8608741931433709 | validation: 0.8809694289259011]
	TIME [epoch: 8.26 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0770240914337195		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 1.0770240914337195 | validation: 0.9241351748912374]
	TIME [epoch: 8.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8966246870961142		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.8966246870961142 | validation: 0.9235493824889949]
	TIME [epoch: 8.27 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371163394506689		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.8371163394506689 | validation: 0.7664891927785396]
	TIME [epoch: 8.26 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775633552816463		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.775633552816463 | validation: 1.1057459911801906]
	TIME [epoch: 8.27 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9201649597960939		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.9201649597960939 | validation: 0.6523257664092499]
	TIME [epoch: 8.26 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8838801592474883		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.8838801592474883 | validation: 0.6760547410698838]
	TIME [epoch: 8.27 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.803182761747535		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.803182761747535 | validation: 0.6918498128562051]
	TIME [epoch: 8.31 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8443160472141991		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.8443160472141991 | validation: 0.6916056082718054]
	TIME [epoch: 8.28 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8167450690858775		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.8167450690858775 | validation: 1.2028938805547014]
	TIME [epoch: 8.26 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0447719727543467		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 1.0447719727543467 | validation: 0.798810163378513]
	TIME [epoch: 8.26 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9372930475644947		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.9372930475644947 | validation: 0.905824656366242]
	TIME [epoch: 8.27 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941473283279689		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.941473283279689 | validation: 0.6727438233558325]
	TIME [epoch: 8.29 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076403216188767		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.8076403216188767 | validation: 0.8154342538400452]
	TIME [epoch: 8.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8766536994731998		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.8766536994731998 | validation: 0.7093645231315562]
	TIME [epoch: 8.26 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825539872729737		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.7825539872729737 | validation: 0.7835324472305158]
	TIME [epoch: 8.27 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7949423868111051		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.7949423868111051 | validation: 1.1566347704289197]
	TIME [epoch: 8.27 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1048741041080143		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 1.1048741041080143 | validation: 0.7872510935762542]
	TIME [epoch: 8.28 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588997608611139		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.7588997608611139 | validation: 0.7076306425221155]
	TIME [epoch: 8.31 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921219479828125		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.7921219479828125 | validation: 0.9009948713452582]
	TIME [epoch: 8.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8951156004313019		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.8951156004313019 | validation: 0.9909856720895857]
	TIME [epoch: 8.27 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519982875408932		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.9519982875408932 | validation: 1.1312441158981699]
	TIME [epoch: 8.27 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0755612107596046		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 1.0755612107596046 | validation: 0.8865504847170691]
	TIME [epoch: 8.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7986956610790742		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.7986956610790742 | validation: 1.000752700489048]
	TIME [epoch: 8.34 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8039614148625983		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.8039614148625983 | validation: 0.7248874385176478]
	TIME [epoch: 8.31 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723928252266157		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.723928252266157 | validation: 0.6916957758176223]
	TIME [epoch: 8.27 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9591447883423212		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.9591447883423212 | validation: 0.9297791671941562]
	TIME [epoch: 8.28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9978765458332213		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.9978765458332213 | validation: 1.2946264513129937]
	TIME [epoch: 8.27 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900789152544737		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.8900789152544737 | validation: 0.7615491411404747]
	TIME [epoch: 8.27 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067897856955573		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.8067897856955573 | validation: 0.6959723127680836]
	TIME [epoch: 8.31 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7944190996993454		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.7944190996993454 | validation: 0.7814626137737877]
	TIME [epoch: 8.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7875914522808309		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.7875914522808309 | validation: 1.0890999214992698]
	TIME [epoch: 8.28 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92146765808743		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.92146765808743 | validation: 0.8163308951922728]
	TIME [epoch: 8.26 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9965651200973179		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.9965651200973179 | validation: 0.6232578847096844]
	TIME [epoch: 8.28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425883293855207		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.7425883293855207 | validation: 1.1941047259466147]
	TIME [epoch: 8.28 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8530086862841769		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.8530086862841769 | validation: 1.059529087750477]
	TIME [epoch: 8.32 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160273487623441		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.8160273487623441 | validation: 1.1473377844092856]
	TIME [epoch: 8.27 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9460183612284023		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.9460183612284023 | validation: 0.6534537893447434]
	TIME [epoch: 8.28 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611944316169136		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.8611944316169136 | validation: 0.7490250628459783]
	TIME [epoch: 8.26 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564988721080868		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.7564988721080868 | validation: 0.7640172009525884]
	TIME [epoch: 8.27 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0130756157295366		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 1.0130756157295366 | validation: 0.9187521854538537]
	TIME [epoch: 8.29 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8564163867766682		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.8564163867766682 | validation: 0.8813227507071211]
	TIME [epoch: 8.31 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8942367162546971		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.8942367162546971 | validation: 0.7911771944806001]
	TIME [epoch: 8.27 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7786003270794749		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.7786003270794749 | validation: 0.6625553956770067]
	TIME [epoch: 8.28 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724931508533142		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.724931508533142 | validation: 0.848685455683258]
	TIME [epoch: 8.26 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9870487786406981		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.9870487786406981 | validation: 0.7255081160298807]
	TIME [epoch: 8.27 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8112269946931032		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.8112269946931032 | validation: 0.8400609916874389]
	TIME [epoch: 8.31 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374716747867574		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.8374716747867574 | validation: 0.9299872485273244]
	TIME [epoch: 8.29 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059531974004028		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.8059531974004028 | validation: 1.0474612077195746]
	TIME [epoch: 8.28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8049863980751664		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.8049863980751664 | validation: 0.5386110720972799]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785314912820224		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.6785314912820224 | validation: 1.2614744734895313]
	TIME [epoch: 8.27 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9442259884373427		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.9442259884373427 | validation: 0.8922199279641121]
	TIME [epoch: 8.29 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8927521431987384		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.8927521431987384 | validation: 1.2116754631246855]
	TIME [epoch: 8.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978403410610419		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.8978403410610419 | validation: 1.0775372223646087]
	TIME [epoch: 8.26 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8529318665671265		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.8529318665671265 | validation: 0.7262840889869661]
	TIME [epoch: 8.26 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731813003346522		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.7731813003346522 | validation: 0.6639920871318612]
	TIME [epoch: 8.27 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8413956157496749		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.8413956157496749 | validation: 0.9679899459664989]
	TIME [epoch: 8.26 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780065773917588		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.7780065773917588 | validation: 0.6228939196815938]
	TIME [epoch: 8.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8268953797268153		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.8268953797268153 | validation: 1.1739768462433204]
	TIME [epoch: 8.27 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8787742137522255		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.8787742137522255 | validation: 0.92852581236193]
	TIME [epoch: 8.27 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8926050648269389		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.8926050648269389 | validation: 0.7833869946165766]
	TIME [epoch: 8.26 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316207431577002		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.7316207431577002 | validation: 0.9881920219731322]
	TIME [epoch: 8.26 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855410514317062		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.855410514317062 | validation: 0.8607310662280157]
	TIME [epoch: 8.29 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820463538085094		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.820463538085094 | validation: 0.6920578554352078]
	TIME [epoch: 8.31 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8267632145038667		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.8267632145038667 | validation: 0.6792414047774014]
	TIME [epoch: 8.27 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359733239253873		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 1.359733239253873 | validation: 1.0046151077737107]
	TIME [epoch: 8.27 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116776236176214		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 1.116776236176214 | validation: 0.7097523220779705]
	TIME [epoch: 8.27 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881810280984981		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.8881810280984981 | validation: 0.6760086122145301]
	TIME [epoch: 8.27 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9475080510235996		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.9475080510235996 | validation: 0.7417640495764268]
	TIME [epoch: 8.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687853505615376		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.7687853505615376 | validation: 0.7723036970316743]
	TIME [epoch: 8.29 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8502562431593577		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.8502562431593577 | validation: 0.9159171154967432]
	TIME [epoch: 8.27 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8453618429246		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.8453618429246 | validation: 0.8271318158166842]
	TIME [epoch: 8.27 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829574954692602		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.8829574954692602 | validation: 0.6339642484140804]
	TIME [epoch: 8.26 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896413325169954		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.6896413325169954 | validation: 0.9728889102022493]
	TIME [epoch: 8.26 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8208523328574138		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.8208523328574138 | validation: 1.0661789994995656]
	TIME [epoch: 8.32 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8887993896279246		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.8887993896279246 | validation: 0.6298912495851297]
	TIME [epoch: 8.27 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803806131134653		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.8803806131134653 | validation: 0.9397370128432534]
	TIME [epoch: 8.28 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.898546622433247		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.898546622433247 | validation: 1.1670107954050906]
	TIME [epoch: 8.28 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399158738065589		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.9399158738065589 | validation: 0.6420436414929414]
	TIME [epoch: 8.26 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601374261486412		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.7601374261486412 | validation: 0.7407248104621297]
	TIME [epoch: 8.29 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8395031779518585		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.8395031779518585 | validation: 0.7961425154408149]
	TIME [epoch: 8.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708749677953264		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.7708749677953264 | validation: 1.057614420423945]
	TIME [epoch: 8.27 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.913078185028179		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.913078185028179 | validation: 0.6889789049013988]
	TIME [epoch: 8.27 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693257633063499		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.7693257633063499 | validation: 1.1379694245981908]
	TIME [epoch: 8.27 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9086374345073192		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.9086374345073192 | validation: 0.8453107385460465]
	TIME [epoch: 8.27 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177823811736981		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.8177823811736981 | validation: 0.8216788347332737]
	TIME [epoch: 8.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245619953892601		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.7245619953892601 | validation: 0.753515916900099]
	TIME [epoch: 8.28 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790249926727185		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.7790249926727185 | validation: 0.705065450747196]
	TIME [epoch: 8.26 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744740263794485		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.744740263794485 | validation: 1.108536696610303]
	TIME [epoch: 8.27 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8979068779134185		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.8979068779134185 | validation: 0.6856739354351697]
	TIME [epoch: 8.27 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517891557968661		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.7517891557968661 | validation: 0.821639106138569]
	TIME [epoch: 8.27 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733764733535612		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.7733764733535612 | validation: 1.1552092878372315]
	TIME [epoch: 8.33 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174140281798068		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.8174140281798068 | validation: 0.641915157448953]
	TIME [epoch: 8.27 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7811675218928331		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.7811675218928331 | validation: 0.7812314561915408]
	TIME [epoch: 8.27 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.850652224529619		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.850652224529619 | validation: 0.8185651998822125]
	TIME [epoch: 8.26 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475885822905347		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.7475885822905347 | validation: 0.6762007410142681]
	TIME [epoch: 8.26 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371749167928805		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.7371749167928805 | validation: 1.2290739514436204]
	TIME [epoch: 8.31 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343282311338152		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.7343282311338152 | validation: 1.1063027640368461]
	TIME [epoch: 8.28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7643471863807556		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.7643471863807556 | validation: 0.7649589744382155]
	TIME [epoch: 8.27 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8138376236865821		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.8138376236865821 | validation: 0.8159766456144264]
	TIME [epoch: 8.27 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8430087117530705		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.8430087117530705 | validation: 0.7995569939631069]
	TIME [epoch: 8.26 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305300272285661		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.7305300272285661 | validation: 0.761032699187391]
	TIME [epoch: 8.27 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808135435163547		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.7808135435163547 | validation: 0.7848987596377566]
	TIME [epoch: 8.32 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885427696982692		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.7885427696982692 | validation: 0.7150082592855002]
	TIME [epoch: 8.28 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8614773454339262		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.8614773454339262 | validation: 0.6983614340319744]
	TIME [epoch: 8.27 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683610019604141		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.8683610019604141 | validation: 0.8406572075596179]
	TIME [epoch: 8.27 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230847662624367		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.7230847662624367 | validation: 0.5878401240977139]
	TIME [epoch: 8.27 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692886993496256		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.692886993496256 | validation: 1.0429279495884036]
	TIME [epoch: 8.29 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252545098380426		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.7252545098380426 | validation: 0.8636090826939833]
	TIME [epoch: 8.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814814069010964		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.6814814069010964 | validation: 0.8432996885802367]
	TIME [epoch: 8.28 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.785248721135817		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.785248721135817 | validation: 0.7481316218679144]
	TIME [epoch: 8.28 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014230210658334		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.7014230210658334 | validation: 0.6113828166160017]
	TIME [epoch: 8.27 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385525311551121		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.8385525311551121 | validation: 0.7836029801153633]
	TIME [epoch: 8.27 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597947603440354		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.7597947603440354 | validation: 0.672954420125575]
	TIME [epoch: 8.32 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7801252221615255		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.7801252221615255 | validation: 0.6501427633309986]
	TIME [epoch: 8.28 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755869821428448		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.6755869821428448 | validation: 0.73105704963522]
	TIME [epoch: 8.27 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7311612541180927		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.7311612541180927 | validation: 1.01069416002287]
	TIME [epoch: 8.28 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173417453392278		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.8173417453392278 | validation: 0.6409626008906179]
	TIME [epoch: 8.27 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899613757461462		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.7899613757461462 | validation: 1.0491208535049235]
	TIME [epoch: 8.28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2015889693858166		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 1.2015889693858166 | validation: 0.6760453103449817]
	TIME [epoch: 8.31 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547055262979121		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.7547055262979121 | validation: 0.8199642386091561]
	TIME [epoch: 8.28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918981469192992		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.7918981469192992 | validation: 1.0018161883280763]
	TIME [epoch: 8.28 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655208648199038		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.7655208648199038 | validation: 0.7062194320108299]
	TIME [epoch: 8.26 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8493028336744418		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.8493028336744418 | validation: 0.8716577492856707]
	TIME [epoch: 8.28 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8616165898976627		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.8616165898976627 | validation: 0.6553491885478382]
	TIME [epoch: 8.31 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812853717404468		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.6812853717404468 | validation: 0.5882597377486599]
	TIME [epoch: 8.29 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7941194849500166		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.7941194849500166 | validation: 0.8946096025500301]
	TIME [epoch: 8.26 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7973844777570572		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.7973844777570572 | validation: 0.6552282309268397]
	TIME [epoch: 8.27 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652231894301302		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.652231894301302 | validation: 0.7835510447348708]
	TIME [epoch: 8.27 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243560928491698		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.7243560928491698 | validation: 0.7123152414115335]
	TIME [epoch: 8.27 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067719525566639		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.8067719525566639 | validation: 0.6410453575118422]
	TIME [epoch: 8.31 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582404238473831		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.8582404238473831 | validation: 0.6783545532508983]
	TIME [epoch: 8.27 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355772971136191		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.7355772971136191 | validation: 0.60580143672858]
	TIME [epoch: 8.27 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7754643542537045		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.7754643542537045 | validation: 0.6469253625168268]
	TIME [epoch: 8.27 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119759264664994		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.7119759264664994 | validation: 0.8735146192823549]
	TIME [epoch: 8.27 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401945692848209		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.7401945692848209 | validation: 0.5509642601141633]
	TIME [epoch: 8.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577607862042473		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.6577607862042473 | validation: 1.352173012411374]
	TIME [epoch: 8.29 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333258540546467		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.8333258540546467 | validation: 0.6850142228544205]
	TIME [epoch: 8.27 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317251500658455		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.7317251500658455 | validation: 0.6297577538899175]
	TIME [epoch: 8.27 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175091144041297		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.7175091144041297 | validation: 0.6912209976025269]
	TIME [epoch: 8.27 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585038137347551		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.6585038137347551 | validation: 0.6615234439102489]
	TIME [epoch: 8.27 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941385481400693		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.6941385481400693 | validation: 0.914337051490073]
	TIME [epoch: 8.32 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964060953278325		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.6964060953278325 | validation: 0.5378016639067429]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851751076983414		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.6851751076983414 | validation: 0.6444151554369333]
	TIME [epoch: 8.27 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955087239018576		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.6955087239018576 | validation: 0.9681504207354792]
	TIME [epoch: 8.26 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7894501639337569		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.7894501639337569 | validation: 0.6999508555010556]
	TIME [epoch: 8.27 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9082883692687078		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.9082883692687078 | validation: 0.6643644519581089]
	TIME [epoch: 8.28 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709131523336306		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.6709131523336306 | validation: 0.7725938351956911]
	TIME [epoch: 8.31 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089052086202434		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.8089052086202434 | validation: 1.1579933724894271]
	TIME [epoch: 8.28 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8500846990320388		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.8500846990320388 | validation: 0.629773540124048]
	TIME [epoch: 8.29 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978916502323677		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.6978916502323677 | validation: 0.638409457929595]
	TIME [epoch: 8.27 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329722309290127		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.6329722309290127 | validation: 0.8048544801756743]
	TIME [epoch: 8.27 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162361395657069		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.7162361395657069 | validation: 0.7617426086165231]
	TIME [epoch: 8.33 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6631647279495667		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.6631647279495667 | validation: 0.6948273967693464]
	TIME [epoch: 8.28 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287739189484749		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.7287739189484749 | validation: 0.6592738919397874]
	TIME [epoch: 8.27 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.644445334939185		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.644445334939185 | validation: 1.2839480716793132]
	TIME [epoch: 8.27 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687758165424663		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.7687758165424663 | validation: 0.9693252049656367]
	TIME [epoch: 8.29 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140792222157486		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.8140792222157486 | validation: 0.7444036338206607]
	TIME [epoch: 8.29 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887416657419907		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.6887416657419907 | validation: 0.5515527623331278]
	TIME [epoch: 8.31 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8033214354594891		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.8033214354594891 | validation: 0.8730922742936045]
	TIME [epoch: 8.27 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613496644359738		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.7613496644359738 | validation: 0.8835756663617277]
	TIME [epoch: 8.28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293653578667435		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.7293653578667435 | validation: 0.8173545259945193]
	TIME [epoch: 8.27 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6246924038353244		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.6246924038353244 | validation: 0.7239444272018332]
	TIME [epoch: 8.27 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851136330323644		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.6851136330323644 | validation: 0.7469065307310827]
	TIME [epoch: 8.32 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463483231973473		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.6463483231973473 | validation: 0.5650104851635094]
	TIME [epoch: 8.29 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547049826228829		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.7547049826228829 | validation: 0.75872747467512]
	TIME [epoch: 8.27 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7633017878414812		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.7633017878414812 | validation: 0.8078533304665082]
	TIME [epoch: 8.27 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660020518740546		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.7660020518740546 | validation: 0.4932696759254658]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263463001675948		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.7263463001675948 | validation: 0.5209830231376127]
	TIME [epoch: 8.29 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5881364550140845		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.5881364550140845 | validation: 0.9635167216855038]
	TIME [epoch: 8.32 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854180938121972		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.6854180938121972 | validation: 0.6597169768933011]
	TIME [epoch: 8.29 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320615465209505		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.6320615465209505 | validation: 1.2276612292955607]
	TIME [epoch: 8.28 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745428032920695		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.745428032920695 | validation: 0.650786057157532]
	TIME [epoch: 8.28 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432703673413597		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.7432703673413597 | validation: 0.5707143983289877]
	TIME [epoch: 8.28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664057456874137		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.6664057456874137 | validation: 0.6893845467495607]
	TIME [epoch: 8.32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152279739449352		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.6152279739449352 | validation: 0.7233188629522292]
	TIME [epoch: 8.29 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382314018667774		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.6382314018667774 | validation: 0.7219771902411201]
	TIME [epoch: 8.28 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8261664714084397		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.8261664714084397 | validation: 0.6139085127598329]
	TIME [epoch: 8.28 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143554384769817		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.8143554384769817 | validation: 0.7870144411301743]
	TIME [epoch: 8.28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734553069786525		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.7734553069786525 | validation: 0.7358199624406838]
	TIME [epoch: 8.28 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831780427632446		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.6831780427632446 | validation: 0.9597129459691652]
	TIME [epoch: 8.32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726941292574335		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.726941292574335 | validation: 0.504036671488547]
	TIME [epoch: 8.28 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656543355893981		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.656543355893981 | validation: 0.7081811317459401]
	TIME [epoch: 8.28 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008091864287389		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.6008091864287389 | validation: 0.6382288238243063]
	TIME [epoch: 8.27 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830812799008442		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.6830812799008442 | validation: 0.6210444710330718]
	TIME [epoch: 8.27 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838279056940201		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.5838279056940201 | validation: 0.7852768227285271]
	TIME [epoch: 8.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7843645106386413		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.7843645106386413 | validation: 0.6989965239859574]
	TIME [epoch: 8.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790787149523267		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.7790787149523267 | validation: 0.6248339147898305]
	TIME [epoch: 8.28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662712670618141		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.662712670618141 | validation: 0.7484885718230442]
	TIME [epoch: 8.28 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.665182657230839		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.665182657230839 | validation: 0.8914626340326479]
	TIME [epoch: 8.28 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.676885625116519		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.676885625116519 | validation: 0.9423723086932458]
	TIME [epoch: 8.28 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461926383853374		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.6461926383853374 | validation: 0.4937974929834814]
	TIME [epoch: 8.32 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284606002429111		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.6284606002429111 | validation: 0.5454876367981992]
	TIME [epoch: 8.29 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184601439624944		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.7184601439624944 | validation: 0.8384412339485727]
	TIME [epoch: 8.28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948102384120733		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.6948102384120733 | validation: 0.6030195752113479]
	TIME [epoch: 8.28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6502837987891547		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.6502837987891547 | validation: 0.8050752019147869]
	TIME [epoch: 8.28 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.769417686185389		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.769417686185389 | validation: 0.4905199091518935]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124888189568003		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.6124888189568003 | validation: 0.5936266925120804]
	TIME [epoch: 8.32 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.60600645951595		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.60600645951595 | validation: 0.516292980109969]
	TIME [epoch: 8.27 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7327707387051297		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.7327707387051297 | validation: 0.7276560307282773]
	TIME [epoch: 8.28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227380059437028		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.6227380059437028 | validation: 0.5590192339969272]
	TIME [epoch: 8.27 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100452549941558		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.7100452549941558 | validation: 0.5793540750647694]
	TIME [epoch: 8.27 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390733808007653		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.5390733808007653 | validation: 0.42442371240023413]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987770947107245		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.5987770947107245 | validation: 0.6990517674595647]
	TIME [epoch: 8.28 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74881479807431		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.74881479807431 | validation: 0.612006274345733]
	TIME [epoch: 8.27 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8031296530817067		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.8031296530817067 | validation: 0.9036427333457986]
	TIME [epoch: 8.26 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724871201259105		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.5724871201259105 | validation: 0.8893543105063834]
	TIME [epoch: 8.28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309801409323098		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.7309801409323098 | validation: 0.42876576562083313]
	TIME [epoch: 8.28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920340934278466		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.6920340934278466 | validation: 0.5004937277934863]
	TIME [epoch: 8.31 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616698356877274		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.6616698356877274 | validation: 0.7369026892597978]
	TIME [epoch: 8.27 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571482169330497		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.6571482169330497 | validation: 0.6101236649572315]
	TIME [epoch: 8.27 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716626690388561		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.6716626690388561 | validation: 0.4606142547179071]
	TIME [epoch: 8.27 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872911663340259		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.6872911663340259 | validation: 0.6999660320970009]
	TIME [epoch: 8.27 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146786870418618		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.7146786870418618 | validation: 0.5788081244144517]
	TIME [epoch: 8.31 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619364672010854		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.5619364672010854 | validation: 0.4473717015373331]
	TIME [epoch: 8.28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077412361265494		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.6077412361265494 | validation: 0.5562513564499926]
	TIME [epoch: 8.27 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992881409886326		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.5992881409886326 | validation: 0.5210838134805762]
	TIME [epoch: 8.27 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980405099653203		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.5980405099653203 | validation: 0.5756757530540733]
	TIME [epoch: 8.27 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6634489823536884		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.6634489823536884 | validation: 0.504737786231022]
	TIME [epoch: 8.28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877081153810066		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.5877081153810066 | validation: 0.5367287987844631]
	TIME [epoch: 8.31 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725241583716641		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.725241583716641 | validation: 0.7056035331209625]
	TIME [epoch: 8.27 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6765906276949251		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.6765906276949251 | validation: 0.5382797767381394]
	TIME [epoch: 8.28 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278686746249936		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.6278686746249936 | validation: 0.4890290344128061]
	TIME [epoch: 8.27 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130379788993755		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.6130379788993755 | validation: 0.4684385207561863]
	TIME [epoch: 8.27 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5344075256711595		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.5344075256711595 | validation: 0.6101926461514146]
	TIME [epoch: 8.29 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307195836653261		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.6307195836653261 | validation: 0.3988002828340121]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6578233469350065		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.6578233469350065 | validation: 1.1589600015309711]
	TIME [epoch: 8.27 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479524126409286		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.6479524126409286 | validation: 0.48126996744979]
	TIME [epoch: 8.27 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517974478321771		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.6517974478321771 | validation: 0.6250571080499613]
	TIME [epoch: 8.28 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733001623431834		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.733001623431834 | validation: 0.6493645959652461]
	TIME [epoch: 8.27 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406029073340457		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.6406029073340457 | validation: 0.5960225474501082]
	TIME [epoch: 8.32 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101317967763704		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.6101317967763704 | validation: 0.720493143613455]
	TIME [epoch: 8.27 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023157732058712		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.6023157732058712 | validation: 0.9190851797812492]
	TIME [epoch: 8.27 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819034554368886		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.6819034554368886 | validation: 0.9037112709646546]
	TIME [epoch: 8.27 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795185758468633		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.6795185758468633 | validation: 0.49989235594519227]
	TIME [epoch: 8.27 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577713511483891		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.577713511483891 | validation: 0.9914216420013648]
	TIME [epoch: 8.29 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8531003663793453		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.8531003663793453 | validation: 0.4659899451003323]
	TIME [epoch: 8.3 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490178347658715		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.5490178347658715 | validation: 0.4761498802123001]
	TIME [epoch: 8.27 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112678912020147		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.6112678912020147 | validation: 0.55563672187193]
	TIME [epoch: 8.27 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554753030625697		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.6554753030625697 | validation: 0.8466214186618894]
	TIME [epoch: 8.27 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910463494862238		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.6910463494862238 | validation: 0.5825834050598446]
	TIME [epoch: 8.27 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6324109734966585		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.6324109734966585 | validation: 0.6092447921005821]
	TIME [epoch: 8.31 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326247630568268		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.6326247630568268 | validation: 0.5216934920115318]
	TIME [epoch: 8.29 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054870154758611		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.5054870154758611 | validation: 0.7372882828789502]
	TIME [epoch: 8.28 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5798351250252514		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.5798351250252514 | validation: 0.5978427896819507]
	TIME [epoch: 8.27 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015840044495129		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.6015840044495129 | validation: 0.6847475945443868]
	TIME [epoch: 8.28 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327396734773417		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.6327396734773417 | validation: 0.6259175445189741]
	TIME [epoch: 8.28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865485465171819		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.5865485465171819 | validation: 0.48604094714503376]
	TIME [epoch: 8.31 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418539318200001		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.7418539318200001 | validation: 0.606076159852408]
	TIME [epoch: 8.27 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484719331122886		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.5484719331122886 | validation: 0.6713040158604139]
	TIME [epoch: 8.27 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899638361869147		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.6899638361869147 | validation: 0.47032165132432285]
	TIME [epoch: 8.27 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.506821763193322		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.506821763193322 | validation: 0.5544115315092294]
	TIME [epoch: 8.26 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962729738408346		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.5962729738408346 | validation: 0.48761860728334494]
	TIME [epoch: 8.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840957611084283		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.5840957611084283 | validation: 0.7392174129176895]
	TIME [epoch: 8.28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225464895406163		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.6225464895406163 | validation: 0.5717094766676611]
	TIME [epoch: 8.26 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327817727096031		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.6327817727096031 | validation: 0.653155201320664]
	TIME [epoch: 8.26 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848794919426357		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.5848794919426357 | validation: 0.6499541210396783]
	TIME [epoch: 8.27 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086392002657447		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.6086392002657447 | validation: 0.4988585308006075]
	TIME [epoch: 8.28 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714388910934475		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.5714388910934475 | validation: 1.0117245677832238]
	TIME [epoch: 8.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616649489571577		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 1.0616649489571577 | validation: 0.516976307522031]
	TIME [epoch: 8.27 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004249033743994		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.7004249033743994 | validation: 0.39772948003558933]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598515112083398		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.6598515112083398 | validation: 0.49212836409580585]
	TIME [epoch: 8.28 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422218523686973		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.6422218523686973 | validation: 0.7216214581551244]
	TIME [epoch: 8.27 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581480843180145		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.6581480843180145 | validation: 0.4952294748563656]
	TIME [epoch: 8.31 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404074103131382		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.5404074103131382 | validation: 0.8556272162846733]
	TIME [epoch: 8.29 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756539852030979		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.5756539852030979 | validation: 0.598524517955293]
	TIME [epoch: 8.27 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5541862506981163		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.5541862506981163 | validation: 0.5418864527149688]
	TIME [epoch: 8.27 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341193079431047		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.6341193079431047 | validation: 0.5546083320975969]
	TIME [epoch: 8.27 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680945463660109		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.680945463660109 | validation: 0.8002126704979327]
	TIME [epoch: 8.27 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822215519647053		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.5822215519647053 | validation: 0.6141376579301776]
	TIME [epoch: 8.31 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885161193861703		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.6885161193861703 | validation: 0.7275881437361474]
	TIME [epoch: 8.27 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073576802215648		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.6073576802215648 | validation: 0.6677095710320593]
	TIME [epoch: 8.28 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014937941112117		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.6014937941112117 | validation: 0.7737633405441737]
	TIME [epoch: 8.27 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688441464798721		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.6688441464798721 | validation: 0.7451229979632841]
	TIME [epoch: 8.27 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5550143419220321		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.5550143419220321 | validation: 0.4845392004459206]
	TIME [epoch: 8.29 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743386182561719		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.5743386182561719 | validation: 0.6160359860650162]
	TIME [epoch: 8.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698595678232299		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.5698595678232299 | validation: 0.507345453809775]
	TIME [epoch: 8.27 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818516043773765		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.6818516043773765 | validation: 0.7282834203235308]
	TIME [epoch: 8.27 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6780650933678324		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.6780650933678324 | validation: 0.6532814963695449]
	TIME [epoch: 8.28 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942393591076774		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.6942393591076774 | validation: 0.6443505293145956]
	TIME [epoch: 8.27 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764265624089418		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.764265624089418 | validation: 0.5458604559793743]
	TIME [epoch: 8.32 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189330639486927		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.6189330639486927 | validation: 0.4355678425978713]
	TIME [epoch: 8.28 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761768296157476		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.5761768296157476 | validation: 0.5551970612555752]
	TIME [epoch: 8.27 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5539010042510781		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.5539010042510781 | validation: 0.8791960449387134]
	TIME [epoch: 8.27 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917745948600333		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.6917745948600333 | validation: 0.7387708100637598]
	TIME [epoch: 8.27 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806258184601915		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.5806258184601915 | validation: 0.8220108102306334]
	TIME [epoch: 8.28 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325462469148755		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.6325462469148755 | validation: 0.6396799596372522]
	TIME [epoch: 8.32 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399474947239972		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.5399474947239972 | validation: 0.6043780035616815]
	TIME [epoch: 8.27 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587033449841373		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.6587033449841373 | validation: 0.526744443867169]
	TIME [epoch: 8.27 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518192337792978		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.5518192337792978 | validation: 0.46792009670641277]
	TIME [epoch: 8.27 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46350914518241554		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.46350914518241554 | validation: 0.43123853849743765]
	TIME [epoch: 8.27 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833606033778946		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.5833606033778946 | validation: 0.7938774811791354]
	TIME [epoch: 8.31 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960118548332697		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.5960118548332697 | validation: 0.653258039274774]
	TIME [epoch: 8.29 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808657850357382		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.5808657850357382 | validation: 0.6462912078425583]
	TIME [epoch: 8.28 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731588709632829		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.5731588709632829 | validation: 0.6464751855823105]
	TIME [epoch: 8.27 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5570994933940849		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.5570994933940849 | validation: 0.5941868058175199]
	TIME [epoch: 8.27 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5545525458435071		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.5545525458435071 | validation: 0.6084395983025033]
	TIME [epoch: 8.28 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5156947268777803		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.5156947268777803 | validation: 0.5515875145606306]
	TIME [epoch: 8.31 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206702744419821		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.5206702744419821 | validation: 0.4949084214358539]
	TIME [epoch: 8.27 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6511900667407063		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.6511900667407063 | validation: 0.6601821834989758]
	TIME [epoch: 8.27 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799451643369078		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.5799451643369078 | validation: 0.5131793712356776]
	TIME [epoch: 8.28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480512604309223		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.6480512604309223 | validation: 0.35652787020550714]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.490274297149378		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.490274297149378 | validation: 0.6595982208050528]
	TIME [epoch: 8.31 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891773700538744		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.4891773700538744 | validation: 0.6151599771391841]
	TIME [epoch: 8.29 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999581241683065		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.5999581241683065 | validation: 0.5447683457317818]
	TIME [epoch: 8.28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753322303670574		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.5753322303670574 | validation: 0.8957565025829413]
	TIME [epoch: 8.27 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463833392007536		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.6463833392007536 | validation: 0.44127521416471704]
	TIME [epoch: 8.27 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481630611417474		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.5481630611417474 | validation: 0.6092311392343049]
	TIME [epoch: 8.28 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6387437278128076		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.6387437278128076 | validation: 0.5029009228123168]
	TIME [epoch: 8.32 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288000042416575		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.5288000042416575 | validation: 0.5072006251949117]
	TIME [epoch: 8.28 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366877607043452		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.5366877607043452 | validation: 0.34261756282957956]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_864.pth
	Model improved!!!
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750912606060622		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.750912606060622 | validation: 0.3828400959458961]
	TIME [epoch: 8.27 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471858835913359		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.5471858835913359 | validation: 0.5773055448203073]
	TIME [epoch: 8.27 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49772521914421985		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.49772521914421985 | validation: 0.6085600356859109]
	TIME [epoch: 8.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001944438201783		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.5001944438201783 | validation: 0.6713553627074114]
	TIME [epoch: 8.29 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5603194945215316		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.5603194945215316 | validation: 0.5791872585688147]
	TIME [epoch: 8.27 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859314102494959		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.5859314102494959 | validation: 0.421945785592828]
	TIME [epoch: 8.27 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516754229852713		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.5516754229852713 | validation: 0.4614931384980927]
	TIME [epoch: 8.27 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5530744527694128		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.5530744527694128 | validation: 0.40788743218293755]
	TIME [epoch: 8.27 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313415126792776		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.6313415126792776 | validation: 0.46588918661727047]
	TIME [epoch: 8.32 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4997093989049115		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.4997093989049115 | validation: 0.6763607878387692]
	TIME [epoch: 8.27 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771311282582601		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.5771311282582601 | validation: 0.3834026894976237]
	TIME [epoch: 8.27 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8359915119351935		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.8359915119351935 | validation: 0.5273176371278899]
	TIME [epoch: 8.27 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45515560429415036		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.45515560429415036 | validation: 0.48940514392699086]
	TIME [epoch: 8.27 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827471510889781		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.6827471510889781 | validation: 0.5148997672428197]
	TIME [epoch: 8.28 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5868698886913948		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.5868698886913948 | validation: 0.4708476405123091]
	TIME [epoch: 8.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999742973363651		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.5999742973363651 | validation: 0.45526065807167426]
	TIME [epoch: 8.27 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4769759021440122		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.4769759021440122 | validation: 0.40340313570802433]
	TIME [epoch: 8.27 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583262551766968		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.4583262551766968 | validation: 0.42526750422589965]
	TIME [epoch: 8.28 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342365439253004		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.5342365439253004 | validation: 0.48419465447293897]
	TIME [epoch: 8.28 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542402565927035		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.542402565927035 | validation: 0.5188539748903565]
	TIME [epoch: 8.31 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103376366305683		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.5103376366305683 | validation: 0.40263260817517926]
	TIME [epoch: 8.28 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4964650193288601		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.4964650193288601 | validation: 0.4051590719026745]
	TIME [epoch: 8.28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49058590644542976		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.49058590644542976 | validation: 0.6290071452736236]
	TIME [epoch: 8.28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6070689443358158		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.6070689443358158 | validation: 0.35386386939730874]
	TIME [epoch: 8.27 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302306066108723		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.5302306066108723 | validation: 0.5503854786548219]
	TIME [epoch: 8.28 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4930619843598173		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.4930619843598173 | validation: 0.6294417944681844]
	TIME [epoch: 8.33 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610367692866597		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.6610367692866597 | validation: 0.9414392458245724]
	TIME [epoch: 8.28 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7153013707506808		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.7153013707506808 | validation: 0.5324840562632983]
	TIME [epoch: 8.27 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976206746473887		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.4976206746473887 | validation: 0.44035039199790466]
	TIME [epoch: 8.28 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532524413798731		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.532524413798731 | validation: 0.5353784403909376]
	TIME [epoch: 8.27 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5984585330451814		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.5984585330451814 | validation: 0.38743740959192097]
	TIME [epoch: 8.31 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46805346582987967		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.46805346582987967 | validation: 0.5333889995394723]
	TIME [epoch: 8.29 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422128804704704		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.5422128804704704 | validation: 0.774080466753372]
	TIME [epoch: 8.28 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686688699937313		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.5686688699937313 | validation: 0.4453162917965381]
	TIME [epoch: 8.27 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47347399975825794		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.47347399975825794 | validation: 1.1102180205423346]
	TIME [epoch: 8.27 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5827189849446738		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.5827189849446738 | validation: 0.5398773499077982]
	TIME [epoch: 8.27 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652218182817032		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.4652218182817032 | validation: 0.6520521287114973]
	TIME [epoch: 8.31 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243430953024524		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.5243430953024524 | validation: 0.519175140967473]
	TIME [epoch: 8.27 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4715378005524906		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.4715378005524906 | validation: 0.6545384358898482]
	TIME [epoch: 8.27 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605591788206564		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.5605591788206564 | validation: 0.6121727292316954]
	TIME [epoch: 8.27 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523984019771002		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.4523984019771002 | validation: 0.7105075752598912]
	TIME [epoch: 8.27 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207248301039034		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.5207248301039034 | validation: 0.6106823442779421]
	TIME [epoch: 8.29 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600163490843266		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.5600163490843266 | validation: 0.6309066518099764]
	TIME [epoch: 8.29 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925675793601438		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.5925675793601438 | validation: 0.6139845061630421]
	TIME [epoch: 8.27 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234438035042908		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.5234438035042908 | validation: 1.0656715097832712]
	TIME [epoch: 8.27 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504020627120877		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.6504020627120877 | validation: 0.6921230453765455]
	TIME [epoch: 8.26 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078925016989237		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.5078925016989237 | validation: 0.4446693349858125]
	TIME [epoch: 8.27 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807850960452361		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.5807850960452361 | validation: 0.5025067224556538]
	TIME [epoch: 8.31 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317761854652837		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.5317761854652837 | validation: 0.6051777843438642]
	TIME [epoch: 8.27 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675472228892782		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.5675472228892782 | validation: 0.4780326714795925]
	TIME [epoch: 8.27 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945995262967863		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.4945995262967863 | validation: 0.45074293921539366]
	TIME [epoch: 8.27 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567785420569618		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.5567785420569618 | validation: 0.472124714516985]
	TIME [epoch: 8.27 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155592829842705		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.5155592829842705 | validation: 0.3393790516058782]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359215149317005		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.4359215149317005 | validation: 0.6493679964862269]
	TIME [epoch: 8.32 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835365133989739		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.5835365133989739 | validation: 0.6555144498380476]
	TIME [epoch: 8.27 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117143243479089		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.5117143243479089 | validation: 0.46458976146480835]
	TIME [epoch: 8.26 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046009281054238		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.5046009281054238 | validation: 0.40770394456456904]
	TIME [epoch: 8.27 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697758584100191		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.5697758584100191 | validation: 0.4807809633591685]
	TIME [epoch: 8.27 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846262964179195		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.5846262964179195 | validation: 0.2550673662285079]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240702_111815/states/model_phi1_1a_v_kl4_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687464139233604		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.4687464139233604 | validation: 0.3909079166624494]
	TIME [epoch: 8.28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45805370433428905		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.45805370433428905 | validation: 0.5181758089384878]
	TIME [epoch: 8.26 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47106025196191986		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.47106025196191986 | validation: 0.562455384116255]
	TIME [epoch: 8.27 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263159075056507		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.5263159075056507 | validation: 0.5608177293609297]
	TIME [epoch: 8.26 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342298675231298		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.5342298675231298 | validation: 0.5240834568948891]
	TIME [epoch: 8.27 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4790970266806328		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.4790970266806328 | validation: 0.5018869002606916]
	TIME [epoch: 8.31 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5982418206745769		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.5982418206745769 | validation: 0.42917194225776756]
	TIME [epoch: 8.27 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204844417782789		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.5204844417782789 | validation: 0.6298405353318273]
	TIME [epoch: 8.27 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48067177716286125		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.48067177716286125 | validation: 0.3609048530074489]
	TIME [epoch: 8.26 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261505481903983		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.5261505481903983 | validation: 0.4310301366944376]
	TIME [epoch: 8.27 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112900831875613		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.5112900831875613 | validation: 0.3798869606022851]
	TIME [epoch: 8.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40583709207283597		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.40583709207283597 | validation: 0.6046324514939887]
	TIME [epoch: 8.28 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48504500552948976		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.48504500552948976 | validation: 0.4925842494441396]
	TIME [epoch: 8.26 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45370008524348		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.45370008524348 | validation: 0.4358605835463779]
	TIME [epoch: 8.26 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48101152546325043		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.48101152546325043 | validation: 1.3034760781711316]
	TIME [epoch: 8.26 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585891199623796		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.6585891199623796 | validation: 0.6708934442573837]
	TIME [epoch: 8.27 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367083906235566		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.4367083906235566 | validation: 0.3593041789241495]
	TIME [epoch: 8.31 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49580774161041696		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.49580774161041696 | validation: 0.32279116848005585]
	TIME [epoch: 8.27 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49624299277135925		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.49624299277135925 | validation: 0.6610805843640065]
	TIME [epoch: 8.26 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4957470389195313		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.4957470389195313 | validation: 0.3421496177396412]
	TIME [epoch: 8.26 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4870606636077244		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.4870606636077244 | validation: 0.39662426286989055]
	TIME [epoch: 8.26 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510299106909111		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.510299106909111 | validation: 0.687595213018808]
	TIME [epoch: 8.29 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354749933433076		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.5354749933433076 | validation: 0.578200669644469]
	TIME [epoch: 8.28 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45125054343110665		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.45125054343110665 | validation: 0.5848471189955462]
	TIME [epoch: 8.27 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46481297448107617		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.46481297448107617 | validation: 0.44592182533228286]
	TIME [epoch: 8.27 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489312959357416		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.4489312959357416 | validation: 0.45673829397793586]
	TIME [epoch: 8.26 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662916782910469		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.5662916782910469 | validation: 0.4260367100096911]
	TIME [epoch: 8.26 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771272486206037		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.4771272486206037 | validation: 0.5013875639490499]
	TIME [epoch: 8.31 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658890875866487		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.4658890875866487 | validation: 0.465587210361411]
	TIME [epoch: 8.27 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621270744347607		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.4621270744347607 | validation: 0.45396893434984686]
	TIME [epoch: 8.26 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48526248038775066		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.48526248038775066 | validation: 0.3958453908669488]
	TIME [epoch: 8.26 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45915337048850613		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.45915337048850613 | validation: 0.5771205689267243]
	TIME [epoch: 8.27 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021782257843084		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.5021782257843084 | validation: 0.6209045027467008]
	TIME [epoch: 8.28 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088847242709384		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.5088847242709384 | validation: 0.3994515670893778]
	TIME [epoch: 8.29 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44708496545879706		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.44708496545879706 | validation: 0.44781324443806336]
	TIME [epoch: 8.26 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4229138332052565		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.4229138332052565 | validation: 0.4697480294974182]
	TIME [epoch: 8.26 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5436535578178259		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.5436535578178259 | validation: 0.41941833360679437]
	TIME [epoch: 8.26 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760279721983821		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.4760279721983821 | validation: 0.4258003632242604]
	TIME [epoch: 8.26 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36667705983628596		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.36667705983628596 | validation: 0.4402993734203924]
	TIME [epoch: 8.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39665161158505313		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.39665161158505313 | validation: 0.5798836910549692]
	TIME [epoch: 8.27 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805695766710015		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.4805695766710015 | validation: 0.5207158962579076]
	TIME [epoch: 8.25 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46499580859415657		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.46499580859415657 | validation: 0.36094860294348197]
	TIME [epoch: 8.26 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43415990709624486		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.43415990709624486 | validation: 0.8148544579996306]
	TIME [epoch: 8.26 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5504758041105012		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.5504758041105012 | validation: 0.5694738167886035]
	TIME [epoch: 8.27 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49479818309711243		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.49479818309711243 | validation: 0.5369829272437554]
	TIME [epoch: 8.29 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506628552820434		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.4506628552820434 | validation: 0.6362385696843192]
	TIME [epoch: 8.26 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423255686183246		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.4423255686183246 | validation: 0.37648377923432164]
	TIME [epoch: 8.26 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4256519350212683		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.4256519350212683 | validation: 0.3463325175762324]
	TIME [epoch: 8.25 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736526533597438		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.4736526533597438 | validation: 0.44957495538367587]
	TIME [epoch: 8.25 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014764231104966		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.5014764231104966 | validation: 0.42722521409809555]
	TIME [epoch: 8.29 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711943242106175		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.4711943242106175 | validation: 0.4157894238600973]
	TIME [epoch: 8.27 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153051913503321		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.5153051913503321 | validation: 0.34480702453495293]
	TIME [epoch: 8.25 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232822115934291		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.5232822115934291 | validation: 0.7801094774655972]
	TIME [epoch: 8.26 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955431481617108		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.5955431481617108 | validation: 0.27498262523388767]
	TIME [epoch: 8.26 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048161461931089		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.4048161461931089 | validation: 0.645779299753388]
	TIME [epoch: 8.25 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089101293645815		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.5089101293645815 | validation: 0.5384830177476692]
	TIME [epoch: 8.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47379332535094587		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.47379332535094587 | validation: 0.5104690598609669]
	TIME [epoch: 8.26 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148306861412365		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.4148306861412365 | validation: 0.31913298612978824]
	TIME [epoch: 8.26 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879507275829755		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.3879507275829755 | validation: 0.3140788972322979]
	TIME [epoch: 8.25 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787395105735696		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.3787395105735696 | validation: 0.38760698921252995]
	TIME [epoch: 8.25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760418413573418		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.4760418413573418 | validation: 0.750884402503718]
	TIME [epoch: 8.28 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977034172531945		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.4977034172531945 | validation: 0.387177263611462]
	TIME [epoch: 8.28 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463360688831659		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.5463360688831659 | validation: 0.4586674807128483]
	TIME [epoch: 8.25 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46319554768600524		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.46319554768600524 | validation: 0.3677845766436195]
	TIME [epoch: 8.25 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687330606384047		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.4687330606384047 | validation: 0.48957545070259906]
	TIME [epoch: 8.26 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45687527417868223		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.45687527417868223 | validation: 0.3070481274553351]
	TIME [epoch: 8.26 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269795275132593		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.3269795275132593 | validation: 0.8486913429746927]
	TIME [epoch: 8.29 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549166125618472		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.5549166125618472 | validation: 0.5246644015579548]
	TIME [epoch: 8.27 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41713495344605944		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.41713495344605944 | validation: 0.3384255098559242]
	TIME [epoch: 8.25 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48000438195948353		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.48000438195948353 | validation: 0.35653248740797133]
	TIME [epoch: 8.25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164760210884734		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.4164760210884734 | validation: 0.38506149462548056]
	TIME [epoch: 8.25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4040306963576464		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.4040306963576464 | validation: 0.42029549910946895]
	TIME [epoch: 8.26 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5568398856085046		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.5568398856085046 | validation: 0.4296663855430138]
	TIME [epoch: 8.29 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4390840417625906		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.4390840417625906 | validation: 0.48508885554705594]
	TIME [epoch: 8.25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47926685704422867		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.47926685704422867 | validation: 0.46023824703974753]
	TIME [epoch: 8.26 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317398214212037		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.5317398214212037 | validation: 0.474084027205972]
	TIME [epoch: 8.25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449537090189475		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.449537090189475 | validation: 0.4367988643146317]
	TIME [epoch: 8.25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127751723769761		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.5127751723769761 | validation: 0.4701220487335563]
	TIME [epoch: 8.29 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044124401524319		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.5044124401524319 | validation: 0.4916689574072618]
	TIME [epoch: 8.27 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955308491519739		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.3955308491519739 | validation: 1.2626825861484088]
	TIME [epoch: 8.25 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941323088469708		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.5941323088469708 | validation: 0.41216013748127867]
	TIME [epoch: 8.25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489628095401358		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.3489628095401358 | validation: 0.3538021986136515]
	TIME [epoch: 8.26 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45313119202629615		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.45313119202629615 | validation: 0.3190810707283397]
	TIME [epoch: 8.26 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657519635283864		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.3657519635283864 | validation: 0.36403767801656295]
	TIME [epoch: 8.29 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508882471172412		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.3508882471172412 | validation: 0.4414178322012683]
	TIME [epoch: 8.25 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40247536877531376		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.40247536877531376 | validation: 0.34133545799819714]
	TIME [epoch: 8.26 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48124045850291824		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.48124045850291824 | validation: 0.3602453943915569]
	TIME [epoch: 8.25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43748246914029065		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.43748246914029065 | validation: 0.6736133756660891]
	TIME [epoch: 8.25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5363136650855151		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.5363136650855151 | validation: 0.8339441257142448]
	TIME [epoch: 8.27 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733700265049541		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.5733700265049541 | validation: 0.34215645023306873]
	TIME [epoch: 8.28 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44931390451365094		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.44931390451365094 | validation: 0.5680216571605634]
	TIME [epoch: 8.25 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4742602785291793		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.4742602785291793 | validation: 0.4492685147521888]
	TIME [epoch: 8.25 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3985245902820591		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.3985245902820591 | validation: 0.5533123052543129]
	TIME [epoch: 8.25 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42393242570938106		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.42393242570938106 | validation: 0.43516851381083516]
	TIME [epoch: 8.25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173418500193423		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.5173418500193423 | validation: 0.4572170623034023]
	TIME [epoch: 8.29 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532734850858241		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.4532734850858241 | validation: 0.35283838495881803]
	TIME [epoch: 8.26 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892141030032291		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.3892141030032291 | validation: 0.2660778026909366]
	TIME [epoch: 8.25 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3578039695653513		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.3578039695653513 | validation: 0.3587272620355575]
	TIME [epoch: 8.25 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997463373329852		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.3997463373329852 | validation: 0.5440013053954721]
	TIME [epoch: 8.25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215364423233682		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.4215364423233682 | validation: 0.7146171465484819]
	TIME [epoch: 8.26 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934931984796335		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.4934931984796335 | validation: 0.506296573723168]
	TIME [epoch: 8.29 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576096023312194		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.3576096023312194 | validation: 0.5067793602935814]
	TIME [epoch: 8.26 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021852396527044		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.4021852396527044 | validation: 0.30090502323978674]
	TIME [epoch: 8.25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.564702907591512		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.564702907591512 | validation: 0.6718872922202204]
	TIME [epoch: 8.26 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135035496998686		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.5135035496998686 | validation: 0.3924676964246726]
	TIME [epoch: 8.25 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923297477994554		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.5923297477994554 | validation: 0.46164398357765035]
	TIME [epoch: 8.29 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4107569763201275		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.4107569763201275 | validation: 0.3353845072171494]
	TIME [epoch: 8.26 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3752962544779544		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.3752962544779544 | validation: 0.6374293392412358]
	TIME [epoch: 8.26 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107854789141768		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.5107854789141768 | validation: 0.5024922967381751]
	TIME [epoch: 8.25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213019290300928		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.4213019290300928 | validation: 0.49140383278246813]
	TIME [epoch: 8.25 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46189164152615736		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.46189164152615736 | validation: 0.28698727778000893]
	TIME [epoch: 8.26 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3266154841651189		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.3266154841651189 | validation: 0.36515225240851046]
	TIME [epoch: 8.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39613871386270144		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.39613871386270144 | validation: 0.5002279901565644]
	TIME [epoch: 8.26 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45482764177697454		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.45482764177697454 | validation: 0.33351334696742857]
	TIME [epoch: 8.25 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38302636337353735		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.38302636337353735 | validation: 0.46818864733211013]
	TIME [epoch: 8.26 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449313115485806		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.449313115485806 | validation: 0.6706962452141272]
	TIME [epoch: 8.25 sec]
EPOCH 1040/2000:
	Training over batches...
ERROR:
!!! UPDATED MODEL HAS NAN VALUES IN PHI.W[0] !!!
