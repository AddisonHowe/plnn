Args:
Namespace(name='model_phi1_4b_v_mmd1', outdir='out/model_training/model_phi1_4b_v_mmd1', training_data='data/training_data/data_phi1_4b/training', validation_data='data/training_data/data_phi1_4b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2210634969

Training model...

Saving initial model state to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.760918032600783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.760918032600783 | validation: 6.557412447767601]
	TIME [epoch: 44.7 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.709431697237618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.709431697237618 | validation: 6.467189485318613]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.5636760508323775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5636760508323775 | validation: 5.741195389538989]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.7790355477060045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7790355477060045 | validation: 6.0702029771013954]
	TIME [epoch: 1.81 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.155049945713191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.155049945713191 | validation: 6.975823577573343]
	TIME [epoch: 1.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 7.122188362094355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.122188362094355 | validation: 6.878114715555903]
	TIME [epoch: 1.8 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.960399283955428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.960399283955428 | validation: 4.9976083106329305]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.130880638750155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.130880638750155 | validation: 5.356433444897466]
	TIME [epoch: 1.81 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.233294500666837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.233294500666837 | validation: 4.653541884205275]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.60912966216567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.60912966216567 | validation: 4.647456090418016]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.692826977368511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.692826977368511 | validation: 5.07478710508466]
	TIME [epoch: 1.81 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.788995115470532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.788995115470532 | validation: 4.417107130437202]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.538727796072963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.538727796072963 | validation: 4.411613876421509]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.484323192239928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.484323192239928 | validation: 4.335962856213534]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.310708271455218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.310708271455218 | validation: 4.308607929982483]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.241723520298771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.241723520298771 | validation: 4.352064351675141]
	TIME [epoch: 1.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.223983280430759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.223983280430759 | validation: 4.1886841635053464]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.186116441745819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.186116441745819 | validation: 4.331702258945345]
	TIME [epoch: 1.81 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.263542451477482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.263542451477482 | validation: 4.242462654483396]
	TIME [epoch: 1.82 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.254534419541643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.254534419541643 | validation: 4.298461424091261]
	TIME [epoch: 1.82 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.209093738393341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.209093738393341 | validation: 4.107519843326862]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.0905877458895645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0905877458895645 | validation: 4.0991329348589325]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.040459994541802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.040459994541802 | validation: 4.049979080352979]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.016254681247212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.016254681247212 | validation: 4.0764763842450575]
	TIME [epoch: 1.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.012738151394758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.012738151394758 | validation: 4.07399753200546]
	TIME [epoch: 1.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.039856072133451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.039856072133451 | validation: 4.198054286921044]
	TIME [epoch: 1.81 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.123320067631491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.123320067631491 | validation: 4.0460285196284325]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.012586036081835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.012586036081835 | validation: 4.008135204434386]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9535904899461434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9535904899461434 | validation: 3.9454198189318435]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.915167025944701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.915167025944701 | validation: 3.959521439006605]
	TIME [epoch: 1.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.900204754612902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.900204754612902 | validation: 3.943810371064663]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.906438109318322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.906438109318322 | validation: 4.005973946761919]
	TIME [epoch: 1.81 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9384429398182106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9384429398182106 | validation: 3.959340188455893]
	TIME [epoch: 1.79 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.925589272877145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.925589272877145 | validation: 3.969211164145446]
	TIME [epoch: 1.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8986406940570615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8986406940570615 | validation: 3.8670827976448665]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8297887044732897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8297887044732897 | validation: 3.8469571724957308]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.795208408359645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.795208408359645 | validation: 3.802985566697284]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.766304663374783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.766304663374783 | validation: 3.824272123111296]
	TIME [epoch: 1.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7613879893555895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7613879893555895 | validation: 3.832944008080911]
	TIME [epoch: 1.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.794801095481819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.794801095481819 | validation: 3.928238439992052]
	TIME [epoch: 1.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8350024107463376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8350024107463376 | validation: 3.826164513761265]
	TIME [epoch: 1.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7871856132179547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7871856132179547 | validation: 3.7792766054006286]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7098449977812518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7098449977812518 | validation: 3.727913757209202]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.671658640462856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.671658640462856 | validation: 3.714181756260701]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.668921671148603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.668921671148603 | validation: 3.7239343930431987]
	TIME [epoch: 1.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.657472277987256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.657472277987256 | validation: 3.6867650547297046]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.650547692831541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.650547692831541 | validation: 3.6680878297721793]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6091928991386113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6091928991386113 | validation: 3.629104578519456]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5854241659933064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5854241659933064 | validation: 3.618710962789182]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5875246607421194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5875246607421194 | validation: 4.108605615197896]
	TIME [epoch: 1.81 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.001574191406477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.001574191406477 | validation: 3.9004573915341845]
	TIME [epoch: 1.81 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.889060852301586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.889060852301586 | validation: 3.7083466534909437]
	TIME [epoch: 1.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6846728327263096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6846728327263096 | validation: 3.617732633166103]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.551477745481886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.551477745481886 | validation: 3.6327464970035495]
	TIME [epoch: 1.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5644991765810845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5644991765810845 | validation: 3.575347961034119]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5129904870648216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5129904870648216 | validation: 3.547448877076153]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5013249320092736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5013249320092736 | validation: 3.546745374110364]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.475151691639886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.475151691639886 | validation: 3.535885202976168]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.462110329300496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.462110329300496 | validation: 3.5125469791344637]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4435752952921486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4435752952921486 | validation: 3.482870129950342]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.434718701673629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.434718701673629 | validation: 3.4818861389961073]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4198873434820083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4198873434820083 | validation: 3.4722189788168722]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4168735491338142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4168735491338142 | validation: 3.519008394868031]
	TIME [epoch: 1.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4560102727194058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4560102727194058 | validation: 3.643592752059965]
	TIME [epoch: 1.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6146687345793316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6146687345793316 | validation: 3.73022313737635]
	TIME [epoch: 1.81 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.664816148836889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.664816148836889 | validation: 3.434880753683516]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.383068605666626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.383068605666626 | validation: 3.5043271993691714]
	TIME [epoch: 1.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4831068501727023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4831068501727023 | validation: 3.57247457106506]
	TIME [epoch: 1.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4746503449727055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4746503449727055 | validation: 3.383924042114138]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.347820368276497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.347820368276497 | validation: 3.3976549102704925]
	TIME [epoch: 1.82 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3560743165522866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3560743165522866 | validation: 3.427101686676612]
	TIME [epoch: 1.81 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3596017967558063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3596017967558063 | validation: 3.362712117040978]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.315945753593782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.315945753593782 | validation: 3.358168728888538]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.295201700327805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.295201700327805 | validation: 3.340973964918972]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2844105749697428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2844105749697428 | validation: 3.3256698518183416]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2747416295747764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2747416295747764 | validation: 3.332966664975534]
	TIME [epoch: 1.81 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.272900649774289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.272900649774289 | validation: 3.3163371205540444]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2994404462579996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2994404462579996 | validation: 3.4669104136255187]
	TIME [epoch: 1.81 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3816505311552802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3816505311552802 | validation: 3.384682308757265]
	TIME [epoch: 1.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.389875863475552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.389875863475552 | validation: 3.3018451817528347]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2803112677116317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2803112677116317 | validation: 3.2970306530954674]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2414142315944345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2414142315944345 | validation: 3.2705662366691373]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.247661219705068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.247661219705068 | validation: 3.266087033847152]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.234640428891068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.234640428891068 | validation: 3.239351263163931]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.213096814486554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.213096814486554 | validation: 3.2527587764457753]
	TIME [epoch: 1.81 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.196085987080112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.196085987080112 | validation: 3.2037691519146834]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1910390226659207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1910390226659207 | validation: 3.232546915589221]
	TIME [epoch: 1.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1830374000829695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1830374000829695 | validation: 3.1915972965123496]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1772645828058854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1772645828058854 | validation: 3.2543571574202583]
	TIME [epoch: 1.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2112407985342686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2112407985342686 | validation: 3.3879341697027856]
	TIME [epoch: 1.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4056644713129005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4056644713129005 | validation: 3.3631032433042933]
	TIME [epoch: 1.82 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3095475678713515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3095475678713515 | validation: 3.2026459305225963]
	TIME [epoch: 1.81 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.167017218864955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.167017218864955 | validation: 3.2296179767517965]
	TIME [epoch: 1.81 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2196186738758543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2196186738758543 | validation: 3.1877559628014605]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1570553614368304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1570553614368304 | validation: 3.151363104539945]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1251366664227316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1251366664227316 | validation: 3.1431727831351752]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1346225105848977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1346225105848977 | validation: 3.1331897570813947]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1109608689019694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1109608689019694 | validation: 3.0998081408124833]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.094689627619114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.094689627619114 | validation: 3.079776136056644]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0769985570627263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0769985570627263 | validation: 3.069960621335303]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.051061575988945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.051061575988945 | validation: 3.0119363146750766]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.001335450020789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.001335450020789 | validation: 2.857366754049606]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8761172595493103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8761172595493103 | validation: 2.4876677927499764]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.530435202605695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.530435202605695 | validation: 2.0711518665249513]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.072142977757469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.072142977757469 | validation: 1.8354217209317039]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8140034494310822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8140034494310822 | validation: 1.6060677072230671]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5343276601582192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5343276601582192 | validation: 1.4541543274151207]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3854161999757852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3854161999757852 | validation: 1.387561493452557]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.431129413409616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.431129413409616 | validation: 1.317090062077129]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2296463575367182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2296463575367182 | validation: 1.3917228726117667]
	TIME [epoch: 1.81 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2471182057862162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2471182057862162 | validation: 1.1780668213677843]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.228235647176013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.228235647176013 | validation: 1.0846545740573432]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0657143595440872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0657143595440872 | validation: 1.1836949099864105]
	TIME [epoch: 1.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0420530452937338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0420530452937338 | validation: 1.0121803546144197]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9532062039646644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9532062039646644 | validation: 0.9694381833425638]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9294171240172173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9294171240172173 | validation: 1.0253830765948482]
	TIME [epoch: 1.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9229404157980645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9229404157980645 | validation: 0.980106941611222]
	TIME [epoch: 1.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9046567833095052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9046567833095052 | validation: 0.9597552428470547]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8930690217478278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8930690217478278 | validation: 0.9642544515015827]
	TIME [epoch: 1.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.888066468340895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.888066468340895 | validation: 0.9598542842063695]
	TIME [epoch: 1.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8989007623892422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8989007623892422 | validation: 1.0004916628256468]
	TIME [epoch: 1.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9269040564617791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9269040564617791 | validation: 1.0337388141324826]
	TIME [epoch: 1.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9314839203163154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9314839203163154 | validation: 0.9918343796913041]
	TIME [epoch: 1.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.932574999920912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.932574999920912 | validation: 0.9393503162819216]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8540945918109923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8540945918109923 | validation: 0.9674760862512027]
	TIME [epoch: 1.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8413162622859649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8413162622859649 | validation: 0.8857678475670469]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8335030686894954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8335030686894954 | validation: 0.9145666013787391]
	TIME [epoch: 1.79 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8208625132935808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8208625132935808 | validation: 0.8978052597610162]
	TIME [epoch: 1.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8387021086580073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8387021086580073 | validation: 0.9625246497043567]
	TIME [epoch: 1.79 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8677822592434628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8677822592434628 | validation: 1.0043188110748893]
	TIME [epoch: 1.79 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9366325794153187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9366325794153187 | validation: 0.9996857663381763]
	TIME [epoch: 1.79 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8814939682227717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8814939682227717 | validation: 0.9320447547355482]
	TIME [epoch: 1.79 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8430528256277441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8430528256277441 | validation: 0.9287858126507186]
	TIME [epoch: 1.81 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7947531801561653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7947531801561653 | validation: 0.8457143940925378]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.799627490673405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.799627490673405 | validation: 0.9287232243098789]
	TIME [epoch: 1.81 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8059621866498106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8059621866498106 | validation: 0.8385576237198449]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8108273138685289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8108273138685289 | validation: 0.9766528739419222]
	TIME [epoch: 1.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8141526333054578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8141526333054578 | validation: 0.8507636955898562]
	TIME [epoch: 1.79 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7895282733874598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7895282733874598 | validation: 0.9034671378491871]
	TIME [epoch: 1.79 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7783376047422778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7783376047422778 | validation: 0.8538160060029085]
	TIME [epoch: 1.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.783368925424184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.783368925424184 | validation: 0.9552028067025322]
	TIME [epoch: 1.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8679243882330596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8679243882330596 | validation: 1.1823174321474985]
	TIME [epoch: 1.79 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0454278758854805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0454278758854805 | validation: 1.0563776893423218]
	TIME [epoch: 1.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9688148480885506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9688148480885506 | validation: 0.8992560352323017]
	TIME [epoch: 1.79 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7655287171292929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7655287171292929 | validation: 0.9284306761858758]
	TIME [epoch: 1.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8253348761009994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8253348761009994 | validation: 0.9514992058526636]
	TIME [epoch: 1.79 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8457320421119812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8457320421119812 | validation: 0.8546483637716922]
	TIME [epoch: 1.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7730344367634743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7730344367634743 | validation: 0.8844962885413268]
	TIME [epoch: 1.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7543778083776745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7543778083776745 | validation: 0.842442825225178]
	TIME [epoch: 1.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7575656719773426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7575656719773426 | validation: 0.8567132899750262]
	TIME [epoch: 1.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7541271947159685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7541271947159685 | validation: 0.884113873409082]
	TIME [epoch: 1.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7604262080490479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7604262080490479 | validation: 0.884250098805528]
	TIME [epoch: 1.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7714959703204382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7714959703204382 | validation: 0.935242125163478]
	TIME [epoch: 1.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8196883976245438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8196883976245438 | validation: 1.0911460723936182]
	TIME [epoch: 1.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9026030385863633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9026030385863633 | validation: 1.0052425838157366]
	TIME [epoch: 1.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9180984513465749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9180984513465749 | validation: 0.8486539665462763]
	TIME [epoch: 1.79 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7693642859056579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7693642859056579 | validation: 1.1432464742559343]
	TIME [epoch: 1.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8360619688535106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8360619688535106 | validation: 0.8646415719913625]
	TIME [epoch: 1.81 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8452724289816916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8452724289816916 | validation: 0.8972323973153058]
	TIME [epoch: 1.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.744421399453976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.744421399453976 | validation: 0.9409994229072347]
	TIME [epoch: 1.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7678458389717934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7678458389717934 | validation: 0.8589818042108569]
	TIME [epoch: 1.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7843564444072209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7843564444072209 | validation: 0.8761871205908925]
	TIME [epoch: 1.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7524135378331653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7524135378331653 | validation: 0.9182173967368776]
	TIME [epoch: 1.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7590072954631566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7590072954631566 | validation: 0.8712409965052693]
	TIME [epoch: 1.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.797608263419806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.797608263419806 | validation: 1.0377237764867686]
	TIME [epoch: 1.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8768865609531712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8768865609531712 | validation: 0.9724889226572142]
	TIME [epoch: 1.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8102348493942695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8102348493942695 | validation: 0.8843428655271238]
	TIME [epoch: 1.79 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7871166228613414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7871166228613414 | validation: 0.9147015884362674]
	TIME [epoch: 1.79 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.739072199735615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.739072199735615 | validation: 0.8573626340342012]
	TIME [epoch: 1.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7311041595443598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7311041595443598 | validation: 0.8385289722633481]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7457179190138595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7457179190138595 | validation: 0.9316408051576318]
	TIME [epoch: 1.81 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7669468819738127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7669468819738127 | validation: 0.9181311983297562]
	TIME [epoch: 1.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8142985496893469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8142985496893469 | validation: 0.9389649226213352]
	TIME [epoch: 1.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8398529240401778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8398529240401778 | validation: 1.0716366309226686]
	TIME [epoch: 1.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8755814831661819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8755814831661819 | validation: 0.8635564863397387]
	TIME [epoch: 1.79 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7468601825064239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7468601825064239 | validation: 0.8457128988428897]
	TIME [epoch: 1.81 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7265428572259728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7265428572259728 | validation: 0.9504136541308178]
	TIME [epoch: 1.79 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7411867239973299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7411867239973299 | validation: 0.8052807981861284]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7506771720676174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7506771720676174 | validation: 0.9873669824376672]
	TIME [epoch: 1.79 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7554037035490409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7554037035490409 | validation: 0.8044672017037696]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7402951457957586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7402951457957586 | validation: 0.8806675904945064]
	TIME [epoch: 1.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7270682820749832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7270682820749832 | validation: 0.8720548110262923]
	TIME [epoch: 1.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7573829147203927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7573829147203927 | validation: 0.9737326361858781]
	TIME [epoch: 1.82 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8854595148558534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8854595148558534 | validation: 1.1414068494054752]
	TIME [epoch: 1.81 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0160111199188684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0160111199188684 | validation: 0.9211829521731159]
	TIME [epoch: 1.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7410962903066556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7410962903066556 | validation: 0.8250268918242849]
	TIME [epoch: 1.81 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7545944799578654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7545944799578654 | validation: 0.9712960539608073]
	TIME [epoch: 1.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7697943856500551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7697943856500551 | validation: 0.861726280808219]
	TIME [epoch: 1.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7284774094688825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7284774094688825 | validation: 0.8095318387314301]
	TIME [epoch: 1.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7404941330500242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7404941330500242 | validation: 0.9668611693311515]
	TIME [epoch: 1.82 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7510264410122426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7510264410122426 | validation: 0.8310336582192372]
	TIME [epoch: 1.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7625201766031066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7625201766031066 | validation: 0.9306589811834087]
	TIME [epoch: 1.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7517477617535565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7517477617535565 | validation: 0.9197989898093337]
	TIME [epoch: 1.79 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7999309486567748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7999309486567748 | validation: 0.891174958834144]
	TIME [epoch: 1.81 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8041059705697532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8041059705697532 | validation: 0.958113803285011]
	TIME [epoch: 1.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7941051504208789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7941051504208789 | validation: 0.8340351660707516]
	TIME [epoch: 1.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7245700939874589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7245700939874589 | validation: 0.838742007626291]
	TIME [epoch: 1.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6995895641589351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6995895641589351 | validation: 0.7843186915781687]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7012629433935942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7012629433935942 | validation: 0.8742779319266554]
	TIME [epoch: 1.79 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7113474353968269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7113474353968269 | validation: 0.8155296543048982]
	TIME [epoch: 1.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7549113167112261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7549113167112261 | validation: 1.2309022594019219]
	TIME [epoch: 44.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8786642742655709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8786642742655709 | validation: 0.9550142831875086]
	TIME [epoch: 3.58 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8808189647223573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8808189647223573 | validation: 0.8127432599052805]
	TIME [epoch: 3.57 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7314606578327968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7314606578327968 | validation: 1.1907335116669069]
	TIME [epoch: 3.56 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8314978160563206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8314978160563206 | validation: 0.7946067501338325]
	TIME [epoch: 3.56 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7298369690891133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7298369690891133 | validation: 0.8211405425177745]
	TIME [epoch: 3.56 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6950419313581983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6950419313581983 | validation: 0.8465992560142797]
	TIME [epoch: 3.57 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6987274288524296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6987274288524296 | validation: 0.8189382744648311]
	TIME [epoch: 3.58 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7046455953504819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7046455953504819 | validation: 0.8317155867627672]
	TIME [epoch: 3.57 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.743190055468919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.743190055468919 | validation: 1.0159749178955562]
	TIME [epoch: 3.57 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8547521212195506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8547521212195506 | validation: 0.8826328232104024]
	TIME [epoch: 3.56 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8112788246047512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8112788246047512 | validation: 0.9339043682684619]
	TIME [epoch: 3.57 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7434545216089987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7434545216089987 | validation: 0.865332908135962]
	TIME [epoch: 3.57 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6896413331512175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6896413331512175 | validation: 0.7829137428403755]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6751813043897112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6751813043897112 | validation: 0.8174519865940045]
	TIME [epoch: 3.58 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6759624594898236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6759624594898236 | validation: 0.7524295692571887]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6706686577955326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6706686577955326 | validation: 0.825329197490936]
	TIME [epoch: 3.57 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6787682290916993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6787682290916993 | validation: 0.7876573293260967]
	TIME [epoch: 3.57 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7225685710410992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7225685710410992 | validation: 1.094265221220401]
	TIME [epoch: 3.55 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9640265827706455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9640265827706455 | validation: 1.2857932327900365]
	TIME [epoch: 3.56 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9250042906091736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9250042906091736 | validation: 0.8659959242906586]
	TIME [epoch: 3.55 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8298484283654868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8298484283654868 | validation: 0.9215323344466478]
	TIME [epoch: 3.57 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7000562371093687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7000562371093687 | validation: 1.0166983741920406]
	TIME [epoch: 3.57 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7383432162145219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7383432162145219 | validation: 0.7804777405153929]
	TIME [epoch: 3.57 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7157194024186003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7157194024186003 | validation: 0.7845469156594613]
	TIME [epoch: 3.57 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6640584525475381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6640584525475381 | validation: 0.7673481878658052]
	TIME [epoch: 3.56 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6594117777856717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6594117777856717 | validation: 0.7702902171440746]
	TIME [epoch: 3.56 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6638249218663405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6638249218663405 | validation: 0.7463903694181943]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6888433708234242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6888433708234242 | validation: 0.9311830539441976]
	TIME [epoch: 3.56 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7758259100807101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7758259100807101 | validation: 0.8757542954677249]
	TIME [epoch: 3.54 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7930063421875212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7930063421875212 | validation: 0.9095268769380536]
	TIME [epoch: 3.54 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7661800361750887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7661800361750887 | validation: 0.9583720899406996]
	TIME [epoch: 3.54 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6954621784566856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6954621784566856 | validation: 0.7363169227439414]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6855014414330802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6855014414330802 | validation: 0.8412635524552716]
	TIME [epoch: 3.55 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6670720396616322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6670720396616322 | validation: 0.6876513647040386]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6627706297920127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6627706297920127 | validation: 0.7843274465884877]
	TIME [epoch: 3.58 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6471665887074163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6471665887074163 | validation: 0.6974228560690272]
	TIME [epoch: 3.58 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6612488286953047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6612488286953047 | validation: 1.062389922838084]
	TIME [epoch: 3.57 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7319987679140653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7319987679140653 | validation: 0.8001777249402361]
	TIME [epoch: 3.57 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8078484794831506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8078484794831506 | validation: 0.9695602563868171]
	TIME [epoch: 3.58 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6861078834977192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6861078834977192 | validation: 0.9411193727388455]
	TIME [epoch: 3.57 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7118871353696384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7118871353696384 | validation: 0.7909026294202783]
	TIME [epoch: 3.56 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.779718911532761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.779718911532761 | validation: 0.9512305751901793]
	TIME [epoch: 3.57 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.76946671444069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.76946671444069 | validation: 0.9391983437887461]
	TIME [epoch: 3.56 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6842019743874819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6842019743874819 | validation: 0.7318769260259362]
	TIME [epoch: 3.59 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6606011332496624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6606011332496624 | validation: 0.785453516495942]
	TIME [epoch: 3.58 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6270691235929462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6270691235929462 | validation: 0.7354456941578309]
	TIME [epoch: 3.58 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6260107340733412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6260107340733412 | validation: 0.7188792671650854]
	TIME [epoch: 3.59 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6150907464261007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6150907464261007 | validation: 0.7573968164450848]
	TIME [epoch: 3.58 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6146359746113016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6146359746113016 | validation: 0.7331304514575928]
	TIME [epoch: 3.58 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6577517322886743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6577517322886743 | validation: 1.19410995714519]
	TIME [epoch: 3.58 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9161495436729824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9161495436729824 | validation: 1.115501481657133]
	TIME [epoch: 3.58 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9592223517660179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9592223517660179 | validation: 0.7802629904966006]
	TIME [epoch: 3.55 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6610647244501697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6610647244501697 | validation: 0.9697952660629299]
	TIME [epoch: 3.58 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6635721529880205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6635721529880205 | validation: 0.8143644927230904]
	TIME [epoch: 3.58 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.662074592956609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.662074592956609 | validation: 0.7097511615417021]
	TIME [epoch: 3.57 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6208410123402333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6208410123402333 | validation: 0.786188817240765]
	TIME [epoch: 3.57 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.626717410747879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.626717410747879 | validation: 0.6448763875310557]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.62712759316768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.62712759316768 | validation: 0.8595893542059854]
	TIME [epoch: 3.56 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6319149046888933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6319149046888933 | validation: 0.6702654521871522]
	TIME [epoch: 3.55 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6392593128136117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6392593128136117 | validation: 0.8762692620160737]
	TIME [epoch: 3.57 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6410686317110103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6410686317110103 | validation: 0.6634298757495578]
	TIME [epoch: 3.57 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6336825059983431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6336825059983431 | validation: 0.8215650844325545]
	TIME [epoch: 3.55 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6181607541986652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6181607541986652 | validation: 0.6639562868653753]
	TIME [epoch: 3.55 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5957082442316642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5957082442316642 | validation: 0.8777859595628507]
	TIME [epoch: 3.55 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6149919069106539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6149919069106539 | validation: 0.792900847235503]
	TIME [epoch: 3.55 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.731207603630337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.731207603630337 | validation: 1.2841162626226268]
	TIME [epoch: 3.56 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0040714249926557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0040714249926557 | validation: 1.0993260936198386]
	TIME [epoch: 3.56 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7656318295811584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7656318295811584 | validation: 0.7479041057705702]
	TIME [epoch: 3.56 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6339676218410835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6339676218410835 | validation: 0.7391923831376973]
	TIME [epoch: 3.54 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6378244633614011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6378244633614011 | validation: 0.857152217403132]
	TIME [epoch: 3.56 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6732955847504428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6732955847504428 | validation: 0.6459583707092524]
	TIME [epoch: 3.55 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5977435083084156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5977435083084156 | validation: 0.6484246843229756]
	TIME [epoch: 3.57 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5728731003050304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5728731003050304 | validation: 0.7514350389953764]
	TIME [epoch: 3.57 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5820342734627881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5820342734627881 | validation: 0.6588333970763235]
	TIME [epoch: 3.56 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5692861794927125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5692861794927125 | validation: 0.754443166333541]
	TIME [epoch: 3.54 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5729896489297522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5729896489297522 | validation: 0.707112898922911]
	TIME [epoch: 3.57 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6389086756323578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6389086756323578 | validation: 1.192715470473317]
	TIME [epoch: 3.55 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8541753966901677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8541753966901677 | validation: 0.8678546426827431]
	TIME [epoch: 3.55 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6962687938308616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6962687938308616 | validation: 0.6532566049178905]
	TIME [epoch: 3.56 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6122970476560442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6122970476560442 | validation: 0.7801326212263988]
	TIME [epoch: 3.56 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5644243688499591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5644243688499591 | validation: 0.6716871514192193]
	TIME [epoch: 3.56 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5512302274487358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5512302274487358 | validation: 0.6017098982346449]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.558098062730484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.558098062730484 | validation: 0.8346510228314687]
	TIME [epoch: 3.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6554857551975816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6554857551975816 | validation: 0.7369974023974099]
	TIME [epoch: 3.56 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7281395115530882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7281395115530882 | validation: 0.8105864716702152]
	TIME [epoch: 3.57 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6650668003279654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6650668003279654 | validation: 1.0368075467048194]
	TIME [epoch: 3.58 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6325328289737331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6325328289737331 | validation: 0.5840613806614362]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5691007366579784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5691007366579784 | validation: 0.6555839282468873]
	TIME [epoch: 3.56 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5594128545805379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5594128545805379 | validation: 0.730975399373555]
	TIME [epoch: 3.56 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5653892293071515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5653892293071515 | validation: 0.6753848095432138]
	TIME [epoch: 3.56 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5788281222190809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5788281222190809 | validation: 0.8503570354281802]
	TIME [epoch: 3.55 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6190868349680089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6190868349680089 | validation: 0.8988359151607295]
	TIME [epoch: 3.55 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6187960086256311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6187960086256311 | validation: 0.5867212962762872]
	TIME [epoch: 3.55 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5797373937808533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5797373937808533 | validation: 0.7563704235572914]
	TIME [epoch: 3.56 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5268019019223504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5268019019223504 | validation: 0.5771590850998084]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5083713951063699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5083713951063699 | validation: 0.7317934386019354]
	TIME [epoch: 3.55 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.507325073158425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.507325073158425 | validation: 0.6003942682717377]
	TIME [epoch: 3.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5519368987593862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5519368987593862 | validation: 1.1301797731026997]
	TIME [epoch: 3.57 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6719591268909056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6719591268909056 | validation: 0.6784721916684935]
	TIME [epoch: 3.57 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5604192803166411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5604192803166411 | validation: 0.6035000560465948]
	TIME [epoch: 3.56 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5356426961072712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5356426961072712 | validation: 0.8974437422534894]
	TIME [epoch: 3.56 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6669068442527818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6669068442527818 | validation: 0.5754434745590035]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5987956650969519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5987956650969519 | validation: 0.7012226449726635]
	TIME [epoch: 3.56 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5308783208207283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5308783208207283 | validation: 0.8395627046464935]
	TIME [epoch: 3.56 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5183494791398542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5183494791398542 | validation: 0.5953606627265623]
	TIME [epoch: 3.57 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45396671879633477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45396671879633477 | validation: 0.5763454439818831]
	TIME [epoch: 3.55 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4321858514124869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4321858514124869 | validation: 0.6260156941140832]
	TIME [epoch: 3.56 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4345607837436238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4345607837436238 | validation: 0.5740311747574823]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.445621287002051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.445621287002051 | validation: 1.0764243316477717]
	TIME [epoch: 3.55 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.58877981200723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.58877981200723 | validation: 0.5600269366551456]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5721002614072139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5721002614072139 | validation: 0.847742919736906]
	TIME [epoch: 3.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4953517587034088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4953517587034088 | validation: 0.6339539742382938]
	TIME [epoch: 3.57 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.548862972085646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.548862972085646 | validation: 0.9369816673504442]
	TIME [epoch: 3.58 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8259551720160075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8259551720160075 | validation: 0.8964564427537547]
	TIME [epoch: 3.58 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5362019088253834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5362019088253834 | validation: 0.8559047493240008]
	TIME [epoch: 3.56 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4891697068200766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4891697068200766 | validation: 0.6880688714041999]
	TIME [epoch: 3.56 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43623281778891276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43623281778891276 | validation: 0.48210087215536657]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4435742137575104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4435742137575104 | validation: 0.8344175308487523]
	TIME [epoch: 3.56 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5043662069323855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5043662069323855 | validation: 0.49051688341391264]
	TIME [epoch: 3.57 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4713683084161353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4713683084161353 | validation: 0.6467502527483968]
	TIME [epoch: 3.55 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39369752588989204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39369752588989204 | validation: 0.5873520474015729]
	TIME [epoch: 3.56 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36275134773898443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36275134773898443 | validation: 0.5248533377057093]
	TIME [epoch: 3.56 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37546589465544883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37546589465544883 | validation: 0.762112782713467]
	TIME [epoch: 3.57 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4021523365466048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4021523365466048 | validation: 0.48667658207155634]
	TIME [epoch: 3.58 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3780271723752111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3780271723752111 | validation: 0.7374211359714478]
	TIME [epoch: 3.57 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4115280471957631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4115280471957631 | validation: 0.4505214498686277]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5905964847336092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5905964847336092 | validation: 0.8017423213722499]
	TIME [epoch: 3.57 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46591884510487014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46591884510487014 | validation: 0.5629541712586612]
	TIME [epoch: 3.56 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3722187491360211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3722187491360211 | validation: 0.5997310129792423]
	TIME [epoch: 3.56 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4239295255942351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4239295255942351 | validation: 0.7484192219603117]
	TIME [epoch: 3.56 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4787695373800881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4787695373800881 | validation: 0.7045300052045722]
	TIME [epoch: 3.56 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3777119630340366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3777119630340366 | validation: 0.4648502406669202]
	TIME [epoch: 3.56 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38720211494742324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38720211494742324 | validation: 0.8598299515893104]
	TIME [epoch: 3.56 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4702261085828245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4702261085828245 | validation: 0.4643958415317171]
	TIME [epoch: 3.56 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4604311379446898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4604311379446898 | validation: 0.6072029156153722]
	TIME [epoch: 3.56 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3124818186179882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3124818186179882 | validation: 0.545296791314727]
	TIME [epoch: 3.57 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2980077917374055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2980077917374055 | validation: 0.5252624558566489]
	TIME [epoch: 3.57 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31245747910202715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31245747910202715 | validation: 0.6967459859414414]
	TIME [epoch: 3.57 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37004002240358475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37004002240358475 | validation: 0.5980260330543148]
	TIME [epoch: 3.57 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32461082956959614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32461082956959614 | validation: 0.445310067871719]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45313017152593377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45313017152593377 | validation: 0.9728740682545054]
	TIME [epoch: 3.55 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6421246069807666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6421246069807666 | validation: 0.5195513444004045]
	TIME [epoch: 3.57 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3217408970112369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3217408970112369 | validation: 0.5180571776323571]
	TIME [epoch: 3.57 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4789483203362848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4789483203362848 | validation: 0.6527832039675601]
	TIME [epoch: 3.56 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3147660435087827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3147660435087827 | validation: 0.48696125368659904]
	TIME [epoch: 3.56 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3331859335320672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3331859335320672 | validation: 0.6870530270189009]
	TIME [epoch: 3.56 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33220245119939834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33220245119939834 | validation: 0.4400761274145758]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2582774102165788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2582774102165788 | validation: 0.601868007672548]
	TIME [epoch: 3.57 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2891045928694692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2891045928694692 | validation: 0.41304858838897984]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37585107349957086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37585107349957086 | validation: 0.8378523029653773]
	TIME [epoch: 3.57 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4752964337365557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4752964337365557 | validation: 0.46004361650908]
	TIME [epoch: 3.57 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3021202063415126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3021202063415126 | validation: 0.5700141383254258]
	TIME [epoch: 3.56 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2709865825208312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2709865825208312 | validation: 0.4878063190539179]
	TIME [epoch: 3.56 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2525208782918985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2525208782918985 | validation: 0.4433942718015029]
	TIME [epoch: 3.57 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24141262259456497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24141262259456497 | validation: 0.6288718336468602]
	TIME [epoch: 3.56 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2828063799549409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2828063799549409 | validation: 0.41898797725514925]
	TIME [epoch: 3.56 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44849873491268244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44849873491268244 | validation: 0.7898687983982764]
	TIME [epoch: 3.56 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40430061764688935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40430061764688935 | validation: 0.42549631748469424]
	TIME [epoch: 3.56 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26777874840347954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26777874840347954 | validation: 0.5410356585997235]
	TIME [epoch: 3.56 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2210842831404225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2210842831404225 | validation: 0.4553794330499543]
	TIME [epoch: 3.56 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21248955439808426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21248955439808426 | validation: 0.4833809651969836]
	TIME [epoch: 3.56 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20180921695619422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20180921695619422 | validation: 0.44118862453390695]
	TIME [epoch: 3.57 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20280529897769292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20280529897769292 | validation: 0.5914033524107425]
	TIME [epoch: 3.58 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22056478396682708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22056478396682708 | validation: 0.5184790615112906]
	TIME [epoch: 3.57 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48207443064376365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48207443064376365 | validation: 0.8777402044404774]
	TIME [epoch: 3.56 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44611680687482347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44611680687482347 | validation: 0.4108912851058518]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27554139852156806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27554139852156806 | validation: 0.5970072999749562]
	TIME [epoch: 3.56 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2999710464765476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2999710464765476 | validation: 0.522586111936479]
	TIME [epoch: 3.56 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2752852516181739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2752852516181739 | validation: 0.5302305333823781]
	TIME [epoch: 3.57 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25063084068385794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25063084068385794 | validation: 0.40908782689928824]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20986169892101758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20986169892101758 | validation: 0.5914251332738785]
	TIME [epoch: 3.56 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2320718965659163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2320718965659163 | validation: 0.3819638014369332]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29557357877872137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29557357877872137 | validation: 0.6350459613104631]
	TIME [epoch: 3.56 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.297926865029365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.297926865029365 | validation: 0.377584045789377]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2569872136624378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2569872136624378 | validation: 0.5792885974186958]
	TIME [epoch: 3.56 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24076321324808483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24076321324808483 | validation: 0.40062490833312836]
	TIME [epoch: 3.56 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21567954322961314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21567954322961314 | validation: 0.5183787297334846]
	TIME [epoch: 3.55 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21771722408971672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21771722408971672 | validation: 0.38961241581011197]
	TIME [epoch: 3.55 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2068168534227035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2068168534227035 | validation: 0.5614429820543464]
	TIME [epoch: 3.55 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23385830298715093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23385830298715093 | validation: 0.3705456165692027]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27538804192784067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27538804192784067 | validation: 0.6912877358331468]
	TIME [epoch: 3.56 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3256923010949491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3256923010949491 | validation: 0.3927700245768871]
	TIME [epoch: 3.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23464755451755673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23464755451755673 | validation: 0.5339791705296012]
	TIME [epoch: 3.54 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1910932906734796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1910932906734796 | validation: 0.4121320900078962]
	TIME [epoch: 3.55 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19400916615967007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19400916615967007 | validation: 0.5068934381528893]
	TIME [epoch: 3.56 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20971353494713715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20971353494713715 | validation: 0.4736465847522527]
	TIME [epoch: 3.56 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23995857954172586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23995857954172586 | validation: 0.5281044383597635]
	TIME [epoch: 3.57 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23159399940764722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23159399940764722 | validation: 0.42315797711717784]
	TIME [epoch: 3.57 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17965781956826377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17965781956826377 | validation: 0.3848615481775981]
	TIME [epoch: 3.56 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21308215216607998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21308215216607998 | validation: 0.7186047133228524]
	TIME [epoch: 3.54 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30155283404098876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30155283404098876 | validation: 0.4382138211062612]
	TIME [epoch: 3.56 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3660386811412995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3660386811412995 | validation: 0.6083046161477956]
	TIME [epoch: 3.55 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.229155779380228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.229155779380228 | validation: 0.4025775982526354]
	TIME [epoch: 3.55 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18307685272315058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18307685272315058 | validation: 0.4234489217591977]
	TIME [epoch: 3.55 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1695830809101794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1695830809101794 | validation: 0.42752000680113583]
	TIME [epoch: 3.58 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15225675978884864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15225675978884864 | validation: 0.3984693845158383]
	TIME [epoch: 3.56 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1367268746451854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1367268746451854 | validation: 0.3891767398435463]
	TIME [epoch: 3.56 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.129763765505743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.129763765505743 | validation: 0.44515058043249306]
	TIME [epoch: 3.56 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13478950975415652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13478950975415652 | validation: 0.33686811041371173]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23694792817730456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23694792817730456 | validation: 0.886912991859213]
	TIME [epoch: 3.56 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5591834745346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5591834745346 | validation: 0.40696613108419677]
	TIME [epoch: 3.59 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1545213824088089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1545213824088089 | validation: 0.3614921892582458]
	TIME [epoch: 3.56 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35088532028800695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35088532028800695 | validation: 0.5763157740678485]
	TIME [epoch: 3.58 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2301191683656605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2301191683656605 | validation: 0.4254074030191779]
	TIME [epoch: 3.56 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24430904483096963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24430904483096963 | validation: 0.5069492031610647]
	TIME [epoch: 3.57 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19680851717418776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19680851717418776 | validation: 0.4187916334505255]
	TIME [epoch: 3.55 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15273053646407608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15273053646407608 | validation: 0.3979001714181245]
	TIME [epoch: 3.57 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19053331816030128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19053331816030128 | validation: 0.527916135909698]
	TIME [epoch: 3.56 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20971387298180855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20971387298180855 | validation: 0.4829199143908336]
	TIME [epoch: 3.56 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21515827047233826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21515827047233826 | validation: 0.3792168176453178]
	TIME [epoch: 3.56 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18056841207311122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18056841207311122 | validation: 0.596932262285298]
	TIME [epoch: 3.56 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20502980459309186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20502980459309186 | validation: 0.3523358239693181]
	TIME [epoch: 3.55 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31404632508547087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31404632508547087 | validation: 0.5397715334416182]
	TIME [epoch: 3.59 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26100632988509354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26100632988509354 | validation: 0.38831303493019537]
	TIME [epoch: 3.59 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13765594705621154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13765594705621154 | validation: 0.3493145320209504]
	TIME [epoch: 3.59 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1317656991358333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1317656991358333 | validation: 0.3992096689376652]
	TIME [epoch: 3.57 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14267394178173576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14267394178173576 | validation: 0.3408175872213705]
	TIME [epoch: 3.58 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13677839026678007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13677839026678007 | validation: 0.44123436915926606]
	TIME [epoch: 3.56 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13241737079294963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13241737079294963 | validation: 0.3456015630775575]
	TIME [epoch: 3.58 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13269372219748687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13269372219748687 | validation: 0.5674738774996261]
	TIME [epoch: 3.56 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17384995364355796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17384995364355796 | validation: 0.3908425256886651]
	TIME [epoch: 3.58 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30467883286076874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30467883286076874 | validation: 0.5944219375046368]
	TIME [epoch: 3.58 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29856177494578434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29856177494578434 | validation: 0.4578061358092518]
	TIME [epoch: 3.58 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15429952617440523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15429952617440523 | validation: 0.32654697543030786]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13020375474498505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13020375474498505 | validation: 0.3681959868205454]
	TIME [epoch: 3.55 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13539801867510007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13539801867510007 | validation: 0.36628651530804435]
	TIME [epoch: 3.58 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1454506679705773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1454506679705773 | validation: 0.40574160605981496]
	TIME [epoch: 3.57 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18344171289746566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18344171289746566 | validation: 0.35859791072047204]
	TIME [epoch: 3.57 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19227600256143385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19227600256143385 | validation: 0.43395132069868847]
	TIME [epoch: 3.56 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17767652908920226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17767652908920226 | validation: 0.36146395902979434]
	TIME [epoch: 3.56 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16222168492935315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16222168492935315 | validation: 0.41626231867699803]
	TIME [epoch: 3.56 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13797209806105395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13797209806105395 | validation: 0.3795828669378707]
	TIME [epoch: 3.56 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1286489136986245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1286489136986245 | validation: 0.3273871289842203]
	TIME [epoch: 3.56 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13740155537601426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13740155537601426 | validation: 0.675284106864822]
	TIME [epoch: 3.56 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25656021358208675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25656021358208675 | validation: 0.3929940620189366]
	TIME [epoch: 3.56 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31255433673121624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31255433673121624 | validation: 0.4270983258999966]
	TIME [epoch: 3.56 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1443432363791524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1443432363791524 | validation: 0.4426667272495046]
	TIME [epoch: 3.56 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13198688617940113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13198688617940113 | validation: 0.33035837554594305]
	TIME [epoch: 3.56 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13233678356161954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13233678356161954 | validation: 0.36574450620616195]
	TIME [epoch: 3.56 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12509225765047932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12509225765047932 | validation: 0.40436764735303027]
	TIME [epoch: 3.56 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14099814645043882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14099814645043882 | validation: 0.3667209110559543]
	TIME [epoch: 3.57 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1729353911786923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1729353911786923 | validation: 0.4633964881284425]
	TIME [epoch: 3.56 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16341277992906858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16341277992906858 | validation: 0.33466795129886545]
	TIME [epoch: 3.57 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13088563462035835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13088563462035835 | validation: 0.3600258853767833]
	TIME [epoch: 3.57 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10441885845761316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10441885845761316 | validation: 0.3880473194581019]
	TIME [epoch: 3.56 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15275501169990513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15275501169990513 | validation: 0.4661202815540899]
	TIME [epoch: 3.56 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23969447384531578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23969447384531578 | validation: 0.30210148502982903]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26414956716953636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26414956716953636 | validation: 0.5876836547263089]
	TIME [epoch: 3.57 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19638504526395756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19638504526395756 | validation: 0.42502572873997374]
	TIME [epoch: 3.57 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23424602476084264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23424602476084264 | validation: 0.5458420318520976]
	TIME [epoch: 3.58 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20367332627786916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20367332627786916 | validation: 0.5698135591681063]
	TIME [epoch: 3.57 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15915960866942455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15915960866942455 | validation: 0.33826563856622366]
	TIME [epoch: 3.57 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1603859094211852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1603859094211852 | validation: 0.3307297941376046]
	TIME [epoch: 3.59 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09979575762857149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09979575762857149 | validation: 0.4768060014022611]
	TIME [epoch: 3.57 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1168874610702912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1168874610702912 | validation: 0.30405503884163665]
	TIME [epoch: 3.56 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1032436398919812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1032436398919812 | validation: 0.3407773076226921]
	TIME [epoch: 3.57 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10244408651115784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10244408651115784 | validation: 0.3551473991256362]
	TIME [epoch: 3.56 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11239217429157343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11239217429157343 | validation: 0.45647802888871924]
	TIME [epoch: 3.56 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21196473736575186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21196473736575186 | validation: 0.40722172386096295]
	TIME [epoch: 3.57 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23779409467374435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23779409467374435 | validation: 0.3864691564823288]
	TIME [epoch: 3.57 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14280930399549582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14280930399549582 | validation: 0.29107805618466465]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0834539198521059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0834539198521059 | validation: 0.34856368839627505]
	TIME [epoch: 3.57 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08963666791073457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08963666791073457 | validation: 0.3527769442501344]
	TIME [epoch: 3.56 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09549101670998869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09549101670998869 | validation: 0.28817307803715697]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10447521567289324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10447521567289324 | validation: 0.5579344021094226]
	TIME [epoch: 3.58 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16217608301607497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16217608301607497 | validation: 0.3538391383211886]
	TIME [epoch: 3.57 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4029355882385211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4029355882385211 | validation: 0.5542979135028742]
	TIME [epoch: 3.56 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.419362667690843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.419362667690843 | validation: 0.5688421884844427]
	TIME [epoch: 3.57 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1742089575418579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1742089575418579 | validation: 0.2994493225732307]
	TIME [epoch: 3.55 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19143880397201327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19143880397201327 | validation: 0.29616550704860833]
	TIME [epoch: 3.55 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1364678095878229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1364678095878229 | validation: 0.44262741244346204]
	TIME [epoch: 3.55 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1261480990202131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1261480990202131 | validation: 0.3596595182158864]
	TIME [epoch: 3.55 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09902793582697914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09902793582697914 | validation: 0.27036446318150775]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09889335003651686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09889335003651686 | validation: 0.28373513293427993]
	TIME [epoch: 3.57 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08749293669309313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08749293669309313 | validation: 0.409898996095609]
	TIME [epoch: 3.55 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11704576420323214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11704576420323214 | validation: 0.3891326683822861]
	TIME [epoch: 3.55 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22923547972874886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22923547972874886 | validation: 0.40583111931330196]
	TIME [epoch: 3.56 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18218373516747016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18218373516747016 | validation: 0.35698393291913116]
	TIME [epoch: 3.57 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11976077384580355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11976077384580355 | validation: 0.2916812911790691]
	TIME [epoch: 3.56 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08856039872192728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08856039872192728 | validation: 0.283862626687993]
	TIME [epoch: 3.56 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08597479021763732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08597479021763732 | validation: 0.3754589328623934]
	TIME [epoch: 3.56 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10410017296238094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10410017296238094 | validation: 0.27025248991000667]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1536688893115657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1536688893115657 | validation: 0.5740353857934993]
	TIME [epoch: 3.59 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26186695255473347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26186695255473347 | validation: 0.26195713474130083]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08564023764409033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08564023764409033 | validation: 0.2660915400970489]
	TIME [epoch: 3.56 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09693862988279424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09693862988279424 | validation: 0.32934543814208195]
	TIME [epoch: 3.57 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10516118737764461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10516118737764461 | validation: 0.29216959066924536]
	TIME [epoch: 3.55 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09098058955631143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09098058955631143 | validation: 0.30242515024591754]
	TIME [epoch: 3.55 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11733845439041506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11733845439041506 | validation: 0.45341079097483467]
	TIME [epoch: 3.56 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1968029098878055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1968029098878055 | validation: 0.3834500216352748]
	TIME [epoch: 3.56 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23519174087230948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23519174087230948 | validation: 0.3103620989336964]
	TIME [epoch: 3.55 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12799470376923747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12799470376923747 | validation: 0.46299523059761616]
	TIME [epoch: 3.55 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11275335577483357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11275335577483357 | validation: 0.27417645062916757]
	TIME [epoch: 3.55 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09435789080542482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09435789080542482 | validation: 0.3379602324229199]
	TIME [epoch: 3.56 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08090048474122781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08090048474122781 | validation: 0.2700821395629017]
	TIME [epoch: 3.55 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07763016055184255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07763016055184255 | validation: 0.2875980697131794]
	TIME [epoch: 3.56 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09467962956957764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09467962956957764 | validation: 0.3360283647797226]
	TIME [epoch: 3.55 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16277034415405445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16277034415405445 | validation: 0.46171957953412274]
	TIME [epoch: 3.55 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.231696825617069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.231696825617069 | validation: 0.253518131621212]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11968659494262857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11968659494262857 | validation: 0.41063411862747223]
	TIME [epoch: 48.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10027956156521707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10027956156521707 | validation: 0.26547614209446724]
	TIME [epoch: 7.66 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09554522311243925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09554522311243925 | validation: 0.28510109012099544]
	TIME [epoch: 7.67 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10513800147607624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10513800147607624 | validation: 0.36659227259185917]
	TIME [epoch: 7.66 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1906717318423371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1906717318423371 | validation: 0.36489584217470994]
	TIME [epoch: 7.69 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19202328389239667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19202328389239667 | validation: 0.3344126085759733]
	TIME [epoch: 7.66 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12771662983134913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12771662983134913 | validation: 0.25445618727112057]
	TIME [epoch: 7.67 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07238129001055663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07238129001055663 | validation: 0.27211109432650543]
	TIME [epoch: 7.67 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06833746805926794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06833746805926794 | validation: 0.27349368113034905]
	TIME [epoch: 7.66 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07857543354489077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07857543354489077 | validation: 0.2896763562881955]
	TIME [epoch: 7.69 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09624648849286371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09624648849286371 | validation: 0.3531464518544204]
	TIME [epoch: 7.69 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15930655983410713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15930655983410713 | validation: 0.2407208410612648]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18648856932885124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18648856932885124 | validation: 0.4926970345166046]
	TIME [epoch: 7.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1783392076224865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1783392076224865 | validation: 0.2394923357593747]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08366348952699702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08366348952699702 | validation: 0.2818933438753781]
	TIME [epoch: 7.69 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12065366721763333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12065366721763333 | validation: 0.27703081220940157]
	TIME [epoch: 7.68 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13371473473927237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13371473473927237 | validation: 0.2975107113125421]
	TIME [epoch: 7.71 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10172257644735767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10172257644735767 | validation: 0.29392231306462485]
	TIME [epoch: 7.72 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12496891225875445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12496891225875445 | validation: 0.3350282638845702]
	TIME [epoch: 7.69 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16789282356915025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16789282356915025 | validation: 0.3031441251110129]
	TIME [epoch: 7.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12865969711007744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12865969711007744 | validation: 0.29488303477669603]
	TIME [epoch: 7.68 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09240411392527925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09240411392527925 | validation: 0.2867322057876791]
	TIME [epoch: 7.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08164874815605185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08164874815605185 | validation: 0.24918659527400383]
	TIME [epoch: 7.68 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06664287259232679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06664287259232679 | validation: 0.2709043714687837]
	TIME [epoch: 7.72 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06956984461930174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06956984461930174 | validation: 0.2360636279694005]
	TIME [epoch: 7.7 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08087359142119031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08087359142119031 | validation: 0.4302873362433548]
	TIME [epoch: 7.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15662485505862925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15662485505862925 | validation: 0.24408728720726539]
	TIME [epoch: 7.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2170036243859953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2170036243859953 | validation: 0.4985432962912798]
	TIME [epoch: 7.68 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21494751240405077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21494751240405077 | validation: 0.3170683505746048]
	TIME [epoch: 7.68 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09589031841167071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09589031841167071 | validation: 0.24727245936348186]
	TIME [epoch: 7.69 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15389203556628814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15389203556628814 | validation: 0.3122032503398967]
	TIME [epoch: 7.69 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17289840254524488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17289840254524488 | validation: 0.5070092220618004]
	TIME [epoch: 7.69 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.146277624528489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.146277624528489 | validation: 0.2791233459821355]
	TIME [epoch: 7.68 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10385056992081448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10385056992081448 | validation: 0.2599988029718481]
	TIME [epoch: 7.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10229938959359755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10229938959359755 | validation: 0.4735777818215873]
	TIME [epoch: 7.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13947206370103984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13947206370103984 | validation: 0.30390669122901853]
	TIME [epoch: 7.71 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10133924639941486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10133924639941486 | validation: 0.27547965756020004]
	TIME [epoch: 7.72 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10076317836465584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10076317836465584 | validation: 0.3278205768073996]
	TIME [epoch: 7.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09090452355074907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09090452355074907 | validation: 0.25237507393556213]
	TIME [epoch: 7.68 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09802399922017624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09802399922017624 | validation: 0.2859008192209622]
	TIME [epoch: 7.69 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11784049430418878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11784049430418878 | validation: 0.2850829947464519]
	TIME [epoch: 7.66 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09288791129371685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09288791129371685 | validation: 0.2584505183815961]
	TIME [epoch: 7.67 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09124701555344795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09124701555344795 | validation: 0.25847470469124767]
	TIME [epoch: 7.67 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0993783255964257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0993783255964257 | validation: 0.3116508342183741]
	TIME [epoch: 7.72 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11248447252588205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11248447252588205 | validation: 0.27516763392210714]
	TIME [epoch: 7.66 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13410471481487418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13410471481487418 | validation: 0.2762568568221723]
	TIME [epoch: 7.68 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09151357853614553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09151357853614553 | validation: 0.27679536630344653]
	TIME [epoch: 7.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06564610257761722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06564610257761722 | validation: 0.227096666923162]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061702955740164774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061702955740164774 | validation: 0.4096370460092187]
	TIME [epoch: 7.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08500601290812071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08500601290812071 | validation: 0.26012841085852456]
	TIME [epoch: 7.71 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10328225379489298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10328225379489298 | validation: 0.5211676819032075]
	TIME [epoch: 7.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14583871477794472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14583871477794472 | validation: 0.4109173893239236]
	TIME [epoch: 7.69 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22724907717966666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22724907717966666 | validation: 0.46560031087429493]
	TIME [epoch: 7.69 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1765581484306624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1765581484306624 | validation: 0.5406943603859118]
	TIME [epoch: 7.68 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2167209204235836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2167209204235836 | validation: 0.24038621211020145]
	TIME [epoch: 7.66 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0811273644786976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0811273644786976 | validation: 0.2280298550153268]
	TIME [epoch: 7.69 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07491358468890644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07491358468890644 | validation: 0.253474083173065]
	TIME [epoch: 7.69 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07837431497703885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07837431497703885 | validation: 0.2367833054540019]
	TIME [epoch: 7.67 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059819154536604614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059819154536604614 | validation: 0.23587067637975265]
	TIME [epoch: 7.69 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06797404424126385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06797404424126385 | validation: 0.3004018624236198]
	TIME [epoch: 7.69 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14484936996065387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14484936996065387 | validation: 0.2752449747063616]
	TIME [epoch: 7.69 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16190589566970062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16190589566970062 | validation: 0.34647431558818176]
	TIME [epoch: 7.66 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2135713283927008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2135713283927008 | validation: 0.27600891378902187]
	TIME [epoch: 7.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11911542229719257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11911542229719257 | validation: 0.21981219754587214]
	TIME [epoch: 7.7 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06984979341605292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06984979341605292 | validation: 0.22587695349234746]
	TIME [epoch: 7.69 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07269205104286648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07269205104286648 | validation: 0.22081944363202594]
	TIME [epoch: 7.69 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06909088044381372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06909088044381372 | validation: 0.26135525383322594]
	TIME [epoch: 7.69 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07259255853334658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07259255853334658 | validation: 0.2089206546360267]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07797189526621622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07797189526621622 | validation: 0.2561461932361285]
	TIME [epoch: 7.72 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09318036534366808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09318036534366808 | validation: 0.25663526591704405]
	TIME [epoch: 7.69 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09977641168468787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09977641168468787 | validation: 0.2968645326839013]
	TIME [epoch: 7.66 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11126269152093635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11126269152093635 | validation: 0.25075195101318565]
	TIME [epoch: 7.68 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13945745280823857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13945745280823857 | validation: 0.26471095419863805]
	TIME [epoch: 7.66 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11702304449089804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11702304449089804 | validation: 0.19858963291693965]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09355789306619082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09355789306619082 | validation: 0.26797149205665793]
	TIME [epoch: 7.68 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10054184637797174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10054184637797174 | validation: 0.20216661790273732]
	TIME [epoch: 7.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08099472721956257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08099472721956257 | validation: 0.25683955940168096]
	TIME [epoch: 7.66 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09910933742905656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09910933742905656 | validation: 0.24669841134066375]
	TIME [epoch: 7.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10124548931953005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10124548931953005 | validation: 0.25411020246178634]
	TIME [epoch: 7.66 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10793603798538476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10793603798538476 | validation: 0.23688809377741737]
	TIME [epoch: 7.72 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07208360971405496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07208360971405496 | validation: 0.19465910152984853]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06364697809543046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06364697809543046 | validation: 0.224853339542472]
	TIME [epoch: 7.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0759329541472213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0759329541472213 | validation: 0.2171368316644364]
	TIME [epoch: 7.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10316793002661116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10316793002661116 | validation: 0.3033824415709643]
	TIME [epoch: 7.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1655077621435293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1655077621435293 | validation: 0.21195541744366084]
	TIME [epoch: 7.71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09514489610385894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09514489610385894 | validation: 0.2294999277561181]
	TIME [epoch: 7.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0943431096027744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0943431096027744 | validation: 0.25479232444053024]
	TIME [epoch: 7.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11999481914127089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11999481914127089 | validation: 0.22024917435624347]
	TIME [epoch: 7.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09057792577344935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09057792577344935 | validation: 0.34006766938554733]
	TIME [epoch: 7.72 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07975048121394633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07975048121394633 | validation: 0.19717643518872296]
	TIME [epoch: 7.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06269300539381806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06269300539381806 | validation: 0.17980443565380821]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059318742586464045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059318742586464045 | validation: 0.2899999763492153]
	TIME [epoch: 7.68 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10395534902298341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10395534902298341 | validation: 0.22749788038465396]
	TIME [epoch: 7.69 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11727079687925088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11727079687925088 | validation: 0.5178856577125878]
	TIME [epoch: 7.71 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18869760748253697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18869760748253697 | validation: 0.31228597660628027]
	TIME [epoch: 7.68 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18732448716563366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18732448716563366 | validation: 0.23173904672497408]
	TIME [epoch: 7.69 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08207420405544813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08207420405544813 | validation: 0.481503211409416]
	TIME [epoch: 7.69 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10407682647567766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10407682647567766 | validation: 0.21937173615543532]
	TIME [epoch: 7.71 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07567139681147293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07567139681147293 | validation: 0.21272747656497068]
	TIME [epoch: 7.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054574455707396705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054574455707396705 | validation: 0.19183606940012102]
	TIME [epoch: 7.69 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05551358761133255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05551358761133255 | validation: 0.1919829108045834]
	TIME [epoch: 7.72 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05618393120516798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05618393120516798 | validation: 0.20192825737085685]
	TIME [epoch: 7.74 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07102481071139598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07102481071139598 | validation: 0.24376651825546236]
	TIME [epoch: 7.68 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13832080758809312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13832080758809312 | validation: 0.18626757295774263]
	TIME [epoch: 7.66 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09145556312513085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09145556312513085 | validation: 0.22404262555170132]
	TIME [epoch: 7.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09191145908348687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09191145908348687 | validation: 0.21243365675487916]
	TIME [epoch: 7.69 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07267868193999054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07267868193999054 | validation: 0.23493520962492262]
	TIME [epoch: 7.67 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11543124611122792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11543124611122792 | validation: 0.36233921066371755]
	TIME [epoch: 7.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1795585813416681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1795585813416681 | validation: 0.24099592045194804]
	TIME [epoch: 7.69 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09375780318305033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09375780318305033 | validation: 0.18824466776161386]
	TIME [epoch: 7.69 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05752630229144488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05752630229144488 | validation: 0.20901103151329004]
	TIME [epoch: 7.67 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06945570562511516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06945570562511516 | validation: 0.1714332242617937]
	TIME [epoch: 7.71 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05855459685401947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05855459685401947 | validation: 0.21890302928083055]
	TIME [epoch: 7.69 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06242751365859041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06242751365859041 | validation: 0.1672107822364165]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05811248972307349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05811248972307349 | validation: 0.19598433039725374]
	TIME [epoch: 7.77 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07835337546827276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07835337546827276 | validation: 0.19854666331151805]
	TIME [epoch: 7.77 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10258483604498932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10258483604498932 | validation: 0.39312514710909996]
	TIME [epoch: 7.78 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22813084702387862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22813084702387862 | validation: 0.3060745520746294]
	TIME [epoch: 7.75 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20920924900020219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20920924900020219 | validation: 0.18870122265378553]
	TIME [epoch: 7.76 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054604206025926486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054604206025926486 | validation: 0.23900745769547127]
	TIME [epoch: 7.77 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06673264799572376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06673264799572376 | validation: 0.2029556517109315]
	TIME [epoch: 7.75 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07002017434734108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07002017434734108 | validation: 0.21850902433393032]
	TIME [epoch: 7.72 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06706863364244095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06706863364244095 | validation: 0.32623690076457407]
	TIME [epoch: 7.78 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0940691851943366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0940691851943366 | validation: 0.21693855529320583]
	TIME [epoch: 7.78 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07372147404037264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07372147404037264 | validation: 0.23909207125759294]
	TIME [epoch: 7.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059665031316375385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059665031316375385 | validation: 0.17466918741999368]
	TIME [epoch: 7.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05194579449876209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05194579449876209 | validation: 0.18371107390897096]
	TIME [epoch: 7.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07274701161439906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07274701161439906 | validation: 0.26048515642538345]
	TIME [epoch: 7.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1719255796106895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1719255796106895 | validation: 0.15794139388384976]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09825188525329664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09825188525329664 | validation: 0.28660672353192823]
	TIME [epoch: 7.76 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10485561849653831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10485561849653831 | validation: 0.21574894544008263]
	TIME [epoch: 7.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0975317665542719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0975317665542719 | validation: 0.23965213269254645]
	TIME [epoch: 7.72 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13807180267052968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13807180267052968 | validation: 0.23787714141083321]
	TIME [epoch: 7.73 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10923521205652727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10923521205652727 | validation: 0.18882473516708093]
	TIME [epoch: 7.76 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07295822175101145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07295822175101145 | validation: 0.19592323086023472]
	TIME [epoch: 7.77 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044994960609784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044994960609784 | validation: 0.1879586968649652]
	TIME [epoch: 7.74 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039973373332698445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039973373332698445 | validation: 0.16212033476206822]
	TIME [epoch: 7.74 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039674116522344385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039674116522344385 | validation: 0.19855803130257133]
	TIME [epoch: 7.73 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04095244319870708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04095244319870708 | validation: 0.14213746284663617]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044350353936852986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044350353936852986 | validation: 0.2291833997851252]
	TIME [epoch: 7.73 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08096792192247836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08096792192247836 | validation: 0.20367847763479408]
	TIME [epoch: 7.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17565848575122595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17565848575122595 | validation: 0.29616296190050245]
	TIME [epoch: 7.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2702130128234183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2702130128234183 | validation: 0.3362154233887005]
	TIME [epoch: 7.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10007009671951694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10007009671951694 | validation: 0.1898718346729684]
	TIME [epoch: 7.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19824890752140967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19824890752140967 | validation: 0.1994764055458351]
	TIME [epoch: 7.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08882516408209057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08882516408209057 | validation: 0.19884686568651508]
	TIME [epoch: 7.72 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06637773788479781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06637773788479781 | validation: 0.1760095372063707]
	TIME [epoch: 7.73 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05372035013002144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05372035013002144 | validation: 0.15739265996310395]
	TIME [epoch: 7.69 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042063177604433795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042063177604433795 | validation: 0.1784860835842561]
	TIME [epoch: 7.71 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041558730722189845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041558730722189845 | validation: 0.16493697695201734]
	TIME [epoch: 7.71 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03814653520340011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03814653520340011 | validation: 0.16165666525165845]
	TIME [epoch: 7.73 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03674271496566194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03674271496566194 | validation: 0.15318617529903777]
	TIME [epoch: 7.72 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03411626259374073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03411626259374073 | validation: 0.1606913557199383]
	TIME [epoch: 7.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031194127468471566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031194127468471566 | validation: 0.13152972876939387]
	TIME [epoch: 7.7 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03751212528836332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03751212528836332 | validation: 0.30346148099328013]
	TIME [epoch: 7.72 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07135951673215934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07135951673215934 | validation: 0.2784917115412277]
	TIME [epoch: 7.68 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16065828798920634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16065828798920634 | validation: 0.7693192765674284]
	TIME [epoch: 7.69 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34974315714775756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34974315714775756 | validation: 0.33157369436036943]
	TIME [epoch: 7.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2324834835073662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2324834835073662 | validation: 0.35606481884234653]
	TIME [epoch: 7.71 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18130523124556927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18130523124556927 | validation: 0.5541484147776137]
	TIME [epoch: 7.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14929537058928088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14929537058928088 | validation: 0.3760393857708164]
	TIME [epoch: 7.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09078373598570606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09078373598570606 | validation: 0.26407909169079335]
	TIME [epoch: 7.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05976272076683563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05976272076683563 | validation: 0.20904313205534628]
	TIME [epoch: 7.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054105126700531636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054105126700531636 | validation: 0.16747172706859015]
	TIME [epoch: 7.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05096194489158492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05096194489158492 | validation: 0.20998627066895015]
	TIME [epoch: 7.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05143880491278309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05143880491278309 | validation: 0.16548923920511027]
	TIME [epoch: 7.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044444045136596964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044444045136596964 | validation: 0.18627180151138567]
	TIME [epoch: 7.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03540845579607374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03540845579607374 | validation: 0.15142531151798932]
	TIME [epoch: 7.71 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03358277989224133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03358277989224133 | validation: 0.1580448652397602]
	TIME [epoch: 7.71 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03815761467306501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03815761467306501 | validation: 0.16522334536713115]
	TIME [epoch: 7.75 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06027626382565442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06027626382565442 | validation: 0.20391942719317654]
	TIME [epoch: 7.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13780966693142943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13780966693142943 | validation: 0.17999522318419167]
	TIME [epoch: 7.69 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10848101670126002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10848101670126002 | validation: 0.3374487213510636]
	TIME [epoch: 7.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11956471827548165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11956471827548165 | validation: 0.1806827930259193]
	TIME [epoch: 7.72 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05642276049920192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05642276049920192 | validation: 0.14664795845423098]
	TIME [epoch: 7.69 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042503932464336355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042503932464336355 | validation: 0.1743725445147257]
	TIME [epoch: 7.69 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044156172261702924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044156172261702924 | validation: 0.1588622674006128]
	TIME [epoch: 7.71 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04325488665271772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04325488665271772 | validation: 0.18498565534285363]
	TIME [epoch: 7.71 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05961002377290356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05961002377290356 | validation: 0.26249502635007266]
	TIME [epoch: 7.69 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14541572532588895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14541572532588895 | validation: 0.4013510077760207]
	TIME [epoch: 7.68 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2706130411781215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2706130411781215 | validation: 0.26718012862532053]
	TIME [epoch: 7.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11611496408742458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11611496408742458 | validation: 0.23512669927251892]
	TIME [epoch: 7.72 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04812147032789076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04812147032789076 | validation: 0.15710857394096653]
	TIME [epoch: 7.73 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05252361376876428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05252361376876428 | validation: 0.15509672065067687]
	TIME [epoch: 7.71 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046421402674795116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046421402674795116 | validation: 0.16267658513475022]
	TIME [epoch: 7.71 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04339995085111667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04339995085111667 | validation: 0.14034686745190608]
	TIME [epoch: 7.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05300118258450203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05300118258450203 | validation: 0.27502967278383866]
	TIME [epoch: 7.72 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06285285885150081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06285285885150081 | validation: 0.16007430686588228]
	TIME [epoch: 7.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0693758444061667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0693758444061667 | validation: 0.23035801308126103]
	TIME [epoch: 7.72 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07772885320502722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07772885320502722 | validation: 0.19542394351754735]
	TIME [epoch: 7.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08513335872692505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08513335872692505 | validation: 0.16868516616289578]
	TIME [epoch: 7.71 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07361590051891652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07361590051891652 | validation: 0.1942758143128867]
	TIME [epoch: 7.71 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0569869257031928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0569869257031928 | validation: 0.12468772379819178]
	TIME [epoch: 7.71 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0439890228899308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0439890228899308 | validation: 0.1463513086576694]
	TIME [epoch: 7.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05486523096587372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05486523096587372 | validation: 0.13841485639199466]
	TIME [epoch: 7.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08845911898270277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08845911898270277 | validation: 0.22755717273538184]
	TIME [epoch: 7.69 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18702658041576786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18702658041576786 | validation: 0.22561861114756196]
	TIME [epoch: 7.71 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10431216896341307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10431216896341307 | validation: 0.18320450730651416]
	TIME [epoch: 7.68 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10485742836748867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10485742836748867 | validation: 0.1670963186607752]
	TIME [epoch: 7.69 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06185391700401992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06185391700401992 | validation: 0.15227440656732402]
	TIME [epoch: 7.71 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03578949328622872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03578949328622872 | validation: 0.13204895962792898]
	TIME [epoch: 7.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03720429115400863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03720429115400863 | validation: 0.13419720854187803]
	TIME [epoch: 7.69 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0317327379832905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0317327379832905 | validation: 0.11832680069294815]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029885268994152482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029885268994152482 | validation: 0.16516869135557632]
	TIME [epoch: 7.71 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032508489411606716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032508489411606716 | validation: 0.11539025785264018]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031855257496788546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031855257496788546 | validation: 0.2123416331722425]
	TIME [epoch: 7.73 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05481132726967789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05481132726967789 | validation: 0.2053748323816784]
	TIME [epoch: 7.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1578896960622841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1578896960622841 | validation: 0.40378285028535804]
	TIME [epoch: 7.74 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27631722112234586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27631722112234586 | validation: 0.314581614604693]
	TIME [epoch: 7.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20247981481029378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20247981481029378 | validation: 0.2584705121008271]
	TIME [epoch: 7.72 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14320816208563164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14320816208563164 | validation: 0.19214266614350342]
	TIME [epoch: 7.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05546745179788338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05546745179788338 | validation: 0.1806417215921374]
	TIME [epoch: 7.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05455745589744475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05455745589744475 | validation: 0.1725905205862823]
	TIME [epoch: 7.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04511615887764364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04511615887764364 | validation: 0.18602923947843084]
	TIME [epoch: 7.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0512137790429669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0512137790429669 | validation: 0.1799971282597214]
	TIME [epoch: 7.73 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057710230909807175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057710230909807175 | validation: 0.18983034557251616]
	TIME [epoch: 7.69 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06433570496528193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06433570496528193 | validation: 0.18821941687694516]
	TIME [epoch: 7.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08177380912530839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08177380912530839 | validation: 0.20650506740180383]
	TIME [epoch: 7.72 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09990358697172193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09990358697172193 | validation: 0.18723012155258179]
	TIME [epoch: 7.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07698807897487733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07698807897487733 | validation: 0.1352557511090507]
	TIME [epoch: 7.74 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058825147763360126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058825147763360126 | validation: 0.15830916860739405]
	TIME [epoch: 7.69 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052776551522247146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052776551522247146 | validation: 0.12719814541930272]
	TIME [epoch: 7.73 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044041733524594485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044041733524594485 | validation: 0.13769475054357794]
	TIME [epoch: 7.73 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03900596276866445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03900596276866445 | validation: 0.1019268457624232]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043457339632812494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043457339632812494 | validation: 0.15018047828655412]
	TIME [epoch: 7.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06335078096139139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06335078096139139 | validation: 0.14079471399871699]
	TIME [epoch: 7.68 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06821659070711857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06821659070711857 | validation: 0.19600549933623113]
	TIME [epoch: 7.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09894789060661836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09894789060661836 | validation: 0.1954151868835906]
	TIME [epoch: 7.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14373999302572463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14373999302572463 | validation: 0.16377544317005566]
	TIME [epoch: 7.72 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09052162707135761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09052162707135761 | validation: 0.1374103069031345]
	TIME [epoch: 7.71 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04975840418206823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04975840418206823 | validation: 0.10394918078077282]
	TIME [epoch: 7.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04356624787867284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04356624787867284 | validation: 0.1680279917109699]
	TIME [epoch: 7.73 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055047667597280664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055047667597280664 | validation: 0.10928719552604549]
	TIME [epoch: 7.72 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03787298398020882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03787298398020882 | validation: 0.12297260579481462]
	TIME [epoch: 7.68 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031164068366636002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031164068366636002 | validation: 0.10605006655444492]
	TIME [epoch: 7.69 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03193091092221815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03193091092221815 | validation: 0.12565158742910518]
	TIME [epoch: 7.68 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048643618454609294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048643618454609294 | validation: 0.19960886840876607]
	TIME [epoch: 7.73 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06968776019080053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06968776019080053 | validation: 0.18414709658101908]
	TIME [epoch: 7.78 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1215990813117832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1215990813117832 | validation: 0.18413220693220597]
	TIME [epoch: 7.67 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15031843064858633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15031843064858633 | validation: 0.19066698850019742]
	TIME [epoch: 7.68 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09203589828871682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09203589828871682 | validation: 0.11739287597848301]
	TIME [epoch: 7.73 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03890818159723219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03890818159723219 | validation: 0.14682476230828367]
	TIME [epoch: 7.73 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03322983882836451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03322983882836451 | validation: 0.12035197744680681]
	TIME [epoch: 7.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04063578976867564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04063578976867564 | validation: 0.10801480451920004]
	TIME [epoch: 7.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038152527558296366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038152527558296366 | validation: 0.10810961161555176]
	TIME [epoch: 7.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038271272939567245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038271272939567245 | validation: 0.09958139591378351]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0614845982299385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0614845982299385 | validation: 0.1558799464165176]
	TIME [epoch: 7.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1189035950247284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1189035950247284 | validation: 0.18022986061973073]
	TIME [epoch: 7.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08128550554946705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08128550554946705 | validation: 0.4504600850342653]
	TIME [epoch: 7.71 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14921904086162383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14921904086162383 | validation: 0.15554760945322374]
	TIME [epoch: 7.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08023736351353986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08023736351353986 | validation: 0.2117516875410096]
	TIME [epoch: 7.76 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10292223086924289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10292223086924289 | validation: 0.19555396136802214]
	TIME [epoch: 7.76 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05691089142375997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05691089142375997 | validation: 0.1512464387667613]
	TIME [epoch: 7.72 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029899016436015086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029899016436015086 | validation: 0.1136175514842557]
	TIME [epoch: 7.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026122026630050713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026122026630050713 | validation: 0.10698164978368603]
	TIME [epoch: 7.73 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022214281374485136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022214281374485136 | validation: 0.10874285971554598]
	TIME [epoch: 7.71 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01905543358195972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01905543358195972 | validation: 0.08490298403195178]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02077261520197964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02077261520197964 | validation: 0.10187871332475536]
	TIME [epoch: 7.78 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041077424853377786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041077424853377786 | validation: 0.13255635875051822]
	TIME [epoch: 7.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09285390978191103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09285390978191103 | validation: 0.2210931654570919]
	TIME [epoch: 7.78 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18242256987522942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18242256987522942 | validation: 0.18604990130023735]
	TIME [epoch: 7.77 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0837727211085511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0837727211085511 | validation: 0.2798275923793998]
	TIME [epoch: 7.79 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10139733655556021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10139733655556021 | validation: 0.20984440305203045]
	TIME [epoch: 7.78 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13180678432954557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13180678432954557 | validation: 0.15962679396380353]
	TIME [epoch: 7.76 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09208603638805198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09208603638805198 | validation: 0.1445055584654449]
	TIME [epoch: 7.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04076442035353475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04076442035353475 | validation: 0.14244308459651078]
	TIME [epoch: 7.77 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03923760114027816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03923760114027816 | validation: 0.12662615525291804]
	TIME [epoch: 7.81 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031992482489141966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031992482489141966 | validation: 0.12586421211157436]
	TIME [epoch: 7.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02342610235692122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02342610235692122 | validation: 0.09627911527776693]
	TIME [epoch: 7.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020096950909492605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020096950909492605 | validation: 0.08314704534061063]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02054447157229338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02054447157229338 | validation: 0.08677115379483064]
	TIME [epoch: 7.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022637449035741802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022637449035741802 | validation: 0.11890908514212271]
	TIME [epoch: 7.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05512005272431297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05512005272431297 | validation: 0.24728505527704747]
	TIME [epoch: 7.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2266139486905184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2266139486905184 | validation: 0.2708154432733309]
	TIME [epoch: 7.71 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1890467369788938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1890467369788938 | validation: 0.11253286503462112]
	TIME [epoch: 7.71 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.040848037706828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.040848037706828 | validation: 0.1062901347103463]
	TIME [epoch: 7.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045673106335850346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045673106335850346 | validation: 0.14837703449248438]
	TIME [epoch: 7.71 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07297342841938392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07297342841938392 | validation: 0.3657502762937548]
	TIME [epoch: 7.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10049932811693595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10049932811693595 | validation: 0.11541400267816576]
	TIME [epoch: 7.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05045250170091696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05045250170091696 | validation: 0.10026264197295315]
	TIME [epoch: 7.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02388397034178058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02388397034178058 | validation: 0.08592094784220655]
	TIME [epoch: 7.73 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021464786795786634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021464786795786634 | validation: 0.08532388725103536]
	TIME [epoch: 7.71 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02449048712932433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02449048712932433 | validation: 0.09494458307432319]
	TIME [epoch: 7.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023437416952816904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023437416952816904 | validation: 0.07532313394807649]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03701502172348124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03701502172348124 | validation: 0.16328310980110433]
	TIME [epoch: 7.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1363357096719545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1363357096719545 | validation: 0.1492588139229872]
	TIME [epoch: 7.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07316688340753201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07316688340753201 | validation: 0.14716133168728454]
	TIME [epoch: 7.72 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059198622420273586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059198622420273586 | validation: 0.11163440498642557]
	TIME [epoch: 7.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03230789524956812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03230789524956812 | validation: 0.1319708870834295]
	TIME [epoch: 7.71 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02617930466184059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02617930466184059 | validation: 0.11158026303031657]
	TIME [epoch: 7.71 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023749081601272017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023749081601272017 | validation: 0.10386685003180696]
	TIME [epoch: 7.71 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02626260799089331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02626260799089331 | validation: 0.12517660232706432]
	TIME [epoch: 7.72 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039219085125525535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039219085125525535 | validation: 0.18561549954185558]
	TIME [epoch: 7.71 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08702253109812118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08702253109812118 | validation: 0.23138334636093646]
	TIME [epoch: 7.74 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24637644059856265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24637644059856265 | validation: 0.3453943075118529]
	TIME [epoch: 7.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2953556457007133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2953556457007133 | validation: 0.47958311105739454]
	TIME [epoch: 7.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10776305124146723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10776305124146723 | validation: 0.13400987050991545]
	TIME [epoch: 7.65 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09608128440416921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09608128440416921 | validation: 0.21638207301156884]
	TIME [epoch: 7.72 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0908928395909549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0908928395909549 | validation: 0.13563013610345478]
	TIME [epoch: 7.73 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0308171004562413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0308171004562413 | validation: 0.1439480726112799]
	TIME [epoch: 7.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03508937778381265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03508937778381265 | validation: 0.12692528360353816]
	TIME [epoch: 7.71 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026783047739630528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026783047739630528 | validation: 0.12468578122873208]
	TIME [epoch: 7.67 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02387783411364267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02387783411364267 | validation: 0.11473400279854183]
	TIME [epoch: 7.68 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020935424129756238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020935424129756238 | validation: 0.09840785825458467]
	TIME [epoch: 7.71 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018206018373151996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.018206018373151996 | validation: 0.09818937843556585]
	TIME [epoch: 7.73 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017440572202479267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.017440572202479267 | validation: 0.10027558423554649]
	TIME [epoch: 7.67 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0172742995439194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0172742995439194 | validation: 0.0929199092335004]
	TIME [epoch: 7.69 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033962954646752676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033962954646752676 | validation: 0.23095700064241687]
	TIME [epoch: 7.69 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1614107424078079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1614107424078079 | validation: 0.309614528142504]
	TIME [epoch: 7.72 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28210675206903774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28210675206903774 | validation: 0.1971526148885338]
	TIME [epoch: 7.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0679156516664343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0679156516664343 | validation: 0.3783616658804676]
	TIME [epoch: 7.72 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06673979056377599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06673979056377599 | validation: 0.1287690139767664]
	TIME [epoch: 7.68 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06756616570645005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06756616570645005 | validation: 0.14556262665103648]
	TIME [epoch: 7.69 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0713254890848384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0713254890848384 | validation: 0.11145305796040002]
	TIME [epoch: 7.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02534188208592637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02534188208592637 | validation: 0.1383589128945634]
	TIME [epoch: 7.71 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028536730499066024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028536730499066024 | validation: 0.107519566439583]
	TIME [epoch: 7.72 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026141227960905712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026141227960905712 | validation: 0.10128622523725328]
	TIME [epoch: 7.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031113781304460977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031113781304460977 | validation: 0.12875097448191464]
	TIME [epoch: 7.71 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03645789323255763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03645789323255763 | validation: 0.17068774095374112]
	TIME [epoch: 7.71 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050263598297131916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050263598297131916 | validation: 0.1438763169381804]
	TIME [epoch: 7.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06024627009182419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06024627009182419 | validation: 0.12992798092434826]
	TIME [epoch: 7.71 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06210039577771731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06210039577771731 | validation: 0.10127275380008086]
	TIME [epoch: 7.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05437891512544066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05437891512544066 | validation: 0.09124795163792226]
	TIME [epoch: 7.73 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05186136588650676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05186136588650676 | validation: 0.0913728886589369]
	TIME [epoch: 7.69 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03734660476770705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03734660476770705 | validation: 0.1739434607164505]
	TIME [epoch: 7.69 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07740093157319079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07740093157319079 | validation: 0.149717216503264]
	TIME [epoch: 7.69 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12097664497340134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12097664497340134 | validation: 0.16959538178917188]
	TIME [epoch: 7.68 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09935803533253892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09935803533253892 | validation: 0.18151246758067183]
	TIME [epoch: 7.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05328719176878929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05328719176878929 | validation: 0.13935625613290015]
	TIME [epoch: 7.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09048513081284544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09048513081284544 | validation: 0.133679117145988]
	TIME [epoch: 7.69 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04741813677964217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04741813677964217 | validation: 0.10380964108137987]
	TIME [epoch: 7.69 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02320358609358997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02320358609358997 | validation: 0.09453935838772912]
	TIME [epoch: 7.69 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028041545840038876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028041545840038876 | validation: 0.1130713898986358]
	TIME [epoch: 7.68 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02949734664540966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02949734664540966 | validation: 0.09902396247114738]
	TIME [epoch: 7.67 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029811898787451892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029811898787451892 | validation: 0.10999034888210012]
	TIME [epoch: 7.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04937428639029818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04937428639029818 | validation: 0.17728392752436894]
	TIME [epoch: 7.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10463363541177405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10463363541177405 | validation: 0.21406722193174665]
	TIME [epoch: 7.71 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1535885033416405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1535885033416405 | validation: 0.13084860072629276]
	TIME [epoch: 7.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054357601126544156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054357601126544156 | validation: 0.09254391921641325]
	TIME [epoch: 7.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023017285984154735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023017285984154735 | validation: 0.08709864575972333]
	TIME [epoch: 7.69 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03142724026453251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03142724026453251 | validation: 0.0970349992233075]
	TIME [epoch: 7.72 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03909644989881552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03909644989881552 | validation: 0.11343337796588285]
	TIME [epoch: 7.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045511669443561435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045511669443561435 | validation: 0.11206168041340324]
	TIME [epoch: 7.68 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09126725780005929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09126725780005929 | validation: 0.1317422236480159]
	TIME [epoch: 7.69 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0757039011567949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0757039011567949 | validation: 0.2327762821203021]
	TIME [epoch: 7.68 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08249845216260226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08249845216260226 | validation: 0.14413913145670945]
	TIME [epoch: 7.69 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04322021354446497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04322021354446497 | validation: 0.09868307839246704]
	TIME [epoch: 7.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028237323285933015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028237323285933015 | validation: 0.12614310846162877]
	TIME [epoch: 7.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037109795522542295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037109795522542295 | validation: 0.11401269587620672]
	TIME [epoch: 7.69 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05611874372074807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05611874372074807 | validation: 0.23256905672281578]
	TIME [epoch: 7.69 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11840576134061599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11840576134061599 | validation: 0.21523685279934757]
	TIME [epoch: 7.67 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14265222154951687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14265222154951687 | validation: 0.17769872613694013]
	TIME [epoch: 7.69 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05754720187555068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05754720187555068 | validation: 0.4442045077198389]
	TIME [epoch: 7.74 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08774576383871206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08774576383871206 | validation: 0.1401780539858236]
	TIME [epoch: 7.69 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04665924181821481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04665924181821481 | validation: 0.1095795328138486]
	TIME [epoch: 7.69 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037126940874900365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037126940874900365 | validation: 0.10282305274944276]
	TIME [epoch: 7.69 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03360751200866426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03360751200866426 | validation: 0.12544228733235827]
	TIME [epoch: 7.68 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03567191662132959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03567191662132959 | validation: 0.10531519074380676]
	TIME [epoch: 7.68 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0365736640658102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0365736640658102 | validation: 0.14745939186806234]
	TIME [epoch: 7.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03539883672139192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03539883672139192 | validation: 0.08365684598432654]
	TIME [epoch: 7.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04317966269121098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04317966269121098 | validation: 0.13130066522112468]
	TIME [epoch: 7.69 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07495280072583603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07495280072583603 | validation: 0.10411057694772015]
	TIME [epoch: 7.68 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03316523523186686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03316523523186686 | validation: 0.09741001528483832]
	TIME [epoch: 7.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019682574955231524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019682574955231524 | validation: 0.08824525666662175]
	TIME [epoch: 7.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021170709026063484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021170709026063484 | validation: 0.12050957863649632]
	TIME [epoch: 7.72 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04111303033326649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04111303033326649 | validation: 0.2975384305691085]
	TIME [epoch: 7.72 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13956094691470733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13956094691470733 | validation: 0.19759612644496363]
	TIME [epoch: 7.71 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12819812881117543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12819812881117543 | validation: 0.10014474055420262]
	TIME [epoch: 7.69 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054286676722612025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054286676722612025 | validation: 0.1268892723545113]
	TIME [epoch: 7.71 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03645421225408832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03645421225408832 | validation: 0.11157994752071002]
	TIME [epoch: 7.69 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05994899176408522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05994899176408522 | validation: 0.143146751389224]
	TIME [epoch: 7.72 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09925489432250775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09925489432250775 | validation: 0.09171310307827207]
	TIME [epoch: 7.68 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026259247591780888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026259247591780888 | validation: 0.08709789982344002]
	TIME [epoch: 7.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02481068305836617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02481068305836617 | validation: 0.11370739996894784]
	TIME [epoch: 7.69 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04020715368396249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04020715368396249 | validation: 0.0933477002089023]
	TIME [epoch: 7.69 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03978526175232631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03978526175232631 | validation: 0.1337882358249631]
	TIME [epoch: 7.67 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053945606121053286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053945606121053286 | validation: 0.12428321958142084]
	TIME [epoch: 7.69 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06004165249888752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06004165249888752 | validation: 0.14203606813278183]
	TIME [epoch: 7.74 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0747279840309174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0747279840309174 | validation: 0.12177837696998672]
	TIME [epoch: 7.73 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0702941274516547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0702941274516547 | validation: 0.09864646816715689]
	TIME [epoch: 7.67 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031477110790294534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031477110790294534 | validation: 0.14616685251235603]
	TIME [epoch: 7.67 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026322326021339496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026322326021339496 | validation: 0.10695152941314712]
	TIME [epoch: 7.68 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027088294219710964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027088294219710964 | validation: 0.14503371554044756]
	TIME [epoch: 7.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03694414038925008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03694414038925008 | validation: 0.09450196911299721]
	TIME [epoch: 7.73 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03221294096436854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03221294096436854 | validation: 0.16395338610341242]
	TIME [epoch: 7.71 sec]
	Saving model to: out/model_training/model_phi1_4b_v_mmd1_20240823_171624/states/model_phi1_4b_v_mmd1_885.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 4628.987 seconds.
