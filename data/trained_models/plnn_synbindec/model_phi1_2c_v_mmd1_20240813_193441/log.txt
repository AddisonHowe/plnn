Args:
Namespace(name='model_phi1_2c_v_mmd1', outdir='out/model_training/model_phi1_2c_v_mmd1', training_data='data/training_data/data_phi1_2c/training', validation_data='data/training_data/data_phi1_2c/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1092900704

Training model...

Saving initial model state to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 2/2] avg loss: 5.628533659296594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.628533659296594 | validation: 5.85778845113357]
	TIME [epoch: 113 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 2/2] avg loss: 6.467553138033445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.467553138033445 | validation: 7.052553971417173]
	TIME [epoch: 6.7 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 2/2] avg loss: 6.990436862846615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.990436862846615 | validation: 4.698264112591396]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.729568202595413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.729568202595413 | validation: 4.606406805426164]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.591116049849383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.591116049849383 | validation: 4.362815370285249]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.421237848496725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.421237848496725 | validation: 4.246565977202504]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.252974152054137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.252974152054137 | validation: 4.074130471252398]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.164883406515024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164883406515024 | validation: 4.075003694805003]
	TIME [epoch: 6.61 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.0038137160457525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0038137160457525 | validation: 3.8785857570189766]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 2/2] avg loss: 4.0949318387174225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0949318387174225 | validation: 3.721161494739333]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.9487900340372857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9487900340372857 | validation: 3.7927190441463328]
	TIME [epoch: 6.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.843261185376179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.843261185376179 | validation: 3.641412784601764]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.7453034740759694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7453034740759694 | validation: 3.51206596065653]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.6711229231932103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6711229231932103 | validation: 3.435667927438249]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.495437656541993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.495437656541993 | validation: 3.4225168094781235]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.5614597368137355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5614597368137355 | validation: 3.514443936457251]
	TIME [epoch: 6.66 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.8081020175805422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8081020175805422 | validation: 3.5147827483683702]
	TIME [epoch: 6.71 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.537848586390023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.537848586390023 | validation: 3.4097111699358025]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.603721971379381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.603721971379381 | validation: 3.312681386786767]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.425084700844077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.425084700844077 | validation: 3.2016980772765553]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.3532629759326653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3532629759326653 | validation: 3.1819321639442637]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.365182726603954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.365182726603954 | validation: 3.1997846501659937]
	TIME [epoch: 6.65 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.3662974815425493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3662974815425493 | validation: 3.3817879949288314]
	TIME [epoch: 6.65 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.4700193444825596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4700193444825596 | validation: 3.117693903134033]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.339398110584053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.339398110584053 | validation: 3.13022957978951]
	TIME [epoch: 6.61 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.2323550167108768		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 3.2323550167108768 | validation: 3.116359580754542]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.2988110359141727		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 3.2988110359141727 | validation: 3.119297025885204]
	TIME [epoch: 6.66 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.2869557570081867		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 3.2869557570081867 | validation: 3.0398379569975886]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.185797483228227		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 3.185797483228227 | validation: 2.9810990888703004]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.1448357520889028		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 3.1448357520889028 | validation: 2.886166999463801]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 2/2] avg loss: 3.0210618844441512		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 3.0210618844441512 | validation: 2.7018269913424136]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 2/2] avg loss: 2.8880132935340654		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 2.8880132935340654 | validation: 2.6496732539821197]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 2/2] avg loss: 2.771949132963916		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 2.771949132963916 | validation: 1.9977102022109532]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 2/2] avg loss: 2.003932117529013		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 2.003932117529013 | validation: 2.1535238272836104]
	TIME [epoch: 6.61 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.8242230723935249		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 1.8242230723935249 | validation: 2.0808706563253487]
	TIME [epoch: 6.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.9091866100414363		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 1.9091866100414363 | validation: 1.5163700028183866]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.551581867405266		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 1.551581867405266 | validation: 1.9884538517837649]
	TIME [epoch: 6.66 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.7863928373858615		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 1.7863928373858615 | validation: 1.527100730715621]
	TIME [epoch: 6.63 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4729810979595799		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 1.4729810979595799 | validation: 1.472525138712216]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.584206060457295		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 1.584206060457295 | validation: 1.453071788725286]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.5717693706981768		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 1.5717693706981768 | validation: 1.4395247493346455]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4608058300994047		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 1.4608058300994047 | validation: 1.402314052025448]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4127634171745276		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 1.4127634171745276 | validation: 1.360804789425198]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4408068548315571		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 1.4408068548315571 | validation: 1.4772984367876172]
	TIME [epoch: 6.66 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4868837077940231		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 1.4868837077940231 | validation: 1.4369638011913783]
	TIME [epoch: 6.67 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4930375383419245		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 1.4930375383419245 | validation: 1.395383370776073]
	TIME [epoch: 6.68 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.5456452178726776		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 1.5456452178726776 | validation: 1.404470841592972]
	TIME [epoch: 6.69 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4472686374875479		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 1.4472686374875479 | validation: 1.349694034339101]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3343647200163467		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 1.3343647200163467 | validation: 1.3603873195233165]
	TIME [epoch: 6.68 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2982426645374052		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 1.2982426645374052 | validation: 1.3284536008734955]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4379535220385518		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 1.4379535220385518 | validation: 1.3759292437732884]
	TIME [epoch: 6.61 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3688188224729454		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 1.3688188224729454 | validation: 1.3553286172034047]
	TIME [epoch: 6.65 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3268487195872205		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 1.3268487195872205 | validation: 1.2893049879106733]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3048058149048538		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 1.3048058149048538 | validation: 1.260492555402136]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.339674803673414		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 1.339674803673414 | validation: 1.3007356667625343]
	TIME [epoch: 6.61 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3242250613418851		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 1.3242250613418851 | validation: 1.3061001641789756]
	TIME [epoch: 6.64 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3304338617638156		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 1.3304338617638156 | validation: 1.2255023603923765]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.257350108998627		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 1.257350108998627 | validation: 1.335333934958757]
	TIME [epoch: 6.64 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3511403292675603		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 1.3511403292675603 | validation: 1.2274103400069647]
	TIME [epoch: 6.64 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2654256870559157		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 1.2654256870559157 | validation: 1.2533252288070842]
	TIME [epoch: 6.63 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2355380030073784		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 1.2355380030073784 | validation: 1.203064011723445]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3146064510405746		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 1.3146064510405746 | validation: 1.2491325085224867]
	TIME [epoch: 6.68 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3904366545764908		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 1.3904366545764908 | validation: 1.813393119701553]
	TIME [epoch: 6.64 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.8242733409760943		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 1.8242733409760943 | validation: 1.47256749863686]
	TIME [epoch: 6.64 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3714767156895857		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 1.3714767156895857 | validation: 1.3271122081961046]
	TIME [epoch: 6.63 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2766006813152795		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 1.2766006813152795 | validation: 1.2365120216492798]
	TIME [epoch: 6.63 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.247950505020945		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 1.247950505020945 | validation: 1.2803187101402167]
	TIME [epoch: 6.66 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2922677897169494		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 1.2922677897169494 | validation: 1.2614548853414809]
	TIME [epoch: 6.64 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.237881667503164		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 1.237881667503164 | validation: 1.2235876363561726]
	TIME [epoch: 6.62 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2410671454066606		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 1.2410671454066606 | validation: 1.228927137638082]
	TIME [epoch: 6.63 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2446045828201169		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 1.2446045828201169 | validation: 1.3260648729174842]
	TIME [epoch: 6.62 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2618269852037793		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 1.2618269852037793 | validation: 1.2252908561403364]
	TIME [epoch: 6.67 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2344461171524632		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 1.2344461171524632 | validation: 1.2228625484655589]
	TIME [epoch: 6.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2231783654798565		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 1.2231783654798565 | validation: 1.2093983660495038]
	TIME [epoch: 6.63 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2117444255337582		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 1.2117444255337582 | validation: 1.1752042859331586]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2227598303637248		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 1.2227598303637248 | validation: 1.231075114656861]
	TIME [epoch: 6.64 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2427746082227311		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 1.2427746082227311 | validation: 1.2650157274806755]
	TIME [epoch: 6.66 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2800376502631385		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 1.2800376502631385 | validation: 1.2012583963292598]
	TIME [epoch: 6.66 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2113998001894526		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 1.2113998001894526 | validation: 1.1993136928104828]
	TIME [epoch: 6.61 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2566553760006545		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 1.2566553760006545 | validation: 1.2919697007505804]
	TIME [epoch: 6.63 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2510037084027494		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 1.2510037084027494 | validation: 1.1932463290550597]
	TIME [epoch: 6.63 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2562338340990984		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 1.2562338340990984 | validation: 1.1649836031254068]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2691443461779253		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 1.2691443461779253 | validation: 1.1641087989216807]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1856851661603804		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 1.1856851661603804 | validation: 1.1485815234492989]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1642918113885758		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 1.1642918113885758 | validation: 1.1424740782493896]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.173151787936499		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 1.173151787936499 | validation: 1.2800268523769796]
	TIME [epoch: 6.57 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.4642640477324567		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 1.4642640477324567 | validation: 1.4488502248534791]
	TIME [epoch: 6.62 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3486245397422052		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 1.3486245397422052 | validation: 1.2033998368043688]
	TIME [epoch: 6.56 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.191668189544882		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 1.191668189544882 | validation: 1.2093101833752897]
	TIME [epoch: 6.56 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2031566516755827		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 1.2031566516755827 | validation: 1.1402940589095152]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1398649139341441		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 1.1398649139341441 | validation: 1.1196461378016822]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1524807179555354		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 1.1524807179555354 | validation: 1.171878706922492]
	TIME [epoch: 6.67 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2345199072838997		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 1.2345199072838997 | validation: 1.2407503077705586]
	TIME [epoch: 6.64 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.3182387534368831		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 1.3182387534368831 | validation: 1.1054614748214806]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1078043339051455		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 1.1078043339051455 | validation: 1.1059315571609076]
	TIME [epoch: 6.63 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1066564161520405		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 1.1066564161520405 | validation: 1.1076729329533512]
	TIME [epoch: 6.62 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1124337661595693		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 1.1124337661595693 | validation: 1.0764874960176247]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0960122600333988		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 1.0960122600333988 | validation: 1.1022983288364754]
	TIME [epoch: 6.69 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.2127479021396237		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 1.2127479021396237 | validation: 1.125863425360398]
	TIME [epoch: 6.65 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.115754727153551		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 1.115754727153551 | validation: 1.0729431748657456]
	TIME [epoch: 6.64 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1236236662905439		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 1.1236236662905439 | validation: 1.1284308419588285]
	TIME [epoch: 6.64 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0903048896481846		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 1.0903048896481846 | validation: 1.0563350762821686]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0961947145878692		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 1.0961947145878692 | validation: 1.0530905202605811]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.093675104083184		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 1.093675104083184 | validation: 1.0331197467263447]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0361079810302096		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 1.0361079810302096 | validation: 1.0710201024377082]
	TIME [epoch: 6.66 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.089002532941303		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 1.089002532941303 | validation: 1.2088101661761175]
	TIME [epoch: 6.67 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1448816618798237		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 1.1448816618798237 | validation: 1.106365922828745]
	TIME [epoch: 6.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.103739269254064		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 1.103739269254064 | validation: 0.9896813538177082]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0534246748508738		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 1.0534246748508738 | validation: 1.0273673091835591]
	TIME [epoch: 6.59 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0212909430901305		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 1.0212909430901305 | validation: 1.006739038120484]
	TIME [epoch: 6.58 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0918895979577248		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 1.0918895979577248 | validation: 1.2148475396278853]
	TIME [epoch: 6.57 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1777122293912567		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 1.1777122293912567 | validation: 1.000283682033316]
	TIME [epoch: 6.62 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1059010813493668		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 1.1059010813493668 | validation: 1.0353141346211057]
	TIME [epoch: 6.61 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0899778623219891		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 1.0899778623219891 | validation: 1.037979757831376]
	TIME [epoch: 6.58 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0463423165196688		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 1.0463423165196688 | validation: 1.0458049012280115]
	TIME [epoch: 6.57 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0353511990735529		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 1.0353511990735529 | validation: 1.0806610350594912]
	TIME [epoch: 6.56 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0131157078174013		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 1.0131157078174013 | validation: 0.9471045786136957]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0323233831297807		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 1.0323233831297807 | validation: 1.0086382635862958]
	TIME [epoch: 6.63 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1213893048883858		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 1.1213893048883858 | validation: 0.9943510211565976]
	TIME [epoch: 6.61 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0294808387375087		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 1.0294808387375087 | validation: 0.9823348883963399]
	TIME [epoch: 6.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9638315812753198		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.9638315812753198 | validation: 0.9460546598961032]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9967279312922226		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.9967279312922226 | validation: 1.1216178244167687]
	TIME [epoch: 6.66 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1749901290107847		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 1.1749901290107847 | validation: 0.9971540745314418]
	TIME [epoch: 6.67 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0328717089236221		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 1.0328717089236221 | validation: 0.9637460343296962]
	TIME [epoch: 6.63 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9613820854643584		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.9613820854643584 | validation: 0.9228776027844674]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9709258521488214		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.9709258521488214 | validation: 0.9323467109568482]
	TIME [epoch: 6.66 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9502731183728358		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.9502731183728358 | validation: 0.9279548360939534]
	TIME [epoch: 6.67 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9523408560429851		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.9523408560429851 | validation: 0.9111576734321933]
	TIME [epoch: 6.69 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9036194915673803		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.9036194915673803 | validation: 0.9634467347474944]
	TIME [epoch: 6.66 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9199266030935321		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.9199266030935321 | validation: 1.1115768858043722]
	TIME [epoch: 6.65 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.27836277898778		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 1.27836277898778 | validation: 0.9333601342599114]
	TIME [epoch: 6.64 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0093328596790165		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 1.0093328596790165 | validation: 0.9895805408259744]
	TIME [epoch: 6.68 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9466149964486934		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.9466149964486934 | validation: 0.872389002006943]
	TIME [epoch: 6.69 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9240140595917222		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.9240140595917222 | validation: 0.8649572541638583]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.913565316532585		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.913565316532585 | validation: 0.9333668767622343]
	TIME [epoch: 6.66 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9623773972894016		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.9623773972894016 | validation: 0.9061689585610941]
	TIME [epoch: 6.66 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9511153249402294		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.9511153249402294 | validation: 0.9284471606506453]
	TIME [epoch: 6.67 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9492964614274201		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.9492964614274201 | validation: 0.8769419803244635]
	TIME [epoch: 6.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9481844732272167		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.9481844732272167 | validation: 0.8695910975222152]
	TIME [epoch: 6.67 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8765950472782909		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.8765950472782909 | validation: 0.8641781182332905]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8639458552320232		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.8639458552320232 | validation: 0.933844581448885]
	TIME [epoch: 6.63 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9369408594613472		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.9369408594613472 | validation: 0.9316416461063444]
	TIME [epoch: 6.64 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8920761856456738		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.8920761856456738 | validation: 0.9390345525046213]
	TIME [epoch: 6.68 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9899118317356882		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.9899118317356882 | validation: 0.9410097325071934]
	TIME [epoch: 6.65 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9224726186409355		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.9224726186409355 | validation: 0.8353354167890217]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9063028668638031		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.9063028668638031 | validation: 0.8423142689245025]
	TIME [epoch: 6.55 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8713876268716669		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.8713876268716669 | validation: 0.8860518485660711]
	TIME [epoch: 6.58 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.853691392087125		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.853691392087125 | validation: 0.9033957975001166]
	TIME [epoch: 6.64 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8704041623371518		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.8704041623371518 | validation: 0.9404925088275731]
	TIME [epoch: 6.57 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9676082180491847		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.9676082180491847 | validation: 0.8410158623748849]
	TIME [epoch: 6.55 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.858193951541476		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.858193951541476 | validation: 0.8743428048491201]
	TIME [epoch: 6.57 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8839235485593655		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.8839235485593655 | validation: 0.8204061650345453]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8520734112736086		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.8520734112736086 | validation: 0.8416716958388138]
	TIME [epoch: 6.64 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8355458172901284		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.8355458172901284 | validation: 0.8378369350849909]
	TIME [epoch: 6.61 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8257911352879227		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.8257911352879227 | validation: 0.8560701983011563]
	TIME [epoch: 6.58 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8743723587221524		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.8743723587221524 | validation: 0.8726374290625011]
	TIME [epoch: 6.56 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9311025407442349		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.9311025407442349 | validation: 0.7945888961913256]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7964902019408581		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.7964902019408581 | validation: 0.7931488865432178]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8049100738708095		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.8049100738708095 | validation: 0.8126221330697405]
	TIME [epoch: 6.65 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7985737028922679		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.7985737028922679 | validation: 0.9596394968402889]
	TIME [epoch: 6.63 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9726720664580155		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.9726720664580155 | validation: 0.8802635288304965]
	TIME [epoch: 6.64 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8558937258580888		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.8558937258580888 | validation: 0.8455887305087821]
	TIME [epoch: 6.64 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8059128120487435		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.8059128120487435 | validation: 0.7875055492610885]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8214753336893431		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.8214753336893431 | validation: 0.9355210387595325]
	TIME [epoch: 6.68 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8316853162405142		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.8316853162405142 | validation: 0.735483081118672]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.78741476902665		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.78741476902665 | validation: 0.7524588021981838]
	TIME [epoch: 6.66 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8371447509054918		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.8371447509054918 | validation: 0.9505491067204445]
	TIME [epoch: 6.66 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8643981550735653		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.8643981550735653 | validation: 0.7677934301135317]
	TIME [epoch: 6.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8360160536763767		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.8360160536763767 | validation: 0.7324981791266968]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7442809538182906		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.7442809538182906 | validation: 0.8021644320538984]
	TIME [epoch: 6.66 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7827612609418813		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.7827612609418813 | validation: 0.8020520163767225]
	TIME [epoch: 6.65 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.771303849258143		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.771303849258143 | validation: 0.7257090079784035]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7404636909631392		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.7404636909631392 | validation: 0.7101894116571057]
	TIME [epoch: 6.69 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7614470491331008		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.7614470491331008 | validation: 1.0829155657910134]
	TIME [epoch: 6.66 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9802359183076317		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.9802359183076317 | validation: 0.7087597728083659]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7754469355229696		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.7754469355229696 | validation: 0.7007154859525732]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7177772074537188		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.7177772074537188 | validation: 0.7189557383920626]
	TIME [epoch: 6.59 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7247296716526299		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.7247296716526299 | validation: 0.7091799452302809]
	TIME [epoch: 6.64 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7243231258024105		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.7243231258024105 | validation: 0.7357085434514483]
	TIME [epoch: 6.59 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7288933443814176		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.7288933443814176 | validation: 0.6401787413558968]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6688132656305235		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.6688132656305235 | validation: 0.8557676381709897]
	TIME [epoch: 6.61 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8744270416386473		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.8744270416386473 | validation: 0.6211016202775262]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7031580002519312		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.7031580002519312 | validation: 0.662106573787244]
	TIME [epoch: 6.68 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7268687238082776		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.7268687238082776 | validation: 0.8552658893619527]
	TIME [epoch: 6.65 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8420143180725169		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.8420143180725169 | validation: 0.6527158236633467]
	TIME [epoch: 6.64 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8006849183171214		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.8006849183171214 | validation: 0.7569293307861966]
	TIME [epoch: 6.64 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7620088223220642		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.7620088223220642 | validation: 0.8235077773841077]
	TIME [epoch: 6.65 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7405743850529625		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.7405743850529625 | validation: 0.6070764648740768]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6565132847207991		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.6565132847207991 | validation: 0.6464365495962758]
	TIME [epoch: 6.67 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6769368712881653		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.6769368712881653 | validation: 0.7315940393149478]
	TIME [epoch: 6.65 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7100330597665819		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.7100330597665819 | validation: 0.6139179816695021]
	TIME [epoch: 6.66 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6561650519330966		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.6561650519330966 | validation: 0.6397188295079679]
	TIME [epoch: 6.65 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6632771693154944		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.6632771693154944 | validation: 0.6267818687689899]
	TIME [epoch: 6.69 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.723577463589743		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.723577463589743 | validation: 0.6123375767598468]
	TIME [epoch: 6.68 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8270499711269703		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.8270499711269703 | validation: 0.5731014979202904]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6739302875426298		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.6739302875426298 | validation: 0.5726446699594228]
	TIME [epoch: 6.66 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6573154767248939		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.6573154767248939 | validation: 0.5820300903485125]
	TIME [epoch: 6.66 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6819922858057481		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.6819922858057481 | validation: 0.7980073520995454]
	TIME [epoch: 6.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6989473671998845		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.6989473671998845 | validation: 0.5535859284923531]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7053634456634454		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.7053634456634454 | validation: 0.5939088968798083]
	TIME [epoch: 6.64 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6107574747350286		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.6107574747350286 | validation: 0.6810934925095827]
	TIME [epoch: 120 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.665611911811427		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.665611911811427 | validation: 0.8073786744613447]
	TIME [epoch: 14.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8283991019846868		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.8283991019846868 | validation: 0.733036027029331]
	TIME [epoch: 14.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6581123707845065		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.6581123707845065 | validation: 0.6013607504421499]
	TIME [epoch: 14.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6114585099222329		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.6114585099222329 | validation: 0.5467536373412782]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.597409098894068		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.597409098894068 | validation: 0.6519902141666087]
	TIME [epoch: 14.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7233415462162731		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.7233415462162731 | validation: 0.82326194255695]
	TIME [epoch: 14.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.9066145620388768		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.9066145620388768 | validation: 0.8147845648920875]
	TIME [epoch: 14.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7227407360647892		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.7227407360647892 | validation: 0.5626972035155625]
	TIME [epoch: 14.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6661887286944785		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.6661887286944785 | validation: 0.5561501849745284]
	TIME [epoch: 14.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6267761918642583		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.6267761918642583 | validation: 0.5282528679989186]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5987871028758711		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.5987871028758711 | validation: 0.5207128464605102]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5981968931846497		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.5981968931846497 | validation: 0.5388494922960103]
	TIME [epoch: 14.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5909946014853911		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.5909946014853911 | validation: 0.6395810194672112]
	TIME [epoch: 14.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6808385099256486		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.6808385099256486 | validation: 0.695040151078391]
	TIME [epoch: 14.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6704355549794752		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.6704355549794752 | validation: 0.5007601002423954]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5949242489691087		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.5949242489691087 | validation: 0.49472130717593715]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5779567854577801		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.5779567854577801 | validation: 0.6202349998890948]
	TIME [epoch: 14.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6911663585206068		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.6911663585206068 | validation: 0.6548866735055894]
	TIME [epoch: 14.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6483743677516287		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.6483743677516287 | validation: 0.5016095713542723]
	TIME [epoch: 14.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6892206563484942		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.6892206563484942 | validation: 0.7463832012841141]
	TIME [epoch: 14.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6921029850412161		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.6921029850412161 | validation: 0.9021381000596485]
	TIME [epoch: 14.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.788137401109439		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.788137401109439 | validation: 0.5135997376497908]
	TIME [epoch: 14.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5646175485420479		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.5646175485420479 | validation: 0.5857352960979473]
	TIME [epoch: 14.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5813147907113632		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.5813147907113632 | validation: 0.545580559654894]
	TIME [epoch: 14.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5757692962075893		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.5757692962075893 | validation: 0.5321647774596767]
	TIME [epoch: 14.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5699669274602184		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.5699669274602184 | validation: 0.9394459229224442]
	TIME [epoch: 14.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.841262259895382		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.841262259895382 | validation: 0.5534175459526572]
	TIME [epoch: 14.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6279002070051725		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.6279002070051725 | validation: 0.5700590372959015]
	TIME [epoch: 14.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6095504275245078		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.6095504275245078 | validation: 0.5181364919118355]
	TIME [epoch: 14.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5916181617630134		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.5916181617630134 | validation: 0.4766423331610479]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5563882733765744		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.5563882733765744 | validation: 0.6389901883523592]
	TIME [epoch: 14.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6741917015821346		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.6741917015821346 | validation: 0.5244297902462489]
	TIME [epoch: 14.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5578939456299246		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.5578939456299246 | validation: 0.4924192942365439]
	TIME [epoch: 14.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6419435019785091		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.6419435019785091 | validation: 0.6634645437668358]
	TIME [epoch: 14.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7011711275728978		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.7011711275728978 | validation: 0.5350570145223511]
	TIME [epoch: 14.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5956959773445715		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.5956959773445715 | validation: 0.5424027428872733]
	TIME [epoch: 14.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6237359096843439		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.6237359096843439 | validation: 0.5111700619322598]
	TIME [epoch: 14.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5795193169978164		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.5795193169978164 | validation: 0.485942175003989]
	TIME [epoch: 14.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5350505756180575		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.5350505756180575 | validation: 0.5222245300559534]
	TIME [epoch: 14.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5547445599458078		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.5547445599458078 | validation: 0.5222533538130619]
	TIME [epoch: 14.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5467978536486773		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.5467978536486773 | validation: 0.489212457348253]
	TIME [epoch: 14.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5162460575287144		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.5162460575287144 | validation: 0.4486965244431613]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5676649485145612		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.5676649485145612 | validation: 0.44965003690351213]
	TIME [epoch: 14.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5339603846846959		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.5339603846846959 | validation: 0.5016689728751738]
	TIME [epoch: 14.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5673214909322942		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.5673214909322942 | validation: 0.5724201316688927]
	TIME [epoch: 14.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6279679334535484		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.6279679334535484 | validation: 0.5893729167636019]
	TIME [epoch: 14.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6286017236877872		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.6286017236877872 | validation: 0.49417927633129044]
	TIME [epoch: 14.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5142795537379895		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.5142795537379895 | validation: 0.438959554886338]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5516131288394841		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.5516131288394841 | validation: 0.5445832627867944]
	TIME [epoch: 14.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8207589598984504		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.8207589598984504 | validation: 0.5608374442107465]
	TIME [epoch: 14.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5373017718390506		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.5373017718390506 | validation: 0.5421254424863896]
	TIME [epoch: 14.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5312684282944525		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.5312684282944525 | validation: 0.47411609595943294]
	TIME [epoch: 14.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5037797378408632		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.5037797378408632 | validation: 0.42230245738766503]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5050627191452244		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.5050627191452244 | validation: 0.5228928485062679]
	TIME [epoch: 14.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5026072758277367		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.5026072758277367 | validation: 0.4025414047886144]
	TIME [epoch: 14.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5276853100557681		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.5276853100557681 | validation: 0.5053339222124092]
	TIME [epoch: 14.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5628250058224984		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.5628250058224984 | validation: 0.45047678692378473]
	TIME [epoch: 14.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.47936967062612734		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.47936967062612734 | validation: 0.5893389263689022]
	TIME [epoch: 14.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5164076595229518		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.5164076595229518 | validation: 0.5019784202639456]
	TIME [epoch: 14.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7458321804293728		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.7458321804293728 | validation: 1.0225777360730657]
	TIME [epoch: 14.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6379092307109848		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.6379092307109848 | validation: 0.5694279937122211]
	TIME [epoch: 14.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6328539774233375		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.6328539774233375 | validation: 0.4090456331544383]
	TIME [epoch: 14.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5087301681917178		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.5087301681917178 | validation: 0.4393226589534087]
	TIME [epoch: 14.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4730894000994358		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.4730894000994358 | validation: 0.4384191649355284]
	TIME [epoch: 14.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.49139159883513434		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.49139159883513434 | validation: 0.5262481001737737]
	TIME [epoch: 14.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5565567806984159		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.5565567806984159 | validation: 0.5427935396609133]
	TIME [epoch: 14.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5407963650875502		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.5407963650875502 | validation: 0.4075797891778679]
	TIME [epoch: 14.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5014751821397725		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.5014751821397725 | validation: 0.6187124451263164]
	TIME [epoch: 14.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5012906595817227		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.5012906595817227 | validation: 0.6865119621591227]
	TIME [epoch: 14.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6713773128898558		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.6713773128898558 | validation: 0.6933827272779115]
	TIME [epoch: 14.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5629010009062405		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.5629010009062405 | validation: 0.7692371850298192]
	TIME [epoch: 14.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6157548672117241		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.6157548672117241 | validation: 0.41495391929136916]
	TIME [epoch: 14.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.42882256849036127		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.42882256849036127 | validation: 0.4122472449684373]
	TIME [epoch: 14.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.43571060456696536		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.43571060456696536 | validation: 0.4596496223498475]
	TIME [epoch: 14.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5934323353179586		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.5934323353179586 | validation: 0.5928018499343909]
	TIME [epoch: 14.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5693908264363644		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.5693908264363644 | validation: 0.7715923782248639]
	TIME [epoch: 14.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6363976168297993		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.6363976168297993 | validation: 0.5863345313904137]
	TIME [epoch: 14.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.544981753857621		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.544981753857621 | validation: 0.7289567152571215]
	TIME [epoch: 14.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6072723526604595		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.6072723526604595 | validation: 0.5993500135828749]
	TIME [epoch: 14.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5810388743906857		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.5810388743906857 | validation: 0.4229023886946191]
	TIME [epoch: 14.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.45910892403626824		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.45910892403626824 | validation: 0.43038283649084347]
	TIME [epoch: 14.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.42907007380226775		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.42907007380226775 | validation: 0.43434537804371776]
	TIME [epoch: 14.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4586630766915138		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.4586630766915138 | validation: 0.7732654213092975]
	TIME [epoch: 14.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6144388170022914		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.6144388170022914 | validation: 0.4945446193568415]
	TIME [epoch: 14.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4204027414827606		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.4204027414827606 | validation: 0.3527040500181654]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4965787549450266		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.4965787549450266 | validation: 0.4789596453230222]
	TIME [epoch: 14.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.47738386047428316		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.47738386047428316 | validation: 0.43233998799335754]
	TIME [epoch: 14.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.43871825138924136		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.43871825138924136 | validation: 0.46828696558802396]
	TIME [epoch: 14.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.47927905929688586		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.47927905929688586 | validation: 0.49588418418609415]
	TIME [epoch: 14.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.44289467535504057		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.44289467535504057 | validation: 0.3291948441640049]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.42959060175092567		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.42959060175092567 | validation: 1.0216907759207763]
	TIME [epoch: 14.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6732341746424091		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.6732341746424091 | validation: 0.33620317078272094]
	TIME [epoch: 14.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4329444378431013		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.4329444378431013 | validation: 0.32278209505892835]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.38907315716307844		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.38907315716307844 | validation: 0.47500677412661274]
	TIME [epoch: 14.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.40197036143298526		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.40197036143298526 | validation: 0.32376035153356314]
	TIME [epoch: 14.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7220703378033759		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.7220703378033759 | validation: 0.5168556186829515]
	TIME [epoch: 14.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5397403969499546		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.5397403969499546 | validation: 0.8933974336412263]
	TIME [epoch: 14.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.7245205954355713		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.7245205954355713 | validation: 0.5116672274520615]
	TIME [epoch: 14.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.45959050759601416		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.45959050759601416 | validation: 0.4190391458385234]
	TIME [epoch: 14.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4365053816976334		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.4365053816976334 | validation: 0.595889727627588]
	TIME [epoch: 14.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5669748701404003		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.5669748701404003 | validation: 0.4939273066463901]
	TIME [epoch: 14.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.41292442318146116		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.41292442318146116 | validation: 0.30053060349639393]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4775503546961992		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.4775503546961992 | validation: 0.4467589401165151]
	TIME [epoch: 14.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.40591638246395145		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.40591638246395145 | validation: 0.5302225321053625]
	TIME [epoch: 14.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.43053576317890907		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.43053576317890907 | validation: 0.33084116561783705]
	TIME [epoch: 14.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3756370295307716		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.3756370295307716 | validation: 0.6190723328965515]
	TIME [epoch: 14.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4859024544636473		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.4859024544636473 | validation: 0.3167291399729056]
	TIME [epoch: 14.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.1427924780877035		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 1.1427924780877035 | validation: 1.3910680333195158]
	TIME [epoch: 14.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 2/2] avg loss: 1.0387782721764853		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 1.0387782721764853 | validation: 0.6785501006954285]
	TIME [epoch: 14.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.581266209739386		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.581266209739386 | validation: 0.594501372613699]
	TIME [epoch: 14.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5361077704510725		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.5361077704510725 | validation: 0.327984669383536]
	TIME [epoch: 14.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4051250643836542		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.4051250643836542 | validation: 0.4050232536637703]
	TIME [epoch: 14.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3846885248113876		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.3846885248113876 | validation: 0.44641115276343757]
	TIME [epoch: 14.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5118439216476455		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.5118439216476455 | validation: 0.38491219672999366]
	TIME [epoch: 14.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.40841799998895534		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.40841799998895534 | validation: 0.30834667852858644]
	TIME [epoch: 14.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.836423978023406		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.836423978023406 | validation: 0.9229564016082957]
	TIME [epoch: 14.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8201277375579482		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.8201277375579482 | validation: 0.43085486840047826]
	TIME [epoch: 14.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4654901871534139		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.4654901871534139 | validation: 0.693646513396283]
	TIME [epoch: 14.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.49057272833331594		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.49057272833331594 | validation: 0.36672045324726166]
	TIME [epoch: 14.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3830409408505354		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.3830409408505354 | validation: 0.33959965717646023]
	TIME [epoch: 14.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.36659754646248377		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.36659754646248377 | validation: 0.42576761373035565]
	TIME [epoch: 14.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.38232823451743714		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.38232823451743714 | validation: 0.4321159379231048]
	TIME [epoch: 14.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3725228607961506		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.3725228607961506 | validation: 0.3375117422190642]
	TIME [epoch: 14.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.342144186280124		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.342144186280124 | validation: 0.3778432547373807]
	TIME [epoch: 14.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.38557503531915177		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.38557503531915177 | validation: 0.3114046434071905]
	TIME [epoch: 14.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3523070409287964		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.3523070409287964 | validation: 0.4447113090604214]
	TIME [epoch: 14.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.36896125968973964		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.36896125968973964 | validation: 0.3185340067123004]
	TIME [epoch: 14.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3642027821398638		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.3642027821398638 | validation: 0.3038021005257851]
	TIME [epoch: 14.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3536411585954985		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.3536411585954985 | validation: 0.42763687245761217]
	TIME [epoch: 14.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.36045953265915043		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.36045953265915043 | validation: 0.3547153774700138]
	TIME [epoch: 14.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.36588648270080915		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.36588648270080915 | validation: 0.6572816966742812]
	TIME [epoch: 14.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5991942328573605		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.5991942328573605 | validation: 0.42809621026370925]
	TIME [epoch: 14.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.448800998092002		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.448800998092002 | validation: 0.6192132923573478]
	TIME [epoch: 14.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4252517117187745		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.4252517117187745 | validation: 0.29128047153163833]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.37808272482017624		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.37808272482017624 | validation: 0.40993022171121285]
	TIME [epoch: 14.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4483451642415027		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.4483451642415027 | validation: 0.39976850329363134]
	TIME [epoch: 14.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.37112308208408373		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.37112308208408373 | validation: 0.29074296497029]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.35926510645542287		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.35926510645542287 | validation: 0.5811108382793151]
	TIME [epoch: 14.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.44279820778939466		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.44279820778939466 | validation: 0.3256868196316306]
	TIME [epoch: 14.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3206373238020545		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.3206373238020545 | validation: 0.4226000554188028]
	TIME [epoch: 14.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.42029149259824317		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.42029149259824317 | validation: 0.33811842074082926]
	TIME [epoch: 14.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3610772325322026		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.3610772325322026 | validation: 0.46807846812691684]
	TIME [epoch: 14.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4058009011425968		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.4058009011425968 | validation: 0.28661340567928245]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.35768213061985005		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.35768213061985005 | validation: 0.4803026232300461]
	TIME [epoch: 14.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.37173166352166076		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.37173166352166076 | validation: 0.44756443359256814]
	TIME [epoch: 14.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4639894783984817		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.4639894783984817 | validation: 0.32058873311358504]
	TIME [epoch: 14.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.41476093406971126		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.41476093406971126 | validation: 0.6471803719387298]
	TIME [epoch: 14.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4872958215066303		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.4872958215066303 | validation: 0.4470203156404951]
	TIME [epoch: 14.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.36101631718636873		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.36101631718636873 | validation: 0.27666552462296834]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2839550378358482		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.2839550378358482 | validation: 0.33579845710033696]
	TIME [epoch: 14.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3327965250964685		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.3327965250964685 | validation: 0.2545513196325164]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3169815221656596		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.3169815221656596 | validation: 0.35166660449237575]
	TIME [epoch: 14.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.32140202310407173		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.32140202310407173 | validation: 0.29017991548728056]
	TIME [epoch: 14.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.31905106852248327		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.31905106852248327 | validation: 0.38845437040386444]
	TIME [epoch: 14.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.33439083464469516		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.33439083464469516 | validation: 0.3671843437330386]
	TIME [epoch: 14.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3334541999592796		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.3334541999592796 | validation: 0.2586495193368795]
	TIME [epoch: 14.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2948798784602277		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.2948798784602277 | validation: 0.4750464597004522]
	TIME [epoch: 14.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4517998967998057		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.4517998967998057 | validation: 0.26644915711000233]
	TIME [epoch: 14.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.8267917830890787		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.8267917830890787 | validation: 0.5293537188957943]
	TIME [epoch: 14.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.48986834938186363		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.48986834938186363 | validation: 0.5451776317916357]
	TIME [epoch: 14.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4315636503266188		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.4315636503266188 | validation: 0.3875756952351741]
	TIME [epoch: 14.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3150352317739024		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.3150352317739024 | validation: 0.22573765708655485]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.26266640206751446		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.26266640206751446 | validation: 0.277366079340937]
	TIME [epoch: 14.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.29194873775934105		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.29194873775934105 | validation: 0.575645927113411]
	TIME [epoch: 14.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5961650342674596		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.5961650342674596 | validation: 0.2681920548860583]
	TIME [epoch: 14.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.31351605781941666		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.31351605781941666 | validation: 0.4460759200888054]
	TIME [epoch: 14.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.34016948219705334		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.34016948219705334 | validation: 0.2359214913618678]
	TIME [epoch: 14.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2728923055878446		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.2728923055878446 | validation: 0.3011717585154379]
	TIME [epoch: 14.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.29847171802337014		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.29847171802337014 | validation: 0.38116876993246085]
	TIME [epoch: 14.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3543520560114972		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.3543520560114972 | validation: 0.36416000948438604]
	TIME [epoch: 14.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.31347306066822034		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.31347306066822034 | validation: 0.27655909493961717]
	TIME [epoch: 14.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3172649100315734		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.3172649100315734 | validation: 0.2270784404185572]
	TIME [epoch: 14.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2670280365755018		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.2670280365755018 | validation: 0.368141437272983]
	TIME [epoch: 14.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.44929340865631745		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.44929340865631745 | validation: 0.7109286429991146]
	TIME [epoch: 14.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.38091466946763797		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.38091466946763797 | validation: 0.27240021966076544]
	TIME [epoch: 14.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2948651296112777		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.2948651296112777 | validation: 0.24028664891430634]
	TIME [epoch: 14.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.35958751092216196		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.35958751092216196 | validation: 0.5924755490630951]
	TIME [epoch: 14.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3926958714429285		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.3926958714429285 | validation: 0.27319915199323347]
	TIME [epoch: 14.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.28513920577256846		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.28513920577256846 | validation: 0.21540575396726927]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2865404453584217		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.2865404453584217 | validation: 0.3540409559790876]
	TIME [epoch: 14.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.34490175591050914		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.34490175591050914 | validation: 0.22864013480480969]
	TIME [epoch: 14.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2807654512135458		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.2807654512135458 | validation: 0.3251251134928739]
	TIME [epoch: 14.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3616643427213719		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.3616643427213719 | validation: 0.480183032836516]
	TIME [epoch: 14.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3694703424575124		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.3694703424575124 | validation: 0.2576982142762669]
	TIME [epoch: 14.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6292112462244657		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.6292112462244657 | validation: 0.723859901176846]
	TIME [epoch: 14.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.669432364233636		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.669432364233636 | validation: 0.39050627749733313]
	TIME [epoch: 14.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3979932612458439		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.3979932612458439 | validation: 0.49141732072841704]
	TIME [epoch: 14.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.33332514830472704		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.33332514830472704 | validation: 0.22593356248367497]
	TIME [epoch: 14.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.26127397919843365		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.26127397919843365 | validation: 0.3716031312661833]
	TIME [epoch: 14.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.4164791725979877		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.4164791725979877 | validation: 0.30431913997684634]
	TIME [epoch: 14.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.341763035117962		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.341763035117962 | validation: 0.3662701133100284]
	TIME [epoch: 14.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.32214808377281934		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.32214808377281934 | validation: 0.24984254178493048]
	TIME [epoch: 14.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3130832842610308		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.3130832842610308 | validation: 0.21904353293266104]
	TIME [epoch: 14.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.28004069797667985		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.28004069797667985 | validation: 0.35133141559418923]
	TIME [epoch: 14.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.29614310786913334		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.29614310786913334 | validation: 0.22605883818118558]
	TIME [epoch: 14.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25024989421369803		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.25024989421369803 | validation: 0.2930774994504972]
	TIME [epoch: 14.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2813867241894303		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.2813867241894303 | validation: 0.24323743009283527]
	TIME [epoch: 14.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2722396401123252		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.2722396401123252 | validation: 0.23270909133456588]
	TIME [epoch: 14.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2613240859344839		[learning rate: 0.00070419]
	Learning Rate: 0.000704194
	LOSS [training: 0.2613240859344839 | validation: 0.5397014005383681]
	TIME [epoch: 14.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.37544491331547775		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.37544491331547775 | validation: 0.36882371140298614]
	TIME [epoch: 14.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3056223954071139		[learning rate: 0.00069429]
	Learning Rate: 0.000694286
	LOSS [training: 0.3056223954071139 | validation: 0.27244164529340387]
	TIME [epoch: 14.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.315223925519318		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.315223925519318 | validation: 0.33736215719749935]
	TIME [epoch: 14.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.32635309250708555		[learning rate: 0.00068452]
	Learning Rate: 0.000684518
	LOSS [training: 0.32635309250708555 | validation: 0.22324461856633318]
	TIME [epoch: 14.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25217188712890193		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.25217188712890193 | validation: 0.23577144191190694]
	TIME [epoch: 14.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2689583937125734		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.2689583937125734 | validation: 0.24211068048366596]
	TIME [epoch: 14.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24368657294345536		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.24368657294345536 | validation: 0.269509975064031]
	TIME [epoch: 14.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2785963130688761		[learning rate: 0.00066539]
	Learning Rate: 0.000665391
	LOSS [training: 0.2785963130688761 | validation: 0.24057692215757004]
	TIME [epoch: 14.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2846794795156157		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.2846794795156157 | validation: 0.22755524518848447]
	TIME [epoch: 14.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23971121893671604		[learning rate: 0.00065603]
	Learning Rate: 0.000656029
	LOSS [training: 0.23971121893671604 | validation: 0.24156292732075046]
	TIME [epoch: 14.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.27029717860645236		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.27029717860645236 | validation: 0.2179829720897618]
	TIME [epoch: 14.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2390845871525864		[learning rate: 0.0006468]
	Learning Rate: 0.000646799
	LOSS [training: 0.2390845871525864 | validation: 0.22952421010079518]
	TIME [epoch: 14.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25148679505471994		[learning rate: 0.00064223]
	Learning Rate: 0.000642233
	LOSS [training: 0.25148679505471994 | validation: 0.19515386422875902]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.26955840619082716		[learning rate: 0.0006377]
	Learning Rate: 0.000637699
	LOSS [training: 0.26955840619082716 | validation: 0.23175842843094274]
	TIME [epoch: 14.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.253416411582198		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.253416411582198 | validation: 0.25242862852930775]
	TIME [epoch: 14.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2662524719979854		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.2662524719979854 | validation: 0.22154041399777002]
	TIME [epoch: 14.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25516033722574416		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.25516033722574416 | validation: 0.18741690824088172]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2529483972919994		[learning rate: 0.00061988]
	Learning Rate: 0.00061988
	LOSS [training: 0.2529483972919994 | validation: 0.4937443164996208]
	TIME [epoch: 14.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3173398890205081		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.3173398890205081 | validation: 0.2292167070038887]
	TIME [epoch: 14.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23912363236938594		[learning rate: 0.00061116]
	Learning Rate: 0.000611158
	LOSS [training: 0.23912363236938594 | validation: 0.7400204630596007]
	TIME [epoch: 14.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.760013242512968		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.760013242512968 | validation: 0.3487042043311214]
	TIME [epoch: 14.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.27948879153202405		[learning rate: 0.00060256]
	Learning Rate: 0.00060256
	LOSS [training: 0.27948879153202405 | validation: 0.23752154361723596]
	TIME [epoch: 14.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24050365036218296		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.24050365036218296 | validation: 0.2587305273465152]
	TIME [epoch: 14.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2681806230968513		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.2681806230968513 | validation: 0.17611358839960503]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23862455600258203		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.23862455600258203 | validation: 0.280134292904937]
	TIME [epoch: 14.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25428959436404347		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.25428959436404347 | validation: 0.19681644662458753]
	TIME [epoch: 14.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21500501259980873		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.21500501259980873 | validation: 0.24983444126339702]
	TIME [epoch: 14.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24116286713485874		[learning rate: 0.00057748]
	Learning Rate: 0.000577482
	LOSS [training: 0.24116286713485874 | validation: 0.277266538003378]
	TIME [epoch: 14.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24126491447723525		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.24126491447723525 | validation: 0.5879431006937351]
	TIME [epoch: 14.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.6181921190286745		[learning rate: 0.00056936]
	Learning Rate: 0.000569357
	LOSS [training: 0.6181921190286745 | validation: 0.5525155671836567]
	TIME [epoch: 14.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.42805104518728354		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.42805104518728354 | validation: 0.2814430492915994]
	TIME [epoch: 14.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.27172134524555025		[learning rate: 0.00056135]
	Learning Rate: 0.000561346
	LOSS [training: 0.27172134524555025 | validation: 0.19259225025493534]
	TIME [epoch: 14.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22074247389490703		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.22074247389490703 | validation: 0.32243853614384815]
	TIME [epoch: 14.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2506087462374389		[learning rate: 0.00055345]
	Learning Rate: 0.000553448
	LOSS [training: 0.2506087462374389 | validation: 0.1983979844817666]
	TIME [epoch: 14.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21833440478696398		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.21833440478696398 | validation: 0.22162748868830598]
	TIME [epoch: 14.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2746604067171837		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.2746604067171837 | validation: 0.1775119137051987]
	TIME [epoch: 14.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22944824927603685		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.22944824927603685 | validation: 0.2586761319695467]
	TIME [epoch: 14.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2653727312013988		[learning rate: 0.00053798]
	Learning Rate: 0.000537984
	LOSS [training: 0.2653727312013988 | validation: 0.18362718559167487]
	TIME [epoch: 14.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21156733534525574		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.21156733534525574 | validation: 0.1862817689534678]
	TIME [epoch: 14.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2158238976017275		[learning rate: 0.00053041]
	Learning Rate: 0.000530415
	LOSS [training: 0.2158238976017275 | validation: 0.268465015060312]
	TIME [epoch: 14.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22012591848966248		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.22012591848966248 | validation: 0.20338033249714338]
	TIME [epoch: 14.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23697164229818557		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.23697164229818557 | validation: 0.3819760161567821]
	TIME [epoch: 14.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.26476748274901574		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.26476748274901574 | validation: 0.2263853936220467]
	TIME [epoch: 14.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2132651443149126		[learning rate: 0.00051559]
	Learning Rate: 0.000515594
	LOSS [training: 0.2132651443149126 | validation: 0.17640567684731306]
	TIME [epoch: 14.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20162326823641777		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.20162326823641777 | validation: 0.27684837185338]
	TIME [epoch: 14.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23556602995491077		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.23556602995491077 | validation: 0.20074445867778348]
	TIME [epoch: 14.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2871731804924863		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.2871731804924863 | validation: 0.19826257521058457]
	TIME [epoch: 14.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2670094951128343		[learning rate: 0.00050119]
	Learning Rate: 0.000501187
	LOSS [training: 0.2670094951128343 | validation: 0.23182942150324348]
	TIME [epoch: 14.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23545059830645662		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.23545059830645662 | validation: 0.17537928102265665]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20815871532824834		[learning rate: 0.00049414]
	Learning Rate: 0.000494136
	LOSS [training: 0.20815871532824834 | validation: 0.2011593905792129]
	TIME [epoch: 14.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21819451954264146		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.21819451954264146 | validation: 0.21374288429641078]
	TIME [epoch: 14.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21297518391456094		[learning rate: 0.00048718]
	Learning Rate: 0.000487183
	LOSS [training: 0.21297518391456094 | validation: 0.16668941468435183]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1990151843152263		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.1990151843152263 | validation: 0.16652359111997353]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19987624102580978		[learning rate: 0.00048033]
	Learning Rate: 0.000480329
	LOSS [training: 0.19987624102580978 | validation: 0.19884096339290241]
	TIME [epoch: 14.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19376048738873902		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.19376048738873902 | validation: 0.19021498639853848]
	TIME [epoch: 14.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1976669420197978		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.1976669420197978 | validation: 0.21623607635889314]
	TIME [epoch: 14.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22514928501664516		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.22514928501664516 | validation: 0.2120607172262664]
	TIME [epoch: 14.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19691929861765498		[learning rate: 0.00046691]
	Learning Rate: 0.000466907
	LOSS [training: 0.19691929861765498 | validation: 0.22059078902932772]
	TIME [epoch: 14.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20906771127858828		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.20906771127858828 | validation: 0.17172010760741419]
	TIME [epoch: 14.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19570172139713474		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.19570172139713474 | validation: 0.2516404288811484]
	TIME [epoch: 14.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20551491787377485		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.20551491787377485 | validation: 0.20759930794434345]
	TIME [epoch: 14.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22254130612341938		[learning rate: 0.00045386]
	Learning Rate: 0.000453861
	LOSS [training: 0.22254130612341938 | validation: 0.15244445629234882]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2060607344054283		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.2060607344054283 | validation: 0.2071564123657638]
	TIME [epoch: 14.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20983026914862712		[learning rate: 0.00044748]
	Learning Rate: 0.000447476
	LOSS [training: 0.20983026914862712 | validation: 0.17241299957199457]
	TIME [epoch: 14.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24156994482278163		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.24156994482278163 | validation: 0.19909264224636145]
	TIME [epoch: 14.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19775653783139785		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.19775653783139785 | validation: 0.17448439782806047]
	TIME [epoch: 14.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19588966447264178		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.19588966447264178 | validation: 0.2185323093713838]
	TIME [epoch: 14.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22707901157416874		[learning rate: 0.00043497]
	Learning Rate: 0.000434972
	LOSS [training: 0.22707901157416874 | validation: 0.1593923447662382]
	TIME [epoch: 14.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18069824985376287		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.18069824985376287 | validation: 0.19389868599219018]
	TIME [epoch: 14.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18158633746516883		[learning rate: 0.00042885]
	Learning Rate: 0.000428852
	LOSS [training: 0.18158633746516883 | validation: 0.2724545534504756]
	TIME [epoch: 14.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.24050454030270213		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.24050454030270213 | validation: 0.17344201433927708]
	TIME [epoch: 14.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20198711434417993		[learning rate: 0.00042282]
	Learning Rate: 0.000422818
	LOSS [training: 0.20198711434417993 | validation: 0.21001171556856146]
	TIME [epoch: 14.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1994589520557472		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.1994589520557472 | validation: 0.18184483147399447]
	TIME [epoch: 14.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20834572654387348		[learning rate: 0.00041687]
	Learning Rate: 0.000416869
	LOSS [training: 0.20834572654387348 | validation: 0.19204740356204716]
	TIME [epoch: 14.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20143209823624436		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.20143209823624436 | validation: 0.18050698210788674]
	TIME [epoch: 14.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18878529631658922		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.18878529631658922 | validation: 0.15608675861532498]
	TIME [epoch: 14.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.35511819269028166		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.35511819269028166 | validation: 0.30307519562588314]
	TIME [epoch: 14.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.27052983110667084		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.27052983110667084 | validation: 0.3632442774987918]
	TIME [epoch: 14.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.32098702505819077		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.32098702505819077 | validation: 0.37271695730516996]
	TIME [epoch: 14.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.23357077194553205		[learning rate: 0.00039952]
	Learning Rate: 0.00039952
	LOSS [training: 0.23357077194553205 | validation: 0.15985083784836246]
	TIME [epoch: 14.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17465805251807923		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.17465805251807923 | validation: 0.16923405762194121]
	TIME [epoch: 14.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19696390017514703		[learning rate: 0.0003939]
	Learning Rate: 0.000393899
	LOSS [training: 0.19696390017514703 | validation: 0.2782841700153087]
	TIME [epoch: 14.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2517938150316013		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.2517938150316013 | validation: 0.19875062298118068]
	TIME [epoch: 14.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.25100928351483726		[learning rate: 0.00038836]
	Learning Rate: 0.000388357
	LOSS [training: 0.25100928351483726 | validation: 0.1947253761468447]
	TIME [epoch: 14.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20567982140324842		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.20567982140324842 | validation: 0.19348972007274612]
	TIME [epoch: 14.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1798033060709766		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.1798033060709766 | validation: 0.1628526156304373]
	TIME [epoch: 14.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17827465843931797		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.17827465843931797 | validation: 0.1677782290203668]
	TIME [epoch: 14.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17447217830106		[learning rate: 0.00037751]
	Learning Rate: 0.000377505
	LOSS [training: 0.17447217830106 | validation: 0.1851112426927849]
	TIME [epoch: 14.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1735253447991616		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.1735253447991616 | validation: 0.14885839908233645]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16488090492151133		[learning rate: 0.00037219]
	Learning Rate: 0.000372194
	LOSS [training: 0.16488090492151133 | validation: 0.16734313540674717]
	TIME [epoch: 14.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2011531814478174		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.2011531814478174 | validation: 0.20503676254363104]
	TIME [epoch: 14.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18306408570938051		[learning rate: 0.00036696]
	Learning Rate: 0.000366957
	LOSS [training: 0.18306408570938051 | validation: 0.15723242721656308]
	TIME [epoch: 14.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18260701251158384		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.18260701251158384 | validation: 0.19435242842077294]
	TIME [epoch: 14.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2071871140980378		[learning rate: 0.00036179]
	Learning Rate: 0.000361794
	LOSS [training: 0.2071871140980378 | validation: 0.16256900804341434]
	TIME [epoch: 14.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18978212653409637		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.18978212653409637 | validation: 0.15819134906456733]
	TIME [epoch: 14.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1724437010963662		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.1724437010963662 | validation: 0.4884963229035531]
	TIME [epoch: 14.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.5257286181267364		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.5257286181267364 | validation: 0.5624548905974853]
	TIME [epoch: 14.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.44875644862826136		[learning rate: 0.00035169]
	Learning Rate: 0.000351685
	LOSS [training: 0.44875644862826136 | validation: 0.20412102279512045]
	TIME [epoch: 14.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2056981878338083		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.2056981878338083 | validation: 0.1783967535140435]
	TIME [epoch: 14.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20711095820459674		[learning rate: 0.00034674]
	Learning Rate: 0.000346737
	LOSS [training: 0.20711095820459674 | validation: 0.1750274267666576]
	TIME [epoch: 14.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17886612989629191		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.17886612989629191 | validation: 0.15213718831549553]
	TIME [epoch: 136 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16602174030631045		[learning rate: 0.00034186]
	Learning Rate: 0.000341858
	LOSS [training: 0.16602174030631045 | validation: 0.16657475143887235]
	TIME [epoch: 31 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17627349626276356		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.17627349626276356 | validation: 0.14398333767210017]
	TIME [epoch: 31.1 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16985675682265178		[learning rate: 0.00033705]
	Learning Rate: 0.000337048
	LOSS [training: 0.16985675682265178 | validation: 0.27637394598981113]
	TIME [epoch: 31.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.3335520345415933		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.3335520345415933 | validation: 0.15482813243933846]
	TIME [epoch: 31 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20682352395316192		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.20682352395316192 | validation: 0.21430087293653433]
	TIME [epoch: 31.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20813824844453865		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.20813824844453865 | validation: 0.14467933057942317]
	TIME [epoch: 31.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16385062472692763		[learning rate: 0.00032763]
	Learning Rate: 0.000327631
	LOSS [training: 0.16385062472692763 | validation: 0.14990258549103327]
	TIME [epoch: 31.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16667383535225294		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.16667383535225294 | validation: 0.15809001392058228]
	TIME [epoch: 31.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17403307976782845		[learning rate: 0.00032302]
	Learning Rate: 0.000323021
	LOSS [training: 0.17403307976782845 | validation: 0.1403623543953578]
	TIME [epoch: 31 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19293324070363455		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.19293324070363455 | validation: 0.34569681399694]
	TIME [epoch: 31.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2259733962808136		[learning rate: 0.00031848]
	Learning Rate: 0.000318476
	LOSS [training: 0.2259733962808136 | validation: 0.1603814300058316]
	TIME [epoch: 31 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18523432438764492		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.18523432438764492 | validation: 0.1486034260077822]
	TIME [epoch: 31.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1707065841230012		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.1707065841230012 | validation: 0.16338504835056164]
	TIME [epoch: 31.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15968777642754634		[learning rate: 0.00031178]
	Learning Rate: 0.000311779
	LOSS [training: 0.15968777642754634 | validation: 0.156065606740336]
	TIME [epoch: 31.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.2034020140563043		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.2034020140563043 | validation: 0.3235017067085485]
	TIME [epoch: 31.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.21501221865100362		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.21501221865100362 | validation: 0.15128658415464283]
	TIME [epoch: 31.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16597830990578533		[learning rate: 0.00030522]
	Learning Rate: 0.000305222
	LOSS [training: 0.16597830990578533 | validation: 0.15285108444182954]
	TIME [epoch: 31.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1693803640762332		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.1693803640762332 | validation: 0.19918176471749607]
	TIME [epoch: 31.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17387596818420084		[learning rate: 0.00030093]
	Learning Rate: 0.000300927
	LOSS [training: 0.17387596818420084 | validation: 0.16225457651461395]
	TIME [epoch: 31.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16889894522746757		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.16889894522746757 | validation: 0.15724185963007065]
	TIME [epoch: 30.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1629152131193402		[learning rate: 0.00029669]
	Learning Rate: 0.000296693
	LOSS [training: 0.1629152131193402 | validation: 0.160561019087679]
	TIME [epoch: 31 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19783271777922204		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.19783271777922204 | validation: 0.18949514401223233]
	TIME [epoch: 31 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18368530227729113		[learning rate: 0.00029252]
	Learning Rate: 0.000292519
	LOSS [training: 0.18368530227729113 | validation: 0.13994202205351977]
	TIME [epoch: 31 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1710034528104977		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.1710034528104977 | validation: 0.14628115183740728]
	TIME [epoch: 31 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16388599062565445		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.16388599062565445 | validation: 0.16721214499226444]
	TIME [epoch: 31 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17974206319500075		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.17974206319500075 | validation: 0.1418341816224523]
	TIME [epoch: 31.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16619813023523064		[learning rate: 0.00028435]
	Learning Rate: 0.000284345
	LOSS [training: 0.16619813023523064 | validation: 0.16074715246326324]
	TIME [epoch: 31 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.18192893369692326		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.18192893369692326 | validation: 0.16256674536169805]
	TIME [epoch: 31.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16586730787526077		[learning rate: 0.00028034]
	Learning Rate: 0.000280345
	LOSS [training: 0.16586730787526077 | validation: 0.1458754657268653]
	TIME [epoch: 30.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16135005518369006		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.16135005518369006 | validation: 0.16716291755604668]
	TIME [epoch: 31.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16600611257706477		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.16600611257706477 | validation: 0.14828303430799333]
	TIME [epoch: 31 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15842354032051142		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.15842354032051142 | validation: 0.145260239448838]
	TIME [epoch: 31 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15614114337201104		[learning rate: 0.00027251]
	Learning Rate: 0.000272511
	LOSS [training: 0.15614114337201104 | validation: 0.1910374827702121]
	TIME [epoch: 31 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1734978519625911		[learning rate: 0.00027059]
	Learning Rate: 0.000270588
	LOSS [training: 0.1734978519625911 | validation: 0.14515938720287594]
	TIME [epoch: 31.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15428034012462655		[learning rate: 0.00026868]
	Learning Rate: 0.000268677
	LOSS [training: 0.15428034012462655 | validation: 0.13191265824404239]
	TIME [epoch: 31.1 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17560610132328738		[learning rate: 0.00026678]
	Learning Rate: 0.00026678
	LOSS [training: 0.17560610132328738 | validation: 0.19032020395038493]
	TIME [epoch: 31.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20334990402720374		[learning rate: 0.0002649]
	Learning Rate: 0.000264897
	LOSS [training: 0.20334990402720374 | validation: 0.13036749496160147]
	TIME [epoch: 31.1 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17318706249013563		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.17318706249013563 | validation: 0.17175841762616317]
	TIME [epoch: 31.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16755832355488182		[learning rate: 0.00026117]
	Learning Rate: 0.00026117
	LOSS [training: 0.16755832355488182 | validation: 0.16377761397565496]
	TIME [epoch: 31.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1542514079468798		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.1542514079468798 | validation: 0.14190454667958638]
	TIME [epoch: 31.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16316155320528974		[learning rate: 0.0002575]
	Learning Rate: 0.000257495
	LOSS [training: 0.16316155320528974 | validation: 0.14882475388656202]
	TIME [epoch: 31.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1503578065813373		[learning rate: 0.00025568]
	Learning Rate: 0.000255677
	LOSS [training: 0.1503578065813373 | validation: 0.13155891775919376]
	TIME [epoch: 31 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1637348149958082		[learning rate: 0.00025387]
	Learning Rate: 0.000253872
	LOSS [training: 0.1637348149958082 | validation: 0.22687279490199985]
	TIME [epoch: 31.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1825590965916269		[learning rate: 0.00025208]
	Learning Rate: 0.00025208
	LOSS [training: 0.1825590965916269 | validation: 0.1732782233584827]
	TIME [epoch: 31.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16175229347334613		[learning rate: 0.0002503]
	Learning Rate: 0.0002503
	LOSS [training: 0.16175229347334613 | validation: 0.16287332066306384]
	TIME [epoch: 31.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1698212488830027		[learning rate: 0.00024853]
	Learning Rate: 0.000248533
	LOSS [training: 0.1698212488830027 | validation: 0.14310381488783538]
	TIME [epoch: 31.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15468572811141368		[learning rate: 0.00024678]
	Learning Rate: 0.000246779
	LOSS [training: 0.15468572811141368 | validation: 0.1489120132298388]
	TIME [epoch: 31.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15426625058615923		[learning rate: 0.00024504]
	Learning Rate: 0.000245037
	LOSS [training: 0.15426625058615923 | validation: 0.14091741346248704]
	TIME [epoch: 31.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15085656898218897		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.15085656898218897 | validation: 0.1571892191108229]
	TIME [epoch: 31 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15151997626996294		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.15151997626996294 | validation: 0.15988428786571215]
	TIME [epoch: 31.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15489343120527538		[learning rate: 0.00023988]
	Learning Rate: 0.000239883
	LOSS [training: 0.15489343120527538 | validation: 0.15991492438870203]
	TIME [epoch: 31 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1520113363251383		[learning rate: 0.00023819]
	Learning Rate: 0.00023819
	LOSS [training: 0.1520113363251383 | validation: 0.14512126867394926]
	TIME [epoch: 31.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1652989729360574		[learning rate: 0.00023651]
	Learning Rate: 0.000236508
	LOSS [training: 0.1652989729360574 | validation: 0.1497399324689088]
	TIME [epoch: 31.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15584179246259647		[learning rate: 0.00023484]
	Learning Rate: 0.000234838
	LOSS [training: 0.15584179246259647 | validation: 0.13587428330344004]
	TIME [epoch: 31.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15118680001967852		[learning rate: 0.00023318]
	Learning Rate: 0.000233181
	LOSS [training: 0.15118680001967852 | validation: 0.201892893056693]
	TIME [epoch: 31.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17191182957024442		[learning rate: 0.00023153]
	Learning Rate: 0.000231534
	LOSS [training: 0.17191182957024442 | validation: 0.15939980364914536]
	TIME [epoch: 31 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15001055515587625		[learning rate: 0.0002299]
	Learning Rate: 0.0002299
	LOSS [training: 0.15001055515587625 | validation: 0.1522593683970914]
	TIME [epoch: 31.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14729697651214327		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.14729697651214327 | validation: 0.13654219367144443]
	TIME [epoch: 31.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14630939746306915		[learning rate: 0.00022667]
	Learning Rate: 0.000226665
	LOSS [training: 0.14630939746306915 | validation: 0.18524608510242566]
	TIME [epoch: 31.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.20714502389868827		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.20714502389868827 | validation: 0.1818328940716344]
	TIME [epoch: 31.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1715039612446827		[learning rate: 0.00022348]
	Learning Rate: 0.000223476
	LOSS [training: 0.1715039612446827 | validation: 0.165962939867066]
	TIME [epoch: 31.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16086233285342713		[learning rate: 0.0002219]
	Learning Rate: 0.000221898
	LOSS [training: 0.16086233285342713 | validation: 0.13397028509268602]
	TIME [epoch: 31 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1460860046200263		[learning rate: 0.00022033]
	Learning Rate: 0.000220332
	LOSS [training: 0.1460860046200263 | validation: 0.14659993789863737]
	TIME [epoch: 31.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15380412282112307		[learning rate: 0.00021878]
	Learning Rate: 0.000218776
	LOSS [training: 0.15380412282112307 | validation: 0.12860989844745485]
	TIME [epoch: 31.1 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13944052821420364		[learning rate: 0.00021723]
	Learning Rate: 0.000217232
	LOSS [training: 0.13944052821420364 | validation: 0.15959628492554603]
	TIME [epoch: 31.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16517079931110018		[learning rate: 0.0002157]
	Learning Rate: 0.000215698
	LOSS [training: 0.16517079931110018 | validation: 0.13105431895043138]
	TIME [epoch: 31.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1986091369641917		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.1986091369641917 | validation: 0.3026688405693181]
	TIME [epoch: 31.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.22757012315643177		[learning rate: 0.00021266]
	Learning Rate: 0.000212663
	LOSS [training: 0.22757012315643177 | validation: 0.15579648603742025]
	TIME [epoch: 31.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15790180565209264		[learning rate: 0.00021116]
	Learning Rate: 0.000211162
	LOSS [training: 0.15790180565209264 | validation: 0.15634188427177162]
	TIME [epoch: 31.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14306195367476424		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.14306195367476424 | validation: 0.11983576685544431]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14143501890113117		[learning rate: 0.00020819]
	Learning Rate: 0.000208191
	LOSS [training: 0.14143501890113117 | validation: 0.14131582636814516]
	TIME [epoch: 31.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15314886987494558		[learning rate: 0.00020672]
	Learning Rate: 0.000206721
	LOSS [training: 0.15314886987494558 | validation: 0.1436761458547697]
	TIME [epoch: 31.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1420256164918815		[learning rate: 0.00020526]
	Learning Rate: 0.000205262
	LOSS [training: 0.1420256164918815 | validation: 0.13362511738495897]
	TIME [epoch: 31.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14211400780582562		[learning rate: 0.00020381]
	Learning Rate: 0.000203812
	LOSS [training: 0.14211400780582562 | validation: 0.15686971227274002]
	TIME [epoch: 31 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1608356587204196		[learning rate: 0.00020237]
	Learning Rate: 0.000202374
	LOSS [training: 0.1608356587204196 | validation: 0.21280865721954184]
	TIME [epoch: 31.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.19846098021029074		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.19846098021029074 | validation: 0.1923257212166643]
	TIME [epoch: 31.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17491243944078977		[learning rate: 0.00019953]
	Learning Rate: 0.000199526
	LOSS [training: 0.17491243944078977 | validation: 0.1430023570509342]
	TIME [epoch: 31.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1493111589673932		[learning rate: 0.00019812]
	Learning Rate: 0.000198118
	LOSS [training: 0.1493111589673932 | validation: 0.11929185336365877]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1589578645676466		[learning rate: 0.00019672]
	Learning Rate: 0.000196719
	LOSS [training: 0.1589578645676466 | validation: 0.12572229250021943]
	TIME [epoch: 31.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1418411390757644		[learning rate: 0.00019533]
	Learning Rate: 0.00019533
	LOSS [training: 0.1418411390757644 | validation: 0.11923986739361236]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14205206378038032		[learning rate: 0.00019395]
	Learning Rate: 0.000193951
	LOSS [training: 0.14205206378038032 | validation: 0.13419567904952542]
	TIME [epoch: 31.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14713844529555217		[learning rate: 0.00019258]
	Learning Rate: 0.000192582
	LOSS [training: 0.14713844529555217 | validation: 0.13469759108706103]
	TIME [epoch: 31.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1515828535754725		[learning rate: 0.00019122]
	Learning Rate: 0.000191222
	LOSS [training: 0.1515828535754725 | validation: 0.15190889002593908]
	TIME [epoch: 31.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1513536591491941		[learning rate: 0.00018987]
	Learning Rate: 0.000189872
	LOSS [training: 0.1513536591491941 | validation: 0.11567825766665918]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1449415135488701		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.1449415135488701 | validation: 0.13228498253311866]
	TIME [epoch: 31.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13867544095907985		[learning rate: 0.0001872]
	Learning Rate: 0.000187201
	LOSS [training: 0.13867544095907985 | validation: 0.1304651469993562]
	TIME [epoch: 31.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13928235013472962		[learning rate: 0.00018588]
	Learning Rate: 0.000185879
	LOSS [training: 0.13928235013472962 | validation: 0.12181893492724596]
	TIME [epoch: 31.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16293957390797567		[learning rate: 0.00018457]
	Learning Rate: 0.000184567
	LOSS [training: 0.16293957390797567 | validation: 0.1346374637837864]
	TIME [epoch: 31.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14896899290059462		[learning rate: 0.00018326]
	Learning Rate: 0.000183264
	LOSS [training: 0.14896899290059462 | validation: 0.1548039767224958]
	TIME [epoch: 31.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14870116216266738		[learning rate: 0.00018197]
	Learning Rate: 0.00018197
	LOSS [training: 0.14870116216266738 | validation: 0.14379943978053522]
	TIME [epoch: 31.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16011504816047348		[learning rate: 0.00018069]
	Learning Rate: 0.000180685
	LOSS [training: 0.16011504816047348 | validation: 0.13438410758262354]
	TIME [epoch: 31.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14314354550084757		[learning rate: 0.00017941]
	Learning Rate: 0.00017941
	LOSS [training: 0.14314354550084757 | validation: 0.12747792389174442]
	TIME [epoch: 31.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14253579728253618		[learning rate: 0.00017814]
	Learning Rate: 0.000178143
	LOSS [training: 0.14253579728253618 | validation: 0.12558169708316766]
	TIME [epoch: 31.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1436486154510821		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.1436486154510821 | validation: 0.13533882940017103]
	TIME [epoch: 31.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16048153444468732		[learning rate: 0.00017564]
	Learning Rate: 0.000175637
	LOSS [training: 0.16048153444468732 | validation: 0.13190726209133172]
	TIME [epoch: 31.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13848224259716227		[learning rate: 0.0001744]
	Learning Rate: 0.000174397
	LOSS [training: 0.13848224259716227 | validation: 0.1283919421924634]
	TIME [epoch: 31.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13673885154232715		[learning rate: 0.00017317]
	Learning Rate: 0.000173166
	LOSS [training: 0.13673885154232715 | validation: 0.13873579190440194]
	TIME [epoch: 31.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14688723702356926		[learning rate: 0.00017194]
	Learning Rate: 0.000171943
	LOSS [training: 0.14688723702356926 | validation: 0.12201192782597761]
	TIME [epoch: 31.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1350374844805048		[learning rate: 0.00017073]
	Learning Rate: 0.000170729
	LOSS [training: 0.1350374844805048 | validation: 0.13438908954701423]
	TIME [epoch: 31.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14416231909638677		[learning rate: 0.00016952]
	Learning Rate: 0.000169524
	LOSS [training: 0.14416231909638677 | validation: 0.1146713932267026]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1389174304465005		[learning rate: 0.00016833]
	Learning Rate: 0.000168327
	LOSS [training: 0.1389174304465005 | validation: 0.14672681836589999]
	TIME [epoch: 31.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14720245741571508		[learning rate: 0.00016714]
	Learning Rate: 0.000167139
	LOSS [training: 0.14720245741571508 | validation: 0.13563078139731632]
	TIME [epoch: 31.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14000105587026745		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.14000105587026745 | validation: 0.12656944177150486]
	TIME [epoch: 31.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13072966304748682		[learning rate: 0.00016479]
	Learning Rate: 0.000164787
	LOSS [training: 0.13072966304748682 | validation: 0.16755136682115446]
	TIME [epoch: 31.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14674030530908994		[learning rate: 0.00016362]
	Learning Rate: 0.000163624
	LOSS [training: 0.14674030530908994 | validation: 0.11372411354595169]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13446109871202022		[learning rate: 0.00016247]
	Learning Rate: 0.000162469
	LOSS [training: 0.13446109871202022 | validation: 0.15171529156904004]
	TIME [epoch: 31.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13984487837431897		[learning rate: 0.00016132]
	Learning Rate: 0.000161322
	LOSS [training: 0.13984487837431897 | validation: 0.17144264232803078]
	TIME [epoch: 31.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1502829895637986		[learning rate: 0.00016018]
	Learning Rate: 0.000160183
	LOSS [training: 0.1502829895637986 | validation: 0.12754580196778376]
	TIME [epoch: 31.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14164040766109978		[learning rate: 0.00015905]
	Learning Rate: 0.000159052
	LOSS [training: 0.14164040766109978 | validation: 0.13983220304861468]
	TIME [epoch: 31.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14073256922038951		[learning rate: 0.00015793]
	Learning Rate: 0.000157929
	LOSS [training: 0.14073256922038951 | validation: 0.1320686738055475]
	TIME [epoch: 31.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1377213058020704		[learning rate: 0.00015681]
	Learning Rate: 0.000156814
	LOSS [training: 0.1377213058020704 | validation: 0.15500434139312924]
	TIME [epoch: 31.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17558472557688365		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.17558472557688365 | validation: 0.1455680864701933]
	TIME [epoch: 31.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1470627358131581		[learning rate: 0.00015461]
	Learning Rate: 0.000154608
	LOSS [training: 0.1470627358131581 | validation: 0.13754450771018842]
	TIME [epoch: 31.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13966111190362102		[learning rate: 0.00015352]
	Learning Rate: 0.000153516
	LOSS [training: 0.13966111190362102 | validation: 0.1197321766970751]
	TIME [epoch: 31.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13079823932249734		[learning rate: 0.00015243]
	Learning Rate: 0.000152432
	LOSS [training: 0.13079823932249734 | validation: 0.1294370821172826]
	TIME [epoch: 31.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13547042945446525		[learning rate: 0.00015136]
	Learning Rate: 0.000151356
	LOSS [training: 0.13547042945446525 | validation: 0.12532455036400858]
	TIME [epoch: 31.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13277836070502216		[learning rate: 0.00015029]
	Learning Rate: 0.000150288
	LOSS [training: 0.13277836070502216 | validation: 0.14506524851664346]
	TIME [epoch: 31.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13749038101488437		[learning rate: 0.00014923]
	Learning Rate: 0.000149227
	LOSS [training: 0.13749038101488437 | validation: 0.11910284779552666]
	TIME [epoch: 31.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1299798638917962		[learning rate: 0.00014817]
	Learning Rate: 0.000148173
	LOSS [training: 0.1299798638917962 | validation: 0.12909325835528526]
	TIME [epoch: 31.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.142245754523259		[learning rate: 0.00014713]
	Learning Rate: 0.000147127
	LOSS [training: 0.142245754523259 | validation: 0.11565703180357492]
	TIME [epoch: 31.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12836972975284155		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.12836972975284155 | validation: 0.1249554150945435]
	TIME [epoch: 31.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1410078429068846		[learning rate: 0.00014506]
	Learning Rate: 0.000145057
	LOSS [training: 0.1410078429068846 | validation: 0.12750494833076517]
	TIME [epoch: 31.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1388319979789993		[learning rate: 0.00014403]
	Learning Rate: 0.000144033
	LOSS [training: 0.1388319979789993 | validation: 0.13469074653084503]
	TIME [epoch: 31.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14895075258085666		[learning rate: 0.00014302]
	Learning Rate: 0.000143016
	LOSS [training: 0.14895075258085666 | validation: 0.12555462458055863]
	TIME [epoch: 31.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13408798887215584		[learning rate: 0.00014201]
	Learning Rate: 0.000142006
	LOSS [training: 0.13408798887215584 | validation: 0.12151367111615739]
	TIME [epoch: 31.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1274260681521716		[learning rate: 0.000141]
	Learning Rate: 0.000141004
	LOSS [training: 0.1274260681521716 | validation: 0.12782458287196571]
	TIME [epoch: 31.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13885849568034014		[learning rate: 0.00014001]
	Learning Rate: 0.000140008
	LOSS [training: 0.13885849568034014 | validation: 0.12865625314228366]
	TIME [epoch: 31.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13501251072914267		[learning rate: 0.00013902]
	Learning Rate: 0.00013902
	LOSS [training: 0.13501251072914267 | validation: 0.11139011834278363]
	TIME [epoch: 31.6 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1280940415720443		[learning rate: 0.00013804]
	Learning Rate: 0.000138038
	LOSS [training: 0.1280940415720443 | validation: 0.16206264264540596]
	TIME [epoch: 31.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.17618156397948403		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.17618156397948403 | validation: 0.1651995248570436]
	TIME [epoch: 31.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13349008380153637		[learning rate: 0.0001361]
	Learning Rate: 0.000136096
	LOSS [training: 0.13349008380153637 | validation: 0.13153497451592153]
	TIME [epoch: 31.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14491426540092422		[learning rate: 0.00013514]
	Learning Rate: 0.000135135
	LOSS [training: 0.14491426540092422 | validation: 0.1356384433799579]
	TIME [epoch: 31.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13371446980274143		[learning rate: 0.00013418]
	Learning Rate: 0.000134181
	LOSS [training: 0.13371446980274143 | validation: 0.11802090517756239]
	TIME [epoch: 31.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12785759710408978		[learning rate: 0.00013323]
	Learning Rate: 0.000133234
	LOSS [training: 0.12785759710408978 | validation: 0.11072121545665753]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1190792487213787		[learning rate: 0.00013229]
	Learning Rate: 0.000132293
	LOSS [training: 0.1190792487213787 | validation: 0.12009030220827005]
	TIME [epoch: 31.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13142882050804958		[learning rate: 0.00013136]
	Learning Rate: 0.00013136
	LOSS [training: 0.13142882050804958 | validation: 0.12369756629210818]
	TIME [epoch: 31.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13002732942168965		[learning rate: 0.00013043]
	Learning Rate: 0.000130432
	LOSS [training: 0.13002732942168965 | validation: 0.12557269023611609]
	TIME [epoch: 31.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13091019164874182		[learning rate: 0.00012951]
	Learning Rate: 0.000129511
	LOSS [training: 0.13091019164874182 | validation: 0.1327006378940709]
	TIME [epoch: 31.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14099882746442832		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.14099882746442832 | validation: 0.1166805882138819]
	TIME [epoch: 31.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12833872553943326		[learning rate: 0.00012769]
	Learning Rate: 0.000127689
	LOSS [training: 0.12833872553943326 | validation: 0.11860916062425884]
	TIME [epoch: 31.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1211426854837459		[learning rate: 0.00012679]
	Learning Rate: 0.000126788
	LOSS [training: 0.1211426854837459 | validation: 0.11436386319795953]
	TIME [epoch: 31.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14010667240267438		[learning rate: 0.00012589]
	Learning Rate: 0.000125893
	LOSS [training: 0.14010667240267438 | validation: 0.12177409824437152]
	TIME [epoch: 31.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12556389052151046		[learning rate: 0.000125]
	Learning Rate: 0.000125004
	LOSS [training: 0.12556389052151046 | validation: 0.11464334246156789]
	TIME [epoch: 31.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13117496606178147		[learning rate: 0.00012412]
	Learning Rate: 0.000124121
	LOSS [training: 0.13117496606178147 | validation: 0.11614255658490497]
	TIME [epoch: 31.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12626793883045972		[learning rate: 0.00012324]
	Learning Rate: 0.000123245
	LOSS [training: 0.12626793883045972 | validation: 0.1263418670506222]
	TIME [epoch: 31.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13358040609311705		[learning rate: 0.00012237]
	Learning Rate: 0.000122375
	LOSS [training: 0.13358040609311705 | validation: 0.11970109895765278]
	TIME [epoch: 31.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12763843037210099		[learning rate: 0.00012151]
	Learning Rate: 0.000121511
	LOSS [training: 0.12763843037210099 | validation: 0.1252892998350708]
	TIME [epoch: 31.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13383833244756704		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.13383833244756704 | validation: 0.15615453777213395]
	TIME [epoch: 31.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15425341028995698		[learning rate: 0.0001198]
	Learning Rate: 0.000119801
	LOSS [training: 0.15425341028995698 | validation: 0.12092675665575865]
	TIME [epoch: 31.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12474070289634623		[learning rate: 0.00011896]
	Learning Rate: 0.000118956
	LOSS [training: 0.12474070289634623 | validation: 0.10699348082695304]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12374502871744644		[learning rate: 0.00011812]
	Learning Rate: 0.000118116
	LOSS [training: 0.12374502871744644 | validation: 0.1351839241583966]
	TIME [epoch: 31.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1422734025082298		[learning rate: 0.00011728]
	Learning Rate: 0.000117282
	LOSS [training: 0.1422734025082298 | validation: 0.11800935535772715]
	TIME [epoch: 31.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13255632051335428		[learning rate: 0.00011645]
	Learning Rate: 0.000116454
	LOSS [training: 0.13255632051335428 | validation: 0.11852504823267003]
	TIME [epoch: 31.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14342985079817222		[learning rate: 0.00011563]
	Learning Rate: 0.000115632
	LOSS [training: 0.14342985079817222 | validation: 0.11148679854293556]
	TIME [epoch: 31.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12484776260873673		[learning rate: 0.00011482]
	Learning Rate: 0.000114815
	LOSS [training: 0.12484776260873673 | validation: 0.11276658222329893]
	TIME [epoch: 31 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12640751668178662		[learning rate: 0.000114]
	Learning Rate: 0.000114005
	LOSS [training: 0.12640751668178662 | validation: 0.13592204407236771]
	TIME [epoch: 31.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.14234475839475266		[learning rate: 0.0001132]
	Learning Rate: 0.0001132
	LOSS [training: 0.14234475839475266 | validation: 0.12457012607170502]
	TIME [epoch: 31.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13960969537015122		[learning rate: 0.0001124]
	Learning Rate: 0.000112401
	LOSS [training: 0.13960969537015122 | validation: 0.11151389892943614]
	TIME [epoch: 31.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12105114668244862		[learning rate: 0.00011161]
	Learning Rate: 0.000111607
	LOSS [training: 0.12105114668244862 | validation: 0.117444674826621]
	TIME [epoch: 31.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12459237187068356		[learning rate: 0.00011082]
	Learning Rate: 0.000110819
	LOSS [training: 0.12459237187068356 | validation: 0.11325558969117151]
	TIME [epoch: 31.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12227480440922937		[learning rate: 0.00011004]
	Learning Rate: 0.000110037
	LOSS [training: 0.12227480440922937 | validation: 0.11806968974964183]
	TIME [epoch: 31.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13099733258134433		[learning rate: 0.00010926]
	Learning Rate: 0.00010926
	LOSS [training: 0.13099733258134433 | validation: 0.11408845971350884]
	TIME [epoch: 31.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12264957141265195		[learning rate: 0.00010849]
	Learning Rate: 0.000108489
	LOSS [training: 0.12264957141265195 | validation: 0.11052108840443786]
	TIME [epoch: 31 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12422035184615204		[learning rate: 0.00010772]
	Learning Rate: 0.000107723
	LOSS [training: 0.12422035184615204 | validation: 0.11305454562415414]
	TIME [epoch: 31.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12206393717984419		[learning rate: 0.00010696]
	Learning Rate: 0.000106962
	LOSS [training: 0.12206393717984419 | validation: 0.11276249244189618]
	TIME [epoch: 31.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12477998577712682		[learning rate: 0.00010621]
	Learning Rate: 0.000106207
	LOSS [training: 0.12477998577712682 | validation: 0.11541077800094911]
	TIME [epoch: 31.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12749190517351042		[learning rate: 0.00010546]
	Learning Rate: 0.000105457
	LOSS [training: 0.12749190517351042 | validation: 0.1068327717543107]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12374353303581678		[learning rate: 0.00010471]
	Learning Rate: 0.000104713
	LOSS [training: 0.12374353303581678 | validation: 0.1142679790280805]
	TIME [epoch: 31.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12475086123808568		[learning rate: 0.00010397]
	Learning Rate: 0.000103974
	LOSS [training: 0.12475086123808568 | validation: 0.13424705624972183]
	TIME [epoch: 31.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12503592301125607		[learning rate: 0.00010324]
	Learning Rate: 0.00010324
	LOSS [training: 0.12503592301125607 | validation: 0.11913143597819027]
	TIME [epoch: 31.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12682266464457556		[learning rate: 0.00010251]
	Learning Rate: 0.000102511
	LOSS [training: 0.12682266464457556 | validation: 0.11333127257183527]
	TIME [epoch: 31.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11835319078747045		[learning rate: 0.00010179]
	Learning Rate: 0.000101787
	LOSS [training: 0.11835319078747045 | validation: 0.11362233069203845]
	TIME [epoch: 31.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12839285728950275		[learning rate: 0.00010107]
	Learning Rate: 0.000101068
	LOSS [training: 0.12839285728950275 | validation: 0.1175273561096084]
	TIME [epoch: 31.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12089238734360025		[learning rate: 0.00010035]
	Learning Rate: 0.000100355
	LOSS [training: 0.12089238734360025 | validation: 0.11391389360156666]
	TIME [epoch: 31.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1260741420753695		[learning rate: 9.9646e-05]
	Learning Rate: 9.96464e-05
	LOSS [training: 0.1260741420753695 | validation: 0.11206191775771163]
	TIME [epoch: 31.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12192233963114232		[learning rate: 9.8943e-05]
	Learning Rate: 9.89429e-05
	LOSS [training: 0.12192233963114232 | validation: 0.13375780118021482]
	TIME [epoch: 31.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13361725609368158		[learning rate: 9.8244e-05]
	Learning Rate: 9.82444e-05
	LOSS [training: 0.13361725609368158 | validation: 0.10988052390020453]
	TIME [epoch: 31.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.15415814805408318		[learning rate: 9.7551e-05]
	Learning Rate: 9.75508e-05
	LOSS [training: 0.15415814805408318 | validation: 0.14233721690696063]
	TIME [epoch: 31.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.16273306441852242		[learning rate: 9.6862e-05]
	Learning Rate: 9.68621e-05
	LOSS [training: 0.16273306441852242 | validation: 0.12784482300655514]
	TIME [epoch: 31.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12908658363758654		[learning rate: 9.6178e-05]
	Learning Rate: 9.61783e-05
	LOSS [training: 0.12908658363758654 | validation: 0.1312162431021897]
	TIME [epoch: 31.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13097604574625996		[learning rate: 9.5499e-05]
	Learning Rate: 9.54993e-05
	LOSS [training: 0.13097604574625996 | validation: 0.10699572025383844]
	TIME [epoch: 31.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12271110318859237		[learning rate: 9.4825e-05]
	Learning Rate: 9.48251e-05
	LOSS [training: 0.12271110318859237 | validation: 0.11165238206200148]
	TIME [epoch: 31.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11944766824681888		[learning rate: 9.4156e-05]
	Learning Rate: 9.41556e-05
	LOSS [training: 0.11944766824681888 | validation: 0.11875694266994624]
	TIME [epoch: 31.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12406943044137458		[learning rate: 9.3491e-05]
	Learning Rate: 9.34909e-05
	LOSS [training: 0.12406943044137458 | validation: 0.11009982079364684]
	TIME [epoch: 31.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11754689583977934		[learning rate: 9.2831e-05]
	Learning Rate: 9.28309e-05
	LOSS [training: 0.11754689583977934 | validation: 0.1069995595313724]
	TIME [epoch: 31.1 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11680342415454387		[learning rate: 9.2176e-05]
	Learning Rate: 9.21755e-05
	LOSS [training: 0.11680342415454387 | validation: 0.11720788637436774]
	TIME [epoch: 31.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12570608256688603		[learning rate: 9.1525e-05]
	Learning Rate: 9.15247e-05
	LOSS [training: 0.12570608256688603 | validation: 0.11042617295840698]
	TIME [epoch: 31 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11952405473468476		[learning rate: 9.0879e-05]
	Learning Rate: 9.08786e-05
	LOSS [training: 0.11952405473468476 | validation: 0.10435397444701278]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12203514844348679		[learning rate: 9.0237e-05]
	Learning Rate: 9.0237e-05
	LOSS [training: 0.12203514844348679 | validation: 0.10690881742326735]
	TIME [epoch: 31.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11544481793380809		[learning rate: 8.96e-05]
	Learning Rate: 8.96e-05
	LOSS [training: 0.11544481793380809 | validation: 0.10610043174248487]
	TIME [epoch: 31.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11792701110625273		[learning rate: 8.8967e-05]
	Learning Rate: 8.89674e-05
	LOSS [training: 0.11792701110625273 | validation: 0.11529948012860279]
	TIME [epoch: 31.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12318528545326698		[learning rate: 8.8339e-05]
	Learning Rate: 8.83393e-05
	LOSS [training: 0.12318528545326698 | validation: 0.10877074303686883]
	TIME [epoch: 31.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11731198868275854		[learning rate: 8.7716e-05]
	Learning Rate: 8.77156e-05
	LOSS [training: 0.11731198868275854 | validation: 0.1075076208110193]
	TIME [epoch: 31.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11692702471295607		[learning rate: 8.7096e-05]
	Learning Rate: 8.70964e-05
	LOSS [training: 0.11692702471295607 | validation: 0.1068035899335397]
	TIME [epoch: 31.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11866090327055123		[learning rate: 8.6481e-05]
	Learning Rate: 8.64815e-05
	LOSS [training: 0.11866090327055123 | validation: 0.11925578953293217]
	TIME [epoch: 31.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11525141768648059		[learning rate: 8.5871e-05]
	Learning Rate: 8.58709e-05
	LOSS [training: 0.11525141768648059 | validation: 0.11173250915443407]
	TIME [epoch: 31.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11346934351601945		[learning rate: 8.5265e-05]
	Learning Rate: 8.52647e-05
	LOSS [training: 0.11346934351601945 | validation: 0.11386494248683854]
	TIME [epoch: 31.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12748966633214157		[learning rate: 8.4663e-05]
	Learning Rate: 8.46628e-05
	LOSS [training: 0.12748966633214157 | validation: 0.10943319231295848]
	TIME [epoch: 31.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12289754746157176		[learning rate: 8.4065e-05]
	Learning Rate: 8.4065e-05
	LOSS [training: 0.12289754746157176 | validation: 0.10768136721664467]
	TIME [epoch: 31.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11953803620605699		[learning rate: 8.3472e-05]
	Learning Rate: 8.34716e-05
	LOSS [training: 0.11953803620605699 | validation: 0.10920133293036703]
	TIME [epoch: 31.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11306183082899016		[learning rate: 8.2882e-05]
	Learning Rate: 8.28823e-05
	LOSS [training: 0.11306183082899016 | validation: 0.10761904446019598]
	TIME [epoch: 31.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11354082712041644		[learning rate: 8.2297e-05]
	Learning Rate: 8.22971e-05
	LOSS [training: 0.11354082712041644 | validation: 0.10248071101100631]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11209100813648254		[learning rate: 8.1716e-05]
	Learning Rate: 8.17161e-05
	LOSS [training: 0.11209100813648254 | validation: 0.1176428277133102]
	TIME [epoch: 31.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13225401115196228		[learning rate: 8.1139e-05]
	Learning Rate: 8.11392e-05
	LOSS [training: 0.13225401115196228 | validation: 0.1166614015853944]
	TIME [epoch: 31.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1206049253151607		[learning rate: 8.0566e-05]
	Learning Rate: 8.05664e-05
	LOSS [training: 0.1206049253151607 | validation: 0.1156846006815629]
	TIME [epoch: 31.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11360700094213988		[learning rate: 7.9998e-05]
	Learning Rate: 7.99976e-05
	LOSS [training: 0.11360700094213988 | validation: 0.10971138174287656]
	TIME [epoch: 31 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11957476026436069		[learning rate: 7.9433e-05]
	Learning Rate: 7.94328e-05
	LOSS [training: 0.11957476026436069 | validation: 0.11081634385193301]
	TIME [epoch: 31.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11798770919540108		[learning rate: 7.8872e-05]
	Learning Rate: 7.88721e-05
	LOSS [training: 0.11798770919540108 | validation: 0.12073147430727911]
	TIME [epoch: 31.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12515613360575834		[learning rate: 7.8315e-05]
	Learning Rate: 7.83152e-05
	LOSS [training: 0.12515613360575834 | validation: 0.11480317203461582]
	TIME [epoch: 31.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1165312585117852		[learning rate: 7.7762e-05]
	Learning Rate: 7.77623e-05
	LOSS [training: 0.1165312585117852 | validation: 0.11507330081174061]
	TIME [epoch: 31.1 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11445993558285092		[learning rate: 7.7213e-05]
	Learning Rate: 7.72134e-05
	LOSS [training: 0.11445993558285092 | validation: 0.10969987342134298]
	TIME [epoch: 31 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11522406838109886		[learning rate: 7.6668e-05]
	Learning Rate: 7.66682e-05
	LOSS [training: 0.11522406838109886 | validation: 0.11732705600226812]
	TIME [epoch: 31.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12457696285050487		[learning rate: 7.6127e-05]
	Learning Rate: 7.6127e-05
	LOSS [training: 0.12457696285050487 | validation: 0.10494587372763226]
	TIME [epoch: 31.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11424943389984224		[learning rate: 7.559e-05]
	Learning Rate: 7.55895e-05
	LOSS [training: 0.11424943389984224 | validation: 0.1045167080900463]
	TIME [epoch: 31 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11879394042193794		[learning rate: 7.5056e-05]
	Learning Rate: 7.50559e-05
	LOSS [training: 0.11879394042193794 | validation: 0.10500568566280753]
	TIME [epoch: 31.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11711845697653961		[learning rate: 7.4526e-05]
	Learning Rate: 7.4526e-05
	LOSS [training: 0.11711845697653961 | validation: 0.1097247212402567]
	TIME [epoch: 31 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12384459303436286		[learning rate: 7.4e-05]
	Learning Rate: 7.39998e-05
	LOSS [training: 0.12384459303436286 | validation: 0.10097928889815684]
	TIME [epoch: 31.1 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11644647558463395		[learning rate: 7.3477e-05]
	Learning Rate: 7.34774e-05
	LOSS [training: 0.11644647558463395 | validation: 0.11015902242119202]
	TIME [epoch: 31.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11724530841608505		[learning rate: 7.2959e-05]
	Learning Rate: 7.29587e-05
	LOSS [training: 0.11724530841608505 | validation: 0.13749140054875403]
	TIME [epoch: 31.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.13017253077992508		[learning rate: 7.2444e-05]
	Learning Rate: 7.24436e-05
	LOSS [training: 0.13017253077992508 | validation: 0.10551281587180679]
	TIME [epoch: 31.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11076223642263719		[learning rate: 7.1932e-05]
	Learning Rate: 7.19322e-05
	LOSS [training: 0.11076223642263719 | validation: 0.11416704509432263]
	TIME [epoch: 31.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11730450259275069		[learning rate: 7.1424e-05]
	Learning Rate: 7.14243e-05
	LOSS [training: 0.11730450259275069 | validation: 0.11611229217479205]
	TIME [epoch: 31.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1160424716190256		[learning rate: 7.092e-05]
	Learning Rate: 7.09201e-05
	LOSS [training: 0.1160424716190256 | validation: 0.1077472703872765]
	TIME [epoch: 31.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11422145701427436		[learning rate: 7.0419e-05]
	Learning Rate: 7.04194e-05
	LOSS [training: 0.11422145701427436 | validation: 0.11668406888405938]
	TIME [epoch: 31.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12047048158115073		[learning rate: 6.9922e-05]
	Learning Rate: 6.99223e-05
	LOSS [training: 0.12047048158115073 | validation: 0.1121597815223856]
	TIME [epoch: 31.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11256304930927907		[learning rate: 6.9429e-05]
	Learning Rate: 6.94286e-05
	LOSS [training: 0.11256304930927907 | validation: 0.11249485613614359]
	TIME [epoch: 31.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1130334273769465		[learning rate: 6.8938e-05]
	Learning Rate: 6.89385e-05
	LOSS [training: 0.1130334273769465 | validation: 0.10125699329739213]
	TIME [epoch: 31.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11474791349015122		[learning rate: 6.8452e-05]
	Learning Rate: 6.84518e-05
	LOSS [training: 0.11474791349015122 | validation: 0.11228536419640894]
	TIME [epoch: 31.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1182265565640728		[learning rate: 6.7968e-05]
	Learning Rate: 6.79685e-05
	LOSS [training: 0.1182265565640728 | validation: 0.11577596432622556]
	TIME [epoch: 31.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11685764943711638		[learning rate: 6.7489e-05]
	Learning Rate: 6.74887e-05
	LOSS [training: 0.11685764943711638 | validation: 0.11169725164178351]
	TIME [epoch: 31.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11369465109128937		[learning rate: 6.7012e-05]
	Learning Rate: 6.70122e-05
	LOSS [training: 0.11369465109128937 | validation: 0.11122308411845738]
	TIME [epoch: 31.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11581810338460805		[learning rate: 6.6539e-05]
	Learning Rate: 6.65391e-05
	LOSS [training: 0.11581810338460805 | validation: 0.10781501631668185]
	TIME [epoch: 31.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11922298939047038		[learning rate: 6.6069e-05]
	Learning Rate: 6.60694e-05
	LOSS [training: 0.11922298939047038 | validation: 0.1044903933316356]
	TIME [epoch: 31.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11829132543185378		[learning rate: 6.5603e-05]
	Learning Rate: 6.56029e-05
	LOSS [training: 0.11829132543185378 | validation: 0.10769728424134616]
	TIME [epoch: 31.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11359242380733847		[learning rate: 6.514e-05]
	Learning Rate: 6.51398e-05
	LOSS [training: 0.11359242380733847 | validation: 0.10840266664620174]
	TIME [epoch: 31.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12032033341553315		[learning rate: 6.468e-05]
	Learning Rate: 6.46799e-05
	LOSS [training: 0.12032033341553315 | validation: 0.1079795586519627]
	TIME [epoch: 31.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11659232466849626		[learning rate: 6.4223e-05]
	Learning Rate: 6.42233e-05
	LOSS [training: 0.11659232466849626 | validation: 0.11202695899556024]
	TIME [epoch: 31.1 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11698189201283551		[learning rate: 6.377e-05]
	Learning Rate: 6.37699e-05
	LOSS [training: 0.11698189201283551 | validation: 0.10925884242018498]
	TIME [epoch: 31.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11397398963441		[learning rate: 6.332e-05]
	Learning Rate: 6.33196e-05
	LOSS [training: 0.11397398963441 | validation: 0.1060566923043858]
	TIME [epoch: 31.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11176087954919599		[learning rate: 6.2873e-05]
	Learning Rate: 6.28726e-05
	LOSS [training: 0.11176087954919599 | validation: 0.1049320013415409]
	TIME [epoch: 31.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11445039716678908		[learning rate: 6.2429e-05]
	Learning Rate: 6.24288e-05
	LOSS [training: 0.11445039716678908 | validation: 0.10878088729638509]
	TIME [epoch: 31.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11332864493882396		[learning rate: 6.1988e-05]
	Learning Rate: 6.1988e-05
	LOSS [training: 0.11332864493882396 | validation: 0.10341200079890088]
	TIME [epoch: 31.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1166412776457664		[learning rate: 6.155e-05]
	Learning Rate: 6.15504e-05
	LOSS [training: 0.1166412776457664 | validation: 0.11255920343494191]
	TIME [epoch: 31.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10915769117182092		[learning rate: 6.1116e-05]
	Learning Rate: 6.11158e-05
	LOSS [training: 0.10915769117182092 | validation: 0.09993447896825898]
	TIME [epoch: 31.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11185851966788302		[learning rate: 6.0684e-05]
	Learning Rate: 6.06844e-05
	LOSS [training: 0.11185851966788302 | validation: 0.10914683547563633]
	TIME [epoch: 31.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1177504994613883		[learning rate: 6.0256e-05]
	Learning Rate: 6.0256e-05
	LOSS [training: 0.1177504994613883 | validation: 0.11155161362068917]
	TIME [epoch: 31.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11317049299338816		[learning rate: 5.9831e-05]
	Learning Rate: 5.98306e-05
	LOSS [training: 0.11317049299338816 | validation: 0.10632931093439878]
	TIME [epoch: 31.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10946716758928304		[learning rate: 5.9408e-05]
	Learning Rate: 5.94082e-05
	LOSS [training: 0.10946716758928304 | validation: 0.10364241867876436]
	TIME [epoch: 31.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1122118736347865		[learning rate: 5.8989e-05]
	Learning Rate: 5.89888e-05
	LOSS [training: 0.1122118736347865 | validation: 0.10320718128216584]
	TIME [epoch: 31.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11097727061155235		[learning rate: 5.8572e-05]
	Learning Rate: 5.85723e-05
	LOSS [training: 0.11097727061155235 | validation: 0.11708136672143295]
	TIME [epoch: 31.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11951300991204677		[learning rate: 5.8159e-05]
	Learning Rate: 5.81588e-05
	LOSS [training: 0.11951300991204677 | validation: 0.10653199983188887]
	TIME [epoch: 31.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11586632679071523		[learning rate: 5.7748e-05]
	Learning Rate: 5.77482e-05
	LOSS [training: 0.11586632679071523 | validation: 0.1005501405074138]
	TIME [epoch: 31.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1123670100104544		[learning rate: 5.7341e-05]
	Learning Rate: 5.73405e-05
	LOSS [training: 0.1123670100104544 | validation: 0.09743235815158571]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10758795232671226		[learning rate: 5.6936e-05]
	Learning Rate: 5.69357e-05
	LOSS [training: 0.10758795232671226 | validation: 0.11333753169201376]
	TIME [epoch: 31.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11552365205715578		[learning rate: 5.6534e-05]
	Learning Rate: 5.65337e-05
	LOSS [training: 0.11552365205715578 | validation: 0.10070744146301035]
	TIME [epoch: 31.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11062298914389661		[learning rate: 5.6135e-05]
	Learning Rate: 5.61346e-05
	LOSS [training: 0.11062298914389661 | validation: 0.09577728563277264]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11141280032815876		[learning rate: 5.5738e-05]
	Learning Rate: 5.57383e-05
	LOSS [training: 0.11141280032815876 | validation: 0.10693426489271385]
	TIME [epoch: 31.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11430803790869298		[learning rate: 5.5345e-05]
	Learning Rate: 5.53448e-05
	LOSS [training: 0.11430803790869298 | validation: 0.10185907581028758]
	TIME [epoch: 31.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10996854255435368		[learning rate: 5.4954e-05]
	Learning Rate: 5.49541e-05
	LOSS [training: 0.10996854255435368 | validation: 0.09634782625312002]
	TIME [epoch: 31.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10989603527535091		[learning rate: 5.4566e-05]
	Learning Rate: 5.45661e-05
	LOSS [training: 0.10989603527535091 | validation: 0.11159916111702982]
	TIME [epoch: 31.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11630583355016344		[learning rate: 5.4181e-05]
	Learning Rate: 5.41809e-05
	LOSS [training: 0.11630583355016344 | validation: 0.10309230940719678]
	TIME [epoch: 31.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11289799508125414		[learning rate: 5.3798e-05]
	Learning Rate: 5.37984e-05
	LOSS [training: 0.11289799508125414 | validation: 0.11048349143984454]
	TIME [epoch: 31.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10913378902822671		[learning rate: 5.3419e-05]
	Learning Rate: 5.34186e-05
	LOSS [training: 0.10913378902822671 | validation: 0.09988762737797743]
	TIME [epoch: 31.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11061993838748578		[learning rate: 5.3041e-05]
	Learning Rate: 5.30415e-05
	LOSS [training: 0.11061993838748578 | validation: 0.11710863095914104]
	TIME [epoch: 31.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11764563223501281		[learning rate: 5.2667e-05]
	Learning Rate: 5.2667e-05
	LOSS [training: 0.11764563223501281 | validation: 0.10961212974743365]
	TIME [epoch: 31.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10914309583845594		[learning rate: 5.2295e-05]
	Learning Rate: 5.22952e-05
	LOSS [training: 0.10914309583845594 | validation: 0.10668094683236816]
	TIME [epoch: 31.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10734994616133227		[learning rate: 5.1926e-05]
	Learning Rate: 5.1926e-05
	LOSS [training: 0.10734994616133227 | validation: 0.1096622898510261]
	TIME [epoch: 31.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11294165608310858		[learning rate: 5.1559e-05]
	Learning Rate: 5.15594e-05
	LOSS [training: 0.11294165608310858 | validation: 0.09724221395591273]
	TIME [epoch: 31.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1090419676763277		[learning rate: 5.1195e-05]
	Learning Rate: 5.11954e-05
	LOSS [training: 0.1090419676763277 | validation: 0.10590840522897858]
	TIME [epoch: 31.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11246172433466572		[learning rate: 5.0834e-05]
	Learning Rate: 5.0834e-05
	LOSS [training: 0.11246172433466572 | validation: 0.09996970646081445]
	TIME [epoch: 31.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1268349792135664		[learning rate: 5.0475e-05]
	Learning Rate: 5.04751e-05
	LOSS [training: 0.1268349792135664 | validation: 0.09802488744023435]
	TIME [epoch: 31.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11226917410759868		[learning rate: 5.0119e-05]
	Learning Rate: 5.01187e-05
	LOSS [training: 0.11226917410759868 | validation: 0.10168314741213372]
	TIME [epoch: 31.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10754341844298704		[learning rate: 4.9765e-05]
	Learning Rate: 4.97649e-05
	LOSS [training: 0.10754341844298704 | validation: 0.10512215497420417]
	TIME [epoch: 31.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11790523542015538		[learning rate: 4.9414e-05]
	Learning Rate: 4.94136e-05
	LOSS [training: 0.11790523542015538 | validation: 0.1102706900455168]
	TIME [epoch: 31.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11786043982068026		[learning rate: 4.9065e-05]
	Learning Rate: 4.90647e-05
	LOSS [training: 0.11786043982068026 | validation: 0.10685547892312393]
	TIME [epoch: 31.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10918905379197166		[learning rate: 4.8718e-05]
	Learning Rate: 4.87183e-05
	LOSS [training: 0.10918905379197166 | validation: 0.10177739731642613]
	TIME [epoch: 31.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10278494657743885		[learning rate: 4.8374e-05]
	Learning Rate: 4.83744e-05
	LOSS [training: 0.10278494657743885 | validation: 0.09871189848627243]
	TIME [epoch: 31.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11197803246861174		[learning rate: 4.8033e-05]
	Learning Rate: 4.80329e-05
	LOSS [training: 0.11197803246861174 | validation: 0.10669233039464898]
	TIME [epoch: 31.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11335925242943663		[learning rate: 4.7694e-05]
	Learning Rate: 4.76938e-05
	LOSS [training: 0.11335925242943663 | validation: 0.10719223874143013]
	TIME [epoch: 31.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11024022836736991		[learning rate: 4.7357e-05]
	Learning Rate: 4.73571e-05
	LOSS [training: 0.11024022836736991 | validation: 0.0995271449834163]
	TIME [epoch: 31.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10658254127735296		[learning rate: 4.7023e-05]
	Learning Rate: 4.70227e-05
	LOSS [training: 0.10658254127735296 | validation: 0.10591328966677481]
	TIME [epoch: 31.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1092918727098755		[learning rate: 4.6691e-05]
	Learning Rate: 4.66907e-05
	LOSS [training: 0.1092918727098755 | validation: 0.10439883286197754]
	TIME [epoch: 31.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10966280910414167		[learning rate: 4.6361e-05]
	Learning Rate: 4.63611e-05
	LOSS [training: 0.10966280910414167 | validation: 0.10804225589045079]
	TIME [epoch: 31.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11121474150626617		[learning rate: 4.6034e-05]
	Learning Rate: 4.60338e-05
	LOSS [training: 0.11121474150626617 | validation: 0.10211421399311492]
	TIME [epoch: 31.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11028034194516294		[learning rate: 4.5709e-05]
	Learning Rate: 4.57088e-05
	LOSS [training: 0.11028034194516294 | validation: 0.09921953777130375]
	TIME [epoch: 31.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10778839731388272		[learning rate: 4.5386e-05]
	Learning Rate: 4.53861e-05
	LOSS [training: 0.10778839731388272 | validation: 0.10431911102165214]
	TIME [epoch: 31.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10457027804755302		[learning rate: 4.5066e-05]
	Learning Rate: 4.50657e-05
	LOSS [training: 0.10457027804755302 | validation: 0.10204049282770725]
	TIME [epoch: 31.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1096287735790278		[learning rate: 4.4748e-05]
	Learning Rate: 4.47476e-05
	LOSS [training: 0.1096287735790278 | validation: 0.09744055221181598]
	TIME [epoch: 31.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10561519109296921		[learning rate: 4.4432e-05]
	Learning Rate: 4.44316e-05
	LOSS [training: 0.10561519109296921 | validation: 0.10802628545800808]
	TIME [epoch: 31.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10946259214352287		[learning rate: 4.4118e-05]
	Learning Rate: 4.4118e-05
	LOSS [training: 0.10946259214352287 | validation: 0.10364346053192547]
	TIME [epoch: 31.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10897034903438832		[learning rate: 4.3807e-05]
	Learning Rate: 4.38065e-05
	LOSS [training: 0.10897034903438832 | validation: 0.09721931808725265]
	TIME [epoch: 31.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11070592858153949		[learning rate: 4.3497e-05]
	Learning Rate: 4.34972e-05
	LOSS [training: 0.11070592858153949 | validation: 0.09798263291325962]
	TIME [epoch: 31.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11555733539922733		[learning rate: 4.319e-05]
	Learning Rate: 4.31902e-05
	LOSS [training: 0.11555733539922733 | validation: 0.10104424969394095]
	TIME [epoch: 31.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10973505778929879		[learning rate: 4.2885e-05]
	Learning Rate: 4.28852e-05
	LOSS [training: 0.10973505778929879 | validation: 0.09356006021581241]
	TIME [epoch: 31.3 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10911019775140832		[learning rate: 4.2582e-05]
	Learning Rate: 4.25825e-05
	LOSS [training: 0.10911019775140832 | validation: 0.10393030259141961]
	TIME [epoch: 31.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10913655783226674		[learning rate: 4.2282e-05]
	Learning Rate: 4.22819e-05
	LOSS [training: 0.10913655783226674 | validation: 0.10280662868884527]
	TIME [epoch: 31.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10773693066284341		[learning rate: 4.1983e-05]
	Learning Rate: 4.19833e-05
	LOSS [training: 0.10773693066284341 | validation: 0.09974648705286318]
	TIME [epoch: 31.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11007003056514617		[learning rate: 4.1687e-05]
	Learning Rate: 4.16869e-05
	LOSS [training: 0.11007003056514617 | validation: 0.10152544078424022]
	TIME [epoch: 31.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11213936198088442		[learning rate: 4.1393e-05]
	Learning Rate: 4.13926e-05
	LOSS [training: 0.11213936198088442 | validation: 0.10114050249542134]
	TIME [epoch: 31.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11701952753179595		[learning rate: 4.11e-05]
	Learning Rate: 4.11004e-05
	LOSS [training: 0.11701952753179595 | validation: 0.10345233854109544]
	TIME [epoch: 31.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10608574063293505		[learning rate: 4.081e-05]
	Learning Rate: 4.08103e-05
	LOSS [training: 0.10608574063293505 | validation: 0.10582280797222468]
	TIME [epoch: 31.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10801188136999307		[learning rate: 4.0522e-05]
	Learning Rate: 4.05221e-05
	LOSS [training: 0.10801188136999307 | validation: 0.10382906227560273]
	TIME [epoch: 31.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1075894433020282		[learning rate: 4.0236e-05]
	Learning Rate: 4.02361e-05
	LOSS [training: 0.1075894433020282 | validation: 0.09647820149563863]
	TIME [epoch: 31.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1123300688585682		[learning rate: 3.9952e-05]
	Learning Rate: 3.9952e-05
	LOSS [training: 0.1123300688585682 | validation: 0.09862827003309656]
	TIME [epoch: 31.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11180101550218437		[learning rate: 3.967e-05]
	Learning Rate: 3.967e-05
	LOSS [training: 0.11180101550218437 | validation: 0.09796628297563229]
	TIME [epoch: 31.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10919147914066293		[learning rate: 3.939e-05]
	Learning Rate: 3.93899e-05
	LOSS [training: 0.10919147914066293 | validation: 0.0990723178489486]
	TIME [epoch: 31.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11021282610321467		[learning rate: 3.9112e-05]
	Learning Rate: 3.91118e-05
	LOSS [training: 0.11021282610321467 | validation: 0.10036752792475204]
	TIME [epoch: 31.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11163111146295226		[learning rate: 3.8836e-05]
	Learning Rate: 3.88357e-05
	LOSS [training: 0.11163111146295226 | validation: 0.09899412444963596]
	TIME [epoch: 31.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10594086940985485		[learning rate: 3.8561e-05]
	Learning Rate: 3.85615e-05
	LOSS [training: 0.10594086940985485 | validation: 0.10406969828409506]
	TIME [epoch: 31.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1047078008510441		[learning rate: 3.8289e-05]
	Learning Rate: 3.82893e-05
	LOSS [training: 0.1047078008510441 | validation: 0.10452761224684488]
	TIME [epoch: 31.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11033653700618948		[learning rate: 3.8019e-05]
	Learning Rate: 3.8019e-05
	LOSS [training: 0.11033653700618948 | validation: 0.10112662455961262]
	TIME [epoch: 31.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10931706686803078		[learning rate: 3.7751e-05]
	Learning Rate: 3.77505e-05
	LOSS [training: 0.10931706686803078 | validation: 0.12199094696551156]
	TIME [epoch: 31.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.12820486784360785		[learning rate: 3.7484e-05]
	Learning Rate: 3.7484e-05
	LOSS [training: 0.12820486784360785 | validation: 0.12495145454010831]
	TIME [epoch: 31.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11867786143043677		[learning rate: 3.7219e-05]
	Learning Rate: 3.72194e-05
	LOSS [training: 0.11867786143043677 | validation: 0.10477678405007768]
	TIME [epoch: 31.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11085051069155993		[learning rate: 3.6957e-05]
	Learning Rate: 3.69566e-05
	LOSS [training: 0.11085051069155993 | validation: 0.10108176222422337]
	TIME [epoch: 31.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10960522558165789		[learning rate: 3.6696e-05]
	Learning Rate: 3.66957e-05
	LOSS [training: 0.10960522558165789 | validation: 0.10122150368185301]
	TIME [epoch: 31.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1080131911849902		[learning rate: 3.6437e-05]
	Learning Rate: 3.64367e-05
	LOSS [training: 0.1080131911849902 | validation: 0.10248145433965204]
	TIME [epoch: 31.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1087222607521409		[learning rate: 3.6179e-05]
	Learning Rate: 3.61794e-05
	LOSS [training: 0.1087222607521409 | validation: 0.10261697854298656]
	TIME [epoch: 31.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10691468928295235		[learning rate: 3.5924e-05]
	Learning Rate: 3.5924e-05
	LOSS [training: 0.10691468928295235 | validation: 0.10098835002395329]
	TIME [epoch: 31.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1080986037382927		[learning rate: 3.567e-05]
	Learning Rate: 3.56704e-05
	LOSS [training: 0.1080986037382927 | validation: 0.10338072170199364]
	TIME [epoch: 31.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10660141836147181		[learning rate: 3.5419e-05]
	Learning Rate: 3.54186e-05
	LOSS [training: 0.10660141836147181 | validation: 0.10818784192159213]
	TIME [epoch: 31.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10836944629805159		[learning rate: 3.5169e-05]
	Learning Rate: 3.51685e-05
	LOSS [training: 0.10836944629805159 | validation: 0.10646227694919011]
	TIME [epoch: 31.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10407908910080474		[learning rate: 3.492e-05]
	Learning Rate: 3.49202e-05
	LOSS [training: 0.10407908910080474 | validation: 0.101202669347891]
	TIME [epoch: 31.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1055977719195241		[learning rate: 3.4674e-05]
	Learning Rate: 3.46737e-05
	LOSS [training: 0.1055977719195241 | validation: 0.10183654703164109]
	TIME [epoch: 31.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10553329097894032		[learning rate: 3.4429e-05]
	Learning Rate: 3.44289e-05
	LOSS [training: 0.10553329097894032 | validation: 0.10244760530306359]
	TIME [epoch: 31.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10561122869889213		[learning rate: 3.4186e-05]
	Learning Rate: 3.41858e-05
	LOSS [training: 0.10561122869889213 | validation: 0.09370478543074152]
	TIME [epoch: 31.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11190313021815168		[learning rate: 3.3944e-05]
	Learning Rate: 3.39445e-05
	LOSS [training: 0.11190313021815168 | validation: 0.10280248134766784]
	TIME [epoch: 31.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10359555484708252		[learning rate: 3.3705e-05]
	Learning Rate: 3.37049e-05
	LOSS [training: 0.10359555484708252 | validation: 0.10298931707103161]
	TIME [epoch: 31.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10769281558783012		[learning rate: 3.3467e-05]
	Learning Rate: 3.34669e-05
	LOSS [training: 0.10769281558783012 | validation: 0.09369842586977169]
	TIME [epoch: 31.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10688497612402137		[learning rate: 3.3231e-05]
	Learning Rate: 3.32306e-05
	LOSS [training: 0.10688497612402137 | validation: 0.10200096184369199]
	TIME [epoch: 31.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10310783138875228		[learning rate: 3.2996e-05]
	Learning Rate: 3.2996e-05
	LOSS [training: 0.10310783138875228 | validation: 0.099033330407353]
	TIME [epoch: 31.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10541379796301484		[learning rate: 3.2763e-05]
	Learning Rate: 3.27631e-05
	LOSS [training: 0.10541379796301484 | validation: 0.1027342496215725]
	TIME [epoch: 31.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10695589776197581		[learning rate: 3.2532e-05]
	Learning Rate: 3.25318e-05
	LOSS [training: 0.10695589776197581 | validation: 0.09897193435658035]
	TIME [epoch: 31.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10696556413716847		[learning rate: 3.2302e-05]
	Learning Rate: 3.23021e-05
	LOSS [training: 0.10696556413716847 | validation: 0.09828547357688872]
	TIME [epoch: 31.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10432258106106476		[learning rate: 3.2074e-05]
	Learning Rate: 3.20741e-05
	LOSS [training: 0.10432258106106476 | validation: 0.09766764338313384]
	TIME [epoch: 31.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10755590021263961		[learning rate: 3.1848e-05]
	Learning Rate: 3.18476e-05
	LOSS [training: 0.10755590021263961 | validation: 0.09364335621261399]
	TIME [epoch: 31.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10760589777177416		[learning rate: 3.1623e-05]
	Learning Rate: 3.16228e-05
	LOSS [training: 0.10760589777177416 | validation: 0.09466598293986088]
	TIME [epoch: 31.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11017465153102621		[learning rate: 3.14e-05]
	Learning Rate: 3.13995e-05
	LOSS [training: 0.11017465153102621 | validation: 0.11503242256175872]
	TIME [epoch: 31.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11564136231043293		[learning rate: 3.1178e-05]
	Learning Rate: 3.11778e-05
	LOSS [training: 0.11564136231043293 | validation: 0.10399451820195305]
	TIME [epoch: 31.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1105175679516596		[learning rate: 3.0958e-05]
	Learning Rate: 3.09577e-05
	LOSS [training: 0.1105175679516596 | validation: 0.09766992367496354]
	TIME [epoch: 31.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10924242698907596		[learning rate: 3.0739e-05]
	Learning Rate: 3.07392e-05
	LOSS [training: 0.10924242698907596 | validation: 0.10314672616422738]
	TIME [epoch: 31.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10377261492502032		[learning rate: 3.0522e-05]
	Learning Rate: 3.05222e-05
	LOSS [training: 0.10377261492502032 | validation: 0.10705677725650638]
	TIME [epoch: 31.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10827989146496084		[learning rate: 3.0307e-05]
	Learning Rate: 3.03067e-05
	LOSS [training: 0.10827989146496084 | validation: 0.10031265451211571]
	TIME [epoch: 31.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10957851209828443		[learning rate: 3.0093e-05]
	Learning Rate: 3.00927e-05
	LOSS [training: 0.10957851209828443 | validation: 0.1016692652954847]
	TIME [epoch: 31.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10471996931191623		[learning rate: 2.988e-05]
	Learning Rate: 2.98803e-05
	LOSS [training: 0.10471996931191623 | validation: 0.0995115823070899]
	TIME [epoch: 31.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11038648146294452		[learning rate: 2.9669e-05]
	Learning Rate: 2.96693e-05
	LOSS [training: 0.11038648146294452 | validation: 0.10062206142403206]
	TIME [epoch: 31.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10931965072605544		[learning rate: 2.946e-05]
	Learning Rate: 2.94599e-05
	LOSS [training: 0.10931965072605544 | validation: 0.10357479861463813]
	TIME [epoch: 31.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10637631340153286		[learning rate: 2.9252e-05]
	Learning Rate: 2.92519e-05
	LOSS [training: 0.10637631340153286 | validation: 0.1028299745600958]
	TIME [epoch: 31.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10733855549596757		[learning rate: 2.9045e-05]
	Learning Rate: 2.90454e-05
	LOSS [training: 0.10733855549596757 | validation: 0.09856662854396453]
	TIME [epoch: 31.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1036561471129771		[learning rate: 2.884e-05]
	Learning Rate: 2.88403e-05
	LOSS [training: 0.1036561471129771 | validation: 0.09235017596720456]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10232616835844328		[learning rate: 2.8637e-05]
	Learning Rate: 2.86367e-05
	LOSS [training: 0.10232616835844328 | validation: 0.09642555009709014]
	TIME [epoch: 31.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10355465649790796		[learning rate: 2.8435e-05]
	Learning Rate: 2.84345e-05
	LOSS [training: 0.10355465649790796 | validation: 0.09619343764690977]
	TIME [epoch: 31.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10716160974209785		[learning rate: 2.8234e-05]
	Learning Rate: 2.82338e-05
	LOSS [training: 0.10716160974209785 | validation: 0.10122121314745058]
	TIME [epoch: 31.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10357669135720945		[learning rate: 2.8034e-05]
	Learning Rate: 2.80345e-05
	LOSS [training: 0.10357669135720945 | validation: 0.09884593823191337]
	TIME [epoch: 31.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10289663322321771		[learning rate: 2.7837e-05]
	Learning Rate: 2.78366e-05
	LOSS [training: 0.10289663322321771 | validation: 0.10432220197305625]
	TIME [epoch: 31.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10877098640631863		[learning rate: 2.764e-05]
	Learning Rate: 2.764e-05
	LOSS [training: 0.10877098640631863 | validation: 0.0969375805326711]
	TIME [epoch: 31.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10507167022532131		[learning rate: 2.7445e-05]
	Learning Rate: 2.74449e-05
	LOSS [training: 0.10507167022532131 | validation: 0.10296368277105304]
	TIME [epoch: 31.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10514309941476727		[learning rate: 2.7251e-05]
	Learning Rate: 2.72511e-05
	LOSS [training: 0.10514309941476727 | validation: 0.08916198158241433]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10521388276325425		[learning rate: 2.7059e-05]
	Learning Rate: 2.70587e-05
	LOSS [training: 0.10521388276325425 | validation: 0.10136394872754194]
	TIME [epoch: 31.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10554559503761243		[learning rate: 2.6868e-05]
	Learning Rate: 2.68677e-05
	LOSS [training: 0.10554559503761243 | validation: 0.09958824532688587]
	TIME [epoch: 31.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1044187018168497		[learning rate: 2.6678e-05]
	Learning Rate: 2.6678e-05
	LOSS [training: 0.1044187018168497 | validation: 0.09562321476962338]
	TIME [epoch: 31.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10329761323801787		[learning rate: 2.649e-05]
	Learning Rate: 2.64897e-05
	LOSS [training: 0.10329761323801787 | validation: 0.09880381690766633]
	TIME [epoch: 31.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10377743226523642		[learning rate: 2.6303e-05]
	Learning Rate: 2.63027e-05
	LOSS [training: 0.10377743226523642 | validation: 0.09382133637295256]
	TIME [epoch: 31.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10647064864567139		[learning rate: 2.6117e-05]
	Learning Rate: 2.6117e-05
	LOSS [training: 0.10647064864567139 | validation: 0.1026713425518609]
	TIME [epoch: 31.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10290313414136007		[learning rate: 2.5933e-05]
	Learning Rate: 2.59326e-05
	LOSS [training: 0.10290313414136007 | validation: 0.10199929718958685]
	TIME [epoch: 31.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11086299842099498		[learning rate: 2.575e-05]
	Learning Rate: 2.57495e-05
	LOSS [training: 0.11086299842099498 | validation: 0.10034462573555268]
	TIME [epoch: 31.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10638023251290646		[learning rate: 2.5568e-05]
	Learning Rate: 2.55677e-05
	LOSS [training: 0.10638023251290646 | validation: 0.10010513040807978]
	TIME [epoch: 31.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10902834505248826		[learning rate: 2.5387e-05]
	Learning Rate: 2.53872e-05
	LOSS [training: 0.10902834505248826 | validation: 0.09403101148606019]
	TIME [epoch: 31.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10318026362041197		[learning rate: 2.5208e-05]
	Learning Rate: 2.5208e-05
	LOSS [training: 0.10318026362041197 | validation: 0.09570886995980617]
	TIME [epoch: 31.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10889781725189902		[learning rate: 2.503e-05]
	Learning Rate: 2.503e-05
	LOSS [training: 0.10889781725189902 | validation: 0.11722025801179492]
	TIME [epoch: 31.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11580443840609554		[learning rate: 2.4853e-05]
	Learning Rate: 2.48533e-05
	LOSS [training: 0.11580443840609554 | validation: 0.10252399211647384]
	TIME [epoch: 31.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10637552078148799		[learning rate: 2.4678e-05]
	Learning Rate: 2.46779e-05
	LOSS [training: 0.10637552078148799 | validation: 0.09715002572677794]
	TIME [epoch: 31.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10315994713633683		[learning rate: 2.4504e-05]
	Learning Rate: 2.45037e-05
	LOSS [training: 0.10315994713633683 | validation: 0.10076836520501808]
	TIME [epoch: 31.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10416927561305014		[learning rate: 2.4331e-05]
	Learning Rate: 2.43307e-05
	LOSS [training: 0.10416927561305014 | validation: 0.09860202825999423]
	TIME [epoch: 31.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10484624024734782		[learning rate: 2.4159e-05]
	Learning Rate: 2.41589e-05
	LOSS [training: 0.10484624024734782 | validation: 0.0965062002869793]
	TIME [epoch: 31.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10913917969599461		[learning rate: 2.3988e-05]
	Learning Rate: 2.39883e-05
	LOSS [training: 0.10913917969599461 | validation: 0.10134482624180344]
	TIME [epoch: 31.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10595364056413		[learning rate: 2.3819e-05]
	Learning Rate: 2.3819e-05
	LOSS [training: 0.10595364056413 | validation: 0.0989047786971802]
	TIME [epoch: 31.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10472103114378957		[learning rate: 2.3651e-05]
	Learning Rate: 2.36508e-05
	LOSS [training: 0.10472103114378957 | validation: 0.09338407879011706]
	TIME [epoch: 31.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10277931350139728		[learning rate: 2.3484e-05]
	Learning Rate: 2.34838e-05
	LOSS [training: 0.10277931350139728 | validation: 0.10108048543645186]
	TIME [epoch: 31.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10503098392824461		[learning rate: 2.3318e-05]
	Learning Rate: 2.33181e-05
	LOSS [training: 0.10503098392824461 | validation: 0.09696131191038693]
	TIME [epoch: 31.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10625750336582651		[learning rate: 2.3153e-05]
	Learning Rate: 2.31534e-05
	LOSS [training: 0.10625750336582651 | validation: 0.09983964655702567]
	TIME [epoch: 31.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10417682375113493		[learning rate: 2.299e-05]
	Learning Rate: 2.299e-05
	LOSS [training: 0.10417682375113493 | validation: 0.09724697088419622]
	TIME [epoch: 31.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10908623880240581		[learning rate: 2.2828e-05]
	Learning Rate: 2.28277e-05
	LOSS [training: 0.10908623880240581 | validation: 0.09789719702579175]
	TIME [epoch: 31.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10106254429009817		[learning rate: 2.2667e-05]
	Learning Rate: 2.26665e-05
	LOSS [training: 0.10106254429009817 | validation: 0.10056352716411061]
	TIME [epoch: 31.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10727223697984667		[learning rate: 2.2506e-05]
	Learning Rate: 2.25065e-05
	LOSS [training: 0.10727223697984667 | validation: 0.10259500122664288]
	TIME [epoch: 31.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10400658211720656		[learning rate: 2.2348e-05]
	Learning Rate: 2.23476e-05
	LOSS [training: 0.10400658211720656 | validation: 0.0990933924682578]
	TIME [epoch: 31.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1057675308969957		[learning rate: 2.219e-05]
	Learning Rate: 2.21898e-05
	LOSS [training: 0.1057675308969957 | validation: 0.09621029806661117]
	TIME [epoch: 31.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10354208583254537		[learning rate: 2.2033e-05]
	Learning Rate: 2.20332e-05
	LOSS [training: 0.10354208583254537 | validation: 0.09780950561955062]
	TIME [epoch: 31.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10208439688836218		[learning rate: 2.1878e-05]
	Learning Rate: 2.18776e-05
	LOSS [training: 0.10208439688836218 | validation: 0.09863371963964869]
	TIME [epoch: 31.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10440179685483045		[learning rate: 2.1723e-05]
	Learning Rate: 2.17232e-05
	LOSS [training: 0.10440179685483045 | validation: 0.10120386807340016]
	TIME [epoch: 31.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10677085722619269		[learning rate: 2.157e-05]
	Learning Rate: 2.15698e-05
	LOSS [training: 0.10677085722619269 | validation: 0.09788920531867537]
	TIME [epoch: 31.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1065307271693105		[learning rate: 2.1418e-05]
	Learning Rate: 2.14175e-05
	LOSS [training: 0.1065307271693105 | validation: 0.10082754120145934]
	TIME [epoch: 31.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10691454986038332		[learning rate: 2.1266e-05]
	Learning Rate: 2.12663e-05
	LOSS [training: 0.10691454986038332 | validation: 0.10286520896181384]
	TIME [epoch: 31.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10300051246987404		[learning rate: 2.1116e-05]
	Learning Rate: 2.11162e-05
	LOSS [training: 0.10300051246987404 | validation: 0.09739621523087585]
	TIME [epoch: 31.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10442692305266771		[learning rate: 2.0967e-05]
	Learning Rate: 2.09671e-05
	LOSS [training: 0.10442692305266771 | validation: 0.09604512417595495]
	TIME [epoch: 31.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10388855862630439		[learning rate: 2.0819e-05]
	Learning Rate: 2.08191e-05
	LOSS [training: 0.10388855862630439 | validation: 0.09656844479340328]
	TIME [epoch: 31.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10891459983456289		[learning rate: 2.0672e-05]
	Learning Rate: 2.06721e-05
	LOSS [training: 0.10891459983456289 | validation: 0.10066816668728598]
	TIME [epoch: 31.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10651992962256879		[learning rate: 2.0526e-05]
	Learning Rate: 2.05262e-05
	LOSS [training: 0.10651992962256879 | validation: 0.10195581269890056]
	TIME [epoch: 31.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10238300931175738		[learning rate: 2.0381e-05]
	Learning Rate: 2.03813e-05
	LOSS [training: 0.10238300931175738 | validation: 0.09377824270836933]
	TIME [epoch: 31.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10367123654233439		[learning rate: 2.0237e-05]
	Learning Rate: 2.02374e-05
	LOSS [training: 0.10367123654233439 | validation: 0.09431758148925738]
	TIME [epoch: 31.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10334479464030322		[learning rate: 2.0094e-05]
	Learning Rate: 2.00945e-05
	LOSS [training: 0.10334479464030322 | validation: 0.09675079291159915]
	TIME [epoch: 31.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10491729444874048		[learning rate: 1.9953e-05]
	Learning Rate: 1.99526e-05
	LOSS [training: 0.10491729444874048 | validation: 0.09635506927752109]
	TIME [epoch: 31.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10277253424894517		[learning rate: 1.9812e-05]
	Learning Rate: 1.98118e-05
	LOSS [training: 0.10277253424894517 | validation: 0.10189226674047412]
	TIME [epoch: 31.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10310450380643837		[learning rate: 1.9672e-05]
	Learning Rate: 1.96719e-05
	LOSS [training: 0.10310450380643837 | validation: 0.10456498649806437]
	TIME [epoch: 31.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10386342660809103		[learning rate: 1.9533e-05]
	Learning Rate: 1.9533e-05
	LOSS [training: 0.10386342660809103 | validation: 0.10260090240308149]
	TIME [epoch: 31.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10357605758749217		[learning rate: 1.9395e-05]
	Learning Rate: 1.93951e-05
	LOSS [training: 0.10357605758749217 | validation: 0.09890469542644985]
	TIME [epoch: 31.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10758462254905832		[learning rate: 1.9258e-05]
	Learning Rate: 1.92582e-05
	LOSS [training: 0.10758462254905832 | validation: 0.09753574514938168]
	TIME [epoch: 31.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10172272213463686		[learning rate: 1.9122e-05]
	Learning Rate: 1.91222e-05
	LOSS [training: 0.10172272213463686 | validation: 0.09619935216586425]
	TIME [epoch: 31.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10097273243713353		[learning rate: 1.8987e-05]
	Learning Rate: 1.89872e-05
	LOSS [training: 0.10097273243713353 | validation: 0.09719150702783895]
	TIME [epoch: 31.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10519105013123735		[learning rate: 1.8853e-05]
	Learning Rate: 1.88532e-05
	LOSS [training: 0.10519105013123735 | validation: 0.09585515772958096]
	TIME [epoch: 31.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10784787631004154		[learning rate: 1.872e-05]
	Learning Rate: 1.87201e-05
	LOSS [training: 0.10784787631004154 | validation: 0.10276384915152229]
	TIME [epoch: 31.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10887571705593245		[learning rate: 1.8588e-05]
	Learning Rate: 1.85879e-05
	LOSS [training: 0.10887571705593245 | validation: 0.09503937627579367]
	TIME [epoch: 31.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10434197337928651		[learning rate: 1.8457e-05]
	Learning Rate: 1.84567e-05
	LOSS [training: 0.10434197337928651 | validation: 0.09992670686259626]
	TIME [epoch: 31.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10618324396041409		[learning rate: 1.8326e-05]
	Learning Rate: 1.83264e-05
	LOSS [training: 0.10618324396041409 | validation: 0.09784518260918838]
	TIME [epoch: 31.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10616375717552234		[learning rate: 1.8197e-05]
	Learning Rate: 1.8197e-05
	LOSS [training: 0.10616375717552234 | validation: 0.10694589262632433]
	TIME [epoch: 31.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10821907987496399		[learning rate: 1.8069e-05]
	Learning Rate: 1.80685e-05
	LOSS [training: 0.10821907987496399 | validation: 0.09570201251268233]
	TIME [epoch: 31.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1012425915878909		[learning rate: 1.7941e-05]
	Learning Rate: 1.7941e-05
	LOSS [training: 0.1012425915878909 | validation: 0.09302657432956792]
	TIME [epoch: 31.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10230655840819577		[learning rate: 1.7814e-05]
	Learning Rate: 1.78143e-05
	LOSS [training: 0.10230655840819577 | validation: 0.09477398001927655]
	TIME [epoch: 31.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10695888252651632		[learning rate: 1.7689e-05]
	Learning Rate: 1.76886e-05
	LOSS [training: 0.10695888252651632 | validation: 0.09871189584811897]
	TIME [epoch: 31.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.09948911767235698		[learning rate: 1.7564e-05]
	Learning Rate: 1.75637e-05
	LOSS [training: 0.09948911767235698 | validation: 0.09664463232104337]
	TIME [epoch: 31.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.09958488898684284		[learning rate: 1.744e-05]
	Learning Rate: 1.74397e-05
	LOSS [training: 0.09958488898684284 | validation: 0.10041871512715694]
	TIME [epoch: 31.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10424958367279455		[learning rate: 1.7317e-05]
	Learning Rate: 1.73166e-05
	LOSS [training: 0.10424958367279455 | validation: 0.0968542938251642]
	TIME [epoch: 31.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10438842882106456		[learning rate: 1.7194e-05]
	Learning Rate: 1.71943e-05
	LOSS [training: 0.10438842882106456 | validation: 0.0966541628062429]
	TIME [epoch: 31.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10484575506300084		[learning rate: 1.7073e-05]
	Learning Rate: 1.70729e-05
	LOSS [training: 0.10484575506300084 | validation: 0.09948626342797301]
	TIME [epoch: 31.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10531129035633019		[learning rate: 1.6952e-05]
	Learning Rate: 1.69524e-05
	LOSS [training: 0.10531129035633019 | validation: 0.10241296358813488]
	TIME [epoch: 31.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10399704977458682		[learning rate: 1.6833e-05]
	Learning Rate: 1.68327e-05
	LOSS [training: 0.10399704977458682 | validation: 0.09570542021939801]
	TIME [epoch: 31.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10147595441732803		[learning rate: 1.6714e-05]
	Learning Rate: 1.67139e-05
	LOSS [training: 0.10147595441732803 | validation: 0.09357478106919231]
	TIME [epoch: 31.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.09984026051270772		[learning rate: 1.6596e-05]
	Learning Rate: 1.65959e-05
	LOSS [training: 0.09984026051270772 | validation: 0.0969751603744825]
	TIME [epoch: 31.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1051210334593343		[learning rate: 1.6479e-05]
	Learning Rate: 1.64787e-05
	LOSS [training: 0.1051210334593343 | validation: 0.09796006694986593]
	TIME [epoch: 31.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10478406001824922		[learning rate: 1.6362e-05]
	Learning Rate: 1.63624e-05
	LOSS [training: 0.10478406001824922 | validation: 0.09857770543691158]
	TIME [epoch: 31.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10316996093136771		[learning rate: 1.6247e-05]
	Learning Rate: 1.62469e-05
	LOSS [training: 0.10316996093136771 | validation: 0.09699226423242914]
	TIME [epoch: 31.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10383451994241155		[learning rate: 1.6132e-05]
	Learning Rate: 1.61322e-05
	LOSS [training: 0.10383451994241155 | validation: 0.09341600190177993]
	TIME [epoch: 31.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1020419201018552		[learning rate: 1.6018e-05]
	Learning Rate: 1.60183e-05
	LOSS [training: 0.1020419201018552 | validation: 0.09743156853445284]
	TIME [epoch: 31.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1044036914139689		[learning rate: 1.5905e-05]
	Learning Rate: 1.59052e-05
	LOSS [training: 0.1044036914139689 | validation: 0.10350649353852491]
	TIME [epoch: 31.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1051259631714227		[learning rate: 1.5793e-05]
	Learning Rate: 1.57929e-05
	LOSS [training: 0.1051259631714227 | validation: 0.10188629457765815]
	TIME [epoch: 31.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10466113834634586		[learning rate: 1.5681e-05]
	Learning Rate: 1.56814e-05
	LOSS [training: 0.10466113834634586 | validation: 0.09670465442974813]
	TIME [epoch: 31.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10964963377764607		[learning rate: 1.5571e-05]
	Learning Rate: 1.55707e-05
	LOSS [training: 0.10964963377764607 | validation: 0.10401470713432322]
	TIME [epoch: 31.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10527358349650681		[learning rate: 1.5461e-05]
	Learning Rate: 1.54608e-05
	LOSS [training: 0.10527358349650681 | validation: 0.10091437521761254]
	TIME [epoch: 31.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10475798457469432		[learning rate: 1.5352e-05]
	Learning Rate: 1.53516e-05
	LOSS [training: 0.10475798457469432 | validation: 0.09510466970854546]
	TIME [epoch: 31.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10597313699213179		[learning rate: 1.5243e-05]
	Learning Rate: 1.52432e-05
	LOSS [training: 0.10597313699213179 | validation: 0.1107144815219538]
	TIME [epoch: 31.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10458492568174739		[learning rate: 1.5136e-05]
	Learning Rate: 1.51356e-05
	LOSS [training: 0.10458492568174739 | validation: 0.09678510560382013]
	TIME [epoch: 31.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1076526618371327		[learning rate: 1.5029e-05]
	Learning Rate: 1.50288e-05
	LOSS [training: 0.1076526618371327 | validation: 0.09445050445761483]
	TIME [epoch: 31.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10430806518514427		[learning rate: 1.4923e-05]
	Learning Rate: 1.49227e-05
	LOSS [training: 0.10430806518514427 | validation: 0.09295773633653351]
	TIME [epoch: 31.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10232165812500721		[learning rate: 1.4817e-05]
	Learning Rate: 1.48173e-05
	LOSS [training: 0.10232165812500721 | validation: 0.09386763544174538]
	TIME [epoch: 31.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10630247508593213		[learning rate: 1.4713e-05]
	Learning Rate: 1.47127e-05
	LOSS [training: 0.10630247508593213 | validation: 0.09392330328561167]
	TIME [epoch: 31.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10126468468145844		[learning rate: 1.4609e-05]
	Learning Rate: 1.46088e-05
	LOSS [training: 0.10126468468145844 | validation: 0.09584658403826674]
	TIME [epoch: 31.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10434506289646518		[learning rate: 1.4506e-05]
	Learning Rate: 1.45057e-05
	LOSS [training: 0.10434506289646518 | validation: 0.10601716808638482]
	TIME [epoch: 31.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10559893302597978		[learning rate: 1.4403e-05]
	Learning Rate: 1.44033e-05
	LOSS [training: 0.10559893302597978 | validation: 0.0996995870366306]
	TIME [epoch: 31.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1042434849177655		[learning rate: 1.4302e-05]
	Learning Rate: 1.43016e-05
	LOSS [training: 0.1042434849177655 | validation: 0.103817986258989]
	TIME [epoch: 31.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10535052873226808		[learning rate: 1.4201e-05]
	Learning Rate: 1.42006e-05
	LOSS [training: 0.10535052873226808 | validation: 0.09796809905100752]
	TIME [epoch: 31.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10701676657447766		[learning rate: 1.41e-05]
	Learning Rate: 1.41004e-05
	LOSS [training: 0.10701676657447766 | validation: 0.10596787038040685]
	TIME [epoch: 31.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.11005289468040291		[learning rate: 1.4001e-05]
	Learning Rate: 1.40008e-05
	LOSS [training: 0.11005289468040291 | validation: 0.09893436988135383]
	TIME [epoch: 31.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10712081123281397		[learning rate: 1.3902e-05]
	Learning Rate: 1.3902e-05
	LOSS [training: 0.10712081123281397 | validation: 0.09377193319856121]
	TIME [epoch: 31.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1030127049129075		[learning rate: 1.3804e-05]
	Learning Rate: 1.38038e-05
	LOSS [training: 0.1030127049129075 | validation: 0.10008849041762216]
	TIME [epoch: 31.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10573345468708986		[learning rate: 1.3706e-05]
	Learning Rate: 1.37064e-05
	LOSS [training: 0.10573345468708986 | validation: 0.10091249951157755]
	TIME [epoch: 31.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10674447126838425		[learning rate: 1.361e-05]
	Learning Rate: 1.36096e-05
	LOSS [training: 0.10674447126838425 | validation: 0.0973680424123325]
	TIME [epoch: 31.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10234033662525739		[learning rate: 1.3514e-05]
	Learning Rate: 1.35135e-05
	LOSS [training: 0.10234033662525739 | validation: 0.09425716548224555]
	TIME [epoch: 31.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.10111272095439947		[learning rate: 1.3418e-05]
	Learning Rate: 1.34181e-05
	LOSS [training: 0.10111272095439947 | validation: 0.09610282164050254]
	TIME [epoch: 31.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 2/2] avg loss: 0.1024262678402229		[learning rate: 1.3323e-05]
	Learning Rate: 1.33234e-05
	LOSS [training: 0.1024262678402229 | validation: 0.09667347666447706]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_phi1_2c_v_mmd1_20240813_193441/states/model_phi1_2c_v_mmd1_960.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 20527.439 seconds.
