Args:
Namespace(name='model_phi1_1a_v_mmd5', outdir='out/model_training/model_phi1_1a_v_mmd5', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4125644803

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2567732819131745		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 5.2567732819131745 | validation: 4.15871267785142]
	TIME [epoch: 104 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512404268655524		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 4.512404268655524 | validation: 3.645543653464501]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.219199234227085		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 4.219199234227085 | validation: 3.3158205687560076]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.895566302105284		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 3.895566302105284 | validation: 3.42572493959051]
	TIME [epoch: 8.25 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.676031574049203		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 3.676031574049203 | validation: 3.255867033992584]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5678422427911944		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 3.5678422427911944 | validation: 3.267849914114845]
	TIME [epoch: 8.3 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.687647747196009		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 3.687647747196009 | validation: 3.4079693234707844]
	TIME [epoch: 8.25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.513509979247832		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 3.513509979247832 | validation: 2.8207969541398987]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.346138727402204		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 3.346138727402204 | validation: 2.8520064567673193]
	TIME [epoch: 8.24 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2831128756129115		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 3.2831128756129115 | validation: 2.650174961100813]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.032713962941248		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 3.032713962941248 | validation: 3.2698088200026465]
	TIME [epoch: 8.29 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.989201937007913		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 2.989201937007913 | validation: 2.890674525114854]
	TIME [epoch: 8.25 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0644631620490874		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 3.0644631620490874 | validation: 2.693702681097763]
	TIME [epoch: 8.24 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.926827467394104		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 2.926827467394104 | validation: 3.0901630606861454]
	TIME [epoch: 8.24 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.95976550035111		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 2.95976550035111 | validation: 2.6171671791146878]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.819448684788545		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 2.819448684788545 | validation: 2.509500229006237]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6932621667542356		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 2.6932621667542356 | validation: 2.529782711812283]
	TIME [epoch: 8.28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.683618626250361		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 2.683618626250361 | validation: 2.5344799237012987]
	TIME [epoch: 8.25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6932372579848787		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 2.6932372579848787 | validation: 2.404978563183313]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5434852917464257		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 2.5434852917464257 | validation: 2.5383769013799915]
	TIME [epoch: 8.24 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5772576358517236		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 2.5772576358517236 | validation: 2.250606206301896]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3741813461337156		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 2.3741813461337156 | validation: 2.356731863792792]
	TIME [epoch: 8.27 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.543171526863917		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 2.543171526863917 | validation: 2.4442058648809377]
	TIME [epoch: 8.25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.445923928127188		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 2.445923928127188 | validation: 2.307633593077215]
	TIME [epoch: 8.24 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38137608090093		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 2.38137608090093 | validation: 2.3055491091832394]
	TIME [epoch: 8.24 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.400765350254279		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 2.400765350254279 | validation: 2.2326227392178755]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287375702429853		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 2.287375702429853 | validation: 2.1795906614422798]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3649999469561065		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 2.3649999469561065 | validation: 2.151298382148341]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289077625892853		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 2.289077625892853 | validation: 2.3315392434237268]
	TIME [epoch: 8.26 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2349233597328366		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 2.2349233597328366 | validation: 2.267849250294961]
	TIME [epoch: 8.25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194016813794508		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 2.194016813794508 | validation: 2.0976853157538864]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3396574475125362		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 2.3396574475125362 | validation: 2.004518879423456]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.013772454121843		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 2.013772454121843 | validation: 1.9299788282606514]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4778752401625557		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 2.4778752401625557 | validation: 2.076530824836855]
	TIME [epoch: 8.25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.951452997448738		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 1.951452997448738 | validation: 1.7995061926819167]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7079435970666572		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 1.7079435970666572 | validation: 1.786486897678378]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7425340630410122		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 1.7425340630410122 | validation: 2.478698527898893]
	TIME [epoch: 8.24 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088071739732208		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 2.088071739732208 | validation: 1.5450320574754857]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62594108927591		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 1.62594108927591 | validation: 1.8407935963298752]
	TIME [epoch: 8.27 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.86496017575093		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 1.86496017575093 | validation: 1.2306706902603677]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4098800334838932		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 1.4098800334838932 | validation: 1.276684245268206]
	TIME [epoch: 8.24 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6176217033327092		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 1.6176217033327092 | validation: 1.1891126600470532]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4204975160547035		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 1.4204975160547035 | validation: 1.3111017575103294]
	TIME [epoch: 8.26 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3248851760404063		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 1.3248851760404063 | validation: 1.3340409666648523]
	TIME [epoch: 8.28 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292685535666563		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 1.2292685535666563 | validation: 1.6428554326469595]
	TIME [epoch: 8.25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2598451538021256		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 1.2598451538021256 | validation: 1.1841595381483228]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1737851062264497		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 1.1737851062264497 | validation: 1.2285465717887596]
	TIME [epoch: 8.25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1722836994970065		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 1.1722836994970065 | validation: 1.1479552853467307]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.204151075251817		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 1.204151075251817 | validation: 0.8417066312004086]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1548067229778551		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 1.1548067229778551 | validation: 1.0717476907498027]
	TIME [epoch: 8.25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651862455413732		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 1.0651862455413732 | validation: 1.0537688897634632]
	TIME [epoch: 8.25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9380806180047865		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.9380806180047865 | validation: 1.0173219838937966]
	TIME [epoch: 8.24 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221652441711803		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 0.9221652441711803 | validation: 0.8545317535839942]
	TIME [epoch: 8.24 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437687973070779		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 0.9437687973070779 | validation: 0.8471724202456414]
	TIME [epoch: 8.25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8145567328775616		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 0.8145567328775616 | validation: 0.8432134836796328]
	TIME [epoch: 8.27 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8562583148059861		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 0.8562583148059861 | validation: 0.8827773409064984]
	TIME [epoch: 8.24 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9567713131819962		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 0.9567713131819962 | validation: 0.6199433611634566]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.891811656245342		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 0.891811656245342 | validation: 0.8963325662902859]
	TIME [epoch: 8.24 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2654915553792663		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 1.2654915553792663 | validation: 0.5345355741906206]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101113817766715		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 0.6101113817766715 | validation: 0.7065046193403917]
	TIME [epoch: 8.28 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665783293672384		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 0.7665783293672384 | validation: 0.520733359004005]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691732622341763		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 0.6691732622341763 | validation: 0.5470617901654597]
	TIME [epoch: 8.26 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376521419961624		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 0.7376521419961624 | validation: 0.515791879896963]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6946951623584914		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 0.6946951623584914 | validation: 0.8086830045975248]
	TIME [epoch: 8.26 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140979236090606		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 0.8140979236090606 | validation: 0.47401904131325356]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112452953234043		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 0.5112452953234043 | validation: 0.48740416695960087]
	TIME [epoch: 8.28 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6523255205902034		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 0.6523255205902034 | validation: 0.498047557278548]
	TIME [epoch: 8.25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9205957218906466		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 0.9205957218906466 | validation: 0.5981566780102427]
	TIME [epoch: 8.25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669145430906462		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 0.6669145430906462 | validation: 0.44878921650031556]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089921964094307		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 0.6089921964094307 | validation: 0.3879814196284219]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643162734677478		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 0.5643162734677478 | validation: 0.5413169754859357]
	TIME [epoch: 8.29 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102269378331472		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 0.6102269378331472 | validation: 0.7017693280287335]
	TIME [epoch: 8.24 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907249548368289		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 0.5907249548368289 | validation: 0.7321494063930326]
	TIME [epoch: 8.23 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556679155757743		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 0.6556679155757743 | validation: 0.8473502204187985]
	TIME [epoch: 8.23 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252125789176844		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 0.7252125789176844 | validation: 0.6344721047231656]
	TIME [epoch: 8.23 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326670468715111		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 0.5326670468715111 | validation: 0.45672941458669153]
	TIME [epoch: 8.26 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487194191249508		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 0.6487194191249508 | validation: 0.5301919985666771]
	TIME [epoch: 8.27 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908687336811531		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 0.5908687336811531 | validation: 0.5594166436000669]
	TIME [epoch: 8.23 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326331104585555		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 0.5326331104585555 | validation: 0.521406278897524]
	TIME [epoch: 8.24 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5872706434735666		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 0.5872706434735666 | validation: 0.6878569987522761]
	TIME [epoch: 8.25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593318857969869		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 0.5593318857969869 | validation: 0.5471713756972572]
	TIME [epoch: 8.24 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684774603259398		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 0.5684774603259398 | validation: 0.5346950079754366]
	TIME [epoch: 8.29 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941208282251873		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 0.5941208282251873 | validation: 0.36859597093945334]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180325941733456		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 0.6180325941733456 | validation: 0.4797683481865306]
	TIME [epoch: 8.25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9605277238495111		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 0.9605277238495111 | validation: 0.8028007282400997]
	TIME [epoch: 8.24 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992009379051894		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 0.5992009379051894 | validation: 0.42261509954309195]
	TIME [epoch: 8.24 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4875974826430888		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 0.4875974826430888 | validation: 0.474481368052068]
	TIME [epoch: 8.24 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099161286602749		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 0.5099161286602749 | validation: 0.5502977938875947]
	TIME [epoch: 8.28 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068617512018965		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 0.5068617512018965 | validation: 0.4024597533123223]
	TIME [epoch: 8.24 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046992176668457		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 0.5046992176668457 | validation: 0.5057552157822404]
	TIME [epoch: 8.23 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141129131977266		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 0.5141129131977266 | validation: 0.3601443238412617]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023859072744804		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 0.6023859072744804 | validation: 0.2911044311229396]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531008906763554		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 0.4531008906763554 | validation: 0.2748399093496094]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727325722896375		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 0.4727325722896375 | validation: 0.28694366882669176]
	TIME [epoch: 8.25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832963303284827		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 0.5832963303284827 | validation: 0.4344696430531818]
	TIME [epoch: 8.24 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395089896253193		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 0.5395089896253193 | validation: 0.3988954813142173]
	TIME [epoch: 8.25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5672864855654236		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 0.5672864855654236 | validation: 0.40093981429190506]
	TIME [epoch: 8.25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452716498640536		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 0.452716498640536 | validation: 0.38602054876345937]
	TIME [epoch: 8.27 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41280607457674656		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 0.41280607457674656 | validation: 0.3191567401111596]
	TIME [epoch: 8.28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46881199453009104		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 0.46881199453009104 | validation: 0.5751480245236965]
	TIME [epoch: 8.26 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269560872965882		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 0.6269560872965882 | validation: 0.2938213598207042]
	TIME [epoch: 8.27 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47109313346746545		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 0.47109313346746545 | validation: 0.29271997607346]
	TIME [epoch: 8.25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535188652063338		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 0.4535188652063338 | validation: 0.4343201715454746]
	TIME [epoch: 8.25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163072253321838		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 0.5163072253321838 | validation: 0.33833891648225345]
	TIME [epoch: 8.28 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211429864169126		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 0.6211429864169126 | validation: 0.29268158277351697]
	TIME [epoch: 8.25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1471835176118352		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 1.1471835176118352 | validation: 0.6072833506658739]
	TIME [epoch: 8.25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6649553576017306		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 0.6649553576017306 | validation: 0.30619153853993875]
	TIME [epoch: 8.24 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4930633342160704		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 0.4930633342160704 | validation: 3.4222163287129685]
	TIME [epoch: 8.24 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8231582312191454		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 3.8231582312191454 | validation: 1.6220949740584931]
	TIME [epoch: 8.24 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.309772601605769		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 1.309772601605769 | validation: 2.0054571306601274]
	TIME [epoch: 8.29 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0136321184385404		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 1.0136321184385404 | validation: 0.5058750769324105]
	TIME [epoch: 8.24 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4334729480811415		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 0.4334729480811415 | validation: 0.40852919288119866]
	TIME [epoch: 8.23 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39178481428419476		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 0.39178481428419476 | validation: 0.3554729181167686]
	TIME [epoch: 8.25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311331358090597		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 0.3311331358090597 | validation: 0.29309392796681333]
	TIME [epoch: 8.24 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31947475620413035		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 0.31947475620413035 | validation: 0.2734225305707241]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433491646489935		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 0.3433491646489935 | validation: 0.28040641039764985]
	TIME [epoch: 8.25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36816215027858185		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 0.36816215027858185 | validation: 0.21596239284047125]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29331026673985233		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 0.29331026673985233 | validation: 0.3131110107850982]
	TIME [epoch: 8.26 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425468144070542		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 0.3425468144070542 | validation: 0.38235271223628897]
	TIME [epoch: 8.24 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34763204273818404		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 0.34763204273818404 | validation: 0.30674752078275225]
	TIME [epoch: 8.25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696326838707101		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 0.3696326838707101 | validation: 0.5336291606278919]
	TIME [epoch: 8.27 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992600469466688		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 0.4992600469466688 | validation: 0.35512656013045896]
	TIME [epoch: 8.23 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41862365304597043		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 0.41862365304597043 | validation: 0.2870326275731684]
	TIME [epoch: 8.24 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694456109621938		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 0.3694456109621938 | validation: 0.26415978668277323]
	TIME [epoch: 8.23 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232306403628432		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 0.3232306403628432 | validation: 0.31483934646737965]
	TIME [epoch: 8.23 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387099088771218		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 0.4387099088771218 | validation: 0.31081073672609416]
	TIME [epoch: 8.27 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916372588507083		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 0.3916372588507083 | validation: 0.6611334725690804]
	TIME [epoch: 8.25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.129513977292885		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 1.129513977292885 | validation: 1.252824796252833]
	TIME [epoch: 8.23 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729690652832923		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 0.6729690652832923 | validation: 0.27941894411330537]
	TIME [epoch: 8.23 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39401668447471716		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 0.39401668447471716 | validation: 0.3925765296727046]
	TIME [epoch: 8.24 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532055724533378		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 0.4532055724533378 | validation: 0.22982958294844513]
	TIME [epoch: 8.23 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37387097484774023		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 0.37387097484774023 | validation: 0.32855006516670515]
	TIME [epoch: 8.29 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914449572165712		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 0.3914449572165712 | validation: 0.3479379005308313]
	TIME [epoch: 8.24 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37652046250745363		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 0.37652046250745363 | validation: 0.30785926140328934]
	TIME [epoch: 8.24 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498855935855017		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 0.3498855935855017 | validation: 0.3825900291348369]
	TIME [epoch: 8.25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4892572323160459		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 0.4892572323160459 | validation: 0.37114167535028514]
	TIME [epoch: 8.24 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4052714136191485		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.4052714136191485 | validation: 0.28730950111928066]
	TIME [epoch: 8.26 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724114721065537		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.3724114721065537 | validation: 0.23970824943092822]
	TIME [epoch: 8.26 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3747764446773034		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.3747764446773034 | validation: 0.2346368382220857]
	TIME [epoch: 8.24 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43290006270633286		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.43290006270633286 | validation: 0.321958088284234]
	TIME [epoch: 8.24 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35990989776553295		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.35990989776553295 | validation: 0.4768779141276345]
	TIME [epoch: 8.23 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513465878527581		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.3513465878527581 | validation: 0.39959534936924]
	TIME [epoch: 8.23 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493971906018785		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.493971906018785 | validation: 0.41156298597054003]
	TIME [epoch: 8.27 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914446541373513		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.3914446541373513 | validation: 0.28682549119214124]
	TIME [epoch: 8.26 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406267615329928		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.3406267615329928 | validation: 0.29036710251537645]
	TIME [epoch: 8.24 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981292946701653		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 0.3981292946701653 | validation: 0.24865183287901205]
	TIME [epoch: 8.24 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330453460336379		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.3330453460336379 | validation: 0.4730443158945281]
	TIME [epoch: 8.24 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37540200756957487		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.37540200756957487 | validation: 0.36471905610266875]
	TIME [epoch: 8.24 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29525522359265644		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.29525522359265644 | validation: 0.3709828910243719]
	TIME [epoch: 8.28 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42100124978695075		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.42100124978695075 | validation: 0.5241302924870462]
	TIME [epoch: 8.24 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32820903500726356		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.32820903500726356 | validation: 0.49977527035176006]
	TIME [epoch: 8.24 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128253600667756		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.3128253600667756 | validation: 0.5424844083294461]
	TIME [epoch: 8.25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168721746237694		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.5168721746237694 | validation: 0.5509856221787147]
	TIME [epoch: 8.25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122059756306527		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.4122059756306527 | validation: 0.3692459324277029]
	TIME [epoch: 8.29 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30681050716620256		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.30681050716620256 | validation: 0.24231217935108768]
	TIME [epoch: 8.24 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762571075415371		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.2762571075415371 | validation: 0.3200050043438571]
	TIME [epoch: 8.23 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723470579446606		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.3723470579446606 | validation: 0.2975918711737786]
	TIME [epoch: 8.24 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259640390866863		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.3259640390866863 | validation: 0.28813087327152065]
	TIME [epoch: 8.23 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230264346213673		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.3230264346213673 | validation: 0.27346174722408906]
	TIME [epoch: 8.23 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632022852950989		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.2632022852950989 | validation: 0.40756875255302094]
	TIME [epoch: 8.28 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40082329973679937		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.40082329973679937 | validation: 0.20317837079520806]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891237064409656		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.2891237064409656 | validation: 0.2777560885147373]
	TIME [epoch: 8.25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35221691658775445		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.35221691658775445 | validation: 0.2958719323526379]
	TIME [epoch: 8.24 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27654878479084144		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.27654878479084144 | validation: 0.38232308162077083]
	TIME [epoch: 8.24 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152175841475423		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.3152175841475423 | validation: 0.2330276046521777]
	TIME [epoch: 8.25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29849684664020776		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.29849684664020776 | validation: 0.3758132826886128]
	TIME [epoch: 8.26 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489121281990989		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.3489121281990989 | validation: 0.31924395718665033]
	TIME [epoch: 8.23 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3205973601013601		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.3205973601013601 | validation: 0.3155895417570227]
	TIME [epoch: 8.23 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27748511527321695		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.27748511527321695 | validation: 0.26529867715177213]
	TIME [epoch: 8.26 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35164408723609286		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 0.35164408723609286 | validation: 0.40658126928979377]
	TIME [epoch: 8.25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29899598222543405		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.29899598222543405 | validation: 0.25964663966896573]
	TIME [epoch: 16.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622569706501144		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.2622569706501144 | validation: 0.21648992655677207]
	TIME [epoch: 8.26 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29654898028255156		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.29654898028255156 | validation: 0.29769729152673774]
	TIME [epoch: 8.24 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39201612739843844		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.39201612739843844 | validation: 0.3473896151856972]
	TIME [epoch: 8.24 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062690074704059		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.5062690074704059 | validation: 0.4028778033176796]
	TIME [epoch: 8.24 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30580746538703946		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.30580746538703946 | validation: 0.17016058886997604]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28354051635267674		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 0.28354051635267674 | validation: 0.2405833895352576]
	TIME [epoch: 8.27 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537952578806117		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 0.2537952578806117 | validation: 0.3565208246639042]
	TIME [epoch: 8.24 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716126613527906		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 0.2716126613527906 | validation: 0.23334689443787948]
	TIME [epoch: 8.24 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25657972412806695		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 0.25657972412806695 | validation: 0.2518061186289034]
	TIME [epoch: 8.23 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25982267781934265		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 0.25982267781934265 | validation: 0.23331452435014371]
	TIME [epoch: 8.23 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25201894721912343		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 0.25201894721912343 | validation: 0.2743874117368658]
	TIME [epoch: 8.27 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220354627764687		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 0.3220354627764687 | validation: 0.22695534763536757]
	TIME [epoch: 8.24 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734432558455658		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 0.2734432558455658 | validation: 0.21428232133549596]
	TIME [epoch: 8.23 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33103989659689975		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.33103989659689975 | validation: 0.1849834383015943]
	TIME [epoch: 8.24 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23563237029004003		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.23563237029004003 | validation: 0.2808863680826167]
	TIME [epoch: 8.24 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32027825008903027		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.32027825008903027 | validation: 0.22262129468326058]
	TIME [epoch: 8.25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584690212898484		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.2584690212898484 | validation: 0.21467003230327303]
	TIME [epoch: 8.29 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26120916173934017		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.26120916173934017 | validation: 0.3569040902665877]
	TIME [epoch: 8.25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32042679931260565		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.32042679931260565 | validation: 0.27484661842846153]
	TIME [epoch: 8.24 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578923188159442		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.2578923188159442 | validation: 0.25538453861013255]
	TIME [epoch: 8.23 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24999584947751735		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.24999584947751735 | validation: 0.38804252865470734]
	TIME [epoch: 8.23 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28838817787617854		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.28838817787617854 | validation: 0.2810689995385047]
	TIME [epoch: 8.26 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381230910690378		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.2381230910690378 | validation: 0.2629674991217438]
	TIME [epoch: 8.26 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626589472728454		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.2626589472728454 | validation: 0.2884271606690123]
	TIME [epoch: 8.25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728566521082616		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.2728566521082616 | validation: 0.206663854745874]
	TIME [epoch: 8.24 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610087209469021		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.2610087209469021 | validation: 0.26623339267403245]
	TIME [epoch: 8.23 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34726638658084685		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.34726638658084685 | validation: 0.15944253112617282]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18663521543951075		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.18663521543951075 | validation: 0.23095523234913867]
	TIME [epoch: 8.29 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29309838459098525		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.29309838459098525 | validation: 0.21767333236167982]
	TIME [epoch: 8.25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23308574613133043		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.23308574613133043 | validation: 0.2223739734707724]
	TIME [epoch: 8.26 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2928263675951084		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.2928263675951084 | validation: 0.29387994086687064]
	TIME [epoch: 8.25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674901942002774		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.2674901942002774 | validation: 0.3928864381523333]
	TIME [epoch: 8.25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117533411114974		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.3117533411114974 | validation: 0.19222313026338383]
	TIME [epoch: 8.27 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002004276344042		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.2002004276344042 | validation: 0.3175739890999111]
	TIME [epoch: 8.29 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31857747195411545		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.31857747195411545 | validation: 0.23130187673528124]
	TIME [epoch: 8.24 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25411495432238596		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.25411495432238596 | validation: 0.23235747606655632]
	TIME [epoch: 8.27 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22241434441336003		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.22241434441336003 | validation: 0.18492663450635027]
	TIME [epoch: 8.24 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537889091047574		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.2537889091047574 | validation: 0.1763510361729166]
	TIME [epoch: 8.24 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705591385875702		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.2705591385875702 | validation: 0.21803623545024492]
	TIME [epoch: 8.28 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22905998827086285		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.22905998827086285 | validation: 0.25578970048339844]
	TIME [epoch: 8.25 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447737479060706		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.22447737479060706 | validation: 0.3040715999632197]
	TIME [epoch: 8.25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23910146001486196		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.23910146001486196 | validation: 0.27742252124337174]
	TIME [epoch: 8.24 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36696876782184856		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.36696876782184856 | validation: 0.2331798316139112]
	TIME [epoch: 8.24 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22417791758163677		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.22417791758163677 | validation: 0.19719515621217787]
	TIME [epoch: 8.25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23088495047694274		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.23088495047694274 | validation: 0.19439783260162402]
	TIME [epoch: 8.29 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055171835766988		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.20055171835766988 | validation: 0.36043665277097203]
	TIME [epoch: 8.24 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27818490935429796		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.27818490935429796 | validation: 0.31054780104627083]
	TIME [epoch: 8.24 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28129876611179727		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.28129876611179727 | validation: 0.20024117417680865]
	TIME [epoch: 8.27 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248251922334581		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.2248251922334581 | validation: 0.30869917729504226]
	TIME [epoch: 8.26 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29174920997994		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.29174920997994 | validation: 0.5562418324561521]
	TIME [epoch: 8.28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412456457414226		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.3412456457414226 | validation: 0.19820192245317536]
	TIME [epoch: 8.28 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17275248756510433		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.17275248756510433 | validation: 0.2851318348795154]
	TIME [epoch: 8.24 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409372552252347		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 0.2409372552252347 | validation: 0.24302942047044274]
	TIME [epoch: 8.25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23398590553182466		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.23398590553182466 | validation: 0.15266836645490475]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882387827682679		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.2882387827682679 | validation: 0.22418848854283252]
	TIME [epoch: 8.24 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25770058888774006		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.25770058888774006 | validation: 0.3499729341474565]
	TIME [epoch: 8.27 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585449275978321		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.2585449275978321 | validation: 0.2161865927956003]
	TIME [epoch: 8.24 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19548517537563279		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.19548517537563279 | validation: 0.23240492313770633]
	TIME [epoch: 8.23 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27656271395876564		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.27656271395876564 | validation: 0.2314433980990171]
	TIME [epoch: 8.23 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929796721503902		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.1929796721503902 | validation: 0.24206557953305696]
	TIME [epoch: 8.23 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2289759798912852		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.2289759798912852 | validation: 0.2701762529911865]
	TIME [epoch: 8.28 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460253645097039		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.3460253645097039 | validation: 0.2100974359397081]
	TIME [epoch: 8.25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17388312474532008		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.17388312474532008 | validation: 0.16676537764495342]
	TIME [epoch: 8.23 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22418308803507336		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.22418308803507336 | validation: 0.19127534644357447]
	TIME [epoch: 8.24 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4819573812640804		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.4819573812640804 | validation: 0.21162219987114314]
	TIME [epoch: 8.26 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038540951947898		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.2038540951947898 | validation: 0.19295990756212292]
	TIME [epoch: 8.24 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002253584898736		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.2002253584898736 | validation: 0.2164695274167534]
	TIME [epoch: 8.29 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19981269314159672		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.19981269314159672 | validation: 0.2192787145678186]
	TIME [epoch: 8.25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234955825839014		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.2234955825839014 | validation: 0.26231407009987745]
	TIME [epoch: 8.24 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23664893554505842		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.23664893554505842 | validation: 0.16975050531127311]
	TIME [epoch: 8.24 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20387047895672833		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.20387047895672833 | validation: 0.1650006440753779]
	TIME [epoch: 8.24 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2016367347589194		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.2016367347589194 | validation: 0.1947247119299772]
	TIME [epoch: 8.26 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22653783108678613		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.22653783108678613 | validation: 0.202174621710644]
	TIME [epoch: 8.27 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23084388272731488		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.23084388272731488 | validation: 0.2018609224188278]
	TIME [epoch: 8.24 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3636946354063786		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.3636946354063786 | validation: 0.2679704975984504]
	TIME [epoch: 8.23 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916816807287097		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.2916816807287097 | validation: 0.2729295075460457]
	TIME [epoch: 8.24 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20958825673481868		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.20958825673481868 | validation: 0.17762924991788936]
	TIME [epoch: 8.24 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911555731028129		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.1911555731028129 | validation: 0.23398647147957402]
	TIME [epoch: 8.29 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355085309724668		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.2355085309724668 | validation: 0.23512598977644544]
	TIME [epoch: 8.25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033624276776752		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.2033624276776752 | validation: 0.26601565504101904]
	TIME [epoch: 8.23 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18937803154718702		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.18937803154718702 | validation: 0.2702964888717143]
	TIME [epoch: 8.25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29710712990505306		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.29710712990505306 | validation: 0.26728862497239564]
	TIME [epoch: 8.26 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21171075612076684		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.21171075612076684 | validation: 0.2137220862244442]
	TIME [epoch: 8.24 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20663094848738292		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.20663094848738292 | validation: 0.20544599508489844]
	TIME [epoch: 8.29 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19117301274982515		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.19117301274982515 | validation: 0.47684431790454074]
	TIME [epoch: 8.34 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744701887268638		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.3744701887268638 | validation: 0.15783704200574064]
	TIME [epoch: 8.24 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17589884259895852		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 0.17589884259895852 | validation: 0.16932707847685638]
	TIME [epoch: 8.24 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177383009995632		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.177383009995632 | validation: 0.26255964721952735]
	TIME [epoch: 8.23 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868396117188386		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.1868396117188386 | validation: 0.21305258534781552]
	TIME [epoch: 8.27 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23174057578999616		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.23174057578999616 | validation: 0.3560288268049705]
	TIME [epoch: 8.26 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24485575242489432		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 0.24485575242489432 | validation: 0.10207639276173984]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19277880488629748		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.19277880488629748 | validation: 0.16650487624284033]
	TIME [epoch: 8.23 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962063561107801		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.1962063561107801 | validation: 0.15952776023251652]
	TIME [epoch: 8.23 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040192618510832		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.2040192618510832 | validation: 0.2251091215460798]
	TIME [epoch: 8.23 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079288898188244		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.2079288898188244 | validation: 0.2777964290367303]
	TIME [epoch: 8.28 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613906725954247		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.2613906725954247 | validation: 0.32009593197592784]
	TIME [epoch: 8.23 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25126499664039187		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.25126499664039187 | validation: 0.2748979468964526]
	TIME [epoch: 8.24 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20551271278103894		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 0.20551271278103894 | validation: 0.1709919498878274]
	TIME [epoch: 8.23 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304039009335026		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.2304039009335026 | validation: 0.1606725872070071]
	TIME [epoch: 8.25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20564878786875557		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.20564878786875557 | validation: 0.1926310086286493]
	TIME [epoch: 8.27 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22266890453067578		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 0.22266890453067578 | validation: 0.19048269557242836]
	TIME [epoch: 8.27 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19695008430977712		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.19695008430977712 | validation: 0.19851303158861477]
	TIME [epoch: 8.24 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853445996636589		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.1853445996636589 | validation: 0.223137999990218]
	TIME [epoch: 8.23 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230250160368334		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.2230250160368334 | validation: 0.27459499778543506]
	TIME [epoch: 8.24 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23754819973633792		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.23754819973633792 | validation: 0.1492377377575725]
	TIME [epoch: 8.23 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17587399272786403		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.17587399272786403 | validation: 0.232082227341903]
	TIME [epoch: 8.28 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2158138328851973		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.2158138328851973 | validation: 0.1795414758576913]
	TIME [epoch: 8.24 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1945351734771885		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.1945351734771885 | validation: 0.36193681888824797]
	TIME [epoch: 8.24 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27810162317606857		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.27810162317606857 | validation: 0.1841163240552852]
	TIME [epoch: 8.23 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2189928007795882		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.2189928007795882 | validation: 0.1909390561816748]
	TIME [epoch: 8.23 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17586925410293866		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.17586925410293866 | validation: 0.20271312611083334]
	TIME [epoch: 8.24 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17521416779016807		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.17521416779016807 | validation: 0.15113655902322087]
	TIME [epoch: 8.28 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17380407419026056		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.17380407419026056 | validation: 0.18682781725621433]
	TIME [epoch: 8.23 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19037679075081532		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.19037679075081532 | validation: 0.2930187200529908]
	TIME [epoch: 8.23 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579052629787351		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.2579052629787351 | validation: 0.16034191772019973]
	TIME [epoch: 8.24 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848304907185052		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.1848304907185052 | validation: 0.30645164423556254]
	TIME [epoch: 8.24 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18606589584657524		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.18606589584657524 | validation: 0.18036096079330283]
	TIME [epoch: 8.28 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17090225311477025		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.17090225311477025 | validation: 0.2106177786074031]
	TIME [epoch: 8.25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17698588731787598		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.17698588731787598 | validation: 0.30077541096609745]
	TIME [epoch: 8.24 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374754491092733		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.3374754491092733 | validation: 0.1903688126152612]
	TIME [epoch: 8.23 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448048408227922		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.1448048408227922 | validation: 0.1646494900408035]
	TIME [epoch: 8.23 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953221756633566		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.1953221756633566 | validation: 0.1770417217878325]
	TIME [epoch: 8.24 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20077813632516572		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.20077813632516572 | validation: 0.14969997299886942]
	TIME [epoch: 8.27 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871745482020335		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.17871745482020335 | validation: 0.2308857596187836]
	TIME [epoch: 8.23 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17801396423199994		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.17801396423199994 | validation: 0.22676001888557434]
	TIME [epoch: 8.24 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19050216015370466		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.19050216015370466 | validation: 0.21230223472942403]
	TIME [epoch: 8.23 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17171733926138671		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.17171733926138671 | validation: 0.24301797469467334]
	TIME [epoch: 8.23 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27766199915135664		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.27766199915135664 | validation: 0.23597423629028516]
	TIME [epoch: 8.26 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18876394422798143		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.18876394422798143 | validation: 0.1727592133195392]
	TIME [epoch: 8.27 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15653874742729793		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.15653874742729793 | validation: 0.37601181800533046]
	TIME [epoch: 8.24 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525781563640387		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.2525781563640387 | validation: 0.13004885368579427]
	TIME [epoch: 8.23 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16594998810097245		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.16594998810097245 | validation: 0.17486653979962719]
	TIME [epoch: 8.24 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111134837592558		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.19111134837592558 | validation: 0.1711741867569413]
	TIME [epoch: 8.25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616278247966174		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.1616278247966174 | validation: 0.15558835023656614]
	TIME [epoch: 8.29 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27073072850761215		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.27073072850761215 | validation: 0.3034342344013705]
	TIME [epoch: 8.24 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20621212320259785		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.20621212320259785 | validation: 0.23310031351673005]
	TIME [epoch: 8.24 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19939652306877653		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.19939652306877653 | validation: 0.1586039825557733]
	TIME [epoch: 8.25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777083523160339		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.1777083523160339 | validation: 0.19595436384737505]
	TIME [epoch: 8.24 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372619459844273		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.16372619459844273 | validation: 0.136503887955644]
	TIME [epoch: 8.25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19059541606874458		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.19059541606874458 | validation: 0.15067828234669126]
	TIME [epoch: 8.27 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17426604286983724		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.17426604286983724 | validation: 0.20740441686373984]
	TIME [epoch: 8.23 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19819076756534432		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.19819076756534432 | validation: 0.1675720141543226]
	TIME [epoch: 8.24 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20652105033782991		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.20652105033782991 | validation: 0.14164714095967362]
	TIME [epoch: 8.24 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530262083960957		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.1530262083960957 | validation: 0.18612373678348543]
	TIME [epoch: 8.24 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16998886388722687		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.16998886388722687 | validation: 0.1598440335263891]
	TIME [epoch: 8.27 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1971434618298497		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.1971434618298497 | validation: 0.17422029128886193]
	TIME [epoch: 8.26 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18604597370370551		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.18604597370370551 | validation: 0.16241146802575518]
	TIME [epoch: 8.24 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16600452278479128		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.16600452278479128 | validation: 0.22672494951308808]
	TIME [epoch: 8.23 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18241144373204668		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.18241144373204668 | validation: 0.11092302397546902]
	TIME [epoch: 8.25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16498122667075704		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.16498122667075704 | validation: 0.14960199827111215]
	TIME [epoch: 8.24 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22783589776174204		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.22783589776174204 | validation: 0.13041437236958495]
	TIME [epoch: 8.29 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18663034203976478		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.18663034203976478 | validation: 0.09924745964342535]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458181620474193		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.1458181620474193 | validation: 0.18991742343708462]
	TIME [epoch: 8.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18818499394230226		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.18818499394230226 | validation: 0.09309941880696745]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405942142103015		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.1405942142103015 | validation: 0.11683397250541905]
	TIME [epoch: 8.24 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18689246654843167		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.18689246654843167 | validation: 0.22262981782830665]
	TIME [epoch: 8.27 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27069342727632817		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.27069342727632817 | validation: 0.1856096778913857]
	TIME [epoch: 8.24 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16725030208727826		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.16725030208727826 | validation: 0.2126425370319645]
	TIME [epoch: 8.23 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16901081404410898		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.16901081404410898 | validation: 0.12246093997211047]
	TIME [epoch: 8.23 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680642333064947		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.1680642333064947 | validation: 0.15248329536985716]
	TIME [epoch: 8.24 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18980479938187503		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.18980479938187503 | validation: 0.158557975710395]
	TIME [epoch: 8.25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856715580448503		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.1856715580448503 | validation: 0.18650981142114748]
	TIME [epoch: 8.27 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22631931734401906		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.22631931734401906 | validation: 0.21857018215641044]
	TIME [epoch: 8.24 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904797430377933		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.17904797430377933 | validation: 0.15024862816856308]
	TIME [epoch: 8.25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15498688845312802		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.15498688845312802 | validation: 0.20819497956101357]
	TIME [epoch: 8.24 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17117408119500546		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.17117408119500546 | validation: 0.1773808777397661]
	TIME [epoch: 8.25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495818278280474		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.1495818278280474 | validation: 0.16577263533357606]
	TIME [epoch: 8.27 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662920779529464		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.1662920779529464 | validation: 0.1361979965879765]
	TIME [epoch: 8.28 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374654010446693		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.16374654010446693 | validation: 0.19255680578645573]
	TIME [epoch: 8.23 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681654522108577		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.1681654522108577 | validation: 0.24373399898210152]
	TIME [epoch: 8.25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764279763707043		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.1764279763707043 | validation: 0.16702158832747907]
	TIME [epoch: 8.24 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659400283922099		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.1659400283922099 | validation: 0.12246963563252061]
	TIME [epoch: 8.23 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18772609921519084		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.18772609921519084 | validation: 0.16731062600269966]
	TIME [epoch: 8.28 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20481924380664857		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.20481924380664857 | validation: 0.15538862292024277]
	TIME [epoch: 8.24 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632277506580547		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.1632277506580547 | validation: 0.1344737579763574]
	TIME [epoch: 8.23 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650908967706676		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.1650908967706676 | validation: 0.25159600089007944]
	TIME [epoch: 8.23 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1905625197420796		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.1905625197420796 | validation: 0.16771164828898105]
	TIME [epoch: 8.23 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18567860577239464		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.18567860577239464 | validation: 0.13276887788553887]
	TIME [epoch: 8.25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389046288334551		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.1389046288334551 | validation: 0.1933877569526837]
	TIME [epoch: 8.28 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23773332172829703		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.23773332172829703 | validation: 0.1884930690596844]
	TIME [epoch: 8.24 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15430507057347964		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.15430507057347964 | validation: 0.13409542365927718]
	TIME [epoch: 8.24 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447660241919001		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.1447660241919001 | validation: 0.22335715168461848]
	TIME [epoch: 8.25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17635183696813106		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.17635183696813106 | validation: 0.1955172677667465]
	TIME [epoch: 8.25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665329895840088		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.1665329895840088 | validation: 0.15066457175541256]
	TIME [epoch: 8.28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20691606232290016		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.20691606232290016 | validation: 0.1994124711915931]
	TIME [epoch: 8.26 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18035841028985594		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.18035841028985594 | validation: 0.15369936280580399]
	TIME [epoch: 8.23 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17809054891326398		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.17809054891326398 | validation: 0.25399004001440456]
	TIME [epoch: 8.24 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16602139742412647		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.16602139742412647 | validation: 0.10153434787625913]
	TIME [epoch: 8.24 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13214779584688113		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.13214779584688113 | validation: 0.12398402226754057]
	TIME [epoch: 8.24 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234459825914082		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.1234459825914082 | validation: 0.1605592846010308]
	TIME [epoch: 8.27 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18214476283343134		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.18214476283343134 | validation: 0.196038743442624]
	TIME [epoch: 8.24 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119409804083797		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.15119409804083797 | validation: 0.1455478087189605]
	TIME [epoch: 8.24 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465473224891685		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.1465473224891685 | validation: 0.11770594601523032]
	TIME [epoch: 8.23 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27102637588098466		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.27102637588098466 | validation: 0.15514301930204577]
	TIME [epoch: 8.24 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15417747938174606		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.15417747938174606 | validation: 0.07905927431995323]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14065378521007246		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.14065378521007246 | validation: 0.17825744756404624]
	TIME [epoch: 8.26 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18653429517730089		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.18653429517730089 | validation: 0.12883951933210505]
	TIME [epoch: 8.54 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18780387926361872		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.18780387926361872 | validation: 0.1103009298085089]
	TIME [epoch: 8.24 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13736735005053577		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.13736735005053577 | validation: 0.16722886188031666]
	TIME [epoch: 8.24 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462694835913965		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.1462694835913965 | validation: 0.15155038351006273]
	TIME [epoch: 8.28 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138823198798896		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.138823198798896 | validation: 0.16796285184879955]
	TIME [epoch: 8.32 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13488958605004267		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.13488958605004267 | validation: 0.15312083511885816]
	TIME [epoch: 8.26 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21255875535426175		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.21255875535426175 | validation: 0.1763345437534321]
	TIME [epoch: 8.26 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984843523123052		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.1984843523123052 | validation: 0.09336717169296489]
	TIME [epoch: 8.25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10284251699203137		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.10284251699203137 | validation: 0.17305607756449579]
	TIME [epoch: 8.26 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802499027288265		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.16802499027288265 | validation: 0.2059287418116056]
	TIME [epoch: 8.27 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657569641779818		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.1657569641779818 | validation: 0.18576549121931987]
	TIME [epoch: 8.27 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701921351640351		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.1701921351640351 | validation: 0.17398199112241028]
	TIME [epoch: 8.24 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18243054100671685		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.18243054100671685 | validation: 0.25037886145822075]
	TIME [epoch: 8.24 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15661946713345096		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.15661946713345096 | validation: 0.29064075070608086]
	TIME [epoch: 8.24 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011407172737394		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.2011407172737394 | validation: 0.13324845584406267]
	TIME [epoch: 8.26 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14341635931433824		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.14341635931433824 | validation: 0.13637193268793596]
	TIME [epoch: 8.29 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328680330438936		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.1328680330438936 | validation: 0.14299140646116465]
	TIME [epoch: 8.25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283779680990123		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.1283779680990123 | validation: 0.13518831662796482]
	TIME [epoch: 8.26 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16856101027218767		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.16856101027218767 | validation: 0.1173233893599262]
	TIME [epoch: 8.24 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17225452675486058		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.17225452675486058 | validation: 0.13187791306912866]
	TIME [epoch: 8.25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12997385474766446		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.12997385474766446 | validation: 0.1749334389720782]
	TIME [epoch: 8.28 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18343351515759912		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.18343351515759912 | validation: 0.20080135301865193]
	TIME [epoch: 8.29 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160914126296593		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.160914126296593 | validation: 0.11378774553125337]
	TIME [epoch: 8.27 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296081873111305		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.1296081873111305 | validation: 0.13174580330208518]
	TIME [epoch: 8.25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13016140454170316		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.13016140454170316 | validation: 0.11390490518097242]
	TIME [epoch: 8.26 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155794038962823		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 0.155794038962823 | validation: 0.23004114227214018]
	TIME [epoch: 8.26 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646840752672406		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.1646840752672406 | validation: 0.19004934611179355]
	TIME [epoch: 8.28 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16446151023511213		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.16446151023511213 | validation: 0.27336099984866813]
	TIME [epoch: 8.25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2153334361002697		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.2153334361002697 | validation: 0.14067069765009244]
	TIME [epoch: 8.24 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19457357710955955		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 0.19457357710955955 | validation: 0.08725941117651179]
	TIME [epoch: 8.24 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13949407936934377		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.13949407936934377 | validation: 0.12169828510087952]
	TIME [epoch: 8.24 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427830667277119		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.1427830667277119 | validation: 0.10590069994614588]
	TIME [epoch: 8.25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601613870579822		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.1601613870579822 | validation: 0.11132629268486832]
	TIME [epoch: 8.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365172295316107		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.1365172295316107 | validation: 0.14044579907975713]
	TIME [epoch: 8.25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16085878522346234		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 0.16085878522346234 | validation: 0.20951103913571612]
	TIME [epoch: 8.24 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16546624021556564		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.16546624021556564 | validation: 0.19398068214358166]
	TIME [epoch: 8.23 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15008973968865805		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.15008973968865805 | validation: 0.11621003441342764]
	TIME [epoch: 8.23 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16741152376769067		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.16741152376769067 | validation: 0.10469954387738153]
	TIME [epoch: 8.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262773559849286		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.13262773559849286 | validation: 0.23059470208385685]
	TIME [epoch: 8.27 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16314327458063568		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.16314327458063568 | validation: 0.1315701316826387]
	TIME [epoch: 8.24 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333751260429702		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.1333751260429702 | validation: 0.18110464525271952]
	TIME [epoch: 8.25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892821680827379		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.1892821680827379 | validation: 0.10636775108133598]
	TIME [epoch: 8.25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15029913108284074		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.15029913108284074 | validation: 0.13814288351031362]
	TIME [epoch: 8.25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14811882907828444		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.14811882907828444 | validation: 0.14891369295548482]
	TIME [epoch: 8.28 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881939982910293		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.15881939982910293 | validation: 0.13906486747336894]
	TIME [epoch: 8.23 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654084346324194		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.1654084346324194 | validation: 0.13222682986387624]
	TIME [epoch: 8.23 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14075594911201472		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.14075594911201472 | validation: 0.11725309207012519]
	TIME [epoch: 8.24 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038043310942153		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.1038043310942153 | validation: 0.13027558304636017]
	TIME [epoch: 8.23 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16386618117012947		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.16386618117012947 | validation: 0.08726672167719282]
	TIME [epoch: 8.25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328905506277323		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.17328905506277323 | validation: 0.10152989275521332]
	TIME [epoch: 8.29 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16020098892037923		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.16020098892037923 | validation: 0.15799944066112565]
	TIME [epoch: 8.24 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17489580146318812		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.17489580146318812 | validation: 0.09716970350172296]
	TIME [epoch: 8.24 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0961456647293392		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.0961456647293392 | validation: 0.126832495809867]
	TIME [epoch: 8.23 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802805587843192		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.1802805587843192 | validation: 0.1375681788993661]
	TIME [epoch: 8.24 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16571313253997766		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.16571313253997766 | validation: 0.12744292912542254]
	TIME [epoch: 8.28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394798156816128		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.1394798156816128 | validation: 0.1323938100373721]
	TIME [epoch: 8.21 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748821742641942		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.13748821742641942 | validation: 0.10234445017943447]
	TIME [epoch: 8.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15055085047711067		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.15055085047711067 | validation: 0.15797196657957557]
	TIME [epoch: 8.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326297402230957		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.1326297402230957 | validation: 0.22436558447877603]
	TIME [epoch: 8.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17061422060843484		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.17061422060843484 | validation: 0.11067225452922971]
	TIME [epoch: 8.21 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14603595778857		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.14603595778857 | validation: 0.10545207598147933]
	TIME [epoch: 8.24 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12233459298891677		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.12233459298891677 | validation: 0.15480078193642433]
	TIME [epoch: 8.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18877956328684808		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.18877956328684808 | validation: 0.15226202036202116]
	TIME [epoch: 8.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625145546137974		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.14625145546137974 | validation: 0.15657589582559378]
	TIME [epoch: 8.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14035156195865478		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.14035156195865478 | validation: 0.18350956343150646]
	TIME [epoch: 8.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753360875939782		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.13753360875939782 | validation: 0.11557347217053277]
	TIME [epoch: 8.22 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1167283141358902		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.1167283141358902 | validation: 0.12449602220167841]
	TIME [epoch: 8.22 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12949918300118032		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.12949918300118032 | validation: 0.09913424267739357]
	TIME [epoch: 8.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14747821558056262		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.14747821558056262 | validation: 0.12174721282484968]
	TIME [epoch: 8.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14046507556672033		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.14046507556672033 | validation: 0.12639874509043453]
	TIME [epoch: 8.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14265117185825815		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.14265117185825815 | validation: 0.1263448419775109]
	TIME [epoch: 8.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212066449418639		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.1212066449418639 | validation: 0.10683345988804502]
	TIME [epoch: 8.24 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10757034351411704		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.10757034351411704 | validation: 0.12321754709237245]
	TIME [epoch: 8.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13167472775995942		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.13167472775995942 | validation: 0.19666230216041142]
	TIME [epoch: 8.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17209829542295463		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.17209829542295463 | validation: 0.3798890890370896]
	TIME [epoch: 8.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19953998351975197		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.19953998351975197 | validation: 0.10948135019000654]
	TIME [epoch: 8.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12208501916738335		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.12208501916738335 | validation: 0.12269936303148937]
	TIME [epoch: 8.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930457413820803		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.12930457413820803 | validation: 0.13514663155752835]
	TIME [epoch: 8.26 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11415113644673693		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.11415113644673693 | validation: 0.2266966502510538]
	TIME [epoch: 8.26 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16783043320926136		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.16783043320926136 | validation: 0.48200351837883676]
	TIME [epoch: 8.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22188443535069624		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.22188443535069624 | validation: 0.08159045314667755]
	TIME [epoch: 8.33 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974474427577068		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.10974474427577068 | validation: 0.10723068434336]
	TIME [epoch: 8.28 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14129627512251675		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.14129627512251675 | validation: 0.12455431783518622]
	TIME [epoch: 8.29 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165532963371981		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.165532963371981 | validation: 0.10890869728890865]
	TIME [epoch: 8.25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293567004570068		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.1293567004570068 | validation: 0.1195120268316659]
	TIME [epoch: 8.24 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11264400244810216		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.11264400244810216 | validation: 0.2509306042929847]
	TIME [epoch: 8.24 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14364858715659293		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.14364858715659293 | validation: 0.12225354837461593]
	TIME [epoch: 8.24 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409505959501657		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.1409505959501657 | validation: 0.5151944159833418]
	TIME [epoch: 8.24 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38273405005291355		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.38273405005291355 | validation: 0.0934428380441036]
	TIME [epoch: 8.28 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033297645518709		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.1033297645518709 | validation: 0.11827081057395783]
	TIME [epoch: 8.23 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15663669209219577		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.15663669209219577 | validation: 0.14166649428709993]
	TIME [epoch: 8.24 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12840690443533884		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.12840690443533884 | validation: 0.11884825282373337]
	TIME [epoch: 8.23 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11860035391615717		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.11860035391615717 | validation: 0.12706771791019705]
	TIME [epoch: 8.24 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314743413208838		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.1314743413208838 | validation: 0.18121446673666866]
	TIME [epoch: 8.27 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464387128298607		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.1464387128298607 | validation: 0.07818469657023175]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09133672274874094		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.09133672274874094 | validation: 0.12300816175973078]
	TIME [epoch: 8.23 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16101777173418463		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.16101777173418463 | validation: 0.15754787813298554]
	TIME [epoch: 8.23 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15540782707422393		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.15540782707422393 | validation: 0.16643395031961833]
	TIME [epoch: 8.23 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13296915573599927		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.13296915573599927 | validation: 0.11239940176099843]
	TIME [epoch: 8.28 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143641297921722		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.143641297921722 | validation: 0.16711722324138278]
	TIME [epoch: 8.29 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16769395370809095		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.16769395370809095 | validation: 0.12892772265049268]
	TIME [epoch: 8.23 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364969790289292		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.11364969790289292 | validation: 0.13597517602621856]
	TIME [epoch: 8.23 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15337897014849525		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.15337897014849525 | validation: 0.13094844737534295]
	TIME [epoch: 8.23 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13621542363973144		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.13621542363973144 | validation: 0.10937101793811582]
	TIME [epoch: 8.24 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14696241366512766		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.14696241366512766 | validation: 0.160203459483754]
	TIME [epoch: 8.25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13667226784670217		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.13667226784670217 | validation: 0.11437481157471362]
	TIME [epoch: 8.27 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921253204483207		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.12921253204483207 | validation: 0.10483639796940088]
	TIME [epoch: 8.24 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949613800316766		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.11949613800316766 | validation: 0.12209674650879809]
	TIME [epoch: 8.23 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15313349430809803		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.15313349430809803 | validation: 0.12069361135089673]
	TIME [epoch: 8.23 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11958056810032172		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.11958056810032172 | validation: 0.11254908029009618]
	TIME [epoch: 8.23 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14108740021335509		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.14108740021335509 | validation: 0.09467262627314393]
	TIME [epoch: 8.27 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462135490895316		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.13462135490895316 | validation: 0.1444188404659038]
	TIME [epoch: 8.24 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004599246190636		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.15004599246190636 | validation: 0.11275365672339785]
	TIME [epoch: 8.23 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11856230728543923		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.11856230728543923 | validation: 0.09624805002161117]
	TIME [epoch: 8.23 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364630519739892		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.11364630519739892 | validation: 0.08001212433676029]
	TIME [epoch: 8.23 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591142785846343		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.12591142785846343 | validation: 0.1258796843549499]
	TIME [epoch: 8.26 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124466146067055		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.1124466146067055 | validation: 0.13810134018550985]
	TIME [epoch: 8.31 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11928977343367506		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.11928977343367506 | validation: 0.12270277708106839]
	TIME [epoch: 8.25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329671383704779		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.11329671383704779 | validation: 0.19495931131398755]
	TIME [epoch: 8.23 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13701808323412423		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.13701808323412423 | validation: 0.5988562896825759]
	TIME [epoch: 8.23 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21581971828402127		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.21581971828402127 | validation: 0.10853557859270298]
	TIME [epoch: 8.24 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13871983519990744		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.13871983519990744 | validation: 0.11041470238988581]
	TIME [epoch: 8.27 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11588925176852988		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.11588925176852988 | validation: 0.10415559092795493]
	TIME [epoch: 8.26 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008478737111393		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.1008478737111393 | validation: 0.16124006334934315]
	TIME [epoch: 8.23 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130620516426027		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.130620516426027 | validation: 0.09478987849684911]
	TIME [epoch: 8.23 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12365373098822471		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.12365373098822471 | validation: 0.1383789814121908]
	TIME [epoch: 8.23 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12492271408878075		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.12492271408878075 | validation: 0.14590943813741641]
	TIME [epoch: 8.23 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11579457902879137		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.11579457902879137 | validation: 0.14199295158775305]
	TIME [epoch: 8.29 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630988973305856		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.1630988973305856 | validation: 0.05716891158015155]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533621787660793		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.08533621787660793 | validation: 0.1353300233852449]
	TIME [epoch: 8.23 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12222275872519164		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.12222275872519164 | validation: 0.09234789494641067]
	TIME [epoch: 8.23 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944656948077622		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.1944656948077622 | validation: 0.1038893089809989]
	TIME [epoch: 8.23 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1202372934007442		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.1202372934007442 | validation: 0.08364235263682855]
	TIME [epoch: 8.27 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947932220152075		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.0947932220152075 | validation: 0.11421576079082756]
	TIME [epoch: 8.29 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514727448222796		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.13514727448222796 | validation: 0.10467911840467271]
	TIME [epoch: 8.23 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11559644487918086		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.11559644487918086 | validation: 0.08904771868481384]
	TIME [epoch: 8.23 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10470835922031721		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.10470835922031721 | validation: 0.09546000100437632]
	TIME [epoch: 8.22 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13548840765472817		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.13548840765472817 | validation: 0.1960684438699734]
	TIME [epoch: 8.23 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12519960586301648		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.12519960586301648 | validation: 0.11408441421553026]
	TIME [epoch: 8.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10022301786443026		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.10022301786443026 | validation: 0.1288781417838025]
	TIME [epoch: 8.24 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13740197569236684		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.13740197569236684 | validation: 0.09843923022586007]
	TIME [epoch: 8.23 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866173920991899		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.0866173920991899 | validation: 0.11138549665887088]
	TIME [epoch: 8.23 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13662942455780336		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.13662942455780336 | validation: 0.23480770909504892]
	TIME [epoch: 8.23 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13311963840232582		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.13311963840232582 | validation: 0.1479065210566433]
	TIME [epoch: 8.25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12964116162259728		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.12964116162259728 | validation: 0.15154658138061877]
	TIME [epoch: 8.26 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12991463190626237		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.12991463190626237 | validation: 0.09255625188061875]
	TIME [epoch: 8.23 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894456076913446		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.10894456076913446 | validation: 0.13165910088308866]
	TIME [epoch: 8.23 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127621027403343		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.127621027403343 | validation: 0.08766248566221495]
	TIME [epoch: 8.23 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401308744923839		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.12401308744923839 | validation: 0.186967497050265]
	TIME [epoch: 8.24 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256463189153894		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.1256463189153894 | validation: 0.10822230663211492]
	TIME [epoch: 8.29 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11008067658103918		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.11008067658103918 | validation: 0.1218075069144207]
	TIME [epoch: 8.25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669920232068937		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.10669920232068937 | validation: 0.09309464054522693]
	TIME [epoch: 8.24 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995032425423667		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.11995032425423667 | validation: 0.12386432900069684]
	TIME [epoch: 8.23 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10476014170777939		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.10476014170777939 | validation: 0.12547974188582828]
	TIME [epoch: 8.23 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699850890591472		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.10699850890591472 | validation: 0.08146669568698922]
	TIME [epoch: 8.24 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829826625940141		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.1829826625940141 | validation: 0.17374605468700402]
	TIME [epoch: 8.27 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14643301610797516		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.14643301610797516 | validation: 0.09156379189656948]
	TIME [epoch: 8.23 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761753549644117		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.09761753549644117 | validation: 0.09453228869192958]
	TIME [epoch: 8.23 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11410342897811125		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.11410342897811125 | validation: 0.12747840652334175]
	TIME [epoch: 8.24 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11384706836976156		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.11384706836976156 | validation: 0.047483819694784435]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06962296593291215		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.06962296593291215 | validation: 0.16926918789568873]
	TIME [epoch: 8.27 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447990073613545		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.1447990073613545 | validation: 0.11606913166138703]
	TIME [epoch: 8.24 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12627116539918426		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.12627116539918426 | validation: 0.11490738629038945]
	TIME [epoch: 8.23 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949131600924554		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.0949131600924554 | validation: 0.10974580666755104]
	TIME [epoch: 8.23 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381866285079735		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.12381866285079735 | validation: 0.17862869818517657]
	TIME [epoch: 8.23 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474370580280596		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.3474370580280596 | validation: 0.09960377052424932]
	TIME [epoch: 8.25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09388139626781655		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.09388139626781655 | validation: 0.11629922361095116]
	TIME [epoch: 8.28 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11120092548821311		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.11120092548821311 | validation: 0.12301364658261701]
	TIME [epoch: 8.26 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13763820075544056		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.13763820075544056 | validation: 0.10934974946486378]
	TIME [epoch: 8.24 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279206450566838		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.10279206450566838 | validation: 0.12727167615982768]
	TIME [epoch: 8.23 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11408550590089901		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.11408550590089901 | validation: 0.10887006611815772]
	TIME [epoch: 8.23 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419252216372331		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.09419252216372331 | validation: 0.10783243417809976]
	TIME [epoch: 8.26 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421778920477848		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.13421778920477848 | validation: 0.15827155611027233]
	TIME [epoch: 8.26 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2331537522157999		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.2331537522157999 | validation: 0.08990626564223772]
	TIME [epoch: 8.23 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393251282456654		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.10393251282456654 | validation: 0.12502485876658703]
	TIME [epoch: 8.23 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12371852588454639		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.12371852588454639 | validation: 0.12123421702159969]
	TIME [epoch: 8.24 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765013792766332		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.08765013792766332 | validation: 0.07177242171512387]
	TIME [epoch: 8.23 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354094236499065		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.1354094236499065 | validation: 0.11068748355068098]
	TIME [epoch: 8.28 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11398524340600923		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.11398524340600923 | validation: 0.07518731311950456]
	TIME [epoch: 8.24 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991937210813515		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.09991937210813515 | validation: 0.13149308942246543]
	TIME [epoch: 8.23 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754204678560094		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.12754204678560094 | validation: 0.12143417208022775]
	TIME [epoch: 8.23 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10579453870701744		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.10579453870701744 | validation: 0.1130834329293314]
	TIME [epoch: 8.23 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362230140561733		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.1362230140561733 | validation: 0.17725636425130048]
	TIME [epoch: 8.25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11310100035218525		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.11310100035218525 | validation: 0.12098900297316117]
	TIME [epoch: 8.28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107551624059579		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.107551624059579 | validation: 0.0958782942635436]
	TIME [epoch: 8.25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09831737914036273		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.09831737914036273 | validation: 0.10122139215271873]
	TIME [epoch: 8.24 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13383128716197631		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.13383128716197631 | validation: 0.05790615870953028]
	TIME [epoch: 8.23 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720347986875161		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.08720347986875161 | validation: 0.13579902154426587]
	TIME [epoch: 8.23 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499816573548243		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.10499816573548243 | validation: 0.10339672500457339]
	TIME [epoch: 8.27 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13513794723338748		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.13513794723338748 | validation: 0.09810115691711813]
	TIME [epoch: 8.24 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175452328138491		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.11175452328138491 | validation: 0.14970699644958274]
	TIME [epoch: 8.23 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13323201462542056		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.13323201462542056 | validation: 0.125331804103477]
	TIME [epoch: 8.23 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522159335172468		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.10522159335172468 | validation: 0.08951039136053343]
	TIME [epoch: 8.23 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960241295921784		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.0960241295921784 | validation: 0.0704575224173439]
	TIME [epoch: 8.23 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09735509935654466		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.09735509935654466 | validation: 0.1209160174412692]
	TIME [epoch: 8.27 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471215048187569		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.1471215048187569 | validation: 0.06158590889416088]
	TIME [epoch: 8.23 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039171313670727		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.09039171313670727 | validation: 0.11274755538095546]
	TIME [epoch: 8.23 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11265158178829565		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.11265158178829565 | validation: 0.20923439843619313]
	TIME [epoch: 8.23 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071456225365361		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.12071456225365361 | validation: 0.11693876339926836]
	TIME [epoch: 8.23 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454450035064265		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.10454450035064265 | validation: 0.09366840152418335]
	TIME [epoch: 8.27 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728700537067445		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.10728700537067445 | validation: 0.11868178046823458]
	TIME [epoch: 8.27 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386364428189263		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.1386364428189263 | validation: 0.10101034457091417]
	TIME [epoch: 8.25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433389911844187		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.09433389911844187 | validation: 0.12126596378265295]
	TIME [epoch: 8.23 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10922558172232977		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.10922558172232977 | validation: 0.10053002372143116]
	TIME [epoch: 8.23 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09784651296914094		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.09784651296914094 | validation: 0.09480792279654429]
	TIME [epoch: 8.23 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09618050814570274		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.09618050814570274 | validation: 0.14622650547949742]
	TIME [epoch: 8.26 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14175130440970507		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.14175130440970507 | validation: 0.16340805979419504]
	TIME [epoch: 8.24 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491295012922505		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.10491295012922505 | validation: 0.08195179069653785]
	TIME [epoch: 8.23 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374757532130609		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.09374757532130609 | validation: 0.07823698630319284]
	TIME [epoch: 8.23 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480647510134854		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.10480647510134854 | validation: 0.10438507990794413]
	TIME [epoch: 8.23 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09417995113712768		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.09417995113712768 | validation: 0.12489589516994158]
	TIME [epoch: 8.24 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30884318490096035		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.30884318490096035 | validation: 0.6180718353069921]
	TIME [epoch: 8.27 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593376920607062		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.2593376920607062 | validation: 0.11320333633929733]
	TIME [epoch: 8.23 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09076756992425908		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.09076756992425908 | validation: 0.0848152834964687]
	TIME [epoch: 8.23 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734952862601758		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.0734952862601758 | validation: 0.09180446692310207]
	TIME [epoch: 8.23 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363347931905685		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.08363347931905685 | validation: 0.08941554598296209]
	TIME [epoch: 8.23 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195549201329787		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.08195549201329787 | validation: 0.08963045506190719]
	TIME [epoch: 8.28 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114199097149399		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.09114199097149399 | validation: 0.21007195638733264]
	TIME [epoch: 8.26 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293004671570159		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.17293004671570159 | validation: 0.080447090586079]
	TIME [epoch: 8.25 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09258049926027087		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.09258049926027087 | validation: 0.09494837521694574]
	TIME [epoch: 8.23 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09423659481479978		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.09423659481479978 | validation: 0.08791136676008629]
	TIME [epoch: 8.23 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08558770912982704		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.08558770912982704 | validation: 0.08621849501026246]
	TIME [epoch: 8.23 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08661226594118387		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.08661226594118387 | validation: 0.07565417452772427]
	TIME [epoch: 8.27 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11136993697824615		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.11136993697824615 | validation: 0.11761150861125397]
	TIME [epoch: 8.23 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987224653884112		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.0987224653884112 | validation: 0.08974877621866617]
	TIME [epoch: 8.23 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11658720250033755		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.11658720250033755 | validation: 0.07407072652336645]
	TIME [epoch: 8.23 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10609339609508284		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.10609339609508284 | validation: 0.07848435977340185]
	TIME [epoch: 8.23 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08430447228480581		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.08430447228480581 | validation: 0.1785103434353762]
	TIME [epoch: 8.25 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539551309912433		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.12539551309912433 | validation: 0.2214162036976216]
	TIME [epoch: 8.32 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16712682592123704		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.16712682592123704 | validation: 0.08013975463110241]
	TIME [epoch: 8.23 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960058737640853		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.0960058737640853 | validation: 0.08605231493000508]
	TIME [epoch: 8.23 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030016563696345		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.10030016563696345 | validation: 0.07464889108421226]
	TIME [epoch: 8.23 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878396915406972		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.0878396915406972 | validation: 0.12455425670803422]
	TIME [epoch: 8.23 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08465693732913018		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.08465693732913018 | validation: 0.10001155392959649]
	TIME [epoch: 8.28 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378263926293334		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.1378263926293334 | validation: 0.055209846594728926]
	TIME [epoch: 8.24 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014482868852708		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.1014482868852708 | validation: 0.20792183287730304]
	TIME [epoch: 8.24 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328042247864851		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.1328042247864851 | validation: 0.11953910649963069]
	TIME [epoch: 8.23 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121268153619377		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.09121268153619377 | validation: 0.09046119318826751]
	TIME [epoch: 8.23 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424541462169641		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.08424541462169641 | validation: 0.11004502836828867]
	TIME [epoch: 8.25 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062668335205272		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.1062668335205272 | validation: 0.08458442883778067]
	TIME [epoch: 8.26 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081862734007223		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.09081862734007223 | validation: 0.0905238962577456]
	TIME [epoch: 8.22 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13300450657260676		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.13300450657260676 | validation: 0.10835185264771877]
	TIME [epoch: 8.23 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15664623007870773		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.15664623007870773 | validation: 0.08207553067530335]
	TIME [epoch: 8.22 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834513127349976		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.10834513127349976 | validation: 0.10166379793487214]
	TIME [epoch: 8.23 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840214942697932		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.09840214942697932 | validation: 0.08657057486934042]
	TIME [epoch: 8.27 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475626219909385		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.08475626219909385 | validation: 0.10129184666175794]
	TIME [epoch: 8.24 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800503893501829		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.09800503893501829 | validation: 0.08179543027343121]
	TIME [epoch: 8.23 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906869582947024		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.0906869582947024 | validation: 0.11682623623968816]
	TIME [epoch: 8.23 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12525569493461752		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.12525569493461752 | validation: 0.10299445790889623]
	TIME [epoch: 8.22 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080782340935097		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.1080782340935097 | validation: 0.07886374271839787]
	TIME [epoch: 8.24 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171231738948		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.10171231738948 | validation: 0.0844863660363539]
	TIME [epoch: 8.28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967983198723125		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.0967983198723125 | validation: 0.14405373016182565]
	TIME [epoch: 8.25 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312727599142389		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.11312727599142389 | validation: 0.057838743642960065]
	TIME [epoch: 8.25 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711619167987763		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.09711619167987763 | validation: 0.12281447705740808]
	TIME [epoch: 8.24 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09541080153222184		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.09541080153222184 | validation: 0.16504090973522922]
	TIME [epoch: 8.23 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11272079628686252		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.11272079628686252 | validation: 0.07881957688884732]
	TIME [epoch: 8.27 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08499017197475082		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.08499017197475082 | validation: 0.10141246229313394]
	TIME [epoch: 8.24 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105278152422052		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.11105278152422052 | validation: 0.10463060547091008]
	TIME [epoch: 8.23 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668530502499025		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.08668530502499025 | validation: 0.09164319110843264]
	TIME [epoch: 8.23 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09500405215663897		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.09500405215663897 | validation: 0.0904924713274232]
	TIME [epoch: 8.23 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413442823230979		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.12413442823230979 | validation: 0.13807319458325096]
	TIME [epoch: 8.23 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10065190032965203		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.10065190032965203 | validation: 0.049753581967916766]
	TIME [epoch: 8.27 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051838534240355824		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.051838534240355824 | validation: 0.13750048866071354]
	TIME [epoch: 8.23 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12404708632289067		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.12404708632289067 | validation: 0.07293486445206077]
	TIME [epoch: 8.23 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509039713662016		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.10509039713662016 | validation: 0.11599237855283252]
	TIME [epoch: 8.23 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10879997219947705		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.10879997219947705 | validation: 0.07228219542732316]
	TIME [epoch: 8.23 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324819543950515		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.08324819543950515 | validation: 0.15112497654373352]
	TIME [epoch: 8.25 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10419478452412884		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.10419478452412884 | validation: 0.07165851281074073]
	TIME [epoch: 8.26 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598311442930329		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.08598311442930329 | validation: 0.09253495557904931]
	TIME [epoch: 8.24 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08527957141187538		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.08527957141187538 | validation: 0.06844075545147991]
	TIME [epoch: 8.25 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888350092201836		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.0888350092201836 | validation: 0.09356497936207113]
	TIME [epoch: 8.24 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15269315628931282		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.15269315628931282 | validation: 0.06323596857911556]
	TIME [epoch: 8.23 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792311667492693		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.07792311667492693 | validation: 0.10106163952137778]
	TIME [epoch: 8.27 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08826958988598801		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.08826958988598801 | validation: 0.08087695862043193]
	TIME [epoch: 8.24 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588257099270254		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.08588257099270254 | validation: 0.1606623542090378]
	TIME [epoch: 8.23 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459301717205812		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.12459301717205812 | validation: 0.09273057241169594]
	TIME [epoch: 8.23 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10071085850949002		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.10071085850949002 | validation: 0.07013038982162989]
	TIME [epoch: 8.23 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09594116067711653		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.09594116067711653 | validation: 0.06602538781263564]
	TIME [epoch: 8.23 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904641450984537		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.0904641450984537 | validation: 0.08871892611898445]
	TIME [epoch: 8.27 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760632858397821		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.11760632858397821 | validation: 0.07542931984724231]
	TIME [epoch: 8.23 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07283614456009828		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.07283614456009828 | validation: 0.1093281188531327]
	TIME [epoch: 8.23 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683652228792759		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.10683652228792759 | validation: 0.0848659979978379]
	TIME [epoch: 8.22 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765653822151445		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.09765653822151445 | validation: 0.0875749947219503]
	TIME [epoch: 8.23 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166459639479703		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.08166459639479703 | validation: 0.06271878119104565]
	TIME [epoch: 8.25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019689965588603		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.1019689965588603 | validation: 0.08959755261272044]
	TIME [epoch: 8.26 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753638927390512		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.09753638927390512 | validation: 0.09032375928399086]
	TIME [epoch: 8.24 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197989564680895		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.10197989564680895 | validation: 0.10175364924261118]
	TIME [epoch: 8.23 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10806329494801387		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.10806329494801387 | validation: 0.0704294015527615]
	TIME [epoch: 8.23 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074929542839019		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.12074929542839019 | validation: 0.06774818436219769]
	TIME [epoch: 8.23 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888315844311313		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.08888315844311313 | validation: 0.07291835954227496]
	TIME [epoch: 8.27 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723782322626258		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.08723782322626258 | validation: 0.06889815978830574]
	TIME [epoch: 8.19 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796669492232319		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.0796669492232319 | validation: 0.18174760030448095]
	TIME [epoch: 8.22 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10880593812374327		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.10880593812374327 | validation: 0.09840100463272328]
	TIME [epoch: 8.22 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09485540127703138		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.09485540127703138 | validation: 0.07313796753282709]
	TIME [epoch: 8.22 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172193987706116		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.10172193987706116 | validation: 0.09148292977061659]
	TIME [epoch: 8.23 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048762973960707		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.10048762973960707 | validation: 0.08723382331588071]
	TIME [epoch: 8.26 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211618830083344		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.10211618830083344 | validation: 0.059458641382074184]
	TIME [epoch: 8.22 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0702639353285952		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.0702639353285952 | validation: 0.06831611169306649]
	TIME [epoch: 8.22 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389778547491997		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.08389778547491997 | validation: 0.08107562481378724]
	TIME [epoch: 8.22 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07601343124292584		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.07601343124292584 | validation: 0.08715216244951754]
	TIME [epoch: 8.22 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229373467838608		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.08229373467838608 | validation: 0.07544837145569609]
	TIME [epoch: 8.26 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096539561116697		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.096539561116697 | validation: 0.09056975243859616]
	TIME [epoch: 8.24 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16509455290033556		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.16509455290033556 | validation: 0.07284545208246482]
	TIME [epoch: 8.23 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790643756241499		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.06790643756241499 | validation: 0.05676295249177148]
	TIME [epoch: 8.23 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0716997174651106		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.0716997174651106 | validation: 0.06048945585514246]
	TIME [epoch: 8.23 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09626039014726705		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.09626039014726705 | validation: 0.05208510608804909]
	TIME [epoch: 8.23 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714547650965564		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.07714547650965564 | validation: 0.08838876504227827]
	TIME [epoch: 8.26 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09479911216593546		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.09479911216593546 | validation: 0.06672218840162633]
	TIME [epoch: 8.22 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07410939055748024		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.07410939055748024 | validation: 0.08903335895122494]
	TIME [epoch: 8.22 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065985249310718		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.08065985249310718 | validation: 0.0907691642462773]
	TIME [epoch: 8.22 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849488095004791		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.09849488095004791 | validation: 0.1052686942385001]
	TIME [epoch: 8.22 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07821755057948503		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.07821755057948503 | validation: 0.07695095370599356]
	TIME [epoch: 8.25 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0704701290736877		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.0704701290736877 | validation: 0.10452881040727138]
	TIME [epoch: 8.25 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056553339898131		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.09056553339898131 | validation: 0.07310592965823809]
	TIME [epoch: 8.23 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080566257639845		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.10080566257639845 | validation: 0.08352893313867309]
	TIME [epoch: 8.23 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10606517949450094		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.10606517949450094 | validation: 0.0856509096442792]
	TIME [epoch: 8.23 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31627248449430395		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.31627248449430395 | validation: 1.462214218805722]
	TIME [epoch: 8.23 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0820887262422352		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 1.0820887262422352 | validation: 0.3890994666257145]
	TIME [epoch: 8.27 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024865086600507		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.5024865086600507 | validation: 0.3179672298263932]
	TIME [epoch: 8.24 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3042528298111774		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.3042528298111774 | validation: 0.2015021614810057]
	TIME [epoch: 8.24 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767307770387192		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.2767307770387192 | validation: 0.15909355908217337]
	TIME [epoch: 8.24 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574622684282829		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.2574622684282829 | validation: 0.14887655529613322]
	TIME [epoch: 8.23 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20887147400365716		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.20887147400365716 | validation: 0.1622105366643264]
	TIME [epoch: 8.24 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18935720942283757		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.18935720942283757 | validation: 0.1453935856122411]
	TIME [epoch: 8.27 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14761124771895495		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.14761124771895495 | validation: 0.0911321120365674]
	TIME [epoch: 8.23 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13376980004762482		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.13376980004762482 | validation: 0.0822898940236482]
	TIME [epoch: 8.23 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905401320540117		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.5905401320540117 | validation: 0.3767796993405385]
	TIME [epoch: 8.22 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589050713408395		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.2589050713408395 | validation: 0.1353908923279395]
	TIME [epoch: 8.23 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11623147732740238		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.11623147732740238 | validation: 0.08308822198950835]
	TIME [epoch: 8.26 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145414227920731		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.07145414227920731 | validation: 0.052154224071074576]
	TIME [epoch: 8.24 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07335595551964792		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.07335595551964792 | validation: 0.07481823688128877]
	TIME [epoch: 8.22 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08899963294665009		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.08899963294665009 | validation: 0.04656642969352765]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061491528532933146		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.061491528532933146 | validation: 0.08305210332339757]
	TIME [epoch: 8.24 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07946709512080655		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.07946709512080655 | validation: 0.07191325388009376]
	TIME [epoch: 8.24 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011652694851518		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.08011652694851518 | validation: 0.0652385227050048]
	TIME [epoch: 8.27 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07487726134964312		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.07487726134964312 | validation: 0.07229724621003997]
	TIME [epoch: 8.24 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07538719130111426		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.07538719130111426 | validation: 0.07613939939908149]
	TIME [epoch: 8.25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092939596649222		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.092939596649222 | validation: 0.1050950934559866]
	TIME [epoch: 8.24 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317868290053863		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.08317868290053863 | validation: 0.08823494751838624]
	TIME [epoch: 8.24 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540405136005934		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.07540405136005934 | validation: 0.07433041387626119]
	TIME [epoch: 8.27 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018862843408679		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.09018862843408679 | validation: 0.12255762686717755]
	TIME [epoch: 8.24 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915164857327877		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.0915164857327877 | validation: 0.13658628315054738]
	TIME [epoch: 8.23 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952705277082302		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.0952705277082302 | validation: 0.07477550931226203]
	TIME [epoch: 8.23 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07416682135767078		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.07416682135767078 | validation: 0.05996927958270769]
	TIME [epoch: 8.23 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630247194326598		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.07630247194326598 | validation: 0.15352845098468076]
	TIME [epoch: 8.23 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09527360098133877		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.09527360098133877 | validation: 0.07447096342041087]
	TIME [epoch: 8.26 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957697308876008		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.07957697308876008 | validation: 0.07890756090660726]
	TIME [epoch: 8.23 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09930151269294485		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.09930151269294485 | validation: 0.1151575402788055]
	TIME [epoch: 8.23 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948426807768036		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.07948426807768036 | validation: 0.07647367074258271]
	TIME [epoch: 8.22 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729776387709529		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.08729776387709529 | validation: 0.07461302030933287]
	TIME [epoch: 8.23 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024362912208427		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.09024362912208427 | validation: 0.12881204111817682]
	TIME [epoch: 8.25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911560956340779		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.09911560956340779 | validation: 0.0801154853550983]
	TIME [epoch: 8.26 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756382567618856		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.0756382567618856 | validation: 0.08157498425794997]
	TIME [epoch: 8.23 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735320037427725		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.07735320037427725 | validation: 0.08797995971891936]
	TIME [epoch: 8.24 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08797273321972553		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.08797273321972553 | validation: 0.292818930035727]
	TIME [epoch: 8.24 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496097483192684		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.13496097483192684 | validation: 0.06625109421277452]
	TIME [epoch: 8.23 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122902849626978		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.07122902849626978 | validation: 0.08084406399755217]
	TIME [epoch: 8.28 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006375571400842		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.06006375571400842 | validation: 0.07831724298438605]
	TIME [epoch: 8.23 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962507506803242		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.07962507506803242 | validation: 0.11795059100782473]
	TIME [epoch: 8.23 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880433151615009		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.0880433151615009 | validation: 0.06522271938196048]
	TIME [epoch: 8.22 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716416381285497		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.08716416381285497 | validation: 0.10302534479007565]
	TIME [epoch: 8.22 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12054665305166441		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.12054665305166441 | validation: 0.07923052981022233]
	TIME [epoch: 8.23 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07344889904426936		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.07344889904426936 | validation: 0.06502556324486211]
	TIME [epoch: 8.27 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758588513509547		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.06758588513509547 | validation: 0.04480867110203534]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06358891373262687		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.06358891373262687 | validation: 0.08346015042469386]
	TIME [epoch: 8.23 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07632030464969926		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.07632030464969926 | validation: 0.09086465810003642]
	TIME [epoch: 8.22 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09454076948359355		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.09454076948359355 | validation: 0.07269920598931784]
	TIME [epoch: 8.22 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308939014910537		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.08308939014910537 | validation: 0.08556125782460212]
	TIME [epoch: 8.26 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042606073522883		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.10042606073522883 | validation: 0.07780698078585406]
	TIME [epoch: 8.24 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05571644257513159		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.05571644257513159 | validation: 0.06812705135417317]
	TIME [epoch: 8.23 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820522256694396		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.0820522256694396 | validation: 0.08593809185576448]
	TIME [epoch: 8.25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108253472230643		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.07108253472230643 | validation: 0.07957937088291503]
	TIME [epoch: 8.23 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06532852476081076		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.06532852476081076 | validation: 0.05234704851380837]
	TIME [epoch: 8.24 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09403682526339306		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.09403682526339306 | validation: 0.07150393746586284]
	TIME [epoch: 8.27 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08219478880843403		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.08219478880843403 | validation: 0.08569182039294908]
	TIME [epoch: 8.23 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07974407444092993		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.07974407444092993 | validation: 0.06854464494569718]
	TIME [epoch: 8.23 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029074649688431		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.07029074649688431 | validation: 0.06375259119186652]
	TIME [epoch: 8.23 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652002405764226		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.06652002405764226 | validation: 0.0855613714792456]
	TIME [epoch: 8.22 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008147934830629		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.1008147934830629 | validation: 0.040619742444863174]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585623099220965		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.0585623099220965 | validation: 0.14128437333253233]
	TIME [epoch: 8.23 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039724616511325		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.10039724616511325 | validation: 0.04422631838592081]
	TIME [epoch: 8.23 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05704816606808359		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.05704816606808359 | validation: 0.07680158600492111]
	TIME [epoch: 8.23 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352196860510373		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.09352196860510373 | validation: 0.09734375210749435]
	TIME [epoch: 8.22 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08613889399209164		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.08613889399209164 | validation: 0.12009761797189467]
	TIME [epoch: 8.23 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09036966445709158		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.09036966445709158 | validation: 0.0734926166100471]
	TIME [epoch: 8.28 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714519583894034		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.0714519583894034 | validation: 0.07570286929344536]
	TIME [epoch: 8.23 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08138744810618409		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.08138744810618409 | validation: 0.1331007631766682]
	TIME [epoch: 8.23 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07456863811767914		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.07456863811767914 | validation: 0.05824719137830853]
	TIME [epoch: 8.23 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06738700415080515		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.06738700415080515 | validation: 0.08382430530516172]
	TIME [epoch: 8.22 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797483813305008		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.06797483813305008 | validation: 0.08412427096099678]
	TIME [epoch: 8.25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05840914840180379		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.05840914840180379 | validation: 0.0623873820882551]
	TIME [epoch: 8.25 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357861665967913		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.10357861665967913 | validation: 0.2277250884482457]
	TIME [epoch: 8.22 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08934921526571046		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.08934921526571046 | validation: 0.060360731991470754]
	TIME [epoch: 8.23 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607195208953001		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.06607195208953001 | validation: 0.05241745871443288]
	TIME [epoch: 8.22 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07454556189150807		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.07454556189150807 | validation: 0.07508849783104166]
	TIME [epoch: 8.22 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508880772844974		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.07508880772844974 | validation: 0.07902661283471715]
	TIME [epoch: 8.26 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07155895335864473		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.07155895335864473 | validation: 0.07326022556441503]
	TIME [epoch: 8.23 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07857751549788505		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.07857751549788505 | validation: 0.06925576803695757]
	TIME [epoch: 8.22 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06946107576048002		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.06946107576048002 | validation: 0.07233074014056282]
	TIME [epoch: 8.22 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585504454530025		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.0585504454530025 | validation: 0.09132925208329373]
	TIME [epoch: 8.22 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014522119200304		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.1014522119200304 | validation: 0.08948409750554454]
	TIME [epoch: 8.23 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0721089866528964		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.0721089866528964 | validation: 0.06719248300948423]
	TIME [epoch: 8.26 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376435014029191		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.06376435014029191 | validation: 0.0964546421395821]
	TIME [epoch: 8.23 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07011390229580577		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.07011390229580577 | validation: 0.16179313966429193]
	TIME [epoch: 8.24 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611886336544105		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.10611886336544105 | validation: 0.21340968811272604]
	TIME [epoch: 8.23 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10285430868662448		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.10285430868662448 | validation: 0.06589691189797396]
	TIME [epoch: 8.23 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06357781847429177		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.06357781847429177 | validation: 0.053451691542426225]
	TIME [epoch: 8.27 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055930415858152116		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.055930415858152116 | validation: 0.09303328685125303]
	TIME [epoch: 8.24 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367704567832947		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.11367704567832947 | validation: 0.07150758062567289]
	TIME [epoch: 8.23 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05436942219746787		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.05436942219746787 | validation: 0.08663066701991612]
	TIME [epoch: 8.22 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08773757001718313		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.08773757001718313 | validation: 0.06769289748882396]
	TIME [epoch: 8.22 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06627993179976296		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.06627993179976296 | validation: 0.09538765488442325]
	TIME [epoch: 8.23 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200520645953413		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.08200520645953413 | validation: 0.06506882005842758]
	TIME [epoch: 8.26 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363125193367301		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.06363125193367301 | validation: 0.062242480079966064]
	TIME [epoch: 8.23 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09759260690683619		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.09759260690683619 | validation: 0.09505802717405044]
	TIME [epoch: 8.22 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692800197263699		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.06692800197263699 | validation: 0.06708888773487963]
	TIME [epoch: 8.23 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06232448787932881		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.06232448787932881 | validation: 0.08267125569384323]
	TIME [epoch: 8.22 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07343980399850951		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.07343980399850951 | validation: 0.062360351925029894]
	TIME [epoch: 8.24 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276804227259644		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.06276804227259644 | validation: 0.14472092727865604]
	TIME [epoch: 8.25 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163147943615925		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.08163147943615925 | validation: 0.1642834898076825]
	TIME [epoch: 8.22 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261663067391031		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.11261663067391031 | validation: 0.0643221676542902]
	TIME [epoch: 8.23 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04931551035879382		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.04931551035879382 | validation: 0.05417342933075328]
	TIME [epoch: 8.23 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819774028744396		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.06819774028744396 | validation: 0.0828660025893053]
	TIME [epoch: 8.23 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07513842412650171		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.07513842412650171 | validation: 0.08937202335512454]
	TIME [epoch: 8.27 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07533432566308726		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.07533432566308726 | validation: 0.07408022235613917]
	TIME [epoch: 8.24 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692215526680789		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.07692215526680789 | validation: 0.0626026047654203]
	TIME [epoch: 8.23 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07616167954375938		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.07616167954375938 | validation: 0.059264958067450746]
	TIME [epoch: 8.22 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259426056484354		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.05259426056484354 | validation: 0.06567757179228241]
	TIME [epoch: 8.22 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982110207665136		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.0982110207665136 | validation: 0.07067680066494024]
	TIME [epoch: 8.23 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05168811528451321		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.05168811528451321 | validation: 0.06316616597415374]
	TIME [epoch: 10.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914441668321528		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.05914441668321528 | validation: 0.05895286997928136]
	TIME [epoch: 8.33 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07339391942877162		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.07339391942877162 | validation: 0.07968990379108032]
	TIME [epoch: 8.23 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720457285289097		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.07720457285289097 | validation: 0.0407213880835431]
	TIME [epoch: 8.23 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300241322446018		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.06300241322446018 | validation: 0.10426530270666393]
	TIME [epoch: 8.22 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183149580496656		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.10183149580496656 | validation: 0.06873991148344624]
	TIME [epoch: 8.26 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06231904286798284		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.06231904286798284 | validation: 0.06573113079169107]
	TIME [epoch: 8.23 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565667133383814		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.05565667133383814 | validation: 0.07098953848771992]
	TIME [epoch: 8.23 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088767511424726		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.088767511424726 | validation: 0.042219511221553055]
	TIME [epoch: 8.24 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605588284668481		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.04605588284668481 | validation: 0.08637197982847117]
	TIME [epoch: 8.23 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687200838620592		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.08687200838620592 | validation: 0.09149336603278677]
	TIME [epoch: 8.24 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994349093515879		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.05994349093515879 | validation: 0.08034077492479309]
	TIME [epoch: 8.27 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000611646714233		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.06000611646714233 | validation: 0.038781246608858844]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_809.pth
	Model improved!!!
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059920860157225586		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.059920860157225586 | validation: 0.07023031766342741]
	TIME [epoch: 8.22 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07046398335021695		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.07046398335021695 | validation: 0.09939614852933068]
	TIME [epoch: 8.22 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385860006763267		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.07385860006763267 | validation: 0.0568256173580432]
	TIME [epoch: 8.22 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07476611402587971		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.07476611402587971 | validation: 0.12299927841986104]
	TIME [epoch: 8.26 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594422398844253		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.07594422398844253 | validation: 0.05588860696662497]
	TIME [epoch: 8.23 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060790918747045355		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.060790918747045355 | validation: 0.07932509660163167]
	TIME [epoch: 8.22 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09231190197775203		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.09231190197775203 | validation: 0.04194419841363718]
	TIME [epoch: 8.22 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05614277358742173		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.05614277358742173 | validation: 0.06591302455803609]
	TIME [epoch: 8.21 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08818463946721311		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.08818463946721311 | validation: 0.034456583896939945]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05986943712486302		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.05986943712486302 | validation: 0.08777716211384623]
	TIME [epoch: 8.26 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06553922339429365		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.06553922339429365 | validation: 0.04121789229277633]
	TIME [epoch: 8.22 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061754597365305613		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.061754597365305613 | validation: 0.09390381296850445]
	TIME [epoch: 8.22 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225464249831012		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.07225464249831012 | validation: 0.05473221465905587]
	TIME [epoch: 8.22 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07048358942283586		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.07048358942283586 | validation: 0.08038897558491899]
	TIME [epoch: 8.23 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057953602592511935		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.057953602592511935 | validation: 0.08380462668569967]
	TIME [epoch: 8.25 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644922037256358		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.0644922037256358 | validation: 0.08409294966418865]
	TIME [epoch: 8.25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271169001578034		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.05271169001578034 | validation: 0.05559769517322986]
	TIME [epoch: 8.22 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123706574159387		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.06123706574159387 | validation: 0.05523122011289206]
	TIME [epoch: 8.22 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451805730884966		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.06451805730884966 | validation: 0.054196217930155416]
	TIME [epoch: 8.22 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918615643718804		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.05918615643718804 | validation: 0.06902095031551962]
	TIME [epoch: 8.22 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07781011854447833		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.07781011854447833 | validation: 0.04360470951937813]
	TIME [epoch: 8.26 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048088474160302326		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.048088474160302326 | validation: 0.07629798671963826]
	TIME [epoch: 8.23 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114883135034275		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.09114883135034275 | validation: 0.03867073253710157]
	TIME [epoch: 8.23 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06114057479921384		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.06114057479921384 | validation: 0.06566097125342524]
	TIME [epoch: 8.22 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05969734812522862		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.05969734812522862 | validation: 0.05959044682134128]
	TIME [epoch: 8.22 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05678411951926887		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.05678411951926887 | validation: 0.0621863278132882]
	TIME [epoch: 8.23 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06817434935366645		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.06817434935366645 | validation: 0.06306038854585273]
	TIME [epoch: 8.26 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07422600178121569		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.07422600178121569 | validation: 0.04097447546628487]
	TIME [epoch: 8.23 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261164263787496		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.05261164263787496 | validation: 0.08302319079901195]
	TIME [epoch: 8.23 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754844253850115		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.05754844253850115 | validation: 0.04851490140186411]
	TIME [epoch: 8.23 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04932570468394288		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.04932570468394288 | validation: 0.048034216101801176]
	TIME [epoch: 8.23 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638976238389278		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.0638976238389278 | validation: 0.08560356152391556]
	TIME [epoch: 8.26 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681096732799728		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.08681096732799728 | validation: 0.0305062813475412]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_842.pth
	Model improved!!!
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046853094875764584		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.046853094875764584 | validation: 0.069851680017827]
	TIME [epoch: 8.23 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790890279274989		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.06790890279274989 | validation: 0.04503385204960372]
	TIME [epoch: 8.24 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058258473780107484		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.058258473780107484 | validation: 0.21958247642211515]
	TIME [epoch: 8.24 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702465434685145		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.10702465434685145 | validation: 0.0459161881937454]
	TIME [epoch: 8.24 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17457812013684357		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.17457812013684357 | validation: 0.07527577335114369]
	TIME [epoch: 8.27 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929202866810209		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.05929202866810209 | validation: 0.057298431730199675]
	TIME [epoch: 8.24 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774484191804284		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.05774484191804284 | validation: 0.053134335307154695]
	TIME [epoch: 8.24 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04440095223442376		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.04440095223442376 | validation: 0.045901193720871133]
	TIME [epoch: 8.24 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589923027945867		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.08589923027945867 | validation: 0.057819864712945146]
	TIME [epoch: 8.23 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531146301886084		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.0531146301886084 | validation: 0.06796105967106357]
	TIME [epoch: 8.27 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05356568438564319		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.05356568438564319 | validation: 0.07033543645448687]
	TIME [epoch: 8.25 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983120511715618		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.06983120511715618 | validation: 0.06295207819376342]
	TIME [epoch: 8.24 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05572680974935703		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.05572680974935703 | validation: 0.049418734272996215]
	TIME [epoch: 8.24 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058051781696291965		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.058051781696291965 | validation: 0.07319430126479469]
	TIME [epoch: 8.25 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520593098675769		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.05520593098675769 | validation: 0.039915459069839454]
	TIME [epoch: 8.25 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09334650166502684		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.09334650166502684 | validation: 0.03444287322613129]
	TIME [epoch: 8.29 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059156767068905144		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.059156767068905144 | validation: 0.05017970158095891]
	TIME [epoch: 8.34 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565154615877541		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.04565154615877541 | validation: 0.049910694219113094]
	TIME [epoch: 8.23 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051284650243976		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.05051284650243976 | validation: 0.07308240174186101]
	TIME [epoch: 8.24 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058639466415500933		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.058639466415500933 | validation: 0.044315176545158486]
	TIME [epoch: 8.23 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08790136808424502		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.08790136808424502 | validation: 0.0688588206486066]
	TIME [epoch: 8.25 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04870925531714714		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.04870925531714714 | validation: 0.07680654845757022]
	TIME [epoch: 8.27 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06195224007796331		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.06195224007796331 | validation: 0.12758457559636133]
	TIME [epoch: 8.24 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564967768832875		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.05564967768832875 | validation: 0.036437986419531776]
	TIME [epoch: 8.23 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555569602403439		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.0555569602403439 | validation: 0.062437565367207945]
	TIME [epoch: 8.24 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545453928600188		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.0545453928600188 | validation: 0.06732475210364888]
	TIME [epoch: 8.23 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05623501020768676		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.05623501020768676 | validation: 0.07233816748797206]
	TIME [epoch: 8.28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331158089980976		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.06331158089980976 | validation: 0.053979752658192486]
	TIME [epoch: 8.25 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430118128019999		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.05430118128019999 | validation: 0.05110408651425573]
	TIME [epoch: 8.24 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344956387259517		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.05344956387259517 | validation: 0.06320208432486465]
	TIME [epoch: 8.24 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493509553560716		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.07493509553560716 | validation: 0.040272051321693335]
	TIME [epoch: 8.25 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054701929360493846		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.054701929360493846 | validation: 0.08016855392018618]
	TIME [epoch: 8.25 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707420442376787		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.05707420442376787 | validation: 0.07312312942662147]
	TIME [epoch: 8.28 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05282611482035081		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.05282611482035081 | validation: 0.047851735805281154]
	TIME [epoch: 8.23 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930313941438747		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.04930313941438747 | validation: 0.04963345516302539]
	TIME [epoch: 8.23 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06697995791667721		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.06697995791667721 | validation: 0.0643307826229048]
	TIME [epoch: 8.24 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848820931047889		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.06848820931047889 | validation: 0.0796340227160865]
	TIME [epoch: 8.23 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023420921855889		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.07023420921855889 | validation: 0.04616307588442848]
	TIME [epoch: 8.27 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680476379601031		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.04680476379601031 | validation: 0.06773785821889045]
	TIME [epoch: 8.24 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051706676990703596		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.051706676990703596 | validation: 0.037871693700829795]
	TIME [epoch: 8.22 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053303879282881675		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.053303879282881675 | validation: 0.06829992401901791]
	TIME [epoch: 8.23 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952924331161582		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.05952924331161582 | validation: 0.04110521224459495]
	TIME [epoch: 8.23 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045866586934188255		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.045866586934188255 | validation: 0.04574583990349348]
	TIME [epoch: 8.24 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04901285929523223		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.04901285929523223 | validation: 0.0637330437996741]
	TIME [epoch: 8.27 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05792189730163169		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.05792189730163169 | validation: 0.10999847479999031]
	TIME [epoch: 8.24 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713925672259007		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.07713925672259007 | validation: 0.08381403646784252]
	TIME [epoch: 8.24 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054601283852461956		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.054601283852461956 | validation: 0.026725865264791038]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179730667684674		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.04179730667684674 | validation: 0.0591151564053072]
	TIME [epoch: 8.24 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094780358430002		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.06094780358430002 | validation: 0.06024584853587216]
	TIME [epoch: 8.27 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05649222594668006		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.05649222594668006 | validation: 0.04468375605352583]
	TIME [epoch: 8.24 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061225537340904905		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.061225537340904905 | validation: 0.043436772137426256]
	TIME [epoch: 8.23 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041452960232621044		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.041452960232621044 | validation: 0.04231007176957548]
	TIME [epoch: 8.23 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727984597308835		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.04727984597308835 | validation: 0.047472908697485716]
	TIME [epoch: 8.22 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07121588096076635		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.07121588096076635 | validation: 0.04668933187785067]
	TIME [epoch: 8.23 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03993735206704819		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.03993735206704819 | validation: 0.044353585749013213]
	TIME [epoch: 8.27 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05697731276772056		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.05697731276772056 | validation: 0.05314613951616033]
	TIME [epoch: 8.23 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654491868876259		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.04654491868876259 | validation: 0.09105100875314907]
	TIME [epoch: 8.22 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06955175118852258		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.06955175118852258 | validation: 0.04320060804794559]
	TIME [epoch: 8.22 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043211699114849234		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.043211699114849234 | validation: 0.04940059110651945]
	TIME [epoch: 8.22 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03786430150773316		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.03786430150773316 | validation: 0.03986800296243018]
	TIME [epoch: 8.24 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294030503019866		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.06294030503019866 | validation: 0.034576734078619185]
	TIME [epoch: 8.25 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863811840803093		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.04863811840803093 | validation: 0.030570390895213462]
	TIME [epoch: 8.22 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199353588686847		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.03199353588686847 | validation: 0.07375662925917215]
	TIME [epoch: 8.23 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189239411208337		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.07189239411208337 | validation: 0.06141238322455564]
	TIME [epoch: 8.23 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893476960241685		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.06893476960241685 | validation: 0.05298056937729161]
	TIME [epoch: 8.23 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445731258602831		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.0445731258602831 | validation: 0.04651988056244204]
	TIME [epoch: 8.27 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04867562607485844		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.04867562607485844 | validation: 0.037128510702519844]
	TIME [epoch: 8.23 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037438796621663765		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.037438796621663765 | validation: 0.04625721116958533]
	TIME [epoch: 8.23 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05861161205567527		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.05861161205567527 | validation: 0.07115940122043901]
	TIME [epoch: 8.23 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05709478176574637		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.05709478176574637 | validation: 0.043715439056271205]
	TIME [epoch: 8.32 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04270990108800049		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.04270990108800049 | validation: 0.04685637005647174]
	TIME [epoch: 8.24 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441623894666317		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.04441623894666317 | validation: 0.07565037498512428]
	TIME [epoch: 8.26 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03998733407408585		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.03998733407408585 | validation: 0.03481750666795954]
	TIME [epoch: 8.22 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622523433701853		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.06622523433701853 | validation: 0.039172702597121675]
	TIME [epoch: 8.22 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03778679277340882		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.03778679277340882 | validation: 0.05209628269422561]
	TIME [epoch: 8.22 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04794411326014679		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.04794411326014679 | validation: 0.038421658564952554]
	TIME [epoch: 8.23 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039613164843440275		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.039613164843440275 | validation: 0.05501890127410353]
	TIME [epoch: 8.26 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053041948237951504		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.053041948237951504 | validation: 0.07184233087631153]
	TIME [epoch: 8.24 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047397878391787454		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.047397878391787454 | validation: 0.06720006368483619]
	TIME [epoch: 8.22 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06241054529780637		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.06241054529780637 | validation: 0.04643258083752803]
	TIME [epoch: 8.23 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040331949901226224		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.040331949901226224 | validation: 0.04713451573126319]
	TIME [epoch: 8.23 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0591644507883227		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.0591644507883227 | validation: 0.0345287000504497]
	TIME [epoch: 8.23 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043974678963527615		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.043974678963527615 | validation: 0.033412202595044765]
	TIME [epoch: 8.27 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044555017787230505		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.044555017787230505 | validation: 0.03336589096540533]
	TIME [epoch: 8.23 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048473872312112115		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.048473872312112115 | validation: 0.04399966583272029]
	TIME [epoch: 8.23 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564870453019847		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.06564870453019847 | validation: 0.029787447456716014]
	TIME [epoch: 8.22 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561574305076388		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.04561574305076388 | validation: 0.05026081741050541]
	TIME [epoch: 8.22 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565880845739543		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.04565880845739543 | validation: 0.03132293554222635]
	TIME [epoch: 8.25 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284662442694303		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.03284662442694303 | validation: 0.07127461327276645]
	TIME [epoch: 8.26 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05977387349301015		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.05977387349301015 | validation: 0.0405801020323177]
	TIME [epoch: 8.23 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037029840660857384		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.037029840660857384 | validation: 0.060899657799374556]
	TIME [epoch: 8.23 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168436005943859		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.08168436005943859 | validation: 0.043694548122387177]
	TIME [epoch: 8.22 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029416757948743558		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.029416757948743558 | validation: 0.02782347313469237]
	TIME [epoch: 8.23 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017243834426887		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.04017243834426887 | validation: 0.06050530970402143]
	TIME [epoch: 8.26 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337281532060495		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.04337281532060495 | validation: 0.044787139388930794]
	TIME [epoch: 8.24 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06570128261120768		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.06570128261120768 | validation: 0.038029612856462204]
	TIME [epoch: 8.23 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02926413713079471		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.02926413713079471 | validation: 0.07079363926792095]
	TIME [epoch: 8.23 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443376117396826		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.06443376117396826 | validation: 0.03365567699609334]
	TIME [epoch: 8.23 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887162985732716		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.03887162985732716 | validation: 0.03661208573822017]
	TIME [epoch: 8.25 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03899994557074315		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.03899994557074315 | validation: 0.03701498012019909]
	TIME [epoch: 8.27 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03598740414955533		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.03598740414955533 | validation: 0.0474781023356825]
	TIME [epoch: 8.24 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05287843918142704		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.05287843918142704 | validation: 0.03170492379960327]
	TIME [epoch: 8.23 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02850322445923322		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.02850322445923322 | validation: 0.04138893830010468]
	TIME [epoch: 8.23 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05364545381204982		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.05364545381204982 | validation: 0.04223970589217405]
	TIME [epoch: 8.23 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445067222096255		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.05445067222096255 | validation: 0.03375889381244581]
	TIME [epoch: 8.26 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04652342383946903		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.04652342383946903 | validation: 0.035527880023479015]
	TIME [epoch: 8.24 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030173008043008043		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.030173008043008043 | validation: 0.030306877293175688]
	TIME [epoch: 8.23 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950904511100373		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.04950904511100373 | validation: 0.12197943257196323]
	TIME [epoch: 8.23 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057825304528530914		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.057825304528530914 | validation: 0.03813273062967521]
	TIME [epoch: 8.22 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04188727560331927		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.04188727560331927 | validation: 0.05272202519539316]
	TIME [epoch: 8.23 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03500645596279778		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.03500645596279778 | validation: 0.04003388851936676]
	TIME [epoch: 8.27 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445551478554911		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.03445551478554911 | validation: 0.04037848764042979]
	TIME [epoch: 8.23 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056418377602331274		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.056418377602331274 | validation: 0.030295990953088367]
	TIME [epoch: 8.23 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033598340409045066		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.033598340409045066 | validation: 0.037325309462469466]
	TIME [epoch: 8.23 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055280356274979035		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.055280356274979035 | validation: 0.04542610282084736]
	TIME [epoch: 8.23 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03842384830679558		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.03842384830679558 | validation: 0.055973077119280484]
	TIME [epoch: 8.26 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377552888826167		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.0377552888826167 | validation: 0.042741010943286126]
	TIME [epoch: 8.26 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802928517715963		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.03802928517715963 | validation: 0.039172454024273745]
	TIME [epoch: 8.22 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060839376750558866		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.060839376750558866 | validation: 0.04526082797751632]
	TIME [epoch: 8.23 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04012916987343984		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.04012916987343984 | validation: 0.038339258797196865]
	TIME [epoch: 8.23 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483353487156261		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.04483353487156261 | validation: 0.028784883106615235]
	TIME [epoch: 8.23 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287020410699441		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.03287020410699441 | validation: 0.030311848933896574]
	TIME [epoch: 8.27 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376723102887993		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.04376723102887993 | validation: 0.03613812552451702]
	TIME [epoch: 8.24 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03337158552521025		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.03337158552521025 | validation: 0.08316835676614312]
	TIME [epoch: 8.23 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052937960498172794		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.052937960498172794 | validation: 0.04995613649413612]
	TIME [epoch: 8.22 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042730064581439846		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.042730064581439846 | validation: 0.04076927166849756]
	TIME [epoch: 8.22 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04218534668454228		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.04218534668454228 | validation: 0.02701209901601119]
	TIME [epoch: 8.23 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033059455434321726		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.033059455434321726 | validation: 0.052568351867171334]
	TIME [epoch: 8.27 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539984551532999		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.03539984551532999 | validation: 0.03754310507751045]
	TIME [epoch: 8.23 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04562474971699035		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.04562474971699035 | validation: 0.03353640036057627]
	TIME [epoch: 8.23 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454404442043317		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.06454404442043317 | validation: 0.031992952527053004]
	TIME [epoch: 8.23 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017853130975931157		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.017853130975931157 | validation: 0.04727876176278556]
	TIME [epoch: 8.23 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04862270685610527		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.04862270685610527 | validation: 0.04490888328926517]
	TIME [epoch: 8.27 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04127883225042712		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.04127883225042712 | validation: 0.028030861256536952]
	TIME [epoch: 8.24 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883334201266869		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.02883334201266869 | validation: 0.03727208996391747]
	TIME [epoch: 8.23 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303287526118235		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.08303287526118235 | validation: 0.07343111289947488]
	TIME [epoch: 8.23 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04942271615761487		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.04942271615761487 | validation: 0.024463367649554053]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043899365877204256		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.043899365877204256 | validation: 0.04055033077007117]
	TIME [epoch: 8.23 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234261975921637		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.03234261975921637 | validation: 0.034587629780513954]
	TIME [epoch: 8.26 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841034003563616		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.04841034003563616 | validation: 0.07210418870658984]
	TIME [epoch: 8.23 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041348080816691515		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.041348080816691515 | validation: 0.07588957716651859]
	TIME [epoch: 8.23 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05515489724878655		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.05515489724878655 | validation: 0.028833058361110084]
	TIME [epoch: 8.22 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685427032706954		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.02685427032706954 | validation: 0.03786409583801687]
	TIME [epoch: 8.22 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278560421182598		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.04278560421182598 | validation: 0.028688436962218705]
	TIME [epoch: 8.26 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044944441086832376		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.044944441086832376 | validation: 0.02587428672850061]
	TIME [epoch: 8.24 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179714163592309		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.04179714163592309 | validation: 0.04508863202080631]
	TIME [epoch: 8.23 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639050262390694		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.03639050262390694 | validation: 0.030962377427931675]
	TIME [epoch: 8.23 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531082019118727		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.03531082019118727 | validation: 0.04811224275371669]
	TIME [epoch: 8.22 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04301790024093467		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.04301790024093467 | validation: 0.029477591461036824]
	TIME [epoch: 8.23 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862347378315209		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.02862347378315209 | validation: 0.08119674646761774]
	TIME [epoch: 8.28 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038491991172400694		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.038491991172400694 | validation: 0.030512068095870048]
	TIME [epoch: 8.23 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023246776241386373		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.023246776241386373 | validation: 0.029069844665905484]
	TIME [epoch: 8.23 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531357785766417		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.03531357785766417 | validation: 0.0429832821600675]
	TIME [epoch: 8.22 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922877460886952		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.04922877460886952 | validation: 0.02913374725495465]
	TIME [epoch: 8.23 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043823685820683654		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.043823685820683654 | validation: 0.03297243340831571]
	TIME [epoch: 8.24 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574727740927399		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.0574727740927399 | validation: 0.06292498258955471]
	TIME [epoch: 8.25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03105090953272351		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.03105090953272351 | validation: 0.02423624799946868]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712584069717819		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.02712584069717819 | validation: 0.034929321224141545]
	TIME [epoch: 8.23 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034373949504544615		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.034373949504544615 | validation: 0.02555892441821763]
	TIME [epoch: 8.23 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027030200158417655		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.027030200158417655 | validation: 0.050376509545472556]
	TIME [epoch: 8.22 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054102327942730566		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.054102327942730566 | validation: 0.0465861084987469]
	TIME [epoch: 8.26 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03076357081353818		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.03076357081353818 | validation: 0.038187712065502824]
	TIME [epoch: 8.22 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975942551029746		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.03975942551029746 | validation: 0.04178242419337372]
	TIME [epoch: 8.22 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027286337479078854		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.027286337479078854 | validation: 0.045120921503724834]
	TIME [epoch: 8.22 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048336891844260356		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.048336891844260356 | validation: 0.17117784235407146]
	TIME [epoch: 8.23 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044905532261407574		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.044905532261407574 | validation: 0.03414920510834161]
	TIME [epoch: 8.23 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02741054770792308		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.02741054770792308 | validation: 0.03043058035389936]
	TIME [epoch: 8.26 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313757920743104		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.03313757920743104 | validation: 0.04917859093885932]
	TIME [epoch: 8.22 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03328069763015659		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.03328069763015659 | validation: 0.017770253901366023]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020462752497622083		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.020462752497622083 | validation: 0.0570760508985743]
	TIME [epoch: 8.23 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05317453249784047		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.05317453249784047 | validation: 0.032172184525663255]
	TIME [epoch: 8.22 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03149012462031818		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.03149012462031818 | validation: 0.031206218349161124]
	TIME [epoch: 8.26 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03848809482458026		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.03848809482458026 | validation: 0.032408613367830984]
	TIME [epoch: 8.22 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034243910199210296		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.034243910199210296 | validation: 0.037076792983075535]
	TIME [epoch: 8.22 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030185278225006572		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.030185278225006572 | validation: 0.028446174160953658]
	TIME [epoch: 8.22 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05228095235923502		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.05228095235923502 | validation: 0.028850637529401084]
	TIME [epoch: 8.23 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040639504874930635		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.040639504874930635 | validation: 0.024249308118570997]
	TIME [epoch: 8.21 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024598950398246097		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.024598950398246097 | validation: 0.023161487629951967]
	TIME [epoch: 8.26 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031146554725169875		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.031146554725169875 | validation: 0.05064873100438952]
	TIME [epoch: 8.23 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497873060920592		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.03497873060920592 | validation: 0.05115500431429274]
	TIME [epoch: 8.22 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048574951421284984		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.048574951421284984 | validation: 0.022792590775315362]
	TIME [epoch: 8.22 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021807436154246813		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.021807436154246813 | validation: 0.03268985216496411]
	TIME [epoch: 8.34 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04140641811959261		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.04140641811959261 | validation: 0.03019943342407382]
	TIME [epoch: 8.26 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051100469977482		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.03051100469977482 | validation: 0.05147613703714046]
	TIME [epoch: 8.2 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410392964544945		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.0410392964544945 | validation: 0.032673772575042934]
	TIME [epoch: 8.22 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023835893922343365		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.023835893922343365 | validation: 0.032213357466880234]
	TIME [epoch: 8.22 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028399390902799214		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.028399390902799214 | validation: 0.018947384934317447]
	TIME [epoch: 8.22 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02876323904574595		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.02876323904574595 | validation: 0.0939518681274949]
	TIME [epoch: 8.23 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05077860591558109		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.05077860591558109 | validation: 0.015355959454666928]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1031.pth
	Model improved!!!
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02852372963543301		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.02852372963543301 | validation: 0.06363861111108278]
	TIME [epoch: 8.24 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03185288712831964		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.03185288712831964 | validation: 0.028991839706773027]
	TIME [epoch: 8.24 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025316851567444083		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.025316851567444083 | validation: 0.023681879770477393]
	TIME [epoch: 8.24 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939668987604873		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.02939668987604873 | validation: 0.04390089374576485]
	TIME [epoch: 8.23 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034483848840749676		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.034483848840749676 | validation: 0.027681945887236735]
	TIME [epoch: 8.26 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028981709135020788		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.028981709135020788 | validation: 0.04496237334418908]
	TIME [epoch: 8.27 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045023705011612486		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.045023705011612486 | validation: 0.032858887279647475]
	TIME [epoch: 8.24 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029457833800106185		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.029457833800106185 | validation: 0.039978018198032296]
	TIME [epoch: 8.24 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028562753040045505		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.028562753040045505 | validation: 0.021715677055054575]
	TIME [epoch: 8.24 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03266253715971877		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.03266253715971877 | validation: 0.04327050562130581]
	TIME [epoch: 8.24 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046900670751075485		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.046900670751075485 | validation: 0.03781301649384777]
	TIME [epoch: 8.29 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02752437814893529		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.02752437814893529 | validation: 0.02755475579430728]
	TIME [epoch: 8.25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030773647804807264		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.030773647804807264 | validation: 0.03403626031505298]
	TIME [epoch: 8.24 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302885530572541		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.03302885530572541 | validation: 0.03749860559032691]
	TIME [epoch: 8.24 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049635598830562434		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.049635598830562434 | validation: 0.02645337061382832]
	TIME [epoch: 8.23 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030870393308808697		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.030870393308808697 | validation: 0.02147854887933679]
	TIME [epoch: 8.25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022534276961842993		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.022534276961842993 | validation: 0.028232315869249784]
	TIME [epoch: 8.26 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02746124970317352		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.02746124970317352 | validation: 0.022993763120837417]
	TIME [epoch: 8.24 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359384836813167		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.02359384836813167 | validation: 0.02564989308108486]
	TIME [epoch: 8.25 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049905653024746		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.03049905653024746 | validation: 0.04112394040431065]
	TIME [epoch: 8.23 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03732412815725599		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.03732412815725599 | validation: 0.020342243859667666]
	TIME [epoch: 8.24 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335564184214161		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.03335564184214161 | validation: 0.038883636362884305]
	TIME [epoch: 8.27 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753237029942108		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.04753237029942108 | validation: 0.01832082632951528]
	TIME [epoch: 8.25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019936651397164416		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.019936651397164416 | validation: 0.03696166117516041]
	TIME [epoch: 8.23 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030363956608625092		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.030363956608625092 | validation: 0.019205542670427622]
	TIME [epoch: 8.23 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019107253525684865		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.019107253525684865 | validation: 0.019584960879902195]
	TIME [epoch: 8.23 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03081262134904312		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.03081262134904312 | validation: 0.05046201103016633]
	TIME [epoch: 8.24 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033970393915264595		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.033970393915264595 | validation: 0.05782320838262484]
	TIME [epoch: 8.27 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508437582357701		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.04508437582357701 | validation: 0.02225411323570713]
	TIME [epoch: 8.24 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022586031893701605		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.022586031893701605 | validation: 0.024659953433658656]
	TIME [epoch: 8.23 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353981544298776		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.03353981544298776 | validation: 0.019067773156193117]
	TIME [epoch: 8.23 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02329536164324342		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.02329536164324342 | validation: 0.021180151990813086]
	TIME [epoch: 8.24 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975902611395282		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.03975902611395282 | validation: 0.04727491282737114]
	TIME [epoch: 8.27 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027776443359759047		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.027776443359759047 | validation: 0.022785975795096898]
	TIME [epoch: 8.25 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025424068078617225		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.025424068078617225 | validation: 0.0596316440807314]
	TIME [epoch: 8.23 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0374805088788126		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.0374805088788126 | validation: 0.017975057028356736]
	TIME [epoch: 8.23 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023456934330102774		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.023456934330102774 | validation: 0.024138603994295686]
	TIME [epoch: 8.23 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031289852233010305		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.031289852233010305 | validation: 0.024953211492172767]
	TIME [epoch: 8.23 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044779429756220845		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.044779429756220845 | validation: 0.027569899858846048]
	TIME [epoch: 8.28 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698585532718409		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.01698585532718409 | validation: 0.017344787525515867]
	TIME [epoch: 8.24 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027381403562605558		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.027381403562605558 | validation: 0.04129939390805505]
	TIME [epoch: 8.23 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032286330220222495		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.032286330220222495 | validation: 0.0316037447205513]
	TIME [epoch: 8.23 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023349437464894863		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.023349437464894863 | validation: 0.023987609788736167]
	TIME [epoch: 8.23 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306457503449013		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.03306457503449013 | validation: 0.027849241606533737]
	TIME [epoch: 8.26 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027842402844540884		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.027842402844540884 | validation: 0.020361261762159123]
	TIME [epoch: 8.27 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026507521288275715		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.026507521288275715 | validation: 0.02385715319620753]
	TIME [epoch: 8.23 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246167378728761		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.03246167378728761 | validation: 0.03784132380794619]
	TIME [epoch: 8.24 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024423834557359882		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.024423834557359882 | validation: 0.018718411878266672]
	TIME [epoch: 8.23 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493411019443001		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.04493411019443001 | validation: 0.05709236325392322]
	TIME [epoch: 8.23 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02655122572322218		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.02655122572322218 | validation: 0.01693250514088332]
	TIME [epoch: 8.28 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114048085911981		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.02114048085911981 | validation: 0.035465374476588596]
	TIME [epoch: 8.24 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549738133129357		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.04549738133129357 | validation: 0.016473258431401426]
	TIME [epoch: 8.23 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01713125803532424		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.01713125803532424 | validation: 0.02177871424148828]
	TIME [epoch: 8.24 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199700475194777		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.0199700475194777 | validation: 0.02376846090713254]
	TIME [epoch: 8.23 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199580175837057		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.02199580175837057 | validation: 0.02543370956574305]
	TIME [epoch: 8.24 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03809878973059474		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.03809878973059474 | validation: 0.02230447515608666]
	TIME [epoch: 8.28 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021794964350344788		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.021794964350344788 | validation: 0.031302230117513895]
	TIME [epoch: 8.23 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031197802140697454		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.031197802140697454 | validation: 0.03127815606692797]
	TIME [epoch: 8.23 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027536431187049237		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.027536431187049237 | validation: 0.02610948748473735]
	TIME [epoch: 8.23 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022135435100515403		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.022135435100515403 | validation: 0.02288279116123822]
	TIME [epoch: 8.23 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046567550159074766		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.046567550159074766 | validation: 0.03293331091022856]
	TIME [epoch: 8.27 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019555709916509956		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.019555709916509956 | validation: 0.02760598788213869]
	TIME [epoch: 8.24 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408169559675643		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.02408169559675643 | validation: 0.019118347332753527]
	TIME [epoch: 8.23 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02164232020962982		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.02164232020962982 | validation: 0.01781097143303781]
	TIME [epoch: 8.24 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0305089610557878		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.0305089610557878 | validation: 0.026983501854872877]
	TIME [epoch: 8.23 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028955316218380354		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.028955316218380354 | validation: 0.023047890344139822]
	TIME [epoch: 8.23 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019691263036148675		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.019691263036148675 | validation: 0.018804206555967068]
	TIME [epoch: 8.28 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021496909794579452		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.021496909794579452 | validation: 0.03284562627626929]
	TIME [epoch: 8.24 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387479965314443		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.0387479965314443 | validation: 0.01539834904521166]
	TIME [epoch: 8.23 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018073805945718793		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.018073805945718793 | validation: 0.02356907363552784]
	TIME [epoch: 8.24 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207000075011976		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.02207000075011976 | validation: 0.02498822321823998]
	TIME [epoch: 8.23 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024211045423113434		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.024211045423113434 | validation: 0.03486541949904212]
	TIME [epoch: 8.26 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030200560755045146		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.030200560755045146 | validation: 0.033479248120690475]
	TIME [epoch: 8.25 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019235838317595372		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.019235838317595372 | validation: 0.025346489890751063]
	TIME [epoch: 8.23 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03865139360599543		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.03865139360599543 | validation: 0.010751793791960902]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026340634963889192		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.026340634963889192 | validation: 0.037206494576465673]
	TIME [epoch: 8.23 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02727556121497034		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.02727556121497034 | validation: 0.024560930283116855]
	TIME [epoch: 8.23 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025716849858117015		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.025716849858117015 | validation: 0.01876872702905149]
	TIME [epoch: 8.27 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014013037402874039		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.014013037402874039 | validation: 0.018865573447053238]
	TIME [epoch: 8.22 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025960790765013494		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.025960790765013494 | validation: 0.029378819377373237]
	TIME [epoch: 8.23 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031238807222256273		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.031238807222256273 | validation: 0.026373723542696008]
	TIME [epoch: 8.23 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02528990914876376		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.02528990914876376 | validation: 0.018629784396593935]
	TIME [epoch: 8.22 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025093408184768195		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.025093408184768195 | validation: 0.025347193648842123]
	TIME [epoch: 8.25 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021959414178637286		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.021959414178637286 | validation: 0.020626866163944414]
	TIME [epoch: 8.25 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017479687974760266		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.017479687974760266 | validation: 0.023522775237941124]
	TIME [epoch: 8.23 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023275067282418956		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.023275067282418956 | validation: 0.03448272683289555]
	TIME [epoch: 8.23 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042344768532137846		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.042344768532137846 | validation: 0.014072069578670422]
	TIME [epoch: 8.23 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594605899222648		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.06594605899222648 | validation: 0.02896415722839419]
	TIME [epoch: 8.22 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02050374340265393		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.02050374340265393 | validation: 0.016762376213401254]
	TIME [epoch: 8.27 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026501301785365874		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.026501301785365874 | validation: 0.03352675361731371]
	TIME [epoch: 8.24 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022100024918994855		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.022100024918994855 | validation: 0.02178562811952995]
	TIME [epoch: 8.23 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01964991887167627		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.01964991887167627 | validation: 0.01734024199484152]
	TIME [epoch: 8.23 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022112804469777085		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.022112804469777085 | validation: 0.021154886285386667]
	TIME [epoch: 8.23 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258030571727138		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.05258030571727138 | validation: 0.035621774150304056]
	TIME [epoch: 8.24 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01821731513711261		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.01821731513711261 | validation: 0.01831708606158432]
	TIME [epoch: 8.27 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014670414249441667		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.014670414249441667 | validation: 0.013227548866090993]
	TIME [epoch: 8.23 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615955780343525		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.01615955780343525 | validation: 0.037720719179248734]
	TIME [epoch: 8.23 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031621980419944365		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.031621980419944365 | validation: 0.017506620246779417]
	TIME [epoch: 8.23 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020972700445240137		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.020972700445240137 | validation: 0.023645523752864307]
	TIME [epoch: 8.23 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234622208572309		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.0234622208572309 | validation: 0.019644821930171197]
	TIME [epoch: 8.26 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015903091418386733		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.015903091418386733 | validation: 0.016020848841957227]
	TIME [epoch: 8.25 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01983796800694267		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.01983796800694267 | validation: 0.019800633593204282]
	TIME [epoch: 8.23 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344047635592368		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.05344047635592368 | validation: 0.03394679765483326]
	TIME [epoch: 8.23 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020407589836176184		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.020407589836176184 | validation: 0.010679554138178199]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1135.pth
	Model improved!!!
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01883946997022652		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.01883946997022652 | validation: 0.021440756992762572]
	TIME [epoch: 8.23 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720570462109353		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.08720570462109353 | validation: 0.06770172020732684]
	TIME [epoch: 8.27 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857540397480579		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.04857540397480579 | validation: 0.026069640763520887]
	TIME [epoch: 8.22 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02134897666686838		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.02134897666686838 | validation: 0.030858521115493993]
	TIME [epoch: 8.22 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023313637026724357		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.023313637026724357 | validation: 0.02139153044900258]
	TIME [epoch: 8.23 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019151476143224953		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.019151476143224953 | validation: 0.02236618624425442]
	TIME [epoch: 8.22 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0209573428726784		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.0209573428726784 | validation: 0.021637238030394523]
	TIME [epoch: 8.25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014691085926097702		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.014691085926097702 | validation: 0.022463879945463637]
	TIME [epoch: 8.24 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025771055174481253		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.025771055174481253 | validation: 0.03420929997822418]
	TIME [epoch: 8.22 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026746738327352103		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.026746738327352103 | validation: 0.03443289135465521]
	TIME [epoch: 8.23 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017474238588335394		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.017474238588335394 | validation: 0.012127457043162607]
	TIME [epoch: 8.22 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211630656697536		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.0211630656697536 | validation: 0.030321002959751014]
	TIME [epoch: 8.22 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022298380784848554		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.022298380784848554 | validation: 0.028393704994534946]
	TIME [epoch: 8.27 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022006857262513113		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.022006857262513113 | validation: 0.025884869636052094]
	TIME [epoch: 8.23 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025861310463323493		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.025861310463323493 | validation: 0.024812301267110568]
	TIME [epoch: 8.23 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01963163485507819		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.01963163485507819 | validation: 0.01722663615310315]
	TIME [epoch: 8.24 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02035114912589099		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.02035114912589099 | validation: 0.055824861806214515]
	TIME [epoch: 8.23 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0284083859373612		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.0284083859373612 | validation: 0.02037568445849005]
	TIME [epoch: 8.23 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029797275615857363		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.029797275615857363 | validation: 0.0309918441125897]
	TIME [epoch: 8.26 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021263005070489394		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.021263005070489394 | validation: 0.01444578121954362]
	TIME [epoch: 8.22 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07311432956067841		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.07311432956067841 | validation: 0.023929732893598975]
	TIME [epoch: 8.22 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013111682914757282		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.013111682914757282 | validation: 0.008579508080302462]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1157.pth
	Model improved!!!
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01005900078868388		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.01005900078868388 | validation: 0.021057531289296494]
	TIME [epoch: 8.22 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02611853128809536		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.02611853128809536 | validation: 0.01863319644214923]
	TIME [epoch: 8.26 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01673723345196665		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.01673723345196665 | validation: 0.020994365997502762]
	TIME [epoch: 8.23 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021520543763773537		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.021520543763773537 | validation: 0.010269285911760451]
	TIME [epoch: 8.22 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011938518146860762		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.011938518146860762 | validation: 0.06582394474707354]
	TIME [epoch: 8.22 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855978855987408		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.03855978855987408 | validation: 0.016842149325005724]
	TIME [epoch: 8.22 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172084160583307		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.0172084160583307 | validation: 0.024175429151562]
	TIME [epoch: 8.23 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019692121711612783		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.019692121711612783 | validation: 0.014371998630469222]
	TIME [epoch: 8.25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010704044354735744		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.010704044354735744 | validation: 0.013047383321040655]
	TIME [epoch: 8.22 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011986337619470919		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.011986337619470919 | validation: 0.03138840634690022]
	TIME [epoch: 8.22 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153987681923489		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.03153987681923489 | validation: 0.02751239844741812]
	TIME [epoch: 8.23 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118812313934301		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.02118812313934301 | validation: 0.018771690533425367]
	TIME [epoch: 8.22 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016939803645565125		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.016939803645565125 | validation: 0.01727551489304219]
	TIME [epoch: 8.26 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021095951162377745		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.021095951162377745 | validation: 0.0239181643423651]
	TIME [epoch: 8.23 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027329168713811962		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.027329168713811962 | validation: 0.015244133903346902]
	TIME [epoch: 8.22 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013640537029894817		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.013640537029894817 | validation: 0.011204774371404222]
	TIME [epoch: 8.22 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020738406990670585		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.020738406990670585 | validation: 0.11049485608243605]
	TIME [epoch: 8.22 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034820488330140655		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.034820488330140655 | validation: 0.009786593266926021]
	TIME [epoch: 8.22 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01270472043687167		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.01270472043687167 | validation: 0.026767050863077818]
	TIME [epoch: 8.26 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02229653948651844		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.02229653948651844 | validation: 0.012094704068754056]
	TIME [epoch: 8.22 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016157232246985093		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.016157232246985093 | validation: 0.025353772842504587]
	TIME [epoch: 8.22 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966574103973883		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.02966574103973883 | validation: 0.014226924892854391]
	TIME [epoch: 8.22 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017404463682264962		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.017404463682264962 | validation: 0.03213150504023626]
	TIME [epoch: 8.22 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017709362118214184		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.017709362118214184 | validation: 0.015760489982641762]
	TIME [epoch: 8.24 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594206586301975		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.015594206586301975 | validation: 0.02275837671172836]
	TIME [epoch: 8.25 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01835406329823761		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.01835406329823761 | validation: 0.020458077198903947]
	TIME [epoch: 8.22 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024063229525504336		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.024063229525504336 | validation: 0.01413887959629134]
	TIME [epoch: 8.23 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282853232744892		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.03282853232744892 | validation: 0.01689189673092522]
	TIME [epoch: 8.22 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014279953442616749		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.014279953442616749 | validation: 0.01868800562097759]
	TIME [epoch: 8.22 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020651799311426144		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.020651799311426144 | validation: 0.016819191787096878]
	TIME [epoch: 8.27 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017622608792106413		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.017622608792106413 | validation: 0.019120777997467954]
	TIME [epoch: 8.23 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01804012143211048		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.01804012143211048 | validation: 0.013284193032119817]
	TIME [epoch: 8.22 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010550366452523196		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.010550366452523196 | validation: 0.011056228500285998]
	TIME [epoch: 8.22 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02055874973369746		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.02055874973369746 | validation: 0.0250515655610316]
	TIME [epoch: 8.23 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021929698453911253		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.021929698453911253 | validation: 0.030731047798842493]
	TIME [epoch: 8.22 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016996247103008164		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.016996247103008164 | validation: 0.01832052920464168]
	TIME [epoch: 8.26 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022340587895787807		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.022340587895787807 | validation: 0.029903933540375766]
	TIME [epoch: 8.22 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01887215668716177		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.01887215668716177 | validation: 0.01201704728339958]
	TIME [epoch: 8.22 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009918593525588505		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.009918593525588505 | validation: 0.018713943180407006]
	TIME [epoch: 8.22 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021983512218387395		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.021983512218387395 | validation: 0.022823715448986936]
	TIME [epoch: 8.22 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021702968802348788		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.021702968802348788 | validation: 0.018307680694955218]
	TIME [epoch: 8.26 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020534586874633415		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.020534586874633415 | validation: 0.07279860094945262]
	TIME [epoch: 8.23 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02406231545137969		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.02406231545137969 | validation: 0.014461159937025892]
	TIME [epoch: 8.22 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014697240838112208		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.014697240838112208 | validation: 0.022843939808623065]
	TIME [epoch: 8.22 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021999492701075127		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.021999492701075127 | validation: 0.021055309463982916]
	TIME [epoch: 8.22 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014068801591524594		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.014068801591524594 | validation: 0.02923486233091243]
	TIME [epoch: 8.23 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01840098791662028		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.01840098791662028 | validation: 0.028641031402802643]
	TIME [epoch: 8.26 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023674066955725954		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.023674066955725954 | validation: 0.020791136125150794]
	TIME [epoch: 8.22 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018703137346897533		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.018703137346897533 | validation: 0.02004237069214289]
	TIME [epoch: 8.22 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016943379040489325		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.016943379040489325 | validation: 0.01468344225386366]
	TIME [epoch: 8.22 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014522788208316116		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.014522788208316116 | validation: 0.03088453280829141]
	TIME [epoch: 8.22 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020151355904927386		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.020151355904927386 | validation: 0.016961291409896554]
	TIME [epoch: 8.24 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015518999665930771		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.015518999665930771 | validation: 0.027139066189804252]
	TIME [epoch: 8.25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030583991301411654		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.030583991301411654 | validation: 0.012565956005690524]
	TIME [epoch: 8.22 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009496898503570706		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.009496898503570706 | validation: 0.016052368289472315]
	TIME [epoch: 8.22 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016485849629240545		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.016485849629240545 | validation: 0.02248769937690724]
	TIME [epoch: 8.22 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801464903734984		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.01801464903734984 | validation: 0.02110879492146695]
	TIME [epoch: 8.22 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022460540358880912		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.022460540358880912 | validation: 0.012288170309206026]
	TIME [epoch: 8.26 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010449180488400045		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.010449180488400045 | validation: 0.015058663441473986]
	TIME [epoch: 8.22 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0261984203378184		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.0261984203378184 | validation: 0.02864975592571688]
	TIME [epoch: 8.21 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014896400532518159		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.014896400532518159 | validation: 0.007942559226136802]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1218.pth
	Model improved!!!
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010330993703920807		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.010330993703920807 | validation: 0.027374545697489868]
	TIME [epoch: 8.23 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025428471548450803		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.025428471548450803 | validation: 0.015743598700567477]
	TIME [epoch: 8.24 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666364000814266		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.01666364000814266 | validation: 0.013550669915225936]
	TIME [epoch: 8.24 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009252577242162482		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.009252577242162482 | validation: 0.010337767033217062]
	TIME [epoch: 8.22 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009972440256950935		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.009972440256950935 | validation: 0.017468540578238944]
	TIME [epoch: 8.22 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019992307952141568		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.019992307952141568 | validation: 0.031907436314969354]
	TIME [epoch: 8.22 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02101446617371158		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.02101446617371158 | validation: 0.006612570574252193]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1225.pth
	Model improved!!!
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007540860250716255		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.007540860250716255 | validation: 0.017647840783898028]
	TIME [epoch: 8.27 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02206696091555522		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.02206696091555522 | validation: 0.026462242069711657]
	TIME [epoch: 8.24 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022046648354827888		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.022046648354827888 | validation: 0.011707332513093506]
	TIME [epoch: 8.23 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014344950214144848		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.014344950214144848 | validation: 0.019440062284331285]
	TIME [epoch: 8.23 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02343694216653468		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.02343694216653468 | validation: 0.01281954784483134]
	TIME [epoch: 8.24 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01649769950873818		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.01649769950873818 | validation: 0.015718798343783858]
	TIME [epoch: 8.25 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013515350710270838		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.013515350710270838 | validation: 0.013066257036674184]
	TIME [epoch: 8.27 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0163977170284329		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.0163977170284329 | validation: 0.010168509792216179]
	TIME [epoch: 8.23 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010748228918262631		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.010748228918262631 | validation: 0.014982111101153644]
	TIME [epoch: 8.24 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01861261305172379		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.01861261305172379 | validation: 0.0180452320339966]
	TIME [epoch: 8.23 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02452137932535193		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.02452137932535193 | validation: 0.02345501901811698]
	TIME [epoch: 8.24 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017518014789437056		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.017518014789437056 | validation: 0.011867715054066169]
	TIME [epoch: 8.27 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012809703835766812		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.012809703835766812 | validation: 0.016787560624488454]
	TIME [epoch: 8.24 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019284978904508338		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.019284978904508338 | validation: 0.015773587515569266]
	TIME [epoch: 8.23 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009717326494681393		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.009717326494681393 | validation: 0.009673651069699514]
	TIME [epoch: 8.23 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652978997191364		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.01652978997191364 | validation: 0.0290635010809197]
	TIME [epoch: 8.23 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015753036662569872		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.015753036662569872 | validation: 0.017455963411950753]
	TIME [epoch: 8.24 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009599647154371975		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.009599647154371975 | validation: 0.016468715833880702]
	TIME [epoch: 8.27 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015019990302445267		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.015019990302445267 | validation: 0.017460669433335067]
	TIME [epoch: 8.24 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023567363974406723		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.023567363974406723 | validation: 0.03982390804276163]
	TIME [epoch: 8.23 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023058201066118382		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.023058201066118382 | validation: 0.00815117536558553]
	TIME [epoch: 8.23 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007874890029595813		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.007874890029595813 | validation: 0.013963273342393046]
	TIME [epoch: 8.23 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014530534406636425		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.014530534406636425 | validation: 0.017666819147716763]
	TIME [epoch: 8.26 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011164936091701733		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.011164936091701733 | validation: 0.0097281897124608]
	TIME [epoch: 8.25 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012450258429492421		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.012450258429492421 | validation: 0.02583580463983348]
	TIME [epoch: 8.23 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232766806591823		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.03232766806591823 | validation: 0.015615589079814984]
	TIME [epoch: 8.23 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009675070343556472		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.009675070343556472 | validation: 0.007154043053174481]
	TIME [epoch: 8.23 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006549629859185185		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.006549629859185185 | validation: 0.01149990679672714]
	TIME [epoch: 8.24 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022985155365187866		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.022985155365187866 | validation: 0.014602752776359362]
	TIME [epoch: 8.28 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012617739218062623		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.012617739218062623 | validation: 0.011839237416615927]
	TIME [epoch: 8.23 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661456636649572		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.01661456636649572 | validation: 0.014928791654662685]
	TIME [epoch: 8.23 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01294124818758184		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.01294124818758184 | validation: 0.013966553772505517]
	TIME [epoch: 8.23 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017697852070654153		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.017697852070654153 | validation: 0.010900393733502912]
	TIME [epoch: 8.23 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010641373513679803		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.010641373513679803 | validation: 0.013870046757280662]
	TIME [epoch: 8.26 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022952007492698927		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.022952007492698927 | validation: 0.020144718904300217]
	TIME [epoch: 8.26 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009382869450413346		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.009382869450413346 | validation: 0.0069079964670306125]
	TIME [epoch: 8.23 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012105188322807749		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.012105188322807749 | validation: 0.00861939608215365]
	TIME [epoch: 8.23 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017551039657527117		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.017551039657527117 | validation: 0.016013993359889366]
	TIME [epoch: 8.23 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01523880001533754		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.01523880001533754 | validation: 0.014915765043615536]
	TIME [epoch: 8.23 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015833541044849943		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.015833541044849943 | validation: 0.010666198277060257]
	TIME [epoch: 8.27 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009819610508497188		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.009819610508497188 | validation: 0.014493512449601358]
	TIME [epoch: 8.24 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02148027639271421		[learning rate: 0.0057381]
	Learning Rate: 0.00573812
	LOSS [training: 0.02148027639271421 | validation: 0.012543417496740402]
	TIME [epoch: 8.23 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011502173509421289		[learning rate: 0.0057232]
	Learning Rate: 0.00572318
	LOSS [training: 0.011502173509421289 | validation: 0.013029722361272714]
	TIME [epoch: 8.23 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022633384589570902		[learning rate: 0.0057083]
	Learning Rate: 0.00570826
	LOSS [training: 0.022633384589570902 | validation: 0.00740116107835813]
	TIME [epoch: 8.23 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011891215690557443		[learning rate: 0.0056933]
	Learning Rate: 0.00569334
	LOSS [training: 0.011891215690557443 | validation: 0.008911141065655461]
	TIME [epoch: 8.24 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01200073888377439		[learning rate: 0.0056784]
	Learning Rate: 0.00567844
	LOSS [training: 0.01200073888377439 | validation: 0.020259027255762993]
	TIME [epoch: 8.27 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01894879429729913		[learning rate: 0.0056635]
	Learning Rate: 0.00566355
	LOSS [training: 0.01894879429729913 | validation: 0.014008888148789483]
	TIME [epoch: 8.24 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00896618783954815		[learning rate: 0.0056487]
	Learning Rate: 0.00564867
	LOSS [training: 0.00896618783954815 | validation: 0.008254599001226656]
	TIME [epoch: 8.23 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009043455178969978		[learning rate: 0.0056338]
	Learning Rate: 0.0056338
	LOSS [training: 0.009043455178969978 | validation: 0.015867288988759273]
	TIME [epoch: 8.24 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018708498477167067		[learning rate: 0.0056189]
	Learning Rate: 0.00561894
	LOSS [training: 0.018708498477167067 | validation: 0.014298931167039668]
	TIME [epoch: 8.23 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01726281512695055		[learning rate: 0.0056041]
	Learning Rate: 0.0056041
	LOSS [training: 0.01726281512695055 | validation: 0.010767881529644776]
	TIME [epoch: 8.27 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010179694526736026		[learning rate: 0.0055893]
	Learning Rate: 0.00558927
	LOSS [training: 0.010179694526736026 | validation: 0.007908526518977018]
	TIME [epoch: 8.25 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009927444285092598		[learning rate: 0.0055744]
	Learning Rate: 0.00557445
	LOSS [training: 0.009927444285092598 | validation: 0.021713182246273787]
	TIME [epoch: 8.23 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018983874695569825		[learning rate: 0.0055596]
	Learning Rate: 0.00555964
	LOSS [training: 0.018983874695569825 | validation: 0.009700680685101326]
	TIME [epoch: 8.23 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011548515628053169		[learning rate: 0.0055448]
	Learning Rate: 0.00554484
	LOSS [training: 0.011548515628053169 | validation: 0.013560997505621768]
	TIME [epoch: 8.24 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014930494946850198		[learning rate: 0.0055301]
	Learning Rate: 0.00553006
	LOSS [training: 0.014930494946850198 | validation: 0.02397204738197812]
	TIME [epoch: 8.35 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015552439077904753		[learning rate: 0.0055153]
	Learning Rate: 0.00551529
	LOSS [training: 0.015552439077904753 | validation: 0.00994245486793773]
	TIME [epoch: 8.28 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010286169271403224		[learning rate: 0.0055005]
	Learning Rate: 0.00550053
	LOSS [training: 0.010286169271403224 | validation: 0.023466734994917242]
	TIME [epoch: 8.24 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01748403397425679		[learning rate: 0.0054858]
	Learning Rate: 0.00548578
	LOSS [training: 0.01748403397425679 | validation: 0.014803884538446898]
	TIME [epoch: 8.23 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014805675243341497		[learning rate: 0.005471]
	Learning Rate: 0.00547105
	LOSS [training: 0.014805675243341497 | validation: 0.014076343260163262]
	TIME [epoch: 8.24 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009174197559306629		[learning rate: 0.0054563]
	Learning Rate: 0.00545632
	LOSS [training: 0.009174197559306629 | validation: 0.007741870610749926]
	TIME [epoch: 8.23 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010041411640539996		[learning rate: 0.0054416]
	Learning Rate: 0.00544161
	LOSS [training: 0.010041411640539996 | validation: 0.015856323995695778]
	TIME [epoch: 8.23 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850645444645118		[learning rate: 0.0054269]
	Learning Rate: 0.00542692
	LOSS [training: 0.01850645444645118 | validation: 0.012092013768657052]
	TIME [epoch: 8.26 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011713057507171831		[learning rate: 0.0054122]
	Learning Rate: 0.00541223
	LOSS [training: 0.011713057507171831 | validation: 0.022865693486600967]
	TIME [epoch: 8.23 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287775022969039		[learning rate: 0.0053976]
	Learning Rate: 0.00539756
	LOSS [training: 0.03287775022969039 | validation: 0.02174966964240154]
	TIME [epoch: 8.23 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012331573573709469		[learning rate: 0.0053829]
	Learning Rate: 0.0053829
	LOSS [training: 0.012331573573709469 | validation: 0.00903953590799531]
	TIME [epoch: 8.23 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012754376235395076		[learning rate: 0.0053683]
	Learning Rate: 0.00536825
	LOSS [training: 0.012754376235395076 | validation: 0.01174729309662715]
	TIME [epoch: 8.23 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010032613467664353		[learning rate: 0.0053536]
	Learning Rate: 0.00535362
	LOSS [training: 0.010032613467664353 | validation: 0.011975555642312778]
	TIME [epoch: 8.28 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00836541983677655		[learning rate: 0.005339]
	Learning Rate: 0.005339
	LOSS [training: 0.00836541983677655 | validation: 0.008935891981482608]
	TIME [epoch: 8.24 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00803085980605502		[learning rate: 0.0053244]
	Learning Rate: 0.00532439
	LOSS [training: 0.00803085980605502 | validation: 0.019816473748222804]
	TIME [epoch: 8.23 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019285278367930446		[learning rate: 0.0053098]
	Learning Rate: 0.00530979
	LOSS [training: 0.019285278367930446 | validation: 0.011979461826523704]
	TIME [epoch: 8.23 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011911940046018154		[learning rate: 0.0052952]
	Learning Rate: 0.00529521
	LOSS [training: 0.011911940046018154 | validation: 0.010956217607069954]
	TIME [epoch: 8.23 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011727321354461258		[learning rate: 0.0052806]
	Learning Rate: 0.00528064
	LOSS [training: 0.011727321354461258 | validation: 0.013999521239705076]
	TIME [epoch: 8.24 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010445192693081144		[learning rate: 0.0052661]
	Learning Rate: 0.00526608
	LOSS [training: 0.010445192693081144 | validation: 0.008672340818361973]
	TIME [epoch: 8.27 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009984987057885853		[learning rate: 0.0052515]
	Learning Rate: 0.00525154
	LOSS [training: 0.009984987057885853 | validation: 0.01127132746137955]
	TIME [epoch: 8.23 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030430034386262763		[learning rate: 0.005237]
	Learning Rate: 0.00523701
	LOSS [training: 0.030430034386262763 | validation: 0.013297985299031166]
	TIME [epoch: 8.22 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00798982314068195		[learning rate: 0.0052225]
	Learning Rate: 0.00522249
	LOSS [training: 0.00798982314068195 | validation: 0.008294727130591019]
	TIME [epoch: 8.22 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070313437125524856		[learning rate: 0.005208]
	Learning Rate: 0.00520799
	LOSS [training: 0.0070313437125524856 | validation: 0.008218091437857579]
	TIME [epoch: 8.22 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011670267644619361		[learning rate: 0.0051935]
	Learning Rate: 0.00519349
	LOSS [training: 0.011670267644619361 | validation: 0.016646197276000866]
	TIME [epoch: 8.25 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012123941657661699		[learning rate: 0.005179]
	Learning Rate: 0.00517901
	LOSS [training: 0.012123941657661699 | validation: 0.017872145322840996]
	TIME [epoch: 8.23 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01376322849664676		[learning rate: 0.0051645]
	Learning Rate: 0.00516455
	LOSS [training: 0.01376322849664676 | validation: 0.01022159451471785]
	TIME [epoch: 8.22 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011140867750676435		[learning rate: 0.0051501]
	Learning Rate: 0.0051501
	LOSS [training: 0.011140867750676435 | validation: 0.012345086641843615]
	TIME [epoch: 8.22 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011113470800078979		[learning rate: 0.0051357]
	Learning Rate: 0.00513566
	LOSS [training: 0.011113470800078979 | validation: 0.011839469856302274]
	TIME [epoch: 8.23 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01063980751018398		[learning rate: 0.0051212]
	Learning Rate: 0.00512123
	LOSS [training: 0.01063980751018398 | validation: 0.00990264688258583]
	TIME [epoch: 8.23 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014470281825481471		[learning rate: 0.0051068]
	Learning Rate: 0.00510682
	LOSS [training: 0.014470281825481471 | validation: 0.013544770147991611]
	TIME [epoch: 8.27 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008614754454377411		[learning rate: 0.0050924]
	Learning Rate: 0.00509242
	LOSS [training: 0.008614754454377411 | validation: 0.007681493990056638]
	TIME [epoch: 8.23 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012328368487544906		[learning rate: 0.005078]
	Learning Rate: 0.00507803
	LOSS [training: 0.012328368487544906 | validation: 0.026915630570406614]
	TIME [epoch: 8.23 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017263670869645593		[learning rate: 0.0050637]
	Learning Rate: 0.00506366
	LOSS [training: 0.017263670869645593 | validation: 0.008646985905567978]
	TIME [epoch: 8.23 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012006985284385392		[learning rate: 0.0050493]
	Learning Rate: 0.0050493
	LOSS [training: 0.012006985284385392 | validation: 0.013006960030100146]
	TIME [epoch: 8.23 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015195306468076762		[learning rate: 0.005035]
	Learning Rate: 0.00503496
	LOSS [training: 0.015195306468076762 | validation: 0.012422384125924998]
	TIME [epoch: 8.26 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01087249580262149		[learning rate: 0.0050206]
	Learning Rate: 0.00502063
	LOSS [training: 0.01087249580262149 | validation: 0.008233806303395663]
	TIME [epoch: 8.23 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007575570252743628		[learning rate: 0.0050063]
	Learning Rate: 0.00500631
	LOSS [training: 0.007575570252743628 | validation: 0.018123746436428896]
	TIME [epoch: 8.22 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018264532980005355		[learning rate: 0.004992]
	Learning Rate: 0.004992
	LOSS [training: 0.018264532980005355 | validation: 0.01193319323336521]
	TIME [epoch: 8.22 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00992587678321081		[learning rate: 0.0049777]
	Learning Rate: 0.00497771
	LOSS [training: 0.00992587678321081 | validation: 0.01127456952484477]
	TIME [epoch: 8.23 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01006033780324734		[learning rate: 0.0049634]
	Learning Rate: 0.00496344
	LOSS [training: 0.01006033780324734 | validation: 0.008642107861107149]
	TIME [epoch: 8.22 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013374614653111903		[learning rate: 0.0049492]
	Learning Rate: 0.00494917
	LOSS [training: 0.013374614653111903 | validation: 0.015462664951354305]
	TIME [epoch: 8.26 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011784339526170483		[learning rate: 0.0049349]
	Learning Rate: 0.00493492
	LOSS [training: 0.011784339526170483 | validation: 0.007966198026960091]
	TIME [epoch: 8.23 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077892610710772565		[learning rate: 0.0049207]
	Learning Rate: 0.00492069
	LOSS [training: 0.0077892610710772565 | validation: 0.011478565301845347]
	TIME [epoch: 8.22 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012535779321465068		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.012535779321465068 | validation: 0.009073727279738954]
	TIME [epoch: 8.22 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011620351000210787		[learning rate: 0.0048923]
	Learning Rate: 0.00489226
	LOSS [training: 0.011620351000210787 | validation: 0.018108944254954212]
	TIME [epoch: 8.22 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011049384237317706		[learning rate: 0.0048781]
	Learning Rate: 0.00487807
	LOSS [training: 0.011049384237317706 | validation: 0.012775637636635393]
	TIME [epoch: 8.25 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015842659006489127		[learning rate: 0.0048639]
	Learning Rate: 0.00486389
	LOSS [training: 0.015842659006489127 | validation: 0.015003531958084328]
	TIME [epoch: 8.26 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880350811052899		[learning rate: 0.0048497]
	Learning Rate: 0.00484972
	LOSS [training: 0.00880350811052899 | validation: 0.014297544496879006]
	TIME [epoch: 8.23 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011521348624636775		[learning rate: 0.0048356]
	Learning Rate: 0.00483557
	LOSS [training: 0.011521348624636775 | validation: 0.007706820193266689]
	TIME [epoch: 8.22 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008702426798280352		[learning rate: 0.0048214]
	Learning Rate: 0.00482143
	LOSS [training: 0.008702426798280352 | validation: 0.014579121145536625]
	TIME [epoch: 8.23 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014346428071716509		[learning rate: 0.0048073]
	Learning Rate: 0.00480731
	LOSS [training: 0.014346428071716509 | validation: 0.016087203455767342]
	TIME [epoch: 8.22 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009071438252960156		[learning rate: 0.0047932]
	Learning Rate: 0.0047932
	LOSS [training: 0.009071438252960156 | validation: 0.012147465481907059]
	TIME [epoch: 8.26 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014519362684380893		[learning rate: 0.0047791]
	Learning Rate: 0.0047791
	LOSS [training: 0.014519362684380893 | validation: 0.01029839219690413]
	TIME [epoch: 8.24 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008111999527296417		[learning rate: 0.004765]
	Learning Rate: 0.00476502
	LOSS [training: 0.008111999527296417 | validation: 0.009174231711875987]
	TIME [epoch: 8.23 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013911685918329569		[learning rate: 0.004751]
	Learning Rate: 0.00475096
	LOSS [training: 0.013911685918329569 | validation: 0.012893500311067476]
	TIME [epoch: 8.23 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010552885283331204		[learning rate: 0.0047369]
	Learning Rate: 0.00473691
	LOSS [training: 0.010552885283331204 | validation: 0.006802688342563937]
	TIME [epoch: 8.22 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006539648681780792		[learning rate: 0.0047229]
	Learning Rate: 0.00472287
	LOSS [training: 0.006539648681780792 | validation: 0.0140052842905399]
	TIME [epoch: 8.23 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018792336113926996		[learning rate: 0.0047088]
	Learning Rate: 0.00470885
	LOSS [training: 0.018792336113926996 | validation: 0.00906775978134687]
	TIME [epoch: 8.25 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007097306049221541		[learning rate: 0.0046948]
	Learning Rate: 0.00469484
	LOSS [training: 0.007097306049221541 | validation: 0.010624763500787497]
	TIME [epoch: 8.23 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011313619892694395		[learning rate: 0.0046808]
	Learning Rate: 0.00468084
	LOSS [training: 0.011313619892694395 | validation: 0.026524384737317788]
	TIME [epoch: 8.22 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01728940155858673		[learning rate: 0.0046669]
	Learning Rate: 0.00466686
	LOSS [training: 0.01728940155858673 | validation: 0.006710439575376275]
	TIME [epoch: 8.22 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012783267900145764		[learning rate: 0.0046529]
	Learning Rate: 0.0046529
	LOSS [training: 0.012783267900145764 | validation: 0.013563214816243459]
	TIME [epoch: 8.22 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00747717430199379		[learning rate: 0.0046389]
	Learning Rate: 0.00463895
	LOSS [training: 0.00747717430199379 | validation: 0.006732622773231229]
	TIME [epoch: 8.26 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006335716412410151		[learning rate: 0.004625]
	Learning Rate: 0.00462501
	LOSS [training: 0.006335716412410151 | validation: 0.011565154374607091]
	TIME [epoch: 8.24 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016678558785355447		[learning rate: 0.0046111]
	Learning Rate: 0.00461109
	LOSS [training: 0.016678558785355447 | validation: 0.01586215183007665]
	TIME [epoch: 8.23 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008965079457055247		[learning rate: 0.0045972]
	Learning Rate: 0.00459719
	LOSS [training: 0.008965079457055247 | validation: 0.008693193162467167]
	TIME [epoch: 8.23 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008265462881569478		[learning rate: 0.0045833]
	Learning Rate: 0.0045833
	LOSS [training: 0.008265462881569478 | validation: 0.010661771836678758]
	TIME [epoch: 8.22 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009976064021163893		[learning rate: 0.0045694]
	Learning Rate: 0.00456942
	LOSS [training: 0.009976064021163893 | validation: 0.006612052618277124]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065880517614465865		[learning rate: 0.0045556]
	Learning Rate: 0.00455556
	LOSS [training: 0.0065880517614465865 | validation: 0.01577603864273932]
	TIME [epoch: 8.27 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022527150563426395		[learning rate: 0.0045417]
	Learning Rate: 0.00454171
	LOSS [training: 0.022527150563426395 | validation: 0.009053312871522296]
	TIME [epoch: 8.23 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00709450736942286		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.00709450736942286 | validation: 0.00743802119152901]
	TIME [epoch: 8.22 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00819955098820823		[learning rate: 0.0045141]
	Learning Rate: 0.00451406
	LOSS [training: 0.00819955098820823 | validation: 0.016279447518297206]
	TIME [epoch: 8.22 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012078081672653578		[learning rate: 0.0045003]
	Learning Rate: 0.00450026
	LOSS [training: 0.012078081672653578 | validation: 0.009528941929429602]
	TIME [epoch: 8.22 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010224751441592291		[learning rate: 0.0044865]
	Learning Rate: 0.00448648
	LOSS [training: 0.010224751441592291 | validation: 0.008550760967212918]
	TIME [epoch: 8.24 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014277655374124882		[learning rate: 0.0044727]
	Learning Rate: 0.0044727
	LOSS [training: 0.014277655374124882 | validation: 0.011507393529812848]
	TIME [epoch: 8.24 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0128722347377794		[learning rate: 0.0044589]
	Learning Rate: 0.00445895
	LOSS [training: 0.0128722347377794 | validation: 0.01171865157734233]
	TIME [epoch: 8.22 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009052522591310265		[learning rate: 0.0044452]
	Learning Rate: 0.00444521
	LOSS [training: 0.009052522591310265 | validation: 0.006857514757025544]
	TIME [epoch: 8.22 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009093356376644086		[learning rate: 0.0044315]
	Learning Rate: 0.00443148
	LOSS [training: 0.009093356376644086 | validation: 0.009708697677112414]
	TIME [epoch: 8.22 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010094709964536824		[learning rate: 0.0044178]
	Learning Rate: 0.00441777
	LOSS [training: 0.010094709964536824 | validation: 0.010037306536746185]
	TIME [epoch: 8.19 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009912500840567011		[learning rate: 0.0044041]
	Learning Rate: 0.00440407
	LOSS [training: 0.009912500840567011 | validation: 0.007995589859711327]
	TIME [epoch: 8.22 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011412035463767942		[learning rate: 0.0043904]
	Learning Rate: 0.00439039
	LOSS [training: 0.011412035463767942 | validation: 0.012446880516416016]
	TIME [epoch: 8.19 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012943830652991699		[learning rate: 0.0043767]
	Learning Rate: 0.00437673
	LOSS [training: 0.012943830652991699 | validation: 0.008373828152435477]
	TIME [epoch: 8.18 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007090732352784179		[learning rate: 0.0043631]
	Learning Rate: 0.00436308
	LOSS [training: 0.007090732352784179 | validation: 0.006448307694095842]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1363.pth
	Model improved!!!
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005739842124442684		[learning rate: 0.0043494]
	Learning Rate: 0.00434945
	LOSS [training: 0.005739842124442684 | validation: 0.008752655996785022]
	TIME [epoch: 8.18 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010871030472061661		[learning rate: 0.0043358]
	Learning Rate: 0.00433583
	LOSS [training: 0.010871030472061661 | validation: 0.014985338531821834]
	TIME [epoch: 8.19 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013099194694720182		[learning rate: 0.0043222]
	Learning Rate: 0.00432222
	LOSS [training: 0.013099194694720182 | validation: 0.0130574722915933]
	TIME [epoch: 8.22 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010367966673891416		[learning rate: 0.0043086]
	Learning Rate: 0.00430864
	LOSS [training: 0.010367966673891416 | validation: 0.010525298581833098]
	TIME [epoch: 8.19 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007743291129258027		[learning rate: 0.0042951]
	Learning Rate: 0.00429506
	LOSS [training: 0.007743291129258027 | validation: 0.009363763077848263]
	TIME [epoch: 8.18 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006361743741055469		[learning rate: 0.0042815]
	Learning Rate: 0.00428151
	LOSS [training: 0.006361743741055469 | validation: 0.00869518667379291]
	TIME [epoch: 8.18 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01286694390503423		[learning rate: 0.004268]
	Learning Rate: 0.00426797
	LOSS [training: 0.01286694390503423 | validation: 0.012913740884629923]
	TIME [epoch: 8.19 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009905787789551701		[learning rate: 0.0042544]
	Learning Rate: 0.00425444
	LOSS [training: 0.009905787789551701 | validation: 0.006309008683625523]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1371.pth
	Model improved!!!
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008465763843973545		[learning rate: 0.0042409]
	Learning Rate: 0.00424093
	LOSS [training: 0.008465763843973545 | validation: 0.007859033263945723]
	TIME [epoch: 8.19 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00999238892700313		[learning rate: 0.0042274]
	Learning Rate: 0.00422744
	LOSS [training: 0.00999238892700313 | validation: 0.01386627262930435]
	TIME [epoch: 8.18 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011404082815687859		[learning rate: 0.004214]
	Learning Rate: 0.00421396
	LOSS [training: 0.011404082815687859 | validation: 0.009708969416602691]
	TIME [epoch: 8.18 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00974708469034609		[learning rate: 0.0042005]
	Learning Rate: 0.0042005
	LOSS [training: 0.00974708469034609 | validation: 0.006261074411173909]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1375.pth
	Model improved!!!
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009694706560377723		[learning rate: 0.0041871]
	Learning Rate: 0.00418705
	LOSS [training: 0.009694706560377723 | validation: 0.016077456845329154]
	TIME [epoch: 8.19 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00954435715348524		[learning rate: 0.0041736]
	Learning Rate: 0.00417362
	LOSS [training: 0.00954435715348524 | validation: 0.005687068715052911]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1377.pth
	Model improved!!!
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00823756897168976		[learning rate: 0.0041602]
	Learning Rate: 0.00416021
	LOSS [training: 0.00823756897168976 | validation: 0.013386315654060683]
	TIME [epoch: 8.2 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010735563227280823		[learning rate: 0.0041468]
	Learning Rate: 0.00414681
	LOSS [training: 0.010735563227280823 | validation: 0.012423476023087975]
	TIME [epoch: 8.18 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012223708093939864		[learning rate: 0.0041334]
	Learning Rate: 0.00413343
	LOSS [training: 0.012223708093939864 | validation: 0.010901165114257098]
	TIME [epoch: 8.18 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007575137545959627		[learning rate: 0.0041201]
	Learning Rate: 0.00412006
	LOSS [training: 0.007575137545959627 | validation: 0.005982043535794078]
	TIME [epoch: 8.18 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008418043771666658		[learning rate: 0.0041067]
	Learning Rate: 0.00410671
	LOSS [training: 0.008418043771666658 | validation: 0.010353087392913683]
	TIME [epoch: 8.22 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007678361595259545		[learning rate: 0.0040934]
	Learning Rate: 0.00409338
	LOSS [training: 0.007678361595259545 | validation: 0.005145246581324368]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1383.pth
	Model improved!!!
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009000459424223464		[learning rate: 0.0040801]
	Learning Rate: 0.00408006
	LOSS [training: 0.009000459424223464 | validation: 0.007408679338618485]
	TIME [epoch: 8.19 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011813565347256279		[learning rate: 0.0040668]
	Learning Rate: 0.00406676
	LOSS [training: 0.011813565347256279 | validation: 0.013955562384264503]
	TIME [epoch: 8.19 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008274344698174658		[learning rate: 0.0040535]
	Learning Rate: 0.00405347
	LOSS [training: 0.008274344698174658 | validation: 0.00676735359344008]
	TIME [epoch: 8.2 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005373806057043059		[learning rate: 0.0040402]
	Learning Rate: 0.00404021
	LOSS [training: 0.005373806057043059 | validation: 0.007656379323676581]
	TIME [epoch: 8.22 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015129821478957022		[learning rate: 0.004027]
	Learning Rate: 0.00402695
	LOSS [training: 0.015129821478957022 | validation: 0.012246919980539017]
	TIME [epoch: 8.24 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009767780723177548		[learning rate: 0.0040137]
	Learning Rate: 0.00401372
	LOSS [training: 0.009767780723177548 | validation: 0.005946242057823674]
	TIME [epoch: 8.21 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007087026569531125		[learning rate: 0.0040005]
	Learning Rate: 0.0040005
	LOSS [training: 0.007087026569531125 | validation: 0.008991883125718967]
	TIME [epoch: 8.2 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01002632564243867		[learning rate: 0.0039873]
	Learning Rate: 0.00398729
	LOSS [training: 0.01002632564243867 | validation: 0.0077178092586677885]
	TIME [epoch: 8.19 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007971143051914199		[learning rate: 0.0039741]
	Learning Rate: 0.00397411
	LOSS [training: 0.007971143051914199 | validation: 0.007988577612010796]
	TIME [epoch: 8.19 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006948717056702198		[learning rate: 0.0039609]
	Learning Rate: 0.00396093
	LOSS [training: 0.006948717056702198 | validation: 0.011994320611136856]
	TIME [epoch: 8.23 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011165565004591428		[learning rate: 0.0039478]
	Learning Rate: 0.00394778
	LOSS [training: 0.011165565004591428 | validation: 0.0072830785324813855]
	TIME [epoch: 8.2 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00726738511379824		[learning rate: 0.0039346]
	Learning Rate: 0.00393464
	LOSS [training: 0.00726738511379824 | validation: 0.011514612018887361]
	TIME [epoch: 8.2 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009286587066974609		[learning rate: 0.0039215]
	Learning Rate: 0.00392152
	LOSS [training: 0.009286587066974609 | validation: 0.009981924486547764]
	TIME [epoch: 8.19 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009433297169236732		[learning rate: 0.0039084]
	Learning Rate: 0.00390842
	LOSS [training: 0.009433297169236732 | validation: 0.00681500888962846]
	TIME [epoch: 8.19 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01021011052031822		[learning rate: 0.0038953]
	Learning Rate: 0.00389533
	LOSS [training: 0.01021011052031822 | validation: 0.009415745264256996]
	TIME [epoch: 8.19 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009798783544405738		[learning rate: 0.0038823]
	Learning Rate: 0.00388226
	LOSS [training: 0.009798783544405738 | validation: 0.008699425007180857]
	TIME [epoch: 8.26 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007331962954462956		[learning rate: 0.0038692]
	Learning Rate: 0.0038692
	LOSS [training: 0.007331962954462956 | validation: 0.008929011624049805]
	TIME [epoch: 8.21 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009400221566599764		[learning rate: 0.0038562]
	Learning Rate: 0.00385617
	LOSS [training: 0.009400221566599764 | validation: 0.009611042111365053]
	TIME [epoch: 8.2 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007465132089282359		[learning rate: 0.0038431]
	Learning Rate: 0.00384315
	LOSS [training: 0.007465132089282359 | validation: 0.007223669128458594]
	TIME [epoch: 8.19 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007884160205773412		[learning rate: 0.0038301]
	Learning Rate: 0.00383014
	LOSS [training: 0.007884160205773412 | validation: 0.01339276006827848]
	TIME [epoch: 8.19 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01015773456497216		[learning rate: 0.0038172]
	Learning Rate: 0.00381716
	LOSS [training: 0.01015773456497216 | validation: 0.008997507518322805]
	TIME [epoch: 8.2 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00787451296680718		[learning rate: 0.0038042]
	Learning Rate: 0.00380419
	LOSS [training: 0.00787451296680718 | validation: 0.012320254030623201]
	TIME [epoch: 8.22 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070025352804391205		[learning rate: 0.0037912]
	Learning Rate: 0.00379123
	LOSS [training: 0.0070025352804391205 | validation: 0.011782468696922625]
	TIME [epoch: 8.19 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006779666827533285		[learning rate: 0.0037783]
	Learning Rate: 0.0037783
	LOSS [training: 0.006779666827533285 | validation: 0.0051293181049199416]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1407.pth
	Model improved!!!
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007576785805920491		[learning rate: 0.0037654]
	Learning Rate: 0.00376538
	LOSS [training: 0.007576785805920491 | validation: 0.013929146236991433]
	TIME [epoch: 8.19 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013970775214856469		[learning rate: 0.0037525]
	Learning Rate: 0.00375248
	LOSS [training: 0.013970775214856469 | validation: 0.008235313787746026]
	TIME [epoch: 8.19 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00668597574890855		[learning rate: 0.0037396]
	Learning Rate: 0.00373959
	LOSS [training: 0.00668597574890855 | validation: 0.010803084127641934]
	TIME [epoch: 8.24 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010374889438124226		[learning rate: 0.0037267]
	Learning Rate: 0.00372672
	LOSS [training: 0.010374889438124226 | validation: 0.00580369583893981]
	TIME [epoch: 8.19 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066350786831029605		[learning rate: 0.0037139]
	Learning Rate: 0.00371387
	LOSS [training: 0.0066350786831029605 | validation: 0.0060320933993477915]
	TIME [epoch: 8.19 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007396030373762026		[learning rate: 0.003701]
	Learning Rate: 0.00370104
	LOSS [training: 0.007396030373762026 | validation: 0.010721830048848982]
	TIME [epoch: 8.19 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01013031606104562		[learning rate: 0.0036882]
	Learning Rate: 0.00368822
	LOSS [training: 0.01013031606104562 | validation: 0.011287673286104347]
	TIME [epoch: 8.18 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008207202251352956		[learning rate: 0.0036754]
	Learning Rate: 0.00367542
	LOSS [training: 0.008207202251352956 | validation: 0.009558323749755513]
	TIME [epoch: 8.2 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013328533563012715		[learning rate: 0.0036626]
	Learning Rate: 0.00366264
	LOSS [training: 0.013328533563012715 | validation: 0.00651150580479509]
	TIME [epoch: 8.23 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005950347487290557		[learning rate: 0.0036499]
	Learning Rate: 0.00364988
	LOSS [training: 0.005950347487290557 | validation: 0.010586914805465716]
	TIME [epoch: 8.19 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008312899776866228		[learning rate: 0.0036371]
	Learning Rate: 0.00363713
	LOSS [training: 0.008312899776866228 | validation: 0.009392566282881498]
	TIME [epoch: 8.19 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00862140572440743		[learning rate: 0.0036244]
	Learning Rate: 0.0036244
	LOSS [training: 0.00862140572440743 | validation: 0.008031282192104708]
	TIME [epoch: 8.19 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005911944439696492		[learning rate: 0.0036117]
	Learning Rate: 0.00361169
	LOSS [training: 0.005911944439696492 | validation: 0.005031149713007188]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1420.pth
	Model improved!!!
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004507891325730107		[learning rate: 0.003599]
	Learning Rate: 0.003599
	LOSS [training: 0.004507891325730107 | validation: 0.006003895525125463]
	TIME [epoch: 8.23 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009577485404342447		[learning rate: 0.0035863]
	Learning Rate: 0.00358632
	LOSS [training: 0.009577485404342447 | validation: 0.014377833294388376]
	TIME [epoch: 8.19 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008967213688861844		[learning rate: 0.0035737]
	Learning Rate: 0.00357366
	LOSS [training: 0.008967213688861844 | validation: 0.007858583928752544]
	TIME [epoch: 8.18 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007190157910137647		[learning rate: 0.003561]
	Learning Rate: 0.00356102
	LOSS [training: 0.007190157910137647 | validation: 0.007245346718105805]
	TIME [epoch: 8.21 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006812833503798291		[learning rate: 0.0035484]
	Learning Rate: 0.00354839
	LOSS [training: 0.006812833503798291 | validation: 0.005540484664879996]
	TIME [epoch: 8.19 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011703948431801071		[learning rate: 0.0035358]
	Learning Rate: 0.00353579
	LOSS [training: 0.011703948431801071 | validation: 0.013738998098541809]
	TIME [epoch: 8.19 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009480987066082514		[learning rate: 0.0035232]
	Learning Rate: 0.0035232
	LOSS [training: 0.009480987066082514 | validation: 0.005857499973691102]
	TIME [epoch: 8.22 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00592763244417374		[learning rate: 0.0035106]
	Learning Rate: 0.00351063
	LOSS [training: 0.00592763244417374 | validation: 0.007176007285153577]
	TIME [epoch: 8.18 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007161879591416511		[learning rate: 0.0034981]
	Learning Rate: 0.00349807
	LOSS [training: 0.007161879591416511 | validation: 0.016088675553623987]
	TIME [epoch: 8.18 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01485152623706989		[learning rate: 0.0034855]
	Learning Rate: 0.00348554
	LOSS [training: 0.01485152623706989 | validation: 0.005655127737509324]
	TIME [epoch: 8.18 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004825003582738652		[learning rate: 0.003473]
	Learning Rate: 0.00347302
	LOSS [training: 0.004825003582738652 | validation: 0.0061690155863884984]
	TIME [epoch: 8.18 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006595695470260491		[learning rate: 0.0034605]
	Learning Rate: 0.00346052
	LOSS [training: 0.006595695470260491 | validation: 0.011468396861444328]
	TIME [epoch: 8.21 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008967158203076727		[learning rate: 0.003448]
	Learning Rate: 0.00344804
	LOSS [training: 0.008967158203076727 | validation: 0.005320281139576096]
	TIME [epoch: 8.2 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005791362544669013		[learning rate: 0.0034356]
	Learning Rate: 0.00343557
	LOSS [training: 0.005791362544669013 | validation: 0.005772341405977999]
	TIME [epoch: 8.18 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005120264637573098		[learning rate: 0.0034231]
	Learning Rate: 0.00342313
	LOSS [training: 0.005120264637573098 | validation: 0.005452360311789146]
	TIME [epoch: 8.19 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007303005426801167		[learning rate: 0.0034107]
	Learning Rate: 0.0034107
	LOSS [training: 0.007303005426801167 | validation: 0.010945079931269246]
	TIME [epoch: 8.19 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009348878735251705		[learning rate: 0.0033983]
	Learning Rate: 0.00339829
	LOSS [training: 0.009348878735251705 | validation: 0.016935818982560143]
	TIME [epoch: 8.19 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007946055109290152		[learning rate: 0.0033859]
	Learning Rate: 0.0033859
	LOSS [training: 0.007946055109290152 | validation: 0.009121534537925243]
	TIME [epoch: 8.22 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00580739702883326		[learning rate: 0.0033735]
	Learning Rate: 0.00337352
	LOSS [training: 0.00580739702883326 | validation: 0.006899415691154556]
	TIME [epoch: 8.19 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007321857537678083		[learning rate: 0.0033612]
	Learning Rate: 0.00336117
	LOSS [training: 0.007321857537678083 | validation: 0.00516719273672993]
	TIME [epoch: 8.19 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006215965443142348		[learning rate: 0.0033488]
	Learning Rate: 0.00334883
	LOSS [training: 0.006215965443142348 | validation: 0.009831478778573585]
	TIME [epoch: 8.19 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009219632794378853		[learning rate: 0.0033365]
	Learning Rate: 0.00333651
	LOSS [training: 0.009219632794378853 | validation: 0.011893118325402912]
	TIME [epoch: 8.19 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007497029745917038		[learning rate: 0.0033242]
	Learning Rate: 0.00332421
	LOSS [training: 0.007497029745917038 | validation: 0.004004734167483657]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1443.pth
	Model improved!!!
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005661037640842491		[learning rate: 0.0033119]
	Learning Rate: 0.00331192
	LOSS [training: 0.005661037640842491 | validation: 0.03140864478622618]
	TIME [epoch: 8.22 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009945746483656419		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.009945746483656419 | validation: 0.005377435777418164]
	TIME [epoch: 8.18 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005558166878317205		[learning rate: 0.0032874]
	Learning Rate: 0.00328741
	LOSS [training: 0.005558166878317205 | validation: 0.006737643385820757]
	TIME [epoch: 8.18 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072152388730681374		[learning rate: 0.0032752]
	Learning Rate: 0.00327518
	LOSS [training: 0.0072152388730681374 | validation: 0.010887705683879808]
	TIME [epoch: 8.18 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010570728698011322		[learning rate: 0.003263]
	Learning Rate: 0.00326298
	LOSS [training: 0.010570728698011322 | validation: 0.005425622124289276]
	TIME [epoch: 8.18 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005191013127305297		[learning rate: 0.0032508]
	Learning Rate: 0.00325078
	LOSS [training: 0.005191013127305297 | validation: 0.005074766272902346]
	TIME [epoch: 8.22 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004470400342543159		[learning rate: 0.0032386]
	Learning Rate: 0.00323861
	LOSS [training: 0.004470400342543159 | validation: 0.008348781815445905]
	TIME [epoch: 8.19 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007710178664501306		[learning rate: 0.0032265]
	Learning Rate: 0.00322646
	LOSS [training: 0.007710178664501306 | validation: 0.006288909787059577]
	TIME [epoch: 8.18 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00730218757986105		[learning rate: 0.0032143]
	Learning Rate: 0.00321432
	LOSS [training: 0.00730218757986105 | validation: 0.007323172467304964]
	TIME [epoch: 8.19 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006310284999462216		[learning rate: 0.0032022]
	Learning Rate: 0.0032022
	LOSS [training: 0.006310284999462216 | validation: 0.006147845393337032]
	TIME [epoch: 8.18 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068640805591195595		[learning rate: 0.0031901]
	Learning Rate: 0.00319011
	LOSS [training: 0.0068640805591195595 | validation: 0.008046900154905745]
	TIME [epoch: 8.19 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010039404992758563		[learning rate: 0.003178]
	Learning Rate: 0.00317803
	LOSS [training: 0.010039404992758563 | validation: 0.008836668791819442]
	TIME [epoch: 8.22 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005979386483768582		[learning rate: 0.003166]
	Learning Rate: 0.00316596
	LOSS [training: 0.005979386483768582 | validation: 0.006557039977228512]
	TIME [epoch: 8.18 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00540635114768602		[learning rate: 0.0031539]
	Learning Rate: 0.00315392
	LOSS [training: 0.00540635114768602 | validation: 0.006107503877592648]
	TIME [epoch: 8.18 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006281591736401102		[learning rate: 0.0031419]
	Learning Rate: 0.0031419
	LOSS [training: 0.006281591736401102 | validation: 0.006091777294670969]
	TIME [epoch: 8.19 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006060141711974629		[learning rate: 0.0031299]
	Learning Rate: 0.00312989
	LOSS [training: 0.006060141711974629 | validation: 0.00882718411489123]
	TIME [epoch: 8.18 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00945714873064421		[learning rate: 0.0031179]
	Learning Rate: 0.00311791
	LOSS [training: 0.00945714873064421 | validation: 0.013237657059989508]
	TIME [epoch: 8.22 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008286034600975586		[learning rate: 0.0031059]
	Learning Rate: 0.00310594
	LOSS [training: 0.008286034600975586 | validation: 0.004218533407155179]
	TIME [epoch: 8.21 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006070541930578661		[learning rate: 0.003094]
	Learning Rate: 0.00309399
	LOSS [training: 0.006070541930578661 | validation: 0.00624653874411165]
	TIME [epoch: 8.18 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005603521337296977		[learning rate: 0.0030821]
	Learning Rate: 0.00308206
	LOSS [training: 0.005603521337296977 | validation: 0.004901654717871785]
	TIME [epoch: 8.18 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004907901409491597		[learning rate: 0.0030701]
	Learning Rate: 0.00307015
	LOSS [training: 0.004907901409491597 | validation: 0.013050037877073368]
	TIME [epoch: 8.18 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009048124667956759		[learning rate: 0.0030583]
	Learning Rate: 0.00305826
	LOSS [training: 0.009048124667956759 | validation: 0.006157280865460975]
	TIME [epoch: 8.19 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004553300078110237		[learning rate: 0.0030464]
	Learning Rate: 0.00304639
	LOSS [training: 0.004553300078110237 | validation: 0.011131888241447362]
	TIME [epoch: 8.22 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006702399561629572		[learning rate: 0.0030345]
	Learning Rate: 0.00303453
	LOSS [training: 0.006702399561629572 | validation: 0.007558327849260933]
	TIME [epoch: 8.19 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008917066927913064		[learning rate: 0.0030227]
	Learning Rate: 0.0030227
	LOSS [training: 0.008917066927913064 | validation: 0.008651507382094182]
	TIME [epoch: 8.18 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005375056947775313		[learning rate: 0.0030109]
	Learning Rate: 0.00301088
	LOSS [training: 0.005375056947775313 | validation: 0.004976703372308061]
	TIME [epoch: 8.19 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005000572082320395		[learning rate: 0.0029991]
	Learning Rate: 0.00299908
	LOSS [training: 0.005000572082320395 | validation: 0.006181443645588066]
	TIME [epoch: 8.19 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00660690204577474		[learning rate: 0.0029873]
	Learning Rate: 0.00298731
	LOSS [training: 0.00660690204577474 | validation: 0.008396760270313053]
	TIME [epoch: 8.19 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010969249384188692		[learning rate: 0.0029755]
	Learning Rate: 0.00297555
	LOSS [training: 0.010969249384188692 | validation: 0.004921174148023013]
	TIME [epoch: 8.22 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004657024983463152		[learning rate: 0.0029638]
	Learning Rate: 0.00296381
	LOSS [training: 0.004657024983463152 | validation: 0.004588421945693374]
	TIME [epoch: 8.19 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004646178818288641		[learning rate: 0.0029521]
	Learning Rate: 0.00295209
	LOSS [training: 0.004646178818288641 | validation: 0.010177514160924325]
	TIME [epoch: 8.19 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009469254764465432		[learning rate: 0.0029404]
	Learning Rate: 0.00294039
	LOSS [training: 0.009469254764465432 | validation: 0.010776002157516618]
	TIME [epoch: 8.19 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004844158989802052		[learning rate: 0.0029287]
	Learning Rate: 0.00292871
	LOSS [training: 0.004844158989802052 | validation: 0.004521568176416862]
	TIME [epoch: 8.19 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005852548996643081		[learning rate: 0.002917]
	Learning Rate: 0.00291705
	LOSS [training: 0.005852548996643081 | validation: 0.005271964128075846]
	TIME [epoch: 8.24 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006814715021686494		[learning rate: 0.0029054]
	Learning Rate: 0.0029054
	LOSS [training: 0.006814715021686494 | validation: 0.009639044629166892]
	TIME [epoch: 8.19 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008299080393038834		[learning rate: 0.0028938]
	Learning Rate: 0.00289378
	LOSS [training: 0.008299080393038834 | validation: 0.00630024643003254]
	TIME [epoch: 8.19 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005260756136455429		[learning rate: 0.0028822]
	Learning Rate: 0.00288218
	LOSS [training: 0.005260756136455429 | validation: 0.007673485753253488]
	TIME [epoch: 8.18 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00627094696026789		[learning rate: 0.0028706]
	Learning Rate: 0.00287059
	LOSS [training: 0.00627094696026789 | validation: 0.006265643392997226]
	TIME [epoch: 8.18 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005818339792504555		[learning rate: 0.002859]
	Learning Rate: 0.00285903
	LOSS [training: 0.005818339792504555 | validation: 0.007911700741657746]
	TIME [epoch: 8.19 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008485408556634615		[learning rate: 0.0028475]
	Learning Rate: 0.00284748
	LOSS [training: 0.008485408556634615 | validation: 0.00792798513391368]
	TIME [epoch: 8.22 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005269083555076069		[learning rate: 0.002836]
	Learning Rate: 0.00283596
	LOSS [training: 0.005269083555076069 | validation: 0.0053625169711142085]
	TIME [epoch: 8.19 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004258371586818653		[learning rate: 0.0028245]
	Learning Rate: 0.00282445
	LOSS [training: 0.004258371586818653 | validation: 0.006565954491608511]
	TIME [epoch: 8.19 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069394668536265575		[learning rate: 0.002813]
	Learning Rate: 0.00281297
	LOSS [training: 0.0069394668536265575 | validation: 0.007006137625051934]
	TIME [epoch: 8.19 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008033073440982247		[learning rate: 0.0028015]
	Learning Rate: 0.0028015
	LOSS [training: 0.008033073440982247 | validation: 0.006172095113096025]
	TIME [epoch: 8.18 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005366437252887912		[learning rate: 0.0027901]
	Learning Rate: 0.00279005
	LOSS [training: 0.005366437252887912 | validation: 0.005215746065064456]
	TIME [epoch: 8.2 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066040379302194484		[learning rate: 0.0027786]
	Learning Rate: 0.00277863
	LOSS [training: 0.0066040379302194484 | validation: 0.004922412793473716]
	TIME [epoch: 8.21 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004911952826629253		[learning rate: 0.0027672]
	Learning Rate: 0.00276722
	LOSS [training: 0.004911952826629253 | validation: 0.004917691262071825]
	TIME [epoch: 8.19 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060770366687488255		[learning rate: 0.0027558]
	Learning Rate: 0.00275583
	LOSS [training: 0.0060770366687488255 | validation: 0.005657686082064862]
	TIME [epoch: 8.19 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005568813108783191		[learning rate: 0.0027445]
	Learning Rate: 0.00274446
	LOSS [training: 0.005568813108783191 | validation: 0.005017519295579672]
	TIME [epoch: 8.19 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006015128313206548		[learning rate: 0.0027331]
	Learning Rate: 0.00273312
	LOSS [training: 0.006015128313206548 | validation: 0.012433395851173175]
	TIME [epoch: 8.18 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006397020341620667		[learning rate: 0.0027218]
	Learning Rate: 0.00272179
	LOSS [training: 0.006397020341620667 | validation: 0.005964600056363534]
	TIME [epoch: 8.22 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071180758763945765		[learning rate: 0.0027105]
	Learning Rate: 0.00271048
	LOSS [training: 0.0071180758763945765 | validation: 0.0040934662659758096]
	TIME [epoch: 8.2 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004652626082979635		[learning rate: 0.0026992]
	Learning Rate: 0.00269919
	LOSS [training: 0.004652626082979635 | validation: 0.004264868405501509]
	TIME [epoch: 8.18 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061379153591197624		[learning rate: 0.0026879]
	Learning Rate: 0.00268792
	LOSS [training: 0.0061379153591197624 | validation: 0.007462974606675695]
	TIME [epoch: 8.18 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007029039500780412		[learning rate: 0.0026767]
	Learning Rate: 0.00267667
	LOSS [training: 0.007029039500780412 | validation: 0.004917740748862578]
	TIME [epoch: 8.21 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004809885944808294		[learning rate: 0.0026654]
	Learning Rate: 0.00266545
	LOSS [training: 0.004809885944808294 | validation: 0.004520706035486887]
	TIME [epoch: 8.19 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038178541384565863		[learning rate: 0.0026542]
	Learning Rate: 0.00265424
	LOSS [training: 0.0038178541384565863 | validation: 0.005137068733820289]
	TIME [epoch: 8.21 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007353417182666126		[learning rate: 0.0026431]
	Learning Rate: 0.00264305
	LOSS [training: 0.007353417182666126 | validation: 0.009843415316873669]
	TIME [epoch: 8.18 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006352736152102043		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.006352736152102043 | validation: 0.004999338486207149]
	TIME [epoch: 8.18 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00507273715493503		[learning rate: 0.0026207]
	Learning Rate: 0.00262073
	LOSS [training: 0.00507273715493503 | validation: 0.006373955162305943]
	TIME [epoch: 8.18 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007131859065696243		[learning rate: 0.0026096]
	Learning Rate: 0.00260961
	LOSS [training: 0.007131859065696243 | validation: 0.006672377327512211]
	TIME [epoch: 8.18 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007490523250830844		[learning rate: 0.0025985]
	Learning Rate: 0.0025985
	LOSS [training: 0.007490523250830844 | validation: 0.004285072430283867]
	TIME [epoch: 8.21 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004688773732142638		[learning rate: 0.0025874]
	Learning Rate: 0.00258741
	LOSS [training: 0.004688773732142638 | validation: 0.005295706486285575]
	TIME [epoch: 8.19 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005859610085894727		[learning rate: 0.0025763]
	Learning Rate: 0.00257635
	LOSS [training: 0.005859610085894727 | validation: 0.004433218819065082]
	TIME [epoch: 8.18 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003882795231748906		[learning rate: 0.0025653]
	Learning Rate: 0.0025653
	LOSS [training: 0.003882795231748906 | validation: 0.004361556163826849]
	TIME [epoch: 8.18 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006781850930480277		[learning rate: 0.0025543]
	Learning Rate: 0.00255427
	LOSS [training: 0.006781850930480277 | validation: 0.006709751720798686]
	TIME [epoch: 8.18 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006755386385615891		[learning rate: 0.0025433]
	Learning Rate: 0.00254327
	LOSS [training: 0.006755386385615891 | validation: 0.003673022490551677]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1510.pth
	Model improved!!!
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004369495532079408		[learning rate: 0.0025323]
	Learning Rate: 0.00253228
	LOSS [training: 0.004369495532079408 | validation: 0.006626609006226275]
	TIME [epoch: 8.23 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006439831870550181		[learning rate: 0.0025213]
	Learning Rate: 0.00252132
	LOSS [training: 0.006439831870550181 | validation: 0.008407544694586098]
	TIME [epoch: 8.18 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005499343626694733		[learning rate: 0.0025104]
	Learning Rate: 0.00251037
	LOSS [training: 0.005499343626694733 | validation: 0.0062399921873231585]
	TIME [epoch: 8.18 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005671317128817488		[learning rate: 0.0024994]
	Learning Rate: 0.00249945
	LOSS [training: 0.005671317128817488 | validation: 0.003826881179037675]
	TIME [epoch: 8.18 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005629817763349935		[learning rate: 0.0024885]
	Learning Rate: 0.00248855
	LOSS [training: 0.005629817763349935 | validation: 0.010218224000002763]
	TIME [epoch: 8.18 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00579910946926865		[learning rate: 0.0024777]
	Learning Rate: 0.00247766
	LOSS [training: 0.00579910946926865 | validation: 0.004829857185566942]
	TIME [epoch: 8.21 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004947706419025922		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.004947706419025922 | validation: 0.006550580736081954]
	TIME [epoch: 8.21 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056672860625398514		[learning rate: 0.002456]
	Learning Rate: 0.00245596
	LOSS [training: 0.0056672860625398514 | validation: 0.013687254469055249]
	TIME [epoch: 8.18 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005739361155340406		[learning rate: 0.0024451]
	Learning Rate: 0.00244514
	LOSS [training: 0.005739361155340406 | validation: 0.005107707381044559]
	TIME [epoch: 8.18 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049788338342606235		[learning rate: 0.0024343]
	Learning Rate: 0.00243434
	LOSS [training: 0.0049788338342606235 | validation: 0.004907926465080276]
	TIME [epoch: 8.18 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050948729752133826		[learning rate: 0.0024236]
	Learning Rate: 0.00242356
	LOSS [training: 0.0050948729752133826 | validation: 0.004217904819495898]
	TIME [epoch: 8.18 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004022701188641573		[learning rate: 0.0024128]
	Learning Rate: 0.0024128
	LOSS [training: 0.004022701188641573 | validation: 0.005453504540710126]
	TIME [epoch: 8.23 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006768936447318003		[learning rate: 0.0024021]
	Learning Rate: 0.00240206
	LOSS [training: 0.006768936447318003 | validation: 0.007029241156622474]
	TIME [epoch: 8.19 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004709123468551467		[learning rate: 0.0023913]
	Learning Rate: 0.00239134
	LOSS [training: 0.004709123468551467 | validation: 0.005084347061661108]
	TIME [epoch: 8.18 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048146548877263315		[learning rate: 0.0023806]
	Learning Rate: 0.00238065
	LOSS [training: 0.0048146548877263315 | validation: 0.00524279985333056]
	TIME [epoch: 8.19 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004785001676178097		[learning rate: 0.00237]
	Learning Rate: 0.00236997
	LOSS [training: 0.004785001676178097 | validation: 0.011455486986869094]
	TIME [epoch: 8.19 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006005150469607378		[learning rate: 0.0023593]
	Learning Rate: 0.00235931
	LOSS [training: 0.006005150469607378 | validation: 0.004595078680836745]
	TIME [epoch: 8.19 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006167618906843659		[learning rate: 0.0023487]
	Learning Rate: 0.00234868
	LOSS [training: 0.006167618906843659 | validation: 0.0058930296895947625]
	TIME [epoch: 8.22 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004147906058937921		[learning rate: 0.0023381]
	Learning Rate: 0.00233807
	LOSS [training: 0.004147906058937921 | validation: 0.004735775605855407]
	TIME [epoch: 8.18 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039859356012017415		[learning rate: 0.0023275]
	Learning Rate: 0.00232748
	LOSS [training: 0.0039859356012017415 | validation: 0.005025684964794056]
	TIME [epoch: 8.18 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005717149658500477		[learning rate: 0.0023169]
	Learning Rate: 0.0023169
	LOSS [training: 0.005717149658500477 | validation: 0.008604127742452866]
	TIME [epoch: 8.18 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006604860482910918		[learning rate: 0.0023064]
	Learning Rate: 0.00230635
	LOSS [training: 0.006604860482910918 | validation: 0.0055184544544133254]
	TIME [epoch: 8.18 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004295550877483659		[learning rate: 0.0022958]
	Learning Rate: 0.00229583
	LOSS [training: 0.004295550877483659 | validation: 0.007288687026990192]
	TIME [epoch: 8.22 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005390212123000192		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.005390212123000192 | validation: 0.00474838254455295]
	TIME [epoch: 8.2 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005008757973540797		[learning rate: 0.0022748]
	Learning Rate: 0.00227483
	LOSS [training: 0.005008757973540797 | validation: 0.004645419244007332]
	TIME [epoch: 8.2 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050389520780080126		[learning rate: 0.0022644]
	Learning Rate: 0.00226436
	LOSS [training: 0.0050389520780080126 | validation: 0.004712797902419921]
	TIME [epoch: 8.19 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047332555593511474		[learning rate: 0.0022539]
	Learning Rate: 0.00225392
	LOSS [training: 0.0047332555593511474 | validation: 0.006442924133535598]
	TIME [epoch: 8.18 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005548485731902162		[learning rate: 0.0022435]
	Learning Rate: 0.0022435
	LOSS [training: 0.005548485731902162 | validation: 0.007134451169771261]
	TIME [epoch: 8.19 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005651723297211851		[learning rate: 0.0022331]
	Learning Rate: 0.00223309
	LOSS [training: 0.005651723297211851 | validation: 0.005084354964789567]
	TIME [epoch: 8.23 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038047909163347743		[learning rate: 0.0022227]
	Learning Rate: 0.00222271
	LOSS [training: 0.0038047909163347743 | validation: 0.0035457233294856087]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1540.pth
	Model improved!!!
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004043930363311233		[learning rate: 0.0022124]
	Learning Rate: 0.00221235
	LOSS [training: 0.004043930363311233 | validation: 0.010438142924853585]
	TIME [epoch: 8.2 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006795879831814011		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.006795879831814011 | validation: 0.006621628456827691]
	TIME [epoch: 8.2 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005055539787917104		[learning rate: 0.0021917]
	Learning Rate: 0.0021917
	LOSS [training: 0.005055539787917104 | validation: 0.004547457843799314]
	TIME [epoch: 8.2 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00517755049208651		[learning rate: 0.0021814]
	Learning Rate: 0.0021814
	LOSS [training: 0.00517755049208651 | validation: 0.0074298680392111665]
	TIME [epoch: 8.22 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00406848284767241		[learning rate: 0.0021711]
	Learning Rate: 0.00217113
	LOSS [training: 0.00406848284767241 | validation: 0.00371871171303414]
	TIME [epoch: 8.22 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004163622834514945		[learning rate: 0.0021609]
	Learning Rate: 0.00216088
	LOSS [training: 0.004163622834514945 | validation: 0.004210849592442926]
	TIME [epoch: 8.2 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005008755223693949		[learning rate: 0.0021506]
	Learning Rate: 0.00215064
	LOSS [training: 0.005008755223693949 | validation: 0.005606881735780519]
	TIME [epoch: 8.2 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005559471489947187		[learning rate: 0.0021404]
	Learning Rate: 0.00214043
	LOSS [training: 0.005559471489947187 | validation: 0.004887890311298763]
	TIME [epoch: 8.2 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038606457179146464		[learning rate: 0.0021302]
	Learning Rate: 0.00213025
	LOSS [training: 0.0038606457179146464 | validation: 0.0036566503630085408]
	TIME [epoch: 8.2 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003966337997713738		[learning rate: 0.0021201]
	Learning Rate: 0.00212008
	LOSS [training: 0.003966337997713738 | validation: 0.005023313128150719]
	TIME [epoch: 8.23 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005999816907911981		[learning rate: 0.0021099]
	Learning Rate: 0.00210993
	LOSS [training: 0.005999816907911981 | validation: 0.00464571309357667]
	TIME [epoch: 8.2 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004104077326015655		[learning rate: 0.0020998]
	Learning Rate: 0.00209981
	LOSS [training: 0.004104077326015655 | validation: 0.003712234903549706]
	TIME [epoch: 8.21 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00418407745887308		[learning rate: 0.0020897]
	Learning Rate: 0.00208971
	LOSS [training: 0.00418407745887308 | validation: 0.006430015562839217]
	TIME [epoch: 8.2 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004603113849363109		[learning rate: 0.0020796]
	Learning Rate: 0.00207963
	LOSS [training: 0.004603113849363109 | validation: 0.006661967454560589]
	TIME [epoch: 8.2 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005908441531943494		[learning rate: 0.0020696]
	Learning Rate: 0.00206957
	LOSS [training: 0.005908441531943494 | validation: 0.005187377689542692]
	TIME [epoch: 8.2 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005383921942881427		[learning rate: 0.0020595]
	Learning Rate: 0.00205953
	LOSS [training: 0.005383921942881427 | validation: 0.006656416887477914]
	TIME [epoch: 8.23 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00428840758276477		[learning rate: 0.0020495]
	Learning Rate: 0.00204952
	LOSS [training: 0.00428840758276477 | validation: 0.0032644918874693086]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1557.pth
	Model improved!!!
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036370685299299474		[learning rate: 0.0020395]
	Learning Rate: 0.00203952
	LOSS [training: 0.0036370685299299474 | validation: 0.0043736734337698775]
	TIME [epoch: 8.19 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006093279736035295		[learning rate: 0.0020296]
	Learning Rate: 0.00202955
	LOSS [training: 0.006093279736035295 | validation: 0.005169646174307282]
	TIME [epoch: 8.19 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004213352457691906		[learning rate: 0.0020196]
	Learning Rate: 0.0020196
	LOSS [training: 0.004213352457691906 | validation: 0.003462026879771443]
	TIME [epoch: 8.19 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00470424438758809		[learning rate: 0.0020097]
	Learning Rate: 0.00200967
	LOSS [training: 0.00470424438758809 | validation: 0.0047185233796325395]
	TIME [epoch: 8.23 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004255018887146151		[learning rate: 0.0019998]
	Learning Rate: 0.00199977
	LOSS [training: 0.004255018887146151 | validation: 0.003810182664233684]
	TIME [epoch: 8.19 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037481295213446933		[learning rate: 0.0019899]
	Learning Rate: 0.00198988
	LOSS [training: 0.0037481295213446933 | validation: 0.0074290311342662466]
	TIME [epoch: 8.18 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042472088105301575		[learning rate: 0.00198]
	Learning Rate: 0.00198002
	LOSS [training: 0.0042472088105301575 | validation: 0.005665437582885667]
	TIME [epoch: 8.18 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004966674171454107		[learning rate: 0.0019702]
	Learning Rate: 0.00197018
	LOSS [training: 0.004966674171454107 | validation: 0.00688788983866625]
	TIME [epoch: 8.18 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052190119446391		[learning rate: 0.0019604]
	Learning Rate: 0.00196036
	LOSS [training: 0.0052190119446391 | validation: 0.004973435820805329]
	TIME [epoch: 8.2 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00426093438648183		[learning rate: 0.0019506]
	Learning Rate: 0.00195056
	LOSS [training: 0.00426093438648183 | validation: 0.0048268751199199945]
	TIME [epoch: 8.23 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005228484416342061		[learning rate: 0.0019408]
	Learning Rate: 0.00194079
	LOSS [training: 0.005228484416342061 | validation: 0.004031065135176817]
	TIME [epoch: 8.19 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033857027811811887		[learning rate: 0.001931]
	Learning Rate: 0.00193103
	LOSS [training: 0.0033857027811811887 | validation: 0.004202769510055304]
	TIME [epoch: 8.19 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004849667761906845		[learning rate: 0.0019213]
	Learning Rate: 0.0019213
	LOSS [training: 0.004849667761906845 | validation: 0.005482339461992609]
	TIME [epoch: 8.19 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004678931282617727		[learning rate: 0.0019116]
	Learning Rate: 0.0019116
	LOSS [training: 0.004678931282617727 | validation: 0.00561249679989285]
	TIME [epoch: 8.19 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00480178811073288		[learning rate: 0.0019019]
	Learning Rate: 0.00190191
	LOSS [training: 0.00480178811073288 | validation: 0.004915908860773359]
	TIME [epoch: 8.21 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036382394968112043		[learning rate: 0.0018922]
	Learning Rate: 0.00189225
	LOSS [training: 0.0036382394968112043 | validation: 0.004240138906803121]
	TIME [epoch: 8.21 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005711357360552337		[learning rate: 0.0018826]
	Learning Rate: 0.0018826
	LOSS [training: 0.005711357360552337 | validation: 0.004328136396213193]
	TIME [epoch: 8.19 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004583542773301465		[learning rate: 0.001873]
	Learning Rate: 0.00187298
	LOSS [training: 0.004583542773301465 | validation: 0.0032769923971394353]
	TIME [epoch: 8.19 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003954134888238181		[learning rate: 0.0018634]
	Learning Rate: 0.00186339
	LOSS [training: 0.003954134888238181 | validation: 0.0033602784137842187]
	TIME [epoch: 8.19 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035571456173322676		[learning rate: 0.0018538]
	Learning Rate: 0.00185381
	LOSS [training: 0.0035571456173322676 | validation: 0.004099753892056954]
	TIME [epoch: 8.19 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005051808012434668		[learning rate: 0.0018443]
	Learning Rate: 0.00184426
	LOSS [training: 0.005051808012434668 | validation: 0.0056683220647297744]
	TIME [epoch: 8.23 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004798660844003615		[learning rate: 0.0018347]
	Learning Rate: 0.00183473
	LOSS [training: 0.004798660844003615 | validation: 0.005330268120979019]
	TIME [epoch: 8.2 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003941537289837508		[learning rate: 0.0018252]
	Learning Rate: 0.00182522
	LOSS [training: 0.003941537289837508 | validation: 0.006410675286763716]
	TIME [epoch: 8.19 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005763965033651022		[learning rate: 0.0018157]
	Learning Rate: 0.00181573
	LOSS [training: 0.005763965033651022 | validation: 0.0078870366600823]
	TIME [epoch: 8.19 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005010102765049242		[learning rate: 0.0018063]
	Learning Rate: 0.00180627
	LOSS [training: 0.005010102765049242 | validation: 0.0029728709353642893]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1582.pth
	Model improved!!!
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003241864331272337		[learning rate: 0.0017968]
	Learning Rate: 0.00179683
	LOSS [training: 0.003241864331272337 | validation: 0.003542188158895309]
	TIME [epoch: 8.19 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003627122135914781		[learning rate: 0.0017874]
	Learning Rate: 0.00178741
	LOSS [training: 0.003627122135914781 | validation: 0.004434635950573156]
	TIME [epoch: 8.22 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003569551921871369		[learning rate: 0.001778]
	Learning Rate: 0.00177801
	LOSS [training: 0.003569551921871369 | validation: 0.004943655674846232]
	TIME [epoch: 8.18 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004811850252015226		[learning rate: 0.0017686]
	Learning Rate: 0.00176864
	LOSS [training: 0.004811850252015226 | validation: 0.007958036769606715]
	TIME [epoch: 8.19 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005509156610383027		[learning rate: 0.0017593]
	Learning Rate: 0.00175929
	LOSS [training: 0.005509156610383027 | validation: 0.00391220385372106]
	TIME [epoch: 8.18 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003922270125563578		[learning rate: 0.00175]
	Learning Rate: 0.00174996
	LOSS [training: 0.003922270125563578 | validation: 0.003938546975186976]
	TIME [epoch: 8.19 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043698800821997405		[learning rate: 0.0017407]
	Learning Rate: 0.00174065
	LOSS [training: 0.0043698800821997405 | validation: 0.0048255984457050245]
	TIME [epoch: 8.22 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035023113675892795		[learning rate: 0.0017314]
	Learning Rate: 0.00173137
	LOSS [training: 0.0035023113675892795 | validation: 0.005441047589807048]
	TIME [epoch: 8.19 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004036348461066398		[learning rate: 0.0017221]
	Learning Rate: 0.00172211
	LOSS [training: 0.004036348461066398 | validation: 0.003876427173194295]
	TIME [epoch: 8.19 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005696539135461973		[learning rate: 0.0017129]
	Learning Rate: 0.00171287
	LOSS [training: 0.005696539135461973 | validation: 0.008062337591105397]
	TIME [epoch: 8.19 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004534914953647521		[learning rate: 0.0017037]
	Learning Rate: 0.00170365
	LOSS [training: 0.004534914953647521 | validation: 0.0036991936116018056]
	TIME [epoch: 8.19 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003877394422677821		[learning rate: 0.0016945]
	Learning Rate: 0.00169446
	LOSS [training: 0.003877394422677821 | validation: 0.0037736335199009263]
	TIME [epoch: 8.19 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003556157199638739		[learning rate: 0.0016853]
	Learning Rate: 0.00168529
	LOSS [training: 0.003556157199638739 | validation: 0.005845140767283583]
	TIME [epoch: 8.23 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038966305461428444		[learning rate: 0.0016761]
	Learning Rate: 0.00167614
	LOSS [training: 0.0038966305461428444 | validation: 0.004117626799037575]
	TIME [epoch: 8.19 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033976832105347098		[learning rate: 0.001667]
	Learning Rate: 0.00166702
	LOSS [training: 0.0033976832105347098 | validation: 0.004732701298011149]
	TIME [epoch: 8.19 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037790069223389245		[learning rate: 0.0016579]
	Learning Rate: 0.00165792
	LOSS [training: 0.0037790069223389245 | validation: 0.004035153042233694]
	TIME [epoch: 8.18 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004778042083487645		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.004778042083487645 | validation: 0.005602039779171894]
	TIME [epoch: 8.18 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003949315498712707		[learning rate: 0.0016398]
	Learning Rate: 0.00163978
	LOSS [training: 0.003949315498712707 | validation: 0.0036899694785458553]
	TIME [epoch: 8.28 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004186680937527165		[learning rate: 0.0016307]
	Learning Rate: 0.00163075
	LOSS [training: 0.004186680937527165 | validation: 0.004909267966246178]
	TIME [epoch: 8.2 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004179471373487488		[learning rate: 0.0016217]
	Learning Rate: 0.00162174
	LOSS [training: 0.004179471373487488 | validation: 0.0033808502609063524]
	TIME [epoch: 8.18 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037183814655588152		[learning rate: 0.0016128]
	Learning Rate: 0.00161275
	LOSS [training: 0.0037183814655588152 | validation: 0.004503667649607515]
	TIME [epoch: 8.18 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035271021277976577		[learning rate: 0.0016038]
	Learning Rate: 0.00160379
	LOSS [training: 0.0035271021277976577 | validation: 0.004485500851726239]
	TIME [epoch: 8.18 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036437581431550186		[learning rate: 0.0015948]
	Learning Rate: 0.00159484
	LOSS [training: 0.0036437581431550186 | validation: 0.0055131951938527]
	TIME [epoch: 8.18 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051769481407876895		[learning rate: 0.0015859]
	Learning Rate: 0.00158593
	LOSS [training: 0.0051769481407876895 | validation: 0.00388753976177619]
	TIME [epoch: 8.22 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044715170316220335		[learning rate: 0.001577]
	Learning Rate: 0.00157703
	LOSS [training: 0.0044715170316220335 | validation: 0.004990884693127943]
	TIME [epoch: 8.18 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003559780276459362		[learning rate: 0.0015682]
	Learning Rate: 0.00156816
	LOSS [training: 0.003559780276459362 | validation: 0.003882985979457288]
	TIME [epoch: 8.18 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035511757510501025		[learning rate: 0.0015593]
	Learning Rate: 0.00155931
	LOSS [training: 0.0035511757510501025 | validation: 0.0037246147857691965]
	TIME [epoch: 8.18 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003845318819831296		[learning rate: 0.0015505]
	Learning Rate: 0.00155048
	LOSS [training: 0.003845318819831296 | validation: 0.003975853773210342]
	TIME [epoch: 8.18 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004420397101737785		[learning rate: 0.0015417]
	Learning Rate: 0.00154168
	LOSS [training: 0.004420397101737785 | validation: 0.006861476162142827]
	TIME [epoch: 8.19 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004061260269741586		[learning rate: 0.0015329]
	Learning Rate: 0.0015329
	LOSS [training: 0.004061260269741586 | validation: 0.004039311591835994]
	TIME [epoch: 8.22 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034274387711977555		[learning rate: 0.0015241]
	Learning Rate: 0.00152414
	LOSS [training: 0.0034274387711977555 | validation: 0.006348273357726423]
	TIME [epoch: 8.18 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00407602763190163		[learning rate: 0.0015154]
	Learning Rate: 0.00151541
	LOSS [training: 0.00407602763190163 | validation: 0.003889962763861337]
	TIME [epoch: 8.18 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034413382852645676		[learning rate: 0.0015067]
	Learning Rate: 0.0015067
	LOSS [training: 0.0034413382852645676 | validation: 0.006678255052201126]
	TIME [epoch: 8.18 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00414622669906233		[learning rate: 0.001498]
	Learning Rate: 0.00149801
	LOSS [training: 0.00414622669906233 | validation: 0.0035416446164524646]
	TIME [epoch: 8.19 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003513664391623349		[learning rate: 0.0014893]
	Learning Rate: 0.00148934
	LOSS [training: 0.003513664391623349 | validation: 0.00594215492485321]
	TIME [epoch: 8.22 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003592089299635073		[learning rate: 0.0014807]
	Learning Rate: 0.0014807
	LOSS [training: 0.003592089299635073 | validation: 0.0050389499767904255]
	TIME [epoch: 8.19 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003630527204501331		[learning rate: 0.0014721]
	Learning Rate: 0.00147209
	LOSS [training: 0.003630527204501331 | validation: 0.003818237885713935]
	TIME [epoch: 8.18 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004034070532518452		[learning rate: 0.0014635]
	Learning Rate: 0.00146349
	LOSS [training: 0.004034070532518452 | validation: 0.0042112094713507645]
	TIME [epoch: 8.18 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035984697899255234		[learning rate: 0.0014549]
	Learning Rate: 0.00145492
	LOSS [training: 0.0035984697899255234 | validation: 0.004519538513289553]
	TIME [epoch: 8.18 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004098790133456345		[learning rate: 0.0014464]
	Learning Rate: 0.00144637
	LOSS [training: 0.004098790133456345 | validation: 0.0033885810089287613]
	TIME [epoch: 8.19 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033822683633912033		[learning rate: 0.0014378]
	Learning Rate: 0.00143785
	LOSS [training: 0.0033822683633912033 | validation: 0.005102202709866094]
	TIME [epoch: 8.22 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004444763718953097		[learning rate: 0.0014293]
	Learning Rate: 0.00142935
	LOSS [training: 0.004444763718953097 | validation: 0.006023301051808186]
	TIME [epoch: 8.19 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003426665400178588		[learning rate: 0.0014209]
	Learning Rate: 0.00142087
	LOSS [training: 0.003426665400178588 | validation: 0.004074092182377361]
	TIME [epoch: 8.19 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035299627673795633		[learning rate: 0.0014124]
	Learning Rate: 0.00141242
	LOSS [training: 0.0035299627673795633 | validation: 0.004065311077580311]
	TIME [epoch: 8.19 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037372514709775135		[learning rate: 0.001404]
	Learning Rate: 0.00140399
	LOSS [training: 0.0037372514709775135 | validation: 0.0037948162250860005]
	TIME [epoch: 8.18 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004096833219820163		[learning rate: 0.0013956]
	Learning Rate: 0.00139558
	LOSS [training: 0.004096833219820163 | validation: 0.003611888066829452]
	TIME [epoch: 8.21 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038484164821345583		[learning rate: 0.0013872]
	Learning Rate: 0.0013872
	LOSS [training: 0.0038484164821345583 | validation: 0.00583860929781857]
	TIME [epoch: 8.2 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004027482726278095		[learning rate: 0.0013788]
	Learning Rate: 0.00137884
	LOSS [training: 0.004027482726278095 | validation: 0.003099534556429754]
	TIME [epoch: 8.19 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004435028034630747		[learning rate: 0.0013705]
	Learning Rate: 0.0013705
	LOSS [training: 0.004435028034630747 | validation: 0.003944125162391526]
	TIME [epoch: 8.18 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036890872655825167		[learning rate: 0.0013622]
	Learning Rate: 0.00136219
	LOSS [training: 0.0036890872655825167 | validation: 0.004389910668990478]
	TIME [epoch: 8.19 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033717313544131774		[learning rate: 0.0013539]
	Learning Rate: 0.0013539
	LOSS [training: 0.0033717313544131774 | validation: 0.004027707604407371]
	TIME [epoch: 8.21 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032256263549649083		[learning rate: 0.0013456]
	Learning Rate: 0.00134564
	LOSS [training: 0.0032256263549649083 | validation: 0.003620214164790232]
	TIME [epoch: 8.22 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003057508956456066		[learning rate: 0.0013374]
	Learning Rate: 0.00133739
	LOSS [training: 0.003057508956456066 | validation: 0.003887823748161951]
	TIME [epoch: 8.19 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037316155832829716		[learning rate: 0.0013292]
	Learning Rate: 0.00132918
	LOSS [training: 0.0037316155832829716 | validation: 0.003977400044131515]
	TIME [epoch: 8.18 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004104886814984973		[learning rate: 0.001321]
	Learning Rate: 0.00132098
	LOSS [training: 0.004104886814984973 | validation: 0.003451726501681243]
	TIME [epoch: 8.18 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003300864238830394		[learning rate: 0.0013128]
	Learning Rate: 0.00131281
	LOSS [training: 0.003300864238830394 | validation: 0.004627372173089012]
	TIME [epoch: 8.2 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036747623726975038		[learning rate: 0.0013047]
	Learning Rate: 0.00130466
	LOSS [training: 0.0036747623726975038 | validation: 0.0038410859951655127]
	TIME [epoch: 8.19 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031695876325918237		[learning rate: 0.0012965]
	Learning Rate: 0.00129654
	LOSS [training: 0.0031695876325918237 | validation: 0.004318509356880969]
	TIME [epoch: 8.22 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004044357055897332		[learning rate: 0.0012884]
	Learning Rate: 0.00128844
	LOSS [training: 0.004044357055897332 | validation: 0.004172706288687392]
	TIME [epoch: 8.19 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00381494115275674		[learning rate: 0.0012804]
	Learning Rate: 0.00128037
	LOSS [training: 0.00381494115275674 | validation: 0.003468822523373447]
	TIME [epoch: 8.19 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031838847824978028		[learning rate: 0.0012723]
	Learning Rate: 0.00127232
	LOSS [training: 0.0031838847824978028 | validation: 0.003276254245538546]
	TIME [epoch: 8.18 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00339225825057906		[learning rate: 0.0012643]
	Learning Rate: 0.00126429
	LOSS [training: 0.00339225825057906 | validation: 0.003518232759213095]
	TIME [epoch: 8.19 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00314214444540396		[learning rate: 0.0012563]
	Learning Rate: 0.00125629
	LOSS [training: 0.00314214444540396 | validation: 0.003764124499657995]
	TIME [epoch: 8.22 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033548332823973917		[learning rate: 0.0012483]
	Learning Rate: 0.00124831
	LOSS [training: 0.0033548332823973917 | validation: 0.004361396320570816]
	TIME [epoch: 8.2 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037659178185245135		[learning rate: 0.0012404]
	Learning Rate: 0.00124035
	LOSS [training: 0.0037659178185245135 | validation: 0.0039976940439377315]
	TIME [epoch: 8.19 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002772700761753258		[learning rate: 0.0012324]
	Learning Rate: 0.00123242
	LOSS [training: 0.002772700761753258 | validation: 0.003769605568877143]
	TIME [epoch: 8.19 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030143856815557724		[learning rate: 0.0012245]
	Learning Rate: 0.00122451
	LOSS [training: 0.0030143856815557724 | validation: 0.003112527914780852]
	TIME [epoch: 8.19 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038001004146876243		[learning rate: 0.0012166]
	Learning Rate: 0.00121663
	LOSS [training: 0.0038001004146876243 | validation: 0.005317495941261999]
	TIME [epoch: 8.19 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003601861419767565		[learning rate: 0.0012088]
	Learning Rate: 0.00120877
	LOSS [training: 0.003601861419767565 | validation: 0.0045234074061393185]
	TIME [epoch: 8.23 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003726417143827628		[learning rate: 0.0012009]
	Learning Rate: 0.00120093
	LOSS [training: 0.003726417143827628 | validation: 0.0036771306274932815]
	TIME [epoch: 8.19 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003579852051766459		[learning rate: 0.0011931]
	Learning Rate: 0.00119312
	LOSS [training: 0.003579852051766459 | validation: 0.003882041499676087]
	TIME [epoch: 8.19 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037811110811328302		[learning rate: 0.0011853]
	Learning Rate: 0.00118533
	LOSS [training: 0.0037811110811328302 | validation: 0.0033239240144869705]
	TIME [epoch: 8.19 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002962527494894074		[learning rate: 0.0011776]
	Learning Rate: 0.00117757
	LOSS [training: 0.002962527494894074 | validation: 0.0038990122952179025]
	TIME [epoch: 8.19 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031931230185191723		[learning rate: 0.0011698]
	Learning Rate: 0.00116983
	LOSS [training: 0.0031931230185191723 | validation: 0.003838584587935266]
	TIME [epoch: 8.21 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003493910003239579		[learning rate: 0.0011621]
	Learning Rate: 0.00116211
	LOSS [training: 0.003493910003239579 | validation: 0.0035379433679394666]
	TIME [epoch: 8.21 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003917380155929242		[learning rate: 0.0011544]
	Learning Rate: 0.00115442
	LOSS [training: 0.003917380155929242 | validation: 0.003296281803268757]
	TIME [epoch: 8.19 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035566707772532		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.0035566707772532 | validation: 0.003877605453099575]
	TIME [epoch: 8.18 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029684966131748756		[learning rate: 0.0011391]
	Learning Rate: 0.00113911
	LOSS [training: 0.0029684966131748756 | validation: 0.0031148123085808265]
	TIME [epoch: 8.2 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003307352236438241		[learning rate: 0.0011315]
	Learning Rate: 0.0011315
	LOSS [training: 0.003307352236438241 | validation: 0.0032065558168714653]
	TIME [epoch: 8.19 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033379869556176907		[learning rate: 0.0011239]
	Learning Rate: 0.0011239
	LOSS [training: 0.0033379869556176907 | validation: 0.0037066847280938873]
	TIME [epoch: 8.23 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033427826336983844		[learning rate: 0.0011163]
	Learning Rate: 0.00111633
	LOSS [training: 0.0033427826336983844 | validation: 0.00414280130229861]
	TIME [epoch: 8.19 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003777866821731366		[learning rate: 0.0011088]
	Learning Rate: 0.00110879
	LOSS [training: 0.003777866821731366 | validation: 0.005280447990001096]
	TIME [epoch: 8.18 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003037562221230312		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.003037562221230312 | validation: 0.003084615147384259]
	TIME [epoch: 8.18 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003108986381632652		[learning rate: 0.0010938]
	Learning Rate: 0.00109377
	LOSS [training: 0.003108986381632652 | validation: 0.0035719195635896513]
	TIME [epoch: 8.19 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032751474297171117		[learning rate: 0.0010863]
	Learning Rate: 0.0010863
	LOSS [training: 0.0032751474297171117 | validation: 0.002979336571901633]
	TIME [epoch: 8.19 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033871317142889473		[learning rate: 0.0010788]
	Learning Rate: 0.00107885
	LOSS [training: 0.0033871317142889473 | validation: 0.0039101095486926245]
	TIME [epoch: 8.22 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035495812670403143		[learning rate: 0.0010714]
	Learning Rate: 0.00107143
	LOSS [training: 0.0035495812670403143 | validation: 0.003803174889656282]
	TIME [epoch: 8.19 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002845351408377558		[learning rate: 0.001064]
	Learning Rate: 0.00106403
	LOSS [training: 0.002845351408377558 | validation: 0.003479270594755955]
	TIME [epoch: 8.19 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034452623383798295		[learning rate: 0.0010567]
	Learning Rate: 0.00105665
	LOSS [training: 0.0034452623383798295 | validation: 0.004325033618523006]
	TIME [epoch: 8.18 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029951820696344647		[learning rate: 0.0010493]
	Learning Rate: 0.0010493
	LOSS [training: 0.0029951820696344647 | validation: 0.0029814630857752968]
	TIME [epoch: 8.18 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002992414541370751		[learning rate: 0.001042]
	Learning Rate: 0.00104198
	LOSS [training: 0.002992414541370751 | validation: 0.004205007217386542]
	TIME [epoch: 8.21 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029860833999213795		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.0029860833999213795 | validation: 0.0036736214827464914]
	TIME [epoch: 8.21 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033746229195633372		[learning rate: 0.0010274]
	Learning Rate: 0.0010274
	LOSS [training: 0.0033746229195633372 | validation: 0.0031093149016972344]
	TIME [epoch: 8.19 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003152792049113685		[learning rate: 0.0010201]
	Learning Rate: 0.00102015
	LOSS [training: 0.003152792049113685 | validation: 0.0033154458079760244]
	TIME [epoch: 8.19 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003074223660854995		[learning rate: 0.0010129]
	Learning Rate: 0.00101292
	LOSS [training: 0.003074223660854995 | validation: 0.003584489386415356]
	TIME [epoch: 8.18 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003698275635737381		[learning rate: 0.0010057]
	Learning Rate: 0.00100571
	LOSS [training: 0.003698275635737381 | validation: 0.0028986979014193415]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1678.pth
	Model improved!!!
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033386195151196936		[learning rate: 0.00099854]
	Learning Rate: 0.000998536
	LOSS [training: 0.0033386195151196936 | validation: 0.0035030601369532973]
	TIME [epoch: 8.23 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003248625449771922		[learning rate: 0.00099138]
	Learning Rate: 0.000991382
	LOSS [training: 0.003248625449771922 | validation: 0.0035794986613208444]
	TIME [epoch: 8.18 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030955502770718115		[learning rate: 0.00098425]
	Learning Rate: 0.000984253
	LOSS [training: 0.0030955502770718115 | validation: 0.004747558158820501]
	TIME [epoch: 8.18 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003150902811312831		[learning rate: 0.00097715]
	Learning Rate: 0.000977149
	LOSS [training: 0.003150902811312831 | validation: 0.0030087018578605447]
	TIME [epoch: 8.18 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003044938467971959		[learning rate: 0.00097007]
	Learning Rate: 0.000970069
	LOSS [training: 0.003044938467971959 | validation: 0.004007669316225744]
	TIME [epoch: 8.19 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002957519387606364		[learning rate: 0.00096301]
	Learning Rate: 0.000963014
	LOSS [training: 0.002957519387606364 | validation: 0.0036753175186564953]
	TIME [epoch: 8.2 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032309707565153526		[learning rate: 0.00095598]
	Learning Rate: 0.000955983
	LOSS [training: 0.0032309707565153526 | validation: 0.0035846930676253787]
	TIME [epoch: 8.21 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035022220208714362		[learning rate: 0.00094898]
	Learning Rate: 0.000948977
	LOSS [training: 0.0035022220208714362 | validation: 0.002978432798074568]
	TIME [epoch: 8.18 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030343923313648456		[learning rate: 0.000942]
	Learning Rate: 0.000941996
	LOSS [training: 0.0030343923313648456 | validation: 0.0032128709019065838]
	TIME [epoch: 8.19 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003327901522190981		[learning rate: 0.00093504]
	Learning Rate: 0.00093504
	LOSS [training: 0.003327901522190981 | validation: 0.0029701404284471237]
	TIME [epoch: 8.19 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002798973556245931		[learning rate: 0.00092811]
	Learning Rate: 0.000928109
	LOSS [training: 0.002798973556245931 | validation: 0.003516854245215163]
	TIME [epoch: 8.18 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002938952166421791		[learning rate: 0.0009212]
	Learning Rate: 0.000921202
	LOSS [training: 0.002938952166421791 | validation: 0.0034427658965195712]
	TIME [epoch: 8.22 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030774906598238856		[learning rate: 0.00091432]
	Learning Rate: 0.000914321
	LOSS [training: 0.0030774906598238856 | validation: 0.0031209768569883554]
	TIME [epoch: 8.19 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00322985373686848		[learning rate: 0.00090746]
	Learning Rate: 0.000907464
	LOSS [training: 0.00322985373686848 | validation: 0.003111887986613841]
	TIME [epoch: 8.18 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034593500514734235		[learning rate: 0.00090063]
	Learning Rate: 0.000900632
	LOSS [training: 0.0034593500514734235 | validation: 0.0036993299843511565]
	TIME [epoch: 8.19 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032551732239229038		[learning rate: 0.00089382]
	Learning Rate: 0.000893825
	LOSS [training: 0.0032551732239229038 | validation: 0.0031595594440087353]
	TIME [epoch: 8.18 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031345779283935256		[learning rate: 0.00088704]
	Learning Rate: 0.000887043
	LOSS [training: 0.0031345779283935256 | validation: 0.0029644036799325777]
	TIME [epoch: 8.19 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003214690558863945		[learning rate: 0.00088029]
	Learning Rate: 0.000880285
	LOSS [training: 0.003214690558863945 | validation: 0.0033285704477591526]
	TIME [epoch: 8.22 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029676274725635304		[learning rate: 0.00087355]
	Learning Rate: 0.000873553
	LOSS [training: 0.0029676274725635304 | validation: 0.0029215984952121648]
	TIME [epoch: 8.18 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035675908629299044		[learning rate: 0.00086685]
	Learning Rate: 0.000866846
	LOSS [training: 0.0035675908629299044 | validation: 0.0033324316540103488]
	TIME [epoch: 8.19 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028118998311561245		[learning rate: 0.00086016]
	Learning Rate: 0.000860163
	LOSS [training: 0.0028118998311561245 | validation: 0.009840413037771115]
	TIME [epoch: 8.19 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004361077064661738		[learning rate: 0.00085351]
	Learning Rate: 0.000853506
	LOSS [training: 0.004361077064661738 | validation: 0.0034577758781077004]
	TIME [epoch: 8.18 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026328348461033464		[learning rate: 0.00084687]
	Learning Rate: 0.000846874
	LOSS [training: 0.0026328348461033464 | validation: 0.003286244869539858]
	TIME [epoch: 8.21 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002957382138572327		[learning rate: 0.00084027]
	Learning Rate: 0.000840266
	LOSS [training: 0.002957382138572327 | validation: 0.0033890524448752057]
	TIME [epoch: 8.21 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032483477633615133		[learning rate: 0.00083368]
	Learning Rate: 0.000833684
	LOSS [training: 0.0032483477633615133 | validation: 0.002481562302430307]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1703.pth
	Model improved!!!
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029057455926156913		[learning rate: 0.00082713]
	Learning Rate: 0.000827127
	LOSS [training: 0.0029057455926156913 | validation: 0.0033035865526925903]
	TIME [epoch: 8.18 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003089221150011172		[learning rate: 0.00082059]
	Learning Rate: 0.000820595
	LOSS [training: 0.003089221150011172 | validation: 0.003278549003944346]
	TIME [epoch: 8.18 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003288104251921189		[learning rate: 0.00081409]
	Learning Rate: 0.000814088
	LOSS [training: 0.003288104251921189 | validation: 0.003982743292321483]
	TIME [epoch: 8.18 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00295694673749025		[learning rate: 0.00080761]
	Learning Rate: 0.000807606
	LOSS [training: 0.00295694673749025 | validation: 0.0027497883972607395]
	TIME [epoch: 8.22 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029099195403064727		[learning rate: 0.00080115]
	Learning Rate: 0.000801149
	LOSS [training: 0.0029099195403064727 | validation: 0.0034754313421439423]
	TIME [epoch: 8.18 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00298149656949026		[learning rate: 0.00079472]
	Learning Rate: 0.000794718
	LOSS [training: 0.00298149656949026 | validation: 0.003294915814830849]
	TIME [epoch: 8.18 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027949657357348		[learning rate: 0.00078831]
	Learning Rate: 0.000788312
	LOSS [training: 0.0027949657357348 | validation: 0.0028451421208090127]
	TIME [epoch: 8.18 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027874323529035227		[learning rate: 0.00078193]
	Learning Rate: 0.00078193
	LOSS [training: 0.0027874323529035227 | validation: 0.003424860108108106]
	TIME [epoch: 8.18 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030859550312506063		[learning rate: 0.00077557]
	Learning Rate: 0.000775574
	LOSS [training: 0.0030859550312506063 | validation: 0.003249180520329257]
	TIME [epoch: 8.2 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032800209836722043		[learning rate: 0.00076924]
	Learning Rate: 0.000769244
	LOSS [training: 0.0032800209836722043 | validation: 0.004912283578128244]
	TIME [epoch: 8.21 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028833396222176354		[learning rate: 0.00076294]
	Learning Rate: 0.000762938
	LOSS [training: 0.0028833396222176354 | validation: 0.003080637312512794]
	TIME [epoch: 8.18 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00289132566867615		[learning rate: 0.00075666]
	Learning Rate: 0.000756658
	LOSS [training: 0.00289132566867615 | validation: 0.0036406838049618502]
	TIME [epoch: 8.18 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027751300806478744		[learning rate: 0.0007504]
	Learning Rate: 0.000750403
	LOSS [training: 0.0027751300806478744 | validation: 0.004041798631596291]
	TIME [epoch: 8.18 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031574052831999247		[learning rate: 0.00074417]
	Learning Rate: 0.000744174
	LOSS [training: 0.0031574052831999247 | validation: 0.0028322259235800578]
	TIME [epoch: 8.18 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027136905866980347		[learning rate: 0.00073797]
	Learning Rate: 0.000737969
	LOSS [training: 0.0027136905866980347 | validation: 0.003965931005892279]
	TIME [epoch: 8.22 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028218792294840613		[learning rate: 0.00073179]
	Learning Rate: 0.00073179
	LOSS [training: 0.0028218792294840613 | validation: 0.00414516579814679]
	TIME [epoch: 8.19 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003048887272534236		[learning rate: 0.00072564]
	Learning Rate: 0.000725637
	LOSS [training: 0.003048887272534236 | validation: 0.002771045841009695]
	TIME [epoch: 8.19 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002968038143533885		[learning rate: 0.00071951]
	Learning Rate: 0.000719509
	LOSS [training: 0.002968038143533885 | validation: 0.004286770303011945]
	TIME [epoch: 8.19 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003056792384847049		[learning rate: 0.00071341]
	Learning Rate: 0.000713406
	LOSS [training: 0.003056792384847049 | validation: 0.0029430231565381864]
	TIME [epoch: 8.19 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030785506786499377		[learning rate: 0.00070733]
	Learning Rate: 0.000707328
	LOSS [training: 0.0030785506786499377 | validation: 0.0030382052967092097]
	TIME [epoch: 8.19 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002739800176456436		[learning rate: 0.00070128]
	Learning Rate: 0.000701276
	LOSS [training: 0.002739800176456436 | validation: 0.0028160627042293643]
	TIME [epoch: 8.22 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002526531403744748		[learning rate: 0.00069525]
	Learning Rate: 0.00069525
	LOSS [training: 0.002526531403744748 | validation: 0.0029605733162738836]
	TIME [epoch: 8.19 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027227214116748713		[learning rate: 0.00068925]
	Learning Rate: 0.000689249
	LOSS [training: 0.0027227214116748713 | validation: 0.003011870682044727]
	TIME [epoch: 8.18 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002896281712865094		[learning rate: 0.00068327]
	Learning Rate: 0.000683273
	LOSS [training: 0.002896281712865094 | validation: 0.002981888781528317]
	TIME [epoch: 8.18 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002739649207933497		[learning rate: 0.00067732]
	Learning Rate: 0.000677323
	LOSS [training: 0.002739649207933497 | validation: 0.0033309961856151904]
	TIME [epoch: 8.18 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002731770696383708		[learning rate: 0.0006714]
	Learning Rate: 0.000671398
	LOSS [training: 0.002731770696383708 | validation: 0.0032837545834331853]
	TIME [epoch: 8.21 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027714025178948295		[learning rate: 0.0006655]
	Learning Rate: 0.000665499
	LOSS [training: 0.0027714025178948295 | validation: 0.004551097820186262]
	TIME [epoch: 8.19 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003110409604171755		[learning rate: 0.00065963]
	Learning Rate: 0.000659625
	LOSS [training: 0.003110409604171755 | validation: 0.002681781337210895]
	TIME [epoch: 8.19 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002837650799129175		[learning rate: 0.00065378]
	Learning Rate: 0.000653777
	LOSS [training: 0.002837650799129175 | validation: 0.0032229236360742488]
	TIME [epoch: 8.18 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002748495721959793		[learning rate: 0.00064795]
	Learning Rate: 0.000647955
	LOSS [training: 0.002748495721959793 | validation: 0.0028542914431061465]
	TIME [epoch: 8.18 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027631300205926616		[learning rate: 0.00064216]
	Learning Rate: 0.000642158
	LOSS [training: 0.0027631300205926616 | validation: 0.0037262728835430786]
	TIME [epoch: 8.19 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002768975932658842		[learning rate: 0.00063639]
	Learning Rate: 0.000636387
	LOSS [training: 0.002768975932658842 | validation: 0.0029551421064003868]
	TIME [epoch: 8.23 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027633990676389497		[learning rate: 0.00063064]
	Learning Rate: 0.000630641
	LOSS [training: 0.0027633990676389497 | validation: 0.0028180486576095997]
	TIME [epoch: 8.19 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002667065314217537		[learning rate: 0.00062492]
	Learning Rate: 0.000624921
	LOSS [training: 0.002667065314217537 | validation: 0.0033328040509617886]
	TIME [epoch: 8.19 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027839643813743235		[learning rate: 0.00061923]
	Learning Rate: 0.000619226
	LOSS [training: 0.0027839643813743235 | validation: 0.0029902199798070737]
	TIME [epoch: 8.19 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029422252952693807		[learning rate: 0.00061356]
	Learning Rate: 0.000613558
	LOSS [training: 0.0029422252952693807 | validation: 0.0028018659886944334]
	TIME [epoch: 8.18 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027315386854384963		[learning rate: 0.00060791]
	Learning Rate: 0.000607914
	LOSS [training: 0.0027315386854384963 | validation: 0.003909861344185665]
	TIME [epoch: 8.21 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003346319751363915		[learning rate: 0.0006023]
	Learning Rate: 0.000602297
	LOSS [training: 0.003346319751363915 | validation: 0.00520123489401822]
	TIME [epoch: 8.21 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00304498481125582		[learning rate: 0.00059671]
	Learning Rate: 0.000596705
	LOSS [training: 0.00304498481125582 | validation: 0.003408784727758598]
	TIME [epoch: 8.18 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025250223166944225		[learning rate: 0.00059114]
	Learning Rate: 0.000591139
	LOSS [training: 0.0025250223166944225 | validation: 0.0033693006530959198]
	TIME [epoch: 8.18 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002936231874772906		[learning rate: 0.0005856]
	Learning Rate: 0.000585599
	LOSS [training: 0.002936231874772906 | validation: 0.003967255894978143]
	TIME [epoch: 8.18 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002937465698401625		[learning rate: 0.00058008]
	Learning Rate: 0.000580085
	LOSS [training: 0.002937465698401625 | validation: 0.0027077164776108395]
	TIME [epoch: 8.19 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027328953892461474		[learning rate: 0.0005746]
	Learning Rate: 0.000574596
	LOSS [training: 0.0027328953892461474 | validation: 0.003144415377220039]
	TIME [epoch: 8.22 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002760107622926954		[learning rate: 0.00056913]
	Learning Rate: 0.000569133
	LOSS [training: 0.002760107622926954 | validation: 0.003523842831062386]
	TIME [epoch: 8.19 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002735462610939867		[learning rate: 0.0005637]
	Learning Rate: 0.000563696
	LOSS [training: 0.002735462610939867 | validation: 0.0030089708568619075]
	TIME [epoch: 8.19 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029836680996069356		[learning rate: 0.00055828]
	Learning Rate: 0.000558285
	LOSS [training: 0.0029836680996069356 | validation: 0.002930062392299477]
	TIME [epoch: 8.18 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024541130407325974		[learning rate: 0.0005529]
	Learning Rate: 0.000552899
	LOSS [training: 0.0024541130407325974 | validation: 0.0030884018084248624]
	TIME [epoch: 8.18 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028854445954688028		[learning rate: 0.00054754]
	Learning Rate: 0.000547539
	LOSS [training: 0.0028854445954688028 | validation: 0.003405118561981355]
	TIME [epoch: 8.19 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002965526980399538		[learning rate: 0.00054221]
	Learning Rate: 0.000542206
	LOSS [training: 0.002965526980399538 | validation: 0.0034984964830482596]
	TIME [epoch: 8.22 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025859604320326453		[learning rate: 0.0005369]
	Learning Rate: 0.000536898
	LOSS [training: 0.0025859604320326453 | validation: 0.0033252272546250056]
	TIME [epoch: 8.18 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028673576066411553		[learning rate: 0.00053162]
	Learning Rate: 0.000531616
	LOSS [training: 0.0028673576066411553 | validation: 0.0027151266537846505]
	TIME [epoch: 8.18 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002904270869942106		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.002904270869942106 | validation: 0.002745195578360451]
	TIME [epoch: 8.18 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027062122053654225		[learning rate: 0.00052113]
	Learning Rate: 0.000521129
	LOSS [training: 0.0027062122053654225 | validation: 0.0033859445835345238]
	TIME [epoch: 8.18 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00293013384168486		[learning rate: 0.00051592]
	Learning Rate: 0.000515925
	LOSS [training: 0.00293013384168486 | validation: 0.0033139740446793526]
	TIME [epoch: 8.21 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002761796964585643		[learning rate: 0.00051075]
	Learning Rate: 0.000510746
	LOSS [training: 0.002761796964585643 | validation: 0.0028528661318782678]
	TIME [epoch: 8.2 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002443740095195323		[learning rate: 0.00050559]
	Learning Rate: 0.000505594
	LOSS [training: 0.002443740095195323 | validation: 0.0028335999237947655]
	TIME [epoch: 8.18 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003101210004854954		[learning rate: 0.00050047]
	Learning Rate: 0.000500468
	LOSS [training: 0.003101210004854954 | validation: 0.002716495988575755]
	TIME [epoch: 8.19 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00250195493743853		[learning rate: 0.00049537]
	Learning Rate: 0.000495367
	LOSS [training: 0.00250195493743853 | validation: 0.002844046810162564]
	TIME [epoch: 8.18 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00249892335044835		[learning rate: 0.00049029]
	Learning Rate: 0.000490293
	LOSS [training: 0.00249892335044835 | validation: 0.002874368029903092]
	TIME [epoch: 8.19 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025968832491590236		[learning rate: 0.00048524]
	Learning Rate: 0.000485244
	LOSS [training: 0.0025968832491590236 | validation: 0.0036771681188224924]
	TIME [epoch: 8.22 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026134806303822647		[learning rate: 0.00048022]
	Learning Rate: 0.000480222
	LOSS [training: 0.0026134806303822647 | validation: 0.0026015912120936416]
	TIME [epoch: 8.19 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028285723954286344		[learning rate: 0.00047523]
	Learning Rate: 0.000475226
	LOSS [training: 0.0028285723954286344 | validation: 0.003138467138249902]
	TIME [epoch: 8.19 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027777887658579216		[learning rate: 0.00047026]
	Learning Rate: 0.000470255
	LOSS [training: 0.0027777887658579216 | validation: 0.0030961260687606814]
	TIME [epoch: 8.19 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024355918361872327		[learning rate: 0.00046531]
	Learning Rate: 0.000465311
	LOSS [training: 0.0024355918361872327 | validation: 0.0023796676471465423]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1767.pth
	Model improved!!!
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027125428834383226		[learning rate: 0.00046039]
	Learning Rate: 0.000460393
	LOSS [training: 0.0027125428834383226 | validation: 0.002776396129656483]
	TIME [epoch: 8.22 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025318443932872622		[learning rate: 0.0004555]
	Learning Rate: 0.000455501
	LOSS [training: 0.0025318443932872622 | validation: 0.0034323513599579416]
	TIME [epoch: 8.23 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027395044259323777		[learning rate: 0.00045063]
	Learning Rate: 0.000450635
	LOSS [training: 0.0027395044259323777 | validation: 0.0028553446393061463]
	TIME [epoch: 8.2 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002598839646523733		[learning rate: 0.00044579]
	Learning Rate: 0.000445795
	LOSS [training: 0.002598839646523733 | validation: 0.0033494051029599164]
	TIME [epoch: 8.2 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002619673082464893		[learning rate: 0.00044098]
	Learning Rate: 0.000440981
	LOSS [training: 0.002619673082464893 | validation: 0.002993816646479632]
	TIME [epoch: 8.2 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023315014081808534		[learning rate: 0.00043619]
	Learning Rate: 0.000436194
	LOSS [training: 0.0023315014081808534 | validation: 0.002982554742961796]
	TIME [epoch: 8.2 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026318066770721843		[learning rate: 0.00043143]
	Learning Rate: 0.000431432
	LOSS [training: 0.0026318066770721843 | validation: 0.002645267321203046]
	TIME [epoch: 8.24 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026045413888422624		[learning rate: 0.0004267]
	Learning Rate: 0.000426697
	LOSS [training: 0.0026045413888422624 | validation: 0.0026405617310455024]
	TIME [epoch: 8.21 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023829246914024056		[learning rate: 0.00042199]
	Learning Rate: 0.000421988
	LOSS [training: 0.0023829246914024056 | validation: 0.0034083449550125484]
	TIME [epoch: 8.2 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00253584641739292		[learning rate: 0.00041731]
	Learning Rate: 0.000417305
	LOSS [training: 0.00253584641739292 | validation: 0.003157670706496452]
	TIME [epoch: 8.2 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002466049313552503		[learning rate: 0.00041265]
	Learning Rate: 0.000412649
	LOSS [training: 0.002466049313552503 | validation: 0.0027710588712245446]
	TIME [epoch: 8.2 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026651930658871505		[learning rate: 0.00040802]
	Learning Rate: 0.000408018
	LOSS [training: 0.0026651930658871505 | validation: 0.003058851884839276]
	TIME [epoch: 8.2 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002532119650556558		[learning rate: 0.00040341]
	Learning Rate: 0.000403414
	LOSS [training: 0.002532119650556558 | validation: 0.0031375888610165686]
	TIME [epoch: 8.23 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002773694168395167		[learning rate: 0.00039884]
	Learning Rate: 0.000398836
	LOSS [training: 0.002773694168395167 | validation: 0.0033287657635064634]
	TIME [epoch: 8.2 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002441268619088255		[learning rate: 0.00039428]
	Learning Rate: 0.000394284
	LOSS [training: 0.002441268619088255 | validation: 0.0032321079935801037]
	TIME [epoch: 8.2 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002589601188470041		[learning rate: 0.00038976]
	Learning Rate: 0.000389759
	LOSS [training: 0.002589601188470041 | validation: 0.002807485279921174]
	TIME [epoch: 8.2 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002301885195265606		[learning rate: 0.00038526]
	Learning Rate: 0.00038526
	LOSS [training: 0.002301885195265606 | validation: 0.0034332031409048626]
	TIME [epoch: 8.21 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024668005958676797		[learning rate: 0.00038079]
	Learning Rate: 0.000380787
	LOSS [training: 0.0024668005958676797 | validation: 0.002747210500535135]
	TIME [epoch: 8.23 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002490868744203113		[learning rate: 0.00037634]
	Learning Rate: 0.000376341
	LOSS [training: 0.002490868744203113 | validation: 0.0031769334083028918]
	TIME [epoch: 8.21 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025353909008838716		[learning rate: 0.00037192]
	Learning Rate: 0.00037192
	LOSS [training: 0.0025353909008838716 | validation: 0.002790343755503459]
	TIME [epoch: 8.2 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002677068490147962		[learning rate: 0.00036753]
	Learning Rate: 0.000367527
	LOSS [training: 0.002677068490147962 | validation: 0.0034773263411891557]
	TIME [epoch: 8.19 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028661428955392898		[learning rate: 0.00036316]
	Learning Rate: 0.000363159
	LOSS [training: 0.0028661428955392898 | validation: 0.002745680426751858]
	TIME [epoch: 8.2 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002470351280783996		[learning rate: 0.00035882]
	Learning Rate: 0.000358818
	LOSS [training: 0.002470351280783996 | validation: 0.0027162032832657025]
	TIME [epoch: 8.19 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024363768490867103		[learning rate: 0.0003545]
	Learning Rate: 0.000354503
	LOSS [training: 0.0024363768490867103 | validation: 0.0025811596810631594]
	TIME [epoch: 8.24 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026965250047357153		[learning rate: 0.00035022]
	Learning Rate: 0.000350215
	LOSS [training: 0.0026965250047357153 | validation: 0.003150858126948336]
	TIME [epoch: 8.19 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025072407466286183		[learning rate: 0.00034595]
	Learning Rate: 0.000345953
	LOSS [training: 0.0025072407466286183 | validation: 0.002937437059638743]
	TIME [epoch: 8.19 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002657833180035262		[learning rate: 0.00034172]
	Learning Rate: 0.000341718
	LOSS [training: 0.002657833180035262 | validation: 0.0028472915139514817]
	TIME [epoch: 8.19 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002479759375847432		[learning rate: 0.00033751]
	Learning Rate: 0.000337508
	LOSS [training: 0.002479759375847432 | validation: 0.0032161314246152164]
	TIME [epoch: 8.19 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024811748232025812		[learning rate: 0.00033333]
	Learning Rate: 0.000333326
	LOSS [training: 0.0024811748232025812 | validation: 0.0033048844203545473]
	TIME [epoch: 8.21 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026059553976409593		[learning rate: 0.00032917]
	Learning Rate: 0.000329169
	LOSS [training: 0.0026059553976409593 | validation: 0.0031390876905123865]
	TIME [epoch: 8.22 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002374549118446618		[learning rate: 0.00032504]
	Learning Rate: 0.00032504
	LOSS [training: 0.002374549118446618 | validation: 0.003166281935402556]
	TIME [epoch: 8.19 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024970258117370304		[learning rate: 0.00032094]
	Learning Rate: 0.000320936
	LOSS [training: 0.0024970258117370304 | validation: 0.00318687078604762]
	TIME [epoch: 8.19 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022639289199820377		[learning rate: 0.00031686]
	Learning Rate: 0.000316859
	LOSS [training: 0.0022639289199820377 | validation: 0.0033213945560286824]
	TIME [epoch: 8.19 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022946147541451746		[learning rate: 0.00031281]
	Learning Rate: 0.000312809
	LOSS [training: 0.0022946147541451746 | validation: 0.00296378296173114]
	TIME [epoch: 8.19 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002402059398139501		[learning rate: 0.00030879]
	Learning Rate: 0.000308785
	LOSS [training: 0.002402059398139501 | validation: 0.0032099232311796084]
	TIME [epoch: 8.23 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024810133069757675		[learning rate: 0.00030479]
	Learning Rate: 0.000304788
	LOSS [training: 0.0024810133069757675 | validation: 0.0028115490222404543]
	TIME [epoch: 8.19 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025853397406153745		[learning rate: 0.00030082]
	Learning Rate: 0.000300817
	LOSS [training: 0.0025853397406153745 | validation: 0.0026410787335986994]
	TIME [epoch: 8.19 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024259460675363437		[learning rate: 0.00029687]
	Learning Rate: 0.000296873
	LOSS [training: 0.0024259460675363437 | validation: 0.0033980563636295917]
	TIME [epoch: 8.19 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00230070847895002		[learning rate: 0.00029295]
	Learning Rate: 0.000292955
	LOSS [training: 0.00230070847895002 | validation: 0.003061537305595759]
	TIME [epoch: 8.19 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026096279244189223		[learning rate: 0.00028906]
	Learning Rate: 0.000289064
	LOSS [training: 0.0026096279244189223 | validation: 0.0025866877044884665]
	TIME [epoch: 8.2 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002479128148458697		[learning rate: 0.0002852]
	Learning Rate: 0.000285199
	LOSS [training: 0.002479128148458697 | validation: 0.002578970540918446]
	TIME [epoch: 8.23 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002352560445923879		[learning rate: 0.00028136]
	Learning Rate: 0.000281361
	LOSS [training: 0.002352560445923879 | validation: 0.003328845508850365]
	TIME [epoch: 8.19 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023264448216327466		[learning rate: 0.00027755]
	Learning Rate: 0.000277549
	LOSS [training: 0.0023264448216327466 | validation: 0.0035594220477042546]
	TIME [epoch: 8.18 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002336629897353131		[learning rate: 0.00027376]
	Learning Rate: 0.000273764
	LOSS [training: 0.002336629897353131 | validation: 0.0027368240669399376]
	TIME [epoch: 8.19 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023648416482984487		[learning rate: 0.00027001]
	Learning Rate: 0.000270006
	LOSS [training: 0.0023648416482984487 | validation: 0.0036349414843984073]
	TIME [epoch: 8.19 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025283089974665433		[learning rate: 0.00026627]
	Learning Rate: 0.000266274
	LOSS [training: 0.0025283089974665433 | validation: 0.0031165585181267257]
	TIME [epoch: 8.22 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002341483072058372		[learning rate: 0.00026257]
	Learning Rate: 0.000262569
	LOSS [training: 0.002341483072058372 | validation: 0.003140951940203749]
	TIME [epoch: 8.2 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024759659366803584		[learning rate: 0.00025889]
	Learning Rate: 0.000258891
	LOSS [training: 0.0024759659366803584 | validation: 0.002640957854896393]
	TIME [epoch: 8.19 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025625823996313487		[learning rate: 0.00025524]
	Learning Rate: 0.000255239
	LOSS [training: 0.0025625823996313487 | validation: 0.0029484336912750414]
	TIME [epoch: 8.18 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002680022319909826		[learning rate: 0.00025161]
	Learning Rate: 0.000251614
	LOSS [training: 0.002680022319909826 | validation: 0.002580771908539379]
	TIME [epoch: 8.19 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024106854490877575		[learning rate: 0.00024802]
	Learning Rate: 0.000248016
	LOSS [training: 0.0024106854490877575 | validation: 0.0025289636973119187]
	TIME [epoch: 8.19 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002513019507140775		[learning rate: 0.00024444]
	Learning Rate: 0.000244444
	LOSS [training: 0.002513019507140775 | validation: 0.003096839147269884]
	TIME [epoch: 8.24 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002432448010207471		[learning rate: 0.0002409]
	Learning Rate: 0.000240899
	LOSS [training: 0.002432448010207471 | validation: 0.0024431084015045642]
	TIME [epoch: 8.19 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002255546278376374		[learning rate: 0.00023738]
	Learning Rate: 0.00023738
	LOSS [training: 0.002255546278376374 | validation: 0.0027759796614954934]
	TIME [epoch: 8.19 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002466096423631049		[learning rate: 0.00023389]
	Learning Rate: 0.000233889
	LOSS [training: 0.002466096423631049 | validation: 0.0036612527335769937]
	TIME [epoch: 8.19 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022615736851566296		[learning rate: 0.00023042]
	Learning Rate: 0.000230424
	LOSS [training: 0.0022615736851566296 | validation: 0.0026889202233889007]
	TIME [epoch: 8.18 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00238607983201571		[learning rate: 0.00022699]
	Learning Rate: 0.000226985
	LOSS [training: 0.00238607983201571 | validation: 0.0027767702286478563]
	TIME [epoch: 8.2 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002433081546211289		[learning rate: 0.00022357]
	Learning Rate: 0.000223574
	LOSS [training: 0.002433081546211289 | validation: 0.0029780617275801235]
	TIME [epoch: 8.23 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025954697439750044		[learning rate: 0.00022019]
	Learning Rate: 0.000220189
	LOSS [training: 0.0025954697439750044 | validation: 0.0028395765777225026]
	TIME [epoch: 8.19 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024766870811440463		[learning rate: 0.00021683]
	Learning Rate: 0.000216831
	LOSS [training: 0.0024766870811440463 | validation: 0.002737127565404764]
	TIME [epoch: 8.19 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023712439536394767		[learning rate: 0.0002135]
	Learning Rate: 0.0002135
	LOSS [training: 0.0023712439536394767 | validation: 0.002317369190987182]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1828.pth
	Model improved!!!
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002399222154688971		[learning rate: 0.0002102]
	Learning Rate: 0.000210195
	LOSS [training: 0.002399222154688971 | validation: 0.003155232491046955]
	TIME [epoch: 8.18 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023164772687144994		[learning rate: 0.00020692]
	Learning Rate: 0.000206917
	LOSS [training: 0.0023164772687144994 | validation: 0.002765757227958422]
	TIME [epoch: 8.22 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002821364647558243		[learning rate: 0.00020367]
	Learning Rate: 0.000203667
	LOSS [training: 0.002821364647558243 | validation: 0.002621965140052083]
	TIME [epoch: 8.19 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024039737362354686		[learning rate: 0.00020044]
	Learning Rate: 0.000200442
	LOSS [training: 0.0024039737362354686 | validation: 0.0023305868381983327]
	TIME [epoch: 8.2 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022752545597454358		[learning rate: 0.00019725]
	Learning Rate: 0.000197245
	LOSS [training: 0.0022752545597454358 | validation: 0.002253407131630454]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd5_20240702_103225/states/model_phi1_1a_v_mmd5_1833.pth
	Model improved!!!
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023408129679273553		[learning rate: 0.00019407]
	Learning Rate: 0.000194075
	LOSS [training: 0.0023408129679273553 | validation: 0.0022583595033218258]
	TIME [epoch: 8.18 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002283130457015562		[learning rate: 0.00019093]
	Learning Rate: 0.000190931
	LOSS [training: 0.002283130457015562 | validation: 0.002602343052860637]
	TIME [epoch: 8.19 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002395754196125131		[learning rate: 0.00018781]
	Learning Rate: 0.000187814
	LOSS [training: 0.002395754196125131 | validation: 0.0023559006942731743]
	TIME [epoch: 8.22 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002265788740905405		[learning rate: 0.00018472]
	Learning Rate: 0.000184724
	LOSS [training: 0.002265788740905405 | validation: 0.002826681421801596]
	TIME [epoch: 8.19 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025257858112007164		[learning rate: 0.00018166]
	Learning Rate: 0.000181661
	LOSS [training: 0.0025257858112007164 | validation: 0.0030491565422702217]
	TIME [epoch: 8.18 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002183161850489332		[learning rate: 0.00017862]
	Learning Rate: 0.000178624
	LOSS [training: 0.002183161850489332 | validation: 0.0031282625963282643]
	TIME [epoch: 8.21 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024826515197170205		[learning rate: 0.00017561]
	Learning Rate: 0.000175615
	LOSS [training: 0.0024826515197170205 | validation: 0.002748223346614607]
	TIME [epoch: 8.2 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025070364111676614		[learning rate: 0.00017263]
	Learning Rate: 0.000172632
	LOSS [training: 0.0025070364111676614 | validation: 0.0026281001483740908]
	TIME [epoch: 8.22 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002192768108832533		[learning rate: 0.00016968]
	Learning Rate: 0.000169677
	LOSS [training: 0.002192768108832533 | validation: 0.0031572040523683382]
	TIME [epoch: 8.19 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002351487741245542		[learning rate: 0.00016675]
	Learning Rate: 0.000166748
	LOSS [training: 0.002351487741245542 | validation: 0.002796268327208887]
	TIME [epoch: 8.18 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002307011228511851		[learning rate: 0.00016385]
	Learning Rate: 0.000163846
	LOSS [training: 0.002307011228511851 | validation: 0.002845155971501324]
	TIME [epoch: 8.19 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025874210702607507		[learning rate: 0.00016097]
	Learning Rate: 0.000160971
	LOSS [training: 0.0025874210702607507 | validation: 0.0031094733025445838]
	TIME [epoch: 8.19 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002275234331069739		[learning rate: 0.00015812]
	Learning Rate: 0.000158123
	LOSS [training: 0.002275234331069739 | validation: 0.0026161707855675786]
	TIME [epoch: 8.19 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002462763256500738		[learning rate: 0.0001553]
	Learning Rate: 0.000155302
	LOSS [training: 0.002462763256500738 | validation: 0.002803354490560257]
	TIME [epoch: 8.22 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023239064290609254		[learning rate: 0.00015251]
	Learning Rate: 0.000152507
	LOSS [training: 0.0023239064290609254 | validation: 0.002673897351053248]
	TIME [epoch: 8.18 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021643784639493006		[learning rate: 0.00014974]
	Learning Rate: 0.00014974
	LOSS [training: 0.0021643784639493006 | validation: 0.0027145649152927323]
	TIME [epoch: 8.18 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002509194700062018		[learning rate: 0.000147]
	Learning Rate: 0.000147
	LOSS [training: 0.002509194700062018 | validation: 0.00293931684932377]
	TIME [epoch: 8.18 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022245426409752325		[learning rate: 0.00014429]
	Learning Rate: 0.000144286
	LOSS [training: 0.0022245426409752325 | validation: 0.0027124649485151613]
	TIME [epoch: 8.18 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024469617374901363		[learning rate: 0.0001416]
	Learning Rate: 0.0001416
	LOSS [training: 0.0024469617374901363 | validation: 0.0027973218700696645]
	TIME [epoch: 8.21 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025211460560557596		[learning rate: 0.00013894]
	Learning Rate: 0.00013894
	LOSS [training: 0.0025211460560557596 | validation: 0.0026213677057917283]
	TIME [epoch: 8.21 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002402287322357815		[learning rate: 0.00013631]
	Learning Rate: 0.000136308
	LOSS [training: 0.002402287322357815 | validation: 0.0031221326791262467]
	TIME [epoch: 8.18 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024913853988192524		[learning rate: 0.0001337]
	Learning Rate: 0.000133702
	LOSS [training: 0.0024913853988192524 | validation: 0.002794881462478932]
	TIME [epoch: 8.19 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002381951032358158		[learning rate: 0.00013112]
	Learning Rate: 0.000131124
	LOSS [training: 0.002381951032358158 | validation: 0.0026501292334982656]
	TIME [epoch: 8.18 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024475035865540447		[learning rate: 0.00012857]
	Learning Rate: 0.000128572
	LOSS [training: 0.0024475035865540447 | validation: 0.0026307706288800515]
	TIME [epoch: 8.19 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002539547055735601		[learning rate: 0.00012605]
	Learning Rate: 0.000126048
	LOSS [training: 0.002539547055735601 | validation: 0.0035605892936801248]
	TIME [epoch: 8.22 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023931282892198894		[learning rate: 0.00012355]
	Learning Rate: 0.00012355
	LOSS [training: 0.0023931282892198894 | validation: 0.0027450430137056243]
	TIME [epoch: 8.19 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023746156408687045		[learning rate: 0.00012108]
	Learning Rate: 0.000121079
	LOSS [training: 0.0023746156408687045 | validation: 0.002896514307128015]
	TIME [epoch: 8.19 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002348235370612541		[learning rate: 0.00011864]
	Learning Rate: 0.000118636
	LOSS [training: 0.002348235370612541 | validation: 0.003070574459408992]
	TIME [epoch: 8.18 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022656815858764293		[learning rate: 0.00011622]
	Learning Rate: 0.000116219
	LOSS [training: 0.0022656815858764293 | validation: 0.0030893715872195512]
	TIME [epoch: 8.18 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002163718766813812		[learning rate: 0.00011383]
	Learning Rate: 0.00011383
	LOSS [training: 0.002163718766813812 | validation: 0.0032859936042611447]
	TIME [epoch: 8.19 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023015184385803368		[learning rate: 0.00011147]
	Learning Rate: 0.000111468
	LOSS [training: 0.0023015184385803368 | validation: 0.002920225674927126]
	TIME [epoch: 8.22 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002271346539373623		[learning rate: 0.00010913]
	Learning Rate: 0.000109132
	LOSS [training: 0.002271346539373623 | validation: 0.002556545940076066]
	TIME [epoch: 8.21 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002565748733069427		[learning rate: 0.00010682]
	Learning Rate: 0.000106824
	LOSS [training: 0.002565748733069427 | validation: 0.002811522224279597]
	TIME [epoch: 8.18 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002408708001281953		[learning rate: 0.00010454]
	Learning Rate: 0.000104543
	LOSS [training: 0.002408708001281953 | validation: 0.0026584030725591195]
	TIME [epoch: 8.18 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025654835829598743		[learning rate: 0.00010229]
	Learning Rate: 0.000102289
	LOSS [training: 0.0025654835829598743 | validation: 0.0025524165590574558]
	TIME [epoch: 8.18 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023908279643801485		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.0023908279643801485 | validation: 0.0024660985816734645]
	TIME [epoch: 8.22 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002177491022376738		[learning rate: 9.7861e-05]
	Learning Rate: 9.78614e-05
	LOSS [training: 0.002177491022376738 | validation: 0.0027891640558007323]
	TIME [epoch: 8.19 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024408583005385252		[learning rate: 9.5688e-05]
	Learning Rate: 9.56885e-05
	LOSS [training: 0.0024408583005385252 | validation: 0.0028484675383409525]
	TIME [epoch: 8.17 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021216633195312797		[learning rate: 9.3543e-05]
	Learning Rate: 9.35426e-05
	LOSS [training: 0.0021216633195312797 | validation: 0.0028810921571600064]
	TIME [epoch: 8.19 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024028563049145815		[learning rate: 9.1424e-05]
	Learning Rate: 9.14239e-05
	LOSS [training: 0.0024028563049145815 | validation: 0.0028871843357387997]
	TIME [epoch: 8.18 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022289407659216477		[learning rate: 8.9332e-05]
	Learning Rate: 8.93322e-05
	LOSS [training: 0.0022289407659216477 | validation: 0.0031511872445012194]
	TIME [epoch: 8.19 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024087339010069237		[learning rate: 8.7268e-05]
	Learning Rate: 8.72677e-05
	LOSS [training: 0.0024087339010069237 | validation: 0.0027415689087164916]
	TIME [epoch: 8.22 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025406760351546595		[learning rate: 8.523e-05]
	Learning Rate: 8.52303e-05
	LOSS [training: 0.0025406760351546595 | validation: 0.0029969514052039354]
	TIME [epoch: 8.18 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002276777192177298		[learning rate: 8.322e-05]
	Learning Rate: 8.322e-05
	LOSS [training: 0.002276777192177298 | validation: 0.0027455951886151547]
	TIME [epoch: 8.18 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002344245229062517		[learning rate: 8.1237e-05]
	Learning Rate: 8.12368e-05
	LOSS [training: 0.002344245229062517 | validation: 0.002873388997761258]
	TIME [epoch: 8.19 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002474727719045018		[learning rate: 7.9281e-05]
	Learning Rate: 7.92808e-05
	LOSS [training: 0.002474727719045018 | validation: 0.003039411124769199]
	TIME [epoch: 8.18 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022208865276501584		[learning rate: 7.7352e-05]
	Learning Rate: 7.73519e-05
	LOSS [training: 0.0022208865276501584 | validation: 0.002994776309297038]
	TIME [epoch: 8.2 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023877538499246635		[learning rate: 7.545e-05]
	Learning Rate: 7.54501e-05
	LOSS [training: 0.0023877538499246635 | validation: 0.0030657859168460176]
	TIME [epoch: 8.21 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002479818499883505		[learning rate: 7.3575e-05]
	Learning Rate: 7.35755e-05
	LOSS [training: 0.002479818499883505 | validation: 0.00259839979235579]
	TIME [epoch: 8.18 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002208302901277273		[learning rate: 7.1728e-05]
	Learning Rate: 7.1728e-05
	LOSS [training: 0.002208302901277273 | validation: 0.0025667962626495316]
	TIME [epoch: 8.19 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002356300082076642		[learning rate: 6.9908e-05]
	Learning Rate: 6.99077e-05
	LOSS [training: 0.002356300082076642 | validation: 0.0023762471067468784]
	TIME [epoch: 8.18 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022812163941822003		[learning rate: 6.8115e-05]
	Learning Rate: 6.81146e-05
	LOSS [training: 0.0022812163941822003 | validation: 0.0030826627393585847]
	TIME [epoch: 8.18 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024185080160702838		[learning rate: 6.6349e-05]
	Learning Rate: 6.63486e-05
	LOSS [training: 0.0024185080160702838 | validation: 0.0026858567025409103]
	TIME [epoch: 8.23 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002548410820651741		[learning rate: 6.461e-05]
	Learning Rate: 6.46098e-05
	LOSS [training: 0.002548410820651741 | validation: 0.002814224249453226]
	TIME [epoch: 8.19 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002257551725791145		[learning rate: 6.2898e-05]
	Learning Rate: 6.28982e-05
	LOSS [training: 0.002257551725791145 | validation: 0.002301327741084603]
	TIME [epoch: 8.2 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024371641730127885		[learning rate: 6.1214e-05]
	Learning Rate: 6.12137e-05
	LOSS [training: 0.0024371641730127885 | validation: 0.002885199895706742]
	TIME [epoch: 8.18 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023534789821516725		[learning rate: 5.9556e-05]
	Learning Rate: 5.95565e-05
	LOSS [training: 0.0023534789821516725 | validation: 0.0024215789807393046]
	TIME [epoch: 8.18 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023229632332470427		[learning rate: 5.7926e-05]
	Learning Rate: 5.79264e-05
	LOSS [training: 0.0023229632332470427 | validation: 0.0027174304718997435]
	TIME [epoch: 8.19 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002329790135073414		[learning rate: 5.6324e-05]
	Learning Rate: 5.63235e-05
	LOSS [training: 0.002329790135073414 | validation: 0.002984096500276404]
	TIME [epoch: 8.22 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002321470910847185		[learning rate: 5.4748e-05]
	Learning Rate: 5.47478e-05
	LOSS [training: 0.002321470910847185 | validation: 0.003310053165112243]
	TIME [epoch: 8.18 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021912606635531946		[learning rate: 5.3199e-05]
	Learning Rate: 5.31994e-05
	LOSS [training: 0.0021912606635531946 | validation: 0.0030575502976374356]
	TIME [epoch: 8.18 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002299109309712729		[learning rate: 5.1678e-05]
	Learning Rate: 5.16781e-05
	LOSS [training: 0.002299109309712729 | validation: 0.0027686662957249358]
	TIME [epoch: 8.18 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023645504953056233		[learning rate: 5.0184e-05]
	Learning Rate: 5.0184e-05
	LOSS [training: 0.0023645504953056233 | validation: 0.002871374889225606]
	TIME [epoch: 8.18 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020772616191249756		[learning rate: 4.8717e-05]
	Learning Rate: 4.87172e-05
	LOSS [training: 0.0020772616191249756 | validation: 0.003198173272890942]
	TIME [epoch: 8.22 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023406311809423598		[learning rate: 4.7278e-05]
	Learning Rate: 4.72776e-05
	LOSS [training: 0.0023406311809423598 | validation: 0.003032195651385047]
	TIME [epoch: 8.2 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002455124771706111		[learning rate: 4.5865e-05]
	Learning Rate: 4.58652e-05
	LOSS [training: 0.002455124771706111 | validation: 0.002886626907827346]
	TIME [epoch: 8.18 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00253270180349974		[learning rate: 4.448e-05]
	Learning Rate: 4.448e-05
	LOSS [training: 0.00253270180349974 | validation: 0.0028563266709716855]
	TIME [epoch: 8.18 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002308561785355713		[learning rate: 4.3122e-05]
	Learning Rate: 4.31221e-05
	LOSS [training: 0.002308561785355713 | validation: 0.00293931605046808]
	TIME [epoch: 8.18 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024860450710329305		[learning rate: 4.1791e-05]
	Learning Rate: 4.17914e-05
	LOSS [training: 0.0024860450710329305 | validation: 0.0035673055392847486]
	TIME [epoch: 8.18 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023727816940157373		[learning rate: 4.0488e-05]
	Learning Rate: 4.04879e-05
	LOSS [training: 0.0023727816940157373 | validation: 0.002690952576429753]
	TIME [epoch: 8.22 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021702955027685183		[learning rate: 3.9212e-05]
	Learning Rate: 3.92117e-05
	LOSS [training: 0.0021702955027685183 | validation: 0.002961218112514056]
	TIME [epoch: 8.18 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024083837713526125		[learning rate: 3.7963e-05]
	Learning Rate: 3.79628e-05
	LOSS [training: 0.0024083837713526125 | validation: 0.002771249665837503]
	TIME [epoch: 8.18 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023770172193073756		[learning rate: 3.6741e-05]
	Learning Rate: 3.6741e-05
	LOSS [training: 0.0023770172193073756 | validation: 0.00307974999149225]
	TIME [epoch: 8.18 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023129560318391534		[learning rate: 3.5547e-05]
	Learning Rate: 3.55466e-05
	LOSS [training: 0.0023129560318391534 | validation: 0.0030675648388479903]
	TIME [epoch: 8.2 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022567080848897177		[learning rate: 3.4379e-05]
	Learning Rate: 3.43794e-05
	LOSS [training: 0.0022567080848897177 | validation: 0.0030306795310972683]
	TIME [epoch: 8.2 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025102073368262045		[learning rate: 3.3239e-05]
	Learning Rate: 3.32394e-05
	LOSS [training: 0.0025102073368262045 | validation: 0.0032159063329458603]
	TIME [epoch: 8.21 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023189758208650713		[learning rate: 3.2127e-05]
	Learning Rate: 3.21267e-05
	LOSS [training: 0.0023189758208650713 | validation: 0.00324358115365456]
	TIME [epoch: 8.18 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002232058114066419		[learning rate: 3.1041e-05]
	Learning Rate: 3.10413e-05
	LOSS [training: 0.002232058114066419 | validation: 0.0033183388680480073]
	TIME [epoch: 8.18 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021546794905315516		[learning rate: 2.9983e-05]
	Learning Rate: 2.99831e-05
	LOSS [training: 0.0021546794905315516 | validation: 0.002496848316606999]
	TIME [epoch: 8.18 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020660299738164342		[learning rate: 2.8952e-05]
	Learning Rate: 2.89522e-05
	LOSS [training: 0.0020660299738164342 | validation: 0.0028120767093496816]
	TIME [epoch: 8.18 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002425978743398642		[learning rate: 2.7949e-05]
	Learning Rate: 2.79486e-05
	LOSS [training: 0.002425978743398642 | validation: 0.0024988161494193008]
	TIME [epoch: 8.22 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023697898093046417		[learning rate: 2.6972e-05]
	Learning Rate: 2.69723e-05
	LOSS [training: 0.0023697898093046417 | validation: 0.002369180876340799]
	TIME [epoch: 8.19 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025691610647073115		[learning rate: 2.6023e-05]
	Learning Rate: 2.60232e-05
	LOSS [training: 0.0025691610647073115 | validation: 0.0033350200927843134]
	TIME [epoch: 8.19 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024964059980379064		[learning rate: 2.5101e-05]
	Learning Rate: 2.51015e-05
	LOSS [training: 0.0024964059980379064 | validation: 0.0030831226214299576]
	TIME [epoch: 8.18 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002195939901934741		[learning rate: 2.4207e-05]
	Learning Rate: 2.4207e-05
	LOSS [training: 0.002195939901934741 | validation: 0.002667605739943387]
	TIME [epoch: 8.18 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002398966541977106		[learning rate: 2.334e-05]
	Learning Rate: 2.33398e-05
	LOSS [training: 0.002398966541977106 | validation: 0.0025774358215883736]
	TIME [epoch: 8.19 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002176841933044994		[learning rate: 2.25e-05]
	Learning Rate: 2.24999e-05
	LOSS [training: 0.002176841933044994 | validation: 0.003230060613273994]
	TIME [epoch: 8.22 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024958930070137987		[learning rate: 2.1687e-05]
	Learning Rate: 2.16873e-05
	LOSS [training: 0.0024958930070137987 | validation: 0.0024681996835186184]
	TIME [epoch: 8.19 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002547579899173237		[learning rate: 2.0902e-05]
	Learning Rate: 2.09019e-05
	LOSS [training: 0.002547579899173237 | validation: 0.00276700773292557]
	TIME [epoch: 8.19 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024676861403650397		[learning rate: 2.0144e-05]
	Learning Rate: 2.01439e-05
	LOSS [training: 0.0024676861403650397 | validation: 0.00309605509473896]
	TIME [epoch: 8.18 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002328971835644907		[learning rate: 1.9413e-05]
	Learning Rate: 1.94132e-05
	LOSS [training: 0.002328971835644907 | validation: 0.0028626696596588835]
	TIME [epoch: 8.19 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002375210618063568		[learning rate: 1.871e-05]
	Learning Rate: 1.87097e-05
	LOSS [training: 0.002375210618063568 | validation: 0.002860694981870114]
	TIME [epoch: 8.22 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024885561287716906		[learning rate: 1.8034e-05]
	Learning Rate: 1.80336e-05
	LOSS [training: 0.0024885561287716906 | validation: 0.003007909778988632]
	TIME [epoch: 8.19 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002264971362523904		[learning rate: 1.7385e-05]
	Learning Rate: 1.73848e-05
	LOSS [training: 0.002264971362523904 | validation: 0.002848248484466096]
	TIME [epoch: 8.19 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024116284491929366		[learning rate: 1.6763e-05]
	Learning Rate: 1.67633e-05
	LOSS [training: 0.0024116284491929366 | validation: 0.002858494861541906]
	TIME [epoch: 8.19 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002252203246087027		[learning rate: 1.6169e-05]
	Learning Rate: 1.61691e-05
	LOSS [training: 0.002252203246087027 | validation: 0.0032400512864666268]
	TIME [epoch: 8.18 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023497186601441782		[learning rate: 1.5602e-05]
	Learning Rate: 1.56022e-05
	LOSS [training: 0.0023497186601441782 | validation: 0.0027396008742932737]
	TIME [epoch: 8.19 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021893466156304078		[learning rate: 1.5063e-05]
	Learning Rate: 1.50626e-05
	LOSS [training: 0.0021893466156304078 | validation: 0.002331305106515207]
	TIME [epoch: 8.24 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002349941831019044		[learning rate: 1.455e-05]
	Learning Rate: 1.45503e-05
	LOSS [training: 0.002349941831019044 | validation: 0.0029397552390849624]
	TIME [epoch: 8.18 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002473522196108429		[learning rate: 1.4065e-05]
	Learning Rate: 1.40653e-05
	LOSS [training: 0.002473522196108429 | validation: 0.0027192891599192104]
	TIME [epoch: 8.18 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022707217890985797		[learning rate: 1.3608e-05]
	Learning Rate: 1.36077e-05
	LOSS [training: 0.0022707217890985797 | validation: 0.002596800820618699]
	TIME [epoch: 8.19 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023004233856847396		[learning rate: 1.3177e-05]
	Learning Rate: 1.31773e-05
	LOSS [training: 0.0023004233856847396 | validation: 0.0028105428718322827]
	TIME [epoch: 8.18 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00212376997552369		[learning rate: 1.2774e-05]
	Learning Rate: 1.27743e-05
	LOSS [training: 0.00212376997552369 | validation: 0.0027833656294735023]
	TIME [epoch: 8.2 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022432890504054015		[learning rate: 1.2399e-05]
	Learning Rate: 1.23986e-05
	LOSS [training: 0.0022432890504054015 | validation: 0.0025442923063935183]
	TIME [epoch: 8.21 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024481703248945726		[learning rate: 1.205e-05]
	Learning Rate: 1.20502e-05
	LOSS [training: 0.0024481703248945726 | validation: 0.0028029607690795003]
	TIME [epoch: 8.18 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023858769736324116		[learning rate: 1.1729e-05]
	Learning Rate: 1.17292e-05
	LOSS [training: 0.0023858769736324116 | validation: 0.0033768884391229153]
	TIME [epoch: 8.18 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002479051789238435		[learning rate: 1.1435e-05]
	Learning Rate: 1.14354e-05
	LOSS [training: 0.002479051789238435 | validation: 0.0025992068468191905]
	TIME [epoch: 8.19 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021403460392140543		[learning rate: 1.1169e-05]
	Learning Rate: 1.1169e-05
	LOSS [training: 0.0021403460392140543 | validation: 0.0032675326045232935]
	TIME [epoch: 8.19 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023434196640858846		[learning rate: 1.093e-05]
	Learning Rate: 1.09299e-05
	LOSS [training: 0.0023434196640858846 | validation: 0.0024807271758026]
	TIME [epoch: 8.22 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024309018869275636		[learning rate: 1.0718e-05]
	Learning Rate: 1.07182e-05
	LOSS [training: 0.0024309018869275636 | validation: 0.00364073595266146]
	TIME [epoch: 8.19 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002164248118407679		[learning rate: 1.0534e-05]
	Learning Rate: 1.05337e-05
	LOSS [training: 0.002164248118407679 | validation: 0.0029157723337581982]
	TIME [epoch: 8.18 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002400487700432775		[learning rate: 1.0377e-05]
	Learning Rate: 1.03766e-05
	LOSS [training: 0.002400487700432775 | validation: 0.0028112008140846073]
	TIME [epoch: 8.18 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002439737925183205		[learning rate: 1.0247e-05]
	Learning Rate: 1.02468e-05
	LOSS [training: 0.002439737925183205 | validation: 0.003235832348717066]
	TIME [epoch: 8.19 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002177540059551405		[learning rate: 1.0144e-05]
	Learning Rate: 1.01443e-05
	LOSS [training: 0.002177540059551405 | validation: 0.0022926205572608564]
	TIME [epoch: 8.2 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024743492289298705		[learning rate: 1.0069e-05]
	Learning Rate: 1.00692e-05
	LOSS [training: 0.0024743492289298705 | validation: 0.0030698603774257]
	TIME [epoch: 8.22 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002320674741726965		[learning rate: 1.0021e-05]
	Learning Rate: 1.00213e-05
	LOSS [training: 0.002320674741726965 | validation: 0.0024340509951845026]
	TIME [epoch: 8.18 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022263520498092557		[learning rate: 1.0001e-05]
	Learning Rate: 1.00009e-05
	LOSS [training: 0.0022263520498092557 | validation: 0.0028220165270529244]
	TIME [epoch: 8.19 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002373269872610671		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002373269872610671 | validation: 0.002415223036277418]
	TIME [epoch: 8.19 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023767338439868975		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023767338439868975 | validation: 0.002627912175896259]
	TIME [epoch: 8.18 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002244456422928439		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002244456422928439 | validation: 0.0026195119583849145]
	TIME [epoch: 8.21 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00230025658366164		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00230025658366164 | validation: 0.002941322849632974]
	TIME [epoch: 8.22 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022900698133757613		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022900698133757613 | validation: 0.0026287920993562225]
	TIME [epoch: 8.2 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022156175437804517		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022156175437804517 | validation: 0.002706992652789551]
	TIME [epoch: 8.19 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002366941988624615		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002366941988624615 | validation: 0.0031409235360301806]
	TIME [epoch: 8.19 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002251621672710629		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002251621672710629 | validation: 0.0029321832050209122]
	TIME [epoch: 8.19 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022483311537536453		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022483311537536453 | validation: 0.0026243294184663418]
	TIME [epoch: 8.24 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002348436319238045		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002348436319238045 | validation: 0.003116519171708316]
	TIME [epoch: 8.2 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002103400701418958		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002103400701418958 | validation: 0.0031145936250042664]
	TIME [epoch: 8.2 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021808618759124373		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021808618759124373 | validation: 0.0024262600724713687]
	TIME [epoch: 8.19 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002231836822974004		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002231836822974004 | validation: 0.002945888492088125]
	TIME [epoch: 8.19 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023703677315530906		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023703677315530906 | validation: 0.002893698508994666]
	TIME [epoch: 8.19 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002144829976267736		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002144829976267736 | validation: 0.0024974620934742377]
	TIME [epoch: 8.23 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022288485416618077		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022288485416618077 | validation: 0.0025015493121937488]
	TIME [epoch: 8.19 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024386873496843944		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0024386873496843944 | validation: 0.002828505937270747]
	TIME [epoch: 8.19 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021385358436982857		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021385358436982857 | validation: 0.0028492555426409025]
	TIME [epoch: 8.19 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023863481219706293		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023863481219706293 | validation: 0.002799892944882041]
	TIME [epoch: 8.19 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023323238542999458		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023323238542999458 | validation: 0.0035185691867639863]
	TIME [epoch: 8.24 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002291559528693439		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002291559528693439 | validation: 0.002703659439793838]
	TIME [epoch: 8.19 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025107851556985506		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0025107851556985506 | validation: 0.003040090008103893]
	TIME [epoch: 8.18 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002253604848152126		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002253604848152126 | validation: 0.0030205575809304657]
	TIME [epoch: 8.19 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002485609952338681		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002485609952338681 | validation: 0.002698245217163726]
	TIME [epoch: 8.18 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023938937470445562		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023938937470445562 | validation: 0.002591629119771559]
	TIME [epoch: 8.19 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002396452360778857		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002396452360778857 | validation: 0.0028042015821967176]
	TIME [epoch: 8.22 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022307379839333775		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022307379839333775 | validation: 0.002566906096980361]
	TIME [epoch: 8.18 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022906407449683848		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022906407449683848 | validation: 0.002710251031513811]
	TIME [epoch: 8.19 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00239777239301037		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00239777239301037 | validation: 0.0029950618326653198]
	TIME [epoch: 8.18 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021162286925372857		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021162286925372857 | validation: 0.0027271427598711097]
	TIME [epoch: 8.18 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023051845726571344		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023051845726571344 | validation: 0.002760979368121605]
	TIME [epoch: 8.21 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023227065313152777		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023227065313152777 | validation: 0.002912835483449502]
	TIME [epoch: 8.21 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002319723326951346		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002319723326951346 | validation: 0.0028597057953306353]
	TIME [epoch: 8.18 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021786442696757353		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021786442696757353 | validation: 0.002825840886846817]
	TIME [epoch: 8.19 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002248941829069582		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002248941829069582 | validation: 0.0025342760475014874]
	TIME [epoch: 8.19 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023863331925503143		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023863331925503143 | validation: 0.002566178247185769]
	TIME [epoch: 8.19 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002269092340046431		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002269092340046431 | validation: 0.0026563583900628806]
	TIME [epoch: 8.23 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022824769344622865		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022824769344622865 | validation: 0.002471355833361221]
	TIME [epoch: 8.19 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002220289149836959		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002220289149836959 | validation: 0.002889044082165486]
	TIME [epoch: 8.19 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002411017989628446		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002411017989628446 | validation: 0.002756695512222725]
	TIME [epoch: 8.19 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022492339533411185		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022492339533411185 | validation: 0.003219122880882788]
	TIME [epoch: 8.19 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025740497098265475		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0025740497098265475 | validation: 0.0028609765247458114]
	TIME [epoch: 8.2 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022696511773505033		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022696511773505033 | validation: 0.002939004166536506]
	TIME [epoch: 8.22 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022953812338652774		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022953812338652774 | validation: 0.0025756572182977075]
	TIME [epoch: 8.19 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023691317055819228		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0023691317055819228 | validation: 0.0026633013005060925]
	TIME [epoch: 8.19 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002213180682880623		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002213180682880623 | validation: 0.0026404712085110085]
	TIME [epoch: 8.19 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00223497661470306		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00223497661470306 | validation: 0.003126811493835719]
	TIME [epoch: 8.19 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024387728854021636		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0024387728854021636 | validation: 0.003005916742073505]
	TIME [epoch: 8.22 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024930995727263238		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0024930995727263238 | validation: 0.0027884071531826013]
	TIME [epoch: 8.19 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021700069772300004		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021700069772300004 | validation: 0.002417262504351152]
	TIME [epoch: 8.18 sec]
Finished training in 16749.564 seconds.
