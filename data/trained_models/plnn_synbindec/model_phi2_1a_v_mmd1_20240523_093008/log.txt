Args:
Namespace(name='model_phi2_1a_v_mmd1', outdir='out/model_training/model_phi2_1a_v_mmd1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3759998210

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497233060531153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.497233060531153 | validation: 4.146770918635726]
	TIME [epoch: 113 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4916753506862674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4916753506862674 | validation: 3.975795565674849]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2653550404165648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2653550404165648 | validation: 3.7886222893973294]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1420988331282818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1420988331282818 | validation: 3.658347728068796]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0233166247255836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0233166247255836 | validation: 3.513781207150112]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8986822742771947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8986822742771947 | validation: 3.316516334665352]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.757211160711545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.757211160711545 | validation: 3.26865528284453]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6795553548696414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6795553548696414 | validation: 3.089369659640324]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5141258199266594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5141258199266594 | validation: 2.9252773539882932]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3415718279525914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3415718279525914 | validation: 2.9512574167874974]
	TIME [epoch: 7.89 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357485913666989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.357485913666989 | validation: 2.69509760531633]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1257281341578813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1257281341578813 | validation: 2.6001527976902232]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0221320875524924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0221320875524924 | validation: 1.8568210053830256]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.831279578377854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.831279578377854 | validation: 1.7887926206322833]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2798723712247027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2798723712247027 | validation: 0.6538933522177343]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735177313438542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.735177313438542 | validation: 0.37147839362434676]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46209323252904744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46209323252904744 | validation: 0.25017797616913595]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138055926007565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3138055926007565 | validation: 0.3061721731287563]
	TIME [epoch: 7.84 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816609215343898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3816609215343898 | validation: 0.2438959375736251]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911452242628408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2911452242628408 | validation: 0.3456095975273167]
	TIME [epoch: 7.85 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3714549757927846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3714549757927846 | validation: 0.29056469321963285]
	TIME [epoch: 7.85 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33361014819273727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33361014819273727 | validation: 0.32447069113279936]
	TIME [epoch: 7.84 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138042760676744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3138042760676744 | validation: 0.18768832026397897]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25737640485405805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25737640485405805 | validation: 0.245517294800626]
	TIME [epoch: 7.89 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4871176417291422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4871176417291422 | validation: 0.23412400556899304]
	TIME [epoch: 7.84 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649341838271255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2649341838271255 | validation: 0.1943673850549416]
	TIME [epoch: 7.83 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26153047011325237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26153047011325237 | validation: 0.23478284176848724]
	TIME [epoch: 7.84 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108822820963032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3108822820963032 | validation: 0.2654064705041923]
	TIME [epoch: 7.87 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361594095698999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3361594095698999 | validation: 0.22782706642693834]
	TIME [epoch: 7.87 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2636033086190741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2636033086190741 | validation: 0.2405090360968163]
	TIME [epoch: 7.84 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879537778218233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2879537778218233 | validation: 0.27629153182709176]
	TIME [epoch: 7.84 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28382432513864175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28382432513864175 | validation: 0.2043405120690044]
	TIME [epoch: 7.84 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29511226561148685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29511226561148685 | validation: 0.2389098233703417]
	TIME [epoch: 7.88 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29158141279894995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29158141279894995 | validation: 0.24427706504494395]
	TIME [epoch: 7.86 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288904592814773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.288904592814773 | validation: 0.21394639765759113]
	TIME [epoch: 7.84 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29223000796034515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29223000796034515 | validation: 0.24389161445893373]
	TIME [epoch: 7.84 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25739927828810927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25739927828810927 | validation: 0.20299163247116886]
	TIME [epoch: 7.84 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28515505590774576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28515505590774576 | validation: 0.19684823705914684]
	TIME [epoch: 7.89 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24296579241637573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24296579241637573 | validation: 0.17345574552506068]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2937917014067488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2937917014067488 | validation: 0.16725003564320035]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279385160377422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2279385160377422 | validation: 0.1855712141200082]
	TIME [epoch: 7.84 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30119534052934954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30119534052934954 | validation: 0.22818366791712016]
	TIME [epoch: 7.86 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574868355991423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2574868355991423 | validation: 0.17241881368982245]
	TIME [epoch: 7.87 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22911796708079396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22911796708079396 | validation: 0.262200048728059]
	TIME [epoch: 7.84 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25966916281452224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25966916281452224 | validation: 0.23318332160300234]
	TIME [epoch: 7.84 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535071924542548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2535071924542548 | validation: 0.18144583222878835]
	TIME [epoch: 7.84 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2485201928737268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2485201928737268 | validation: 0.1752838098750219]
	TIME [epoch: 7.86 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25385093750053983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25385093750053983 | validation: 0.17002728053494162]
	TIME [epoch: 7.86 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22916930285035655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22916930285035655 | validation: 0.15674098094805644]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268268695047155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2268268695047155 | validation: 0.18024251444651324]
	TIME [epoch: 7.84 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23437082662602193		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.23437082662602193 | validation: 0.2285109011812136]
	TIME [epoch: 7.84 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25596861624382244		[learning rate: 0.0099588]
	Learning Rate: 0.00995876
	LOSS [training: 0.25596861624382244 | validation: 0.18053369214878023]
	TIME [epoch: 7.88 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346946044389299		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.2346946044389299 | validation: 0.15630504046078747]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23064539228211717		[learning rate: 0.0099118]
	Learning Rate: 0.00991183
	LOSS [training: 0.23064539228211717 | validation: 0.19086629284138829]
	TIME [epoch: 7.84 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22135334236070875		[learning rate: 0.0098884]
	Learning Rate: 0.00988845
	LOSS [training: 0.22135334236070875 | validation: 0.148434480319208]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2200370783406584		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.2200370783406584 | validation: 0.25929950274472285]
	TIME [epoch: 7.85 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2334851252951931		[learning rate: 0.0098419]
	Learning Rate: 0.00984185
	LOSS [training: 0.2334851252951931 | validation: 0.1523139303346041]
	TIME [epoch: 7.88 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21860442350046494		[learning rate: 0.0098186]
	Learning Rate: 0.00981864
	LOSS [training: 0.21860442350046494 | validation: 0.19801381022076528]
	TIME [epoch: 7.83 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063212748015514		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.2063212748015514 | validation: 0.179407324153116]
	TIME [epoch: 7.84 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22691004424412659		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 0.22691004424412659 | validation: 0.15756967368543595]
	TIME [epoch: 7.84 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148822487351052		[learning rate: 0.0097493]
	Learning Rate: 0.00974932
	LOSS [training: 0.2148822487351052 | validation: 0.20343107067347715]
	TIME [epoch: 7.87 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2186965495985494		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.2186965495985494 | validation: 0.17201001846158892]
	TIME [epoch: 7.85 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19133759768969566		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.19133759768969566 | validation: 0.22941496894070973]
	TIME [epoch: 7.84 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20010118867455684		[learning rate: 0.0096805]
	Learning Rate: 0.00968049
	LOSS [training: 0.20010118867455684 | validation: 0.16116429328692902]
	TIME [epoch: 7.84 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19406288461056287		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.19406288461056287 | validation: 0.20303902061797485]
	TIME [epoch: 7.85 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21581574959375824		[learning rate: 0.0096349]
	Learning Rate: 0.00963488
	LOSS [training: 0.21581574959375824 | validation: 0.15407294112530845]
	TIME [epoch: 7.89 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17035921224415115		[learning rate: 0.0096121]
	Learning Rate: 0.00961215
	LOSS [training: 0.17035921224415115 | validation: 0.1266256251278432]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19591759319105123		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.19591759319105123 | validation: 0.20238711818165012]
	TIME [epoch: 7.84 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18285902957951078		[learning rate: 0.0095669]
	Learning Rate: 0.00956686
	LOSS [training: 0.18285902957951078 | validation: 0.15623380152667127]
	TIME [epoch: 7.84 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20073349503311386		[learning rate: 0.0095443]
	Learning Rate: 0.00954429
	LOSS [training: 0.20073349503311386 | validation: 0.12029723046528226]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702242380877959		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.1702242380877959 | validation: 0.1768484393802502]
	TIME [epoch: 7.88 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17212823611247685		[learning rate: 0.0094993]
	Learning Rate: 0.00949931
	LOSS [training: 0.17212823611247685 | validation: 0.12481321908064291]
	TIME [epoch: 7.84 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912505683286443		[learning rate: 0.0094769]
	Learning Rate: 0.00947691
	LOSS [training: 0.1912505683286443 | validation: 0.13315558533456415]
	TIME [epoch: 7.85 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040472949080656		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.2040472949080656 | validation: 0.13346067681139884]
	TIME [epoch: 7.84 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15495301093985675		[learning rate: 0.0094323]
	Learning Rate: 0.00943225
	LOSS [training: 0.15495301093985675 | validation: 0.1436592212310145]
	TIME [epoch: 7.88 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15777832618931298		[learning rate: 0.00941]
	Learning Rate: 0.00941
	LOSS [training: 0.15777832618931298 | validation: 0.16122618765516605]
	TIME [epoch: 7.86 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14315884185160271		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.14315884185160271 | validation: 0.28877007414926875]
	TIME [epoch: 7.84 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20383985543589478		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.20383985543589478 | validation: 0.10867166289630525]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14298846590335987		[learning rate: 0.0093436]
	Learning Rate: 0.00934357
	LOSS [training: 0.14298846590335987 | validation: 0.09876616613500974]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14285956772982997		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.14285956772982997 | validation: 0.24355714593417085]
	TIME [epoch: 7.89 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20890791438474432		[learning rate: 0.0092995]
	Learning Rate: 0.00929954
	LOSS [training: 0.20890791438474432 | validation: 0.12681295551343003]
	TIME [epoch: 7.85 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463311954478083		[learning rate: 0.0092776]
	Learning Rate: 0.00927761
	LOSS [training: 0.13463311954478083 | validation: 0.15614607293868912]
	TIME [epoch: 7.85 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15314732407635684		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.15314732407635684 | validation: 0.1262280526459388]
	TIME [epoch: 7.85 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1742534748270721		[learning rate: 0.0092339]
	Learning Rate: 0.00923389
	LOSS [training: 0.1742534748270721 | validation: 0.12923267806424552]
	TIME [epoch: 7.85 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927559754719836		[learning rate: 0.0092121]
	Learning Rate: 0.00921211
	LOSS [training: 0.12927559754719836 | validation: 0.10625684407448527]
	TIME [epoch: 7.89 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697284710548042		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.1697284710548042 | validation: 0.14401244971912855]
	TIME [epoch: 7.84 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815061039876109		[learning rate: 0.0091687]
	Learning Rate: 0.0091687
	LOSS [training: 0.16815061039876109 | validation: 0.10060539823385628]
	TIME [epoch: 7.84 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16984787536251425		[learning rate: 0.0091471]
	Learning Rate: 0.00914707
	LOSS [training: 0.16984787536251425 | validation: 0.26407021079360365]
	TIME [epoch: 7.85 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155124801411519		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.155124801411519 | validation: 0.20330140465027602]
	TIME [epoch: 7.87 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484647173227734		[learning rate: 0.009104]
	Learning Rate: 0.00910397
	LOSS [training: 0.15484647173227734 | validation: 0.13807806932569677]
	TIME [epoch: 7.88 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115275468311578		[learning rate: 0.0090825]
	Learning Rate: 0.00908249
	LOSS [training: 0.14115275468311578 | validation: 0.2339016338000321]
	TIME [epoch: 7.85 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183147035365202		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.15183147035365202 | validation: 0.09856566375878985]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536304949349703		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.12536304949349703 | validation: 0.09754656380667306]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13020210038235436		[learning rate: 0.0090184]
	Learning Rate: 0.00901837
	LOSS [training: 0.13020210038235436 | validation: 0.11925068077171148]
	TIME [epoch: 7.89 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16718470035293764		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.16718470035293764 | validation: 0.10997916998913239]
	TIME [epoch: 7.85 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12721374350841774		[learning rate: 0.0089759]
	Learning Rate: 0.00897588
	LOSS [training: 0.12721374350841774 | validation: 0.1832699135396147]
	TIME [epoch: 7.83 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13649305953268273		[learning rate: 0.0089547]
	Learning Rate: 0.0089547
	LOSS [training: 0.13649305953268273 | validation: 0.09198028218437845]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08476467448931625		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.08476467448931625 | validation: 0.07843309796131043]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18610561489158012		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.18610561489158012 | validation: 0.1110911358887946]
	TIME [epoch: 7.89 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364660917837249		[learning rate: 0.0088915]
	Learning Rate: 0.00889149
	LOSS [training: 0.1364660917837249 | validation: 0.0984962254913619]
	TIME [epoch: 7.84 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604786697974063		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.12604786697974063 | validation: 0.0867320687598288]
	TIME [epoch: 7.84 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297394152329982		[learning rate: 0.0088496]
	Learning Rate: 0.00884959
	LOSS [training: 0.1297394152329982 | validation: 0.07623571198890058]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11944237517691297		[learning rate: 0.0088287]
	Learning Rate: 0.00882871
	LOSS [training: 0.11944237517691297 | validation: 0.20597882964026232]
	TIME [epoch: 7.88 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374855223261398		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.10374855223261398 | validation: 0.08784788707146671]
	TIME [epoch: 7.85 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14039175644277885		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.14039175644277885 | validation: 0.11326572565351782]
	TIME [epoch: 7.84 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13056059399788514		[learning rate: 0.0087664]
	Learning Rate: 0.00876638
	LOSS [training: 0.13056059399788514 | validation: 0.06698286625135388]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457432396521582		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.11457432396521582 | validation: 0.09417991919842063]
	TIME [epoch: 7.85 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10969791492853717		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.10969791492853717 | validation: 0.12777581300994528]
	TIME [epoch: 7.89 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13607919686742131		[learning rate: 0.0087045]
	Learning Rate: 0.00870449
	LOSS [training: 0.13607919686742131 | validation: 0.11869722986622505]
	TIME [epoch: 7.84 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211223094078865		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.1211223094078865 | validation: 0.12777101247325504]
	TIME [epoch: 7.84 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757369839300902		[learning rate: 0.0086635]
	Learning Rate: 0.00866348
	LOSS [training: 0.11757369839300902 | validation: 0.1131764621081858]
	TIME [epoch: 7.84 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17413197605142428		[learning rate: 0.008643]
	Learning Rate: 0.00864304
	LOSS [training: 0.17413197605142428 | validation: 0.06678751310380483]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07360484805835674		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.07360484805835674 | validation: 0.0999412601469738]
	TIME [epoch: 7.89 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095159079693719		[learning rate: 0.0086023]
	Learning Rate: 0.00860232
	LOSS [training: 0.10095159079693719 | validation: 0.09164632147465612]
	TIME [epoch: 7.84 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640305859097333		[learning rate: 0.008582]
	Learning Rate: 0.00858202
	LOSS [training: 0.10640305859097333 | validation: 0.06634165999590533]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595898987152448		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.11595898987152448 | validation: 0.08131614541173537]
	TIME [epoch: 7.84 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249525448551505		[learning rate: 0.0085416]
	Learning Rate: 0.00854158
	LOSS [training: 0.1249525448551505 | validation: 0.19534863351115844]
	TIME [epoch: 7.87 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10880092787489007		[learning rate: 0.0085214]
	Learning Rate: 0.00852144
	LOSS [training: 0.10880092787489007 | validation: 0.06817547753886004]
	TIME [epoch: 7.86 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045315316086861		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.1045315316086861 | validation: 0.0686403869013103]
	TIME [epoch: 7.83 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468222338703974		[learning rate: 0.0084813]
	Learning Rate: 0.00848128
	LOSS [training: 0.1468222338703974 | validation: 0.1625973424797677]
	TIME [epoch: 7.84 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514538275491362		[learning rate: 0.0084613]
	Learning Rate: 0.00846128
	LOSS [training: 0.14514538275491362 | validation: 0.2299405000966992]
	TIME [epoch: 7.84 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12202050880306767		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.12202050880306767 | validation: 0.10792115178337719]
	TIME [epoch: 7.88 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10394471084755985		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.10394471084755985 | validation: 0.09415084880961118]
	TIME [epoch: 7.84 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12031307931428431		[learning rate: 0.0084015]
	Learning Rate: 0.00840154
	LOSS [training: 0.12031307931428431 | validation: 0.07749257136092791]
	TIME [epoch: 7.83 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08927235931038663		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.08927235931038663 | validation: 0.07843628931156785]
	TIME [epoch: 7.84 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09055746283876759		[learning rate: 0.008362]
	Learning Rate: 0.00836195
	LOSS [training: 0.09055746283876759 | validation: 0.10996970728236774]
	TIME [epoch: 7.84 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09105673559568211		[learning rate: 0.0083422]
	Learning Rate: 0.00834223
	LOSS [training: 0.09105673559568211 | validation: 0.0570269254435847]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09698758859438675		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.09698758859438675 | validation: 0.05787023034077517]
	TIME [epoch: 7.84 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671986688804495		[learning rate: 0.0083029]
	Learning Rate: 0.00830292
	LOSS [training: 0.08671986688804495 | validation: 0.05112390867115717]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09526865662302161		[learning rate: 0.0082833]
	Learning Rate: 0.00828333
	LOSS [training: 0.09526865662302161 | validation: 0.05278342428229559]
	TIME [epoch: 7.84 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147894745994492		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.09147894745994492 | validation: 0.047172602102792616]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12064273990221677		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12064273990221677 | validation: 0.05989238771842485]
	TIME [epoch: 7.86 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695870660339658		[learning rate: 0.0082249]
	Learning Rate: 0.00822485
	LOSS [training: 0.08695870660339658 | validation: 0.04795113125344278]
	TIME [epoch: 7.84 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855354122400339		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.07855354122400339 | validation: 0.09257155669453324]
	TIME [epoch: 7.84 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361604625309442		[learning rate: 0.0081861]
	Learning Rate: 0.0081861
	LOSS [training: 0.07361604625309442 | validation: 0.08387661788015638]
	TIME [epoch: 7.84 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760299448072035		[learning rate: 0.0081668]
	Learning Rate: 0.00816679
	LOSS [training: 0.0760299448072035 | validation: 0.11627666860242875]
	TIME [epoch: 7.88 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09836112032406136		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.09836112032406136 | validation: 0.06030716906779997]
	TIME [epoch: 7.84 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06229843848355736		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.06229843848355736 | validation: 0.07367005522326982]
	TIME [epoch: 7.84 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117107483803414		[learning rate: 0.0081091]
	Learning Rate: 0.00810913
	LOSS [training: 0.1117107483803414 | validation: 0.05729209196007719]
	TIME [epoch: 7.84 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692960788212921		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.07692960788212921 | validation: 0.07803680213754105]
	TIME [epoch: 7.84 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09183728893262902		[learning rate: 0.0080709]
	Learning Rate: 0.00807092
	LOSS [training: 0.09183728893262902 | validation: 0.06393706039530858]
	TIME [epoch: 7.88 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046116502430012		[learning rate: 0.0080519]
	Learning Rate: 0.00805188
	LOSS [training: 0.08046116502430012 | validation: 0.03966897982714204]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05624473331459426		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.05624473331459426 | validation: 0.0550068159404234]
	TIME [epoch: 7.85 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220894076830558		[learning rate: 0.0080139]
	Learning Rate: 0.00801394
	LOSS [training: 0.13220894076830558 | validation: 0.19475034204336683]
	TIME [epoch: 7.84 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718755470961671		[learning rate: 0.007995]
	Learning Rate: 0.00799504
	LOSS [training: 0.1718755470961671 | validation: 0.10963025547964778]
	TIME [epoch: 7.86 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824441092542875		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.07824441092542875 | validation: 0.04604346108458261]
	TIME [epoch: 7.87 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847004765863835		[learning rate: 0.0079574]
	Learning Rate: 0.00795736
	LOSS [training: 0.0847004765863835 | validation: 0.0452594690195717]
	TIME [epoch: 7.84 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06948372513813511		[learning rate: 0.0079386]
	Learning Rate: 0.00793859
	LOSS [training: 0.06948372513813511 | validation: 0.08180816360133802]
	TIME [epoch: 7.84 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11224851636133111		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.11224851636133111 | validation: 0.10176588653423171]
	TIME [epoch: 7.84 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525962462030091		[learning rate: 0.0079012]
	Learning Rate: 0.00790119
	LOSS [training: 0.06525962462030091 | validation: 0.06305534678573294]
	TIME [epoch: 7.87 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09331241908940381		[learning rate: 0.0078825]
	Learning Rate: 0.00788255
	LOSS [training: 0.09331241908940381 | validation: 0.0518801507796013]
	TIME [epoch: 7.86 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863362405092597		[learning rate: 0.007864]
	Learning Rate: 0.00786396
	LOSS [training: 0.07863362405092597 | validation: 0.041186240509656406]
	TIME [epoch: 7.83 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08110670152523489		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.08110670152523489 | validation: 0.055657861934409275]
	TIME [epoch: 7.84 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246451627735619		[learning rate: 0.0078269]
	Learning Rate: 0.0078269
	LOSS [training: 0.07246451627735619 | validation: 0.09010752083457121]
	TIME [epoch: 7.84 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460211252728843		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.08460211252728843 | validation: 0.037984537196762924]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05300987932106688		[learning rate: 0.00779]
	Learning Rate: 0.00779002
	LOSS [training: 0.05300987932106688 | validation: 0.1853221541869674]
	TIME [epoch: 7.85 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941509855576267		[learning rate: 0.0077716]
	Learning Rate: 0.00777164
	LOSS [training: 0.08941509855576267 | validation: 0.0519949209204061]
	TIME [epoch: 7.85 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060655006465753225		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.060655006465753225 | validation: 0.0860240646090416]
	TIME [epoch: 7.84 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11502370726449157		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.11502370726449157 | validation: 0.04327765274372704]
	TIME [epoch: 7.85 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07552493832028276		[learning rate: 0.0077168]
	Learning Rate: 0.00771678
	LOSS [training: 0.07552493832028276 | validation: 0.0456136622510368]
	TIME [epoch: 7.88 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04960560926602585		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.04960560926602585 | validation: 0.13984256237434517]
	TIME [epoch: 7.85 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103392895798181		[learning rate: 0.0076804]
	Learning Rate: 0.00768041
	LOSS [training: 0.103392895798181 | validation: 0.04579237386025539]
	TIME [epoch: 7.84 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05097642784648496		[learning rate: 0.0076623]
	Learning Rate: 0.0076623
	LOSS [training: 0.05097642784648496 | validation: 0.1303664303682344]
	TIME [epoch: 7.84 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253518924542617		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.1253518924542617 | validation: 0.06440960816960124]
	TIME [epoch: 7.85 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228368807072387		[learning rate: 0.0076262]
	Learning Rate: 0.00762619
	LOSS [training: 0.12228368807072387 | validation: 0.04348598906287464]
	TIME [epoch: 7.86 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06986923000897272		[learning rate: 0.0076082]
	Learning Rate: 0.0076082
	LOSS [training: 0.06986923000897272 | validation: 0.074350485180922]
	TIME [epoch: 7.84 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058647060171490566		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.058647060171490566 | validation: 0.08029737519670899]
	TIME [epoch: 7.84 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14892804083929465		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.14892804083929465 | validation: 0.06968823118304573]
	TIME [epoch: 7.84 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023946826112073		[learning rate: 0.0075545]
	Learning Rate: 0.00755449
	LOSS [training: 0.10023946826112073 | validation: 0.06533164384121473]
	TIME [epoch: 7.88 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05575321523187053		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.05575321523187053 | validation: 0.03364911214000451]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04186312681742266		[learning rate: 0.0075189]
	Learning Rate: 0.00751889
	LOSS [training: 0.04186312681742266 | validation: 0.04500955710974805]
	TIME [epoch: 7.84 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10487500540898753		[learning rate: 0.0075012]
	Learning Rate: 0.00750116
	LOSS [training: 0.10487500540898753 | validation: 0.09179018104186568]
	TIME [epoch: 7.84 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951246658737321		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.09951246658737321 | validation: 0.05469380872583741]
	TIME [epoch: 7.84 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934187279360955		[learning rate: 0.0074658]
	Learning Rate: 0.00746581
	LOSS [training: 0.06934187279360955 | validation: 0.03282882422313017]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05182704971922429		[learning rate: 0.0074482]
	Learning Rate: 0.0074482
	LOSS [training: 0.05182704971922429 | validation: 0.18299976551704752]
	TIME [epoch: 7.84 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14975229183032135		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.14975229183032135 | validation: 0.06067964332153474]
	TIME [epoch: 7.84 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061845108558500186		[learning rate: 0.0074131]
	Learning Rate: 0.0074131
	LOSS [training: 0.061845108558500186 | validation: 0.04660811686949365]
	TIME [epoch: 7.85 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794718002533122		[learning rate: 0.0073956]
	Learning Rate: 0.00739562
	LOSS [training: 0.0794718002533122 | validation: 0.03151918757008945]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04617633726684474		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.04617633726684474 | validation: 0.028333642235926906]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758881199200979		[learning rate: 0.0073608]
	Learning Rate: 0.00736077
	LOSS [training: 0.06758881199200979 | validation: 0.029492208253618625]
	TIME [epoch: 7.86 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779541693499246		[learning rate: 0.0073434]
	Learning Rate: 0.0073434
	LOSS [training: 0.05779541693499246 | validation: 0.03775084467216039]
	TIME [epoch: 7.85 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875900871571837		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.08875900871571837 | validation: 0.06743727944753519]
	TIME [epoch: 7.84 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05624949640407878		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.05624949640407878 | validation: 0.030497725873751488]
	TIME [epoch: 7.89 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07558168836264009		[learning rate: 0.0072916]
	Learning Rate: 0.00729156
	LOSS [training: 0.07558168836264009 | validation: 0.03424608640076488]
	TIME [epoch: 7.86 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415678654543619		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.03415678654543619 | validation: 0.024953581844333744]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409980899811703		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.06409980899811703 | validation: 0.04044322577587317]
	TIME [epoch: 7.85 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07464599058683638		[learning rate: 0.0072401]
	Learning Rate: 0.00724008
	LOSS [training: 0.07464599058683638 | validation: 0.03575862316238927]
	TIME [epoch: 7.85 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050016076725096476		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.050016076725096476 | validation: 0.046625844618827295]
	TIME [epoch: 7.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04302797972161217		[learning rate: 0.007206]
	Learning Rate: 0.00720597
	LOSS [training: 0.04302797972161217 | validation: 0.06488713219782449]
	TIME [epoch: 7.85 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361807362115048		[learning rate: 0.007189]
	Learning Rate: 0.00718897
	LOSS [training: 0.04361807362115048 | validation: 0.04117025305377062]
	TIME [epoch: 7.84 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05384559656652094		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.05384559656652094 | validation: 0.053301881557199005]
	TIME [epoch: 7.85 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098859168367639		[learning rate: 0.0071551]
	Learning Rate: 0.00715509
	LOSS [training: 0.08098859168367639 | validation: 0.022567130320755364]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492578705604758		[learning rate: 0.0071382]
	Learning Rate: 0.00713822
	LOSS [training: 0.05492578705604758 | validation: 0.03500175849457409]
	TIME [epoch: 7.88 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0372156204782486		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.0372156204782486 | validation: 0.0763838815055248]
	TIME [epoch: 7.84 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419781439265366		[learning rate: 0.0071046]
	Learning Rate: 0.00710458
	LOSS [training: 0.08419781439265366 | validation: 0.1339329551042745]
	TIME [epoch: 7.84 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190899328065111		[learning rate: 0.0070878]
	Learning Rate: 0.00708782
	LOSS [training: 0.1190899328065111 | validation: 0.07588856767174845]
	TIME [epoch: 7.84 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07606867988205628		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.07606867988205628 | validation: 0.024964956620763017]
	TIME [epoch: 7.88 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04116940236128276		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.04116940236128276 | validation: 0.02563750968501017]
	TIME [epoch: 7.86 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470601167876571		[learning rate: 0.0070378]
	Learning Rate: 0.00703778
	LOSS [training: 0.04470601167876571 | validation: 0.029606208602078077]
	TIME [epoch: 7.84 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03906425885545595		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.03906425885545595 | validation: 0.05133090650317569]
	TIME [epoch: 7.84 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05278102318285878		[learning rate: 0.0070046]
	Learning Rate: 0.00700462
	LOSS [training: 0.05278102318285878 | validation: 0.03857588498115423]
	TIME [epoch: 7.84 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05870040577977249		[learning rate: 0.0069881]
	Learning Rate: 0.0069881
	LOSS [training: 0.05870040577977249 | validation: 0.03358205787136701]
	TIME [epoch: 7.86 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308187999608658		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.04308187999608658 | validation: 0.05961417567392149]
	TIME [epoch: 7.83 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655130628411661		[learning rate: 0.0069552]
	Learning Rate: 0.00695517
	LOSS [training: 0.05655130628411661 | validation: 0.028436144989049048]
	TIME [epoch: 7.84 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733120291916622		[learning rate: 0.0069388]
	Learning Rate: 0.00693876
	LOSS [training: 0.04733120291916622 | validation: 0.027513749083288838]
	TIME [epoch: 7.83 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03001406628913017		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.03001406628913017 | validation: 0.04437523286634269]
	TIME [epoch: 7.83 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981113866595137		[learning rate: 0.0069061]
	Learning Rate: 0.00690607
	LOSS [training: 0.04981113866595137 | validation: 0.07119709790001835]
	TIME [epoch: 7.88 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19513026607940331		[learning rate: 0.0068898]
	Learning Rate: 0.00688978
	LOSS [training: 0.19513026607940331 | validation: 0.33021260631159294]
	TIME [epoch: 7.84 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13896305706832193		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.13896305706832193 | validation: 0.027257090864976078]
	TIME [epoch: 7.84 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201907375915101		[learning rate: 0.0068573]
	Learning Rate: 0.00685731
	LOSS [training: 0.03201907375915101 | validation: 0.03951909686135617]
	TIME [epoch: 7.84 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03796805206242705		[learning rate: 0.0068411]
	Learning Rate: 0.00684114
	LOSS [training: 0.03796805206242705 | validation: 0.029110776481973764]
	TIME [epoch: 7.87 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047856098317705605		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.047856098317705605 | validation: 0.043143430522580184]
	TIME [epoch: 7.85 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06846597975713047		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.06846597975713047 | validation: 0.056403569781701524]
	TIME [epoch: 7.84 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108805508857091		[learning rate: 0.0067928]
	Learning Rate: 0.00679284
	LOSS [training: 0.10108805508857091 | validation: 0.09013648563533791]
	TIME [epoch: 7.84 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14843331242655367		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.14843331242655367 | validation: 0.04324320426672491]
	TIME [epoch: 7.83 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043258868651236654		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.043258868651236654 | validation: 0.02043818540545512]
	TIME [epoch: 7.87 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371368719832644		[learning rate: 0.0067449]
	Learning Rate: 0.00674488
	LOSS [training: 0.03371368719832644 | validation: 0.030855975733322237]
	TIME [epoch: 7.85 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030137523706937373		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.030137523706937373 | validation: 0.03692384249089723]
	TIME [epoch: 7.84 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967810595721979		[learning rate: 0.0067131]
	Learning Rate: 0.0067131
	LOSS [training: 0.02967810595721979 | validation: 0.04951677205169429]
	TIME [epoch: 7.84 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06759528896908985		[learning rate: 0.0066973]
	Learning Rate: 0.00669726
	LOSS [training: 0.06759528896908985 | validation: 0.07329467304496526]
	TIME [epoch: 7.83 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155496864689989		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.04155496864689989 | validation: 0.03449628567487396]
	TIME [epoch: 7.88 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040286396016123695		[learning rate: 0.0066657]
	Learning Rate: 0.00666571
	LOSS [training: 0.040286396016123695 | validation: 0.02264906359166794]
	TIME [epoch: 7.84 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484949479583034		[learning rate: 0.00665]
	Learning Rate: 0.00664998
	LOSS [training: 0.0484949479583034 | validation: 0.0570786334013566]
	TIME [epoch: 7.84 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466266612300058		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.06466266612300058 | validation: 0.019375287245180305]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771014087097644		[learning rate: 0.0066186]
	Learning Rate: 0.00661865
	LOSS [training: 0.04771014087097644 | validation: 0.16167616003201193]
	TIME [epoch: 7.85 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301904437341753		[learning rate: 0.006603]
	Learning Rate: 0.00660304
	LOSS [training: 0.08301904437341753 | validation: 0.03181693034920982]
	TIME [epoch: 7.87 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04960046163630083		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.04960046163630083 | validation: 0.018656245957439335]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642758829920372		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.03642758829920372 | validation: 0.046457731212376216]
	TIME [epoch: 7.83 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583073095508087		[learning rate: 0.0065564]
	Learning Rate: 0.00655642
	LOSS [training: 0.03583073095508087 | validation: 0.02651778986597917]
	TIME [epoch: 7.84 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357563060489997		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.0357563060489997 | validation: 0.03529268283492183]
	TIME [epoch: 7.86 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05553762365958039		[learning rate: 0.0065255]
	Learning Rate: 0.00652552
	LOSS [training: 0.05553762365958039 | validation: 0.017394713476251177]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090655993885543		[learning rate: 0.0065101]
	Learning Rate: 0.00651013
	LOSS [training: 0.03090655993885543 | validation: 0.0532005333846754]
	TIME [epoch: 7.84 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856999627982645		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.06856999627982645 | validation: 0.023720542836027182]
	TIME [epoch: 7.83 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022145418321840978		[learning rate: 0.0064795]
	Learning Rate: 0.00647945
	LOSS [training: 0.022145418321840978 | validation: 0.031538076030198606]
	TIME [epoch: 7.84 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03686392522600834		[learning rate: 0.0064642]
	Learning Rate: 0.00646417
	LOSS [training: 0.03686392522600834 | validation: 0.0373312175391648]
	TIME [epoch: 7.88 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673552972663352		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.03673552972663352 | validation: 0.024447566029485022]
	TIME [epoch: 7.84 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03672789400889491		[learning rate: 0.0064337]
	Learning Rate: 0.00643371
	LOSS [training: 0.03672789400889491 | validation: 0.08534617558912531]
	TIME [epoch: 7.84 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516662093075518		[learning rate: 0.0064185]
	Learning Rate: 0.00641853
	LOSS [training: 0.06516662093075518 | validation: 0.015362399526784313]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022725957162025044		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.022725957162025044 | validation: 0.031089461196106723]
	TIME [epoch: 7.85 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05701016007719964		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.05701016007719964 | validation: 0.047253217417379326]
	TIME [epoch: 7.88 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607196144801761		[learning rate: 0.0063732]
	Learning Rate: 0.00637322
	LOSS [training: 0.06607196144801761 | validation: 0.08835279768581189]
	TIME [epoch: 7.84 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548717376152536		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.04548717376152536 | validation: 0.020465111119466396]
	TIME [epoch: 7.83 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026151842430353976		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.026151842430353976 | validation: 0.03338207759939654]
	TIME [epoch: 7.84 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028704179723177056		[learning rate: 0.0063282]
	Learning Rate: 0.00632823
	LOSS [training: 0.028704179723177056 | validation: 0.04568464497241628]
	TIME [epoch: 7.88 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0596649779074572		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.0596649779074572 | validation: 0.04159521201513851]
	TIME [epoch: 7.86 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588244978818793		[learning rate: 0.0062984]
	Learning Rate: 0.00629841
	LOSS [training: 0.04588244978818793 | validation: 0.01992023096407139]
	TIME [epoch: 7.84 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02475631631072499		[learning rate: 0.0062836]
	Learning Rate: 0.00628355
	LOSS [training: 0.02475631631072499 | validation: 0.03279892910546678]
	TIME [epoch: 7.84 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360501182823643		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.05360501182823643 | validation: 0.026185483416251678]
	TIME [epoch: 7.84 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02247535286469017		[learning rate: 0.0062539]
	Learning Rate: 0.00625394
	LOSS [training: 0.02247535286469017 | validation: 0.04129997303995741]
	TIME [epoch: 7.89 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717141319761556		[learning rate: 0.0062392]
	Learning Rate: 0.00623919
	LOSS [training: 0.03717141319761556 | validation: 0.15865857486606755]
	TIME [epoch: 7.85 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1809464033452382		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.1809464033452382 | validation: 0.0927404623089092]
	TIME [epoch: 7.84 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914868330057995		[learning rate: 0.0062098]
	Learning Rate: 0.00620979
	LOSS [training: 0.05914868330057995 | validation: 0.022172269028212052]
	TIME [epoch: 7.84 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023979966987991454		[learning rate: 0.0061951]
	Learning Rate: 0.00619514
	LOSS [training: 0.023979966987991454 | validation: 0.016941818384814088]
	TIME [epoch: 7.84 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318572800015191		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.03318572800015191 | validation: 0.07170816334554185]
	TIME [epoch: 7.89 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508478354806126		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.04508478354806126 | validation: 0.022322936082426525]
	TIME [epoch: 7.84 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020180584122451963		[learning rate: 0.0061514]
	Learning Rate: 0.00615141
	LOSS [training: 0.020180584122451963 | validation: 0.026827241786901594]
	TIME [epoch: 7.84 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03403436740614249		[learning rate: 0.0061369]
	Learning Rate: 0.0061369
	LOSS [training: 0.03403436740614249 | validation: 0.10386473789802009]
	TIME [epoch: 7.84 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07043990250567045		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.07043990250567045 | validation: 0.02940199812665788]
	TIME [epoch: 7.84 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035278433630646915		[learning rate: 0.006108]
	Learning Rate: 0.00610798
	LOSS [training: 0.035278433630646915 | validation: 0.068710818324171]
	TIME [epoch: 7.89 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1044647921304616		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.1044647921304616 | validation: 0.02846332065099476]
	TIME [epoch: 7.85 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429411681875765		[learning rate: 0.0060792]
	Learning Rate: 0.0060792
	LOSS [training: 0.05429411681875765 | validation: 0.038332408277033936]
	TIME [epoch: 7.85 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037991624294885715		[learning rate: 0.0060649]
	Learning Rate: 0.00606486
	LOSS [training: 0.037991624294885715 | validation: 0.03092794964356084]
	TIME [epoch: 7.85 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03830230336900094		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.03830230336900094 | validation: 0.022464128155948282]
	TIME [epoch: 7.88 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02163446322741028		[learning rate: 0.0060363]
	Learning Rate: 0.00603628
	LOSS [training: 0.02163446322741028 | validation: 0.02247606293987967]
	TIME [epoch: 7.85 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611313934008283		[learning rate: 0.006022]
	Learning Rate: 0.00602204
	LOSS [training: 0.05611313934008283 | validation: 0.017263080144577052]
	TIME [epoch: 7.85 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048235849578271636		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.048235849578271636 | validation: 0.03082864479188102]
	TIME [epoch: 7.84 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030560470613359914		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.030560470613359914 | validation: 0.026471933118991292]
	TIME [epoch: 7.84 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048222395919085684		[learning rate: 0.0059795]
	Learning Rate: 0.00597952
	LOSS [training: 0.048222395919085684 | validation: 0.037020818686841324]
	TIME [epoch: 7.89 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513779274121521		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.06513779274121521 | validation: 0.0196095040963401]
	TIME [epoch: 7.86 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022542573698993273		[learning rate: 0.0059513]
	Learning Rate: 0.00595135
	LOSS [training: 0.022542573698993273 | validation: 0.040273623463446165]
	TIME [epoch: 7.85 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470314584060106		[learning rate: 0.0059373]
	Learning Rate: 0.00593731
	LOSS [training: 0.04470314584060106 | validation: 0.023374681671377875]
	TIME [epoch: 7.85 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026956230577457777		[learning rate: 0.0059233]
	Learning Rate: 0.00592331
	LOSS [training: 0.026956230577457777 | validation: 0.019716616300814567]
	TIME [epoch: 7.85 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387608353144725		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.0387608353144725 | validation: 0.025616761614203926]
	TIME [epoch: 7.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195774171596538		[learning rate: 0.0058954]
	Learning Rate: 0.00589539
	LOSS [training: 0.03195774171596538 | validation: 0.030460320486933458]
	TIME [epoch: 7.85 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195967913711022		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.03195967913711022 | validation: 0.028367842951590665]
	TIME [epoch: 7.85 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741358809268484		[learning rate: 0.0058676]
	Learning Rate: 0.00586761
	LOSS [training: 0.04741358809268484 | validation: 0.02038508641497215]
	TIME [epoch: 7.85 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239178470018318		[learning rate: 0.0058538]
	Learning Rate: 0.00585377
	LOSS [training: 0.02239178470018318 | validation: 0.07542470459958281]
	TIME [epoch: 7.86 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054940163749129224		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.054940163749129224 | validation: 0.026740500820583137]
	TIME [epoch: 7.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02700347251080424		[learning rate: 0.0058262]
	Learning Rate: 0.00582619
	LOSS [training: 0.02700347251080424 | validation: 0.021187790038058204]
	TIME [epoch: 7.85 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036214882745057915		[learning rate: 0.0058124]
	Learning Rate: 0.00581245
	LOSS [training: 0.036214882745057915 | validation: 0.051360309152885586]
	TIME [epoch: 7.85 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03013463263822585		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.03013463263822585 | validation: 0.01450433125008601]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03020291538161413		[learning rate: 0.0057851]
	Learning Rate: 0.00578506
	LOSS [training: 0.03020291538161413 | validation: 0.01679503018193728]
	TIME [epoch: 7.88 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020287553414671304		[learning rate: 0.0057714]
	Learning Rate: 0.00577141
	LOSS [training: 0.020287553414671304 | validation: 0.018775623129279235]
	TIME [epoch: 7.87 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04793594158454343		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.04793594158454343 | validation: 0.03344213743195582]
	TIME [epoch: 7.85 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044458504675776805		[learning rate: 0.0057442]
	Learning Rate: 0.00574422
	LOSS [training: 0.044458504675776805 | validation: 0.04733250005152112]
	TIME [epoch: 7.85 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02943791513662261		[learning rate: 0.0057307]
	Learning Rate: 0.00573067
	LOSS [training: 0.02943791513662261 | validation: 0.012544346672735567]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951065830831319		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.01951065830831319 | validation: 0.015175839442464291]
	TIME [epoch: 7.85 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023630795818574617		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.023630795818574617 | validation: 0.07027526982628175]
	TIME [epoch: 7.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287345409563261		[learning rate: 0.0056902]
	Learning Rate: 0.00569021
	LOSS [training: 0.06287345409563261 | validation: 0.022261190634515912]
	TIME [epoch: 7.82 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211207064996908		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.06211207064996908 | validation: 0.05760551693439418]
	TIME [epoch: 7.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424749843723483		[learning rate: 0.0056634]
	Learning Rate: 0.0056634
	LOSS [training: 0.05424749843723483 | validation: 0.017757160963395455]
	TIME [epoch: 7.83 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288128776787955		[learning rate: 0.00565]
	Learning Rate: 0.00565004
	LOSS [training: 0.02288128776787955 | validation: 0.017200403115031727]
	TIME [epoch: 7.85 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016522483942079363		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.016522483942079363 | validation: 0.040837176554831586]
	TIME [epoch: 7.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056770358519523584		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.056770358519523584 | validation: 0.0204727891526617]
	TIME [epoch: 7.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02859065717506886		[learning rate: 0.0056101]
	Learning Rate: 0.00561015
	LOSS [training: 0.02859065717506886 | validation: 0.015581833688908763]
	TIME [epoch: 7.79 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903384698989773		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.03903384698989773 | validation: 0.034786715294710994]
	TIME [epoch: 7.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764505252170686		[learning rate: 0.0055837]
	Learning Rate: 0.00558371
	LOSS [training: 0.02764505252170686 | validation: 0.01503756973780915]
	TIME [epoch: 7.85 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014361737480947339		[learning rate: 0.0055705]
	Learning Rate: 0.00557054
	LOSS [training: 0.014361737480947339 | validation: 0.02079194147431565]
	TIME [epoch: 7.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03419498445631428		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.03419498445631428 | validation: 0.04237065792040404]
	TIME [epoch: 7.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032950831509482865		[learning rate: 0.0055443]
	Learning Rate: 0.00554429
	LOSS [training: 0.032950831509482865 | validation: 0.02511539202633352]
	TIME [epoch: 7.82 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023102568836524725		[learning rate: 0.0055312]
	Learning Rate: 0.00553121
	LOSS [training: 0.023102568836524725 | validation: 0.02536874777036186]
	TIME [epoch: 7.88 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033401350883591176		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.033401350883591176 | validation: 0.0195460852810087]
	TIME [epoch: 7.86 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015435566231837023		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.015435566231837023 | validation: 0.020845151348464895]
	TIME [epoch: 7.85 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01922424718607206		[learning rate: 0.0054922]
	Learning Rate: 0.00549216
	LOSS [training: 0.01922424718607206 | validation: 0.0245331349023891]
	TIME [epoch: 7.83 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03076344781519095		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.03076344781519095 | validation: 0.015259709308419368]
	TIME [epoch: 7.84 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017122894898359674		[learning rate: 0.0054663]
	Learning Rate: 0.00546629
	LOSS [training: 0.017122894898359674 | validation: 0.022395905191728793]
	TIME [epoch: 7.89 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028753357934835626		[learning rate: 0.0054534]
	Learning Rate: 0.00545339
	LOSS [training: 0.028753357934835626 | validation: 0.07408785162717532]
	TIME [epoch: 7.85 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613230923490165		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.03613230923490165 | validation: 0.0349258207729656]
	TIME [epoch: 7.83 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04691966851082917		[learning rate: 0.0054277]
	Learning Rate: 0.00542769
	LOSS [training: 0.04691966851082917 | validation: 0.010324415156754033]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02262581044653005		[learning rate: 0.0054149]
	Learning Rate: 0.00541489
	LOSS [training: 0.02262581044653005 | validation: 0.03187463658013169]
	TIME [epoch: 7.85 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03389753046263482		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.03389753046263482 | validation: 0.02154158730879603]
	TIME [epoch: 7.88 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02431566153040509		[learning rate: 0.0053894]
	Learning Rate: 0.00538938
	LOSS [training: 0.02431566153040509 | validation: 0.013838749052402503]
	TIME [epoch: 7.84 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007184152082773		[learning rate: 0.0053767]
	Learning Rate: 0.00537666
	LOSS [training: 0.03007184152082773 | validation: 0.017746247374973115]
	TIME [epoch: 7.84 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02179340838029432		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.02179340838029432 | validation: 0.03504166220032042]
	TIME [epoch: 7.84 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332442452280947		[learning rate: 0.0053513]
	Learning Rate: 0.00535133
	LOSS [training: 0.03332442452280947 | validation: 0.013991440317262644]
	TIME [epoch: 7.86 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014631690197271324		[learning rate: 0.0053387]
	Learning Rate: 0.00533871
	LOSS [training: 0.014631690197271324 | validation: 0.03646560712169486]
	TIME [epoch: 7.86 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047351724037729165		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.047351724037729165 | validation: 0.02547247139371582]
	TIME [epoch: 7.84 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030639974571181474		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.030639974571181474 | validation: 0.010843439547124668]
	TIME [epoch: 7.84 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025894411672584338		[learning rate: 0.005301]
	Learning Rate: 0.00530101
	LOSS [training: 0.025894411672584338 | validation: 0.016070789820617753]
	TIME [epoch: 7.85 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016770154142437727		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.016770154142437727 | validation: 0.024550175020239894]
	TIME [epoch: 7.88 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275390985865959		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.0275390985865959 | validation: 0.04080730607538095]
	TIME [epoch: 7.85 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02336677643973653		[learning rate: 0.0052636]
	Learning Rate: 0.00526359
	LOSS [training: 0.02336677643973653 | validation: 0.023993579009249297]
	TIME [epoch: 7.84 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209014381635967		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.03209014381635967 | validation: 0.022236551721168552]
	TIME [epoch: 7.84 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02872567256548496		[learning rate: 0.0052388]
	Learning Rate: 0.00523879
	LOSS [training: 0.02872567256548496 | validation: 0.036868831153912096]
	TIME [epoch: 7.84 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02586630641084746		[learning rate: 0.0052264]
	Learning Rate: 0.00522643
	LOSS [training: 0.02586630641084746 | validation: 0.023851909678021012]
	TIME [epoch: 7.89 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029352253138201057		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.029352253138201057 | validation: 0.017265220678911376]
	TIME [epoch: 7.85 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013488453590472353		[learning rate: 0.0052018]
	Learning Rate: 0.0052018
	LOSS [training: 0.013488453590472353 | validation: 0.013929145569179641]
	TIME [epoch: 7.84 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244233296037792		[learning rate: 0.0051895]
	Learning Rate: 0.00518953
	LOSS [training: 0.02244233296037792 | validation: 0.012687473186256681]
	TIME [epoch: 7.84 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019081312189082437		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.019081312189082437 | validation: 0.0416593873599668]
	TIME [epoch: 7.85 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04067988532130566		[learning rate: 0.0051651]
	Learning Rate: 0.00516508
	LOSS [training: 0.04067988532130566 | validation: 0.022769291437721235]
	TIME [epoch: 7.89 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489758102115737		[learning rate: 0.0051529]
	Learning Rate: 0.00515289
	LOSS [training: 0.03489758102115737 | validation: 0.014385609137868209]
	TIME [epoch: 7.84 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015131505949006405		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.015131505949006405 | validation: 0.01084808235976619]
	TIME [epoch: 7.84 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024250373959177694		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.024250373959177694 | validation: 0.03398016282027573]
	TIME [epoch: 7.84 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023176302979674986		[learning rate: 0.0051165]
	Learning Rate: 0.00511652
	LOSS [training: 0.023176302979674986 | validation: 0.015797350537296244]
	TIME [epoch: 7.86 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02104799050454602		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.02104799050454602 | validation: 0.012140810801415148]
	TIME [epoch: 7.88 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03198361136269337		[learning rate: 0.0050924]
	Learning Rate: 0.00509241
	LOSS [training: 0.03198361136269337 | validation: 0.05015539737711508]
	TIME [epoch: 7.85 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039246321446513265		[learning rate: 0.0050804]
	Learning Rate: 0.00508039
	LOSS [training: 0.039246321446513265 | validation: 0.027640840643398744]
	TIME [epoch: 7.84 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021197405498072773		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.021197405498072773 | validation: 0.014055278270096174]
	TIME [epoch: 7.84 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015524060607970016		[learning rate: 0.0050565]
	Learning Rate: 0.00505645
	LOSS [training: 0.015524060607970016 | validation: 0.016720021866996566]
	TIME [epoch: 7.87 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043982581027103444		[learning rate: 0.0050445]
	Learning Rate: 0.00504453
	LOSS [training: 0.043982581027103444 | validation: 0.013183297757758155]
	TIME [epoch: 7.86 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661225852700257		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.01661225852700257 | validation: 0.009012726750238934]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028638796913601817		[learning rate: 0.0050208]
	Learning Rate: 0.00502076
	LOSS [training: 0.028638796913601817 | validation: 0.031109410122894393]
	TIME [epoch: 7.84 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02876304127795898		[learning rate: 0.0050089]
	Learning Rate: 0.00500891
	LOSS [training: 0.02876304127795898 | validation: 0.01770931592306272]
	TIME [epoch: 7.84 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022823339211355		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.022823339211355 | validation: 0.0226857448732003]
	TIME [epoch: 7.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030140516477246325		[learning rate: 0.0049853]
	Learning Rate: 0.00498531
	LOSS [training: 0.030140516477246325 | validation: 0.01803089105306774]
	TIME [epoch: 7.85 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016522720681033914		[learning rate: 0.0049736]
	Learning Rate: 0.00497355
	LOSS [training: 0.016522720681033914 | validation: 0.0308133020340095]
	TIME [epoch: 7.84 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02142511352423557		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.02142511352423557 | validation: 0.02871456229001137]
	TIME [epoch: 7.84 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170553453446104		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.03170553453446104 | validation: 0.02517418374836862]
	TIME [epoch: 7.85 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018085211928413645		[learning rate: 0.0049384]
	Learning Rate: 0.00493844
	LOSS [training: 0.018085211928413645 | validation: 0.012247412214509031]
	TIME [epoch: 7.89 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307699005270828		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.04307699005270828 | validation: 0.023587558788628477]
	TIME [epoch: 7.85 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018999006501772095		[learning rate: 0.0049152]
	Learning Rate: 0.00491517
	LOSS [training: 0.018999006501772095 | validation: 0.014587929241393235]
	TIME [epoch: 7.84 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020028274425289004		[learning rate: 0.0049036]
	Learning Rate: 0.00490357
	LOSS [training: 0.020028274425289004 | validation: 0.011620696450539886]
	TIME [epoch: 7.84 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159928896217215		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.04159928896217215 | validation: 0.0504910370576286]
	TIME [epoch: 7.86 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040982399017046645		[learning rate: 0.0048805]
	Learning Rate: 0.00488047
	LOSS [training: 0.040982399017046645 | validation: 0.015150905336857506]
	TIME [epoch: 7.88 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05362503557962936		[learning rate: 0.004869]
	Learning Rate: 0.00486896
	LOSS [training: 0.05362503557962936 | validation: 0.047342685856288334]
	TIME [epoch: 7.85 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0488940824359276		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.0488940824359276 | validation: 0.012027964404862906]
	TIME [epoch: 7.85 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01564472494063468		[learning rate: 0.004846]
	Learning Rate: 0.00484601
	LOSS [training: 0.01564472494063468 | validation: 0.011742003935086192]
	TIME [epoch: 7.84 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017512088258533683		[learning rate: 0.0048346]
	Learning Rate: 0.00483458
	LOSS [training: 0.017512088258533683 | validation: 0.019194990323203688]
	TIME [epoch: 7.88 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879297894936133		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.01879297894936133 | validation: 0.010901454238001696]
	TIME [epoch: 7.87 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01133185204001782		[learning rate: 0.0048118]
	Learning Rate: 0.0048118
	LOSS [training: 0.01133185204001782 | validation: 0.011321982736809379]
	TIME [epoch: 7.85 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029956474608334085		[learning rate: 0.0048005]
	Learning Rate: 0.00480045
	LOSS [training: 0.029956474608334085 | validation: 0.03133368510411183]
	TIME [epoch: 7.86 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02017546715331223		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.02017546715331223 | validation: 0.02479224894153763]
	TIME [epoch: 7.84 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027925095135153913		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.027925095135153913 | validation: 0.012136345288186268]
	TIME [epoch: 7.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013676402308648961		[learning rate: 0.0047666]
	Learning Rate: 0.00476656
	LOSS [training: 0.013676402308648961 | validation: 0.011747962132365144]
	TIME [epoch: 7.85 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024947930030191273		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.024947930030191273 | validation: 0.022062076500998142]
	TIME [epoch: 7.84 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466194253480465		[learning rate: 0.0047441]
	Learning Rate: 0.0047441
	LOSS [training: 0.02466194253480465 | validation: 0.013139759970699362]
	TIME [epoch: 7.84 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023441405379112094		[learning rate: 0.0047329]
	Learning Rate: 0.00473291
	LOSS [training: 0.023441405379112094 | validation: 0.018363346494374252]
	TIME [epoch: 7.85 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01679563954566713		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.01679563954566713 | validation: 0.01844030560990215]
	TIME [epoch: 7.88 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021867279117472927		[learning rate: 0.0047106]
	Learning Rate: 0.00471061
	LOSS [training: 0.021867279117472927 | validation: 0.01845237338870606]
	TIME [epoch: 7.85 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855431683268521		[learning rate: 0.0046995]
	Learning Rate: 0.0046995
	LOSS [training: 0.04855431683268521 | validation: 0.01604256965115024]
	TIME [epoch: 7.85 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016767549966627725		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.016767549966627725 | validation: 0.01055778604231252]
	TIME [epoch: 7.84 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022676019680722533		[learning rate: 0.0046774]
	Learning Rate: 0.00467735
	LOSS [training: 0.022676019680722533 | validation: 0.012405073860099902]
	TIME [epoch: 7.86 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011366903755445442		[learning rate: 0.0046663]
	Learning Rate: 0.00466632
	LOSS [training: 0.011366903755445442 | validation: 0.011410429149371048]
	TIME [epoch: 7.88 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014860503133584734		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.014860503133584734 | validation: 0.041130756483327105]
	TIME [epoch: 7.85 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027907570716809937		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.027907570716809937 | validation: 0.017682977276228664]
	TIME [epoch: 7.85 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014451298509794902		[learning rate: 0.0046334]
	Learning Rate: 0.00463338
	LOSS [training: 0.014451298509794902 | validation: 0.013412729361691404]
	TIME [epoch: 7.85 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014229038764909		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.014229038764909 | validation: 0.01234362259028129]
	TIME [epoch: 7.88 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590461820575658		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.01590461820575658 | validation: 0.02691403417918007]
	TIME [epoch: 7.87 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030396049080272124		[learning rate: 0.0046007]
	Learning Rate: 0.00460066
	LOSS [training: 0.030396049080272124 | validation: 0.015938517397531476]
	TIME [epoch: 7.85 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019059509620501427		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.019059509620501427 | validation: 0.013678305234435889]
	TIME [epoch: 7.85 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01684599080685125		[learning rate: 0.004579]
	Learning Rate: 0.00457899
	LOSS [training: 0.01684599080685125 | validation: 0.02996801095918042]
	TIME [epoch: 7.85 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02529717115687001		[learning rate: 0.0045682]
	Learning Rate: 0.00456818
	LOSS [training: 0.02529717115687001 | validation: 0.014359696554814085]
	TIME [epoch: 7.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013475351420996427		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.013475351420996427 | validation: 0.035136787752329396]
	TIME [epoch: 7.86 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029134430653026473		[learning rate: 0.0045467]
	Learning Rate: 0.00454666
	LOSS [training: 0.029134430653026473 | validation: 0.018245293359847488]
	TIME [epoch: 7.85 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013080124772516813		[learning rate: 0.0045359]
	Learning Rate: 0.00453593
	LOSS [training: 0.013080124772516813 | validation: 0.025659632735452825]
	TIME [epoch: 7.86 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030705455973073288		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.030705455973073288 | validation: 0.010235229718166618]
	TIME [epoch: 7.86 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025651902289428347		[learning rate: 0.0045146]
	Learning Rate: 0.00451456
	LOSS [training: 0.025651902289428347 | validation: 0.013880799358208087]
	TIME [epoch: 7.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016563695554875305		[learning rate: 0.0045039]
	Learning Rate: 0.00450391
	LOSS [training: 0.016563695554875305 | validation: 0.019731251165113546]
	TIME [epoch: 7.85 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021980206529822834		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.021980206529822834 | validation: 0.012368171384869397]
	TIME [epoch: 7.85 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020494317042607273		[learning rate: 0.0044827]
	Learning Rate: 0.00448269
	LOSS [training: 0.020494317042607273 | validation: 0.02648453425418524]
	TIME [epoch: 7.86 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02204407705861662		[learning rate: 0.0044721]
	Learning Rate: 0.00447211
	LOSS [training: 0.02204407705861662 | validation: 0.012878441954807205]
	TIME [epoch: 7.86 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01672776027474468		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.01672776027474468 | validation: 0.014310078550691822]
	TIME [epoch: 7.89 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01530334095195835		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.01530334095195835 | validation: 0.018987537414656027]
	TIME [epoch: 7.85 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021886403839810935		[learning rate: 0.0044405]
	Learning Rate: 0.00444054
	LOSS [training: 0.021886403839810935 | validation: 0.028020860524136562]
	TIME [epoch: 7.85 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02344769378873322		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.02344769378873322 | validation: 0.008582129293486942]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01244668929684752		[learning rate: 0.0044196]
	Learning Rate: 0.00441962
	LOSS [training: 0.01244668929684752 | validation: 0.0111671622999098]
	TIME [epoch: 7.89 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021563334513066263		[learning rate: 0.0044092]
	Learning Rate: 0.00440919
	LOSS [training: 0.021563334513066263 | validation: 0.009656047610622864]
	TIME [epoch: 7.86 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0208165671861751		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.0208165671861751 | validation: 0.014579183036676628]
	TIME [epoch: 7.86 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019009207277978342		[learning rate: 0.0043884]
	Learning Rate: 0.00438841
	LOSS [training: 0.019009207277978342 | validation: 0.014576872587048454]
	TIME [epoch: 7.85 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014218108875285271		[learning rate: 0.0043781]
	Learning Rate: 0.00437806
	LOSS [training: 0.014218108875285271 | validation: 0.01814879576471717]
	TIME [epoch: 7.85 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01930234479423314		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.01930234479423314 | validation: 0.029183274997576097]
	TIME [epoch: 7.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023658928152826848		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.023658928152826848 | validation: 0.011426072915537478]
	TIME [epoch: 7.86 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011031982764811581		[learning rate: 0.0043472]
	Learning Rate: 0.00434715
	LOSS [training: 0.011031982764811581 | validation: 0.016083192889186054]
	TIME [epoch: 7.85 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01920858942582284		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.01920858942582284 | validation: 0.013457811236677619]
	TIME [epoch: 7.85 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911074432496431		[learning rate: 0.0043267]
	Learning Rate: 0.00432667
	LOSS [training: 0.01911074432496431 | validation: 0.012634373361381318]
	TIME [epoch: 7.86 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0178127587977437		[learning rate: 0.0043165]
	Learning Rate: 0.00431646
	LOSS [training: 0.0178127587977437 | validation: 0.020894849422513788]
	TIME [epoch: 7.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0208930357024382		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.0208930357024382 | validation: 0.013274526187695665]
	TIME [epoch: 7.85 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015528532377762062		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.015528532377762062 | validation: 0.01961624465716015]
	TIME [epoch: 7.85 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021083174551856845		[learning rate: 0.004286]
	Learning Rate: 0.00428599
	LOSS [training: 0.021083174551856845 | validation: 0.008938143910045104]
	TIME [epoch: 7.85 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08645697907587228		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.08645697907587228 | validation: 0.053595811494394095]
	TIME [epoch: 7.88 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902908799026763		[learning rate: 0.0042658]
	Learning Rate: 0.0042658
	LOSS [training: 0.04902908799026763 | validation: 0.012281211856843941]
	TIME [epoch: 7.87 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015216991599638924		[learning rate: 0.0042557]
	Learning Rate: 0.00425573
	LOSS [training: 0.015216991599638924 | validation: 0.009538097998365821]
	TIME [epoch: 7.85 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012098982841873464		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.012098982841873464 | validation: 0.016743764697943413]
	TIME [epoch: 7.85 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597016271375516		[learning rate: 0.0042357]
	Learning Rate: 0.00423568
	LOSS [training: 0.01597016271375516 | validation: 0.009346112727568235]
	TIME [epoch: 7.86 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014454069188824008		[learning rate: 0.0042257]
	Learning Rate: 0.00422569
	LOSS [training: 0.014454069188824008 | validation: 0.01245832398004916]
	TIME [epoch: 7.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01025203005109402		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.01025203005109402 | validation: 0.012675840645685766]
	TIME [epoch: 7.86 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024728986599627044		[learning rate: 0.0042058]
	Learning Rate: 0.00420578
	LOSS [training: 0.024728986599627044 | validation: 0.019490760996005878]
	TIME [epoch: 7.85 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014548098760296429		[learning rate: 0.0041959]
	Learning Rate: 0.00419585
	LOSS [training: 0.014548098760296429 | validation: 0.010641454090912335]
	TIME [epoch: 7.84 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013209333709792666		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.013209333709792666 | validation: 0.021060106778280678]
	TIME [epoch: 7.84 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01940926517595775		[learning rate: 0.0041761]
	Learning Rate: 0.00417608
	LOSS [training: 0.01940926517595775 | validation: 0.04045188992317518]
	TIME [epoch: 7.89 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731238113636756		[learning rate: 0.0041662]
	Learning Rate: 0.00416623
	LOSS [training: 0.03731238113636756 | validation: 0.010881877653650993]
	TIME [epoch: 7.85 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020915590458720712		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.020915590458720712 | validation: 0.021457484080872193]
	TIME [epoch: 7.85 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01803755509528165		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.01803755509528165 | validation: 0.010728307535010195]
	TIME [epoch: 7.85 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011027327875048693		[learning rate: 0.0041368]
	Learning Rate: 0.00413682
	LOSS [training: 0.011027327875048693 | validation: 0.011837949148002975]
	TIME [epoch: 7.85 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016116215136611965		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.016116215136611965 | validation: 0.02097501519673477]
	TIME [epoch: 7.89 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026779942888078796		[learning rate: 0.0041173]
	Learning Rate: 0.00411733
	LOSS [training: 0.026779942888078796 | validation: 0.017599257662542358]
	TIME [epoch: 7.84 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018994986833698158		[learning rate: 0.0041076]
	Learning Rate: 0.00410762
	LOSS [training: 0.018994986833698158 | validation: 0.01323033467873206]
	TIME [epoch: 7.84 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012476492379218898		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.012476492379218898 | validation: 0.010762913258300782]
	TIME [epoch: 7.85 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013868636735672742		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.013868636735672742 | validation: 0.023106466856186662]
	TIME [epoch: 7.88 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543874748808204		[learning rate: 0.0040786]
	Learning Rate: 0.00407862
	LOSS [training: 0.03543874748808204 | validation: 0.01924418248319029]
	TIME [epoch: 7.86 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017116632185276034		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.017116632185276034 | validation: 0.013878633874485395]
	TIME [epoch: 7.85 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08010571235703927		[learning rate: 0.0040594]
	Learning Rate: 0.0040594
	LOSS [training: 0.08010571235703927 | validation: 0.026951712091242475]
	TIME [epoch: 7.84 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02326978526730535		[learning rate: 0.0040498]
	Learning Rate: 0.00404982
	LOSS [training: 0.02326978526730535 | validation: 0.009298032979074753]
	TIME [epoch: 7.85 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008783918058147122		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.008783918058147122 | validation: 0.00859531292410867]
	TIME [epoch: 7.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008344370657593955		[learning rate: 0.0040307]
	Learning Rate: 0.00403074
	LOSS [training: 0.008344370657593955 | validation: 0.011820302349818675]
	TIME [epoch: 7.86 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01630208873178303		[learning rate: 0.0040212]
	Learning Rate: 0.00402123
	LOSS [training: 0.01630208873178303 | validation: 0.013590077184086865]
	TIME [epoch: 7.85 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01150698498848801		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.01150698498848801 | validation: 0.0076403597221897015]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00901722901601335		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.00901722901601335 | validation: 0.0074272428176688195]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01269046094652073		[learning rate: 0.0039928]
	Learning Rate: 0.00399284
	LOSS [training: 0.01269046094652073 | validation: 0.02138043857988011]
	TIME [epoch: 7.91 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015021079403536957		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.015021079403536957 | validation: 0.019457406039136014]
	TIME [epoch: 7.86 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986303202603919		[learning rate: 0.003974]
	Learning Rate: 0.00397403
	LOSS [training: 0.02986303202603919 | validation: 0.04690307195187432]
	TIME [epoch: 7.84 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04324364750460468		[learning rate: 0.0039647]
	Learning Rate: 0.00396465
	LOSS [training: 0.04324364750460468 | validation: 0.014723451014334903]
	TIME [epoch: 7.82 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013902149499911108		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.013902149499911108 | validation: 0.011265652963914156]
	TIME [epoch: 7.85 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009864332210482336		[learning rate: 0.003946]
	Learning Rate: 0.00394597
	LOSS [training: 0.009864332210482336 | validation: 0.007939872673553821]
	TIME [epoch: 7.86 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009626208183970662		[learning rate: 0.0039367]
	Learning Rate: 0.00393666
	LOSS [training: 0.009626208183970662 | validation: 0.00868915466711299]
	TIME [epoch: 7.84 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025922048682170434		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.025922048682170434 | validation: 0.009108114310984263]
	TIME [epoch: 7.82 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011551472078408818		[learning rate: 0.0039181]
	Learning Rate: 0.00391811
	LOSS [training: 0.011551472078408818 | validation: 0.013146004062470962]
	TIME [epoch: 7.82 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010471112383780826		[learning rate: 0.0039089]
	Learning Rate: 0.00390887
	LOSS [training: 0.010471112383780826 | validation: 0.007750746640688028]
	TIME [epoch: 7.86 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015765334226158244		[learning rate: 0.0038996]
	Learning Rate: 0.00389965
	LOSS [training: 0.015765334226158244 | validation: 0.04739764347776366]
	TIME [epoch: 7.85 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042663360617590296		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.042663360617590296 | validation: 0.00957100263297611]
	TIME [epoch: 7.83 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010900705258722894		[learning rate: 0.0038813]
	Learning Rate: 0.00388127
	LOSS [training: 0.010900705258722894 | validation: 0.01058743702167566]
	TIME [epoch: 7.82 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010540412934432563		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.010540412934432563 | validation: 0.008809270872807431]
	TIME [epoch: 7.82 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014102242523445246		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.014102242523445246 | validation: 0.017881218372088573]
	TIME [epoch: 7.87 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0259825385019023		[learning rate: 0.0038539]
	Learning Rate: 0.00385387
	LOSS [training: 0.0259825385019023 | validation: 0.009034497794838921]
	TIME [epoch: 7.84 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822266982723035		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.01822266982723035 | validation: 0.01751166956233559]
	TIME [epoch: 7.84 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015467234729734797		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.015467234729734797 | validation: 0.012529815960355946]
	TIME [epoch: 7.82 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011027997892349855		[learning rate: 0.0038267]
	Learning Rate: 0.00382667
	LOSS [training: 0.011027997892349855 | validation: 0.031179305832477897]
	TIME [epoch: 7.82 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023568097004564317		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.023568097004564317 | validation: 0.00860495233945973]
	TIME [epoch: 7.87 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018821380274863554		[learning rate: 0.0038086]
	Learning Rate: 0.00380863
	LOSS [training: 0.018821380274863554 | validation: 0.009633679877481625]
	TIME [epoch: 7.84 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01327023643672847		[learning rate: 0.0037996]
	Learning Rate: 0.00379965
	LOSS [training: 0.01327023643672847 | validation: 0.011584751248844026]
	TIME [epoch: 7.84 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026943999096438076		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.026943999096438076 | validation: 0.039402710575428095]
	TIME [epoch: 7.82 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03149069064452552		[learning rate: 0.0037817]
	Learning Rate: 0.00378175
	LOSS [training: 0.03149069064452552 | validation: 0.0119480147210204]
	TIME [epoch: 7.84 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010276269285129357		[learning rate: 0.0037728]
	Learning Rate: 0.00377283
	LOSS [training: 0.010276269285129357 | validation: 0.008384496622333808]
	TIME [epoch: 7.86 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010126007013740754		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.010126007013740754 | validation: 0.010126741242547449]
	TIME [epoch: 7.83 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00890396664076165		[learning rate: 0.003755]
	Learning Rate: 0.00375505
	LOSS [training: 0.00890396664076165 | validation: 0.007026480718864625]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016768242155943185		[learning rate: 0.0037462]
	Learning Rate: 0.00374619
	LOSS [training: 0.016768242155943185 | validation: 0.012566837814622468]
	TIME [epoch: 7.85 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011907301023860329		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.011907301023860329 | validation: 0.010344112370847019]
	TIME [epoch: 7.89 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016210924007105974		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.016210924007105974 | validation: 0.029773063091111378]
	TIME [epoch: 7.87 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023040709290654902		[learning rate: 0.0037197]
	Learning Rate: 0.00371974
	LOSS [training: 0.023040709290654902 | validation: 0.009273229734845317]
	TIME [epoch: 7.84 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009490093269461701		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.009490093269461701 | validation: 0.012459410530570179]
	TIME [epoch: 7.85 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014004126072687405		[learning rate: 0.0037022]
	Learning Rate: 0.00370221
	LOSS [training: 0.014004126072687405 | validation: 0.01409490287167359]
	TIME [epoch: 7.85 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025179619544862454		[learning rate: 0.0036935]
	Learning Rate: 0.00369348
	LOSS [training: 0.025179619544862454 | validation: 0.00816254826265897]
	TIME [epoch: 7.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01796943379433112		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.01796943379433112 | validation: 0.020479883813294193]
	TIME [epoch: 7.85 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016892271043647288		[learning rate: 0.0036761]
	Learning Rate: 0.00367608
	LOSS [training: 0.016892271043647288 | validation: 0.011072425667889097]
	TIME [epoch: 7.85 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012997978561440577		[learning rate: 0.0036674]
	Learning Rate: 0.00366741
	LOSS [training: 0.012997978561440577 | validation: 0.016986802505536774]
	TIME [epoch: 7.84 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010686931681353668		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.010686931681353668 | validation: 0.014955154786585014]
	TIME [epoch: 7.85 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026464740302217904		[learning rate: 0.0036501]
	Learning Rate: 0.00365012
	LOSS [training: 0.026464740302217904 | validation: 0.012972581495644543]
	TIME [epoch: 7.89 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015794135065600793		[learning rate: 0.0036415]
	Learning Rate: 0.00364151
	LOSS [training: 0.015794135065600793 | validation: 0.010280394453211564]
	TIME [epoch: 7.85 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008831021675706104		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.008831021675706104 | validation: 0.008465639764831799]
	TIME [epoch: 7.85 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011328364889706873		[learning rate: 0.0036244]
	Learning Rate: 0.00362436
	LOSS [training: 0.011328364889706873 | validation: 0.012153289217494766]
	TIME [epoch: 7.84 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011369291321522073		[learning rate: 0.0036158]
	Learning Rate: 0.00361581
	LOSS [training: 0.011369291321522073 | validation: 0.016448885725849478]
	TIME [epoch: 7.86 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018110810745198783		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.018110810745198783 | validation: 0.02844732460038671]
	TIME [epoch: 7.87 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05016173751858293		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.05016173751858293 | validation: 0.02975916553785183]
	TIME [epoch: 7.86 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04801208245654112		[learning rate: 0.0035903]
	Learning Rate: 0.00359028
	LOSS [training: 0.04801208245654112 | validation: 0.0545340816398419]
	TIME [epoch: 7.85 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030975783461222015		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.030975783461222015 | validation: 0.031657030528068925]
	TIME [epoch: 7.84 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019343750775415672		[learning rate: 0.0035734]
	Learning Rate: 0.00357336
	LOSS [training: 0.019343750775415672 | validation: 0.011653126891738651]
	TIME [epoch: 7.88 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011177042348645541		[learning rate: 0.0035649]
	Learning Rate: 0.00356493
	LOSS [training: 0.011177042348645541 | validation: 0.009064974981726419]
	TIME [epoch: 7.87 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010328125782102737		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.010328125782102737 | validation: 0.00873905113188803]
	TIME [epoch: 7.85 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011684412645429451		[learning rate: 0.0035481]
	Learning Rate: 0.00354813
	LOSS [training: 0.011684412645429451 | validation: 0.014882600141354566]
	TIME [epoch: 7.85 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01193659180817803		[learning rate: 0.0035398]
	Learning Rate: 0.00353976
	LOSS [training: 0.01193659180817803 | validation: 0.012819993799409655]
	TIME [epoch: 7.85 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012637875838962587		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.012637875838962587 | validation: 0.016737524067296117]
	TIME [epoch: 7.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010900464716825957		[learning rate: 0.0035231]
	Learning Rate: 0.00352308
	LOSS [training: 0.010900464716825957 | validation: 0.006819762413246748]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016479704354001274		[learning rate: 0.0035148]
	Learning Rate: 0.00351477
	LOSS [training: 0.016479704354001274 | validation: 0.011888299108634651]
	TIME [epoch: 7.85 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011187647252385769		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.011187647252385769 | validation: 0.012124263988159066]
	TIME [epoch: 7.84 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013765696546770997		[learning rate: 0.0034982]
	Learning Rate: 0.00349821
	LOSS [training: 0.013765696546770997 | validation: 0.007949669017973799]
	TIME [epoch: 7.85 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012444542606672231		[learning rate: 0.00349]
	Learning Rate: 0.00348996
	LOSS [training: 0.012444542606672231 | validation: 0.028243865090426576]
	TIME [epoch: 7.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020005570439053228		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.020005570439053228 | validation: 0.008538090685202105]
	TIME [epoch: 7.85 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008275186842970647		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.008275186842970647 | validation: 0.011110365434697105]
	TIME [epoch: 7.86 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012278377201155518		[learning rate: 0.0034653]
	Learning Rate: 0.00346532
	LOSS [training: 0.012278377201155518 | validation: 0.00881384549754632]
	TIME [epoch: 7.85 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009424123110884312		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.009424123110884312 | validation: 0.05457492248759725]
	TIME [epoch: 7.89 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03194494096461282		[learning rate: 0.003449]
	Learning Rate: 0.00344899
	LOSS [training: 0.03194494096461282 | validation: 0.009979098398427156]
	TIME [epoch: 7.87 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012002642634635434		[learning rate: 0.0034409]
	Learning Rate: 0.00344086
	LOSS [training: 0.012002642634635434 | validation: 0.012023037991740256]
	TIME [epoch: 7.85 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035953504808100716		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.035953504808100716 | validation: 0.010886003163045525]
	TIME [epoch: 7.85 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009791063324571338		[learning rate: 0.0034246]
	Learning Rate: 0.00342464
	LOSS [training: 0.009791063324571338 | validation: 0.008456761623225884]
	TIME [epoch: 7.85 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016804974898833352		[learning rate: 0.0034166]
	Learning Rate: 0.00341657
	LOSS [training: 0.016804974898833352 | validation: 0.008737545024632521]
	TIME [epoch: 7.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007791242103671721		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.007791242103671721 | validation: 0.006385813071580348]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01199619025375527		[learning rate: 0.0034005]
	Learning Rate: 0.00340047
	LOSS [training: 0.01199619025375527 | validation: 0.010907084431177038]
	TIME [epoch: 7.86 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011682325471798902		[learning rate: 0.0033924]
	Learning Rate: 0.00339244
	LOSS [training: 0.011682325471798902 | validation: 0.007095721038806549]
	TIME [epoch: 7.85 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011579449456036964		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.011579449456036964 | validation: 0.008040214205476877]
	TIME [epoch: 7.85 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008178903378162225		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.008178903378162225 | validation: 0.016896177009565472]
	TIME [epoch: 7.89 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01292428200883587		[learning rate: 0.0033685]
	Learning Rate: 0.0033685
	LOSS [training: 0.01292428200883587 | validation: 0.031568233703635665]
	TIME [epoch: 7.85 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02951524540785563		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.02951524540785563 | validation: 0.010637809717683883]
	TIME [epoch: 7.85 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010590651423636039		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.010590651423636039 | validation: 0.00730399868131109]
	TIME [epoch: 7.85 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008083560048031346		[learning rate: 0.0033447]
	Learning Rate: 0.00334471
	LOSS [training: 0.008083560048031346 | validation: 0.008880598235086763]
	TIME [epoch: 7.88 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013443721399881405		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.013443721399881405 | validation: 0.014887851584172282]
	TIME [epoch: 7.89 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012340906239253203		[learning rate: 0.003329]
	Learning Rate: 0.00332895
	LOSS [training: 0.012340906239253203 | validation: 0.009744255353754061]
	TIME [epoch: 7.86 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009096351057549459		[learning rate: 0.0033211]
	Learning Rate: 0.0033211
	LOSS [training: 0.009096351057549459 | validation: 0.009669448555466602]
	TIME [epoch: 7.85 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008661699519360007		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.008661699519360007 | validation: 0.011930895575267116]
	TIME [epoch: 7.85 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016476502136743166		[learning rate: 0.0033055]
	Learning Rate: 0.00330545
	LOSS [training: 0.016476502136743166 | validation: 0.012202954661327876]
	TIME [epoch: 7.89 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010342427964900812		[learning rate: 0.0032977]
	Learning Rate: 0.00329765
	LOSS [training: 0.010342427964900812 | validation: 0.006518894378499276]
	TIME [epoch: 7.87 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01985729157118452		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.01985729157118452 | validation: 0.012158346228673237]
	TIME [epoch: 7.85 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009215255114518671		[learning rate: 0.0032821]
	Learning Rate: 0.00328212
	LOSS [training: 0.009215255114518671 | validation: 0.010603615392844889]
	TIME [epoch: 7.84 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017346637907259956		[learning rate: 0.0032744]
	Learning Rate: 0.00327437
	LOSS [training: 0.017346637907259956 | validation: 0.012603963928688289]
	TIME [epoch: 7.85 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0139557692143382		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.0139557692143382 | validation: 0.01646185646999887]
	TIME [epoch: 7.89 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01369442808743908		[learning rate: 0.0032589]
	Learning Rate: 0.00325894
	LOSS [training: 0.01369442808743908 | validation: 0.009510805360572014]
	TIME [epoch: 7.85 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024841337845958936		[learning rate: 0.0032513]
	Learning Rate: 0.00325126
	LOSS [training: 0.024841337845958936 | validation: 0.10154704129776182]
	TIME [epoch: 7.84 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320376239824689		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.07320376239824689 | validation: 0.022491796767632764]
	TIME [epoch: 7.85 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014462314659039792		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.014462314659039792 | validation: 0.0075665332046151775]
	TIME [epoch: 7.85 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007819228440701664		[learning rate: 0.0032283]
	Learning Rate: 0.0032283
	LOSS [training: 0.007819228440701664 | validation: 0.02657043903051375]
	TIME [epoch: 7.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015686775441603275		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.015686775441603275 | validation: 0.008905704800296786]
	TIME [epoch: 7.86 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008928422237172575		[learning rate: 0.0032131]
	Learning Rate: 0.00321309
	LOSS [training: 0.008928422237172575 | validation: 0.010548295088941124]
	TIME [epoch: 7.84 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020268608810684076		[learning rate: 0.0032055]
	Learning Rate: 0.00320551
	LOSS [training: 0.020268608810684076 | validation: 0.012601786107287186]
	TIME [epoch: 7.86 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010751334146240838		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.010751334146240838 | validation: 0.006731218483821505]
	TIME [epoch: 7.86 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008751087952306679		[learning rate: 0.0031904]
	Learning Rate: 0.00319041
	LOSS [training: 0.008751087952306679 | validation: 0.009156751054338516]
	TIME [epoch: 7.88 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009197370272158382		[learning rate: 0.0031829]
	Learning Rate: 0.00318288
	LOSS [training: 0.009197370272158382 | validation: 0.009875517347548648]
	TIME [epoch: 7.86 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010566307565609596		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.010566307565609596 | validation: 0.018589454671407227]
	TIME [epoch: 7.85 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012287996216123606		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.012287996216123606 | validation: 0.014223194414298517]
	TIME [epoch: 7.85 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013006761607068278		[learning rate: 0.0031604]
	Learning Rate: 0.00316041
	LOSS [training: 0.013006761607068278 | validation: 0.01394672835646412]
	TIME [epoch: 7.88 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021882617815393687		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.021882617815393687 | validation: 0.008690171289532745]
	TIME [epoch: 7.87 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011618698124761023		[learning rate: 0.0031455]
	Learning Rate: 0.00314552
	LOSS [training: 0.011618698124761023 | validation: 0.00778685187492177]
	TIME [epoch: 7.85 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008949754099295623		[learning rate: 0.0031381]
	Learning Rate: 0.0031381
	LOSS [training: 0.008949754099295623 | validation: 0.007853524219412935]
	TIME [epoch: 7.85 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010771566108603602		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.010771566108603602 | validation: 0.01947859406459687]
	TIME [epoch: 7.84 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014855902090601402		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.014855902090601402 | validation: 0.006956746313508471]
	TIME [epoch: 7.91 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010077988992855919		[learning rate: 0.0031159]
	Learning Rate: 0.00311594
	LOSS [training: 0.010077988992855919 | validation: 0.0077738224178789325]
	TIME [epoch: 7.86 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013563284461185762		[learning rate: 0.0031086]
	Learning Rate: 0.0031086
	LOSS [training: 0.013563284461185762 | validation: 0.01143240239754106]
	TIME [epoch: 7.85 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010540910136158783		[learning rate: 0.0031013]
	Learning Rate: 0.00310126
	LOSS [training: 0.010540910136158783 | validation: 0.008411125075609965]
	TIME [epoch: 7.85 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009968901693679467		[learning rate: 0.0030939]
	Learning Rate: 0.00309395
	LOSS [training: 0.009968901693679467 | validation: 0.029554248464837025]
	TIME [epoch: 7.85 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024204076807353394		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.024204076807353394 | validation: 0.008163999891513788]
	TIME [epoch: 7.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01252392223789284		[learning rate: 0.0030794]
	Learning Rate: 0.00307937
	LOSS [training: 0.01252392223789284 | validation: 0.013115488686456253]
	TIME [epoch: 7.85 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011188481168045612		[learning rate: 0.0030721]
	Learning Rate: 0.0030721
	LOSS [training: 0.011188481168045612 | validation: 0.009356171331273559]
	TIME [epoch: 7.85 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021635324073775344		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.021635324073775344 | validation: 0.021789737288155184]
	TIME [epoch: 7.84 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019877132499267678		[learning rate: 0.0030576]
	Learning Rate: 0.00305763
	LOSS [training: 0.019877132499267678 | validation: 0.00672000731765731]
	TIME [epoch: 7.86 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00793252202512468		[learning rate: 0.0030504]
	Learning Rate: 0.00305042
	LOSS [training: 0.00793252202512468 | validation: 0.007430612498063819]
	TIME [epoch: 7.88 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007705604165004232		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.007705604165004232 | validation: 0.00633611541642427]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008902414990431012		[learning rate: 0.003036]
	Learning Rate: 0.00303604
	LOSS [training: 0.008902414990431012 | validation: 0.010636706749736519]
	TIME [epoch: 7.84 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011840985607093108		[learning rate: 0.0030289]
	Learning Rate: 0.00302888
	LOSS [training: 0.011840985607093108 | validation: 0.007516879729428594]
	TIME [epoch: 7.84 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007513139865130232		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.007513139865130232 | validation: 0.015309561947315824]
	TIME [epoch: 7.89 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012141912542246627		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.012141912542246627 | validation: 0.008731071633251427]
	TIME [epoch: 7.86 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007712670340999506		[learning rate: 0.0030075]
	Learning Rate: 0.0030075
	LOSS [training: 0.007712670340999506 | validation: 0.007174486103025462]
	TIME [epoch: 7.85 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007431693716946554		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.007431693716946554 | validation: 0.01371753856529474]
	TIME [epoch: 7.85 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018507061670303828		[learning rate: 0.0029933]
	Learning Rate: 0.00299332
	LOSS [training: 0.018507061670303828 | validation: 0.00635042343083652]
	TIME [epoch: 7.85 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009848932701775896		[learning rate: 0.0029863]
	Learning Rate: 0.00298626
	LOSS [training: 0.009848932701775896 | validation: 0.00699939154800766]
	TIME [epoch: 7.91 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011431489403348717		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.011431489403348717 | validation: 0.007517683886758267]
	TIME [epoch: 7.86 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027464352942394556		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.027464352942394556 | validation: 0.04531298183841585]
	TIME [epoch: 7.85 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031137872398555907		[learning rate: 0.0029652]
	Learning Rate: 0.00296518
	LOSS [training: 0.031137872398555907 | validation: 0.007577871111759525]
	TIME [epoch: 7.85 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008124768278292276		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.008124768278292276 | validation: 0.009239872381769583]
	TIME [epoch: 7.85 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749322350869367		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.02749322350869367 | validation: 0.028821945041317548]
	TIME [epoch: 7.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02386646458292601		[learning rate: 0.0029442]
	Learning Rate: 0.00294425
	LOSS [training: 0.02386646458292601 | validation: 0.011117085299141948]
	TIME [epoch: 7.85 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015102237279176558		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.015102237279176558 | validation: 0.00796147458607536]
	TIME [epoch: 7.85 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04016543243359331		[learning rate: 0.0029304]
	Learning Rate: 0.00293037
	LOSS [training: 0.04016543243359331 | validation: 0.008373507531994737]
	TIME [epoch: 7.85 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021433216434915407		[learning rate: 0.0029235]
	Learning Rate: 0.00292346
	LOSS [training: 0.021433216434915407 | validation: 0.0321483378068135]
	TIME [epoch: 7.87 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021626509221572124		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.021626509221572124 | validation: 0.013143186211793948]
	TIME [epoch: 7.89 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012729507156944212		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.012729507156944212 | validation: 0.008679459098602883]
	TIME [epoch: 7.85 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010971505001533622		[learning rate: 0.0029028]
	Learning Rate: 0.00290282
	LOSS [training: 0.010971505001533622 | validation: 0.008132015378161793]
	TIME [epoch: 7.85 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00889669242587791		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.00889669242587791 | validation: 0.008148868837608682]
	TIME [epoch: 7.84 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010493481918739247		[learning rate: 0.0028891]
	Learning Rate: 0.00288914
	LOSS [training: 0.010493481918739247 | validation: 0.011647300290571056]
	TIME [epoch: 7.88 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009648055110313025		[learning rate: 0.0028823]
	Learning Rate: 0.00288233
	LOSS [training: 0.009648055110313025 | validation: 0.009022914420484085]
	TIME [epoch: 7.87 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007450873199591349		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.007450873199591349 | validation: 0.009925320987854081]
	TIME [epoch: 7.85 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011097210026620969		[learning rate: 0.0028687]
	Learning Rate: 0.00286875
	LOSS [training: 0.011097210026620969 | validation: 0.016416933260909684]
	TIME [epoch: 7.84 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015324411136640912		[learning rate: 0.002862]
	Learning Rate: 0.00286198
	LOSS [training: 0.015324411136640912 | validation: 0.011048375324470004]
	TIME [epoch: 7.84 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012112567749408682		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.012112567749408682 | validation: 0.00827327188781913]
	TIME [epoch: 7.89 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01180540123073237		[learning rate: 0.0028485]
	Learning Rate: 0.00284849
	LOSS [training: 0.01180540123073237 | validation: 0.01093076720995723]
	TIME [epoch: 7.84 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013287659384044295		[learning rate: 0.0028418]
	Learning Rate: 0.00284178
	LOSS [training: 0.013287659384044295 | validation: 0.0071617516800936195]
	TIME [epoch: 7.84 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008301093120450513		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.008301093120450513 | validation: 0.009450910824422135]
	TIME [epoch: 7.84 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010355307484092248		[learning rate: 0.0028284]
	Learning Rate: 0.00282838
	LOSS [training: 0.010355307484092248 | validation: 0.007267640478798465]
	TIME [epoch: 7.84 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008687851428725746		[learning rate: 0.0028217]
	Learning Rate: 0.00282171
	LOSS [training: 0.008687851428725746 | validation: 0.013088443346241665]
	TIME [epoch: 7.89 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011778061552486317		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.011778061552486317 | validation: 0.009947505706300453]
	TIME [epoch: 7.84 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010369402558576067		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.010369402558576067 | validation: 0.007457581933403599]
	TIME [epoch: 7.85 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012021497245897798		[learning rate: 0.0028018]
	Learning Rate: 0.00280179
	LOSS [training: 0.012021497245897798 | validation: 0.05959492655423482]
	TIME [epoch: 7.85 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208235848429653		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.04208235848429653 | validation: 0.007018866095265437]
	TIME [epoch: 7.86 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009346607316251634		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.009346607316251634 | validation: 0.00888567425570048]
	TIME [epoch: 7.88 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007411649226035115		[learning rate: 0.002782]
	Learning Rate: 0.00278201
	LOSS [training: 0.007411649226035115 | validation: 0.008434601014477808]
	TIME [epoch: 7.86 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009491273816503732		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.009491273816503732 | validation: 0.012287919577981588]
	TIME [epoch: 7.84 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008862768098294364		[learning rate: 0.0027689]
	Learning Rate: 0.0027689
	LOSS [training: 0.008862768098294364 | validation: 0.0094412768098556]
	TIME [epoch: 7.84 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008006186530085944		[learning rate: 0.0027624]
	Learning Rate: 0.00276237
	LOSS [training: 0.008006186530085944 | validation: 0.008063207159402515]
	TIME [epoch: 7.87 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020790360517180827		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.020790360517180827 | validation: 0.009816256004332254]
	TIME [epoch: 7.87 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00964427038776617		[learning rate: 0.0027494]
	Learning Rate: 0.00274936
	LOSS [training: 0.00964427038776617 | validation: 0.02806686155162469]
	TIME [epoch: 7.84 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314922407120461		[learning rate: 0.0027429]
	Learning Rate: 0.00274287
	LOSS [training: 0.0314922407120461 | validation: 0.015960413177406513]
	TIME [epoch: 7.85 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015735749237668236		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.015735749237668236 | validation: 0.005063761105603856]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008937898295021339		[learning rate: 0.0027299]
	Learning Rate: 0.00272994
	LOSS [training: 0.008937898295021339 | validation: 0.03405843210754342]
	TIME [epoch: 7.89 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017571009389489158		[learning rate: 0.0027235]
	Learning Rate: 0.00272351
	LOSS [training: 0.017571009389489158 | validation: 0.006987018275940962]
	TIME [epoch: 7.83 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007960446509119201		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.007960446509119201 | validation: 0.006688307965511413]
	TIME [epoch: 7.84 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006930146095663963		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.006930146095663963 | validation: 0.013771770573159271]
	TIME [epoch: 7.84 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010595089377340628		[learning rate: 0.0027043]
	Learning Rate: 0.00270428
	LOSS [training: 0.010595089377340628 | validation: 0.007582872265475231]
	TIME [epoch: 7.85 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024417084028734472		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.024417084028734472 | validation: 0.01172223456085569]
	TIME [epoch: 7.87 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008887628934474298		[learning rate: 0.0026915]
	Learning Rate: 0.00269153
	LOSS [training: 0.008887628934474298 | validation: 0.00772761976018553]
	TIME [epoch: 7.83 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072237820952635035		[learning rate: 0.0026852]
	Learning Rate: 0.00268519
	LOSS [training: 0.0072237820952635035 | validation: 0.008329868517928352]
	TIME [epoch: 7.84 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007639521778149946		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.007639521778149946 | validation: 0.00798570879248555]
	TIME [epoch: 7.84 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041340319111639316		[learning rate: 0.0026725]
	Learning Rate: 0.00267253
	LOSS [training: 0.041340319111639316 | validation: 0.018835332604941652]
	TIME [epoch: 7.87 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013055618527117147		[learning rate: 0.0026662]
	Learning Rate: 0.00266623
	LOSS [training: 0.013055618527117147 | validation: 0.012400901807231215]
	TIME [epoch: 7.86 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009874233744826304		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.009874233744826304 | validation: 0.007718911947125753]
	TIME [epoch: 7.84 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019289974257360017		[learning rate: 0.0026537]
	Learning Rate: 0.00265367
	LOSS [training: 0.019289974257360017 | validation: 0.009450254710733573]
	TIME [epoch: 7.83 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009711684977842049		[learning rate: 0.0026474]
	Learning Rate: 0.00264741
	LOSS [training: 0.009711684977842049 | validation: 0.012235068371639405]
	TIME [epoch: 7.84 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01433712385215267		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.01433712385215267 | validation: 0.013938679330226338]
	TIME [epoch: 7.88 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02414609165290884		[learning rate: 0.0026349]
	Learning Rate: 0.00263493
	LOSS [training: 0.02414609165290884 | validation: 0.01945760128624567]
	TIME [epoch: 7.85 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014564187897080126		[learning rate: 0.0026287]
	Learning Rate: 0.00262872
	LOSS [training: 0.014564187897080126 | validation: 0.008722996704891036]
	TIME [epoch: 7.84 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069776458894382064		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.0069776458894382064 | validation: 0.007855835084203153]
	TIME [epoch: 7.84 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070163421303976415		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.0070163421303976415 | validation: 0.008103841067928243]
	TIME [epoch: 7.85 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00994840860188372		[learning rate: 0.0026102]
	Learning Rate: 0.00261016
	LOSS [training: 0.00994840860188372 | validation: 0.014610577438897095]
	TIME [epoch: 7.89 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021177862210425398		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.021177862210425398 | validation: 0.013738810460024129]
	TIME [epoch: 7.84 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014028450167938225		[learning rate: 0.0025979]
	Learning Rate: 0.00259786
	LOSS [training: 0.014028450167938225 | validation: 0.00839272830471081]
	TIME [epoch: 7.84 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010265159753166511		[learning rate: 0.0025917]
	Learning Rate: 0.00259173
	LOSS [training: 0.010265159753166511 | validation: 0.009119672097685806]
	TIME [epoch: 7.84 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00784793804407824		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.00784793804407824 | validation: 0.00800508284709602]
	TIME [epoch: 7.84 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009389143175506187		[learning rate: 0.0025795]
	Learning Rate: 0.00257952
	LOSS [training: 0.009389143175506187 | validation: 0.02284128830090038]
	TIME [epoch: 7.89 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012324353704409121		[learning rate: 0.0025734]
	Learning Rate: 0.00257343
	LOSS [training: 0.012324353704409121 | validation: 0.009984702834120637]
	TIME [epoch: 7.84 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006683269166132547		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.006683269166132547 | validation: 0.01240466223613074]
	TIME [epoch: 7.84 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028437502123923625		[learning rate: 0.0025613]
	Learning Rate: 0.00256131
	LOSS [training: 0.028437502123923625 | validation: 0.014678677802309088]
	TIME [epoch: 7.84 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01609777223798278		[learning rate: 0.0025553]
	Learning Rate: 0.00255526
	LOSS [training: 0.01609777223798278 | validation: 0.009932653309299324]
	TIME [epoch: 7.88 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009268569567355188		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.009268569567355188 | validation: 0.007403465804889505]
	TIME [epoch: 7.86 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009479710345920255		[learning rate: 0.0025432]
	Learning Rate: 0.00254322
	LOSS [training: 0.009479710345920255 | validation: 0.00691403862603]
	TIME [epoch: 7.84 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00808257505704076		[learning rate: 0.0025372]
	Learning Rate: 0.00253722
	LOSS [training: 0.00808257505704076 | validation: 0.0058126048295861765]
	TIME [epoch: 7.85 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007831926648639369		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.007831926648639369 | validation: 0.008519435600643537]
	TIME [epoch: 7.85 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007482324212868801		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.007482324212868801 | validation: 0.005784037765620672]
	TIME [epoch: 7.91 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006629826384155246		[learning rate: 0.0025193]
	Learning Rate: 0.00251931
	LOSS [training: 0.006629826384155246 | validation: 0.00827512318843266]
	TIME [epoch: 7.85 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019250746568045797		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.019250746568045797 | validation: 0.008764179207386386]
	TIME [epoch: 7.84 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01858070959545177		[learning rate: 0.0025074]
	Learning Rate: 0.00250744
	LOSS [training: 0.01858070959545177 | validation: 0.017351776568307532]
	TIME [epoch: 7.84 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01826833060995847		[learning rate: 0.0025015]
	Learning Rate: 0.00250153
	LOSS [training: 0.01826833060995847 | validation: 0.0180067712245248]
	TIME [epoch: 7.84 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010234060007927738		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.010234060007927738 | validation: 0.006110381251897198]
	TIME [epoch: 7.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006824401979733224		[learning rate: 0.0024897]
	Learning Rate: 0.00248974
	LOSS [training: 0.006824401979733224 | validation: 0.0070361816453570316]
	TIME [epoch: 7.85 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00782304248025586		[learning rate: 0.0024839]
	Learning Rate: 0.00248387
	LOSS [training: 0.00782304248025586 | validation: 0.0082737789203224]
	TIME [epoch: 7.84 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013317077440280978		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.013317077440280978 | validation: 0.011875196128429914]
	TIME [epoch: 7.85 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008435778737381227		[learning rate: 0.0024722]
	Learning Rate: 0.00247216
	LOSS [training: 0.008435778737381227 | validation: 0.008402535422181712]
	TIME [epoch: 7.85 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007702871984821126		[learning rate: 0.0024663]
	Learning Rate: 0.00246633
	LOSS [training: 0.007702871984821126 | validation: 0.021628022503364215]
	TIME [epoch: 7.88 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014885337961403702		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.014885337961403702 | validation: 0.00712574812621772]
	TIME [epoch: 7.85 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007202037264926631		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.007202037264926631 | validation: 0.00592146636557549]
	TIME [epoch: 7.85 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007314231589109939		[learning rate: 0.0024489]
	Learning Rate: 0.00244892
	LOSS [training: 0.007314231589109939 | validation: 0.008653880259995354]
	TIME [epoch: 7.85 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007413291710212693		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.007413291710212693 | validation: 0.01682723134460925]
	TIME [epoch: 7.88 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01012044196895344		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.01012044196895344 | validation: 0.009725876341255182]
	TIME [epoch: 7.87 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007882404140423628		[learning rate: 0.0024316]
	Learning Rate: 0.00243163
	LOSS [training: 0.007882404140423628 | validation: 0.007799060570616424]
	TIME [epoch: 7.85 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012078309747294014		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.012078309747294014 | validation: 0.0070407987889505134]
	TIME [epoch: 7.84 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007234917934019765		[learning rate: 0.0024202]
	Learning Rate: 0.00242017
	LOSS [training: 0.007234917934019765 | validation: 0.0061496030682822965]
	TIME [epoch: 7.84 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008014519085801093		[learning rate: 0.0024145]
	Learning Rate: 0.00241446
	LOSS [training: 0.008014519085801093 | validation: 0.012044362330504257]
	TIME [epoch: 7.89 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012245335593514891		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.012245335593514891 | validation: 0.005851086615854638]
	TIME [epoch: 7.85 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007852281939524856		[learning rate: 0.0024031]
	Learning Rate: 0.00240309
	LOSS [training: 0.007852281939524856 | validation: 0.004037614594477659]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006541272020100789		[learning rate: 0.0023974]
	Learning Rate: 0.00239742
	LOSS [training: 0.006541272020100789 | validation: 0.022120062840070284]
	TIME [epoch: 7.85 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015909364503667305		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.015909364503667305 | validation: 0.005743304331133981]
	TIME [epoch: 7.84 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007274885384000588		[learning rate: 0.0023861]
	Learning Rate: 0.00238612
	LOSS [training: 0.007274885384000588 | validation: 0.03709858568554819]
	TIME [epoch: 7.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309444896634722		[learning rate: 0.0023805]
	Learning Rate: 0.00238049
	LOSS [training: 0.03309444896634722 | validation: 0.010154704109920552]
	TIME [epoch: 7.85 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00818888867688652		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.00818888867688652 | validation: 0.006787396781628436]
	TIME [epoch: 7.85 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007017453594228949		[learning rate: 0.0023693]
	Learning Rate: 0.00236927
	LOSS [training: 0.007017453594228949 | validation: 0.006393831671420988]
	TIME [epoch: 7.85 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069223890802018		[learning rate: 0.0023637]
	Learning Rate: 0.00236369
	LOSS [training: 0.0069223890802018 | validation: 0.004801454680824931]
	TIME [epoch: 7.87 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00778551468661705		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.00778551468661705 | validation: 0.007083871092334302]
	TIME [epoch: 7.89 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008464806133548487		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.008464806133548487 | validation: 0.005614572189133748]
	TIME [epoch: 7.86 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061028832512242575		[learning rate: 0.002347]
	Learning Rate: 0.002347
	LOSS [training: 0.0061028832512242575 | validation: 0.008082329198777848]
	TIME [epoch: 7.85 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008740888735366862		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.008740888735366862 | validation: 0.0065153798212264375]
	TIME [epoch: 7.85 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007963016609254546		[learning rate: 0.0023359]
	Learning Rate: 0.00233594
	LOSS [training: 0.007963016609254546 | validation: 0.008728585344348262]
	TIME [epoch: 7.88 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008445673345182873		[learning rate: 0.0023304]
	Learning Rate: 0.00233043
	LOSS [training: 0.008445673345182873 | validation: 0.008727437817962385]
	TIME [epoch: 7.87 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011738106580461623		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.011738106580461623 | validation: 0.007457412259074144]
	TIME [epoch: 7.85 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008551853163567599		[learning rate: 0.0023194]
	Learning Rate: 0.00231945
	LOSS [training: 0.008551853163567599 | validation: 0.006994853370062644]
	TIME [epoch: 7.85 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007874943104270487		[learning rate: 0.002314]
	Learning Rate: 0.00231398
	LOSS [training: 0.007874943104270487 | validation: 0.0062412626396613265]
	TIME [epoch: 7.85 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016290840847510556		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.016290840847510556 | validation: 0.007861750257770354]
	TIME [epoch: 7.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010198712992650832		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.010198712992650832 | validation: 0.007190506247931763]
	TIME [epoch: 7.86 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011041596898214759		[learning rate: 0.0022976]
	Learning Rate: 0.00229764
	LOSS [training: 0.011041596898214759 | validation: 0.013084930967629714]
	TIME [epoch: 7.84 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012029570288537742		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.012029570288537742 | validation: 0.009409974986763875]
	TIME [epoch: 7.85 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01111034250246264		[learning rate: 0.0022868]
	Learning Rate: 0.00228681
	LOSS [training: 0.01111034250246264 | validation: 0.00848016224455295]
	TIME [epoch: 7.85 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008076257100138049		[learning rate: 0.0022814]
	Learning Rate: 0.00228142
	LOSS [training: 0.008076257100138049 | validation: 0.006701693130299624]
	TIME [epoch: 7.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008203411154256126		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.008203411154256126 | validation: 0.007735596574674939]
	TIME [epoch: 7.85 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019754494649669194		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.019754494649669194 | validation: 0.01394504375115222]
	TIME [epoch: 7.85 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010713642128842418		[learning rate: 0.0022653]
	Learning Rate: 0.00226531
	LOSS [training: 0.010713642128842418 | validation: 0.006655595073161802]
	TIME [epoch: 7.85 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007036580076979576		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.007036580076979576 | validation: 0.005380004361277025]
	TIME [epoch: 7.87 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065461007825551795		[learning rate: 0.0022546]
	Learning Rate: 0.00225464
	LOSS [training: 0.0065461007825551795 | validation: 0.008267107217609681]
	TIME [epoch: 7.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009206732741852812		[learning rate: 0.0022493]
	Learning Rate: 0.00224932
	LOSS [training: 0.009206732741852812 | validation: 0.0063545511087458135]
	TIME [epoch: 7.84 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064196086258814155		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.0064196086258814155 | validation: 0.0053253874600288215]
	TIME [epoch: 7.85 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006741933534889034		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.006741933534889034 | validation: 0.012669762001131506]
	TIME [epoch: 7.85 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01021463785759567		[learning rate: 0.0022334]
	Learning Rate: 0.00223344
	LOSS [training: 0.01021463785759567 | validation: 0.005698898664263607]
	TIME [epoch: 7.89 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011087019684635194		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.011087019684635194 | validation: 0.008847704969034649]
	TIME [epoch: 7.86 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0079740800733137		[learning rate: 0.0022229]
	Learning Rate: 0.00222292
	LOSS [training: 0.0079740800733137 | validation: 0.004790536796993577]
	TIME [epoch: 7.85 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008118226314424198		[learning rate: 0.0022177]
	Learning Rate: 0.00221767
	LOSS [training: 0.008118226314424198 | validation: 0.010066818352897605]
	TIME [epoch: 7.84 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020580002064907184		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.020580002064907184 | validation: 0.013955387814990186]
	TIME [epoch: 7.85 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018823992317309905		[learning rate: 0.0022072]
	Learning Rate: 0.00220722
	LOSS [training: 0.018823992317309905 | validation: 0.0064835580446214736]
	TIME [epoch: 7.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007324217794779305		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.007324217794779305 | validation: 0.006528673331740745]
	TIME [epoch: 7.86 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006232798823420722		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.006232798823420722 | validation: 0.02278565045630966]
	TIME [epoch: 7.85 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012269564501694948		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.012269564501694948 | validation: 0.0067756544267832865]
	TIME [epoch: 7.85 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062190021951954175		[learning rate: 0.0021865]
	Learning Rate: 0.00218647
	LOSS [training: 0.0062190021951954175 | validation: 0.006195109406890306]
	TIME [epoch: 7.84 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006317589910729135		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.006317589910729135 | validation: 0.0068597324695987135]
	TIME [epoch: 7.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010241004915281075		[learning rate: 0.0021762]
	Learning Rate: 0.00217617
	LOSS [training: 0.010241004915281075 | validation: 0.010595939807475235]
	TIME [epoch: 7.86 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007064981752227169		[learning rate: 0.002171]
	Learning Rate: 0.00217103
	LOSS [training: 0.007064981752227169 | validation: 0.006940283292753791]
	TIME [epoch: 7.86 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008325722221799446		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.008325722221799446 | validation: 0.009280657950292582]
	TIME [epoch: 7.85 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00873109249529527		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.00873109249529527 | validation: 0.008516451430628222]
	TIME [epoch: 7.86 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008473389890553837		[learning rate: 0.0021557]
	Learning Rate: 0.00215571
	LOSS [training: 0.008473389890553837 | validation: 0.007020369166526405]
	TIME [epoch: 7.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012848625086055335		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.012848625086055335 | validation: 0.008707114384778]
	TIME [epoch: 7.85 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007590940175099285		[learning rate: 0.0021455]
	Learning Rate: 0.00214555
	LOSS [training: 0.007590940175099285 | validation: 0.005509743464442832]
	TIME [epoch: 7.85 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007580711515327869		[learning rate: 0.0021405]
	Learning Rate: 0.00214049
	LOSS [training: 0.007580711515327869 | validation: 0.005647449921767717]
	TIME [epoch: 7.85 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006931486795780473		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.006931486795780473 | validation: 0.006349363319509453]
	TIME [epoch: 7.88 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01112106032158213		[learning rate: 0.0021304]
	Learning Rate: 0.0021304
	LOSS [training: 0.01112106032158213 | validation: 0.019596778344014645]
	TIME [epoch: 7.87 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011066839408579408		[learning rate: 0.0021254]
	Learning Rate: 0.00212538
	LOSS [training: 0.011066839408579408 | validation: 0.008111517227177588]
	TIME [epoch: 7.85 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00665306403656903		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.00665306403656903 | validation: 0.005968917179508438]
	TIME [epoch: 7.85 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005901861648025728		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.005901861648025728 | validation: 0.006350920366650593]
	TIME [epoch: 7.85 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00991046943918612		[learning rate: 0.0021104]
	Learning Rate: 0.00211037
	LOSS [training: 0.00991046943918612 | validation: 0.005049112943849408]
	TIME [epoch: 7.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010122771786852794		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.010122771786852794 | validation: 0.007088146549272237]
	TIME [epoch: 7.85 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007120602309074018		[learning rate: 0.0021004]
	Learning Rate: 0.00210043
	LOSS [training: 0.007120602309074018 | validation: 0.005718553696696762]
	TIME [epoch: 7.85 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013384886616926838		[learning rate: 0.0020955]
	Learning Rate: 0.00209547
	LOSS [training: 0.013384886616926838 | validation: 0.020813655228349125]
	TIME [epoch: 7.84 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014058107515281514		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.014058107515281514 | validation: 0.022050724082791892]
	TIME [epoch: 7.85 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01422868492320679		[learning rate: 0.0020856]
	Learning Rate: 0.0020856
	LOSS [training: 0.01422868492320679 | validation: 0.01547594444913712]
	TIME [epoch: 7.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010173414417900989		[learning rate: 0.0020807]
	Learning Rate: 0.00208068
	LOSS [training: 0.010173414417900989 | validation: 0.005851180399403494]
	TIME [epoch: 7.85 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006880664105504485		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.006880664105504485 | validation: 0.007541636457325057]
	TIME [epoch: 7.85 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006304346100662946		[learning rate: 0.0020709]
	Learning Rate: 0.00207087
	LOSS [training: 0.006304346100662946 | validation: 0.006845180451770105]
	TIME [epoch: 7.85 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01797591182695886		[learning rate: 0.002066]
	Learning Rate: 0.00206599
	LOSS [training: 0.01797591182695886 | validation: 0.008527578422560566]
	TIME [epoch: 7.86 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008671578513732167		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.008671578513732167 | validation: 0.007425126169183293]
	TIME [epoch: 7.88 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007250579826514029		[learning rate: 0.0020563]
	Learning Rate: 0.00205626
	LOSS [training: 0.007250579826514029 | validation: 0.01063356411348762]
	TIME [epoch: 7.84 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009060976884245826		[learning rate: 0.0020514]
	Learning Rate: 0.0020514
	LOSS [training: 0.009060976884245826 | validation: 0.006391273549372979]
	TIME [epoch: 7.85 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007298420018195069		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.007298420018195069 | validation: 0.013685620353135381]
	TIME [epoch: 7.84 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010582907629956511		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.010582907629956511 | validation: 0.005756879315986433]
	TIME [epoch: 7.87 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072236527582418865		[learning rate: 0.0020369]
	Learning Rate: 0.00203692
	LOSS [training: 0.0072236527582418865 | validation: 0.006467203944414281]
	TIME [epoch: 7.86 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00779063376222381		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.00779063376222381 | validation: 0.007678886968116331]
	TIME [epoch: 7.85 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006570971433658167		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.006570971433658167 | validation: 0.006243774089143591]
	TIME [epoch: 7.85 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009635698566114119		[learning rate: 0.0020225]
	Learning Rate: 0.00202254
	LOSS [training: 0.009635698566114119 | validation: 0.008386236958875703]
	TIME [epoch: 7.85 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074860787756708385		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.0074860787756708385 | validation: 0.006155257236166381]
	TIME [epoch: 7.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068660977428720744		[learning rate: 0.002013]
	Learning Rate: 0.00201301
	LOSS [training: 0.0068660977428720744 | validation: 0.00593364965571107]
	TIME [epoch: 7.85 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010128790894933787		[learning rate: 0.0020083]
	Learning Rate: 0.00200826
	LOSS [training: 0.010128790894933787 | validation: 0.005648890110569698]
	TIME [epoch: 7.85 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009193799817592805		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.009193799817592805 | validation: 0.00604551666273928]
	TIME [epoch: 7.85 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009209512806450982		[learning rate: 0.0019988]
	Learning Rate: 0.0019988
	LOSS [training: 0.009209512806450982 | validation: 0.008234297177347714]
	TIME [epoch: 7.85 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011416930469180521		[learning rate: 0.0019941]
	Learning Rate: 0.00199408
	LOSS [training: 0.011416930469180521 | validation: 0.006033223719767224]
	TIME [epoch: 7.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013799033210806203		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.013799033210806203 | validation: 0.009576189342004245]
	TIME [epoch: 7.85 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008768941918500627		[learning rate: 0.0019847]
	Learning Rate: 0.00198469
	LOSS [training: 0.008768941918500627 | validation: 0.006698108879964577]
	TIME [epoch: 7.84 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011807563221132265		[learning rate: 0.00198]
	Learning Rate: 0.00198001
	LOSS [training: 0.011807563221132265 | validation: 0.005418374731766771]
	TIME [epoch: 7.84 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008828131258406546		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.008828131258406546 | validation: 0.008581218246891172]
	TIME [epoch: 7.86 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075346749558885175		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.0075346749558885175 | validation: 0.007661445531270324]
	TIME [epoch: 7.87 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006994615387977792		[learning rate: 0.001966]
	Learning Rate: 0.00196603
	LOSS [training: 0.006994615387977792 | validation: 0.005349223908754727]
	TIME [epoch: 7.85 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006969897584784893		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.006969897584784893 | validation: 0.006243952198312976]
	TIME [epoch: 7.84 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008625617526200613		[learning rate: 0.0019568]
	Learning Rate: 0.00195676
	LOSS [training: 0.008625617526200613 | validation: 0.0065293992401995035]
	TIME [epoch: 7.85 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00824280110488484		[learning rate: 0.0019521]
	Learning Rate: 0.00195215
	LOSS [training: 0.00824280110488484 | validation: 0.005105059132032885]
	TIME [epoch: 7.88 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053635333582773585		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.0053635333582773585 | validation: 0.00598904486250561]
	TIME [epoch: 7.87 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007508593243591911		[learning rate: 0.0019429]
	Learning Rate: 0.00194295
	LOSS [training: 0.007508593243591911 | validation: 0.00565840658087561]
	TIME [epoch: 7.84 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010152679919079767		[learning rate: 0.0019384]
	Learning Rate: 0.00193837
	LOSS [training: 0.010152679919079767 | validation: 0.005449938663684384]
	TIME [epoch: 7.84 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006868941995082957		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.006868941995082957 | validation: 0.005487573175538744]
	TIME [epoch: 7.84 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061408351038596005		[learning rate: 0.0019292]
	Learning Rate: 0.00192923
	LOSS [training: 0.0061408351038596005 | validation: 0.005889512159573217]
	TIME [epoch: 7.89 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073308918718192236		[learning rate: 0.0019247]
	Learning Rate: 0.00192468
	LOSS [training: 0.0073308918718192236 | validation: 0.010690829732707137]
	TIME [epoch: 7.85 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009654621663691881		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.009654621663691881 | validation: 0.006647865106242736]
	TIME [epoch: 7.84 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005958015345542706		[learning rate: 0.0019156]
	Learning Rate: 0.00191561
	LOSS [training: 0.005958015345542706 | validation: 0.00809003780582538]
	TIME [epoch: 7.85 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009114396458010019		[learning rate: 0.0019111]
	Learning Rate: 0.00191109
	LOSS [training: 0.009114396458010019 | validation: 0.005793486040742691]
	TIME [epoch: 7.85 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006483586708943381		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.006483586708943381 | validation: 0.005451242237262245]
	TIME [epoch: 7.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00632730492336968		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.00632730492336968 | validation: 0.005873460193428573]
	TIME [epoch: 7.85 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007338461797325199		[learning rate: 0.0018976]
	Learning Rate: 0.0018976
	LOSS [training: 0.007338461797325199 | validation: 0.006156944931492744]
	TIME [epoch: 7.85 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008153538955813338		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.008153538955813338 | validation: 0.007543899216299226]
	TIME [epoch: 7.85 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005835991937287539		[learning rate: 0.0018887]
	Learning Rate: 0.00188866
	LOSS [training: 0.005835991937287539 | validation: 0.009510441058028507]
	TIME [epoch: 7.86 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009493902415764168		[learning rate: 0.0018842]
	Learning Rate: 0.00188421
	LOSS [training: 0.009493902415764168 | validation: 0.008082929547565206]
	TIME [epoch: 7.89 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013288663748848314		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.013288663748848314 | validation: 0.011328581869766237]
	TIME [epoch: 7.85 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008918181049111063		[learning rate: 0.0018753]
	Learning Rate: 0.00187533
	LOSS [training: 0.008918181049111063 | validation: 0.004883889541205686]
	TIME [epoch: 7.84 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005596285512603989		[learning rate: 0.0018709]
	Learning Rate: 0.0018709
	LOSS [training: 0.005596285512603989 | validation: 0.004807120342091979]
	TIME [epoch: 7.85 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012114581634241024		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.012114581634241024 | validation: 0.0069588314608079425]
	TIME [epoch: 7.88 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007578419348498589		[learning rate: 0.0018621]
	Learning Rate: 0.00186209
	LOSS [training: 0.007578419348498589 | validation: 0.0073537384446267316]
	TIME [epoch: 7.87 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007017642288392336		[learning rate: 0.0018577]
	Learning Rate: 0.00185769
	LOSS [training: 0.007017642288392336 | validation: 0.007329102416288652]
	TIME [epoch: 7.86 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077199679431187666		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.0077199679431187666 | validation: 0.006397062251835862]
	TIME [epoch: 7.85 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005099745412062807		[learning rate: 0.0018489]
	Learning Rate: 0.00184894
	LOSS [training: 0.005099745412062807 | validation: 0.00639899661196178]
	TIME [epoch: 7.85 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008209496542821602		[learning rate: 0.0018446]
	Learning Rate: 0.00184458
	LOSS [training: 0.008209496542821602 | validation: 0.004377321319567506]
	TIME [epoch: 7.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005771684839219928		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.005771684839219928 | validation: 0.004150731330976552]
	TIME [epoch: 7.86 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006290657650205592		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.006290657650205592 | validation: 0.006642543653240883]
	TIME [epoch: 7.85 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006639919363780384		[learning rate: 0.0018316]
	Learning Rate: 0.00183156
	LOSS [training: 0.006639919363780384 | validation: 0.010905874154342955]
	TIME [epoch: 7.87 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00947464986261361		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.00947464986261361 | validation: 0.008765809047707667]
	TIME [epoch: 7.85 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072125760442367706		[learning rate: 0.0018229]
	Learning Rate: 0.00182293
	LOSS [training: 0.0072125760442367706 | validation: 0.005935474729794902]
	TIME [epoch: 7.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008322616485478197		[learning rate: 0.0018186]
	Learning Rate: 0.00181863
	LOSS [training: 0.008322616485478197 | validation: 0.008271008578296539]
	TIME [epoch: 7.85 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008022977502113426		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.008022977502113426 | validation: 0.00722107907653268]
	TIME [epoch: 7.85 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005985645408753271		[learning rate: 0.0018101]
	Learning Rate: 0.00181006
	LOSS [training: 0.005985645408753271 | validation: 0.00419057315344408]
	TIME [epoch: 7.85 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009219991586027331		[learning rate: 0.0018058]
	Learning Rate: 0.00180579
	LOSS [training: 0.009219991586027331 | validation: 0.00617381695311153]
	TIME [epoch: 7.86 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013525234572216625		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.013525234572216625 | validation: 0.0060091944995049945]
	TIME [epoch: 7.88 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00620906637546779		[learning rate: 0.0017973]
	Learning Rate: 0.00179728
	LOSS [training: 0.00620906637546779 | validation: 0.0056528031308034354]
	TIME [epoch: 7.84 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005985687906224187		[learning rate: 0.001793]
	Learning Rate: 0.00179304
	LOSS [training: 0.005985687906224187 | validation: 0.004657495275086047]
	TIME [epoch: 7.84 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005699173506956342		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.005699173506956342 | validation: 0.005791824266805259]
	TIME [epoch: 7.84 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008151639782180016		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.008151639782180016 | validation: 0.007705908840155361]
	TIME [epoch: 7.88 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006492168615845672		[learning rate: 0.0017804]
	Learning Rate: 0.00178038
	LOSS [training: 0.006492168615845672 | validation: 0.005306559454220405]
	TIME [epoch: 7.86 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005062857163387769		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.005062857163387769 | validation: 0.005120178306330894]
	TIME [epoch: 7.84 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009220282755330551		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.009220282755330551 | validation: 0.006949426070080851]
	TIME [epoch: 7.84 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007521362894530981		[learning rate: 0.0017678]
	Learning Rate: 0.00176781
	LOSS [training: 0.007521362894530981 | validation: 0.00376575955444385]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006107090552104384		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.006107090552104384 | validation: 0.008823370562610126]
	TIME [epoch: 7.89 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009170324333530194		[learning rate: 0.0017595]
	Learning Rate: 0.00175948
	LOSS [training: 0.009170324333530194 | validation: 0.004392273221791209]
	TIME [epoch: 7.85 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011011865397539424		[learning rate: 0.0017553]
	Learning Rate: 0.00175533
	LOSS [training: 0.011011865397539424 | validation: 0.01307601582119772]
	TIME [epoch: 7.85 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010445441757403057		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.010445441757403057 | validation: 0.00729203264771805]
	TIME [epoch: 7.83 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005449108795298413		[learning rate: 0.0017471]
	Learning Rate: 0.00174706
	LOSS [training: 0.005449108795298413 | validation: 0.005535926380317498]
	TIME [epoch: 7.85 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005084171524121979		[learning rate: 0.0017429]
	Learning Rate: 0.00174294
	LOSS [training: 0.005084171524121979 | validation: 0.004642446864448679]
	TIME [epoch: 7.89 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005627796886100619		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.005627796886100619 | validation: 0.0061646175943886]
	TIME [epoch: 7.85 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005647485686875244		[learning rate: 0.0017347]
	Learning Rate: 0.00173473
	LOSS [training: 0.005647485686875244 | validation: 0.005170628906061646]
	TIME [epoch: 7.84 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007253289759732002		[learning rate: 0.0017306]
	Learning Rate: 0.00173063
	LOSS [training: 0.007253289759732002 | validation: 0.007919563149797991]
	TIME [epoch: 7.84 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008257245002995853		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.008257245002995853 | validation: 0.007361080522951069]
	TIME [epoch: 7.86 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005648209882873776		[learning rate: 0.0017225]
	Learning Rate: 0.00172248
	LOSS [training: 0.005648209882873776 | validation: 0.006465632040711299]
	TIME [epoch: 7.87 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006291348422629182		[learning rate: 0.0017184]
	Learning Rate: 0.00171842
	LOSS [training: 0.006291348422629182 | validation: 0.004562151236744692]
	TIME [epoch: 7.84 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007123238225368745		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.007123238225368745 | validation: 0.004275488962995614]
	TIME [epoch: 7.84 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006458398795383331		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.006458398795383331 | validation: 0.0056295457031965215]
	TIME [epoch: 7.84 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006397105836126423		[learning rate: 0.0017063]
	Learning Rate: 0.00170628
	LOSS [training: 0.006397105836126423 | validation: 0.006828312581941635]
	TIME [epoch: 7.88 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005795498304507557		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.005795498304507557 | validation: 0.005042518152978432]
	TIME [epoch: 7.86 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004624329445151099		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.004624329445151099 | validation: 0.005716160710676259]
	TIME [epoch: 7.85 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005277888038782842		[learning rate: 0.0016942]
	Learning Rate: 0.00169424
	LOSS [training: 0.005277888038782842 | validation: 0.0033247885277655157]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005029604493010372		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.005029604493010372 | validation: 0.006456121561724417]
	TIME [epoch: 7.84 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005932366448125287		[learning rate: 0.0016863]
	Learning Rate: 0.00168625
	LOSS [training: 0.005932366448125287 | validation: 0.005401406798594556]
	TIME [epoch: 7.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007734629945562512		[learning rate: 0.0016823]
	Learning Rate: 0.00168228
	LOSS [training: 0.007734629945562512 | validation: 0.00900609041132536]
	TIME [epoch: 7.85 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007192229951455956		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.007192229951455956 | validation: 0.00513272028829587]
	TIME [epoch: 7.84 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011949945681360777		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.011949945681360777 | validation: 0.0077534184678707384]
	TIME [epoch: 7.84 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008121625513413408		[learning rate: 0.0016704]
	Learning Rate: 0.0016704
	LOSS [training: 0.008121625513413408 | validation: 0.005352653190586482]
	TIME [epoch: 7.86 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005942262961275537		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.005942262961275537 | validation: 0.004634601569431218]
	TIME [epoch: 7.88 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00446756006416925		[learning rate: 0.0016625]
	Learning Rate: 0.00166253
	LOSS [training: 0.00446756006416925 | validation: 0.0032011072976254797]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047881482824958105		[learning rate: 0.0016586]
	Learning Rate: 0.00165861
	LOSS [training: 0.0047881482824958105 | validation: 0.02034640543439809]
	TIME [epoch: 7.86 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011665893751296785		[learning rate: 0.0016547]
	Learning Rate: 0.0016547
	LOSS [training: 0.011665893751296785 | validation: 0.00448762122003221]
	TIME [epoch: 7.86 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007462376148346345		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.007462376148346345 | validation: 0.00577349058367614]
	TIME [epoch: 7.89 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004868905483650401		[learning rate: 0.0016469]
	Learning Rate: 0.0016469
	LOSS [training: 0.004868905483650401 | validation: 0.0035173406578564085]
	TIME [epoch: 7.87 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006104362722266378		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.006104362722266378 | validation: 0.00796738087224282]
	TIME [epoch: 7.85 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00967948684834011		[learning rate: 0.0016391]
	Learning Rate: 0.00163914
	LOSS [training: 0.00967948684834011 | validation: 0.0044966191438449675]
	TIME [epoch: 7.86 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004729228731047116		[learning rate: 0.0016353]
	Learning Rate: 0.00163527
	LOSS [training: 0.004729228731047116 | validation: 0.004254056950972985]
	TIME [epoch: 7.85 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01782383753895947		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.01782383753895947 | validation: 0.02033121261875888]
	TIME [epoch: 7.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011043159597939127		[learning rate: 0.0016276]
	Learning Rate: 0.00162757
	LOSS [training: 0.011043159597939127 | validation: 0.005830783459784036]
	TIME [epoch: 7.85 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005241761072992107		[learning rate: 0.0016237]
	Learning Rate: 0.00162373
	LOSS [training: 0.005241761072992107 | validation: 0.004072436969475561]
	TIME [epoch: 7.85 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00605642937802115		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.00605642937802115 | validation: 0.004288010717105427]
	TIME [epoch: 7.85 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005353813385315045		[learning rate: 0.0016161]
	Learning Rate: 0.00161608
	LOSS [training: 0.005353813385315045 | validation: 0.003824173129486084]
	TIME [epoch: 7.85 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005478959563090069		[learning rate: 0.0016123]
	Learning Rate: 0.00161226
	LOSS [training: 0.005478959563090069 | validation: 0.004937980801060055]
	TIME [epoch: 7.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005699538357235218		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.005699538357235218 | validation: 0.004879235433608065]
	TIME [epoch: 7.86 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007504241822614093		[learning rate: 0.0016047]
	Learning Rate: 0.00160467
	LOSS [training: 0.007504241822614093 | validation: 0.0035679055321152756]
	TIME [epoch: 7.85 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006318493713928771		[learning rate: 0.0016009]
	Learning Rate: 0.00160088
	LOSS [training: 0.006318493713928771 | validation: 0.004387159093623773]
	TIME [epoch: 7.85 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00535396215322364		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.00535396215322364 | validation: 0.007672631503820935]
	TIME [epoch: 7.88 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006607232441960764		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.006607232441960764 | validation: 0.003967844930009852]
	TIME [epoch: 7.86 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007600147227379225		[learning rate: 0.0015896]
	Learning Rate: 0.00158958
	LOSS [training: 0.007600147227379225 | validation: 0.005410171402270493]
	TIME [epoch: 7.85 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005636103129116303		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.005636103129116303 | validation: 0.005130908433427963]
	TIME [epoch: 7.85 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007878375166796342		[learning rate: 0.0015821]
	Learning Rate: 0.00158209
	LOSS [training: 0.007878375166796342 | validation: 0.013800268275947991]
	TIME [epoch: 7.85 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012665486104711916		[learning rate: 0.0015784]
	Learning Rate: 0.00157836
	LOSS [training: 0.012665486104711916 | validation: 0.005820521170299322]
	TIME [epoch: 7.89 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00823047911600607		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.00823047911600607 | validation: 0.0029028087299542513]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049769462027643		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.0049769462027643 | validation: 0.006261274980314074]
	TIME [epoch: 7.85 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005136046683221095		[learning rate: 0.0015672]
	Learning Rate: 0.00156721
	LOSS [training: 0.005136046683221095 | validation: 0.0046323532057941305]
	TIME [epoch: 7.85 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006455504135440294		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.006455504135440294 | validation: 0.004401901571161163]
	TIME [epoch: 7.85 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00634466592272646		[learning rate: 0.0015598]
	Learning Rate: 0.00155983
	LOSS [training: 0.00634466592272646 | validation: 0.011908380644399367]
	TIME [epoch: 7.89 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073410618069329504		[learning rate: 0.0015561]
	Learning Rate: 0.00155615
	LOSS [training: 0.0073410618069329504 | validation: 0.0057338751994635]
	TIME [epoch: 7.85 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004346617255322692		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.004346617255322692 | validation: 0.0030966380172661604]
	TIME [epoch: 7.84 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004838123514856196		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.004838123514856196 | validation: 0.005483562614031106]
	TIME [epoch: 7.85 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004957689702706492		[learning rate: 0.0015452]
	Learning Rate: 0.00154516
	LOSS [training: 0.004957689702706492 | validation: 0.0041073059982584354]
	TIME [epoch: 7.85 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055342695604251		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.0055342695604251 | validation: 0.007090756634175813]
	TIME [epoch: 7.89 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009456540264546044		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.009456540264546044 | validation: 0.0037360979627037846]
	TIME [epoch: 7.85 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004458201339985315		[learning rate: 0.0015343]
	Learning Rate: 0.00153425
	LOSS [training: 0.004458201339985315 | validation: 0.0034232951878662007]
	TIME [epoch: 7.85 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008447324065531132		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.008447324065531132 | validation: 0.006096371025289768]
	TIME [epoch: 7.85 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008908658530476374		[learning rate: 0.001527]
	Learning Rate: 0.00152703
	LOSS [training: 0.008908658530476374 | validation: 0.0037215232910376432]
	TIME [epoch: 7.88 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005938992352114123		[learning rate: 0.0015234]
	Learning Rate: 0.00152342
	LOSS [training: 0.005938992352114123 | validation: 0.004911469139056424]
	TIME [epoch: 7.87 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004452791991701335		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.004452791991701335 | validation: 0.004687220954955771]
	TIME [epoch: 7.86 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004650893913736572		[learning rate: 0.0015162]
	Learning Rate: 0.00151624
	LOSS [training: 0.004650893913736572 | validation: 0.006070359959089271]
	TIME [epoch: 7.85 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005803630109693909		[learning rate: 0.0015127]
	Learning Rate: 0.00151267
	LOSS [training: 0.005803630109693909 | validation: 0.0051808061452457916]
	TIME [epoch: 7.86 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003980362909448659		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.003980362909448659 | validation: 0.003295037161243056]
	TIME [epoch: 7.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004266269660193812		[learning rate: 0.0015055]
	Learning Rate: 0.00150554
	LOSS [training: 0.004266269660193812 | validation: 0.003613651507978735]
	TIME [epoch: 7.86 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003876157819977125		[learning rate: 0.001502]
	Learning Rate: 0.00150199
	LOSS [training: 0.003876157819977125 | validation: 0.00567828849763739]
	TIME [epoch: 7.86 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038842207876936914		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.0038842207876936914 | validation: 0.0034209059997451323]
	TIME [epoch: 7.85 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005439884753410651		[learning rate: 0.0014949]
	Learning Rate: 0.00149491
	LOSS [training: 0.005439884753410651 | validation: 0.0038920947674016522]
	TIME [epoch: 7.85 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004716013573118792		[learning rate: 0.0014914]
	Learning Rate: 0.00149139
	LOSS [training: 0.004716013573118792 | validation: 0.004094316858361234]
	TIME [epoch: 7.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01272500372198922		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.01272500372198922 | validation: 0.017112372028319167]
	TIME [epoch: 7.86 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011719862192671727		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.011719862192671727 | validation: 0.004783562592979142]
	TIME [epoch: 7.87 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035355225265183764		[learning rate: 0.0014809]
	Learning Rate: 0.00148086
	LOSS [training: 0.0035355225265183764 | validation: 0.0037518985763283245]
	TIME [epoch: 7.85 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043051250859307815		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.0043051250859307815 | validation: 0.0038054375215755493]
	TIME [epoch: 7.85 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025830544219971135		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.0025830544219971135 | validation: 0.002519985553843026]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006676412756815798		[learning rate: 0.0014704]
	Learning Rate: 0.0014704
	LOSS [training: 0.006676412756815798 | validation: 0.0036889268100423664]
	TIME [epoch: 7.86 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034747042860812493		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.0034747042860812493 | validation: 0.004817875662802153]
	TIME [epoch: 7.84 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00816528813405915		[learning rate: 0.0014635]
	Learning Rate: 0.00146347
	LOSS [training: 0.00816528813405915 | validation: 0.004098864811559586]
	TIME [epoch: 7.85 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003980670922341592		[learning rate: 0.00146]
	Learning Rate: 0.00146002
	LOSS [training: 0.003980670922341592 | validation: 0.0035626919260156632]
	TIME [epoch: 7.89 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004580063040179685		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.004580063040179685 | validation: 0.003357273450589804]
	TIME [epoch: 7.87 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002426925068132566		[learning rate: 0.0014531]
	Learning Rate: 0.00145314
	LOSS [training: 0.002426925068132566 | validation: 0.003962784636132549]
	TIME [epoch: 7.85 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003821179703267315		[learning rate: 0.0014497]
	Learning Rate: 0.00144971
	LOSS [training: 0.003821179703267315 | validation: 0.002929631469884596]
	TIME [epoch: 7.85 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038470404111127744		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.0038470404111127744 | validation: 0.002807678688283413]
	TIME [epoch: 7.85 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003625661289476721		[learning rate: 0.0014429]
	Learning Rate: 0.00144288
	LOSS [training: 0.003625661289476721 | validation: 0.002891294543922996]
	TIME [epoch: 7.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026923249685679163		[learning rate: 0.0014395]
	Learning Rate: 0.00143948
	LOSS [training: 0.0026923249685679163 | validation: 0.0021343719550700785]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003704602085266312		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.003704602085266312 | validation: 0.0031872095886132028]
	TIME [epoch: 7.85 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026275877436376482		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.0026275877436376482 | validation: 0.003185950488938688]
	TIME [epoch: 7.85 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036375431232024765		[learning rate: 0.0014293]
	Learning Rate: 0.00142932
	LOSS [training: 0.0036375431232024765 | validation: 0.0042389320197962245]
	TIME [epoch: 7.86 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004098517919804143		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.004098517919804143 | validation: 0.002567334577599842]
	TIME [epoch: 7.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00737628241637662		[learning rate: 0.0014226]
	Learning Rate: 0.00142258
	LOSS [training: 0.00737628241637662 | validation: 0.006471415034213916]
	TIME [epoch: 7.85 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004050530072392507		[learning rate: 0.0014192]
	Learning Rate: 0.00141923
	LOSS [training: 0.004050530072392507 | validation: 0.0033936351739092003]
	TIME [epoch: 7.85 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002327169035881448		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.002327169035881448 | validation: 0.002867113466226239]
	TIME [epoch: 7.85 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005561804688069775		[learning rate: 0.0014125]
	Learning Rate: 0.00141254
	LOSS [training: 0.005561804688069775 | validation: 0.003246733397542104]
	TIME [epoch: 7.88 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034673268188396664		[learning rate: 0.0014092]
	Learning Rate: 0.00140921
	LOSS [training: 0.0034673268188396664 | validation: 0.0017328285062516964]
	TIME [epoch: 7.87 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_880.pth
	Model improved!!!
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023248331625084235		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.0023248331625084235 | validation: 0.0017478856417181576]
	TIME [epoch: 7.86 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029696938682039972		[learning rate: 0.0014026]
	Learning Rate: 0.00140257
	LOSS [training: 0.0029696938682039972 | validation: 0.001535642561463868]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002099318280969827		[learning rate: 0.0013993]
	Learning Rate: 0.00139926
	LOSS [training: 0.002099318280969827 | validation: 0.003733403643293119]
	TIME [epoch: 7.85 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00338141365366577		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.00338141365366577 | validation: 0.007610874907578499]
	TIME [epoch: 7.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024304529231307888		[learning rate: 0.0013927]
	Learning Rate: 0.00139266
	LOSS [training: 0.024304529231307888 | validation: 0.019531879916823577]
	TIME [epoch: 7.85 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011014798499424518		[learning rate: 0.0013894]
	Learning Rate: 0.00138938
	LOSS [training: 0.011014798499424518 | validation: 0.004813555816348029]
	TIME [epoch: 7.85 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002610468502634921		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.002610468502634921 | validation: 0.0015752493717719291]
	TIME [epoch: 7.85 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027018511127533335		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.0027018511127533335 | validation: 0.0022198453748631464]
	TIME [epoch: 7.85 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029304216762685823		[learning rate: 0.0013796]
	Learning Rate: 0.00137957
	LOSS [training: 0.0029304216762685823 | validation: 0.005690981516409522]
	TIME [epoch: 7.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004073251095005668		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.004073251095005668 | validation: 0.0012868651589531188]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_890.pth
	Model improved!!!
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002210237621989942		[learning rate: 0.0013731]
	Learning Rate: 0.00137307
	LOSS [training: 0.002210237621989942 | validation: 0.0023589586087924552]
	TIME [epoch: 7.85 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022676612160285135		[learning rate: 0.0013698]
	Learning Rate: 0.00136983
	LOSS [training: 0.0022676612160285135 | validation: 0.0019152854567972381]
	TIME [epoch: 7.85 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030412910774980824		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.0030412910774980824 | validation: 0.006911987654177725]
	TIME [epoch: 7.88 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003100272914079318		[learning rate: 0.0013634]
	Learning Rate: 0.00136338
	LOSS [training: 0.003100272914079318 | validation: 0.0014077636416983084]
	TIME [epoch: 7.87 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019504060336660708		[learning rate: 0.0013602]
	Learning Rate: 0.00136016
	LOSS [training: 0.0019504060336660708 | validation: 0.0029385593620450314]
	TIME [epoch: 7.85 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018045862741321154		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.0018045862741321154 | validation: 0.0028148749515925203]
	TIME [epoch: 7.84 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005764407086432409		[learning rate: 0.0013538]
	Learning Rate: 0.00135375
	LOSS [training: 0.005764407086432409 | validation: 0.006580342905345056]
	TIME [epoch: 7.84 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047494894464916865		[learning rate: 0.0013506]
	Learning Rate: 0.00135056
	LOSS [training: 0.0047494894464916865 | validation: 0.005072377981254398]
	TIME [epoch: 7.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027683829858384675		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.0027683829858384675 | validation: 0.0027820470006220113]
	TIME [epoch: 7.85 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028566311434503836		[learning rate: 0.0013442]
	Learning Rate: 0.00134419
	LOSS [training: 0.0028566311434503836 | validation: 0.0019058856915058148]
	TIME [epoch: 7.85 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001752358106204863		[learning rate: 0.001341]
	Learning Rate: 0.00134102
	LOSS [training: 0.001752358106204863 | validation: 0.0016191227291152566]
	TIME [epoch: 7.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015856758945277018		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.0015856758945277018 | validation: 0.002699654332849624]
	TIME [epoch: 7.86 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017088646175893783		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.0017088646175893783 | validation: 0.00172880656873201]
	TIME [epoch: 7.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016172264627795216		[learning rate: 0.0013316]
	Learning Rate: 0.00133155
	LOSS [training: 0.0016172264627795216 | validation: 0.002644786855653696]
	TIME [epoch: 7.86 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003516187155103632		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.003516187155103632 | validation: 0.0023464209746312473]
	TIME [epoch: 7.86 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027626228000317016		[learning rate: 0.0013253]
	Learning Rate: 0.00132528
	LOSS [training: 0.0027626228000317016 | validation: 0.0016518807188379463]
	TIME [epoch: 7.86 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013319150351185232		[learning rate: 0.0013222]
	Learning Rate: 0.00132215
	LOSS [training: 0.0013319150351185232 | validation: 0.0018736265087775888]
	TIME [epoch: 7.88 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013619858673673006		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.0013619858673673006 | validation: 0.00896733476039923]
	TIME [epoch: 7.89 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005264850575417084		[learning rate: 0.0013159]
	Learning Rate: 0.00131592
	LOSS [training: 0.005264850575417084 | validation: 0.0026451754712582673]
	TIME [epoch: 7.86 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023340855938078233		[learning rate: 0.0013128]
	Learning Rate: 0.00131282
	LOSS [training: 0.0023340855938078233 | validation: 0.0015193595050669764]
	TIME [epoch: 7.86 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013666340266264324		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.0013666340266264324 | validation: 0.002449661568630465]
	TIME [epoch: 7.86 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023182345793041756		[learning rate: 0.0013066]
	Learning Rate: 0.00130663
	LOSS [training: 0.0023182345793041756 | validation: 0.0023134074228136027]
	TIME [epoch: 7.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017967246925434588		[learning rate: 0.0013036]
	Learning Rate: 0.00130355
	LOSS [training: 0.0017967246925434588 | validation: 0.002242536083088309]
	TIME [epoch: 7.87 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012166631774063364		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.012166631774063364 | validation: 0.005224419836713878]
	TIME [epoch: 7.86 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027475189054876736		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.0027475189054876736 | validation: 0.0015827016459940544]
	TIME [epoch: 7.86 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012104422329628772		[learning rate: 0.0012943]
	Learning Rate: 0.00129435
	LOSS [training: 0.0012104422329628772 | validation: 0.002298399843403129]
	TIME [epoch: 7.86 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019173031784298577		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.0019173031784298577 | validation: 0.0024741188090909314]
	TIME [epoch: 7.91 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021690409929934684		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.0021690409929934684 | validation: 0.0026424120304847807]
	TIME [epoch: 7.87 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005666710413529295		[learning rate: 0.0012852]
	Learning Rate: 0.00128521
	LOSS [training: 0.0005666710413529295 | validation: 0.0028699874398651656]
	TIME [epoch: 7.86 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002516635607569896		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.002516635607569896 | validation: 0.002047067783820634]
	TIME [epoch: 7.86 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031288775856765146		[learning rate: 0.0012792]
	Learning Rate: 0.00127915
	LOSS [training: 0.0031288775856765146 | validation: 0.0014788822506170622]
	TIME [epoch: 7.87 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001152437757122399		[learning rate: 0.0012761]
	Learning Rate: 0.00127614
	LOSS [training: 0.001152437757122399 | validation: 0.0013581284008661817]
	TIME [epoch: 7.91 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023111838253220014		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.0023111838253220014 | validation: 0.00275426280352214]
	TIME [epoch: 7.86 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002265196939330119		[learning rate: 0.0012701]
	Learning Rate: 0.00127012
	LOSS [training: 0.002265196939330119 | validation: 0.0008959468166533378]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_924.pth
	Model improved!!!
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001419300606980861		[learning rate: 0.0012671]
	Learning Rate: 0.00126713
	LOSS [training: 0.001419300606980861 | validation: 0.0009558376266624618]
	TIME [epoch: 7.85 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017037710537434868		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.0017037710537434868 | validation: 0.0005209664994824039]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001672050423292775		[learning rate: 0.0012612]
	Learning Rate: 0.00126116
	LOSS [training: 0.001672050423292775 | validation: 0.001909090848318237]
	TIME [epoch: 7.86 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023087409154712276		[learning rate: 0.0012582]
	Learning Rate: 0.00125818
	LOSS [training: 0.0023087409154712276 | validation: 0.0009531880664263125]
	TIME [epoch: 7.84 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018934297202681187		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.0018934297202681187 | validation: 0.001264294845876127]
	TIME [epoch: 7.85 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001943376251481646		[learning rate: 0.0012523]
	Learning Rate: 0.00125225
	LOSS [training: 0.001943376251481646 | validation: 0.001202025309262358]
	TIME [epoch: 7.84 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020578160342396147		[learning rate: 0.0012493]
	Learning Rate: 0.0012493
	LOSS [training: 0.0020578160342396147 | validation: 0.002028084932528888]
	TIME [epoch: 7.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011822760264580611		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.0011822760264580611 | validation: 0.0008224460704598182]
	TIME [epoch: 7.85 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027496451142986164		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.0027496451142986164 | validation: -6.39015210222915e-05]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_933.pth
	Model improved!!!
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011604960138465593		[learning rate: 0.0012405]
	Learning Rate: 0.00124048
	LOSS [training: 0.0011604960138465593 | validation: 0.0022820236569354004]
	TIME [epoch: 7.85 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008822394180292885		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.0008822394180292885 | validation: 0.0009183720334419388]
	TIME [epoch: 7.85 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010161803106431277		[learning rate: 0.0012346]
	Learning Rate: 0.00123463
	LOSS [training: 0.0010161803106431277 | validation: 0.011076181890919187]
	TIME [epoch: 7.89 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006231612068703371		[learning rate: 0.0012317]
	Learning Rate: 0.00123172
	LOSS [training: 0.006231612068703371 | validation: 0.0023962726390649707]
	TIME [epoch: 7.85 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026302187349625497		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.0026302187349625497 | validation: 0.0016617474911289332]
	TIME [epoch: 7.84 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010507266046613875		[learning rate: 0.0012259]
	Learning Rate: 0.00122592
	LOSS [training: 0.0010507266046613875 | validation: 0.01846913968491283]
	TIME [epoch: 7.85 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010150298449988097		[learning rate: 0.001223]
	Learning Rate: 0.00122303
	LOSS [training: 0.010150298449988097 | validation: 0.001823418945097515]
	TIME [epoch: 7.87 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031043908274417504		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.0031043908274417504 | validation: 0.001982249701527008]
	TIME [epoch: 7.86 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003528640751470607		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.003528640751470607 | validation: 0.002884989410301854]
	TIME [epoch: 7.84 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024749675521210743		[learning rate: 0.0012144]
	Learning Rate: 0.00121439
	LOSS [training: 0.0024749675521210743 | validation: 0.0015910405543599088]
	TIME [epoch: 7.84 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011282687077542137		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.0011282687077542137 | validation: 0.0012405182033795668]
	TIME [epoch: 7.85 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007130121899229923		[learning rate: 0.0012087]
	Learning Rate: 0.00120867
	LOSS [training: 0.0007130121899229923 | validation: 6.239904130591917e-05]
	TIME [epoch: 7.88 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041577474732135155		[learning rate: 0.0012058]
	Learning Rate: 0.00120582
	LOSS [training: 0.00041577474732135155 | validation: 0.0028443008158718763]
	TIME [epoch: 7.85 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002614662344107509		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.002614662344107509 | validation: 0.0029777001939672526]
	TIME [epoch: 7.84 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011345138062587214		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.0011345138062587214 | validation: 0.001087674690984326]
	TIME [epoch: 7.84 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000991113366433404		[learning rate: 0.0011973]
	Learning Rate: 0.00119731
	LOSS [training: 0.000991113366433404 | validation: 0.0014279728784677452]
	TIME [epoch: 7.83 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009138272346360717		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.0009138272346360717 | validation: 0.00025973628076499724]
	TIME [epoch: 7.88 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00205354064729142		[learning rate: 0.0011917]
	Learning Rate: 0.00119166
	LOSS [training: 0.00205354064729142 | validation: 0.0006321096021198334]
	TIME [epoch: 7.84 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018113027577899387		[learning rate: 0.0011889]
	Learning Rate: 0.00118885
	LOSS [training: 0.0018113027577899387 | validation: 0.0012205823633696438]
	TIME [epoch: 7.84 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018786874361961543		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.0018786874361961543 | validation: 0.0008786866505150263]
	TIME [epoch: 7.84 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009612591729613824		[learning rate: 0.0011833]
	Learning Rate: 0.00118325
	LOSS [training: 0.0009612591729613824 | validation: 0.001336774710944832]
	TIME [epoch: 7.84 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002398211437480232		[learning rate: 0.0011805]
	Learning Rate: 0.00118046
	LOSS [training: 0.002398211437480232 | validation: 0.0010776199491926756]
	TIME [epoch: 7.89 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013391792616747366		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.0013391792616747366 | validation: 0.00411462735571556]
	TIME [epoch: 7.83 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001957600899127838		[learning rate: 0.0011749]
	Learning Rate: 0.0011749
	LOSS [training: 0.001957600899127838 | validation: 0.0021205199655680257]
	TIME [epoch: 7.83 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016479054286636908		[learning rate: 0.0011721]
	Learning Rate: 0.00117213
	LOSS [training: 0.0016479054286636908 | validation: 0.0015695778886332707]
	TIME [epoch: 7.83 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024375466001576953		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.0024375466001576953 | validation: 0.0018790085390795453]
	TIME [epoch: 7.87 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011065516658192891		[learning rate: 0.0011666]
	Learning Rate: 0.0011666
	LOSS [training: 0.0011065516658192891 | validation: 0.0005752099232860655]
	TIME [epoch: 7.86 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004538373562156629		[learning rate: 0.0011639]
	Learning Rate: 0.00116385
	LOSS [training: 0.004538373562156629 | validation: 0.0020699004424019904]
	TIME [epoch: 7.83 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002850565599301654		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.002850565599301654 | validation: 0.0027765229330291154]
	TIME [epoch: 7.83 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021644749628691763		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.0021644749628691763 | validation: 0.003262914293615055]
	TIME [epoch: 7.84 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002860268599733649		[learning rate: 0.0011556]
	Learning Rate: 0.00115563
	LOSS [training: 0.002860268599733649 | validation: 0.0012145266297397604]
	TIME [epoch: 7.88 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007654978667220472		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.0007654978667220472 | validation: 0.0010032637864957098]
	TIME [epoch: 7.85 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002899668670049124		[learning rate: 0.0011502]
	Learning Rate: 0.00115019
	LOSS [training: 0.002899668670049124 | validation: 0.001548716418959413]
	TIME [epoch: 7.84 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008164811713239124		[learning rate: 0.0011475]
	Learning Rate: 0.00114748
	LOSS [training: 0.0008164811713239124 | validation: 0.0015258881057139306]
	TIME [epoch: 7.84 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006988044656697552		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.0006988044656697552 | validation: 0.0014211549913956034]
	TIME [epoch: 7.84 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001330447955715793		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.001330447955715793 | validation: 0.0036698274201858016]
	TIME [epoch: 7.88 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016064996523117675		[learning rate: 0.0011394]
	Learning Rate: 0.00113937
	LOSS [training: 0.0016064996523117675 | validation: 0.0007390689537162487]
	TIME [epoch: 7.85 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021347418760100448		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.0021347418760100448 | validation: 0.002575362934845003]
	TIME [epoch: 7.84 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014098624275464902		[learning rate: 0.001134]
	Learning Rate: 0.00113401
	LOSS [training: 0.0014098624275464902 | validation: 0.001124328108254025]
	TIME [epoch: 7.85 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009240159380315543		[learning rate: 0.0011313]
	Learning Rate: 0.00113133
	LOSS [training: 0.0009240159380315543 | validation: 0.0002766999152900116]
	TIME [epoch: 7.84 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001833439673807692		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.001833439673807692 | validation: 0.0006436355978766577]
	TIME [epoch: 7.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004225816991847762		[learning rate: 0.001126]
	Learning Rate: 0.001126
	LOSS [training: 0.0004225816991847762 | validation: 0.0015192781808294367]
	TIME [epoch: 7.86 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005647066280535596		[learning rate: 0.0011233]
	Learning Rate: 0.00112334
	LOSS [training: 0.005647066280535596 | validation: 0.0008110732889482809]
	TIME [epoch: 7.84 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007742116624052423		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.0007742116624052423 | validation: 0.0004384721020974109]
	TIME [epoch: 7.84 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000284649955100396		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.000284649955100396 | validation: -3.3751363272962055e-05]
	TIME [epoch: 7.87 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012019926333447098		[learning rate: 0.0011154]
	Learning Rate: 0.00111541
	LOSS [training: 0.0012019926333447098 | validation: 0.002322399094414548]
	TIME [epoch: 7.86 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015755118654526955		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.0015755118654526955 | validation: 0.0006628009246354209]
	TIME [epoch: 7.84 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001006492670946552		[learning rate: 0.0011102]
	Learning Rate: 0.00111016
	LOSS [training: 0.001006492670946552 | validation: 0.0011176081430547989]
	TIME [epoch: 7.85 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016429744668729168		[learning rate: 0.0011075]
	Learning Rate: 0.00110754
	LOSS [training: 0.0016429744668729168 | validation: 0.0007517759642242296]
	TIME [epoch: 7.85 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009466259258069473		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.0009466259258069473 | validation: 0.0007470022583739149]
	TIME [epoch: 7.89 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026704495549961984		[learning rate: 0.0011023]
	Learning Rate: 0.00110232
	LOSS [training: 0.0026704495549961984 | validation: 0.0036465565847284788]
	TIME [epoch: 7.86 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002757549326191397		[learning rate: 0.0010997]
	Learning Rate: 0.00109972
	LOSS [training: 0.002757549326191397 | validation: 0.0002694046576651825]
	TIME [epoch: 7.84 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00045344571646239865		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.00045344571646239865 | validation: 0.00174483015625421]
	TIME [epoch: 7.85 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014356439005032504		[learning rate: 0.0010945]
	Learning Rate: 0.00109454
	LOSS [training: 0.0014356439005032504 | validation: 0.0004960197830245825]
	TIME [epoch: 7.84 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007062314969539644		[learning rate: 0.001092]
	Learning Rate: 0.00109196
	LOSS [training: 0.0007062314969539644 | validation: 0.0014342263072347609]
	TIME [epoch: 7.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007760403397231257		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.0007760403397231257 | validation: 0.0015033347728585483]
	TIME [epoch: 7.85 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048362051583099254		[learning rate: 0.0010868]
	Learning Rate: 0.00108681
	LOSS [training: 0.00048362051583099254 | validation: 0.00048226797974623904]
	TIME [epoch: 7.85 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004697346211453811		[learning rate: 0.0010842]
	Learning Rate: 0.00108425
	LOSS [training: 0.004697346211453811 | validation: 0.008699003093398869]
	TIME [epoch: 7.85 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005450131250005237		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.005450131250005237 | validation: 0.0006333360942046729]
	TIME [epoch: 7.85 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011069485628800585		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.0011069485628800585 | validation: 0.00016405005221150091]
	TIME [epoch: 7.89 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004131116028397706		[learning rate: 0.0010766]
	Learning Rate: 0.00107659
	LOSS [training: 0.0004131116028397706 | validation: 0.000369103664789685]
	TIME [epoch: 7.85 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007808202283642546		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.0007808202283642546 | validation: 0.0005446875577160273]
	TIME [epoch: 7.84 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004310852780790781		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.0004310852780790781 | validation: 0.00015073868771527674]
	TIME [epoch: 7.84 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010603731620923498		[learning rate: 0.001069]
	Learning Rate: 0.00106899
	LOSS [training: 0.0010603731620923498 | validation: 0.0013593867318860593]
	TIME [epoch: 7.87 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000589827213328793		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.000589827213328793 | validation: 0.0006777888496223841]
	TIME [epoch: 7.86 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004899793488592377		[learning rate: 0.001064]
	Learning Rate: 0.00106395
	LOSS [training: 0.0004899793488592377 | validation: 0.0015313256469978562]
	TIME [epoch: 7.84 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026487312258119395		[learning rate: 0.0010614]
	Learning Rate: 0.00106144
	LOSS [training: 0.0026487312258119395 | validation: 5.006718422810908e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013221647433325101		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.0013221647433325101 | validation: 0.00567184175839773]
	TIME [epoch: 7.85 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003920718692812231		[learning rate: 0.0010564]
	Learning Rate: 0.00105644
	LOSS [training: 0.003920718692812231 | validation: 0.005037989223047275]
	TIME [epoch: 7.89 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022050265313371727		[learning rate: 0.001054]
	Learning Rate: 0.00105395
	LOSS [training: 0.0022050265313371727 | validation: 0.0016769237644722503]
	TIME [epoch: 7.86 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014902939755935622		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.00014902939755935622 | validation: 0.001087944405132013]
	TIME [epoch: 7.84 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.61831350108879e-05		[learning rate: 0.001049]
	Learning Rate: 0.00104898
	LOSS [training: 7.61831350108879e-05 | validation: 0.001106918699055325]
	TIME [epoch: 7.84 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003588951927135813		[learning rate: 0.0010465]
	Learning Rate: 0.00104651
	LOSS [training: 0.0003588951927135813 | validation: 0.0009464551920082456]
	TIME [epoch: 7.84 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006531806974935038		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.0006531806974935038 | validation: 0.001000339235414268]
	TIME [epoch: 7.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00323388774966912		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.00323388774966912 | validation: 0.005999245398511025]
	TIME [epoch: 7.85 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003613757291238956		[learning rate: 0.0010391]
	Learning Rate: 0.00103912
	LOSS [training: 0.003613757291238956 | validation: 0.0006060285593635052]
	TIME [epoch: 7.85 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007964634417855082		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.0007964634417855082 | validation: 0.0009325197500407537]
	TIME [epoch: 7.84 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000626531418987952		[learning rate: 0.0010342]
	Learning Rate: 0.00103423
	LOSS [training: 0.000626531418987952 | validation: 0.0003483127832341388]
	TIME [epoch: 7.84 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002058680657936165		[learning rate: 0.0010318]
	Learning Rate: 0.00103179
	LOSS [training: 0.0002058680657936165 | validation: 0.0003229674221034724]
	TIME [epoch: 7.89 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016628624482972645		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.00016628624482972645 | validation: 0.00015597090352673386]
	TIME [epoch: 7.85 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003753603667893122		[learning rate: 0.0010269]
	Learning Rate: 0.00102692
	LOSS [training: 0.0003753603667893122 | validation: 0.001780987163557854]
	TIME [epoch: 7.85 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017081466930858356		[learning rate: 0.0010245]
	Learning Rate: 0.0010245
	LOSS [training: 0.017081466930858356 | validation: 0.007985823552354604]
	TIME [epoch: 7.85 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042835623777767035		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.0042835623777767035 | validation: 0.0009638307587262256]
	TIME [epoch: 7.88 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005825766577873274		[learning rate: 0.0010197]
	Learning Rate: 0.00101967
	LOSS [training: 0.0005825766577873274 | validation: 0.0003756277751322057]
	TIME [epoch: 7.87 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015267757754589082		[learning rate: 0.0010173]
	Learning Rate: 0.00101727
	LOSS [training: 0.00015267757754589082 | validation: 0.00015726118537251832]
	TIME [epoch: 7.84 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006309278191438323		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.0006309278191438323 | validation: 0.002621556947705444]
	TIME [epoch: 7.85 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007474753928970463		[learning rate: 0.0010125]
	Learning Rate: 0.00101248
	LOSS [training: 0.0007474753928970463 | validation: 0.0008175492564600336]
	TIME [epoch: 7.85 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004671169164508095		[learning rate: 0.0010101]
	Learning Rate: 0.00101009
	LOSS [training: 0.0004671169164508095 | validation: 0.00036964878333526306]
	TIME [epoch: 7.89 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.411317716241327e-05		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: -5.411317716241327e-05 | validation: 0.0008723072575769049]
	TIME [epoch: 7.86 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013998265861329072		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.0013998265861329072 | validation: 0.00025021057808500034]
	TIME [epoch: 7.85 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011214314942212989		[learning rate: 0.001003]
	Learning Rate: 0.00100296
	LOSS [training: 0.0011214314942212989 | validation: 0.00043965050072559687]
	TIME [epoch: 7.85 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008871063720692851		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.0008871063720692851 | validation: 0.001218780384990049]
	TIME [epoch: 7.85 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035232897203725045		[learning rate: 0.00099823]
	Learning Rate: 0.000998231
	LOSS [training: 0.00035232897203725045 | validation: 0.0006289864441955459]
	TIME [epoch: 7.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020100735290310527		[learning rate: 0.00099588]
	Learning Rate: 0.000995876
	LOSS [training: 0.0020100735290310527 | validation: -0.00013019092494805573]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1027.pth
	Model improved!!!
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010528220001312211		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.0010528220001312211 | validation: 0.0013945975856100414]
	TIME [epoch: 7.85 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006089200364258709		[learning rate: 0.00099118]
	Learning Rate: 0.000991183
	LOSS [training: 0.0006089200364258709 | validation: 0.0016161957553882669]
	TIME [epoch: 7.85 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038871968930059977		[learning rate: 0.00098885]
	Learning Rate: 0.000988845
	LOSS [training: 0.00038871968930059977 | validation: 0.000929952411237379]
	TIME [epoch: 7.87 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00045458215028827925		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.00045458215028827925 | validation: 0.0010764417532706987]
	TIME [epoch: 7.88 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014588451588614343		[learning rate: 0.00098419]
	Learning Rate: 0.000984185
	LOSS [training: 0.0014588451588614343 | validation: 0.002007411903328946]
	TIME [epoch: 7.85 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026183222806224		[learning rate: 0.00098186]
	Learning Rate: 0.000981864
	LOSS [training: 0.0026183222806224 | validation: 0.004198667473114962]
	TIME [epoch: 7.85 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002052624535677631		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.002052624535677631 | validation: 0.0004294512629165537]
	TIME [epoch: 7.88 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012875072708435815		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.0012875072708435815 | validation: 0.001468241211042436]
	TIME [epoch: 7.88 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004752112905858701		[learning rate: 0.00097493]
	Learning Rate: 0.000974932
	LOSS [training: 0.0004752112905858701 | validation: 0.001161399599169311]
	TIME [epoch: 7.87 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006133361467505188		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.0006133361467505188 | validation: 0.0019744785255530117]
	TIME [epoch: 7.85 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005518163575141912		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.005518163575141912 | validation: 0.0004637837420442663]
	TIME [epoch: 7.85 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005026881197851118		[learning rate: 0.00096805]
	Learning Rate: 0.000968049
	LOSS [training: 0.0005026881197851118 | validation: 0.000721631384069934]
	TIME [epoch: 7.85 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005061869570945123		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.0005061869570945123 | validation: 0.003145118323388328]
	TIME [epoch: 7.89 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002443351071218237		[learning rate: 0.00096349]
	Learning Rate: 0.000963488
	LOSS [training: 0.002443351071218237 | validation: 0.004298143759033503]
	TIME [epoch: 7.85 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016529508614487164		[learning rate: 0.00096121]
	Learning Rate: 0.000961215
	LOSS [training: 0.0016529508614487164 | validation: 0.0010106785105074567]
	TIME [epoch: 7.85 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011377045903748485		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: -0.00011377045903748485 | validation: 0.00017268650972265178]
	TIME [epoch: 7.85 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000391740961213303		[learning rate: 0.00095669]
	Learning Rate: 0.000956686
	LOSS [training: 0.000391740961213303 | validation: 0.000557554917985688]
	TIME [epoch: 7.84 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008966435038645743		[learning rate: 0.00095443]
	Learning Rate: 0.000954429
	LOSS [training: 0.008966435038645743 | validation: 0.012978768665834283]
	TIME [epoch: 7.89 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006396175001913835		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.006396175001913835 | validation: 0.0001225101543833835]
	TIME [epoch: 7.84 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.142821146952864e-06		[learning rate: 0.00094993]
	Learning Rate: 0.000949932
	LOSS [training: 7.142821146952864e-06 | validation: 0.00024568258628890186]
	TIME [epoch: 7.83 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002393524397567087		[learning rate: 0.00094769]
	Learning Rate: 0.000947691
	LOSS [training: 0.002393524397567087 | validation: 0.0013721437377982558]
	TIME [epoch: 7.84 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005290714763306262		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.0005290714763306262 | validation: 0.0013043529141790926]
	TIME [epoch: 7.86 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012035407007385689		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.0012035407007385689 | validation: 0.0002689659273346359]
	TIME [epoch: 7.87 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.514663524585519e-05		[learning rate: 0.000941]
	Learning Rate: 0.000941
	LOSS [training: 6.514663524585519e-05 | validation: 0.0005947613204588284]
	TIME [epoch: 7.87 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016390515819470165		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.0016390515819470165 | validation: 0.0030986956427282893]
	TIME [epoch: 7.84 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014283471442268292		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.0014283471442268292 | validation: 0.0016081006881777612]
	TIME [epoch: 7.84 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005449907987406713		[learning rate: 0.00093436]
	Learning Rate: 0.000934357
	LOSS [training: 0.0005449907987406713 | validation: 0.00023302841572865862]
	TIME [epoch: 7.88 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027187453461493806		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: -0.00027187453461493806 | validation: 0.0007997996866479449]
	TIME [epoch: 7.86 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044700216151996223		[learning rate: 0.00092995]
	Learning Rate: 0.000929954
	LOSS [training: 0.00044700216151996223 | validation: 0.0008164819067151296]
	TIME [epoch: 7.84 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059263411907792985		[learning rate: 0.00092776]
	Learning Rate: 0.000927761
	LOSS [training: 0.0059263411907792985 | validation: 0.007064394155785875]
	TIME [epoch: 7.84 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003982685289503659		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.003982685289503659 | validation: 0.0020407424285456503]
	TIME [epoch: 7.84 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007437208807139442		[learning rate: 0.00092339]
	Learning Rate: 0.000923389
	LOSS [training: 0.0007437208807139442 | validation: 9.911826355258404e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.108994987914753e-05		[learning rate: 0.00092121]
	Learning Rate: 0.000921211
	LOSS [training: 8.108994987914753e-05 | validation: -0.0005151522422773405]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1060.pth
	Model improved!!!
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.6233471424603085e-05		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: -1.6233471424603085e-05 | validation: -0.0003397490090443421]
	TIME [epoch: 7.85 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028426408525858275		[learning rate: 0.00091687]
	Learning Rate: 0.00091687
	LOSS [training: 0.00028426408525858275 | validation: -0.0003176036850524495]
	TIME [epoch: 7.86 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006119352239118128		[learning rate: 0.00091471]
	Learning Rate: 0.000914707
	LOSS [training: 0.0006119352239118128 | validation: 0.00025901749121518816]
	TIME [epoch: 7.86 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00024079745052293401		[learning rate: 0.00091255]
	Learning Rate: 0.00091255
	LOSS [training: -0.00024079745052293401 | validation: 0.0002961313105410599]
	TIME [epoch: 7.91 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001484131867792511		[learning rate: 0.0009104]
	Learning Rate: 0.000910397
	LOSS [training: -0.0001484131867792511 | validation: 0.00035158542222925467]
	TIME [epoch: 7.86 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017314507652024314		[learning rate: 0.00090825]
	Learning Rate: 0.00090825
	LOSS [training: 0.00017314507652024314 | validation: 0.0003326316616424894]
	TIME [epoch: 7.86 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010989216684473475		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.0010989216684473475 | validation: 0.0005951348543412611]
	TIME [epoch: 7.87 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020327669082612478		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: -0.00020327669082612478 | validation: -0.00021025493344837323]
	TIME [epoch: 7.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006601544813065609		[learning rate: 0.00090184]
	Learning Rate: 0.000901837
	LOSS [training: 0.0006601544813065609 | validation: 0.0005210191085432481]
	TIME [epoch: 7.88 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012538549164264869		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.012538549164264869 | validation: 0.004041814025676747]
	TIME [epoch: 7.87 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033457041573119878		[learning rate: 0.00089759]
	Learning Rate: 0.000897588
	LOSS [training: 0.0033457041573119878 | validation: 0.0002391606260156829]
	TIME [epoch: 7.87 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.929595389373765e-05		[learning rate: 0.00089547]
	Learning Rate: 0.00089547
	LOSS [training: 4.929595389373765e-05 | validation: 0.0008636340732825207]
	TIME [epoch: 7.87 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000601382262039278		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.000601382262039278 | validation: 0.0015934865373209374]
	TIME [epoch: 7.91 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022851631673553508		[learning rate: 0.00089125]
	Learning Rate: 0.000891251
	LOSS [training: -0.00022851631673553508 | validation: 0.0004432992205752853]
	TIME [epoch: 7.88 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020694429920843963		[learning rate: 0.00088915]
	Learning Rate: 0.000889149
	LOSS [training: 0.00020694429920843963 | validation: 0.00031186425558611046]
	TIME [epoch: 7.87 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005213909077906112		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.0005213909077906112 | validation: -2.8124289520084858e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00013869029578025095		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: -0.00013869029578025095 | validation: 0.005343246240027779]
	TIME [epoch: 7.86 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005830226922133246		[learning rate: 0.00088287]
	Learning Rate: 0.000882871
	LOSS [training: 0.005830226922133246 | validation: 0.003834037735369693]
	TIME [epoch: 7.92 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001077764656132546		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.001077764656132546 | validation: 0.0005849685430864873]
	TIME [epoch: 7.87 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.330520118731257e-05		[learning rate: 0.00087871]
	Learning Rate: 0.000878711
	LOSS [training: -9.330520118731257e-05 | validation: 0.0005669239843252725]
	TIME [epoch: 7.86 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010132422748341518		[learning rate: 0.00087664]
	Learning Rate: 0.000876639
	LOSS [training: 0.00010132422748341518 | validation: 0.000248500396929098]
	TIME [epoch: 7.87 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017524157981294142		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.00017524157981294142 | validation: 0.00020164437980211858]
	TIME [epoch: 7.88 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005408287889562878		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.0005408287889562878 | validation: 0.0002890737234943042]
	TIME [epoch: 7.92 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018774171961526685		[learning rate: 0.00087045]
	Learning Rate: 0.00087045
	LOSS [training: 0.00018774171961526685 | validation: 0.0005980380069830562]
	TIME [epoch: 7.86 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000312870870659419		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.000312870870659419 | validation: 0.0006717698515494539]
	TIME [epoch: 7.86 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011316607797088143		[learning rate: 0.00086635]
	Learning Rate: 0.000866348
	LOSS [training: -0.00011316607797088143 | validation: 0.0016601474770459768]
	TIME [epoch: 7.86 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027093316188831374		[learning rate: 0.0008643]
	Learning Rate: 0.000864304
	LOSS [training: 0.00027093316188831374 | validation: 0.000965938192753426]
	TIME [epoch: 7.89 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011435916097016826		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.0011435916097016826 | validation: 0.0008410753529761945]
	TIME [epoch: 7.88 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007175548873461122		[learning rate: 0.00086023]
	Learning Rate: 0.000860232
	LOSS [training: 0.0007175548873461122 | validation: 0.00010847365257190368]
	TIME [epoch: 7.86 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004316700243292784		[learning rate: 0.0008582]
	Learning Rate: 0.000858202
	LOSS [training: 0.0004316700243292784 | validation: 0.0008988316083927827]
	TIME [epoch: 7.86 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010985236920360643		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.00010985236920360643 | validation: 0.0003537116695602181]
	TIME [epoch: 7.86 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005956195240093216		[learning rate: 0.00085416]
	Learning Rate: 0.000854159
	LOSS [training: 0.0005956195240093216 | validation: 0.00012018484835755184]
	TIME [epoch: 7.91 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020434018298642704		[learning rate: 0.00085214]
	Learning Rate: 0.000852144
	LOSS [training: 0.0020434018298642704 | validation: 0.0007241443692534246]
	TIME [epoch: 7.87 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002003097451325292		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.002003097451325292 | validation: 4.516349968703944e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005549306523601938		[learning rate: 0.00084813]
	Learning Rate: 0.000848128
	LOSS [training: 0.0005549306523601938 | validation: 0.0021349383910059033]
	TIME [epoch: 7.87 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024004309778094312		[learning rate: 0.00084613]
	Learning Rate: 0.000846128
	LOSS [training: 0.00024004309778094312 | validation: -0.000261907576162522]
	TIME [epoch: 7.87 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005912785197265211		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.0005912785197265211 | validation: 0.00037592386564092094]
	TIME [epoch: 7.92 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013044711451461804		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.0013044711451461804 | validation: 0.0009866410211140484]
	TIME [epoch: 7.87 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008483732963421025		[learning rate: 0.00084015]
	Learning Rate: 0.000840154
	LOSS [training: 0.0008483732963421025 | validation: -1.1147041167334224e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028585310139995725		[learning rate: 0.00083817]
	Learning Rate: 0.000838173
	LOSS [training: 0.00028585310139995725 | validation: 0.0003525512833017768]
	TIME [epoch: 7.87 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002959371781939658		[learning rate: 0.0008362]
	Learning Rate: 0.000836195
	LOSS [training: 0.0002959371781939658 | validation: 0.00042687728977045626]
	TIME [epoch: 7.88 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012796858847643892		[learning rate: 0.00083422]
	Learning Rate: 0.000834223
	LOSS [training: -0.00012796858847643892 | validation: 0.0016018030047961478]
	TIME [epoch: 7.87 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1329874742850297e-05		[learning rate: 0.00083226]
	Learning Rate: 0.000832255
	LOSS [training: 1.1329874742850297e-05 | validation: -0.0005896960156173382]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1103.pth
	Model improved!!!
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009629802780298254		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.0009629802780298254 | validation: -0.00029578858653897023]
	TIME [epoch: 7.84 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.565095111182219e-05		[learning rate: 0.00082833]
	Learning Rate: 0.000828333
	LOSS [training: 5.565095111182219e-05 | validation: 0.000691671998615881]
	TIME [epoch: 7.84 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003771816231347056		[learning rate: 0.00082638]
	Learning Rate: 0.00082638
	LOSS [training: 0.0003771816231347056 | validation: -0.00020912749567383892]
	TIME [epoch: 7.89 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6929539738302693e-05		[learning rate: 0.00082443]
	Learning Rate: 0.00082443
	LOSS [training: 1.6929539738302693e-05 | validation: 0.0008185753092652638]
	TIME [epoch: 7.84 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.318107044124094e-05		[learning rate: 0.00082249]
	Learning Rate: 0.000822485
	LOSS [training: -2.318107044124094e-05 | validation: 0.001138623214819198]
	TIME [epoch: 7.84 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004455036051817247		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.0004455036051817247 | validation: -0.00046526262980330736]
	TIME [epoch: 7.84 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009866016614168177		[learning rate: 0.00081861]
	Learning Rate: 0.00081861
	LOSS [training: 0.0009866016614168177 | validation: -0.00018055995934299502]
	TIME [epoch: 7.84 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009996788196185383		[learning rate: 0.00081668]
	Learning Rate: 0.000816679
	LOSS [training: 0.0009996788196185383 | validation: 0.0007434421901266593]
	TIME [epoch: 7.89 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017366513611668944		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: -0.00017366513611668944 | validation: 0.001167575313498373]
	TIME [epoch: 7.85 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004918175866134053		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.0004918175866134053 | validation: 0.0003803872281585954]
	TIME [epoch: 7.85 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035182823970121335		[learning rate: 0.00081091]
	Learning Rate: 0.000810913
	LOSS [training: 0.00035182823970121335 | validation: 0.000774470776906051]
	TIME [epoch: 7.85 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035077477074299204		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.00035077477074299204 | validation: 0.005940286567055973]
	TIME [epoch: 7.87 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019390592267887203		[learning rate: 0.00080709]
	Learning Rate: 0.000807092
	LOSS [training: 0.0019390592267887203 | validation: 0.00017773527892185425]
	TIME [epoch: 7.89 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001941710408948405		[learning rate: 0.00080519]
	Learning Rate: 0.000805188
	LOSS [training: -0.0001941710408948405 | validation: 0.0012984894012611496]
	TIME [epoch: 7.86 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001188650559752771		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: -0.0001188650559752771 | validation: 0.0011186916319189649]
	TIME [epoch: 7.85 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00052367028794523		[learning rate: 0.00080139]
	Learning Rate: 0.000801394
	LOSS [training: 0.00052367028794523 | validation: 0.0006173820979182768]
	TIME [epoch: 7.85 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000312663546937584		[learning rate: 0.0007995]
	Learning Rate: 0.000799504
	LOSS [training: 0.000312663546937584 | validation: 0.0006020719845846317]
	TIME [epoch: 7.89 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019614659716348745		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.0019614659716348745 | validation: 0.0006504282311675516]
	TIME [epoch: 7.87 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038618351187607485		[learning rate: 0.00079574]
	Learning Rate: 0.000795736
	LOSS [training: 0.00038618351187607485 | validation: -0.00024095391673274017]
	TIME [epoch: 7.85 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010665210895205476		[learning rate: 0.00079386]
	Learning Rate: 0.000793859
	LOSS [training: 0.0010665210895205476 | validation: 0.0009222049562843128]
	TIME [epoch: 7.86 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.116840863922723e-05		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 7.116840863922723e-05 | validation: 0.0001942139639067784]
	TIME [epoch: 7.85 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004781891143088303		[learning rate: 0.00079012]
	Learning Rate: 0.000790119
	LOSS [training: 0.0004781891143088303 | validation: 0.0006282398294153668]
	TIME [epoch: 7.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007485786411637629		[learning rate: 0.00078826]
	Learning Rate: 0.000788255
	LOSS [training: 0.0007485786411637629 | validation: 0.00020261014524767515]
	TIME [epoch: 7.86 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019197577320849812		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.0019197577320849812 | validation: 0.0016948710591238273]
	TIME [epoch: 7.86 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021028794937766626		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.0021028794937766626 | validation: 0.0006653505396516155]
	TIME [epoch: 7.84 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027291243870674123		[learning rate: 0.00078269]
	Learning Rate: 0.00078269
	LOSS [training: -0.00027291243870674123 | validation: 0.0006454183401292367]
	TIME [epoch: 7.84 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1026022929851916e-06		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 3.1026022929851916e-06 | validation: 0.000508477465721794]
	TIME [epoch: 7.89 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.905005182284053e-05		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: -6.905005182284053e-05 | validation: 0.0008154029927464066]
	TIME [epoch: 7.84 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010736372264251455		[learning rate: 0.00077716]
	Learning Rate: 0.000777164
	LOSS [training: 0.0010736372264251455 | validation: 0.0013324094676275004]
	TIME [epoch: 7.84 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.871121146369787e-05		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: -7.871121146369787e-05 | validation: 0.0001049736576964726]
	TIME [epoch: 7.84 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001285810132953644		[learning rate: 0.0007735]
	Learning Rate: 0.000773502
	LOSS [training: 0.0001285810132953644 | validation: 0.0040309211542721305]
	TIME [epoch: 7.85 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002047674370886516		[learning rate: 0.00077168]
	Learning Rate: 0.000771678
	LOSS [training: 0.002047674370886516 | validation: 0.0005731261960539968]
	TIME [epoch: 7.88 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0142869550231065e-05		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 3.0142869550231065e-05 | validation: -7.295087012447078e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022124921108050976		[learning rate: 0.00076804]
	Learning Rate: 0.000768041
	LOSS [training: -0.00022124921108050976 | validation: 2.8456523170795395e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009366681794653622		[learning rate: 0.00076623]
	Learning Rate: 0.00076623
	LOSS [training: 0.0009366681794653622 | validation: 0.0003844459926067647]
	TIME [epoch: 7.84 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015774331009033168		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.0015774331009033168 | validation: 0.0005443949217666981]
	TIME [epoch: 7.88 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.091969901616206e-06		[learning rate: 0.00076262]
	Learning Rate: 0.000762619
	LOSS [training: -2.091969901616206e-06 | validation: 0.00136199546269733]
	TIME [epoch: 7.86 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.487960627112724e-05		[learning rate: 0.00076082]
	Learning Rate: 0.00076082
	LOSS [training: -5.487960627112724e-05 | validation: -0.0001763654330296656]
	TIME [epoch: 7.84 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008855665581923817		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.0008855665581923817 | validation: 0.0007355961791468627]
	TIME [epoch: 7.84 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012124116831333498		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.0012124116831333498 | validation: 0.0005783836997160577]
	TIME [epoch: 7.84 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000128132755885112		[learning rate: 0.00075545]
	Learning Rate: 0.000755449
	LOSS [training: 0.000128132755885112 | validation: 0.00042840830259360455]
	TIME [epoch: 7.89 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.452185423139146e-05		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 9.452185423139146e-05 | validation: -0.0003193533199856265]
	TIME [epoch: 7.84 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001979501710728615		[learning rate: 0.00075189]
	Learning Rate: 0.000751889
	LOSS [training: -0.0001979501710728615 | validation: 0.00033438642525092724]
	TIME [epoch: 7.85 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010953763255881996		[learning rate: 0.00075012]
	Learning Rate: 0.000750116
	LOSS [training: 0.00010953763255881996 | validation: 0.0002212267033681314]
	TIME [epoch: 7.84 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021138280466249477		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.0021138280466249477 | validation: 0.0022307215549397254]
	TIME [epoch: 7.85 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008795210276939946		[learning rate: 0.00074658]
	Learning Rate: 0.000746581
	LOSS [training: 0.0008795210276939946 | validation: 0.0010549069423119338]
	TIME [epoch: 7.89 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013639324010289577		[learning rate: 0.00074482]
	Learning Rate: 0.00074482
	LOSS [training: 0.00013639324010289577 | validation: 9.828598833118108e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006747056216437435		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.006747056216437435 | validation: 0.012434162204352124]
	TIME [epoch: 7.84 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008167661249263247		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.008167661249263247 | validation: 0.0003031495576825849]
	TIME [epoch: 7.84 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004125486164676011		[learning rate: 0.00073956]
	Learning Rate: 0.000739562
	LOSS [training: 0.0004125486164676011 | validation: -0.00044139444838474124]
	TIME [epoch: 7.86 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001937593607981558		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.0001937593607981558 | validation: 0.0003052245227405286]
	TIME [epoch: 7.88 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007578718335228464		[learning rate: 0.00073608]
	Learning Rate: 0.000736077
	LOSS [training: -0.0007578718335228464 | validation: 0.00014421186310673085]
	TIME [epoch: 7.85 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3005309360880718e-07		[learning rate: 0.00073434]
	Learning Rate: 0.000734341
	LOSS [training: 2.3005309360880718e-07 | validation: -0.00043383468663138697]
	TIME [epoch: 7.84 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008888601930401774		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: -0.0008888601930401774 | validation: 0.0002561918055946948]
	TIME [epoch: 7.84 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.999752268467315e-05		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 2.999752268467315e-05 | validation: 0.0022112672216467897]
	TIME [epoch: 7.88 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002621087801285492		[learning rate: 0.00072916]
	Learning Rate: 0.000729156
	LOSS [training: 0.002621087801285492 | validation: 5.5562029079232506e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020975474103601436		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: -0.00020975474103601436 | validation: -0.0007105176623741225]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1160.pth
	Model improved!!!
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002547461482603666		[learning rate: 0.00072572]
	Learning Rate: 0.00072572
	LOSS [training: 0.0002547461482603666 | validation: -0.0002988669543467664]
	TIME [epoch: 7.84 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007282715488912778		[learning rate: 0.00072401]
	Learning Rate: 0.000724008
	LOSS [training: 0.0007282715488912778 | validation: 0.0009846172832476741]
	TIME [epoch: 7.84 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00033585707365704363		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: -0.00033585707365704363 | validation: 0.0001893366070080593]
	TIME [epoch: 7.89 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021336531826810255		[learning rate: 0.0007206]
	Learning Rate: 0.000720597
	LOSS [training: -0.00021336531826810255 | validation: -0.0005812752567006508]
	TIME [epoch: 7.85 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.246463976797981e-05		[learning rate: 0.0007189]
	Learning Rate: 0.000718897
	LOSS [training: -7.246463976797981e-05 | validation: -1.7438622773700006e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00467029081233738		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.00467029081233738 | validation: 0.0010553314840037343]
	TIME [epoch: 7.85 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009496660138684711		[learning rate: 0.00071551]
	Learning Rate: 0.00071551
	LOSS [training: 0.0009496660138684711 | validation: -3.8358193413469805e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029925747087882626		[learning rate: 0.00071382]
	Learning Rate: 0.000713822
	LOSS [training: -0.00029925747087882626 | validation: 0.00033876810136513935]
	TIME [epoch: 7.89 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022838748350380756		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.00022838748350380756 | validation: 0.000305323779537368]
	TIME [epoch: 7.84 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025536593093765635		[learning rate: 0.00071046]
	Learning Rate: 0.000710458
	LOSS [training: 0.00025536593093765635 | validation: 6.640986076223679e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001330251198568211		[learning rate: 0.00070878]
	Learning Rate: 0.000708782
	LOSS [training: 0.0001330251198568211 | validation: 0.0005978863943061384]
	TIME [epoch: 7.83 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2843319061260064e-06		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 1.2843319061260064e-06 | validation: 0.000651881931718628]
	TIME [epoch: 7.86 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008837737333639871		[learning rate: 0.00070544]
	Learning Rate: 0.000705443
	LOSS [training: 0.0008837737333639871 | validation: 0.0010516988292228755]
	TIME [epoch: 7.87 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007456342585859738		[learning rate: 0.00070378]
	Learning Rate: 0.000703778
	LOSS [training: 0.0007456342585859738 | validation: 0.00026237880163070806]
	TIME [epoch: 7.84 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002648069317979958		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.0002648069317979958 | validation: 0.0004480311756270554]
	TIME [epoch: 7.84 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012264642192316022		[learning rate: 0.00070046]
	Learning Rate: 0.000700462
	LOSS [training: 0.00012264642192316022 | validation: -0.0002612889115862345]
	TIME [epoch: 7.84 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000542915516754473		[learning rate: 0.00069881]
	Learning Rate: 0.00069881
	LOSS [training: -0.000542915516754473 | validation: -0.00016635420202105376]
	TIME [epoch: 7.88 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047737071318886134		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.00047737071318886134 | validation: 0.0018368352714379396]
	TIME [epoch: 7.86 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.395177360181265e-05		[learning rate: 0.00069552]
	Learning Rate: 0.000695517
	LOSS [training: -3.395177360181265e-05 | validation: 0.0008454678367128517]
	TIME [epoch: 7.85 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.154556381743585e-05		[learning rate: 0.00069388]
	Learning Rate: 0.000693876
	LOSS [training: 7.154556381743585e-05 | validation: -0.0003759642208459288]
	TIME [epoch: 7.85 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.011678679710824e-05		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: -8.011678679710824e-05 | validation: 3.635284831017893e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.891915043108154e-05		[learning rate: 0.00069061]
	Learning Rate: 0.000690607
	LOSS [training: 5.891915043108154e-05 | validation: 0.00013357863038517117]
	TIME [epoch: 7.92 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003913508813109177		[learning rate: 0.00068898]
	Learning Rate: 0.000688978
	LOSS [training: -0.0003913508813109177 | validation: 0.0009671833970439089]
	TIME [epoch: 7.84 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7861764919644216e-05		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 2.7861764919644216e-05 | validation: 0.0010341315190241368]
	TIME [epoch: 7.84 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008919192076037292		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.0008919192076037292 | validation: 0.00031560756663742896]
	TIME [epoch: 7.84 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015116542771528916		[learning rate: 0.00068411]
	Learning Rate: 0.000684114
	LOSS [training: 0.00015116542771528916 | validation: 0.0009987272430894256]
	TIME [epoch: 7.84 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005632768162298743		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.0005632768162298743 | validation: 0.0030166927623797987]
	TIME [epoch: 7.89 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010505140219144737		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.0010505140219144737 | validation: 0.00010726638249589684]
	TIME [epoch: 7.84 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009718934395362671		[learning rate: 0.00067928]
	Learning Rate: 0.000679284
	LOSS [training: 0.0009718934395362671 | validation: 0.0036834709230378383]
	TIME [epoch: 7.84 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016697557123128523		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.0016697557123128523 | validation: 0.00019093471615308873]
	TIME [epoch: 7.84 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019370425542680558		[learning rate: 0.00067608]
	Learning Rate: 0.000676083
	LOSS [training: -0.00019370425542680558 | validation: -0.0005508686398365645]
	TIME [epoch: 7.86 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000170872236401451		[learning rate: 0.00067449]
	Learning Rate: 0.000674488
	LOSS [training: 0.000170872236401451 | validation: 0.00029372961974760914]
	TIME [epoch: 7.87 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.128072082788938e-05		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: -7.128072082788938e-05 | validation: 0.0008240677651425252]
	TIME [epoch: 7.84 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011983137844007486		[learning rate: 0.00067131]
	Learning Rate: 0.00067131
	LOSS [training: -0.00011983137844007486 | validation: -0.0002883798391209913]
	TIME [epoch: 7.85 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007090845602058967		[learning rate: 0.00066973]
	Learning Rate: 0.000669726
	LOSS [training: 0.007090845602058967 | validation: 0.0028762122489576977]
	TIME [epoch: 7.85 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012049316630564444		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.0012049316630564444 | validation: 0.0002422585771148018]
	TIME [epoch: 7.88 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025430262564775494		[learning rate: 0.00066657]
	Learning Rate: 0.000666571
	LOSS [training: -0.00025430262564775494 | validation: 0.0010090783746910343]
	TIME [epoch: 7.86 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.25818070567805e-05		[learning rate: 0.000665]
	Learning Rate: 0.000664998
	LOSS [training: 5.25818070567805e-05 | validation: 0.0002196869986772683]
	TIME [epoch: 7.84 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008210366322832805		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.0008210366322832805 | validation: 0.0005593824181477932]
	TIME [epoch: 7.84 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001534274921479284		[learning rate: 0.00066186]
	Learning Rate: 0.000661865
	LOSS [training: -0.0001534274921479284 | validation: 0.00018338081734878964]
	TIME [epoch: 7.84 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002912368830627805		[learning rate: 0.0006603]
	Learning Rate: 0.000660304
	LOSS [training: 0.0002912368830627805 | validation: 0.0015290068751848192]
	TIME [epoch: 7.89 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007745337548676614		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.0007745337548676614 | validation: -0.00021374459607111394]
	TIME [epoch: 7.85 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008702355300969494		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.0008702355300969494 | validation: 0.005494634478346666]
	TIME [epoch: 7.83 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00488232438471445		[learning rate: 0.00065564]
	Learning Rate: 0.000655642
	LOSS [training: 0.00488232438471445 | validation: 0.0009575182140468889]
	TIME [epoch: 7.84 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003773482934222172		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.0003773482934222172 | validation: 8.469223526001951e-06]
	TIME [epoch: 7.85 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000193253270885329		[learning rate: 0.00065255]
	Learning Rate: 0.000652552
	LOSS [training: 0.000193253270885329 | validation: -1.417791251761576e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0833155442362183e-05		[learning rate: 0.00065101]
	Learning Rate: 0.000651013
	LOSS [training: 2.0833155442362183e-05 | validation: 0.0006483762660480474]
	TIME [epoch: 7.85 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006619295630337734		[learning rate: 0.00064948]
	Learning Rate: 0.000649478
	LOSS [training: -0.0006619295630337734 | validation: -0.0004056912353844169]
	TIME [epoch: 7.84 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043697352897240733		[learning rate: 0.00064795]
	Learning Rate: 0.000647945
	LOSS [training: -0.00043697352897240733 | validation: -0.0003031767606876375]
	TIME [epoch: 7.84 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000566263678601267		[learning rate: 0.00064642]
	Learning Rate: 0.000646417
	LOSS [training: 0.000566263678601267 | validation: 0.0018848298270882134]
	TIME [epoch: 7.88 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021627797670850275		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.0021627797670850275 | validation: 0.0005543660783851693]
	TIME [epoch: 7.86 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829268749485838e-05		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 5.829268749485838e-05 | validation: 0.0007913904182831545]
	TIME [epoch: 7.84 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011049930119468376		[learning rate: 0.00064185]
	Learning Rate: 0.000641854
	LOSS [training: -0.00011049930119468376 | validation: -0.00010635977253321415]
	TIME [epoch: 7.84 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003093909573050413		[learning rate: 0.00064034]
	Learning Rate: 0.00064034
	LOSS [training: -0.0003093909573050413 | validation: 0.001390449984327057]
	TIME [epoch: 7.84 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.7367845623475e-05		[learning rate: 0.00063883]
	Learning Rate: 0.000638829
	LOSS [training: 8.7367845623475e-05 | validation: 0.0008462711990314355]
	TIME [epoch: 7.89 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039918004891899804		[learning rate: 0.00063732]
	Learning Rate: 0.000637322
	LOSS [training: 0.00039918004891899804 | validation: 0.00047725751744474377]
	TIME [epoch: 7.84 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034421199758878233		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: -0.00034421199758878233 | validation: 0.0004182415080224833]
	TIME [epoch: 7.83 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004899297017707512		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.0004899297017707512 | validation: 0.000864830124262904]
	TIME [epoch: 7.84 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004581293485708502		[learning rate: 0.00063282]
	Learning Rate: 0.000632823
	LOSS [training: -0.0004581293485708502 | validation: 0.0005703283562744233]
	TIME [epoch: 7.84 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037380174757407355		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: -0.00037380174757407355 | validation: -0.0003120992827453981]
	TIME [epoch: 7.88 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017776285665635683		[learning rate: 0.00062984]
	Learning Rate: 0.000629841
	LOSS [training: 0.0017776285665635683 | validation: 0.0005489872712563063]
	TIME [epoch: 7.84 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004283832517058697		[learning rate: 0.00062836]
	Learning Rate: 0.000628355
	LOSS [training: 0.0004283832517058697 | validation: 0.00044717778251866314]
	TIME [epoch: 7.84 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034432664338713464		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: -0.00034432664338713464 | validation: -0.00013103995827482075]
	TIME [epoch: 7.84 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.833540182387844e-05		[learning rate: 0.00062539]
	Learning Rate: 0.000625394
	LOSS [training: -8.833540182387844e-05 | validation: 0.00020637122914379352]
	TIME [epoch: 7.84 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.898535182806696e-05		[learning rate: 0.00062392]
	Learning Rate: 0.000623919
	LOSS [training: 2.898535182806696e-05 | validation: 0.000787327124728447]
	TIME [epoch: 7.88 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001077861929303913		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.001077861929303913 | validation: 0.0019779741251102576]
	TIME [epoch: 7.84 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014111069642745498		[learning rate: 0.00062098]
	Learning Rate: 0.000620979
	LOSS [training: 0.0014111069642745498 | validation: -0.00016604638334305076]
	TIME [epoch: 7.84 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013597302780838283		[learning rate: 0.00061951]
	Learning Rate: 0.000619514
	LOSS [training: 0.00013597302780838283 | validation: -0.00044379931857351624]
	TIME [epoch: 7.84 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004439946336419374		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: -0.0004439946336419374 | validation: 0.0005282737809728513]
	TIME [epoch: 7.88 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00016660452507926825		[learning rate: 0.0006166]
	Learning Rate: 0.000616595
	LOSS [training: -0.00016660452507926825 | validation: -0.00011206002600418109]
	TIME [epoch: 7.86 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015389584074245688		[learning rate: 0.00061514]
	Learning Rate: 0.000615141
	LOSS [training: 0.00015389584074245688 | validation: 0.0006161620144160662]
	TIME [epoch: 7.84 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010654524778913396		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: -0.00010654524778913396 | validation: -0.0001281224415392588]
	TIME [epoch: 7.84 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002996463815528154		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: -0.0002996463815528154 | validation: -0.0004022348831454292]
	TIME [epoch: 7.84 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011583144488527262		[learning rate: 0.0006108]
	Learning Rate: 0.000610798
	LOSS [training: 0.0011583144488527262 | validation: 0.0007124372945017736]
	TIME [epoch: 7.88 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006800099499885139		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.0006800099499885139 | validation: 0.0003369314456028532]
	TIME [epoch: 7.84 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001780377512676872		[learning rate: 0.00060792]
	Learning Rate: 0.00060792
	LOSS [training: 0.0001780377512676872 | validation: -0.00010812787154884385]
	TIME [epoch: 7.84 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011933112834659255		[learning rate: 0.00060649]
	Learning Rate: 0.000606486
	LOSS [training: -0.00011933112834659255 | validation: -0.00047178920851099137]
	TIME [epoch: 7.84 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007430415608051335		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.0007430415608051335 | validation: 0.000333879728206258]
	TIME [epoch: 7.84 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.080605667516891e-05		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: -5.080605667516891e-05 | validation: 0.0010213467357186715]
	TIME [epoch: 7.89 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007204845977540488		[learning rate: 0.0006022]
	Learning Rate: 0.000602204
	LOSS [training: 0.0007204845977540488 | validation: 0.000513830714380652]
	TIME [epoch: 7.85 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001774764453269211		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.0001774764453269211 | validation: 0.00035160637113123937]
	TIME [epoch: 7.84 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001275719420609664		[learning rate: 0.00059937]
	Learning Rate: 0.000599366
	LOSS [training: 0.0001275719420609664 | validation: 9.668773272477737e-07]
	TIME [epoch: 7.85 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002222225102024014		[learning rate: 0.00059795]
	Learning Rate: 0.000597953
	LOSS [training: 0.002222225102024014 | validation: -3.3031904572976354e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010771653865067504		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.0010771653865067504 | validation: 0.0037858607738790397]
	TIME [epoch: 7.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014547137990553968		[learning rate: 0.00059513]
	Learning Rate: 0.000595135
	LOSS [training: 0.0014547137990553968 | validation: 0.0018458230025372583]
	TIME [epoch: 7.84 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008000743677138438		[learning rate: 0.00059373]
	Learning Rate: 0.000593731
	LOSS [training: 0.0008000743677138438 | validation: 0.0006305691347890976]
	TIME [epoch: 7.84 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.614175941137645e-05		[learning rate: 0.00059233]
	Learning Rate: 0.000592331
	LOSS [training: 6.614175941137645e-05 | validation: 2.5686743921351954e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004809915549791941		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: -0.0004809915549791941 | validation: 0.0004132134554941489]
	TIME [epoch: 7.87 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9552035244009306e-05		[learning rate: 0.00058954]
	Learning Rate: 0.000589539
	LOSS [training: 4.9552035244009306e-05 | validation: 0.000531883812743545]
	TIME [epoch: 7.86 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012732619694991493		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.0012732619694991493 | validation: 0.0025652525849711176]
	TIME [epoch: 7.84 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006609041012901536		[learning rate: 0.00058676]
	Learning Rate: 0.000586761
	LOSS [training: 0.0006609041012901536 | validation: 0.0005470995681254336]
	TIME [epoch: 7.85 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000522567774614876		[learning rate: 0.00058538]
	Learning Rate: 0.000585377
	LOSS [training: 0.000522567774614876 | validation: 0.0005182639474097184]
	TIME [epoch: 7.84 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031849213932820476		[learning rate: 0.000584]
	Learning Rate: 0.000583997
	LOSS [training: 0.00031849213932820476 | validation: -0.000685909146008937]
	TIME [epoch: 7.89 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003998617090858483		[learning rate: 0.00058262]
	Learning Rate: 0.000582619
	LOSS [training: -0.0003998617090858483 | validation: -0.0007108714008372089]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1254.pth
	Model improved!!!
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.596917779044428e-05		[learning rate: 0.00058124]
	Learning Rate: 0.000581245
	LOSS [training: 3.596917779044428e-05 | validation: 0.0008863213462181841]
	TIME [epoch: 7.84 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010388312652205049		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.010388312652205049 | validation: 0.007925334976692946]
	TIME [epoch: 7.84 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004067033801947685		[learning rate: 0.00057851]
	Learning Rate: 0.000578506
	LOSS [training: 0.004067033801947685 | validation: 3.0814685066523414e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048581672973543546		[learning rate: 0.00057714]
	Learning Rate: 0.000577141
	LOSS [training: 0.00048581672973543546 | validation: 0.0006324542385468761]
	TIME [epoch: 7.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.423399531128805e-05		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 5.423399531128805e-05 | validation: 0.0005942433648097331]
	TIME [epoch: 7.85 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003491384728540983		[learning rate: 0.00057442]
	Learning Rate: 0.000574422
	LOSS [training: -0.0003491384728540983 | validation: 0.0003839952231148654]
	TIME [epoch: 7.85 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.613115411822367e-05		[learning rate: 0.00057307]
	Learning Rate: 0.000573067
	LOSS [training: -3.613115411822367e-05 | validation: -0.000259238228399683]
	TIME [epoch: 7.84 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9870201860226597e-05		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 2.9870201860226597e-05 | validation: 5.5703958412137025e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000309013656534715		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.000309013656534715 | validation: -0.00017561683966845499]
	TIME [epoch: 7.88 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.780866620411503e-05		[learning rate: 0.00056902]
	Learning Rate: 0.000569021
	LOSS [training: -2.780866620411503e-05 | validation: -0.0010365770167783364]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1264.pth
	Model improved!!!
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001649977317944349		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: -0.0001649977317944349 | validation: 0.00038936414300654444]
	TIME [epoch: 7.84 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001901471529905783		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.0001901471529905783 | validation: -0.0008845805064331143]
	TIME [epoch: 7.84 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.386091809021632e-05		[learning rate: 0.000565]
	Learning Rate: 0.000565004
	LOSS [training: -6.386091809021632e-05 | validation: 0.0003042823232605403]
	TIME [epoch: 7.89 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006716211536325765		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.0006716211536325765 | validation: 0.001597454130644879]
	TIME [epoch: 7.85 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005499312925445121		[learning rate: 0.00056234]
	Learning Rate: 0.000562341
	LOSS [training: 0.0005499312925445121 | validation: 0.000840020179225153]
	TIME [epoch: 7.84 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011822599615466196		[learning rate: 0.00056101]
	Learning Rate: 0.000561015
	LOSS [training: 0.0011822599615466196 | validation: 0.004226812356016058]
	TIME [epoch: 7.84 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026932122076637043		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.0026932122076637043 | validation: 0.00047092873323409054]
	TIME [epoch: 7.83 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012541238156338333		[learning rate: 0.00055837]
	Learning Rate: 0.000558371
	LOSS [training: 0.0012541238156338333 | validation: 0.0002891841235350348]
	TIME [epoch: 7.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559826798575917e-05		[learning rate: 0.00055705]
	Learning Rate: 0.000557054
	LOSS [training: 4.559826798575917e-05 | validation: 0.00021821881338846303]
	TIME [epoch: 7.85 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004092526141277075		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.0004092526141277075 | validation: 0.0014063404779282437]
	TIME [epoch: 7.84 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.5128603759782245e-05		[learning rate: 0.00055443]
	Learning Rate: 0.000554429
	LOSS [training: -2.5128603759782245e-05 | validation: 0.0005783286407855988]
	TIME [epoch: 7.84 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004910920065434995		[learning rate: 0.00055312]
	Learning Rate: 0.000553121
	LOSS [training: 0.004910920065434995 | validation: 0.014505782639858342]
	TIME [epoch: 7.85 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00876773632563376		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.00876773632563376 | validation: 0.003209014391615352]
	TIME [epoch: 7.89 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012404497702099108		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.0012404497702099108 | validation: 0.000655355660716063]
	TIME [epoch: 7.85 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008517652780169263		[learning rate: 0.00054922]
	Learning Rate: 0.000549216
	LOSS [training: 0.0008517652780169263 | validation: 0.0001445493189486223]
	TIME [epoch: 7.84 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033385907768647275		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.00033385907768647275 | validation: -9.882283083562405e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753076518581719e-05		[learning rate: 0.00054663]
	Learning Rate: 0.000546629
	LOSS [training: 1.753076518581719e-05 | validation: 0.00047673312134537273]
	TIME [epoch: 7.87 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002659223618246831		[learning rate: 0.00054534]
	Learning Rate: 0.000545339
	LOSS [training: -0.0002659223618246831 | validation: 0.0016806232393410533]
	TIME [epoch: 7.86 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003661467006968926		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.003661467006968926 | validation: 0.0036156875836587826]
	TIME [epoch: 7.84 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039247722619382		[learning rate: 0.00054277]
	Learning Rate: 0.000542769
	LOSS [training: 0.0039247722619382 | validation: 0.00030308638346433314]
	TIME [epoch: 7.85 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005315943791929902		[learning rate: 0.00054149]
	Learning Rate: 0.000541489
	LOSS [training: -0.0005315943791929902 | validation: -0.0005879069903364057]
	TIME [epoch: 7.84 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011914816432295595		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: -0.00011914816432295595 | validation: -7.961137980869547e-05]
	TIME [epoch: 7.88 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047727128884500106		[learning rate: 0.00053894]
	Learning Rate: 0.000538938
	LOSS [training: -0.00047727128884500106 | validation: -0.0006597195851549098]
	TIME [epoch: 7.86 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006068994682592002		[learning rate: 0.00053767]
	Learning Rate: 0.000537666
	LOSS [training: -0.0006068994682592002 | validation: 0.0002447812534063289]
	TIME [epoch: 7.84 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013018654549817519		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.00013018654549817519 | validation: 0.00018295654261535522]
	TIME [epoch: 7.85 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019803519622286619		[learning rate: 0.00053513]
	Learning Rate: 0.000535133
	LOSS [training: -0.00019803519622286619 | validation: 0.0008150350591339594]
	TIME [epoch: 7.84 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006848514713137875		[learning rate: 0.00053387]
	Learning Rate: 0.00053387
	LOSS [training: -0.0006848514713137875 | validation: -0.0008030390878956694]
	TIME [epoch: 7.89 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006487636043165414		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: -0.0006487636043165414 | validation: -0.0002790352667604852]
	TIME [epoch: 7.84 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002214863991463887		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.002214863991463887 | validation: 0.002272285356629137]
	TIME [epoch: 7.84 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003423102246106548		[learning rate: 0.0005301]
	Learning Rate: 0.000530101
	LOSS [training: -0.0003423102246106548 | validation: -0.00031505710649895315]
	TIME [epoch: 7.84 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000968280856067324		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: -0.000968280856067324 | validation: 0.00047443780679884683]
	TIME [epoch: 7.85 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021989066043365962		[learning rate: 0.0005276]
	Learning Rate: 0.000527603
	LOSS [training: -0.00021989066043365962 | validation: 0.0009786821519952797]
	TIME [epoch: 7.89 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013258030417972557		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.0013258030417972557 | validation: 0.0009466174283113235]
	TIME [epoch: 7.88 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003908094288307973		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: -0.0003908094288307973 | validation: -0.0004717621452827476]
	TIME [epoch: 7.85 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000399352181064119		[learning rate: 0.00052388]
	Learning Rate: 0.000523879
	LOSS [training: -0.000399352181064119 | validation: 0.0005885877498369557]
	TIME [epoch: 7.85 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022037850801986546		[learning rate: 0.00052264]
	Learning Rate: 0.000522643
	LOSS [training: -0.00022037850801986546 | validation: -0.0005237549183208161]
	TIME [epoch: 7.88 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.29959642465461e-05		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: 9.29959642465461e-05 | validation: -0.00018770676056361642]
	TIME [epoch: 7.86 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.221366557798903e-05		[learning rate: 0.00052018]
	Learning Rate: 0.00052018
	LOSS [training: -7.221366557798903e-05 | validation: -0.00018308360421859948]
	TIME [epoch: 7.84 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003993626959851877		[learning rate: 0.00051895]
	Learning Rate: 0.000518953
	LOSS [training: -0.0003993626959851877 | validation: 0.0017292313235338615]
	TIME [epoch: 7.84 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027870368354782207		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: 0.00027870368354782207 | validation: 0.0016353661597082168]
	TIME [epoch: 7.84 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013168010312542824		[learning rate: 0.00051651]
	Learning Rate: 0.000516508
	LOSS [training: 0.00013168010312542824 | validation: 0.00010125728461959585]
	TIME [epoch: 7.89 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.2792380262283584e-05		[learning rate: 0.00051529]
	Learning Rate: 0.000515289
	LOSS [training: -2.2792380262283584e-05 | validation: 0.0003595773627027152]
	TIME [epoch: 7.84 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00014988185800101018		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: -0.00014988185800101018 | validation: 0.0003179628483959651]
	TIME [epoch: 7.84 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008789362879245381		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.0008789362879245381 | validation: 0.00028762920255190187]
	TIME [epoch: 7.83 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028685135907706937		[learning rate: 0.00051165]
	Learning Rate: 0.000511652
	LOSS [training: -0.00028685135907706937 | validation: 5.9902273316925214e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046931462329270014		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: -0.00046931462329270014 | validation: -0.0004068813589070936]
	TIME [epoch: 7.89 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003263900662014958		[learning rate: 0.00050924]
	Learning Rate: 0.000509241
	LOSS [training: -0.0003263900662014958 | validation: 0.0010418798346249522]
	TIME [epoch: 7.84 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028017823046197975		[learning rate: 0.00050804]
	Learning Rate: 0.000508039
	LOSS [training: -0.00028017823046197975 | validation: -0.0001688441832847167]
	TIME [epoch: 7.84 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004034011813767051		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 0.004034011813767051 | validation: 0.002323506469433238]
	TIME [epoch: 7.84 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003132247569368294		[learning rate: 0.00050565]
	Learning Rate: 0.000505646
	LOSS [training: 0.0003132247569368294 | validation: 0.0002010032147938641]
	TIME [epoch: 7.85 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004370380362457658		[learning rate: 0.00050445]
	Learning Rate: 0.000504453
	LOSS [training: -0.0004370380362457658 | validation: -0.0007204808964637022]
	TIME [epoch: 7.88 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004910875584681876		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: -0.0004910875584681876 | validation: -0.00011295033086992177]
	TIME [epoch: 7.84 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002039409613317267		[learning rate: 0.00050208]
	Learning Rate: 0.000502076
	LOSS [training: -0.0002039409613317267 | validation: -0.0003631434448473665]
	TIME [epoch: 7.84 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.817637056166717e-05		[learning rate: 0.00050089]
	Learning Rate: 0.000500891
	LOSS [training: 9.817637056166717e-05 | validation: -0.0006462373470570401]
	TIME [epoch: 7.84 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021572951436066946		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: -0.00021572951436066946 | validation: 0.000701742781705331]
	TIME [epoch: 7.88 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020087206448046692		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: -0.00020087206448046692 | validation: -0.00030232815921549385]
	TIME [epoch: 7.86 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00354858975756258		[learning rate: 0.00049736]
	Learning Rate: 0.000497355
	LOSS [training: 0.00354858975756258 | validation: 0.003858926420357521]
	TIME [epoch: 7.85 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029677462954955203		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: 0.0029677462954955203 | validation: 0.0008308129719825561]
	TIME [epoch: 7.84 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001852293389744737		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.001852293389744737 | validation: -0.0005438702036699091]
	TIME [epoch: 7.84 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004378356936402812		[learning rate: 0.00049384]
	Learning Rate: 0.000493844
	LOSS [training: -0.0004378356936402812 | validation: 0.0007351860788732032]
	TIME [epoch: 7.89 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015545369515994635		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.00015545369515994635 | validation: 9.69328026033529e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006640737084497501		[learning rate: 0.00049152]
	Learning Rate: 0.000491517
	LOSS [training: -0.0006640737084497501 | validation: -0.0005230341626814186]
	TIME [epoch: 7.84 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007116939649765266		[learning rate: 0.00049036]
	Learning Rate: 0.000490358
	LOSS [training: -0.0007116939649765266 | validation: 0.0005889242303888121]
	TIME [epoch: 7.84 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007008688235395573		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: -0.0007008688235395573 | validation: -0.00026701971916670656]
	TIME [epoch: 7.85 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005566880987749732		[learning rate: 0.00048805]
	Learning Rate: 0.000488047
	LOSS [training: -0.0005566880987749732 | validation: 0.003678760512355038]
	TIME [epoch: 7.9 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00278052609962291		[learning rate: 0.0004869]
	Learning Rate: 0.000486896
	LOSS [training: 0.00278052609962291 | validation: -0.00023372340357621994]
	TIME [epoch: 8.16 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00016818733712020982		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: -0.00016818733712020982 | validation: -0.0009369664940839133]
	TIME [epoch: 7.86 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005255089784278843		[learning rate: 0.0004846]
	Learning Rate: 0.000484601
	LOSS [training: -0.0005255089784278843 | validation: 0.00019389682675858877]
	TIME [epoch: 7.86 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004541473102711771		[learning rate: 0.00048346]
	Learning Rate: 0.000483458
	LOSS [training: -0.0004541473102711771 | validation: 0.000260432671740622]
	TIME [epoch: 7.88 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006008328511960565		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: -0.0006008328511960565 | validation: -0.0007074495698078623]
	TIME [epoch: 7.9 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004591564504756089		[learning rate: 0.00048118]
	Learning Rate: 0.00048118
	LOSS [training: -0.0004591564504756089 | validation: -0.0004944156196753488]
	TIME [epoch: 7.87 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006015413167968631		[learning rate: 0.00048005]
	Learning Rate: 0.000480045
	LOSS [training: -0.0006015413167968631 | validation: -3.236441416248149e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000296865422211708		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: -0.000296865422211708 | validation: 0.00041195769252046113]
	TIME [epoch: 7.87 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003198460721040794		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: -0.0003198460721040794 | validation: -5.707521824401019e-05]
	TIME [epoch: 7.9 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000524302232710844		[learning rate: 0.00047666]
	Learning Rate: 0.000476656
	LOSS [training: -0.000524302232710844 | validation: -0.00035902854288613145]
	TIME [epoch: 7.89 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004007079199973369		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: -0.0004007079199973369 | validation: -0.0007339123123401828]
	TIME [epoch: 7.86 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012825761426959727		[learning rate: 0.00047441]
	Learning Rate: 0.00047441
	LOSS [training: 0.00012825761426959727 | validation: -0.0002946959192534036]
	TIME [epoch: 7.86 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227359629491543e-05		[learning rate: 0.00047329]
	Learning Rate: 0.000473291
	LOSS [training: 3.227359629491543e-05 | validation: 0.0010794298188131638]
	TIME [epoch: 7.87 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014056455528632525		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: 0.00014056455528632525 | validation: -0.0003710487190397438]
	TIME [epoch: 7.92 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011705042726386571		[learning rate: 0.00047106]
	Learning Rate: 0.000471061
	LOSS [training: -0.00011705042726386571 | validation: -4.4375356687451854e-08]
	TIME [epoch: 7.87 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022799609386201094		[learning rate: 0.00046995]
	Learning Rate: 0.00046995
	LOSS [training: -0.00022799609386201094 | validation: -0.00038058276501101495]
	TIME [epoch: 7.87 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006926388795910099		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: -0.0006926388795910099 | validation: -0.0002600861392433136]
	TIME [epoch: 7.86 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2487666754914996e-05		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 2.2487666754914996e-05 | validation: -0.000523770213425891]
	TIME [epoch: 7.87 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003984313882175974		[learning rate: 0.00046663]
	Learning Rate: 0.000466632
	LOSS [training: -0.0003984313882175974 | validation: -0.0009948864395798163]
	TIME [epoch: 7.91 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6119415950918834e-05		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: 3.6119415950918834e-05 | validation: -0.0004942991015648631]
	TIME [epoch: 7.87 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002775728433638689		[learning rate: 0.00046443]
	Learning Rate: 0.000464433
	LOSS [training: 0.002775728433638689 | validation: 0.002168210716759082]
	TIME [epoch: 7.87 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014931260484297045		[learning rate: 0.00046334]
	Learning Rate: 0.000463338
	LOSS [training: 0.0014931260484297045 | validation: -0.0004296438001886309]
	TIME [epoch: 7.87 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.827116757725642e-05		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: -1.827116757725642e-05 | validation: 3.5152014624976894e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018806344717377078		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: -0.00018806344717377078 | validation: 0.0029015814249490008]
	TIME [epoch: 7.89 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027576770396812115		[learning rate: 0.00046007]
	Learning Rate: 0.000460066
	LOSS [training: 0.0027576770396812115 | validation: -0.001105629178906769]
	TIME [epoch: 7.87 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1354.pth
	Model improved!!!
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023557058088873565		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: -0.00023557058088873565 | validation: -0.0003412500905887303]
	TIME [epoch: 7.86 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006502238833959948		[learning rate: 0.0004579]
	Learning Rate: 0.000457898
	LOSS [training: -0.0006502238833959948 | validation: -0.0003547374562540462]
	TIME [epoch: 7.86 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006572366715778224		[learning rate: 0.00045682]
	Learning Rate: 0.000456818
	LOSS [training: -0.0006572366715778224 | validation: 0.00014919113250828214]
	TIME [epoch: 7.9 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003245939581246689		[learning rate: 0.00045574]
	Learning Rate: 0.000455741
	LOSS [training: -0.0003245939581246689 | validation: 0.00021978666246483367]
	TIME [epoch: 7.87 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.588761193683919e-05		[learning rate: 0.00045467]
	Learning Rate: 0.000454666
	LOSS [training: -3.588761193683919e-05 | validation: 1.4760244434706147e-06]
	TIME [epoch: 7.87 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.309971221354706e-05		[learning rate: 0.00045359]
	Learning Rate: 0.000453593
	LOSS [training: 7.309971221354706e-05 | validation: 0.0004902338627854114]
	TIME [epoch: 7.87 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005909836315088492		[learning rate: 0.00045252]
	Learning Rate: 0.000452523
	LOSS [training: 0.005909836315088492 | validation: 0.003299457650648768]
	TIME [epoch: 7.86 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035101172863580385		[learning rate: 0.00045146]
	Learning Rate: 0.000451456
	LOSS [training: 0.00035101172863580385 | validation: 0.001157581464484425]
	TIME [epoch: 7.91 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.4105979335459856e-05		[learning rate: 0.00045039]
	Learning Rate: 0.000450391
	LOSS [training: -1.4105979335459856e-05 | validation: 0.0005900417219780851]
	TIME [epoch: 7.86 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045568459591446646		[learning rate: 0.00044933]
	Learning Rate: 0.000449329
	LOSS [training: -0.00045568459591446646 | validation: -9.20788345767205e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022010086418467996		[learning rate: 0.00044827]
	Learning Rate: 0.000448269
	LOSS [training: -0.00022010086418467996 | validation: -0.0003562876243929223]
	TIME [epoch: 7.86 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.681215702808888e-05		[learning rate: 0.00044721]
	Learning Rate: 0.000447211
	LOSS [training: -8.681215702808888e-05 | validation: -0.0001257914544407961]
	TIME [epoch: 7.9 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001397154669199099		[learning rate: 0.00044616]
	Learning Rate: 0.000446157
	LOSS [training: 0.0001397154669199099 | validation: 0.00037201956988220926]
	TIME [epoch: 7.9 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008342249450097781		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: -0.0008342249450097781 | validation: 0.0002578889237046877]
	TIME [epoch: 7.86 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002648066050257152		[learning rate: 0.00044405]
	Learning Rate: 0.000444054
	LOSS [training: 0.0002648066050257152 | validation: 0.000238722166092519]
	TIME [epoch: 7.86 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004656938074352352		[learning rate: 0.00044301]
	Learning Rate: 0.000443007
	LOSS [training: -0.0004656938074352352 | validation: -0.00012781373854696111]
	TIME [epoch: 7.86 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002984603644616006		[learning rate: 0.00044196]
	Learning Rate: 0.000441962
	LOSS [training: -0.0002984603644616006 | validation: -0.0006987538794583039]
	TIME [epoch: 7.89 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009106696459889483		[learning rate: 0.00044092]
	Learning Rate: 0.000440919
	LOSS [training: 0.0009106696459889483 | validation: 0.005580973546175151]
	TIME [epoch: 7.88 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048087357434687256		[learning rate: 0.00043988]
	Learning Rate: 0.000439879
	LOSS [training: 0.0048087357434687256 | validation: -0.0006871329245350499]
	TIME [epoch: 7.86 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002788332864475305		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: -0.0002788332864475305 | validation: 0.00028645910953410073]
	TIME [epoch: 7.86 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005271094513984487		[learning rate: 0.00043781]
	Learning Rate: 0.000437806
	LOSS [training: 0.0005271094513984487 | validation: 0.006250415210210272]
	TIME [epoch: 7.86 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004945897226948151		[learning rate: 0.00043677]
	Learning Rate: 0.000436774
	LOSS [training: 0.004945897226948151 | validation: 0.0004494181566382483]
	TIME [epoch: 7.91 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028254009210726514		[learning rate: 0.00043574]
	Learning Rate: 0.000435743
	LOSS [training: 0.00028254009210726514 | validation: 0.0012977622639659683]
	TIME [epoch: 7.87 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025850583921189		[learning rate: 0.00043472]
	Learning Rate: 0.000434715
	LOSS [training: -0.00025850583921189 | validation: 2.347792721154728e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002705284911914723		[learning rate: 0.00043369]
	Learning Rate: 0.00043369
	LOSS [training: -0.0002705284911914723 | validation: -1.6329547946685623e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039002360478275076		[learning rate: 0.00043267]
	Learning Rate: 0.000432667
	LOSS [training: -0.00039002360478275076 | validation: -0.00012836622485457917]
	TIME [epoch: 7.87 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004699602965318055		[learning rate: 0.00043165]
	Learning Rate: 0.000431647
	LOSS [training: -0.0004699602965318055 | validation: 0.00019121202592214414]
	TIME [epoch: 7.91 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043054255031851744		[learning rate: 0.00043063]
	Learning Rate: 0.000430628
	LOSS [training: -0.00043054255031851744 | validation: 0.0010366979935707739]
	TIME [epoch: 7.87 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.766313971900124e-05		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 4.766313971900124e-05 | validation: 0.0001555917308634087]
	TIME [epoch: 7.86 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.19175744153495e-05		[learning rate: 0.0004286]
	Learning Rate: 0.000428599
	LOSS [training: 7.19175744153495e-05 | validation: 0.003210525283349397]
	TIME [epoch: 7.86 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024027827320077756		[learning rate: 0.00042759]
	Learning Rate: 0.000427588
	LOSS [training: 0.0024027827320077756 | validation: 0.0010292361955884042]
	TIME [epoch: 7.88 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029046177885068663		[learning rate: 0.00042658]
	Learning Rate: 0.000426579
	LOSS [training: -0.00029046177885068663 | validation: -0.00030330673778773047]
	TIME [epoch: 7.89 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006779785583651959		[learning rate: 0.00042557]
	Learning Rate: 0.000425573
	LOSS [training: -0.0006779785583651959 | validation: 7.126457603056568e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.416639755127628e-05		[learning rate: 0.00042457]
	Learning Rate: 0.000424569
	LOSS [training: 5.416639755127628e-05 | validation: 0.0010639054370611821]
	TIME [epoch: 7.86 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001184275570223298		[learning rate: 0.00042357]
	Learning Rate: 0.000423568
	LOSS [training: 0.001184275570223298 | validation: 0.0001436592219882664]
	TIME [epoch: 7.86 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004060812679437782		[learning rate: 0.00042257]
	Learning Rate: 0.000422569
	LOSS [training: -0.0004060812679437782 | validation: -0.000855526848679924]
	TIME [epoch: 7.89 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034799583752949826		[learning rate: 0.00042157]
	Learning Rate: 0.000421572
	LOSS [training: -0.00034799583752949826 | validation: 4.264174927797002e-05]
	TIME [epoch: 7.88 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223028585653531e-05		[learning rate: 0.00042058]
	Learning Rate: 0.000420578
	LOSS [training: 3.223028585653531e-05 | validation: -0.0004309556472562179]
	TIME [epoch: 7.86 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045447920425033825		[learning rate: 0.00041959]
	Learning Rate: 0.000419586
	LOSS [training: -0.00045447920425033825 | validation: 0.0003428972732197422]
	TIME [epoch: 7.86 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001399803661541328		[learning rate: 0.0004186]
	Learning Rate: 0.000418596
	LOSS [training: -0.0001399803661541328 | validation: -0.0004050682449324392]
	TIME [epoch: 7.85 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.696517771032151e-05		[learning rate: 0.00041761]
	Learning Rate: 0.000417608
	LOSS [training: -7.696517771032151e-05 | validation: 0.0005683115395023219]
	TIME [epoch: 7.9 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002132080093339997		[learning rate: 0.00041662]
	Learning Rate: 0.000416623
	LOSS [training: -0.0002132080093339997 | validation: -0.00031459545234818173]
	TIME [epoch: 7.86 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002703787716795558		[learning rate: 0.00041564]
	Learning Rate: 0.000415641
	LOSS [training: -0.0002703787716795558 | validation: 0.0006027755171126006]
	TIME [epoch: 7.86 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004541661771483947		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: -0.0004541661771483947 | validation: -8.241330579721452e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00013362922137767557		[learning rate: 0.00041368]
	Learning Rate: 0.000413682
	LOSS [training: -0.00013362922137767557 | validation: -0.0004050540676589924]
	TIME [epoch: 7.87 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012213386056012212		[learning rate: 0.00041271]
	Learning Rate: 0.000412706
	LOSS [training: -0.00012213386056012212 | validation: 0.0003643950719248203]
	TIME [epoch: 7.9 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.8493341060776016e-06		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: -2.8493341060776016e-06 | validation: -0.00041970626772447914]
	TIME [epoch: 7.86 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000332575170818292		[learning rate: 0.00041076]
	Learning Rate: 0.000410761
	LOSS [training: -0.000332575170818292 | validation: 0.0005394658395167151]
	TIME [epoch: 7.85 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00016390903117693558		[learning rate: 0.00040979]
	Learning Rate: 0.000409793
	LOSS [training: -0.00016390903117693558 | validation: -0.0011611039914651792]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1403.pth
	Model improved!!!
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041842559305165346		[learning rate: 0.00040883]
	Learning Rate: 0.000408826
	LOSS [training: -0.00041842559305165346 | validation: -0.00047196184093551357]
	TIME [epoch: 7.88 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002778771812904452		[learning rate: 0.00040786]
	Learning Rate: 0.000407862
	LOSS [training: -0.0002778771812904452 | validation: -0.0006974542892577306]
	TIME [epoch: 7.87 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018287486511529805		[learning rate: 0.0004069]
	Learning Rate: 0.0004069
	LOSS [training: -0.00018287486511529805 | validation: -0.0005870219334734293]
	TIME [epoch: 7.84 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002830903622285894		[learning rate: 0.00040594]
	Learning Rate: 0.00040594
	LOSS [training: -0.0002830903622285894 | validation: 0.00014744258491079256]
	TIME [epoch: 7.85 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.9991175892239987e-05		[learning rate: 0.00040498]
	Learning Rate: 0.000404982
	LOSS [training: -2.9991175892239987e-05 | validation: 0.0012536738889157828]
	TIME [epoch: 7.84 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039710960175601224		[learning rate: 0.00040403]
	Learning Rate: 0.000404027
	LOSS [training: 0.00039710960175601224 | validation: -0.0004010326446449999]
	TIME [epoch: 7.9 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006173392472945741		[learning rate: 0.00040307]
	Learning Rate: 0.000403074
	LOSS [training: -0.0006173392472945741 | validation: 0.001954035404731186]
	TIME [epoch: 7.85 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.754005951929766e-05		[learning rate: 0.00040212]
	Learning Rate: 0.000402123
	LOSS [training: 6.754005951929766e-05 | validation: 0.00010027379092911515]
	TIME [epoch: 7.85 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005780035923568703		[learning rate: 0.00040117]
	Learning Rate: 0.000401175
	LOSS [training: -0.0005780035923568703 | validation: -0.0002959761951359865]
	TIME [epoch: 7.85 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003739121242437831		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: -0.0003739121242437831 | validation: 0.0003780158812660228]
	TIME [epoch: 7.85 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006338376677215643		[learning rate: 0.00039928]
	Learning Rate: 0.000399284
	LOSS [training: -0.0006338376677215643 | validation: -0.0006542232129826347]
	TIME [epoch: 7.89 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005300402269842301		[learning rate: 0.00039834]
	Learning Rate: 0.000398342
	LOSS [training: -0.0005300402269842301 | validation: -0.00036260962576780423]
	TIME [epoch: 7.85 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001178414245387923		[learning rate: 0.0003974]
	Learning Rate: 0.000397403
	LOSS [training: 0.001178414245387923 | validation: -0.00027832165419297675]
	TIME [epoch: 7.85 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004789777761776677		[learning rate: 0.00039647]
	Learning Rate: 0.000396465
	LOSS [training: -0.0004789777761776677 | validation: 0.0005841090013197112]
	TIME [epoch: 7.84 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039903628616370137		[learning rate: 0.00039553]
	Learning Rate: 0.00039553
	LOSS [training: -0.00039903628616370137 | validation: -0.000829594007062113]
	TIME [epoch: 7.86 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005705787350061258		[learning rate: 0.0003946]
	Learning Rate: 0.000394597
	LOSS [training: -0.0005705787350061258 | validation: -0.0004697081024881111]
	TIME [epoch: 7.88 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014540015625953684		[learning rate: 0.00039367]
	Learning Rate: 0.000393666
	LOSS [training: 0.00014540015625953684 | validation: 0.0005562671943943373]
	TIME [epoch: 7.85 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018026531452873932		[learning rate: 0.00039274]
	Learning Rate: 0.000392738
	LOSS [training: 0.0018026531452873932 | validation: 0.005990154492743499]
	TIME [epoch: 7.85 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006073140113279212		[learning rate: 0.00039181]
	Learning Rate: 0.000391811
	LOSS [training: 0.006073140113279212 | validation: 0.0009402431797060098]
	TIME [epoch: 7.85 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.675631534713085e-05		[learning rate: 0.00039089]
	Learning Rate: 0.000390887
	LOSS [training: -3.675631534713085e-05 | validation: -0.0005965494969437684]
	TIME [epoch: 7.88 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004972376367307824		[learning rate: 0.00038997]
	Learning Rate: 0.000389965
	LOSS [training: -0.0004972376367307824 | validation: -0.0003060837338861875]
	TIME [epoch: 7.86 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005841624208797744		[learning rate: 0.00038905]
	Learning Rate: 0.000389045
	LOSS [training: -0.0005841624208797744 | validation: 0.00015760830786803033]
	TIME [epoch: 7.84 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00036386671234176914		[learning rate: 0.00038813]
	Learning Rate: 0.000388127
	LOSS [training: -0.00036386671234176914 | validation: -0.000963681280733371]
	TIME [epoch: 7.84 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012749439154188956		[learning rate: 0.00038721]
	Learning Rate: 0.000387212
	LOSS [training: 0.0012749439154188956 | validation: 2.8321401796581455e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007851071788175116		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.0007851071788175116 | validation: -0.0002553131936650259]
	TIME [epoch: 7.92 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003465413627292555		[learning rate: 0.00038539]
	Learning Rate: 0.000385387
	LOSS [training: -0.0003465413627292555 | validation: -0.0007646083682529272]
	TIME [epoch: 7.85 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009500802335643587		[learning rate: 0.00038448]
	Learning Rate: 0.000384478
	LOSS [training: -0.0009500802335643587 | validation: 0.0007447689277431811]
	TIME [epoch: 7.85 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008161620156081986		[learning rate: 0.00038357]
	Learning Rate: 0.000383571
	LOSS [training: -0.0008161620156081986 | validation: -0.0011302962116001255]
	TIME [epoch: 7.85 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007909002569148323		[learning rate: 0.00038267]
	Learning Rate: 0.000382667
	LOSS [training: -0.0007909002569148323 | validation: 0.0002880933418219423]
	TIME [epoch: 7.84 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009680864717096583		[learning rate: 0.00038176]
	Learning Rate: 0.000381764
	LOSS [training: -0.0009680864717096583 | validation: -6.523155934267955e-05]
	TIME [epoch: 7.9 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021564672400844434		[learning rate: 0.00038086]
	Learning Rate: 0.000380863
	LOSS [training: -0.00021564672400844434 | validation: 0.0008654187037239814]
	TIME [epoch: 7.85 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019975319679775992		[learning rate: 0.00037997]
	Learning Rate: 0.000379965
	LOSS [training: -0.00019975319679775992 | validation: 9.179431434282612e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00055517579114577		[learning rate: 0.00037907]
	Learning Rate: 0.000379069
	LOSS [training: -0.00055517579114577 | validation: -0.00041013042660982806]
	TIME [epoch: 7.85 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003330805159536809		[learning rate: 0.00037817]
	Learning Rate: 0.000378175
	LOSS [training: -0.0003330805159536809 | validation: 0.003343578525116102]
	TIME [epoch: 7.86 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068779032316074		[learning rate: 0.00037728]
	Learning Rate: 0.000377283
	LOSS [training: 0.0068779032316074 | validation: 0.001132918050698998]
	TIME [epoch: 7.87 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6988892032808964e-05		[learning rate: 0.00037639]
	Learning Rate: 0.000376393
	LOSS [training: 2.6988892032808964e-05 | validation: -7.865337646193238e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017254414798380236		[learning rate: 0.0003755]
	Learning Rate: 0.000375505
	LOSS [training: -0.00017254414798380236 | validation: -0.000979802932971523]
	TIME [epoch: 7.84 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005121476484069152		[learning rate: 0.00037462]
	Learning Rate: 0.000374619
	LOSS [training: -0.0005121476484069152 | validation: -0.00022258871283389105]
	TIME [epoch: 7.85 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0040184322404234725		[learning rate: 0.00037374]
	Learning Rate: 0.000373735
	LOSS [training: 0.0040184322404234725 | validation: 0.003132826234900001]
	TIME [epoch: 7.88 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021088154992587264		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.0021088154992587264 | validation: 8.582770776904261e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008391786811940815		[learning rate: 0.00037197]
	Learning Rate: 0.000371974
	LOSS [training: -0.0008391786811940815 | validation: 7.034167488258091e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008872473700057115		[learning rate: 0.0003711]
	Learning Rate: 0.000371097
	LOSS [training: -0.0008872473700057115 | validation: -0.00038277265260343947]
	TIME [epoch: 7.85 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00031941442319092866		[learning rate: 0.00037022]
	Learning Rate: 0.000370221
	LOSS [training: -0.00031941442319092866 | validation: -0.000828495732152002]
	TIME [epoch: 7.84 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005121106605777123		[learning rate: 0.00036935]
	Learning Rate: 0.000369348
	LOSS [training: -0.0005121106605777123 | validation: -0.0006178032889125666]
	TIME [epoch: 7.89 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005411368263528204		[learning rate: 0.00036848]
	Learning Rate: 0.000368477
	LOSS [training: -0.0005411368263528204 | validation: 0.001143412276031031]
	TIME [epoch: 7.85 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012147291166975738		[learning rate: 0.00036761]
	Learning Rate: 0.000367608
	LOSS [training: 0.0012147291166975738 | validation: -0.0003327433303818799]
	TIME [epoch: 7.84 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020432828900190315		[learning rate: 0.00036674]
	Learning Rate: 0.000366741
	LOSS [training: -0.00020432828900190315 | validation: -0.0008068811324610148]
	TIME [epoch: 7.84 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005947774839460752		[learning rate: 0.00036588]
	Learning Rate: 0.000365876
	LOSS [training: -0.0005947774839460752 | validation: 0.0002790583437361551]
	TIME [epoch: 7.85 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.932643491199729e-05		[learning rate: 0.00036501]
	Learning Rate: 0.000365012
	LOSS [training: 8.932643491199729e-05 | validation: -0.0007050059782321085]
	TIME [epoch: 7.89 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041672008418132547		[learning rate: 0.00036415]
	Learning Rate: 0.000364152
	LOSS [training: -0.00041672008418132547 | validation: -0.0002123455412910382]
	TIME [epoch: 7.85 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044083290245496		[learning rate: 0.00036329]
	Learning Rate: 0.000363293
	LOSS [training: -0.00044083290245496 | validation: 0.0006231004201262427]
	TIME [epoch: 7.84 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.294795116762228e-05		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: -3.294795116762228e-05 | validation: 3.6690074924345783e-06]
	TIME [epoch: 7.84 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007957504134608459		[learning rate: 0.00036158]
	Learning Rate: 0.000361581
	LOSS [training: -0.0007957504134608459 | validation: -0.0008571681085815279]
	TIME [epoch: 7.86 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019904803138386204		[learning rate: 0.00036073]
	Learning Rate: 0.000360728
	LOSS [training: -0.00019904803138386204 | validation: -0.0006262473600106246]
	TIME [epoch: 7.88 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.09046941622473e-05		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: -6.09046941622473e-05 | validation: 0.0025069285701677787]
	TIME [epoch: 7.85 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002616054948982409		[learning rate: 0.00035903]
	Learning Rate: 0.000359028
	LOSS [training: -0.0002616054948982409 | validation: -6.98028610664725e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004384250249427171		[learning rate: 0.00035818]
	Learning Rate: 0.000358181
	LOSS [training: -0.0004384250249427171 | validation: -0.00046508100551959157]
	TIME [epoch: 7.85 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005938343361518979		[learning rate: 0.00035734]
	Learning Rate: 0.000357336
	LOSS [training: -0.0005938343361518979 | validation: -0.0004952535736668428]
	TIME [epoch: 7.88 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007952092070821965		[learning rate: 0.00035649]
	Learning Rate: 0.000356493
	LOSS [training: -0.0007952092070821965 | validation: -0.0005662236174040478]
	TIME [epoch: 7.86 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020726083284514725		[learning rate: 0.00035565]
	Learning Rate: 0.000355652
	LOSS [training: 0.00020726083284514725 | validation: -4.373356288210495e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029371571152980453		[learning rate: 0.00035481]
	Learning Rate: 0.000354813
	LOSS [training: -0.00029371571152980453 | validation: -0.0012382837929695429]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1464.pth
	Model improved!!!
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017405690512315664		[learning rate: 0.00035398]
	Learning Rate: 0.000353976
	LOSS [training: -0.00017405690512315664 | validation: 0.00039521861521040516]
	TIME [epoch: 7.84 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.703430736054877e-06		[learning rate: 0.00035314]
	Learning Rate: 0.000353141
	LOSS [training: -1.703430736054877e-06 | validation: 5.796910590498693e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005116489229600015		[learning rate: 0.00035231]
	Learning Rate: 0.000352309
	LOSS [training: -0.0005116489229600015 | validation: -0.0007526187571898727]
	TIME [epoch: 7.84 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005495419700875624		[learning rate: 0.00035148]
	Learning Rate: 0.000351477
	LOSS [training: -0.0005495419700875624 | validation: 0.0002818562167966139]
	TIME [epoch: 7.84 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039606711774770514		[learning rate: 0.00035065]
	Learning Rate: 0.000350648
	LOSS [training: -0.00039606711774770514 | validation: -0.0002753546204011212]
	TIME [epoch: 7.84 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0997418191055273e-06		[learning rate: 0.00034982]
	Learning Rate: 0.000349821
	LOSS [training: 2.0997418191055273e-06 | validation: -0.0011894748828192756]
	TIME [epoch: 7.84 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004032914967425973		[learning rate: 0.000349]
	Learning Rate: 0.000348996
	LOSS [training: -0.0004032914967425973 | validation: -0.0001418034420669101]
	TIME [epoch: 7.88 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025882377591301254		[learning rate: 0.00034817]
	Learning Rate: 0.000348173
	LOSS [training: -0.00025882377591301254 | validation: -0.0004424312899226388]
	TIME [epoch: 7.84 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00026780171355328614		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: -0.00026780171355328614 | validation: -0.0002122948187475484]
	TIME [epoch: 7.84 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.7697245269273847e-05		[learning rate: 0.00034653]
	Learning Rate: 0.000346532
	LOSS [training: -2.7697245269273847e-05 | validation: 0.0006205801031403743]
	TIME [epoch: 7.84 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023256167170580713		[learning rate: 0.00034571]
	Learning Rate: 0.000345715
	LOSS [training: 0.00023256167170580713 | validation: -0.0007796118089848041]
	TIME [epoch: 7.87 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006208796496457341		[learning rate: 0.0003449]
	Learning Rate: 0.000344899
	LOSS [training: -0.0006208796496457341 | validation: 0.0005290350843622606]
	TIME [epoch: 7.86 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00042385567392315806		[learning rate: 0.00034409]
	Learning Rate: 0.000344086
	LOSS [training: -0.00042385567392315806 | validation: 9.843391894861364e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.358143909959994e-05		[learning rate: 0.00034327]
	Learning Rate: 0.000343274
	LOSS [training: -5.358143909959994e-05 | validation: 0.0004214142173412095]
	TIME [epoch: 7.84 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034622059204150984		[learning rate: 0.00034246]
	Learning Rate: 0.000342464
	LOSS [training: -0.00034622059204150984 | validation: -0.0006275546445615309]
	TIME [epoch: 7.84 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004986306202459394		[learning rate: 0.00034166]
	Learning Rate: 0.000341657
	LOSS [training: -0.0004986306202459394 | validation: -0.000431893051849368]
	TIME [epoch: 7.88 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006402764382835424		[learning rate: 0.00034085]
	Learning Rate: 0.000340851
	LOSS [training: -0.0006402764382835424 | validation: 0.0013838603307725272]
	TIME [epoch: 7.84 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001850502847867066		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: -0.0001850502847867066 | validation: -0.0002629401602024748]
	TIME [epoch: 7.84 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045354065204574677		[learning rate: 0.00033924]
	Learning Rate: 0.000339245
	LOSS [training: -0.00045354065204574677 | validation: 5.166675443794722e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002100316205439692		[learning rate: 0.00033844]
	Learning Rate: 0.000338444
	LOSS [training: -0.0002100316205439692 | validation: 0.00018058824568318102]
	TIME [epoch: 7.84 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012666097542479563		[learning rate: 0.00033765]
	Learning Rate: 0.000337646
	LOSS [training: -0.00012666097542479563 | validation: -0.00040591378788896294]
	TIME [epoch: 7.89 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011098806582515807		[learning rate: 0.00033685]
	Learning Rate: 0.00033685
	LOSS [training: 0.00011098806582515807 | validation: 0.00011462248668289554]
	TIME [epoch: 7.84 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045394840559724137		[learning rate: 0.00033605]
	Learning Rate: 0.000336055
	LOSS [training: -0.00045394840559724137 | validation: -0.0002742155794625951]
	TIME [epoch: 7.84 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008950912712269947		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: -0.0008950912712269947 | validation: 0.00011821202701618462]
	TIME [epoch: 7.84 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005083194001871528		[learning rate: 0.00033447]
	Learning Rate: 0.000334471
	LOSS [training: -0.0005083194001871528 | validation: -4.6079115648169904e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00033340767499215774		[learning rate: 0.00033368]
	Learning Rate: 0.000333682
	LOSS [training: -0.00033340767499215774 | validation: 6.619324328424625e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005155569914051172		[learning rate: 0.0003329]
	Learning Rate: 0.000332895
	LOSS [training: -0.0005155569914051172 | validation: -0.00014096435013256903]
	TIME [epoch: 7.84 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004479909257835282		[learning rate: 0.00033211]
	Learning Rate: 0.00033211
	LOSS [training: -0.0004479909257835282 | validation: -0.00010189170030231723]
	TIME [epoch: 7.84 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003978752192248678		[learning rate: 0.00033133]
	Learning Rate: 0.000331327
	LOSS [training: -0.0003978752192248678 | validation: -0.0004497724686126463]
	TIME [epoch: 7.84 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008983648635661106		[learning rate: 0.00033055]
	Learning Rate: 0.000330545
	LOSS [training: -0.0008983648635661106 | validation: -0.0006031255432627641]
	TIME [epoch: 7.88 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.07178396182608e-05		[learning rate: 0.00032977]
	Learning Rate: 0.000329765
	LOSS [training: 4.07178396182608e-05 | validation: -0.0002564594430351317]
	TIME [epoch: 7.86 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000920693238167952		[learning rate: 0.00032899]
	Learning Rate: 0.000328988
	LOSS [training: -0.000920693238167952 | validation: -0.0003278621653400529]
	TIME [epoch: 7.84 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008458232802864067		[learning rate: 0.00032821]
	Learning Rate: 0.000328212
	LOSS [training: -0.0008458232802864067 | validation: 4.122531722548485e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.481542565773627e-05		[learning rate: 0.00032744]
	Learning Rate: 0.000327437
	LOSS [training: -8.481542565773627e-05 | validation: 0.00011512221196365678]
	TIME [epoch: 7.84 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003417313308324219		[learning rate: 0.00032666]
	Learning Rate: 0.000326665
	LOSS [training: -0.0003417313308324219 | validation: 0.0005821847725239265]
	TIME [epoch: 7.89 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006037672739043358		[learning rate: 0.00032589]
	Learning Rate: 0.000325894
	LOSS [training: -0.0006037672739043358 | validation: -0.0007954700430346327]
	TIME [epoch: 7.85 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023367332209570812		[learning rate: 0.00032513]
	Learning Rate: 0.000325126
	LOSS [training: -0.00023367332209570812 | validation: -0.00024236266050162137]
	TIME [epoch: 7.85 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008775859886661742		[learning rate: 0.00032436]
	Learning Rate: 0.000324359
	LOSS [training: -0.0008775859886661742 | validation: -0.0003867586888614416]
	TIME [epoch: 7.84 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005742759894037242		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: -0.0005742759894037242 | validation: -0.0005753924593891258]
	TIME [epoch: 7.85 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045385498192408225		[learning rate: 0.00032283]
	Learning Rate: 0.00032283
	LOSS [training: -0.00045385498192408225 | validation: -0.000797767304545765]
	TIME [epoch: 7.89 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022314527081409305		[learning rate: 0.00032207]
	Learning Rate: 0.000322069
	LOSS [training: -0.00022314527081409305 | validation: -0.0004100150015226363]
	TIME [epoch: 7.84 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000603778460489752		[learning rate: 0.00032131]
	Learning Rate: 0.000321309
	LOSS [training: -0.000603778460489752 | validation: 0.0005963623535450698]
	TIME [epoch: 7.85 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000409532429237085		[learning rate: 0.00032055]
	Learning Rate: 0.000320551
	LOSS [training: -0.000409532429237085 | validation: -0.0009056535844749764]
	TIME [epoch: 7.84 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005119002143499074		[learning rate: 0.0003198]
	Learning Rate: 0.000319795
	LOSS [training: -0.0005119002143499074 | validation: -1.6124125800764944e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00042136212046451553		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: -0.00042136212046451553 | validation: 0.00045891281819814684]
	TIME [epoch: 7.87 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005109901648366029		[learning rate: 0.00031829]
	Learning Rate: 0.000318288
	LOSS [training: -0.0005109901648366029 | validation: -0.00012981588278299804]
	TIME [epoch: 7.86 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00049094919008777		[learning rate: 0.00031754]
	Learning Rate: 0.000317537
	LOSS [training: -0.00049094919008777 | validation: -0.0004095137731534356]
	TIME [epoch: 7.84 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003760051396527608		[learning rate: 0.00031679]
	Learning Rate: 0.000316788
	LOSS [training: -0.0003760051396527608 | validation: 0.0005557911965443193]
	TIME [epoch: 7.84 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019609950033482295		[learning rate: 0.00031604]
	Learning Rate: 0.000316041
	LOSS [training: -0.00019609950033482295 | validation: 0.00023202377819363473]
	TIME [epoch: 7.87 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041075359234780473		[learning rate: 0.0003153]
	Learning Rate: 0.000315296
	LOSS [training: -0.00041075359234780473 | validation: -0.0007065366109834557]
	TIME [epoch: 7.86 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000656163211060026		[learning rate: 0.00031455]
	Learning Rate: 0.000314552
	LOSS [training: -0.000656163211060026 | validation: 0.0005259741743216249]
	TIME [epoch: 7.84 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006542482488058455		[learning rate: 0.00031381]
	Learning Rate: 0.00031381
	LOSS [training: -0.0006542482488058455 | validation: -0.000708262304696436]
	TIME [epoch: 7.84 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00042478119403401135		[learning rate: 0.00031307]
	Learning Rate: 0.00031307
	LOSS [training: -0.00042478119403401135 | validation: -0.00044792943104959496]
	TIME [epoch: 7.84 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005430834890423208		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: -0.0005430834890423208 | validation: -0.0007610099343458127]
	TIME [epoch: 7.89 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005709589839114422		[learning rate: 0.00031159]
	Learning Rate: 0.000311594
	LOSS [training: -0.0005709589839114422 | validation: -0.000818973370451356]
	TIME [epoch: 7.85 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007265085675538775		[learning rate: 0.00031086]
	Learning Rate: 0.00031086
	LOSS [training: -0.0007265085675538775 | validation: -5.4711068883080756e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005258467030401319		[learning rate: 0.00031013]
	Learning Rate: 0.000310126
	LOSS [training: -0.0005258467030401319 | validation: -0.0003331552164052325]
	TIME [epoch: 7.84 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005117899186847212		[learning rate: 0.00030939]
	Learning Rate: 0.000309395
	LOSS [training: -0.0005117899186847212 | validation: -0.0004937749796284225]
	TIME [epoch: 7.85 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041972967555477394		[learning rate: 0.00030866]
	Learning Rate: 0.000308665
	LOSS [training: -0.00041972967555477394 | validation: -0.000733485168374493]
	TIME [epoch: 7.88 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005010798489096231		[learning rate: 0.00030794]
	Learning Rate: 0.000307937
	LOSS [training: -0.0005010798489096231 | validation: -0.000887700247967973]
	TIME [epoch: 7.85 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007160568376293789		[learning rate: 0.00030721]
	Learning Rate: 0.00030721
	LOSS [training: -0.0007160568376293789 | validation: -0.0005618615693044023]
	TIME [epoch: 7.84 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.161122583340598e-05		[learning rate: 0.00030649]
	Learning Rate: 0.000306486
	LOSS [training: -1.161122583340598e-05 | validation: -0.00022749740147778665]
	TIME [epoch: 7.86 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044193056605177825		[learning rate: 0.00030576]
	Learning Rate: 0.000305763
	LOSS [training: -0.00044193056605177825 | validation: 8.157221038101926e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005353880035423029		[learning rate: 0.00030504]
	Learning Rate: 0.000305042
	LOSS [training: -0.0005353880035423029 | validation: -0.0001234500414833559]
	TIME [epoch: 7.87 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009821515801850906		[learning rate: 0.00030432]
	Learning Rate: 0.000304322
	LOSS [training: -0.0009821515801850906 | validation: -0.000622457286485973]
	TIME [epoch: 7.85 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047160589992859567		[learning rate: 0.0003036]
	Learning Rate: 0.000303604
	LOSS [training: -0.00047160589992859567 | validation: -0.00054016085520988]
	TIME [epoch: 7.84 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002588201341361502		[learning rate: 0.00030289]
	Learning Rate: 0.000302888
	LOSS [training: -0.0002588201341361502 | validation: -0.00042810738137280513]
	TIME [epoch: 7.84 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.42094181634103e-05		[learning rate: 0.00030217]
	Learning Rate: 0.000302174
	LOSS [training: 4.42094181634103e-05 | validation: -0.000871235999227697]
	TIME [epoch: 7.88 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002824564497405222		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: -0.0002824564497405222 | validation: -0.0008733428517414788]
	TIME [epoch: 7.85 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005336023674990491		[learning rate: 0.00030075]
	Learning Rate: 0.00030075
	LOSS [training: -0.0005336023674990491 | validation: 0.0001644770195751031]
	TIME [epoch: 7.84 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005665525625263325		[learning rate: 0.00030004]
	Learning Rate: 0.00030004
	LOSS [training: -0.0005665525625263325 | validation: -0.00042141751799864923]
	TIME [epoch: 7.84 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019488366751598132		[learning rate: 0.00029933]
	Learning Rate: 0.000299332
	LOSS [training: -0.00019488366751598132 | validation: -0.00048355109769213734]
	TIME [epoch: 7.84 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000646786828502296		[learning rate: 0.00029863]
	Learning Rate: 0.000298626
	LOSS [training: -0.000646786828502296 | validation: -0.00016620025690461659]
	TIME [epoch: 7.89 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005286198670743783		[learning rate: 0.00029792]
	Learning Rate: 0.000297922
	LOSS [training: -0.0005286198670743783 | validation: 0.0005788725205447553]
	TIME [epoch: 7.84 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009358902994959688		[learning rate: 0.00029722]
	Learning Rate: 0.000297219
	LOSS [training: -0.0009358902994959688 | validation: -0.0008098565104544692]
	TIME [epoch: 7.84 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00091598793058344		[learning rate: 0.00029652]
	Learning Rate: 0.000296518
	LOSS [training: -0.00091598793058344 | validation: -0.0005936448078528631]
	TIME [epoch: 7.84 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023249205593982227		[learning rate: 0.00029582]
	Learning Rate: 0.000295819
	LOSS [training: -0.00023249205593982227 | validation: -0.0011378017079767021]
	TIME [epoch: 7.84 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008591062609898629		[learning rate: 0.00029512]
	Learning Rate: 0.000295121
	LOSS [training: -0.0008591062609898629 | validation: 0.00019151087214532714]
	TIME [epoch: 7.88 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045601236250453		[learning rate: 0.00029442]
	Learning Rate: 0.000294425
	LOSS [training: -0.00045601236250453 | validation: 3.640833135667387e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002914047435519773		[learning rate: 0.00029373]
	Learning Rate: 0.00029373
	LOSS [training: 0.0002914047435519773 | validation: -0.0006123163634460047]
	TIME [epoch: 7.84 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008588783520814357		[learning rate: 0.00029304]
	Learning Rate: 0.000293037
	LOSS [training: -0.0008588783520814357 | validation: -0.00041083555908689464]
	TIME [epoch: 7.84 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009009758048679943		[learning rate: 0.00029235]
	Learning Rate: 0.000292346
	LOSS [training: -0.0009009758048679943 | validation: -0.0008205655580367241]
	TIME [epoch: 7.87 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00042863035825627273		[learning rate: 0.00029166]
	Learning Rate: 0.000291657
	LOSS [training: -0.00042863035825627273 | validation: 0.000254010381066391]
	TIME [epoch: 7.86 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047138654669828697		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: -0.00047138654669828697 | validation: -0.0002789680053745944]
	TIME [epoch: 7.84 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003329795004911244		[learning rate: 0.00029028]
	Learning Rate: 0.000290282
	LOSS [training: 0.0003329795004911244 | validation: -0.00022943494851251068]
	TIME [epoch: 7.84 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005278338575144375		[learning rate: 0.0002896]
	Learning Rate: 0.000289598
	LOSS [training: -0.0005278338575144375 | validation: -0.0013772330747060524]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1550.pth
	Model improved!!!
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003420908054935747		[learning rate: 0.00028891]
	Learning Rate: 0.000288914
	LOSS [training: -0.0003420908054935747 | validation: 0.00015685328471360638]
	TIME [epoch: 7.89 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000408390289356376		[learning rate: 0.00028823]
	Learning Rate: 0.000288233
	LOSS [training: -0.000408390289356376 | validation: 0.0007886888789432965]
	TIME [epoch: 7.85 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005015504712205111		[learning rate: 0.00028755]
	Learning Rate: 0.000287553
	LOSS [training: -0.0005015504712205111 | validation: -0.000125185406161231]
	TIME [epoch: 7.84 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012025185213926128		[learning rate: 0.00028687]
	Learning Rate: 0.000286875
	LOSS [training: -0.00012025185213926128 | validation: -0.0012698058222293022]
	TIME [epoch: 7.84 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000650442958001628		[learning rate: 0.0002862]
	Learning Rate: 0.000286198
	LOSS [training: -0.000650442958001628 | validation: -0.00018333960133770823]
	TIME [epoch: 7.83 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003362027455445409		[learning rate: 0.00028552]
	Learning Rate: 0.000285523
	LOSS [training: -0.0003362027455445409 | validation: 8.989698413613522e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004564446589993892		[learning rate: 0.00028485]
	Learning Rate: 0.000284849
	LOSS [training: -0.0004564446589993892 | validation: -0.0004112515319855099]
	TIME [epoch: 7.84 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000250515615086704		[learning rate: 0.00028418]
	Learning Rate: 0.000284178
	LOSS [training: -0.000250515615086704 | validation: -0.00040993918225669954]
	TIME [epoch: 7.84 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007836664663085204		[learning rate: 0.00028351]
	Learning Rate: 0.000283507
	LOSS [training: -0.0007836664663085204 | validation: 0.00013924720779483123]
	TIME [epoch: 7.86 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000426355846146105		[learning rate: 0.00028284]
	Learning Rate: 0.000282839
	LOSS [training: -0.000426355846146105 | validation: 0.0006256971859988791]
	TIME [epoch: 7.85 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012787231479430901		[learning rate: 0.00028217]
	Learning Rate: 0.000282171
	LOSS [training: 0.0012787231479430901 | validation: -0.0009534148418248725]
	TIME [epoch: 7.88 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011876368557197205		[learning rate: 0.00028151]
	Learning Rate: 0.000281506
	LOSS [training: 0.00011876368557197205 | validation: 0.0005373794164771555]
	TIME [epoch: 7.83 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008478489754942902		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: -0.0008478489754942902 | validation: -0.0011761538487570502]
	TIME [epoch: 7.84 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004053816772351818		[learning rate: 0.00028018]
	Learning Rate: 0.000280179
	LOSS [training: 0.0004053816772351818 | validation: 0.0029607989952387423]
	TIME [epoch: 7.84 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002040953319919804		[learning rate: 0.00027952]
	Learning Rate: 0.000279518
	LOSS [training: 0.002040953319919804 | validation: -0.0006915434106699689]
	TIME [epoch: 7.87 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018144006871613993		[learning rate: 0.00027886]
	Learning Rate: 0.000278859
	LOSS [training: -0.00018144006871613993 | validation: -0.0009269918766494949]
	TIME [epoch: 7.86 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008591924041307078		[learning rate: 0.0002782]
	Learning Rate: 0.000278201
	LOSS [training: -0.0008591924041307078 | validation: -0.0005396231599961259]
	TIME [epoch: 7.84 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007633448595494145		[learning rate: 0.00027755]
	Learning Rate: 0.000277545
	LOSS [training: -0.0007633448595494145 | validation: -0.0003968404386272257]
	TIME [epoch: 7.84 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045908586144694375		[learning rate: 0.00027689]
	Learning Rate: 0.00027689
	LOSS [training: -0.00045908586144694375 | validation: -0.00038490307048598686]
	TIME [epoch: 7.84 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004498764819868444		[learning rate: 0.00027624]
	Learning Rate: 0.000276237
	LOSS [training: -0.0004498764819868444 | validation: -0.0007543826391335849]
	TIME [epoch: 7.9 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004037586990225275		[learning rate: 0.00027559]
	Learning Rate: 0.000275586
	LOSS [training: -0.0004037586990225275 | validation: -6.286379392636565e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.058783888527095e-05		[learning rate: 0.00027494]
	Learning Rate: 0.000274935
	LOSS [training: -4.058783888527095e-05 | validation: -0.00047126144139053496]
	TIME [epoch: 7.84 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000495585687903284		[learning rate: 0.00027429]
	Learning Rate: 0.000274287
	LOSS [training: -0.000495585687903284 | validation: 0.0009292818304956696]
	TIME [epoch: 7.84 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045150818740485253		[learning rate: 0.00027364]
	Learning Rate: 0.00027364
	LOSS [training: -0.00045150818740485253 | validation: 0.0005808790066835185]
	TIME [epoch: 7.84 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041621531432509796		[learning rate: 0.00027299]
	Learning Rate: 0.000272994
	LOSS [training: -0.00041621531432509796 | validation: 0.0005098004165976198]
	TIME [epoch: 7.89 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007473134897538721		[learning rate: 0.00027235]
	Learning Rate: 0.000272351
	LOSS [training: -0.0007473134897538721 | validation: 0.00025690199206607423]
	TIME [epoch: 7.86 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009809068681480902		[learning rate: 0.00027171]
	Learning Rate: 0.000271708
	LOSS [training: -0.0009809068681480902 | validation: -0.0002768342183396011]
	TIME [epoch: 7.84 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009080451258232593		[learning rate: 0.00027107]
	Learning Rate: 0.000271067
	LOSS [training: -0.0009080451258232593 | validation: -0.00012624306921021677]
	TIME [epoch: 7.85 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003852212089802611		[learning rate: 0.00027043]
	Learning Rate: 0.000270428
	LOSS [training: -0.0003852212089802611 | validation: -0.00015871123272552222]
	TIME [epoch: 7.86 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008761086521078951		[learning rate: 0.00026979]
	Learning Rate: 0.00026979
	LOSS [training: -0.0008761086521078951 | validation: 0.0010812694685412105]
	TIME [epoch: 7.88 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001097693214451525		[learning rate: 0.00026915]
	Learning Rate: 0.000269154
	LOSS [training: 0.001097693214451525 | validation: 0.0011180136087862364]
	TIME [epoch: 7.84 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013490019442446593		[learning rate: 0.00026852]
	Learning Rate: 0.000268519
	LOSS [training: 0.0013490019442446593 | validation: 0.0006648018352070116]
	TIME [epoch: 7.84 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019295945659236822		[learning rate: 0.00026789]
	Learning Rate: 0.000267885
	LOSS [training: -0.00019295945659236822 | validation: 0.0002588372069944915]
	TIME [epoch: 7.83 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000587864319297356		[learning rate: 0.00026725]
	Learning Rate: 0.000267253
	LOSS [training: -0.000587864319297356 | validation: 6.550987423740252e-05]
	TIME [epoch: 7.88 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00030969282641260537		[learning rate: 0.00026662]
	Learning Rate: 0.000266623
	LOSS [training: -0.00030969282641260537 | validation: -0.0009782716223999213]
	TIME [epoch: 7.86 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.782599827711902e-06		[learning rate: 0.00026599]
	Learning Rate: 0.000265994
	LOSS [training: 7.782599827711902e-06 | validation: -0.00021591029264587063]
	TIME [epoch: 7.84 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004866061906368145		[learning rate: 0.00026537]
	Learning Rate: 0.000265367
	LOSS [training: -0.0004866061906368145 | validation: 0.0006526653934434647]
	TIME [epoch: 7.84 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007009677314797828		[learning rate: 0.00026474]
	Learning Rate: 0.000264741
	LOSS [training: -0.0007009677314797828 | validation: -0.0014334342746471]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1588.pth
	Model improved!!!
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009287367251706063		[learning rate: 0.00026412]
	Learning Rate: 0.000264116
	LOSS [training: -0.0009287367251706063 | validation: -0.0004856300097510071]
	TIME [epoch: 7.89 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001564321523624064		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.0001564321523624064 | validation: 0.0009035771144085465]
	TIME [epoch: 7.85 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010034641162719915		[learning rate: 0.00026287]
	Learning Rate: 0.000262872
	LOSS [training: 0.0010034641162719915 | validation: -0.0003389888983333611]
	TIME [epoch: 7.84 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035476672309650104		[learning rate: 0.00026225]
	Learning Rate: 0.000262252
	LOSS [training: -0.00035476672309650104 | validation: 6.278051635127203e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003639913017798802		[learning rate: 0.00026163]
	Learning Rate: 0.000261633
	LOSS [training: -0.0003639913017798802 | validation: 0.0001534283241893539]
	TIME [epoch: 7.84 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007165195491267333		[learning rate: 0.00026102]
	Learning Rate: 0.000261016
	LOSS [training: -0.0007165195491267333 | validation: -0.0005702624371876092]
	TIME [epoch: 7.89 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010427106270423936		[learning rate: 0.0002604]
	Learning Rate: 0.0002604
	LOSS [training: -0.00010427106270423936 | validation: -6.034468264357694e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007684170570469787		[learning rate: 0.00025979]
	Learning Rate: 0.000259786
	LOSS [training: -0.0007684170570469787 | validation: 0.0006928347654774525]
	TIME [epoch: 7.84 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001796356904281595		[learning rate: 0.00025917]
	Learning Rate: 0.000259173
	LOSS [training: -0.0001796356904281595 | validation: 0.001266718670573829]
	TIME [epoch: 7.84 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018178356888049672		[learning rate: 0.00025856]
	Learning Rate: 0.000258562
	LOSS [training: -0.00018178356888049672 | validation: 0.00017269741675947614]
	TIME [epoch: 7.86 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005165279328369222		[learning rate: 0.00025795]
	Learning Rate: 0.000257952
	LOSS [training: -0.0005165279328369222 | validation: -0.00029075073835868365]
	TIME [epoch: 7.87 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007533775063896812		[learning rate: 0.00025734]
	Learning Rate: 0.000257343
	LOSS [training: -0.0007533775063896812 | validation: -0.00032200919677503046]
	TIME [epoch: 7.84 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003542989195340911		[learning rate: 0.00025674]
	Learning Rate: 0.000256736
	LOSS [training: -0.0003542989195340911 | validation: -0.0005850905922863175]
	TIME [epoch: 7.84 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008157126741638477		[learning rate: 0.00025613]
	Learning Rate: 0.000256131
	LOSS [training: -0.0008157126741638477 | validation: 0.0007019433457846893]
	TIME [epoch: 7.84 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003901858502050033		[learning rate: 0.00025553]
	Learning Rate: 0.000255527
	LOSS [training: -0.0003901858502050033 | validation: -0.0005878400057118451]
	TIME [epoch: 7.89 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000571703163148968		[learning rate: 0.00025492]
	Learning Rate: 0.000254924
	LOSS [training: -0.000571703163148968 | validation: -0.0006466547330111686]
	TIME [epoch: 7.84 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003645886072222928		[learning rate: 0.00025432]
	Learning Rate: 0.000254322
	LOSS [training: -0.0003645886072222928 | validation: 0.00013786226085885867]
	TIME [epoch: 7.84 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006888423795813874		[learning rate: 0.00025372]
	Learning Rate: 0.000253723
	LOSS [training: -0.0006888423795813874 | validation: -0.00024027022372091934]
	TIME [epoch: 7.84 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006324413487384519		[learning rate: 0.00025312]
	Learning Rate: 0.000253124
	LOSS [training: -0.0006324413487384519 | validation: -0.0006250355937256607]
	TIME [epoch: 7.84 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005883662255956662		[learning rate: 0.00025253]
	Learning Rate: 0.000252527
	LOSS [training: -0.0005883662255956662 | validation: -0.0005557502559831016]
	TIME [epoch: 7.89 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005905531868933036		[learning rate: 0.00025193]
	Learning Rate: 0.000251931
	LOSS [training: -0.0005905531868933036 | validation: -0.0011526499377750592]
	TIME [epoch: 7.84 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005620869467248203		[learning rate: 0.00025134]
	Learning Rate: 0.000251337
	LOSS [training: -0.0005620869467248203 | validation: -0.00011539918490350367]
	TIME [epoch: 7.84 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004915326125719592		[learning rate: 0.00025074]
	Learning Rate: 0.000250744
	LOSS [training: -0.0004915326125719592 | validation: -0.00029463181850791954]
	TIME [epoch: 7.84 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032890575657416513		[learning rate: 0.00025015]
	Learning Rate: 0.000250153
	LOSS [training: -0.00032890575657416513 | validation: -0.0008744609478831383]
	TIME [epoch: 7.84 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001962684142528381		[learning rate: 0.00024956]
	Learning Rate: 0.000249563
	LOSS [training: -0.0001962684142528381 | validation: -0.001323676950495003]
	TIME [epoch: 7.89 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015554898000952042		[learning rate: 0.00024897]
	Learning Rate: 0.000248974
	LOSS [training: 0.0015554898000952042 | validation: 0.0031233085890899743]
	TIME [epoch: 7.84 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002012039575470391		[learning rate: 0.00024839]
	Learning Rate: 0.000248387
	LOSS [training: 0.002012039575470391 | validation: 0.0011330759123243809]
	TIME [epoch: 7.84 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005784571104245182		[learning rate: 0.0002478]
	Learning Rate: 0.000247801
	LOSS [training: -0.0005784571104245182 | validation: -0.0003028484673002643]
	TIME [epoch: 7.84 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007847234393891168		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: -0.0007847234393891168 | validation: -0.0007074520994969778]
	TIME [epoch: 7.87 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005563870975301703		[learning rate: 0.00024663]
	Learning Rate: 0.000246633
	LOSS [training: -0.0005563870975301703 | validation: -0.0006342673074942717]
	TIME [epoch: 7.86 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008371317037927596		[learning rate: 0.00024605]
	Learning Rate: 0.000246051
	LOSS [training: -0.0008371317037927596 | validation: -8.542604907792661e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018631911627704727		[learning rate: 0.00024547]
	Learning Rate: 0.000245471
	LOSS [training: -0.00018631911627704727 | validation: 0.00019800781802671043]
	TIME [epoch: 7.84 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044756542172221897		[learning rate: 0.00024489]
	Learning Rate: 0.000244892
	LOSS [training: -0.00044756542172221897 | validation: 0.0005326938958294769]
	TIME [epoch: 7.84 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009249505281159772		[learning rate: 0.00024431]
	Learning Rate: 0.000244314
	LOSS [training: -0.0009249505281159772 | validation: -0.00041798119850306164]
	TIME [epoch: 7.89 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044196023482350724		[learning rate: 0.00024374]
	Learning Rate: 0.000243738
	LOSS [training: -0.00044196023482350724 | validation: 0.0002518824678263219]
	TIME [epoch: 7.85 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006745538032280616		[learning rate: 0.00024316]
	Learning Rate: 0.000243163
	LOSS [training: -0.0006745538032280616 | validation: -0.0004446165003181406]
	TIME [epoch: 7.84 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007857972433015581		[learning rate: 0.00024259]
	Learning Rate: 0.000242589
	LOSS [training: -0.0007857972433015581 | validation: -0.0006961268014044562]
	TIME [epoch: 7.84 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005082108926015019		[learning rate: 0.00024202]
	Learning Rate: 0.000242017
	LOSS [training: -0.0005082108926015019 | validation: -0.0005728330440336746]
	TIME [epoch: 7.84 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043810753851064566		[learning rate: 0.00024145]
	Learning Rate: 0.000241446
	LOSS [training: -0.00043810753851064566 | validation: -0.0009684050395253037]
	TIME [epoch: 7.89 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009019389327448255		[learning rate: 0.00024088]
	Learning Rate: 0.000240877
	LOSS [training: -0.0009019389327448255 | validation: -0.0003116125364467619]
	TIME [epoch: 7.84 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005649617632332692		[learning rate: 0.00024031]
	Learning Rate: 0.000240309
	LOSS [training: -0.0005649617632332692 | validation: -0.00035291958166103573]
	TIME [epoch: 7.84 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005073078531907751		[learning rate: 0.00023974]
	Learning Rate: 0.000239742
	LOSS [training: -0.0005073078531907751 | validation: 6.722469274060127e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007392994075065633		[learning rate: 0.00023918]
	Learning Rate: 0.000239176
	LOSS [training: -0.0007392994075065633 | validation: 0.00012509288051991072]
	TIME [epoch: 7.85 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.14091528939172e-05		[learning rate: 0.00023861]
	Learning Rate: 0.000238612
	LOSS [training: -8.14091528939172e-05 | validation: 0.00042347384560316925]
	TIME [epoch: 7.88 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00013293951592530974		[learning rate: 0.00023805]
	Learning Rate: 0.000238049
	LOSS [training: -0.00013293951592530974 | validation: -0.0008261148796392269]
	TIME [epoch: 7.84 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000787612106798352		[learning rate: 0.00023749]
	Learning Rate: 0.000237488
	LOSS [training: -0.000787612106798352 | validation: 0.0003016333870677941]
	TIME [epoch: 7.84 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035371571298276175		[learning rate: 0.00023693]
	Learning Rate: 0.000236927
	LOSS [training: -0.00035371571298276175 | validation: -0.0007364201147100902]
	TIME [epoch: 7.84 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008140355095286342		[learning rate: 0.00023637]
	Learning Rate: 0.000236369
	LOSS [training: -0.0008140355095286342 | validation: 9.083736054648473e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004976302353557376		[learning rate: 0.00023581]
	Learning Rate: 0.000235811
	LOSS [training: -0.0004976302353557376 | validation: -2.00764399103579e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008088037910655437		[learning rate: 0.00023525]
	Learning Rate: 0.000235255
	LOSS [training: -0.0008088037910655437 | validation: -0.0006048324494561803]
	TIME [epoch: 7.84 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008435890744765269		[learning rate: 0.0002347]
	Learning Rate: 0.0002347
	LOSS [training: -0.0008435890744765269 | validation: -0.000516989728536705]
	TIME [epoch: 7.84 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008223784912747784		[learning rate: 0.00023415]
	Learning Rate: 0.000234146
	LOSS [training: -0.0008223784912747784 | validation: -0.0003501525593182726]
	TIME [epoch: 7.84 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008364304020443303		[learning rate: 0.00023359]
	Learning Rate: 0.000233594
	LOSS [training: -0.0008364304020443303 | validation: -0.0004306070189616991]
	TIME [epoch: 7.9 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006854992897865555		[learning rate: 0.00023304]
	Learning Rate: 0.000233043
	LOSS [training: -0.0006854992897865555 | validation: -0.00045234283188897]
	TIME [epoch: 7.84 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000467695347070344		[learning rate: 0.00023249]
	Learning Rate: 0.000232493
	LOSS [training: -0.000467695347070344 | validation: -8.466649922349444e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010743064922258457		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: -0.0010743064922258457 | validation: 9.303806756833665e-05]
	TIME [epoch: 7.83 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008707977338647379		[learning rate: 0.0002314]
	Learning Rate: 0.000231398
	LOSS [training: -0.0008707977338647379 | validation: -2.0873568989616628e-05]
	TIME [epoch: 7.91 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007016622564138906		[learning rate: 0.00023085]
	Learning Rate: 0.000230852
	LOSS [training: -0.0007016622564138906 | validation: 0.0001699346606105161]
	TIME [epoch: 7.9 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009408265886178891		[learning rate: 0.00023031]
	Learning Rate: 0.000230307
	LOSS [training: -0.0009408265886178891 | validation: -0.0008029591607142548]
	TIME [epoch: 7.84 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006151091867392429		[learning rate: 0.00022976]
	Learning Rate: 0.000229764
	LOSS [training: -0.0006151091867392429 | validation: 0.0011105872292088983]
	TIME [epoch: 7.84 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.973531495635799e-05		[learning rate: 0.00022922]
	Learning Rate: 0.000229222
	LOSS [training: -4.973531495635799e-05 | validation: -0.0010228894030082296]
	TIME [epoch: 7.84 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005772417623333853		[learning rate: 0.00022868]
	Learning Rate: 0.000228681
	LOSS [training: -0.0005772417623333853 | validation: -0.00013561664962221886]
	TIME [epoch: 7.85 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005333123682474874		[learning rate: 0.00022814]
	Learning Rate: 0.000228142
	LOSS [training: -0.0005333123682474874 | validation: 0.00024878777012653865]
	TIME [epoch: 7.88 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008861910125884617		[learning rate: 0.0002276]
	Learning Rate: 0.000227604
	LOSS [training: -0.0008861910125884617 | validation: 0.001417249603171375]
	TIME [epoch: 7.84 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019373246523821263		[learning rate: 0.00022707]
	Learning Rate: 0.000227067
	LOSS [training: 0.00019373246523821263 | validation: -0.0008280389704260305]
	TIME [epoch: 7.84 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006115811084238362		[learning rate: 0.00022653]
	Learning Rate: 0.000226531
	LOSS [training: -0.0006115811084238362 | validation: -0.00013098627509730765]
	TIME [epoch: 7.84 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003714335824652204		[learning rate: 0.000226]
	Learning Rate: 0.000225997
	LOSS [training: -0.0003714335824652204 | validation: -0.0005635099675029785]
	TIME [epoch: 7.87 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.688726701449817e-05		[learning rate: 0.00022546]
	Learning Rate: 0.000225464
	LOSS [training: -3.688726701449817e-05 | validation: -0.0007738612185823555]
	TIME [epoch: 7.86 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011838829735425472		[learning rate: 0.00022493]
	Learning Rate: 0.000224932
	LOSS [training: -0.0011838829735425472 | validation: 6.358753231247994e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007509797540455033		[learning rate: 0.0002244]
	Learning Rate: 0.000224401
	LOSS [training: -0.0007509797540455033 | validation: -0.0006360273371202201]
	TIME [epoch: 7.84 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008919967544565126		[learning rate: 0.00022387]
	Learning Rate: 0.000223872
	LOSS [training: -0.0008919967544565126 | validation: -3.4591437292633495e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005424141670075039		[learning rate: 0.00022334]
	Learning Rate: 0.000223344
	LOSS [training: -0.0005424141670075039 | validation: -0.000497378606796957]
	TIME [epoch: 7.89 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004663029114603263		[learning rate: 0.00022282]
	Learning Rate: 0.000222817
	LOSS [training: -0.0004663029114603263 | validation: -0.00019159951121431007]
	TIME [epoch: 7.84 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005847723445866351		[learning rate: 0.00022229]
	Learning Rate: 0.000222292
	LOSS [training: -0.0005847723445866351 | validation: -0.0002565606689175719]
	TIME [epoch: 7.84 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040037291650278075		[learning rate: 0.00022177]
	Learning Rate: 0.000221767
	LOSS [training: -0.00040037291650278075 | validation: -0.0002956039460472777]
	TIME [epoch: 7.84 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003805069750883425		[learning rate: 0.00022124]
	Learning Rate: 0.000221244
	LOSS [training: -0.0003805069750883425 | validation: 0.0001717229534758267]
	TIME [epoch: 7.84 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005490706376718283		[learning rate: 0.00022072]
	Learning Rate: 0.000220722
	LOSS [training: -0.0005490706376718283 | validation: -0.000919886441144986]
	TIME [epoch: 7.89 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000570919049780134		[learning rate: 0.0002202]
	Learning Rate: 0.000220202
	LOSS [training: -0.000570919049780134 | validation: -0.0003850206971120063]
	TIME [epoch: 7.84 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010308691045377233		[learning rate: 0.00021968]
	Learning Rate: 0.000219682
	LOSS [training: -0.0010308691045377233 | validation: -0.0006961003993094059]
	TIME [epoch: 7.84 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008167327658549239		[learning rate: 0.00021916]
	Learning Rate: 0.000219164
	LOSS [training: -0.0008167327658549239 | validation: -0.0005986249659538316]
	TIME [epoch: 7.84 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005225352024708576		[learning rate: 0.00021865]
	Learning Rate: 0.000218647
	LOSS [training: -0.0005225352024708576 | validation: 8.73941542065313e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043034006255684184		[learning rate: 0.00021813]
	Learning Rate: 0.000218131
	LOSS [training: -0.00043034006255684184 | validation: 0.0003545017102405548]
	TIME [epoch: 7.88 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00024271757007181472		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: -0.00024271757007181472 | validation: 2.9619831641050532e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007146492669633745		[learning rate: 0.0002171]
	Learning Rate: 0.000217103
	LOSS [training: -0.0007146492669633745 | validation: -0.0007625653381995417]
	TIME [epoch: 7.84 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006971435342301484		[learning rate: 0.00021659]
	Learning Rate: 0.000216591
	LOSS [training: -0.0006971435342301484 | validation: 5.920930908685662e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007371019575885213		[learning rate: 0.00021608]
	Learning Rate: 0.00021608
	LOSS [training: -0.0007371019575885213 | validation: 0.0010385661459366604]
	TIME [epoch: 7.88 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006188958055994986		[learning rate: 0.00021557]
	Learning Rate: 0.000215571
	LOSS [training: -0.0006188958055994986 | validation: -0.0006485204669643188]
	TIME [epoch: 7.87 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010237227179802457		[learning rate: 0.00021506]
	Learning Rate: 0.000215062
	LOSS [training: -0.0010237227179802457 | validation: -0.0006848404493860736]
	TIME [epoch: 7.84 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006594567240708457		[learning rate: 0.00021455]
	Learning Rate: 0.000214555
	LOSS [training: -0.0006594567240708457 | validation: -0.0009973802620521029]
	TIME [epoch: 7.84 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000743941227940102		[learning rate: 0.00021405]
	Learning Rate: 0.000214049
	LOSS [training: -0.000743941227940102 | validation: -0.0002063202406347031]
	TIME [epoch: 7.84 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004573486978642292		[learning rate: 0.00021354]
	Learning Rate: 0.000213544
	LOSS [training: -0.0004573486978642292 | validation: 3.617652246244951e-05]
	TIME [epoch: 7.9 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007261991923391115		[learning rate: 0.00021304]
	Learning Rate: 0.00021304
	LOSS [training: -0.0007261991923391115 | validation: -0.0006756522133589923]
	TIME [epoch: 7.85 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007397478093828127		[learning rate: 0.00021254]
	Learning Rate: 0.000212538
	LOSS [training: -0.0007397478093828127 | validation: -9.294259945838058e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005209527891664601		[learning rate: 0.00021204]
	Learning Rate: 0.000212036
	LOSS [training: -0.0005209527891664601 | validation: -0.0007684032118223385]
	TIME [epoch: 7.83 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001142445052793732		[learning rate: 0.00021154]
	Learning Rate: 0.000211536
	LOSS [training: -0.001142445052793732 | validation: -0.00013943107706354893]
	TIME [epoch: 7.84 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007250186294722019		[learning rate: 0.00021104]
	Learning Rate: 0.000211037
	LOSS [training: -0.0007250186294722019 | validation: -0.00029081234149995396]
	TIME [epoch: 7.88 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000756116468366347		[learning rate: 0.00021054]
	Learning Rate: 0.000210539
	LOSS [training: -0.000756116468366347 | validation: -0.0005269915723336509]
	TIME [epoch: 7.84 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004648835262681519		[learning rate: 0.00021004]
	Learning Rate: 0.000210043
	LOSS [training: -0.0004648835262681519 | validation: 0.00022810790178176443]
	TIME [epoch: 7.83 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004453018395941668		[learning rate: 0.00020955]
	Learning Rate: 0.000209547
	LOSS [training: -0.0004453018395941668 | validation: 8.599624838645823e-05]
	TIME [epoch: 7.83 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002860656663313679		[learning rate: 0.00020905]
	Learning Rate: 0.000209053
	LOSS [training: -0.0002860656663313679 | validation: 0.00021622468719954748]
	TIME [epoch: 7.85 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4751971039988593e-05		[learning rate: 0.00020856]
	Learning Rate: 0.00020856
	LOSS [training: 1.4751971039988593e-05 | validation: -0.0007891054370509654]
	TIME [epoch: 7.86 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004498822099328299		[learning rate: 0.00020807]
	Learning Rate: 0.000208068
	LOSS [training: -0.0004498822099328299 | validation: -0.0002969439633261039]
	TIME [epoch: 7.86 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009950599014206059		[learning rate: 0.00020758]
	Learning Rate: 0.000207577
	LOSS [training: -0.0009950599014206059 | validation: -0.00014677301071283424]
	TIME [epoch: 7.84 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006789081600593332		[learning rate: 0.00020709]
	Learning Rate: 0.000207087
	LOSS [training: -0.0006789081600593332 | validation: -0.0010508945479321468]
	TIME [epoch: 7.83 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008409268304480611		[learning rate: 0.0002066]
	Learning Rate: 0.000206599
	LOSS [training: -0.0008409268304480611 | validation: -0.0005885939701515643]
	TIME [epoch: 7.87 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007246012821947582		[learning rate: 0.00020611]
	Learning Rate: 0.000206112
	LOSS [training: -0.0007246012821947582 | validation: -0.0009058080656314034]
	TIME [epoch: 7.85 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003526665593961509		[learning rate: 0.00020563]
	Learning Rate: 0.000205625
	LOSS [training: -0.0003526665593961509 | validation: 0.00021587182214123144]
	TIME [epoch: 7.83 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007235898735436408		[learning rate: 0.00020514]
	Learning Rate: 0.00020514
	LOSS [training: -0.0007235898735436408 | validation: -0.0007229327450078742]
	TIME [epoch: 7.83 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007474309174293527		[learning rate: 0.00020466]
	Learning Rate: 0.000204657
	LOSS [training: -0.0007474309174293527 | validation: -0.0004546732303595969]
	TIME [epoch: 7.83 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002578730714750832		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: -0.0002578730714750832 | validation: -0.0003442103131298806]
	TIME [epoch: 7.88 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008584076265610392		[learning rate: 0.00020369]
	Learning Rate: 0.000203692
	LOSS [training: -0.0008584076265610392 | validation: 0.00044436012797550187]
	TIME [epoch: 7.83 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.9810475778164737e-05		[learning rate: 0.00020321]
	Learning Rate: 0.000203212
	LOSS [training: -2.9810475778164737e-05 | validation: -9.130410318930257e-06]
	TIME [epoch: 7.83 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004598162628330591		[learning rate: 0.00020273]
	Learning Rate: 0.000202732
	LOSS [training: -0.0004598162628330591 | validation: 0.00013753771745238908]
	TIME [epoch: 7.84 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005073045927464886		[learning rate: 0.00020225]
	Learning Rate: 0.000202254
	LOSS [training: -0.0005073045927464886 | validation: -0.0006597827725626733]
	TIME [epoch: 7.86 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006019076969060507		[learning rate: 0.00020178]
	Learning Rate: 0.000201777
	LOSS [training: -0.0006019076969060507 | validation: -0.001011380387689775]
	TIME [epoch: 7.9 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047416904263232994		[learning rate: 0.0002013]
	Learning Rate: 0.000201301
	LOSS [training: -0.00047416904263232994 | validation: -0.0009570998408587692]
	TIME [epoch: 7.86 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007350651569952626		[learning rate: 0.00020083]
	Learning Rate: 0.000200826
	LOSS [training: -0.0007350651569952626 | validation: 0.0006958374045671275]
	TIME [epoch: 7.86 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000758264414100966		[learning rate: 0.00020035]
	Learning Rate: 0.000200353
	LOSS [training: -0.000758264414100966 | validation: -0.00015022197127153805]
	TIME [epoch: 7.86 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005474631489506717		[learning rate: 0.00019988]
	Learning Rate: 0.00019988
	LOSS [training: -0.0005474631489506717 | validation: 0.0001837802661003578]
	TIME [epoch: 7.93 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005618983738349418		[learning rate: 0.00019941]
	Learning Rate: 0.000199408
	LOSS [training: -0.0005618983738349418 | validation: 0.000979916855994862]
	TIME [epoch: 7.88 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011728373363043844		[learning rate: 0.00019894]
	Learning Rate: 0.000198938
	LOSS [training: -0.00011728373363043844 | validation: -0.0006316644172389717]
	TIME [epoch: 7.86 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005718819415561665		[learning rate: 0.00019847]
	Learning Rate: 0.000198469
	LOSS [training: -0.0005718819415561665 | validation: -0.0003352388275267009]
	TIME [epoch: 7.86 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007253799197749298		[learning rate: 0.000198]
	Learning Rate: 0.000198001
	LOSS [training: -0.0007253799197749298 | validation: -0.0003564669790936983]
	TIME [epoch: 7.86 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006735493055342847		[learning rate: 0.00019753]
	Learning Rate: 0.000197534
	LOSS [training: -0.0006735493055342847 | validation: -0.00031907377724358765]
	TIME [epoch: 7.9 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008809570889270846		[learning rate: 0.00019707]
	Learning Rate: 0.000197068
	LOSS [training: -0.0008809570889270846 | validation: -0.00044748695984938534]
	TIME [epoch: 7.86 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008069018047415028		[learning rate: 0.0001966]
	Learning Rate: 0.000196603
	LOSS [training: -0.0008069018047415028 | validation: -0.0008718705583041202]
	TIME [epoch: 7.86 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004594398459280884		[learning rate: 0.00019614]
	Learning Rate: 0.000196139
	LOSS [training: -0.0004594398459280884 | validation: -0.0005715439458988514]
	TIME [epoch: 7.86 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006091606714106943		[learning rate: 0.00019568]
	Learning Rate: 0.000195676
	LOSS [training: -0.0006091606714106943 | validation: -0.00019767469830295117]
	TIME [epoch: 7.86 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005486928305640068		[learning rate: 0.00019521]
	Learning Rate: 0.000195215
	LOSS [training: -0.0005486928305640068 | validation: 0.0003787423533859995]
	TIME [epoch: 7.91 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.806277853941638e-05		[learning rate: 0.00019475]
	Learning Rate: 0.000194754
	LOSS [training: -9.806277853941638e-05 | validation: -0.0005654150483219008]
	TIME [epoch: 7.86 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034567050306831337		[learning rate: 0.00019429]
	Learning Rate: 0.000194295
	LOSS [training: -0.00034567050306831337 | validation: 2.3344855894640303e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007510509827433284		[learning rate: 0.00019384]
	Learning Rate: 0.000193837
	LOSS [training: -0.0007510509827433284 | validation: 0.00017915242458606162]
	TIME [epoch: 7.86 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008022299359134336		[learning rate: 0.00019338]
	Learning Rate: 0.000193379
	LOSS [training: -0.0008022299359134336 | validation: -0.0004022629612768638]
	TIME [epoch: 7.87 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011282920523849067		[learning rate: 0.00019292]
	Learning Rate: 0.000192923
	LOSS [training: -0.00011282920523849067 | validation: -0.0005415830415071822]
	TIME [epoch: 7.9 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043524549164040895		[learning rate: 0.00019247]
	Learning Rate: 0.000192468
	LOSS [training: -0.00043524549164040895 | validation: -4.770682651855028e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006119187751181255		[learning rate: 0.00019201]
	Learning Rate: 0.000192014
	LOSS [training: -0.0006119187751181255 | validation: -0.0002836018288124036]
	TIME [epoch: 7.86 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004845480908061528		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: -0.0004845480908061528 | validation: -0.0005134876080796281]
	TIME [epoch: 7.86 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007445844143941244		[learning rate: 0.00019111]
	Learning Rate: 0.000191109
	LOSS [training: -0.0007445844143941244 | validation: -0.00023826453916728286]
	TIME [epoch: 7.9 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006579281005859403		[learning rate: 0.00019066]
	Learning Rate: 0.000190659
	LOSS [training: -0.0006579281005859403 | validation: -0.0008566523386723763]
	TIME [epoch: 7.88 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006201612095192255		[learning rate: 0.00019021]
	Learning Rate: 0.000190209
	LOSS [training: -0.0006201612095192255 | validation: -0.0005584846066803837]
	TIME [epoch: 7.86 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007007458471635322		[learning rate: 0.00018976]
	Learning Rate: 0.00018976
	LOSS [training: -0.0007007458471635322 | validation: -0.0015065023748241616]
	TIME [epoch: 7.86 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1729.pth
	Model improved!!!
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009890117779486269		[learning rate: 0.00018931]
	Learning Rate: 0.000189313
	LOSS [training: -0.0009890117779486269 | validation: 0.00014214735550519152]
	TIME [epoch: 7.86 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011875224015502539		[learning rate: 0.00018887]
	Learning Rate: 0.000188866
	LOSS [training: -0.00011875224015502539 | validation: -0.0005931370362803849]
	TIME [epoch: 7.91 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002612424610033485		[learning rate: 0.00018842]
	Learning Rate: 0.00018842
	LOSS [training: -0.0002612424610033485 | validation: -0.001095227799785964]
	TIME [epoch: 7.86 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004758412794797524		[learning rate: 0.00018798]
	Learning Rate: 0.000187976
	LOSS [training: -0.0004758412794797524 | validation: -0.0005661352839413705]
	TIME [epoch: 7.85 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000561591089866369		[learning rate: 0.00018753]
	Learning Rate: 0.000187533
	LOSS [training: -0.000561591089866369 | validation: -0.00013549398750868532]
	TIME [epoch: 7.86 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00108176445462649		[learning rate: 0.00018709]
	Learning Rate: 0.00018709
	LOSS [training: -0.00108176445462649 | validation: -0.0010281992080860304]
	TIME [epoch: 7.86 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001223107891054034		[learning rate: 0.00018665]
	Learning Rate: 0.000186649
	LOSS [training: -0.0001223107891054034 | validation: 0.0010919662139228913]
	TIME [epoch: 7.91 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002019520221570301		[learning rate: 0.00018621]
	Learning Rate: 0.000186209
	LOSS [training: -0.0002019520221570301 | validation: -0.0008801838945939755]
	TIME [epoch: 7.86 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006958192734866232		[learning rate: 0.00018577]
	Learning Rate: 0.000185769
	LOSS [training: -0.0006958192734866232 | validation: -0.0006015722395107384]
	TIME [epoch: 7.86 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007708313725193813		[learning rate: 0.00018533]
	Learning Rate: 0.000185331
	LOSS [training: -0.0007708313725193813 | validation: -6.42168894745883e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000538616162596663		[learning rate: 0.00018489]
	Learning Rate: 0.000184894
	LOSS [training: -0.000538616162596663 | validation: -0.0005683407035803403]
	TIME [epoch: 7.89 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005327442881727775		[learning rate: 0.00018446]
	Learning Rate: 0.000184458
	LOSS [training: -0.0005327442881727775 | validation: -0.0003665089876027432]
	TIME [epoch: 7.88 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046432822175042457		[learning rate: 0.00018402]
	Learning Rate: 0.000184023
	LOSS [training: -0.00046432822175042457 | validation: -0.0007466374820302778]
	TIME [epoch: 7.86 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005511266151850549		[learning rate: 0.00018359]
	Learning Rate: 0.000183589
	LOSS [training: -0.0005511266151850549 | validation: -0.0007384092899344062]
	TIME [epoch: 7.86 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007338279081051007		[learning rate: 0.00018316]
	Learning Rate: 0.000183156
	LOSS [training: -0.0007338279081051007 | validation: -0.0005213605877073891]
	TIME [epoch: 7.88 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007059422132242155		[learning rate: 0.00018272]
	Learning Rate: 0.000182724
	LOSS [training: -0.0007059422132242155 | validation: -0.0003158238001573937]
	TIME [epoch: 7.9 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010965666023919148		[learning rate: 0.00018229]
	Learning Rate: 0.000182293
	LOSS [training: -0.0010965666023919148 | validation: -0.0006074011279267313]
	TIME [epoch: 7.86 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015616920278226564		[learning rate: 0.00018186]
	Learning Rate: 0.000181863
	LOSS [training: 0.00015616920278226564 | validation: -0.00039269849482004467]
	TIME [epoch: 7.86 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000492368024059394		[learning rate: 0.00018143]
	Learning Rate: 0.000181434
	LOSS [training: -0.000492368024059394 | validation: -0.0009154220223622632]
	TIME [epoch: 7.85 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010953423074256952		[learning rate: 0.00018101]
	Learning Rate: 0.000181006
	LOSS [training: -0.0010953423074256952 | validation: -0.0008568183119987598]
	TIME [epoch: 7.86 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022856826867795685		[learning rate: 0.00018058]
	Learning Rate: 0.000180579
	LOSS [training: -0.00022856826867795685 | validation: -0.0004552288567622056]
	TIME [epoch: 7.91 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007851278305604611		[learning rate: 0.00018015]
	Learning Rate: 0.000180153
	LOSS [training: -0.0007851278305604611 | validation: 0.00024218245414691888]
	TIME [epoch: 7.86 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044442306882789564		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: -0.00044442306882789564 | validation: 0.00023822147807107009]
	TIME [epoch: 7.85 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008724480293381992		[learning rate: 0.0001793]
	Learning Rate: 0.000179304
	LOSS [training: -0.0008724480293381992 | validation: 0.0001268134088330579]
	TIME [epoch: 7.85 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006514988131411877		[learning rate: 0.00017888]
	Learning Rate: 0.000178881
	LOSS [training: -0.0006514988131411877 | validation: 0.0003326162403323512]
	TIME [epoch: 7.86 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002758907825810028		[learning rate: 0.00017846]
	Learning Rate: 0.000178459
	LOSS [training: 0.0002758907825810028 | validation: -0.000766269103920973]
	TIME [epoch: 7.89 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006093083415162217		[learning rate: 0.00017804]
	Learning Rate: 0.000178038
	LOSS [training: -0.0006093083415162217 | validation: -0.001112218787126833]
	TIME [epoch: 7.85 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007788867583909893		[learning rate: 0.00017762]
	Learning Rate: 0.000177618
	LOSS [training: -0.0007788867583909893 | validation: 8.877290843891224e-06]
	TIME [epoch: 7.85 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010425066461764835		[learning rate: 0.0001772]
	Learning Rate: 0.000177199
	LOSS [training: -0.0010425066461764835 | validation: -0.0005455278269335371]
	TIME [epoch: 7.85 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011861398745646751		[learning rate: 0.00017678]
	Learning Rate: 0.000176781
	LOSS [training: -0.0011861398745646751 | validation: -0.0004923809867550664]
	TIME [epoch: 7.89 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007564200020363043		[learning rate: 0.00017636]
	Learning Rate: 0.000176364
	LOSS [training: -0.0007564200020363043 | validation: -0.000928869692737595]
	TIME [epoch: 7.88 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005145370435115642		[learning rate: 0.00017595]
	Learning Rate: 0.000175948
	LOSS [training: -0.0005145370435115642 | validation: -0.0006190950143413727]
	TIME [epoch: 7.85 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009827848434537912		[learning rate: 0.00017553]
	Learning Rate: 0.000175533
	LOSS [training: -0.0009827848434537912 | validation: -0.00010463813353548139]
	TIME [epoch: 7.85 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004895641317878654		[learning rate: 0.00017512]
	Learning Rate: 0.000175119
	LOSS [training: -0.0004895641317878654 | validation: -0.00038716883771616663]
	TIME [epoch: 7.85 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007664489703287236		[learning rate: 0.00017471]
	Learning Rate: 0.000174706
	LOSS [training: -0.0007664489703287236 | validation: -0.0002038391328547089]
	TIME [epoch: 7.9 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006003773209027139		[learning rate: 0.00017429]
	Learning Rate: 0.000174294
	LOSS [training: -0.0006003773209027139 | validation: -0.00018644048739302742]
	TIME [epoch: 7.85 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.0208888366533715e-05		[learning rate: 0.00017388]
	Learning Rate: 0.000173883
	LOSS [training: -5.0208888366533715e-05 | validation: -0.0002842393308218707]
	TIME [epoch: 7.85 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006427910480054985		[learning rate: 0.00017347]
	Learning Rate: 0.000173473
	LOSS [training: -0.0006427910480054985 | validation: -0.00043290349799716445]
	TIME [epoch: 7.86 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007437899617083849		[learning rate: 0.00017306]
	Learning Rate: 0.000173063
	LOSS [training: -0.0007437899617083849 | validation: -0.0013302508173798412]
	TIME [epoch: 7.85 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00048107030646013136		[learning rate: 0.00017266]
	Learning Rate: 0.000172655
	LOSS [training: -0.00048107030646013136 | validation: 0.00023801410477892218]
	TIME [epoch: 7.9 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035642280664448874		[learning rate: 0.00017225]
	Learning Rate: 0.000172248
	LOSS [training: -0.00035642280664448874 | validation: -0.0004637985124080952]
	TIME [epoch: 7.85 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007979769092211666		[learning rate: 0.00017184]
	Learning Rate: 0.000171842
	LOSS [training: -0.0007979769092211666 | validation: -0.0002150877188935172]
	TIME [epoch: 7.85 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000669955814739734		[learning rate: 0.00017144]
	Learning Rate: 0.000171436
	LOSS [training: -0.000669955814739734 | validation: -0.00018322147953251159]
	TIME [epoch: 7.85 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007711445688035994		[learning rate: 0.00017103]
	Learning Rate: 0.000171032
	LOSS [training: -0.0007711445688035994 | validation: -0.0001434671912915992]
	TIME [epoch: 7.87 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007449550981362769		[learning rate: 0.00017063]
	Learning Rate: 0.000170628
	LOSS [training: -0.0007449550981362769 | validation: -0.00019186520919341454]
	TIME [epoch: 7.89 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007570695520618222		[learning rate: 0.00017023]
	Learning Rate: 0.000170226
	LOSS [training: -0.0007570695520618222 | validation: -0.0002939479880105136]
	TIME [epoch: 7.85 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008080870676954184		[learning rate: 0.00016982]
	Learning Rate: 0.000169824
	LOSS [training: -0.0008080870676954184 | validation: -5.982772020531125e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003914132533568473		[learning rate: 0.00016942]
	Learning Rate: 0.000169424
	LOSS [training: -0.0003914132533568473 | validation: 5.4371638951096214e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006801075266050642		[learning rate: 0.00016902]
	Learning Rate: 0.000169024
	LOSS [training: -0.0006801075266050642 | validation: -0.00016611907113147107]
	TIME [epoch: 7.89 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006764140279051509		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: -0.0006764140279051509 | validation: 5.127328220220397e-05]
	TIME [epoch: 7.87 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004031893919937506		[learning rate: 0.00016823]
	Learning Rate: 0.000168228
	LOSS [training: -0.0004031893919937506 | validation: -0.000542905500336651]
	TIME [epoch: 7.85 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006464420969536505		[learning rate: 0.00016783]
	Learning Rate: 0.000167831
	LOSS [training: -0.0006464420969536505 | validation: -9.797477917099283e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005078950562909275		[learning rate: 0.00016743]
	Learning Rate: 0.000167435
	LOSS [training: -0.0005078950562909275 | validation: -0.0004015346194642752]
	TIME [epoch: 7.85 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005227932545062036		[learning rate: 0.00016704]
	Learning Rate: 0.00016704
	LOSS [training: -0.0005227932545062036 | validation: -0.0007510976604768898]
	TIME [epoch: 7.91 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009583962310573571		[learning rate: 0.00016665]
	Learning Rate: 0.000166646
	LOSS [training: -0.0009583962310573571 | validation: -0.0009872988745741442]
	TIME [epoch: 7.85 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008166729367974741		[learning rate: 0.00016625]
	Learning Rate: 0.000166253
	LOSS [training: -0.0008166729367974741 | validation: 0.00012846176054548094]
	TIME [epoch: 7.85 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005485700713398226		[learning rate: 0.00016586]
	Learning Rate: 0.000165861
	LOSS [training: -0.0005485700713398226 | validation: -0.0006385676077377509]
	TIME [epoch: 7.85 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002970956232162097		[learning rate: 0.00016547]
	Learning Rate: 0.00016547
	LOSS [training: -0.0002970956232162097 | validation: -0.00020004273166535482]
	TIME [epoch: 7.86 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000605017111809517		[learning rate: 0.00016508]
	Learning Rate: 0.000165079
	LOSS [training: -0.000605017111809517 | validation: -0.0007868856012760884]
	TIME [epoch: 7.9 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008243045341793106		[learning rate: 0.00016469]
	Learning Rate: 0.00016469
	LOSS [training: -0.0008243045341793106 | validation: -0.0008183544030143426]
	TIME [epoch: 7.85 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009499180634006225		[learning rate: 0.0001643]
	Learning Rate: 0.000164301
	LOSS [training: -0.0009499180634006225 | validation: -0.001046071362152726]
	TIME [epoch: 7.86 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001679890763035663		[learning rate: 0.00016391]
	Learning Rate: 0.000163914
	LOSS [training: -0.0001679890763035663 | validation: 0.00020727742313904774]
	TIME [epoch: 7.85 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046253504317625893		[learning rate: 0.00016353]
	Learning Rate: 0.000163527
	LOSS [training: -0.00046253504317625893 | validation: 0.000391981414084555]
	TIME [epoch: 7.87 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.151858260894791e-05		[learning rate: 0.00016314]
	Learning Rate: 0.000163141
	LOSS [training: 4.151858260894791e-05 | validation: 0.00013154557968641755]
	TIME [epoch: 7.89 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004316865254842719		[learning rate: 0.00016276]
	Learning Rate: 0.000162757
	LOSS [training: -0.0004316865254842719 | validation: -0.000990456532520451]
	TIME [epoch: 7.85 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007648132787710469		[learning rate: 0.00016237]
	Learning Rate: 0.000162373
	LOSS [training: -0.0007648132787710469 | validation: 0.0002265819126333937]
	TIME [epoch: 7.85 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000718038063592477		[learning rate: 0.00016199]
	Learning Rate: 0.00016199
	LOSS [training: -0.000718038063592477 | validation: -1.3054618097117387e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003759801634311506		[learning rate: 0.00016161]
	Learning Rate: 0.000161608
	LOSS [training: -0.0003759801634311506 | validation: 0.00026785736172273736]
	TIME [epoch: 7.89 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006229352771131804		[learning rate: 0.00016123]
	Learning Rate: 0.000161226
	LOSS [training: -0.0006229352771131804 | validation: -0.0001626900354742422]
	TIME [epoch: 7.87 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007898855995837188		[learning rate: 0.00016085]
	Learning Rate: 0.000160846
	LOSS [training: -0.0007898855995837188 | validation: -0.0008581415879671943]
	TIME [epoch: 7.85 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007438145493377757		[learning rate: 0.00016047]
	Learning Rate: 0.000160467
	LOSS [training: -0.0007438145493377757 | validation: -0.0004538014741722556]
	TIME [epoch: 7.85 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011574138793341137		[learning rate: 0.00016009]
	Learning Rate: 0.000160088
	LOSS [training: -0.0011574138793341137 | validation: -0.00037501002571813346]
	TIME [epoch: 7.84 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007157672891627985		[learning rate: 0.00015971]
	Learning Rate: 0.00015971
	LOSS [training: -0.0007157672891627985 | validation: -0.0003937113014500415]
	TIME [epoch: 7.89 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006328203996883105		[learning rate: 0.00015933]
	Learning Rate: 0.000159334
	LOSS [training: -0.0006328203996883105 | validation: 8.691676902596648e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009788714854446071		[learning rate: 0.00015896]
	Learning Rate: 0.000158958
	LOSS [training: -0.0009788714854446071 | validation: -0.0005114994832575453]
	TIME [epoch: 7.85 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000686391047677965		[learning rate: 0.00015858]
	Learning Rate: 0.000158583
	LOSS [training: -0.000686391047677965 | validation: 0.00019427983947818505]
	TIME [epoch: 7.85 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007323085285796434		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: -0.0007323085285796434 | validation: 0.0001333997054910747]
	TIME [epoch: 7.86 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007165210604018645		[learning rate: 0.00015784]
	Learning Rate: 0.000157836
	LOSS [training: -0.0007165210604018645 | validation: -0.00028850064381139885]
	TIME [epoch: 7.88 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00036324924757469095		[learning rate: 0.00015746]
	Learning Rate: 0.000157463
	LOSS [training: -0.00036324924757469095 | validation: -0.0012751491001853985]
	TIME [epoch: 7.84 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010287686638798955		[learning rate: 0.00015709]
	Learning Rate: 0.000157092
	LOSS [training: -0.0010287686638798955 | validation: -0.00022790586480117052]
	TIME [epoch: 7.84 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000872317748765362		[learning rate: 0.00015672]
	Learning Rate: 0.000156721
	LOSS [training: -0.000872317748765362 | validation: -0.00040623662775035287]
	TIME [epoch: 7.84 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008007871504891824		[learning rate: 0.00015635]
	Learning Rate: 0.000156352
	LOSS [training: -0.0008007871504891824 | validation: -0.0009989844618812855]
	TIME [epoch: 7.87 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0013014208714222828		[learning rate: 0.00015598]
	Learning Rate: 0.000155983
	LOSS [training: -0.0013014208714222828 | validation: 0.0001491804548370337]
	TIME [epoch: 7.85 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003818903051211591		[learning rate: 0.00015561]
	Learning Rate: 0.000155615
	LOSS [training: -0.0003818903051211591 | validation: -0.0006394273817984884]
	TIME [epoch: 7.83 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008805762062727286		[learning rate: 0.00015525]
	Learning Rate: 0.000155248
	LOSS [training: -0.0008805762062727286 | validation: 7.900002287415696e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009268009384754828		[learning rate: 0.00015488]
	Learning Rate: 0.000154882
	LOSS [training: -0.0009268009384754828 | validation: 0.00024963320083070474]
	TIME [epoch: 7.83 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006814492934405217		[learning rate: 0.00015452]
	Learning Rate: 0.000154516
	LOSS [training: -0.0006814492934405217 | validation: -0.00032801481499524643]
	TIME [epoch: 7.89 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006694564116550771		[learning rate: 0.00015415]
	Learning Rate: 0.000154152
	LOSS [training: -0.0006694564116550771 | validation: -0.0011067337285719802]
	TIME [epoch: 7.84 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006861241310316764		[learning rate: 0.00015379]
	Learning Rate: 0.000153788
	LOSS [training: -0.0006861241310316764 | validation: -0.00042850367188012895]
	TIME [epoch: 7.83 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006121933016870917		[learning rate: 0.00015343]
	Learning Rate: 0.000153425
	LOSS [training: -0.0006121933016870917 | validation: -0.00026894875276416743]
	TIME [epoch: 7.83 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005595624065161103		[learning rate: 0.00015306]
	Learning Rate: 0.000153064
	LOSS [training: -0.0005595624065161103 | validation: -0.000823070807125038]
	TIME [epoch: 7.84 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008429927704337219		[learning rate: 0.0001527]
	Learning Rate: 0.000152703
	LOSS [training: -0.0008429927704337219 | validation: -0.0012128899799502993]
	TIME [epoch: 7.91 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001118052587367566		[learning rate: 0.00015234]
	Learning Rate: 0.000152342
	LOSS [training: -0.001118052587367566 | validation: -0.00010183903671705786]
	TIME [epoch: 7.84 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011016272855012238		[learning rate: 0.00015198]
	Learning Rate: 0.000151983
	LOSS [training: -0.0011016272855012238 | validation: -0.0008955645823603619]
	TIME [epoch: 7.83 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001025069729129679		[learning rate: 0.00015162]
	Learning Rate: 0.000151624
	LOSS [training: -0.001025069729129679 | validation: -0.0004931278353018063]
	TIME [epoch: 7.84 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015344996738522924		[learning rate: 0.00015127]
	Learning Rate: 0.000151267
	LOSS [training: -0.00015344996738522924 | validation: 4.958621303638867e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004908396747024353		[learning rate: 0.00015091]
	Learning Rate: 0.00015091
	LOSS [training: -0.0004908396747024353 | validation: -0.0013002541729903914]
	TIME [epoch: 7.87 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008120122390340382		[learning rate: 0.00015055]
	Learning Rate: 0.000150554
	LOSS [training: -0.0008120122390340382 | validation: -0.0007366295948817458]
	TIME [epoch: 7.83 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008711569400836812		[learning rate: 0.0001502]
	Learning Rate: 0.000150199
	LOSS [training: -0.0008711569400836812 | validation: -0.0009439969455322253]
	TIME [epoch: 7.84 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008693268131637304		[learning rate: 0.00014984]
	Learning Rate: 0.000149845
	LOSS [training: -0.0008693268131637304 | validation: -0.00041740108268203626]
	TIME [epoch: 7.84 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006155561159799637		[learning rate: 0.00014949]
	Learning Rate: 0.000149491
	LOSS [training: -0.0006155561159799637 | validation: -0.0007492381613311143]
	TIME [epoch: 7.88 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006094306005466231		[learning rate: 0.00014914]
	Learning Rate: 0.000149139
	LOSS [training: -0.0006094306005466231 | validation: 0.0002887289893801004]
	TIME [epoch: 7.86 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010307203991557158		[learning rate: 0.00014879]
	Learning Rate: 0.000148787
	LOSS [training: -0.0010307203991557158 | validation: -0.0003286487222196741]
	TIME [epoch: 7.84 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000770644822807447		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: -0.000770644822807447 | validation: 0.00013732862000070647]
	TIME [epoch: 7.84 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008518756799358336		[learning rate: 0.00014809]
	Learning Rate: 0.000148086
	LOSS [training: -0.0008518756799358336 | validation: -0.0007076681051851903]
	TIME [epoch: 7.84 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005309250343455569		[learning rate: 0.00014774]
	Learning Rate: 0.000147736
	LOSS [training: -0.0005309250343455569 | validation: 0.0001481860290485475]
	TIME [epoch: 7.9 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001808347487398765		[learning rate: 0.00014739]
	Learning Rate: 0.000147388
	LOSS [training: -0.0001808347487398765 | validation: -0.00043309552619936033]
	TIME [epoch: 7.84 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008138931115376113		[learning rate: 0.00014704]
	Learning Rate: 0.00014704
	LOSS [training: -0.0008138931115376113 | validation: -0.00024438538203571975]
	TIME [epoch: 7.84 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009619851230190042		[learning rate: 0.00014669]
	Learning Rate: 0.000146693
	LOSS [training: -0.0009619851230190042 | validation: 2.038149841314407e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046687667192647547		[learning rate: 0.00014635]
	Learning Rate: 0.000146347
	LOSS [training: -0.00046687667192647547 | validation: -0.000745613970370472]
	TIME [epoch: 7.85 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0012462363869339466		[learning rate: 0.000146]
	Learning Rate: 0.000146002
	LOSS [training: -0.0012462363869339466 | validation: -0.00021948137259815726]
	TIME [epoch: 7.89 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007126495506979551		[learning rate: 0.00014566]
	Learning Rate: 0.000145658
	LOSS [training: -0.0007126495506979551 | validation: -0.0006562184434530298]
	TIME [epoch: 7.84 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045737862066588364		[learning rate: 0.00014531]
	Learning Rate: 0.000145314
	LOSS [training: -0.00045737862066588364 | validation: 0.0004963926333179205]
	TIME [epoch: 7.84 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008416598203084004		[learning rate: 0.00014497]
	Learning Rate: 0.000144971
	LOSS [training: -0.0008416598203084004 | validation: -0.00034573824534046783]
	TIME [epoch: 7.84 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005002469282530628		[learning rate: 0.00014463]
	Learning Rate: 0.000144629
	LOSS [training: -0.0005002469282530628 | validation: 0.00014230336207183967]
	TIME [epoch: 7.85 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035388895738629157		[learning rate: 0.00014429]
	Learning Rate: 0.000144288
	LOSS [training: -0.00035388895738629157 | validation: -0.0006524403331711066]
	TIME [epoch: 7.88 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009150329504773238		[learning rate: 0.00014395]
	Learning Rate: 0.000143948
	LOSS [training: -0.0009150329504773238 | validation: 0.0004620542712159637]
	TIME [epoch: 7.84 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004486662797927001		[learning rate: 0.00014361]
	Learning Rate: 0.000143608
	LOSS [training: -0.0004486662797927001 | validation: 0.0001914810029987022]
	TIME [epoch: 7.84 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006166095043826692		[learning rate: 0.00014327]
	Learning Rate: 0.00014327
	LOSS [training: -0.0006166095043826692 | validation: -0.0011677800465798671]
	TIME [epoch: 7.84 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011462284961818287		[learning rate: 0.00014293]
	Learning Rate: 0.000142932
	LOSS [training: -0.0011462284961818287 | validation: -0.001263015004264793]
	TIME [epoch: 7.88 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008041078960364111		[learning rate: 0.00014259]
	Learning Rate: 0.000142594
	LOSS [training: -0.0008041078960364111 | validation: -0.0007816415956195835]
	TIME [epoch: 7.87 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008460949669512774		[learning rate: 0.00014226]
	Learning Rate: 0.000142258
	LOSS [training: -0.0008460949669512774 | validation: -0.0005712101526730997]
	TIME [epoch: 7.85 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007070595079860548		[learning rate: 0.00014192]
	Learning Rate: 0.000141923
	LOSS [training: -0.0007070595079860548 | validation: -0.00013014458074125823]
	TIME [epoch: 7.84 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008262497456721757		[learning rate: 0.00014159]
	Learning Rate: 0.000141588
	LOSS [training: -0.0008262497456721757 | validation: -0.00027800158545529774]
	TIME [epoch: 7.84 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006089745203126833		[learning rate: 0.00014125]
	Learning Rate: 0.000141254
	LOSS [training: -0.0006089745203126833 | validation: -0.0011497996103728707]
	TIME [epoch: 7.9 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001000982208026073		[learning rate: 0.00014092]
	Learning Rate: 0.000140921
	LOSS [training: -0.001000982208026073 | validation: -0.0006184592422391266]
	TIME [epoch: 7.85 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.162505690950117e-05		[learning rate: 0.00014059]
	Learning Rate: 0.000140588
	LOSS [training: -7.162505690950117e-05 | validation: -0.0006677640699632281]
	TIME [epoch: 7.84 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005447515087307045		[learning rate: 0.00014026]
	Learning Rate: 0.000140257
	LOSS [training: -0.0005447515087307045 | validation: -8.007895428547494e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007374988279730952		[learning rate: 0.00013993]
	Learning Rate: 0.000139926
	LOSS [training: -0.0007374988279730952 | validation: -0.00017559363487861603]
	TIME [epoch: 7.84 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010905592053915708		[learning rate: 0.0001396]
	Learning Rate: 0.000139596
	LOSS [training: -0.0010905592053915708 | validation: -0.0007188351687541514]
	TIME [epoch: 7.89 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000732080852749772		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: -0.000732080852749772 | validation: -0.0005865575990766855]
	TIME [epoch: 7.84 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011303617472936522		[learning rate: 0.00013894]
	Learning Rate: 0.000138938
	LOSS [training: -0.0011303617472936522 | validation: 0.00023935730526052806]
	TIME [epoch: 7.85 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008438882622967737		[learning rate: 0.00013861]
	Learning Rate: 0.00013861
	LOSS [training: -0.0008438882622967737 | validation: -0.0006747875163255822]
	TIME [epoch: 7.85 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005695602555601173		[learning rate: 0.00013828]
	Learning Rate: 0.000138283
	LOSS [training: -0.0005695602555601173 | validation: -7.772037807410426e-05]
	TIME [epoch: 7.86 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003683260970257187		[learning rate: 0.00013796]
	Learning Rate: 0.000137957
	LOSS [training: -0.0003683260970257187 | validation: -0.0006139321632638777]
	TIME [epoch: 7.87 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007813291896214911		[learning rate: 0.00013763]
	Learning Rate: 0.000137632
	LOSS [training: -0.0007813291896214911 | validation: -0.00041843953688327985]
	TIME [epoch: 7.84 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008542443659798771		[learning rate: 0.00013731]
	Learning Rate: 0.000137307
	LOSS [training: -0.0008542443659798771 | validation: 0.0002544708796441455]
	TIME [epoch: 7.84 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006991150076009962		[learning rate: 0.00013698]
	Learning Rate: 0.000136983
	LOSS [training: 0.0006991150076009962 | validation: 0.000600472832517883]
	TIME [epoch: 7.84 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.764945435726251e-05		[learning rate: 0.00013666]
	Learning Rate: 0.00013666
	LOSS [training: -3.764945435726251e-05 | validation: -0.0003013848062547977]
	TIME [epoch: 7.87 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007541190026040705		[learning rate: 0.00013634]
	Learning Rate: 0.000136338
	LOSS [training: -0.0007541190026040705 | validation: -0.0003129379414511227]
	TIME [epoch: 7.86 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007687242636524008		[learning rate: 0.00013602]
	Learning Rate: 0.000136016
	LOSS [training: -0.0007687242636524008 | validation: -0.00021199634831220487]
	TIME [epoch: 7.84 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005743296650538919		[learning rate: 0.0001357]
	Learning Rate: 0.000135695
	LOSS [training: -0.0005743296650538919 | validation: -0.00021388855164647234]
	TIME [epoch: 7.84 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006382500995332958		[learning rate: 0.00013538]
	Learning Rate: 0.000135375
	LOSS [training: -0.0006382500995332958 | validation: -0.0002435509186642402]
	TIME [epoch: 7.84 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005604449268251617		[learning rate: 0.00013506]
	Learning Rate: 0.000135056
	LOSS [training: -0.0005604449268251617 | validation: -0.0006618897183642253]
	TIME [epoch: 7.89 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004416424730165829		[learning rate: 0.00013474]
	Learning Rate: 0.000134737
	LOSS [training: -0.0004416424730165829 | validation: -0.0006806377412535821]
	TIME [epoch: 7.84 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003565785025429891		[learning rate: 0.00013442]
	Learning Rate: 0.000134419
	LOSS [training: -0.0003565785025429891 | validation: -0.0006361626530663682]
	TIME [epoch: 7.84 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009234471871354404		[learning rate: 0.0001341]
	Learning Rate: 0.000134102
	LOSS [training: -0.0009234471871354404 | validation: -0.0005732496016912299]
	TIME [epoch: 7.84 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000720591123966988		[learning rate: 0.00013379]
	Learning Rate: 0.000133786
	LOSS [training: -0.000720591123966988 | validation: -0.00019658744914991734]
	TIME [epoch: 7.85 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007383687676831457		[learning rate: 0.00013347]
	Learning Rate: 0.00013347
	LOSS [training: -0.0007383687676831457 | validation: -0.0008298343276602967]
	TIME [epoch: 7.89 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008335990140606226		[learning rate: 0.00013316]
	Learning Rate: 0.000133155
	LOSS [training: -0.0008335990140606226 | validation: 4.481979234685786e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006266762052566419		[learning rate: 0.00013284]
	Learning Rate: 0.000132841
	LOSS [training: -0.0006266762052566419 | validation: -0.00038539445815756457]
	TIME [epoch: 7.84 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.0125757421176416e-05		[learning rate: 0.00013253]
	Learning Rate: 0.000132528
	LOSS [training: -5.0125757421176416e-05 | validation: -7.811426296216428e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008886270885557594		[learning rate: 0.00013222]
	Learning Rate: 0.000132215
	LOSS [training: -0.0008886270885557594 | validation: 8.925451851510768e-05]
	TIME [epoch: 7.88 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019580344280986628		[learning rate: 0.0001319]
	Learning Rate: 0.000131904
	LOSS [training: -0.00019580344280986628 | validation: -0.0010305215186390136]
	TIME [epoch: 7.86 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005510076571088047		[learning rate: 0.00013159]
	Learning Rate: 0.000131592
	LOSS [training: -0.0005510076571088047 | validation: -0.000462941392074939]
	TIME [epoch: 7.84 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000852096779930335		[learning rate: 0.00013128]
	Learning Rate: 0.000131282
	LOSS [training: -0.000852096779930335 | validation: -0.0005051063542505579]
	TIME [epoch: 7.84 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.327655719380566e-05		[learning rate: 0.00013097]
	Learning Rate: 0.000130972
	LOSS [training: -7.327655719380566e-05 | validation: -0.00033016519037781003]
	TIME [epoch: 7.84 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010084226791984697		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: -0.0010084226791984697 | validation: -0.0008162251604649721]
	TIME [epoch: 7.89 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007902222575249152		[learning rate: 0.00013036]
	Learning Rate: 0.000130355
	LOSS [training: -0.0007902222575249152 | validation: -0.0007302187942138051]
	TIME [epoch: 7.86 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004423110617900852		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: -0.0004423110617900852 | validation: -0.0005110275244743572]
	TIME [epoch: 7.84 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008949089430079082		[learning rate: 0.00012974]
	Learning Rate: 0.000129741
	LOSS [training: -0.0008949089430079082 | validation: -0.0008123973811794479]
	TIME [epoch: 7.84 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005424203680159074		[learning rate: 0.00012943]
	Learning Rate: 0.000129435
	LOSS [training: -0.0005424203680159074 | validation: -0.000489516029269807]
	TIME [epoch: 7.84 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007672390530636691		[learning rate: 0.00012913]
	Learning Rate: 0.00012913
	LOSS [training: -0.0007672390530636691 | validation: 0.0006119527775172533]
	TIME [epoch: 7.91 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.736211414365998e-05		[learning rate: 0.00012882]
	Learning Rate: 0.000128825
	LOSS [training: -3.736211414365998e-05 | validation: -0.0005007111426278143]
	TIME [epoch: 7.85 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003170165978073434		[learning rate: 0.00012852]
	Learning Rate: 0.000128521
	LOSS [training: -0.0003170165978073434 | validation: -0.00040584652299717347]
	TIME [epoch: 7.85 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047057685249207883		[learning rate: 0.00012822]
	Learning Rate: 0.000128218
	LOSS [training: -0.00047057685249207883 | validation: -0.000580333034715121]
	TIME [epoch: 7.85 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007218988736066042		[learning rate: 0.00012792]
	Learning Rate: 0.000127915
	LOSS [training: -0.0007218988736066042 | validation: -0.0005511570245106511]
	TIME [epoch: 7.85 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008651098395579344		[learning rate: 0.00012761]
	Learning Rate: 0.000127614
	LOSS [training: -0.0008651098395579344 | validation: -0.0006724802153526324]
	TIME [epoch: 7.9 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006187501094214642		[learning rate: 0.00012731]
	Learning Rate: 0.000127313
	LOSS [training: -0.0006187501094214642 | validation: -0.0005017454488217919]
	TIME [epoch: 7.85 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010310014195520191		[learning rate: 0.00012701]
	Learning Rate: 0.000127012
	LOSS [training: -0.0010310014195520191 | validation: -0.0005970253764124584]
	TIME [epoch: 7.85 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005111047222553053		[learning rate: 0.00012671]
	Learning Rate: 0.000126713
	LOSS [training: -0.0005111047222553053 | validation: -0.00047106984837981883]
	TIME [epoch: 7.85 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004842575360570352		[learning rate: 0.00012641]
	Learning Rate: 0.000126414
	LOSS [training: -0.0004842575360570352 | validation: -0.00040808837459834814]
	TIME [epoch: 7.89 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010546087828472099		[learning rate: 0.00012612]
	Learning Rate: 0.000126116
	LOSS [training: -0.0010546087828472099 | validation: 0.0003609383637769157]
	TIME [epoch: 7.86 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007265199982502699		[learning rate: 0.00012582]
	Learning Rate: 0.000125818
	LOSS [training: -0.0007265199982502699 | validation: 0.0003669789594207145]
	TIME [epoch: 7.84 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005755223370976616		[learning rate: 0.00012552]
	Learning Rate: 0.000125521
	LOSS [training: -0.0005755223370976616 | validation: -0.000652362445081705]
	TIME [epoch: 7.84 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006474258620428357		[learning rate: 0.00012523]
	Learning Rate: 0.000125225
	LOSS [training: -0.0006474258620428357 | validation: -0.001583912970278828]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1905.pth
	Model improved!!!
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001021354993263138		[learning rate: 0.00012493]
	Learning Rate: 0.00012493
	LOSS [training: -0.001021354993263138 | validation: -1.410219255108648e-05]
	TIME [epoch: 7.89 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009064818169652173		[learning rate: 0.00012464]
	Learning Rate: 0.000124635
	LOSS [training: -0.0009064818169652173 | validation: -0.00020964144281353735]
	TIME [epoch: 7.84 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007977869452049642		[learning rate: 0.00012434]
	Learning Rate: 0.000124341
	LOSS [training: -0.0007977869452049642 | validation: -0.0007667663084257113]
	TIME [epoch: 7.83 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006818100495228174		[learning rate: 0.00012405]
	Learning Rate: 0.000124048
	LOSS [training: -0.0006818100495228174 | validation: -8.217396383217488e-06]
	TIME [epoch: 7.84 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006924840799695053		[learning rate: 0.00012376]
	Learning Rate: 0.000123755
	LOSS [training: -0.0006924840799695053 | validation: -0.0005163010519125013]
	TIME [epoch: 7.84 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007963694414315436		[learning rate: 0.00012346]
	Learning Rate: 0.000123463
	LOSS [training: -0.0007963694414315436 | validation: -0.0009501806521714878]
	TIME [epoch: 7.88 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007865539811269405		[learning rate: 0.00012317]
	Learning Rate: 0.000123172
	LOSS [training: -0.0007865539811269405 | validation: -0.0003788114606585977]
	TIME [epoch: 7.84 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.259572717927256e-05		[learning rate: 0.00012288]
	Learning Rate: 0.000122882
	LOSS [training: -9.259572717927256e-05 | validation: -0.000621388595630263]
	TIME [epoch: 7.84 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006703313965919607		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: -0.0006703313965919607 | validation: -0.00021598812914369248]
	TIME [epoch: 7.84 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000997087555612075		[learning rate: 0.0001223]
	Learning Rate: 0.000122303
	LOSS [training: -0.000997087555612075 | validation: -0.0006594214548413388]
	TIME [epoch: 7.87 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007326073975040109		[learning rate: 0.00012201]
	Learning Rate: 0.000122014
	LOSS [training: -0.0007326073975040109 | validation: -0.0007149326635072048]
	TIME [epoch: 7.86 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007912278814337595		[learning rate: 0.00012173]
	Learning Rate: 0.000121726
	LOSS [training: -0.0007912278814337595 | validation: -0.000656043563728705]
	TIME [epoch: 7.84 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007750313440659615		[learning rate: 0.00012144]
	Learning Rate: 0.000121439
	LOSS [training: -0.0007750313440659615 | validation: 6.23958854679363e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005209839227276376		[learning rate: 0.00012115]
	Learning Rate: 0.000121153
	LOSS [training: -0.0005209839227276376 | validation: -0.00039351699760574823]
	TIME [epoch: 7.84 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008371441716241244		[learning rate: 0.00012087]
	Learning Rate: 0.000120867
	LOSS [training: -0.0008371441716241244 | validation: -0.0003695255826240977]
	TIME [epoch: 7.88 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00038845600606999577		[learning rate: 0.00012058]
	Learning Rate: 0.000120582
	LOSS [training: -0.00038845600606999577 | validation: -0.00019479564241584724]
	TIME [epoch: 7.85 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010600122580076124		[learning rate: 0.0001203]
	Learning Rate: 0.000120297
	LOSS [training: -0.0010600122580076124 | validation: -0.0007081982573352432]
	TIME [epoch: 7.84 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004367017550055625		[learning rate: 0.00012001]
	Learning Rate: 0.000120014
	LOSS [training: -0.0004367017550055625 | validation: -0.00030503671208640434]
	TIME [epoch: 7.84 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001105343019957505		[learning rate: 0.00011973]
	Learning Rate: 0.000119731
	LOSS [training: -0.001105343019957505 | validation: -0.0005530642489874853]
	TIME [epoch: 7.84 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010083114769261297		[learning rate: 0.00011945]
	Learning Rate: 0.000119448
	LOSS [training: -0.0010083114769261297 | validation: 0.0008777859887075375]
	TIME [epoch: 7.89 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007421618316812455		[learning rate: 0.00011917]
	Learning Rate: 0.000119166
	LOSS [training: -0.0007421618316812455 | validation: -0.00013591972230770868]
	TIME [epoch: 7.85 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006290723669763456		[learning rate: 0.00011889]
	Learning Rate: 0.000118885
	LOSS [training: -0.0006290723669763456 | validation: 0.0020762190122416584]
	TIME [epoch: 7.84 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014366122668376161		[learning rate: 0.0001186]
	Learning Rate: 0.000118605
	LOSS [training: 0.0014366122668376161 | validation: 0.0010864225751902135]
	TIME [epoch: 7.84 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004344473369441637		[learning rate: 0.00011833]
	Learning Rate: 0.000118325
	LOSS [training: -0.0004344473369441637 | validation: -0.00030071022083144296]
	TIME [epoch: 7.84 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007642663542962011		[learning rate: 0.00011805]
	Learning Rate: 0.000118046
	LOSS [training: -0.0007642663542962011 | validation: -0.00011439523173226897]
	TIME [epoch: 7.89 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006951528119985273		[learning rate: 0.00011777]
	Learning Rate: 0.000117768
	LOSS [training: -0.0006951528119985273 | validation: 0.0007067397587103326]
	TIME [epoch: 7.83 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010548396963458656		[learning rate: 0.00011749]
	Learning Rate: 0.00011749
	LOSS [training: -0.0010548396963458656 | validation: 0.00028096452556190864]
	TIME [epoch: 7.84 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000736255029774119		[learning rate: 0.00011721]
	Learning Rate: 0.000117213
	LOSS [training: -0.000736255029774119 | validation: -0.0004273815801649943]
	TIME [epoch: 7.84 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008971477512833898		[learning rate: 0.00011694]
	Learning Rate: 0.000116936
	LOSS [training: -0.0008971477512833898 | validation: -0.0001304113482726259]
	TIME [epoch: 7.87 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005522599073440788		[learning rate: 0.00011666]
	Learning Rate: 0.00011666
	LOSS [training: -0.0005522599073440788 | validation: -0.00021013718806214902]
	TIME [epoch: 7.86 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006955641876675036		[learning rate: 0.00011639]
	Learning Rate: 0.000116385
	LOSS [training: -0.0006955641876675036 | validation: -0.0005153971129061405]
	TIME [epoch: 7.84 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009825695708544253		[learning rate: 0.00011611]
	Learning Rate: 0.000116111
	LOSS [training: -0.0009825695708544253 | validation: -0.00014571832215244207]
	TIME [epoch: 7.84 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006258550534202068		[learning rate: 0.00011584]
	Learning Rate: 0.000115837
	LOSS [training: -0.0006258550534202068 | validation: 0.001218641441925711]
	TIME [epoch: 7.84 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.5330022554250517e-06		[learning rate: 0.00011556]
	Learning Rate: 0.000115563
	LOSS [training: -2.5330022554250517e-06 | validation: -9.790535454049466e-05]
	TIME [epoch: 7.88 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006519753155127721		[learning rate: 0.00011529]
	Learning Rate: 0.000115291
	LOSS [training: -0.0006519753155127721 | validation: -0.00025487143172785664]
	TIME [epoch: 7.85 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006137405971044399		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: -0.0006137405971044399 | validation: -0.00043559767018333686]
	TIME [epoch: 7.84 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007629037867681414		[learning rate: 0.00011475]
	Learning Rate: 0.000114748
	LOSS [training: -0.0007629037867681414 | validation: 6.516185309155987e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008565015569928451		[learning rate: 0.00011448]
	Learning Rate: 0.000114477
	LOSS [training: -0.0008565015569928451 | validation: -0.0001590434817539026]
	TIME [epoch: 7.84 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006257811074263653		[learning rate: 0.00011421]
	Learning Rate: 0.000114207
	LOSS [training: -0.0006257811074263653 | validation: -0.0012430036489703676]
	TIME [epoch: 7.89 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008698469782125395		[learning rate: 0.00011394]
	Learning Rate: 0.000113938
	LOSS [training: -0.0008698469782125395 | validation: -0.0004262457730444651]
	TIME [epoch: 7.84 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010240183102800812		[learning rate: 0.00011367]
	Learning Rate: 0.000113669
	LOSS [training: -0.0010240183102800812 | validation: -0.0010605395843264964]
	TIME [epoch: 7.84 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008742487259396367		[learning rate: 0.0001134]
	Learning Rate: 0.000113401
	LOSS [training: -0.0008742487259396367 | validation: 0.00023512551335635925]
	TIME [epoch: 7.85 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000691185972554818		[learning rate: 0.00011313]
	Learning Rate: 0.000113133
	LOSS [training: -0.000691185972554818 | validation: -0.0005179455701447692]
	TIME [epoch: 7.85 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001639356542143089		[learning rate: 0.00011287]
	Learning Rate: 0.000112866
	LOSS [training: -0.0001639356542143089 | validation: -0.00042680700359662275]
	TIME [epoch: 7.89 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009083162573264264		[learning rate: 0.0001126]
	Learning Rate: 0.0001126
	LOSS [training: -0.0009083162573264264 | validation: -0.00032436991366030374]
	TIME [epoch: 7.84 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006915395999904144		[learning rate: 0.00011233]
	Learning Rate: 0.000112334
	LOSS [training: -0.0006915395999904144 | validation: -0.0007082472372161348]
	TIME [epoch: 7.84 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009698938029435502		[learning rate: 0.00011207]
	Learning Rate: 0.000112069
	LOSS [training: -0.0009698938029435502 | validation: -0.0003696429433436386]
	TIME [epoch: 7.84 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001155480133075122		[learning rate: 0.00011181]
	Learning Rate: 0.000111805
	LOSS [training: -0.001155480133075122 | validation: -0.0009531067361585874]
	TIME [epoch: 7.88 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008805527854508095		[learning rate: 0.00011154]
	Learning Rate: 0.000111541
	LOSS [training: -0.0008805527854508095 | validation: -0.0006549751985903604]
	TIME [epoch: 7.86 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008047701388056679		[learning rate: 0.00011128]
	Learning Rate: 0.000111278
	LOSS [training: -0.0008047701388056679 | validation: -0.0011152910447243128]
	TIME [epoch: 7.84 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005509969274879439		[learning rate: 0.00011102]
	Learning Rate: 0.000111016
	LOSS [training: -0.0005509969274879439 | validation: -0.00010140056876551374]
	TIME [epoch: 7.84 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007766498334205215		[learning rate: 0.00011075]
	Learning Rate: 0.000110754
	LOSS [training: -0.0007766498334205215 | validation: -0.00048640346337716124]
	TIME [epoch: 7.84 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005421089584805563		[learning rate: 0.00011049]
	Learning Rate: 0.000110493
	LOSS [training: -0.0005421089584805563 | validation: -0.0006361413636826403]
	TIME [epoch: 7.89 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007194507551812655		[learning rate: 0.00011023]
	Learning Rate: 0.000110232
	LOSS [training: -0.0007194507551812655 | validation: -0.0007944051816150219]
	TIME [epoch: 7.84 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008383348317014705		[learning rate: 0.00010997]
	Learning Rate: 0.000109972
	LOSS [training: -0.0008383348317014705 | validation: -3.6857353892325576e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007422003785908795		[learning rate: 0.00010971]
	Learning Rate: 0.000109713
	LOSS [training: -0.0007422003785908795 | validation: -0.00020507320752281456]
	TIME [epoch: 7.85 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003867234182683588		[learning rate: 0.00010945]
	Learning Rate: 0.000109454
	LOSS [training: -0.0003867234182683588 | validation: -0.0001004195242045394]
	TIME [epoch: 7.85 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009730126060094324		[learning rate: 0.0001092]
	Learning Rate: 0.000109196
	LOSS [training: -0.0009730126060094324 | validation: -0.001883968070155089]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240523_093008/states/model_phi2_1a_v_mmd1_1963.pth
	Model improved!!!
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006588614138904664		[learning rate: 0.00010894]
	Learning Rate: 0.000108938
	LOSS [training: -0.0006588614138904664 | validation: -0.00011827207622735659]
	TIME [epoch: 7.84 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010790837622117124		[learning rate: 0.00010868]
	Learning Rate: 0.000108681
	LOSS [training: -0.0010790837622117124 | validation: -0.0011148836135178976]
	TIME [epoch: 7.84 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011445379062030281		[learning rate: 0.00010842]
	Learning Rate: 0.000108425
	LOSS [training: -0.0011445379062030281 | validation: -0.0008616484102555914]
	TIME [epoch: 7.83 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007142838770302773		[learning rate: 0.00010817]
	Learning Rate: 0.000108169
	LOSS [training: -0.0007142838770302773 | validation: -0.0005341763524151144]
	TIME [epoch: 7.86 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011855561566931536		[learning rate: 0.00010791]
	Learning Rate: 0.000107914
	LOSS [training: -0.0011855561566931536 | validation: -0.000458576933493319]
	TIME [epoch: 7.87 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001905734449076326		[learning rate: 0.00010766]
	Learning Rate: 0.000107659
	LOSS [training: 0.0001905734449076326 | validation: -0.0005455225632467271]
	TIME [epoch: 7.85 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007066703165067529		[learning rate: 0.00010741]
	Learning Rate: 0.000107405
	LOSS [training: -0.0007066703165067529 | validation: 0.0007857001514111096]
	TIME [epoch: 7.83 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008753807141678922		[learning rate: 0.00010715]
	Learning Rate: 0.000107152
	LOSS [training: -0.0008753807141678922 | validation: -0.00022061073047163228]
	TIME [epoch: 7.84 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000720745555977935		[learning rate: 0.0001069]
	Learning Rate: 0.000106899
	LOSS [training: -0.000720745555977935 | validation: 0.00041798139306073966]
	TIME [epoch: 7.88 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006259672941837373		[learning rate: 0.00010665]
	Learning Rate: 0.000106647
	LOSS [training: -0.0006259672941837373 | validation: -0.00021243065468512732]
	TIME [epoch: 7.85 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0012177773632566305		[learning rate: 0.0001064]
	Learning Rate: 0.000106395
	LOSS [training: -0.0012177773632566305 | validation: 1.5211776314305592e-05]
	TIME [epoch: 7.84 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001017363518364499		[learning rate: 0.00010614]
	Learning Rate: 0.000106145
	LOSS [training: -0.001017363518364499 | validation: -0.0014322433164254034]
	TIME [epoch: 7.84 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008799898350771946		[learning rate: 0.00010589]
	Learning Rate: 0.000105894
	LOSS [training: -0.0008799898350771946 | validation: 0.0004413773844446704]
	TIME [epoch: 7.84 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007976702443175743		[learning rate: 0.00010564]
	Learning Rate: 0.000105644
	LOSS [training: -0.0007976702443175743 | validation: -0.0013060716613312495]
	TIME [epoch: 7.88 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005634579319801449		[learning rate: 0.0001054]
	Learning Rate: 0.000105395
	LOSS [training: -0.0005634579319801449 | validation: 7.191372837195597e-05]
	TIME [epoch: 7.85 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008434089478264984		[learning rate: 0.00010515]
	Learning Rate: 0.000105147
	LOSS [training: -0.0008434089478264984 | validation: -0.0010037796663682462]
	TIME [epoch: 7.84 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00031251048214235897		[learning rate: 0.0001049]
	Learning Rate: 0.000104899
	LOSS [training: -0.00031251048214235897 | validation: -0.0002610503894057268]
	TIME [epoch: 7.84 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041360208099908835		[learning rate: 0.00010465]
	Learning Rate: 0.000104651
	LOSS [training: -0.00041360208099908835 | validation: -0.0006483965287466793]
	TIME [epoch: 7.84 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039581226996658733		[learning rate: 0.0001044]
	Learning Rate: 0.000104404
	LOSS [training: -0.00039581226996658733 | validation: -0.0012399092721314933]
	TIME [epoch: 7.89 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007920319968715684		[learning rate: 0.00010416]
	Learning Rate: 0.000104158
	LOSS [training: -0.0007920319968715684 | validation: -0.0003507296693538531]
	TIME [epoch: 7.84 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009195453526434492		[learning rate: 0.00010391]
	Learning Rate: 0.000103912
	LOSS [training: -0.0009195453526434492 | validation: -0.0008770354731464712]
	TIME [epoch: 7.84 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007831868085502031		[learning rate: 0.00010367]
	Learning Rate: 0.000103667
	LOSS [training: -0.0007831868085502031 | validation: -0.0011302835597533942]
	TIME [epoch: 7.85 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009856568513636832		[learning rate: 0.00010342]
	Learning Rate: 0.000103423
	LOSS [training: -0.0009856568513636832 | validation: -0.0002728309142305005]
	TIME [epoch: 7.87 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007467238323715225		[learning rate: 0.00010318]
	Learning Rate: 0.000103179
	LOSS [training: -0.0007467238323715225 | validation: -0.0004772834592017051]
	TIME [epoch: 7.87 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022595136582905442		[learning rate: 0.00010294]
	Learning Rate: 0.000102935
	LOSS [training: -0.00022595136582905442 | validation: -0.0006009863420807924]
	TIME [epoch: 7.84 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004956934896507277		[learning rate: 0.00010269]
	Learning Rate: 0.000102692
	LOSS [training: -0.0004956934896507277 | validation: -0.0011534592024820384]
	TIME [epoch: 7.84 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000427737236286069		[learning rate: 0.00010245]
	Learning Rate: 0.00010245
	LOSS [training: -0.000427737236286069 | validation: -0.0005556825642451027]
	TIME [epoch: 7.85 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010333322086351288		[learning rate: 0.00010221]
	Learning Rate: 0.000102209
	LOSS [training: -0.0010333322086351288 | validation: -0.0007304873960106604]
	TIME [epoch: 7.89 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008745160395404819		[learning rate: 0.00010197]
	Learning Rate: 0.000101967
	LOSS [training: -0.0008745160395404819 | validation: 0.00013662450512039068]
	TIME [epoch: 7.86 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001006705271963506		[learning rate: 0.00010173]
	Learning Rate: 0.000101727
	LOSS [training: -0.001006705271963506 | validation: 0.0004854906580185183]
	TIME [epoch: 7.84 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007785479771184432		[learning rate: 0.00010149]
	Learning Rate: 0.000101487
	LOSS [training: -0.0007785479771184432 | validation: 0.00030379585407046153]
	TIME [epoch: 7.84 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005837329013664847		[learning rate: 0.00010125]
	Learning Rate: 0.000101248
	LOSS [training: -0.0005837329013664847 | validation: 0.0002481815091513595]
	TIME [epoch: 7.86 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007250181969368781		[learning rate: 0.00010101]
	Learning Rate: 0.000101009
	LOSS [training: -0.0007250181969368781 | validation: 6.782578050145062e-05]
	TIME [epoch: 7.9 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046985324276357574		[learning rate: 0.00010077]
	Learning Rate: 0.000100771
	LOSS [training: -0.00046985324276357574 | validation: -0.0005539946809617562]
	TIME [epoch: 7.85 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002358118527218931		[learning rate: 0.00010053]
	Learning Rate: 0.000100533
	LOSS [training: -0.0002358118527218931 | validation: -0.0006647241879817276]
	TIME [epoch: 7.85 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008320061419631908		[learning rate: 0.0001003]
	Learning Rate: 0.000100296
	LOSS [training: -0.0008320061419631908 | validation: -0.0003979930632482698]
	TIME [epoch: 7.84 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010520320298438423		[learning rate: 0.00010006]
	Learning Rate: 0.000100059
	LOSS [training: -0.0010520320298438423 | validation: -0.0005270948316177124]
	TIME [epoch: 7.85 sec]
Finished training in 15994.298 seconds.
