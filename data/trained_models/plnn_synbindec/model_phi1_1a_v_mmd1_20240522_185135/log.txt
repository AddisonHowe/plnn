Args:
Namespace(name='model_phi1_1a_v_mmd1', outdir='out/model_training/model_phi1_1a_v_mmd1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4198393568

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96605319698576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96605319698576 | validation: 5.656558269828778]
	TIME [epoch: 97.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.49085626811494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.49085626811494 | validation: 4.926935125027116]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.969977351043323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.969977351043323 | validation: 4.763256906450954]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.349891937153468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.349891937153468 | validation: 4.358197735059603]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.070066242167706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.070066242167706 | validation: 4.651344806827585]
	TIME [epoch: 8.19 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.263765037824082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.263765037824082 | validation: 4.150900985587919]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7686768808586435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7686768808586435 | validation: 3.783988985032688]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.74617676840053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.74617676840053 | validation: 4.704508940390761]
	TIME [epoch: 8.17 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522648898098582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.522648898098582 | validation: 4.006784147066494]
	TIME [epoch: 8.17 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8214810412248497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8214810412248497 | validation: 3.1975525745646207]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166352732075869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.166352732075869 | validation: 3.086892825523488]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.229759077218376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.229759077218376 | validation: 3.2021822830125766]
	TIME [epoch: 8.24 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1736637143589013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1736637143589013 | validation: 3.094810508727808]
	TIME [epoch: 8.18 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9239582751930686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9239582751930686 | validation: 2.610688614214372]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.994570264240732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.994570264240732 | validation: 2.776085431465945]
	TIME [epoch: 8.17 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6270717613300434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6270717613300434 | validation: 2.9991079479754257]
	TIME [epoch: 8.18 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4401413955656706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4401413955656706 | validation: 2.2094653887189812]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2068996902984197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2068996902984197 | validation: 2.09876808134029]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0918655189366975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0918655189366975 | validation: 2.1834629436693356]
	TIME [epoch: 8.19 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0896393760070873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0896393760070873 | validation: 1.9207714429275353]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.852726598242053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.852726598242053 | validation: 2.708899155565584]
	TIME [epoch: 8.21 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4834621360828484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4834621360828484 | validation: 3.1788330583027866]
	TIME [epoch: 8.23 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319500488935345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.319500488935345 | validation: 1.7388665566085124]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6274612836199542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6274612836199542 | validation: 2.0464289368743858]
	TIME [epoch: 8.2 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8703272858991238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8703272858991238 | validation: 1.506745909450605]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396602964792777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.396602964792777 | validation: 1.8257411186207921]
	TIME [epoch: 8.2 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832795475169819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.832795475169819 | validation: 1.7420710375729693]
	TIME [epoch: 8.25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5178901896086021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5178901896086021 | validation: 1.4964385295468292]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5177454084171835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5177454084171835 | validation: 1.231691613357845]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1186581740047647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1186581740047647 | validation: 1.611586944692096]
	TIME [epoch: 8.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.529870828789691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.529870828789691 | validation: 1.0001262854201898]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1614813204144752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1614813204144752 | validation: 1.7098793304267863]
	TIME [epoch: 8.23 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0772765634509391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0772765634509391 | validation: 0.7872409347269141]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.389088015163232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.389088015163232 | validation: 1.2420853003600252]
	TIME [epoch: 8.19 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9256095594316383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9256095594316383 | validation: 1.356915960096635]
	TIME [epoch: 8.19 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0607271670224094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0607271670224094 | validation: 0.8139162656346566]
	TIME [epoch: 8.19 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708954851254079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.708954851254079 | validation: 0.6765344821873851]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.96278478682512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.96278478682512 | validation: 1.2208005141789386]
	TIME [epoch: 8.21 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0780043443298184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0780043443298184 | validation: 0.6689477500809953]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563850745893828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7563850745893828 | validation: 0.6754100128103206]
	TIME [epoch: 8.19 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309864101113882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7309864101113882 | validation: 0.6285884000022223]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807728193870754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5807728193870754 | validation: 0.5996994383431995]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1629061566906227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1629061566906227 | validation: 1.5872804264062865]
	TIME [epoch: 8.19 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9139474269198137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9139474269198137 | validation: 0.5904283699117872]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568505382828982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.568505382828982 | validation: 0.45046430508973334]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9976923120461225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9976923120461225 | validation: 0.5851398924979243]
	TIME [epoch: 8.19 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6040889889122854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6040889889122854 | validation: 0.5969756216828632]
	TIME [epoch: 8.22 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486924542537994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5486924542537994 | validation: 0.4524194593174557]
	TIME [epoch: 8.21 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9696456662409778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9696456662409778 | validation: 0.8456307713754798]
	TIME [epoch: 8.19 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109646131830156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7109646131830156 | validation: 0.48565670443926173]
	TIME [epoch: 8.19 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572393393548689		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.572393393548689 | validation: 0.6219514166706064]
	TIME [epoch: 8.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574678294320188		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.6574678294320188 | validation: 0.5786761789711543]
	TIME [epoch: 8.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528623805534993		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5528623805534993 | validation: 0.4241901635320769]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461225729547593		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.6461225729547593 | validation: 0.9161527980272932]
	TIME [epoch: 8.18 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6539319842709517		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.6539319842709517 | validation: 0.5886845135617746]
	TIME [epoch: 8.19 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8030648131673352		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8030648131673352 | validation: 0.6487216529927957]
	TIME [epoch: 8.18 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591960888080278		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7591960888080278 | validation: 0.7220863002520364]
	TIME [epoch: 8.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8010430354487956		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.8010430354487956 | validation: 0.5539946131812948]
	TIME [epoch: 8.21 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283483626807558		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6283483626807558 | validation: 0.7845204043539187]
	TIME [epoch: 8.19 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6600142139166759		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.6600142139166759 | validation: 0.5578364771184274]
	TIME [epoch: 8.19 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713642487235991		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.5713642487235991 | validation: 0.5378847591926333]
	TIME [epoch: 8.19 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552830742075206		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.552830742075206 | validation: 0.5310706469211293]
	TIME [epoch: 8.19 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137836612909452		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5137836612909452 | validation: 0.6233031418690207]
	TIME [epoch: 8.23 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833530198209342		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5833530198209342 | validation: 0.5298447375082682]
	TIME [epoch: 8.19 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141323160738456		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5141323160738456 | validation: 0.6135724311742674]
	TIME [epoch: 8.18 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640356831382172		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.640356831382172 | validation: 0.5434672797855714]
	TIME [epoch: 8.19 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792743116277904		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5792743116277904 | validation: 0.5457810095857334]
	TIME [epoch: 8.18 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563332966563173		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5563332966563173 | validation: 0.5559761993099127]
	TIME [epoch: 8.23 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338962144585681		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.6338962144585681 | validation: 0.8979245729511989]
	TIME [epoch: 8.19 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8883555261451341		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.8883555261451341 | validation: 0.5787402744875187]
	TIME [epoch: 8.19 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723721100687552		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5723721100687552 | validation: 0.5203794838081954]
	TIME [epoch: 8.18 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47121503384089586		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.47121503384089586 | validation: 1.458800635166868]
	TIME [epoch: 8.19 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0038024233589593		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.0038024233589593 | validation: 0.6338444191318027]
	TIME [epoch: 8.21 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878496264774349		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5878496264774349 | validation: 0.5365193035099036]
	TIME [epoch: 8.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5566668870461166		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5566668870461166 | validation: 0.5459809018247894]
	TIME [epoch: 8.19 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660462106695231		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5660462106695231 | validation: 0.5533112301609026]
	TIME [epoch: 8.18 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380606070487597		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.5380606070487597 | validation: 0.44145151608703886]
	TIME [epoch: 8.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49012564656040514		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.49012564656040514 | validation: 0.5069974259136322]
	TIME [epoch: 8.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483659182884086		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.6483659182884086 | validation: 0.8939913711848877]
	TIME [epoch: 8.24 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734517625463654		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6734517625463654 | validation: 0.536617416878697]
	TIME [epoch: 8.19 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596634011645598		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5596634011645598 | validation: 0.5363416520793688]
	TIME [epoch: 8.18 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575776120409354		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5575776120409354 | validation: 0.5482380800853516]
	TIME [epoch: 8.18 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499725593550362		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5499725593550362 | validation: 0.5503963918999413]
	TIME [epoch: 8.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565776540613332		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.565776540613332 | validation: 0.5545476843837363]
	TIME [epoch: 8.23 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357619890666279		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5357619890666279 | validation: 0.7136505168347207]
	TIME [epoch: 8.18 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218877946707593		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6218877946707593 | validation: 0.5041789536528514]
	TIME [epoch: 8.19 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4765054935815117		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4765054935815117 | validation: 3.0162495119766275]
	TIME [epoch: 8.18 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109524175016202		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.109524175016202 | validation: 0.6134821566863295]
	TIME [epoch: 8.18 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823703689219242		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6823703689219242 | validation: 0.5553058151806678]
	TIME [epoch: 8.22 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580424783257999		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5580424783257999 | validation: 0.5039189838496503]
	TIME [epoch: 8.19 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49613817620334977		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.49613817620334977 | validation: 0.6953961825419492]
	TIME [epoch: 8.18 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930290880598886		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.6930290880598886 | validation: 0.6095119339126578]
	TIME [epoch: 8.19 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692923039234602		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5692923039234602 | validation: 0.5413903634525257]
	TIME [epoch: 8.19 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600349566180853		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.5600349566180853 | validation: 0.5539768063131462]
	TIME [epoch: 8.21 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639612280832502		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5639612280832502 | validation: 0.5382878809650756]
	TIME [epoch: 8.19 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632159256993817		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.5632159256993817 | validation: 0.5475228304818675]
	TIME [epoch: 8.17 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451787275788124		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.5451787275788124 | validation: 0.5384095003416819]
	TIME [epoch: 8.18 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832543729461069		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5832543729461069 | validation: 0.48267417089172526]
	TIME [epoch: 8.17 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42324105750323127		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.42324105750323127 | validation: 0.9169673870173517]
	TIME [epoch: 8.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9502961918271701		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.9502961918271701 | validation: 0.7954077460784215]
	TIME [epoch: 8.19 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227977982902948		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.6227977982902948 | validation: 0.5234308454401375]
	TIME [epoch: 8.18 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46980585213085113		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.46980585213085113 | validation: 0.3667537429852632]
	TIME [epoch: 8.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33981958710719967		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.33981958710719967 | validation: 0.748267301706262]
	TIME [epoch: 8.18 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351012032876924		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6351012032876924 | validation: 0.5227209058953401]
	TIME [epoch: 8.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354893605780391		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5354893605780391 | validation: 0.5009959851158484]
	TIME [epoch: 8.23 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301872958598981		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4301872958598981 | validation: 0.3780233610790998]
	TIME [epoch: 8.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911202604826342		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3911202604826342 | validation: 0.7595809606212877]
	TIME [epoch: 8.19 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368846317092948		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6368846317092948 | validation: 0.49315454516688384]
	TIME [epoch: 8.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43440419571131744		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.43440419571131744 | validation: 0.4039980516496203]
	TIME [epoch: 8.19 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.758939583068466		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.758939583068466 | validation: 0.6505814399238492]
	TIME [epoch: 8.24 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48884988249128464		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.48884988249128464 | validation: 0.3885353373038813]
	TIME [epoch: 8.19 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32453582777971546		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.32453582777971546 | validation: 0.6262631582204609]
	TIME [epoch: 8.19 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39484246854653743		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.39484246854653743 | validation: 0.38345953549517076]
	TIME [epoch: 8.19 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329076280359902		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.3329076280359902 | validation: 0.3423666295835034]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815078513480027		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.2815078513480027 | validation: 0.39755520280693857]
	TIME [epoch: 8.23 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36760567094823127		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.36760567094823127 | validation: 0.4426956014878719]
	TIME [epoch: 8.19 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27735753887294445		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.27735753887294445 | validation: 0.28381698441897923]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774906035520931		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.2774906035520931 | validation: 0.7185717661766946]
	TIME [epoch: 8.17 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713470010061561		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5713470010061561 | validation: 0.3502340566172454]
	TIME [epoch: 8.18 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38165530334327624		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.38165530334327624 | validation: 0.454861601125814]
	TIME [epoch: 8.23 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27035890208789987		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.27035890208789987 | validation: 0.247266575376418]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806629316292065		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.2806629316292065 | validation: 0.3431123853300031]
	TIME [epoch: 8.19 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22553537256791428		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.22553537256791428 | validation: 0.30716612735152404]
	TIME [epoch: 8.18 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.425923289963594		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.425923289963594 | validation: 0.40669545892473546]
	TIME [epoch: 8.19 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052353550873794		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3052353550873794 | validation: 0.26289913333413945]
	TIME [epoch: 8.21 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26555431055494505		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.26555431055494505 | validation: 0.2600295943137532]
	TIME [epoch: 8.19 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447566078390813		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.22447566078390813 | validation: 0.3768469158033587]
	TIME [epoch: 8.18 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32006158126522577		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.32006158126522577 | validation: 0.29235126977969933]
	TIME [epoch: 8.19 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24852437689889587		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.24852437689889587 | validation: 0.2466880680369197]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27437256900743834		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.27437256900743834 | validation: 0.45712313954316264]
	TIME [epoch: 8.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38370370492631634		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.38370370492631634 | validation: 0.2930697504324492]
	TIME [epoch: 8.21 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743592486875428		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.2743592486875428 | validation: 0.37276115984006886]
	TIME [epoch: 8.18 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500689474599208		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.2500689474599208 | validation: 0.3390422495577558]
	TIME [epoch: 8.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614003243452901		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2614003243452901 | validation: 0.2662350977931351]
	TIME [epoch: 8.18 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298638215988973		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.2298638215988973 | validation: 0.2429580761033945]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31197458589472826		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.31197458589472826 | validation: 0.3299602915209445]
	TIME [epoch: 8.23 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27437170859998555		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.27437170859998555 | validation: 0.3168415138446784]
	TIME [epoch: 8.21 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31521672234820375		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.31521672234820375 | validation: 0.27075296682311206]
	TIME [epoch: 8.18 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21735978709624337		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.21735978709624337 | validation: 0.2624407705108876]
	TIME [epoch: 8.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21524562238966136		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.21524562238966136 | validation: 0.38968936050444414]
	TIME [epoch: 8.19 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664852942124836		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.2664852942124836 | validation: 0.3375806208256229]
	TIME [epoch: 8.23 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25252486722857614		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.25252486722857614 | validation: 0.2102053649123075]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041610350829962		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.2041610350829962 | validation: 0.32487795053962787]
	TIME [epoch: 8.18 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23916811929618062		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.23916811929618062 | validation: 0.30935297613518686]
	TIME [epoch: 8.19 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2358272991350074		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2358272991350074 | validation: 0.3136306017722308]
	TIME [epoch: 8.18 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20744806950999378		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.20744806950999378 | validation: 0.16884534655167288]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203640260580459		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.2203640260580459 | validation: 0.3115653706938205]
	TIME [epoch: 8.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247698109565346		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.247698109565346 | validation: 0.2798933195208043]
	TIME [epoch: 8.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24329550566077468		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.24329550566077468 | validation: 0.198931169254342]
	TIME [epoch: 8.22 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23382101191118965		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.23382101191118965 | validation: 0.21288639494660383]
	TIME [epoch: 8.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739776553282189		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.1739776553282189 | validation: 0.2030471982624481]
	TIME [epoch: 8.26 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021768212737017		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.2021768212737017 | validation: 0.20249977191643243]
	TIME [epoch: 8.21 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.238532109363396		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.238532109363396 | validation: 0.18458285454787204]
	TIME [epoch: 8.22 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17446229409255748		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.17446229409255748 | validation: 0.23982929731608837]
	TIME [epoch: 8.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21576396817334048		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.21576396817334048 | validation: 0.1883267098974161]
	TIME [epoch: 8.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18477704373141207		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.18477704373141207 | validation: 0.19073541420571022]
	TIME [epoch: 8.24 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22368933756000203		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.22368933756000203 | validation: 0.24924625885863608]
	TIME [epoch: 8.22 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20058858840024127		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.20058858840024127 | validation: 0.18345151774385848]
	TIME [epoch: 8.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017526578584479		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.2017526578584479 | validation: 0.15882335960140626]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18730676252668743		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.18730676252668743 | validation: 0.14297071249694937]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143438750634689		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.143438750634689 | validation: 0.17353423932509562]
	TIME [epoch: 8.21 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21063076450966572		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.21063076450966572 | validation: 0.22439995526043593]
	TIME [epoch: 8.22 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17792323547627287		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.17792323547627287 | validation: 0.29805703023310137]
	TIME [epoch: 8.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19163552036505893		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.19163552036505893 | validation: 0.17296365907411768]
	TIME [epoch: 8.21 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554089548020265		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1554089548020265 | validation: 0.17975068696439644]
	TIME [epoch: 8.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2386858694288186		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.2386858694288186 | validation: 0.15236138724989073]
	TIME [epoch: 8.19 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17453088467128713		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.17453088467128713 | validation: 0.16936661168916017]
	TIME [epoch: 8.24 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584309556584219		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.1584309556584219 | validation: 0.14250273301646552]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20476689630929745		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.20476689630929745 | validation: 0.1370736107067237]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517559453957907		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.1517559453957907 | validation: 0.1297513495623149]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12096113652109461		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.12096113652109461 | validation: 0.12932548747728323]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14742995335580017		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.14742995335580017 | validation: 0.17019626001064253]
	TIME [epoch: 8.23 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20667933310420572		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.20667933310420572 | validation: 0.13402213302935725]
	TIME [epoch: 8.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630519138280937		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.14630519138280937 | validation: 0.2163891676445878]
	TIME [epoch: 8.19 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16221169836839472		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.16221169836839472 | validation: 0.10341922311393945]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314587850698043		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.1314587850698043 | validation: 0.16819732080777783]
	TIME [epoch: 8.22 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271307532251072		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.15271307532251072 | validation: 0.11018513852271143]
	TIME [epoch: 8.24 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471944340844218		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.12471944340844218 | validation: 0.19679045948273416]
	TIME [epoch: 8.22 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17482785054219213		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.17482785054219213 | validation: 0.23144393583998035]
	TIME [epoch: 8.21 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16811883999418398		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.16811883999418398 | validation: 0.14754489549256294]
	TIME [epoch: 8.21 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13551540290419278		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.13551540290419278 | validation: 0.1292806942057299]
	TIME [epoch: 8.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655082197436748		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.1655082197436748 | validation: 0.13526191323630082]
	TIME [epoch: 8.25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571976626840656		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.12571976626840656 | validation: 0.10078335013849671]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000709372693323		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.14000709372693323 | validation: 0.1793043181788228]
	TIME [epoch: 8.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14853334138144153		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.14853334138144153 | validation: 0.12298334315696607]
	TIME [epoch: 8.21 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480777034438925		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.10480777034438925 | validation: 0.08605971989657318]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16331589571848745		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.16331589571848745 | validation: 0.292037634014486]
	TIME [epoch: 8.25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16852738470071948		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.16852738470071948 | validation: 0.13891502472897505]
	TIME [epoch: 8.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11204625475278869		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.11204625475278869 | validation: 0.11772636159967362]
	TIME [epoch: 8.21 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12981378110173256		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.12981378110173256 | validation: 0.12753084721537383]
	TIME [epoch: 8.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11874248008733439		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.11874248008733439 | validation: 0.1162536766458892]
	TIME [epoch: 8.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266675287411883		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.13266675287411883 | validation: 0.10306828050506886]
	TIME [epoch: 8.25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11591329188866817		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.11591329188866817 | validation: 0.1330307928868436]
	TIME [epoch: 8.22 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359881467719016		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.11359881467719016 | validation: 0.09761951219556853]
	TIME [epoch: 8.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126025524508443		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.126025524508443 | validation: 0.08782476731929517]
	TIME [epoch: 8.19 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939886908665503		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.07939886908665503 | validation: 0.08016969560619319]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09766591498511018		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.09766591498511018 | validation: 0.17184479694373692]
	TIME [epoch: 8.22 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14732875007414828		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.14732875007414828 | validation: 0.0760226403124172]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310847141681774		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.08310847141681774 | validation: 0.1141131852059133]
	TIME [epoch: 8.19 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16408881118330887		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.16408881118330887 | validation: 0.11324791354035157]
	TIME [epoch: 8.19 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040740133211831		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.1040740133211831 | validation: 0.06272837390982733]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720306417631006		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.08720306417631006 | validation: 0.12332979222179036]
	TIME [epoch: 8.22 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336686461724072		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.1336686461724072 | validation: 0.08557148384396823]
	TIME [epoch: 8.21 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517086436203528		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.08517086436203528 | validation: 0.10786443571796356]
	TIME [epoch: 8.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11620109653855865		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.11620109653855865 | validation: 0.10650184097572073]
	TIME [epoch: 8.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817343152386054		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.09817343152386054 | validation: 0.07584707152230705]
	TIME [epoch: 8.19 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12075940094346509		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.12075940094346509 | validation: 0.14535467060726853]
	TIME [epoch: 8.22 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052230527398147		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.1052230527398147 | validation: 0.06992705609354063]
	TIME [epoch: 8.23 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012181610845441		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.08012181610845441 | validation: 0.08270000367143879]
	TIME [epoch: 8.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881073420621643		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.0881073420621643 | validation: 0.24479399289015863]
	TIME [epoch: 8.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401652621408546		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.1401652621408546 | validation: 0.0895724722130477]
	TIME [epoch: 8.19 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101546139655918		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.07101546139655918 | validation: 0.10273883405327641]
	TIME [epoch: 8.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147663483604297		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.1147663483604297 | validation: 0.11517731993037515]
	TIME [epoch: 8.23 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07677053146201256		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.07677053146201256 | validation: 0.07255995929975412]
	TIME [epoch: 8.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13437689849767698		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.13437689849767698 | validation: 0.13296532105917758]
	TIME [epoch: 8.19 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09192825402879712		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.09192825402879712 | validation: 0.06057159185543948]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09230503592172834		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.09230503592172834 | validation: 0.10304502844919619]
	TIME [epoch: 8.21 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11153145672569922		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.11153145672569922 | validation: 0.07053437904241217]
	TIME [epoch: 8.24 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037685871368569		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.08037685871368569 | validation: 0.08656001681825362]
	TIME [epoch: 8.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557246071100442		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.08557246071100442 | validation: 0.08376352505551624]
	TIME [epoch: 8.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968926959227283		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.08968926959227283 | validation: 0.06188335810390362]
	TIME [epoch: 8.21 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489165599535165		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.10489165599535165 | validation: 0.16620127625123804]
	TIME [epoch: 8.21 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295875878387255		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.1295875878387255 | validation: 0.0783085608086288]
	TIME [epoch: 8.25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149861077446418		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.13149861077446418 | validation: 0.1099934412456349]
	TIME [epoch: 8.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11652098969157478		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.11652098969157478 | validation: 0.07568977215087744]
	TIME [epoch: 8.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656227486739922		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.0656227486739922 | validation: 0.05782455894205215]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361419212293541		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.06361419212293541 | validation: 0.10364205531916731]
	TIME [epoch: 8.19 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874304517810437		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.09874304517810437 | validation: 0.0715973781154844]
	TIME [epoch: 8.24 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850027476317549		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.05850027476317549 | validation: 0.06879411195420795]
	TIME [epoch: 8.21 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09720537061552856		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.09720537061552856 | validation: 0.07471619247208298]
	TIME [epoch: 8.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629023000538175		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.0629023000538175 | validation: 0.059609467149667444]
	TIME [epoch: 8.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495719376035355		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.10495719376035355 | validation: 0.053432369132724505]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056873108699612325		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.056873108699612325 | validation: 0.06005154596301789]
	TIME [epoch: 8.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357745899954467		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.09357745899954467 | validation: 0.0875548599244042]
	TIME [epoch: 8.23 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07389328499519698		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.07389328499519698 | validation: 0.0782217501008518]
	TIME [epoch: 8.19 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612977367704957		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.0612977367704957 | validation: 0.04753191163047722]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080188059725177		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.08080188059725177 | validation: 0.16133123976236877]
	TIME [epoch: 8.21 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292461541218498		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.10292461541218498 | validation: 0.06803115222113615]
	TIME [epoch: 8.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060280669598369814		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.060280669598369814 | validation: 0.045648206703470084]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06674480435223332		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.06674480435223332 | validation: 0.10168508044045721]
	TIME [epoch: 8.19 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076474357554821		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.07076474357554821 | validation: 0.0709399811555373]
	TIME [epoch: 8.19 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06523169568994597		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.06523169568994597 | validation: 0.1014106463229801]
	TIME [epoch: 8.19 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08443071945234694		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.08443071945234694 | validation: 0.05042387493666075]
	TIME [epoch: 8.21 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05204551657072815		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.05204551657072815 | validation: 0.07267298536888224]
	TIME [epoch: 8.22 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657030579925592		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.07657030579925592 | validation: 0.07524902660132571]
	TIME [epoch: 8.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058578773370891804		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.058578773370891804 | validation: 0.059627760055721124]
	TIME [epoch: 8.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09032472917692962		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.09032472917692962 | validation: 0.05103194190138119]
	TIME [epoch: 8.18 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622112270085342		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.04622112270085342 | validation: 0.0695900478916974]
	TIME [epoch: 8.18 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892607029265747		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.06892607029265747 | validation: 0.0598446316435787]
	TIME [epoch: 8.22 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05276065986677243		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.05276065986677243 | validation: 0.049616649279877384]
	TIME [epoch: 8.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499932367488714		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.06499932367488714 | validation: 0.07520057633140415]
	TIME [epoch: 8.19 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905767887574221		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.05905767887574221 | validation: 0.049002907660615436]
	TIME [epoch: 8.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966074129814436		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.05966074129814436 | validation: 0.06728847651520864]
	TIME [epoch: 8.19 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07592652560388631		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.07592652560388631 | validation: 0.07628721166162156]
	TIME [epoch: 8.23 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07658010708363913		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.07658010708363913 | validation: 0.05249752152357827]
	TIME [epoch: 8.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04628158906898636		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.04628158906898636 | validation: 0.055091482174903235]
	TIME [epoch: 8.18 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06364846738433116		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.06364846738433116 | validation: 0.07016364787372456]
	TIME [epoch: 8.19 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09671113428110975		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.09671113428110975 | validation: 0.0694948780911858]
	TIME [epoch: 8.18 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06786558395679282		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.06786558395679282 | validation: 0.07047802352979463]
	TIME [epoch: 8.22 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044935616627403155		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.044935616627403155 | validation: 0.05063604000078165]
	TIME [epoch: 8.21 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312163994214269		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.06312163994214269 | validation: 0.08621485533540055]
	TIME [epoch: 8.19 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981499282402233		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.04981499282402233 | validation: 0.04936436386978511]
	TIME [epoch: 8.19 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109659793271535		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.12109659793271535 | validation: 0.13972392641317993]
	TIME [epoch: 8.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12348575291654836		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.12348575291654836 | validation: 0.07895527769312409]
	TIME [epoch: 8.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229432565084767		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.07229432565084767 | validation: 0.0647463610887799]
	TIME [epoch: 8.24 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044693922635694966		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.044693922635694966 | validation: 0.03831740084215157]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02949066409535743		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.02949066409535743 | validation: 0.05279479533839569]
	TIME [epoch: 8.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923932103265627		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.07923932103265627 | validation: 0.05094980359531773]
	TIME [epoch: 8.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040210895540703305		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.040210895540703305 | validation: 0.06172404536446372]
	TIME [epoch: 8.19 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05848577071134271		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.05848577071134271 | validation: 0.033150018713415615]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04255129536235475		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.04255129536235475 | validation: 0.08498507229082614]
	TIME [epoch: 8.19 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694310269568063		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.06694310269568063 | validation: 0.06946269893025313]
	TIME [epoch: 8.19 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175935988681313		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.05175935988681313 | validation: 0.04028675238628463]
	TIME [epoch: 8.18 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051524971127692186		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.051524971127692186 | validation: 0.09485405689463573]
	TIME [epoch: 8.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051927364933628956		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.051927364933628956 | validation: 0.04332019524061043]
	TIME [epoch: 8.23 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568780609769859		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.03568780609769859 | validation: 0.027541138671485547]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03684495789928976		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.03684495789928976 | validation: 0.16391026445695386]
	TIME [epoch: 8.18 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08602414336866424		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.08602414336866424 | validation: 0.038741460892411594]
	TIME [epoch: 8.19 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610073540102964		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.03610073540102964 | validation: 0.048280979962192064]
	TIME [epoch: 8.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07586421220997963		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.07586421220997963 | validation: 0.03277859209279668]
	TIME [epoch: 8.23 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411309342183455		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.03411309342183455 | validation: 0.04444989912614532]
	TIME [epoch: 8.21 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947116826626149		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.03947116826626149 | validation: 0.06301725966616109]
	TIME [epoch: 8.18 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733577076654618		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.04733577076654618 | validation: 0.07207002578690139]
	TIME [epoch: 8.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049744053090367654		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.049744053090367654 | validation: 0.025473116445051118]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029560443862385502		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.029560443862385502 | validation: 0.07274252941305248]
	TIME [epoch: 8.23 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272411280313903		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.06272411280313903 | validation: 0.03743194472489082]
	TIME [epoch: 8.21 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670809681390407		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.03670809681390407 | validation: 0.05323905395244605]
	TIME [epoch: 8.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04635885716033228		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.04635885716033228 | validation: 0.03349387712653594]
	TIME [epoch: 8.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02332425682770922		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.02332425682770922 | validation: 0.042915207238876985]
	TIME [epoch: 8.19 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07116398858726593		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.07116398858726593 | validation: 0.04828682174285233]
	TIME [epoch: 8.22 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03196475261798575		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.03196475261798575 | validation: 0.03798611045445024]
	TIME [epoch: 8.22 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055150578912902065		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.055150578912902065 | validation: 0.03600077072775836]
	TIME [epoch: 8.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03001223346598717		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.03001223346598717 | validation: 0.03769917025986615]
	TIME [epoch: 8.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600107384919769		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.03600107384919769 | validation: 0.09447815287884981]
	TIME [epoch: 8.21 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003793110084437		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.05003793110084437 | validation: 0.04178189978453209]
	TIME [epoch: 8.21 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822779516919489		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.02822779516919489 | validation: 0.03110922970112062]
	TIME [epoch: 8.24 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04443665077673626		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.04443665077673626 | validation: 0.0879771980052435]
	TIME [epoch: 8.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042444704828240656		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.042444704828240656 | validation: 0.023740454213590435]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133513639241749		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.03133513639241749 | validation: 0.053126756117291604]
	TIME [epoch: 8.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04567487676386079		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.04567487676386079 | validation: 0.07537176124630199]
	TIME [epoch: 8.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04679577302539557		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.04679577302539557 | validation: 0.03452776886646856]
	TIME [epoch: 8.24 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125709909260874		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.03125709909260874 | validation: 0.050620142054922906]
	TIME [epoch: 8.19 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037533303028902246		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.037533303028902246 | validation: 0.025980084504634047]
	TIME [epoch: 8.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031364654163437825		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.031364654163437825 | validation: 0.0557954025296109]
	TIME [epoch: 8.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05265025629813695		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.05265025629813695 | validation: 0.024410194431916166]
	TIME [epoch: 8.18 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02300366860371586		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.02300366860371586 | validation: 0.02650001093949518]
	TIME [epoch: 8.24 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04031984698587773		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.04031984698587773 | validation: 0.05342891334440829]
	TIME [epoch: 8.18 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04407810122693896		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.04407810122693896 | validation: 0.042065009923143756]
	TIME [epoch: 8.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165915702327046		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.03165915702327046 | validation: 0.0557943368489928]
	TIME [epoch: 8.18 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032280089592010605		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.032280089592010605 | validation: 0.04144877847434756]
	TIME [epoch: 8.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046900814393104076		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.046900814393104076 | validation: 0.05956352830642993]
	TIME [epoch: 8.21 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032909491036914124		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.032909491036914124 | validation: 0.022837252887105895]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02747371056478582		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.02747371056478582 | validation: 0.05509228791950868]
	TIME [epoch: 8.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04097299432585611		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.04097299432585611 | validation: 0.030122438718133904]
	TIME [epoch: 8.19 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314854243997028		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.0314854243997028 | validation: 0.052581496295531265]
	TIME [epoch: 8.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209023895191621		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.04209023895191621 | validation: 0.019720655791490654]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018582752310754673		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.018582752310754673 | validation: 0.030694479992585066]
	TIME [epoch: 8.21 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050133490563747066		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.050133490563747066 | validation: 0.02937156770093241]
	TIME [epoch: 8.19 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020319916514302615		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.020319916514302615 | validation: 0.03339252985485979]
	TIME [epoch: 8.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041969248398971364		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.041969248398971364 | validation: 0.02681317154463987]
	TIME [epoch: 8.18 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019863803842353124		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.019863803842353124 | validation: 0.03321859100976804]
	TIME [epoch: 8.21 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029883808034212013		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.029883808034212013 | validation: 0.04409755503866318]
	TIME [epoch: 8.23 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05093288247996203		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.05093288247996203 | validation: 0.03895898503193431]
	TIME [epoch: 8.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023749817611024182		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.023749817611024182 | validation: 0.03262164709272818]
	TIME [epoch: 8.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040063194387642054		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.040063194387642054 | validation: 0.036060174490853095]
	TIME [epoch: 8.19 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021387791504644194		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.021387791504644194 | validation: 0.026986923306551273]
	TIME [epoch: 8.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025941341805611154		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.025941341805611154 | validation: 0.04103267706995399]
	TIME [epoch: 8.22 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058011734997092265		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.058011734997092265 | validation: 0.02472868602020524]
	TIME [epoch: 8.19 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020967187536739117		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.020967187536739117 | validation: 0.0942774326740812]
	TIME [epoch: 8.18 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444878970093314		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.06444878970093314 | validation: 0.025642848416342068]
	TIME [epoch: 8.19 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938597352570295		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.02938597352570295 | validation: 0.0352247858057642]
	TIME [epoch: 8.18 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02810786802745862		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.02810786802745862 | validation: 0.023803026066424718]
	TIME [epoch: 8.23 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024780759262104386		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.024780759262104386 | validation: 0.058583956811784646]
	TIME [epoch: 8.19 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03463981856095593		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.03463981856095593 | validation: 0.015076725814027492]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01780023505222226		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.01780023505222226 | validation: 0.02333446847627326]
	TIME [epoch: 8.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892608812371251		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.04892608812371251 | validation: 0.020487294115551433]
	TIME [epoch: 8.18 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02495375558626686		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.02495375558626686 | validation: 0.03897955397010654]
	TIME [epoch: 8.24 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028446434000807236		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.028446434000807236 | validation: 0.01989896364134097]
	TIME [epoch: 8.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018145664697346367		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.018145664697346367 | validation: 0.03649207151319223]
	TIME [epoch: 8.19 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262134860273106		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.04262134860273106 | validation: 0.034576900569260216]
	TIME [epoch: 8.18 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016834903200349405		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.016834903200349405 | validation: 0.020808646658665553]
	TIME [epoch: 8.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025940507867002097		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.025940507867002097 | validation: 0.0365329185484958]
	TIME [epoch: 8.22 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036492856178690455		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.036492856178690455 | validation: 0.05503529506510962]
	TIME [epoch: 8.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027679835744549054		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.027679835744549054 | validation: 0.020440627653025012]
	TIME [epoch: 8.19 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025136413916715405		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.025136413916715405 | validation: 0.035303328584845764]
	TIME [epoch: 8.19 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029156309979549107		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.029156309979549107 | validation: 0.038243524571938504]
	TIME [epoch: 8.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02044283557159795		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.02044283557159795 | validation: 0.04587216973592233]
	TIME [epoch: 8.21 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716920515508243		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.03716920515508243 | validation: 0.018182344753467663]
	TIME [epoch: 8.22 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822376039125999		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.01822376039125999 | validation: 0.029314185448616383]
	TIME [epoch: 8.18 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030759535501597397		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.030759535501597397 | validation: 0.03523150479484351]
	TIME [epoch: 8.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024057389189228614		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.024057389189228614 | validation: 0.019399740123044438]
	TIME [epoch: 8.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02012934238041311		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.02012934238041311 | validation: 0.04454413507793886]
	TIME [epoch: 8.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397269082478792		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.03397269082478792 | validation: 0.020616342447376486]
	TIME [epoch: 8.23 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017615285924168562		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.017615285924168562 | validation: 0.03669508039622239]
	TIME [epoch: 8.19 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03601464679213282		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.03601464679213282 | validation: 0.03068703563269364]
	TIME [epoch: 8.19 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093084500710145		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.02093084500710145 | validation: 0.030732743554289958]
	TIME [epoch: 8.19 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542832420395434		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.02542832420395434 | validation: 0.022099473743255646]
	TIME [epoch: 8.19 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018689516737683563		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.018689516737683563 | validation: 0.02944455681347552]
	TIME [epoch: 8.23 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621031440911984		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.03621031440911984 | validation: 0.022121596580489376]
	TIME [epoch: 8.21 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016538845866507397		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.016538845866507397 | validation: 0.014943443988701316]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619306238318577		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.03619306238318577 | validation: 0.06771039036188736]
	TIME [epoch: 8.19 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04454717459352238		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.04454717459352238 | validation: 0.022619750624234394]
	TIME [epoch: 8.19 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020460292114420624		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.020460292114420624 | validation: 0.01650099583986491]
	TIME [epoch: 8.22 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013647418258717965		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.013647418258717965 | validation: 0.02902329837860277]
	TIME [epoch: 8.21 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03732933659133833		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.03732933659133833 | validation: 0.01743480318424786]
	TIME [epoch: 8.19 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015914435271943854		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.015914435271943854 | validation: 0.023782660741143997]
	TIME [epoch: 8.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02705776379856958		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.02705776379856958 | validation: 0.01720546485503183]
	TIME [epoch: 8.18 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01716446376671532		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.01716446376671532 | validation: 0.014037584464496213]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02428945991805544		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.02428945991805544 | validation: 0.0456816291445241]
	TIME [epoch: 8.22 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023630589284790723		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.023630589284790723 | validation: 0.012346089169729216]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014540730415039308		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.014540730415039308 | validation: 0.02822313128248562]
	TIME [epoch: 8.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036103968460363525		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.036103968460363525 | validation: 0.02927547787950055]
	TIME [epoch: 8.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01663255341883769		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.01663255341883769 | validation: 0.0134383660846229]
	TIME [epoch: 8.22 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01168668058680013		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.01168668058680013 | validation: 0.01790346420517968]
	TIME [epoch: 8.22 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034326658885090865		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.034326658885090865 | validation: 0.03898158523110991]
	TIME [epoch: 8.21 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020321691048341296		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.020321691048341296 | validation: 0.015992839540225116]
	TIME [epoch: 8.19 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01571566440519799		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.01571566440519799 | validation: 0.022911983875579446]
	TIME [epoch: 8.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02982936797102075		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.02982936797102075 | validation: 0.017215885488126553]
	TIME [epoch: 8.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013560381790463726		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.013560381790463726 | validation: 0.022810381954327316]
	TIME [epoch: 8.24 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027185177050975257		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.027185177050975257 | validation: 0.037801902797107746]
	TIME [epoch: 8.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02044740491456707		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.02044740491456707 | validation: 0.015032105171270325]
	TIME [epoch: 8.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02117735078561237		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.02117735078561237 | validation: 0.031010052951134272]
	TIME [epoch: 8.21 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021043357931277554		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.021043357931277554 | validation: 0.014571003630307425]
	TIME [epoch: 8.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590582992775735		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.01590582992775735 | validation: 0.029603685805634557]
	TIME [epoch: 8.24 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03036994300312253		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.03036994300312253 | validation: 0.018889307543888633]
	TIME [epoch: 8.19 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01575295825242542		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.01575295825242542 | validation: 0.01908924022785305]
	TIME [epoch: 8.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024483511659135076		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.024483511659135076 | validation: 0.02558666554726432]
	TIME [epoch: 8.19 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014431158437975673		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.014431158437975673 | validation: 0.012168157731892967]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012892814057992728		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.012892814057992728 | validation: 0.040307769055799914]
	TIME [epoch: 8.24 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03915559505175932		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.03915559505175932 | validation: 0.013996415390406853]
	TIME [epoch: 8.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014895116936643842		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.014895116936643842 | validation: 0.018815530673773694]
	TIME [epoch: 8.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018222769491862106		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.018222769491862106 | validation: 0.03805007039836713]
	TIME [epoch: 8.19 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020627069120864035		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.020627069120864035 | validation: 0.03111664496656165]
	TIME [epoch: 8.21 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020192084861902482		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.020192084861902482 | validation: 0.015212651672633408]
	TIME [epoch: 8.24 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020919951837860863		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.020919951837860863 | validation: 0.019950710605733675]
	TIME [epoch: 8.22 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014622992657424505		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.014622992657424505 | validation: 0.014941276406233956]
	TIME [epoch: 8.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015529591292196178		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.015529591292196178 | validation: 0.05487388814045366]
	TIME [epoch: 8.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216913233595965		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.03216913233595965 | validation: 0.013830728174053232]
	TIME [epoch: 8.19 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019847427957606828		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.019847427957606828 | validation: 0.024623220808483046]
	TIME [epoch: 8.22 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01511802418998135		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.01511802418998135 | validation: 0.016642450327194167]
	TIME [epoch: 8.22 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017878043192064666		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.017878043192064666 | validation: 0.038495945798043205]
	TIME [epoch: 8.19 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019526868321210623		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.019526868321210623 | validation: 0.02445678280921086]
	TIME [epoch: 8.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01998373703150649		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.01998373703150649 | validation: 0.012485307215937623]
	TIME [epoch: 8.19 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015070533083713394		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.015070533083713394 | validation: 0.022430100425078887]
	TIME [epoch: 8.21 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020226552056403016		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.020226552056403016 | validation: 0.07070101612553098]
	TIME [epoch: 8.22 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0334300119943538		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.0334300119943538 | validation: 0.014101308367159355]
	TIME [epoch: 8.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010770894892104482		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.010770894892104482 | validation: 0.013083099418032984]
	TIME [epoch: 8.19 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00945243959982807		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.00945243959982807 | validation: 0.013789411485600745]
	TIME [epoch: 8.19 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016529626555688185		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.016529626555688185 | validation: 0.015640568252339157]
	TIME [epoch: 8.19 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622484076780581		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.03622484076780581 | validation: 0.01924512148336576]
	TIME [epoch: 8.23 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01317262309615599		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.01317262309615599 | validation: 0.010693229788913003]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010996953213829862		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.010996953213829862 | validation: 0.017188443324285173]
	TIME [epoch: 8.19 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022709799248318487		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.022709799248318487 | validation: 0.03261710113228189]
	TIME [epoch: 8.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01957174962159023		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.01957174962159023 | validation: 0.012332508234097896]
	TIME [epoch: 8.18 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01074775435890366		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.01074775435890366 | validation: 0.01654214109410885]
	TIME [epoch: 8.23 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022251591838519998		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.022251591838519998 | validation: 0.032886504478691625]
	TIME [epoch: 8.19 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015526397350112084		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.015526397350112084 | validation: 0.010389698919958286]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010042378920188272		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.010042378920188272 | validation: 0.014113819434453279]
	TIME [epoch: 8.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014372574658524196		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.014372574658524196 | validation: 0.014716333114087973]
	TIME [epoch: 8.19 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431957918255922		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.03431957918255922 | validation: 0.01164040800729469]
	TIME [epoch: 8.23 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014205380855615998		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.014205380855615998 | validation: 0.011124727973367488]
	TIME [epoch: 8.19 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01093380656767672		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.01093380656767672 | validation: 0.018358025481474024]
	TIME [epoch: 8.19 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021996568044902222		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.021996568044902222 | validation: 0.018055426263621215]
	TIME [epoch: 8.19 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012171874622429397		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.012171874622429397 | validation: 0.011962459789107725]
	TIME [epoch: 8.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010541000037342006		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.010541000037342006 | validation: 0.021925202348030325]
	TIME [epoch: 8.23 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029138676621477087		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.029138676621477087 | validation: 0.01209876666438707]
	TIME [epoch: 8.21 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011620350828411192		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.011620350828411192 | validation: 0.011657687328669127]
	TIME [epoch: 8.18 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016608546804722644		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.016608546804722644 | validation: 0.02862601487742233]
	TIME [epoch: 8.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018255012561426722		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.018255012561426722 | validation: 0.013507603460116863]
	TIME [epoch: 8.19 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015786298687150584		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.015786298687150584 | validation: 0.0230807451959532]
	TIME [epoch: 8.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02200173009414165		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.02200173009414165 | validation: 0.012274034327330399]
	TIME [epoch: 8.23 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011032218575625294		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.011032218575625294 | validation: 0.01478520987681533]
	TIME [epoch: 8.19 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022339341343172243		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.022339341343172243 | validation: 0.01433422966414985]
	TIME [epoch: 8.19 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011034939703317183		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.011034939703317183 | validation: 0.010108423570576713]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014172407862982394		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.014172407862982394 | validation: 0.025086062338456255]
	TIME [epoch: 8.21 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023050740848790576		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.023050740848790576 | validation: 0.016072384424732602]
	TIME [epoch: 8.23 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010911568186347548		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.010911568186347548 | validation: 0.012323858187686748]
	TIME [epoch: 8.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014332306042379978		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.014332306042379978 | validation: 0.030331912043572044]
	TIME [epoch: 8.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023651708506112153		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.023651708506112153 | validation: 0.014650076169662952]
	TIME [epoch: 8.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011056432361558193		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.011056432361558193 | validation: 0.010626587760730694]
	TIME [epoch: 8.21 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00869752711886667		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.00869752711886667 | validation: 0.009532795175313833]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012102400261824667		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.012102400261824667 | validation: 0.030444750119285408]
	TIME [epoch: 8.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024936787174886798		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.024936787174886798 | validation: 0.011821596877114506]
	TIME [epoch: 8.19 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013781153150386975		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.013781153150386975 | validation: 0.026636264818373168]
	TIME [epoch: 8.19 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01729012978685772		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.01729012978685772 | validation: 0.010713397028609701]
	TIME [epoch: 8.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012302588645094016		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.012302588645094016 | validation: 0.014328210165708802]
	TIME [epoch: 8.23 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020867071977910823		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.020867071977910823 | validation: 0.033819333057574355]
	TIME [epoch: 8.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045733620492566		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.02045733620492566 | validation: 0.014357093469779866]
	TIME [epoch: 8.19 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014972307658900688		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.014972307658900688 | validation: 0.013039776916428051]
	TIME [epoch: 8.19 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009461340356244017		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.009461340356244017 | validation: 0.015321210192957742]
	TIME [epoch: 8.19 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019509176174730452		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.019509176174730452 | validation: 0.022652484487622068]
	TIME [epoch: 8.23 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015111064955873634		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.015111064955873634 | validation: 0.017625800956410316]
	TIME [epoch: 8.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010658267134267626		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.010658267134267626 | validation: 0.011191929115948268]
	TIME [epoch: 8.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019266843681605028		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.019266843681605028 | validation: 0.025482238318020795]
	TIME [epoch: 8.19 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013746097257517912		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.013746097257517912 | validation: 0.009231279561727054]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009570250551191714		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.009570250551191714 | validation: 0.019115336319811865]
	TIME [epoch: 8.21 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019481804904019587		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.019481804904019587 | validation: 0.02568906964173264]
	TIME [epoch: 8.22 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014407515323847278		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.014407515323847278 | validation: 0.011662000435037019]
	TIME [epoch: 8.19 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011394455129428733		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.011394455129428733 | validation: 0.01722112188928835]
	TIME [epoch: 8.18 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019035303912336057		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.019035303912336057 | validation: 0.01520338862145393]
	TIME [epoch: 8.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011378183670739447		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.011378183670739447 | validation: 0.015094242864638695]
	TIME [epoch: 8.19 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012612775112201923		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.012612775112201923 | validation: 0.01138289234432851]
	TIME [epoch: 8.23 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023543347697535418		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.023543347697535418 | validation: 0.012776585568543244]
	TIME [epoch: 8.19 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011833665603170375		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.011833665603170375 | validation: 0.012453307917398373]
	TIME [epoch: 8.19 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010218762535772495		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.010218762535772495 | validation: 0.009734745359871651]
	TIME [epoch: 8.19 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008862661212130831		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.008862661212130831 | validation: 0.015847687358354755]
	TIME [epoch: 8.19 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016921637404223696		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.016921637404223696 | validation: 0.029363233461620307]
	TIME [epoch: 8.23 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016344407944811287		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.016344407944811287 | validation: 0.010390972995250172]
	TIME [epoch: 8.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010456626696101097		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.010456626696101097 | validation: 0.015401774726182961]
	TIME [epoch: 8.19 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011484055599104195		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.011484055599104195 | validation: 0.010587764556342671]
	TIME [epoch: 8.18 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017594804318550827		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.017594804318550827 | validation: 0.01857975788391026]
	TIME [epoch: 8.19 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01184470268997603		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.01184470268997603 | validation: 0.010015470929390443]
	TIME [epoch: 8.22 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008558938357711297		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.008558938357711297 | validation: 0.011187259280011365]
	TIME [epoch: 8.19 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017795642275768075		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.017795642275768075 | validation: 0.041192046084745]
	TIME [epoch: 8.19 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020339590793897355		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.020339590793897355 | validation: 0.011127967866445876]
	TIME [epoch: 8.19 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009554373940389046		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.009554373940389046 | validation: 0.010998143683048123]
	TIME [epoch: 8.19 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012014834491649702		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.012014834491649702 | validation: 0.019765291422317047]
	TIME [epoch: 8.23 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614932755724564		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.01614932755724564 | validation: 0.0112378023202917]
	TIME [epoch: 8.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010521990134521058		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.010521990134521058 | validation: 0.009100477271633496]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008729029490875014		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.008729029490875014 | validation: 0.010654511013897361]
	TIME [epoch: 8.19 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010749645533332575		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.010749645533332575 | validation: 0.014235175023083857]
	TIME [epoch: 8.18 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020773321229305225		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.020773321229305225 | validation: 0.033175497789676406]
	TIME [epoch: 8.22 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01540808981993207		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.01540808981993207 | validation: 0.009336948563036927]
	TIME [epoch: 8.21 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008029614554783007		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.008029614554783007 | validation: 0.010248610881249674]
	TIME [epoch: 8.19 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011035774386990993		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.011035774386990993 | validation: 0.01596742632333384]
	TIME [epoch: 8.19 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0158705455584216		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.0158705455584216 | validation: 0.017851400797241755]
	TIME [epoch: 8.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01077468648777391		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.01077468648777391 | validation: 0.011270924944024895]
	TIME [epoch: 8.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009948838286439603		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.009948838286439603 | validation: 0.011096214827094405]
	TIME [epoch: 8.23 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013336222166487983		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.013336222166487983 | validation: 0.03823008048316016]
	TIME [epoch: 8.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019342156440529577		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.019342156440529577 | validation: 0.01629776862577692]
	TIME [epoch: 8.19 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010031561799026888		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.010031561799026888 | validation: 0.009600369234126617]
	TIME [epoch: 8.19 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013024089316373659		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.013024089316373659 | validation: 0.019694711610219663]
	TIME [epoch: 8.19 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01067676501791897		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.01067676501791897 | validation: 0.011543510838594128]
	TIME [epoch: 8.24 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01486505317744162		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.01486505317744162 | validation: 0.013234505964239644]
	TIME [epoch: 8.19 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00975379337994312		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.00975379337994312 | validation: 0.00917153746517161]
	TIME [epoch: 8.19 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009658827689137138		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.009658827689137138 | validation: 0.013614117275226933]
	TIME [epoch: 8.19 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018408084186809923		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.018408084186809923 | validation: 0.009216349364271199]
	TIME [epoch: 8.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00937085912048287		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.00937085912048287 | validation: 0.009060631455401303]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009318424232227972		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.009318424232227972 | validation: 0.010533250109362482]
	TIME [epoch: 8.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016379112187103865		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.016379112187103865 | validation: 0.01369232780223488]
	TIME [epoch: 8.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010610360400178922		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.010610360400178922 | validation: 0.017556690649500148]
	TIME [epoch: 8.19 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010828615998484253		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.010828615998484253 | validation: 0.01126397829628663]
	TIME [epoch: 8.19 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053497720791915136		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.053497720791915136 | validation: 0.03159990811537869]
	TIME [epoch: 8.22 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01584746400192413		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.01584746400192413 | validation: 0.011362973316436837]
	TIME [epoch: 8.21 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009216731314521845		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.009216731314521845 | validation: 0.00854062810416614]
	TIME [epoch: 8.17 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00921328895550175		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.00921328895550175 | validation: 0.012428076528508834]
	TIME [epoch: 8.19 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00961507956658572		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.00961507956658572 | validation: 0.0098946000829397]
	TIME [epoch: 8.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010493998121995253		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.010493998121995253 | validation: 0.014271303147157615]
	TIME [epoch: 8.21 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012872081982057582		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.012872081982057582 | validation: 0.017271676996410093]
	TIME [epoch: 8.22 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013479817483096427		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.013479817483096427 | validation: 0.01665187305446785]
	TIME [epoch: 8.18 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014782652829129259		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.014782652829129259 | validation: 0.015466207146715063]
	TIME [epoch: 8.21 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01034528080481743		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.01034528080481743 | validation: 0.01174111787387461]
	TIME [epoch: 8.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009982924140638245		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.009982924140638245 | validation: 0.01494525886428888]
	TIME [epoch: 8.21 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012910151967649686		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.012910151967649686 | validation: 0.01579943559214875]
	TIME [epoch: 8.23 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009765736440848043		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.009765736440848043 | validation: 0.010780939894355595]
	TIME [epoch: 8.19 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014186844285570524		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.014186844285570524 | validation: 0.012447837539489307]
	TIME [epoch: 8.19 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009267642010442063		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.009267642010442063 | validation: 0.01045292101489091]
	TIME [epoch: 8.19 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00989048510777221		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.00989048510777221 | validation: 0.02073602582588092]
	TIME [epoch: 8.21 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01633589759644651		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.01633589759644651 | validation: 0.009396735407316847]
	TIME [epoch: 8.24 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017706116882501646		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.017706116882501646 | validation: 0.014396027955061057]
	TIME [epoch: 8.21 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01199312706023529		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.01199312706023529 | validation: 0.014432369304475074]
	TIME [epoch: 8.19 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01087760417996088		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.01087760417996088 | validation: 0.007885652828485086]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008290057866540771		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.008290057866540771 | validation: 0.009563188992113704]
	TIME [epoch: 8.19 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0148332530749405		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.0148332530749405 | validation: 0.01904787449414494]
	TIME [epoch: 8.25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012470417195036772		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.012470417195036772 | validation: 0.012257228023460753]
	TIME [epoch: 8.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00952944980162284		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.00952944980162284 | validation: 0.011200373702203028]
	TIME [epoch: 8.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009626090855758709		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.009626090855758709 | validation: 0.010975333589983764]
	TIME [epoch: 8.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013024830275705324		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.013024830275705324 | validation: 0.009700713990292062]
	TIME [epoch: 8.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008559409190881849		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.008559409190881849 | validation: 0.008086981448498787]
	TIME [epoch: 8.24 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007351144998426635		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.007351144998426635 | validation: 0.010930284477455438]
	TIME [epoch: 8.21 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01669312830634294		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.01669312830634294 | validation: 0.00990933618975508]
	TIME [epoch: 8.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007816179291501017		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.007816179291501017 | validation: 0.009931664929868151]
	TIME [epoch: 8.19 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008543983233147158		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.008543983233147158 | validation: 0.008562498866499029]
	TIME [epoch: 8.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010613845944378572		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.010613845944378572 | validation: 0.0216468593295354]
	TIME [epoch: 8.22 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014599251157001376		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.014599251157001376 | validation: 0.008791116824810222]
	TIME [epoch: 8.23 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007686500902688325		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.007686500902688325 | validation: 0.009336423851502764]
	TIME [epoch: 8.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013046699422097466		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.013046699422097466 | validation: 0.01155459279612011]
	TIME [epoch: 8.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00912253265757716		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.00912253265757716 | validation: 0.011621994708268694]
	TIME [epoch: 8.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009556839652390325		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.009556839652390325 | validation: 0.008639216853320385]
	TIME [epoch: 8.21 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008510081729129045		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.008510081729129045 | validation: 0.01621860107905071]
	TIME [epoch: 8.24 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013399548051545699		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.013399548051545699 | validation: 0.008626823006502051]
	TIME [epoch: 8.19 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008342604902655293		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.008342604902655293 | validation: 0.008507588404033359]
	TIME [epoch: 8.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009543630365683672		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.009543630365683672 | validation: 0.012012644474426872]
	TIME [epoch: 8.19 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009946481804334092		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.009946481804334092 | validation: 0.021467844916409823]
	TIME [epoch: 8.21 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01301463272856858		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.01301463272856858 | validation: 0.00855688389522139]
	TIME [epoch: 8.24 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007753797011094328		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.007753797011094328 | validation: 0.007802715792706402]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007871852028639059		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.007871852028639059 | validation: 0.018642940411679444]
	TIME [epoch: 8.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016319539622124814		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.016319539622124814 | validation: 0.009309187140209991]
	TIME [epoch: 8.19 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008121783536662996		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.008121783536662996 | validation: 0.007552866849468634]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007838643333909876		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.007838643333909876 | validation: 0.008458698775176767]
	TIME [epoch: 8.22 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007535994858146683		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.007535994858146683 | validation: 0.010321467759258282]
	TIME [epoch: 8.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013986720799121045		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.013986720799121045 | validation: 0.015944359933230186]
	TIME [epoch: 8.19 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009590982248319396		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.009590982248319396 | validation: 0.008746733457853]
	TIME [epoch: 8.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007203729543627707		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.007203729543627707 | validation: 0.008473921307293797]
	TIME [epoch: 8.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007598880388959598		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.007598880388959598 | validation: 0.009985086494351121]
	TIME [epoch: 8.23 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010060249682503066		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.010060249682503066 | validation: 0.018086456106602377]
	TIME [epoch: 8.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012708775738310581		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.012708775738310581 | validation: 0.013355445564056122]
	TIME [epoch: 8.19 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011100803497918726		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.011100803497918726 | validation: 0.013152402809687814]
	TIME [epoch: 8.19 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010922278167521584		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.010922278167521584 | validation: 0.009508010142954925]
	TIME [epoch: 8.19 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006819624045455041		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.006819624045455041 | validation: 0.007594283149982791]
	TIME [epoch: 8.22 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009366656748342164		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.009366656748342164 | validation: 0.01276975129190271]
	TIME [epoch: 8.19 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011603608956695695		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.011603608956695695 | validation: 0.010234029725124005]
	TIME [epoch: 8.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006683333244536612		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.006683333244536612 | validation: 0.008129720890866743]
	TIME [epoch: 8.17 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007180860176498893		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.007180860176498893 | validation: 0.014351333075451889]
	TIME [epoch: 8.19 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014284049049211538		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.014284049049211538 | validation: 0.007907092122838888]
	TIME [epoch: 8.21 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007406589180845052		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.007406589180845052 | validation: 0.010433897692352144]
	TIME [epoch: 8.21 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008764631004650162		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.008764631004650162 | validation: 0.010530541284497303]
	TIME [epoch: 8.19 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010641991330467376		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.010641991330467376 | validation: 0.010905831321540597]
	TIME [epoch: 8.19 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00771347941997496		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.00771347941997496 | validation: 0.007697717450485376]
	TIME [epoch: 8.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007229088438667846		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.007229088438667846 | validation: 0.01562480415606016]
	TIME [epoch: 8.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014282119602517747		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.014282119602517747 | validation: 0.009658922175445313]
	TIME [epoch: 8.23 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008697000721810098		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.008697000721810098 | validation: 0.008380776101144766]
	TIME [epoch: 8.18 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007861315176464215		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.007861315176464215 | validation: 0.00965155648922577]
	TIME [epoch: 8.19 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012239230294777718		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.012239230294777718 | validation: 0.0094531442672477]
	TIME [epoch: 8.18 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007984812063485048		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.007984812063485048 | validation: 0.010381754944911609]
	TIME [epoch: 8.18 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010196971968018028		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.010196971968018028 | validation: 0.008790807577802404]
	TIME [epoch: 8.23 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007059311979366922		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.007059311979366922 | validation: 0.00805312878489583]
	TIME [epoch: 8.19 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009776147321621164		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.009776147321621164 | validation: 0.018925072965858374]
	TIME [epoch: 8.19 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01113249214467346		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.01113249214467346 | validation: 0.00849520724171605]
	TIME [epoch: 8.18 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007902013761432196		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.007902013761432196 | validation: 0.009542821480787014]
	TIME [epoch: 8.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009366762364350818		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.009366762364350818 | validation: 0.009285799414017458]
	TIME [epoch: 8.22 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008259941559460051		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.008259941559460051 | validation: 0.009519057457935009]
	TIME [epoch: 8.21 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00904230129661473		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.00904230129661473 | validation: 0.017662040778814846]
	TIME [epoch: 8.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01043182080230438		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.01043182080230438 | validation: 0.008093245915161763]
	TIME [epoch: 8.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008423771121855562		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.008423771121855562 | validation: 0.00939109567828199]
	TIME [epoch: 8.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008508447724350606		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.008508447724350606 | validation: 0.01366093374208569]
	TIME [epoch: 8.21 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009396030952466354		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.009396030952466354 | validation: 0.0086355194824985]
	TIME [epoch: 8.21 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008757896262408615		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.008757896262408615 | validation: 0.011407330447527484]
	TIME [epoch: 8.19 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008997133385105952		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.008997133385105952 | validation: 0.008076159522914402]
	TIME [epoch: 8.19 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007354084142096651		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.007354084142096651 | validation: 0.010917694912836253]
	TIME [epoch: 8.18 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01259644686298121		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.01259644686298121 | validation: 0.009023264929254558]
	TIME [epoch: 8.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007927215182941242		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.007927215182941242 | validation: 0.00896729866105124]
	TIME [epoch: 8.22 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006897351811065515		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.006897351811065515 | validation: 0.00752158312917628]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009267725617485047		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.009267725617485047 | validation: 0.009155406305801146]
	TIME [epoch: 8.18 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008043540447618546		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.008043540447618546 | validation: 0.011516022576732106]
	TIME [epoch: 8.18 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008840694109405774		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.008840694109405774 | validation: 0.0081304951099085]
	TIME [epoch: 8.19 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006551813348589339		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.006551813348589339 | validation: 0.009837490607670167]
	TIME [epoch: 8.24 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009730507506278645		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.009730507506278645 | validation: 0.012271353111727456]
	TIME [epoch: 8.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00848450673411015		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.00848450673411015 | validation: 0.008448360373247109]
	TIME [epoch: 8.19 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008903859755668177		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.008903859755668177 | validation: 0.013691305474784542]
	TIME [epoch: 8.19 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009359582315393114		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.009359582315393114 | validation: 0.007953983029640932]
	TIME [epoch: 8.19 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006174065921138342		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.006174065921138342 | validation: 0.00791767468274484]
	TIME [epoch: 8.24 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008670288346565979		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.008670288346565979 | validation: 0.01509657060122541]
	TIME [epoch: 8.18 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009237482829858857		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.009237482829858857 | validation: 0.00856985062663346]
	TIME [epoch: 8.19 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007312651246597		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.007312651246597 | validation: 0.007033843305962352]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006373289559586389		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.006373289559586389 | validation: 0.007414609454495869]
	TIME [epoch: 8.18 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068396508804761695		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.0068396508804761695 | validation: 0.016650759047699224]
	TIME [epoch: 8.22 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01062998944791951		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.01062998944791951 | validation: 0.011063389352447257]
	TIME [epoch: 8.18 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007375446130112218		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.007375446130112218 | validation: 0.007701461505412701]
	TIME [epoch: 8.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006584290953458241		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.006584290953458241 | validation: 0.01102837534829687]
	TIME [epoch: 8.19 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010464656401944		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.010464656401944 | validation: 0.009115146163459922]
	TIME [epoch: 8.18 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00668817530577222		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.00668817530577222 | validation: 0.006522683642701492]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006811498267147137		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.006811498267147137 | validation: 0.012145248970691568]
	TIME [epoch: 8.21 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008825029946726936		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.008825029946726936 | validation: 0.0075748615978547375]
	TIME [epoch: 8.19 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006950493835114526		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.006950493835114526 | validation: 0.01059681345546639]
	TIME [epoch: 8.19 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01016388780404905		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.01016388780404905 | validation: 0.00904136373449337]
	TIME [epoch: 8.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005856561929753135		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.005856561929753135 | validation: 0.00672820999213765]
	TIME [epoch: 8.21 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006969544606025094		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.006969544606025094 | validation: 0.014812118258060461]
	TIME [epoch: 8.22 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880538208378211		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.00880538208378211 | validation: 0.008070471202644288]
	TIME [epoch: 8.18 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007265893260967043		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.007265893260967043 | validation: 0.009701659665182138]
	TIME [epoch: 8.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006450763160106604		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.006450763160106604 | validation: 0.006832718556166055]
	TIME [epoch: 8.19 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072740298322069566		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.0072740298322069566 | validation: 0.007229220493218311]
	TIME [epoch: 8.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009615096425951618		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.009615096425951618 | validation: 0.012385953795013931]
	TIME [epoch: 8.23 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008568766056994416		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.008568766056994416 | validation: 0.008632241131066176]
	TIME [epoch: 8.19 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00769056944710594		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.00769056944710594 | validation: 0.0085639133248377]
	TIME [epoch: 8.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068516324846863135		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.0068516324846863135 | validation: 0.006924749593344997]
	TIME [epoch: 8.18 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059774728804285835		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.0059774728804285835 | validation: 0.00825941305957625]
	TIME [epoch: 8.21 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00712780318327343		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.00712780318327343 | validation: 0.016176204876682535]
	TIME [epoch: 8.23 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009505655119507841		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.009505655119507841 | validation: 0.007320126479146552]
	TIME [epoch: 8.21 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006909847391845232		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.006909847391845232 | validation: 0.009327620230152848]
	TIME [epoch: 8.19 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007545693568421434		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.007545693568421434 | validation: 0.007508844342653229]
	TIME [epoch: 8.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071617614960057824		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0071617614960057824 | validation: 0.009167834571623321]
	TIME [epoch: 8.18 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00741622019100212		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.00741622019100212 | validation: 0.009523305028675643]
	TIME [epoch: 8.22 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007613877736253742		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.007613877736253742 | validation: 0.010382563473653864]
	TIME [epoch: 8.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008112977936936182		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.008112977936936182 | validation: 0.007105337799314822]
	TIME [epoch: 8.19 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006589983936290677		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.006589983936290677 | validation: 0.014985208998523972]
	TIME [epoch: 8.19 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008966800458428148		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.008966800458428148 | validation: 0.006971088098490126]
	TIME [epoch: 8.19 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007508096872398233		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.007508096872398233 | validation: 0.007390361414781398]
	TIME [epoch: 8.22 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005924376330807503		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.005924376330807503 | validation: 0.008781272830823922]
	TIME [epoch: 8.21 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009513833041632029		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.009513833041632029 | validation: 0.008310981927765441]
	TIME [epoch: 8.19 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007026402752904996		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.007026402752904996 | validation: 0.007849701705034295]
	TIME [epoch: 8.18 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006263192829045741		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.006263192829045741 | validation: 0.00912263989123086]
	TIME [epoch: 8.19 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008614525148608991		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.008614525148608991 | validation: 0.007279449160728329]
	TIME [epoch: 8.21 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006417414515691674		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.006417414515691674 | validation: 0.008954477537942087]
	TIME [epoch: 8.23 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007956153816250665		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.007956153816250665 | validation: 0.0058916738700666715]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_645.pth
	Model improved!!!
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007268406705213069		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.007268406705213069 | validation: 0.0081349678612289]
	TIME [epoch: 8.19 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006986781888127082		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.006986781888127082 | validation: 0.008034257102954051]
	TIME [epoch: 8.19 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007280061126480479		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.007280061126480479 | validation: 0.01099974009658561]
	TIME [epoch: 8.19 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006510896085646589		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.006510896085646589 | validation: 0.008807305755285186]
	TIME [epoch: 8.24 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007820212267489218		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.007820212267489218 | validation: 0.007269408734855924]
	TIME [epoch: 8.19 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006427368528599714		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.006427368528599714 | validation: 0.008987012835175019]
	TIME [epoch: 8.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008667552096111824		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.008667552096111824 | validation: 0.007099393583098605]
	TIME [epoch: 8.18 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006709939353560855		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.006709939353560855 | validation: 0.007204648731899014]
	TIME [epoch: 8.19 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006298070009398352		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.006298070009398352 | validation: 0.011841013006998663]
	TIME [epoch: 8.23 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008559403933334226		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.008559403933334226 | validation: 0.006867853107371202]
	TIME [epoch: 8.19 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006707102411698818		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.006707102411698818 | validation: 0.00665133192243033]
	TIME [epoch: 8.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005853618743032714		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.005853618743032714 | validation: 0.009816270024735688]
	TIME [epoch: 8.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008935979588105642		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.008935979588105642 | validation: 0.006492907816651791]
	TIME [epoch: 8.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005502380183959215		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.005502380183959215 | validation: 0.007066737536727598]
	TIME [epoch: 8.23 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005970758569811806		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.005970758569811806 | validation: 0.007589323556291144]
	TIME [epoch: 8.21 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006546408731396442		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.006546408731396442 | validation: 0.010498959919604391]
	TIME [epoch: 8.19 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010219436178950604		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.010219436178950604 | validation: 0.0074197351805234]
	TIME [epoch: 8.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006394294168574991		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.006394294168574991 | validation: 0.007951527089730872]
	TIME [epoch: 8.19 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005892989604548019		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.005892989604548019 | validation: 0.00825867241192885]
	TIME [epoch: 8.22 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007299389393895163		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.007299389393895163 | validation: 0.007681184875946673]
	TIME [epoch: 8.22 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006956499006186905		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.006956499006186905 | validation: 0.007597492838984494]
	TIME [epoch: 8.19 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006513654016565685		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.006513654016565685 | validation: 0.007572993124313505]
	TIME [epoch: 8.19 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006878889255109277		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.006878889255109277 | validation: 0.009701177597407743]
	TIME [epoch: 8.19 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007876550349442586		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.007876550349442586 | validation: 0.0073899708694691035]
	TIME [epoch: 8.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060744938592133405		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.0060744938592133405 | validation: 0.008000462298240748]
	TIME [epoch: 8.23 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006109195221241111		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.006109195221241111 | validation: 0.00765734875055212]
	TIME [epoch: 8.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070438790314561765		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.0070438790314561765 | validation: 0.010915804884564402]
	TIME [epoch: 8.18 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007318489792185985		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.007318489792185985 | validation: 0.006552492937079248]
	TIME [epoch: 8.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01096022320264007		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.01096022320264007 | validation: 0.009974657942237283]
	TIME [epoch: 8.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00649724589437556		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.00649724589437556 | validation: 0.007712916700492393]
	TIME [epoch: 8.23 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006622290203227556		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.006622290203227556 | validation: 0.006510983317181243]
	TIME [epoch: 8.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00617245268337251		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.00617245268337251 | validation: 0.007624821176878025]
	TIME [epoch: 8.19 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070812067270281335		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.0070812067270281335 | validation: 0.009724513997015911]
	TIME [epoch: 8.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006876752706072678		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.006876752706072678 | validation: 0.007283989592792896]
	TIME [epoch: 8.19 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006411991434766557		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.006411991434766557 | validation: 0.01092071951067761]
	TIME [epoch: 8.24 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006644968567699657		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.006644968567699657 | validation: 0.007208298909804965]
	TIME [epoch: 8.19 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067065820534671534		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.0067065820534671534 | validation: 0.0059824318177058265]
	TIME [epoch: 8.21 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055852177351459024		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0055852177351459024 | validation: 0.007600576507613843]
	TIME [epoch: 8.19 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006951943977887948		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.006951943977887948 | validation: 0.006734077554251351]
	TIME [epoch: 8.18 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007114830776119522		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.007114830776119522 | validation: 0.006514825353718933]
	TIME [epoch: 8.24 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00601150593046657		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.00601150593046657 | validation: 0.00636091584777489]
	TIME [epoch: 8.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006748862560928061		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.006748862560928061 | validation: 0.008654282306136928]
	TIME [epoch: 8.19 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005887215984680497		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.005887215984680497 | validation: 0.006028889807584394]
	TIME [epoch: 8.19 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006312117492593201		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.006312117492593201 | validation: 0.006332965354421686]
	TIME [epoch: 8.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068880154154418935		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.0068880154154418935 | validation: 0.011380335536824927]
	TIME [epoch: 8.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007473431486555904		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.007473431486555904 | validation: 0.006991228948517312]
	TIME [epoch: 8.22 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005256607342107387		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.005256607342107387 | validation: 0.006597705690767587]
	TIME [epoch: 8.18 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006874624574025779		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.006874624574025779 | validation: 0.007564700309470018]
	TIME [epoch: 8.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006034999348039371		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.006034999348039371 | validation: 0.00790960877074807]
	TIME [epoch: 8.19 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005773095324987162		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.005773095324987162 | validation: 0.007116214839649099]
	TIME [epoch: 8.19 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077183796741796245		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.0077183796741796245 | validation: 0.006359065626453]
	TIME [epoch: 8.23 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005848127867757432		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.005848127867757432 | validation: 0.009065094021865706]
	TIME [epoch: 8.19 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006461425392070492		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.006461425392070492 | validation: 0.007279986420642251]
	TIME [epoch: 8.19 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006140483902486116		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.006140483902486116 | validation: 0.012778064619921804]
	TIME [epoch: 8.19 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007627659579095145		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.007627659579095145 | validation: 0.0071123095948764856]
	TIME [epoch: 8.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005572914922291135		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.005572914922291135 | validation: 0.006347120121818914]
	TIME [epoch: 8.23 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005976280244377236		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.005976280244377236 | validation: 0.007681120935406062]
	TIME [epoch: 8.19 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008661110562916128		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.008661110562916128 | validation: 0.007518477991307506]
	TIME [epoch: 8.18 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006209774316841939		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.006209774316841939 | validation: 0.005916828857776569]
	TIME [epoch: 8.19 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005420815216641456		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.005420815216641456 | validation: 0.0062704104896573794]
	TIME [epoch: 8.18 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00586947481090069		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.00586947481090069 | validation: 0.007757139142234069]
	TIME [epoch: 8.22 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005974987744002262		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.005974987744002262 | validation: 0.006971156840198363]
	TIME [epoch: 8.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005741725550226101		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.005741725550226101 | validation: 0.006513953354620535]
	TIME [epoch: 8.18 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007566839786836066		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.007566839786836066 | validation: 0.011188371020121273]
	TIME [epoch: 8.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067720363359097865		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.0067720363359097865 | validation: 0.006088842649722861]
	TIME [epoch: 8.18 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005844280177226662		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.005844280177226662 | validation: 0.00778474434779713]
	TIME [epoch: 8.23 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005779819221025441		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.005779819221025441 | validation: 0.006476838720349577]
	TIME [epoch: 8.19 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006361793716311907		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.006361793716311907 | validation: 0.009153031710951356]
	TIME [epoch: 8.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064354669749056344		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.0064354669749056344 | validation: 0.006579015482398376]
	TIME [epoch: 8.19 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006971337525699397		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.006971337525699397 | validation: 0.007930463822508322]
	TIME [epoch: 8.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005257087292606983		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.005257087292606983 | validation: 0.0067473459531878]
	TIME [epoch: 8.21 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006385259318051463		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.006385259318051463 | validation: 0.006896821336700136]
	TIME [epoch: 8.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005548422008524408		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.005548422008524408 | validation: 0.005771850277269711]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00513399453017426		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.00513399453017426 | validation: 0.007434811301329435]
	TIME [epoch: 8.17 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005763900847103242		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.005763900847103242 | validation: 0.01057488385814591]
	TIME [epoch: 8.19 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00721962791994759		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.00721962791994759 | validation: 0.006129849749663366]
	TIME [epoch: 8.19 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005476608162428487		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.005476608162428487 | validation: 0.005746633222950921]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_722.pth
	Model improved!!!
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006573318326996508		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.006573318326996508 | validation: 0.007461959713142536]
	TIME [epoch: 8.18 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005154136478498288		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.005154136478498288 | validation: 0.007357882901742481]
	TIME [epoch: 8.18 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005480778555377494		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.005480778555377494 | validation: 0.008417996385704493]
	TIME [epoch: 8.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007122725166634578		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.007122725166634578 | validation: 0.007361795244217287]
	TIME [epoch: 8.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005485546995924813		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.005485546995924813 | validation: 0.005914378614332465]
	TIME [epoch: 8.25 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00504125698860819		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.00504125698860819 | validation: 0.006320275748189482]
	TIME [epoch: 8.19 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005004168786491081		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.005004168786491081 | validation: 0.005897980964738422]
	TIME [epoch: 8.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007506969948539579		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.007506969948539579 | validation: 0.006380943816774131]
	TIME [epoch: 8.19 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00635987984780402		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.00635987984780402 | validation: 0.0064683209245718345]
	TIME [epoch: 8.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005292632109829488		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.005292632109829488 | validation: 0.006156714057134029]
	TIME [epoch: 8.22 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00500949655748515		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.00500949655748515 | validation: 0.007022119964904429]
	TIME [epoch: 8.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006402190454270937		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.006402190454270937 | validation: 0.005929471424508536]
	TIME [epoch: 8.19 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005133448679539734		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.005133448679539734 | validation: 0.0060297953901232]
	TIME [epoch: 8.18 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006235390032327936		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.006235390032327936 | validation: 0.009235705155142885]
	TIME [epoch: 8.18 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006543665551750544		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.006543665551750544 | validation: 0.009490754718328725]
	TIME [epoch: 8.22 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060519546678641225		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.0060519546678641225 | validation: 0.006193126208387462]
	TIME [epoch: 8.21 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005089720800516695		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.005089720800516695 | validation: 0.007229300074879081]
	TIME [epoch: 8.18 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005463955233926946		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.005463955233926946 | validation: 0.006841238648454939]
	TIME [epoch: 8.19 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006324861283551636		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.006324861283551636 | validation: 0.006414791197220281]
	TIME [epoch: 8.18 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005267502850164809		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.005267502850164809 | validation: 0.006343955606354704]
	TIME [epoch: 8.19 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051471023523860255		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.0051471023523860255 | validation: 0.006831094071142822]
	TIME [epoch: 8.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073053378014924855		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.0073053378014924855 | validation: 0.006067821126855312]
	TIME [epoch: 8.19 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005535688776662246		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.005535688776662246 | validation: 0.006775429960658054]
	TIME [epoch: 8.19 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005077204040565742		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.005077204040565742 | validation: 0.0061611810906099405]
	TIME [epoch: 8.19 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005159634032207739		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.005159634032207739 | validation: 0.007325862120840167]
	TIME [epoch: 8.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00542738528939087		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.00542738528939087 | validation: 0.007443259628773751]
	TIME [epoch: 8.22 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006481876453440225		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.006481876453440225 | validation: 0.00717419579963611]
	TIME [epoch: 8.19 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005179312326840943		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.005179312326840943 | validation: 0.005804054213566974]
	TIME [epoch: 8.18 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005477450967591546		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.005477450967591546 | validation: 0.008424925039934018]
	TIME [epoch: 8.19 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060273911334002865		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.0060273911334002865 | validation: 0.006627252148145334]
	TIME [epoch: 8.17 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005402059089117806		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.005402059089117806 | validation: 0.006378235882798958]
	TIME [epoch: 8.23 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048799988452265805		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.0048799988452265805 | validation: 0.007094799425157252]
	TIME [epoch: 8.19 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006048788774102572		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.006048788774102572 | validation: 0.005453244907566885]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_755.pth
	Model improved!!!
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005153978512019179		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.005153978512019179 | validation: 0.006984399607565003]
	TIME [epoch: 8.19 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005242037467370082		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.005242037467370082 | validation: 0.006233965566753389]
	TIME [epoch: 8.18 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005306572529226148		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.005306572529226148 | validation: 0.006352593037804234]
	TIME [epoch: 8.24 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004944898612853819		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.004944898612853819 | validation: 0.005804461110576579]
	TIME [epoch: 8.19 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006810620616409852		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.006810620616409852 | validation: 0.007880900477787275]
	TIME [epoch: 8.19 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005415041420323272		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.005415041420323272 | validation: 0.005726610392644327]
	TIME [epoch: 8.17 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053473556926136485		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0053473556926136485 | validation: 0.006664566134627266]
	TIME [epoch: 8.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005275831453632418		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.005275831453632418 | validation: 0.005579702511138045]
	TIME [epoch: 8.22 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005443688242525958		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.005443688242525958 | validation: 0.007032005276791813]
	TIME [epoch: 8.19 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005664750415474901		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.005664750415474901 | validation: 0.006490826700215764]
	TIME [epoch: 8.18 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004718131923182988		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.004718131923182988 | validation: 0.006063760703868297]
	TIME [epoch: 8.18 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00561383160690195		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.00561383160690195 | validation: 0.008141248199377052]
	TIME [epoch: 8.19 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005339844571479825		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.005339844571479825 | validation: 0.006282906458037558]
	TIME [epoch: 8.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005589080764590047		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.005589080764590047 | validation: 0.007302676832892063]
	TIME [epoch: 8.21 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006247885694765547		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.006247885694765547 | validation: 0.005973612331380209]
	TIME [epoch: 8.17 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00466554161813152		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.00466554161813152 | validation: 0.00579996779612335]
	TIME [epoch: 8.18 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005316039585447178		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.005316039585447178 | validation: 0.005752970461833819]
	TIME [epoch: 8.17 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056403056598834		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0056403056598834 | validation: 0.009695856267180692]
	TIME [epoch: 8.19 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005911955777400607		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.005911955777400607 | validation: 0.007714823283206218]
	TIME [epoch: 8.23 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005272445655393024		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.005272445655393024 | validation: 0.00733646566365306]
	TIME [epoch: 8.18 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004979378407447622		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.004979378407447622 | validation: 0.005063724685321704]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005701438719864447		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.005701438719864447 | validation: 0.007193838512796036]
	TIME [epoch: 8.18 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00566303895801755		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.00566303895801755 | validation: 0.006739478138798042]
	TIME [epoch: 8.18 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004539065033253794		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.004539065033253794 | validation: 0.00632565720141006]
	TIME [epoch: 8.22 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055079453347825595		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.0055079453347825595 | validation: 0.005580957723728882]
	TIME [epoch: 8.18 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005439566147824933		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.005439566147824933 | validation: 0.0057522378914188505]
	TIME [epoch: 8.19 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00491914448313306		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.00491914448313306 | validation: 0.008247349677573337]
	TIME [epoch: 8.19 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049357942071092875		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0049357942071092875 | validation: 0.00628601737448594]
	TIME [epoch: 8.17 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005150240468739554		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.005150240468739554 | validation: 0.0059869950962801585]
	TIME [epoch: 8.22 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004870640975742336		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.004870640975742336 | validation: 0.005825290959921642]
	TIME [epoch: 8.19 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006235152412758192		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.006235152412758192 | validation: 0.00685896865877684]
	TIME [epoch: 8.18 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00510302706525313		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.00510302706525313 | validation: 0.014383687128155163]
	TIME [epoch: 8.19 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006888465977549592		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.006888465977549592 | validation: 0.006679132881093609]
	TIME [epoch: 8.18 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005937237470931283		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.005937237470931283 | validation: 0.006626642615777714]
	TIME [epoch: 8.21 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005341394012600312		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.005341394012600312 | validation: 0.006017373331656485]
	TIME [epoch: 8.19 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049018200944037586		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.0049018200944037586 | validation: 0.0055892201056270685]
	TIME [epoch: 8.19 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045097870594287765		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.0045097870594287765 | validation: 0.0057958390000159375]
	TIME [epoch: 8.16 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053837817826639656		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0053837817826639656 | validation: 0.008844474484691393]
	TIME [epoch: 8.18 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050899496853283556		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.0050899496853283556 | validation: 0.005422690635467981]
	TIME [epoch: 8.18 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004510451274388387		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.004510451274388387 | validation: 0.006422344516369045]
	TIME [epoch: 8.21 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004621984238321338		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.004621984238321338 | validation: 0.006947916540569534]
	TIME [epoch: 8.19 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006084321788045892		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.006084321788045892 | validation: 0.005745740505828402]
	TIME [epoch: 8.17 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005302861699832806		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.005302861699832806 | validation: 0.007217909529996505]
	TIME [epoch: 8.18 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005258756943775062		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.005258756943775062 | validation: 0.006432606777109691]
	TIME [epoch: 8.17 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004916629939284184		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.004916629939284184 | validation: 0.005855372127814864]
	TIME [epoch: 8.22 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005008426711344775		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.005008426711344775 | validation: 0.005801451423152608]
	TIME [epoch: 8.18 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004934087959293156		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.004934087959293156 | validation: 0.0057589198831225815]
	TIME [epoch: 8.19 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005396129498109933		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.005396129498109933 | validation: 0.006606101741718797]
	TIME [epoch: 8.18 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004559247220097723		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.004559247220097723 | validation: 0.006139159895336095]
	TIME [epoch: 8.17 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00483188024402828		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.00483188024402828 | validation: 0.0063432438149913055]
	TIME [epoch: 8.22 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005055264701703947		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.005055264701703947 | validation: 0.005841396816453286]
	TIME [epoch: 8.18 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00442674882505469		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.00442674882505469 | validation: 0.005654537396094705]
	TIME [epoch: 8.18 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005597264324201052		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.005597264324201052 | validation: 0.006100958429956579]
	TIME [epoch: 8.18 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005323651664036847		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.005323651664036847 | validation: 0.006825264197887549]
	TIME [epoch: 8.19 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005100291408903602		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.005100291408903602 | validation: 0.005012393711413907]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00444355379055318		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.00444355379055318 | validation: 0.005683164257802784]
	TIME [epoch: 8.21 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004818678549376313		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.004818678549376313 | validation: 0.005355302242964832]
	TIME [epoch: 8.19 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004580298870910382		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.004580298870910382 | validation: 0.007326615451723405]
	TIME [epoch: 8.19 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006542428738157902		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.006542428738157902 | validation: 0.006891081302065451]
	TIME [epoch: 8.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004793582837184526		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.004793582837184526 | validation: 0.004890188312307029]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004325501544392506		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.004325501544392506 | validation: 0.005367292120740936]
	TIME [epoch: 8.22 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050214673523544095		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.0050214673523544095 | validation: 0.006398786128118178]
	TIME [epoch: 8.19 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005224643790434468		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.005224643790434468 | validation: 0.005259309611449695]
	TIME [epoch: 8.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044414055244481505		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0044414055244481505 | validation: 0.005912787281442759]
	TIME [epoch: 8.18 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004751024542665879		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.004751024542665879 | validation: 0.0070959079192277645]
	TIME [epoch: 8.21 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004991388229154833		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.004991388229154833 | validation: 0.005025987611458732]
	TIME [epoch: 8.22 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00484653554701471		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.00484653554701471 | validation: 0.0070124605356545605]
	TIME [epoch: 8.18 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055108743907785794		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0055108743907785794 | validation: 0.006448629555712989]
	TIME [epoch: 8.19 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005133023040430498		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.005133023040430498 | validation: 0.006134432924094819]
	TIME [epoch: 8.18 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004447677816152499		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.004447677816152499 | validation: 0.005608832314649719]
	TIME [epoch: 8.19 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004743162631813749		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.004743162631813749 | validation: 0.005887794439921191]
	TIME [epoch: 8.22 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042393303127240085		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0042393303127240085 | validation: 0.005010155127955427]
	TIME [epoch: 8.19 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004655127526050635		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.004655127526050635 | validation: 0.005945276869860281]
	TIME [epoch: 8.18 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005526873260845796		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.005526873260845796 | validation: 0.00593587120704379]
	TIME [epoch: 8.19 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048300076076795056		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0048300076076795056 | validation: 0.005169542512194723]
	TIME [epoch: 8.18 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046976014056055015		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0046976014056055015 | validation: 0.006269566189662156]
	TIME [epoch: 8.24 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004620914829083386		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.004620914829083386 | validation: 0.005674569188408297]
	TIME [epoch: 8.19 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004344810540137364		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.004344810540137364 | validation: 0.007321587604642037]
	TIME [epoch: 8.18 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049086386778674565		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0049086386778674565 | validation: 0.005884320610293028]
	TIME [epoch: 8.19 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052326864817434015		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0052326864817434015 | validation: 0.005361754562459473]
	TIME [epoch: 8.18 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004545972323578805		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.004545972323578805 | validation: 0.005448546721540812]
	TIME [epoch: 8.22 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004206329947766433		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.004206329947766433 | validation: 0.00559047397446949]
	TIME [epoch: 8.19 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004730583879489515		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.004730583879489515 | validation: 0.007117161794714886]
	TIME [epoch: 8.19 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051986159125135874		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0051986159125135874 | validation: 0.005107635495120864]
	TIME [epoch: 8.18 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004808604594236371		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.004808604594236371 | validation: 0.005493356957759672]
	TIME [epoch: 8.19 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004939948602508572		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.004939948602508572 | validation: 0.0056276350902237805]
	TIME [epoch: 8.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004796487267892561		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.004796487267892561 | validation: 0.005649767435880951]
	TIME [epoch: 8.21 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004915577757066843		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.004915577757066843 | validation: 0.005419761519489993]
	TIME [epoch: 8.18 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045300604395767715		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.0045300604395767715 | validation: 0.005939273730002676]
	TIME [epoch: 8.19 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005011167554028441		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.005011167554028441 | validation: 0.005486934047746193]
	TIME [epoch: 8.19 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004636359700189477		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.004636359700189477 | validation: 0.006188109488436134]
	TIME [epoch: 8.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005146914509717731		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.005146914509717731 | validation: 0.006193800215665516]
	TIME [epoch: 8.22 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004415853578284809		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.004415853578284809 | validation: 0.0050962978956014095]
	TIME [epoch: 8.19 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004680607192412648		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.004680607192412648 | validation: 0.005716461244830815]
	TIME [epoch: 8.19 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004661350168386452		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.004661350168386452 | validation: 0.005454062781467504]
	TIME [epoch: 8.18 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046626899885550965		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.0046626899885550965 | validation: 0.007446400818091602]
	TIME [epoch: 8.19 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005079392678921033		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.005079392678921033 | validation: 0.005705956331872361]
	TIME [epoch: 8.23 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004759319259116346		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.004759319259116346 | validation: 0.006302522652038971]
	TIME [epoch: 8.19 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004251131370097936		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.004251131370097936 | validation: 0.0051735640711807656]
	TIME [epoch: 8.19 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004703496914738873		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.004703496914738873 | validation: 0.007211968508122205]
	TIME [epoch: 8.18 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004274853383588703		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.004274853383588703 | validation: 0.006636729390754778]
	TIME [epoch: 8.19 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004939722090541417		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.004939722090541417 | validation: 0.006008146736049071]
	TIME [epoch: 8.22 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004770150949929188		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.004770150949929188 | validation: 0.005471076109096138]
	TIME [epoch: 8.21 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00431686501112406		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.00431686501112406 | validation: 0.005052914704576831]
	TIME [epoch: 8.19 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004393291637226862		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.004393291637226862 | validation: 0.006187729814843491]
	TIME [epoch: 8.19 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004637946217315772		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.004637946217315772 | validation: 0.006017034132387033]
	TIME [epoch: 8.18 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043796517916377745		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.0043796517916377745 | validation: 0.005751121920483531]
	TIME [epoch: 8.23 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00470732267427706		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.00470732267427706 | validation: 0.005435653671324562]
	TIME [epoch: 8.19 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004502455164797012		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.004502455164797012 | validation: 0.007450969947514312]
	TIME [epoch: 8.18 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004820089555774331		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.004820089555774331 | validation: 0.005510998694759664]
	TIME [epoch: 8.18 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004855350207559952		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.004855350207559952 | validation: 0.006830444809539496]
	TIME [epoch: 8.18 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004236746889596549		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.004236746889596549 | validation: 0.005482517191409813]
	TIME [epoch: 8.21 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004561106795119169		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.004561106795119169 | validation: 0.004852800811389826]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003926763573849879		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.003926763573849879 | validation: 0.005008882371786578]
	TIME [epoch: 8.19 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004439824148903781		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.004439824148903781 | validation: 0.00598881418515872]
	TIME [epoch: 8.18 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004597664235624226		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.004597664235624226 | validation: 0.005192833568612727]
	TIME [epoch: 8.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004812722047502375		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.004812722047502375 | validation: 0.005514140045683753]
	TIME [epoch: 8.19 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004082866412350242		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.004082866412350242 | validation: 0.005901468324440313]
	TIME [epoch: 8.22 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004618504017445752		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.004618504017445752 | validation: 0.005706633902697582]
	TIME [epoch: 8.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004584703255227307		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.004584703255227307 | validation: 0.005461999482758804]
	TIME [epoch: 8.19 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004334130317422898		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.004334130317422898 | validation: 0.005222689169254041]
	TIME [epoch: 8.19 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004144620398092848		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.004144620398092848 | validation: 0.005034570839895199]
	TIME [epoch: 8.19 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004598220240168427		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.004598220240168427 | validation: 0.005826121798545165]
	TIME [epoch: 8.23 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004398351701283351		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.004398351701283351 | validation: 0.0056216353094422754]
	TIME [epoch: 8.18 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004232221481025121		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.004232221481025121 | validation: 0.00511965357132366]
	TIME [epoch: 8.19 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004278036656378263		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.004278036656378263 | validation: 0.005234565253587181]
	TIME [epoch: 8.17 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004732277885180313		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.004732277885180313 | validation: 0.00555701177999236]
	TIME [epoch: 8.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046391882787973635		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0046391882787973635 | validation: 0.0057981179550895025]
	TIME [epoch: 8.22 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004360787080370444		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.004360787080370444 | validation: 0.0060767590225103895]
	TIME [epoch: 8.19 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004652816161942814		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.004652816161942814 | validation: 0.005833466014819289]
	TIME [epoch: 8.19 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004495432842123069		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.004495432842123069 | validation: 0.005153261032794716]
	TIME [epoch: 8.18 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041315675707389934		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0041315675707389934 | validation: 0.005267843167915075]
	TIME [epoch: 8.19 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004548057528112808		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.004548057528112808 | validation: 0.005997220601304318]
	TIME [epoch: 8.22 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004801023421640885		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.004801023421640885 | validation: 0.005094468192845288]
	TIME [epoch: 8.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004313783812339399		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.004313783812339399 | validation: 0.005860523346035215]
	TIME [epoch: 8.19 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004470654354222076		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.004470654354222076 | validation: 0.005395892742383065]
	TIME [epoch: 8.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004328911496244065		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.004328911496244065 | validation: 0.0049419571734076635]
	TIME [epoch: 8.17 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004461233512507792		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.004461233512507792 | validation: 0.004908824150086368]
	TIME [epoch: 8.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004392660743870167		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.004392660743870167 | validation: 0.005472275451939823]
	TIME [epoch: 8.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049622223787669515		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0049622223787669515 | validation: 0.0052860404332396894]
	TIME [epoch: 8.17 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045183460892791304		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0045183460892791304 | validation: 0.005366969609002442]
	TIME [epoch: 8.18 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004355391786912398		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.004355391786912398 | validation: 0.004874445092574387]
	TIME [epoch: 8.19 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004581997379813995		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.004581997379813995 | validation: 0.005921204306258403]
	TIME [epoch: 8.19 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003961251907087651		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.003961251907087651 | validation: 0.0044487219382949115]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_899.pth
	Model improved!!!
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00470549523907487		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.00470549523907487 | validation: 0.005486173247703218]
	TIME [epoch: 8.19 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003826800214422642		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.003826800214422642 | validation: 0.006833199606105997]
	TIME [epoch: 8.18 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004533741749936001		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.004533741749936001 | validation: 0.005209619783170646]
	TIME [epoch: 8.17 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004382475965034652		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.004382475965034652 | validation: 0.004737115197933454]
	TIME [epoch: 8.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044431080697475474		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0044431080697475474 | validation: 0.005365921267304721]
	TIME [epoch: 8.23 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004342311517922628		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.004342311517922628 | validation: 0.0051901703634486575]
	TIME [epoch: 8.19 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004289032990670187		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.004289032990670187 | validation: 0.00483519512532676]
	TIME [epoch: 8.18 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003899139511598292		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.003899139511598292 | validation: 0.005018964034670179]
	TIME [epoch: 8.19 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004349961985178184		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.004349961985178184 | validation: 0.00545050655432889]
	TIME [epoch: 8.18 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004052297867651369		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.004052297867651369 | validation: 0.005241226173426419]
	TIME [epoch: 8.22 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004020056357680826		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.004020056357680826 | validation: 0.006568262888310588]
	TIME [epoch: 8.19 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004496743083284361		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.004496743083284361 | validation: 0.005955509050973693]
	TIME [epoch: 8.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004664411372479342		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.004664411372479342 | validation: 0.005428446910499443]
	TIME [epoch: 8.18 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004420367837934946		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.004420367837934946 | validation: 0.006009876756146084]
	TIME [epoch: 8.18 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00404427591481587		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.00404427591481587 | validation: 0.004274480931886833]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_914.pth
	Model improved!!!
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003912767828931799		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.003912767828931799 | validation: 0.005012385171824231]
	TIME [epoch: 8.19 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004510033348497636		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.004510033348497636 | validation: 0.004444106635425163]
	TIME [epoch: 8.19 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004110014559423277		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.004110014559423277 | validation: 0.0053062124379873316]
	TIME [epoch: 8.18 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003927646790206025		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.003927646790206025 | validation: 0.005212740212889582]
	TIME [epoch: 8.19 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004113150151393494		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.004113150151393494 | validation: 0.005842484037412014]
	TIME [epoch: 8.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004333234247688078		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.004333234247688078 | validation: 0.006185951162489885]
	TIME [epoch: 8.21 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004249560196166653		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.004249560196166653 | validation: 0.004561045263888057]
	TIME [epoch: 8.17 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004058183527018941		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.004058183527018941 | validation: 0.004997740380853359]
	TIME [epoch: 8.19 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043127015474036245		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0043127015474036245 | validation: 0.005918815202323341]
	TIME [epoch: 8.18 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004351747454480019		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.004351747454480019 | validation: 0.005057535752216338]
	TIME [epoch: 8.19 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004689616856674966		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.004689616856674966 | validation: 0.004932100513376461]
	TIME [epoch: 8.23 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004284927691883173		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.004284927691883173 | validation: 0.005717344900450312]
	TIME [epoch: 8.18 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004102370699232783		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.004102370699232783 | validation: 0.004578924878133637]
	TIME [epoch: 8.18 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004351160217097443		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.004351160217097443 | validation: 0.00580117225166575]
	TIME [epoch: 8.18 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042364227781198855		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0042364227781198855 | validation: 0.006022329371347189]
	TIME [epoch: 8.19 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004292796899834955		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.004292796899834955 | validation: 0.006142769663783662]
	TIME [epoch: 8.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004350662446656443		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.004350662446656443 | validation: 0.005292861506222298]
	TIME [epoch: 8.19 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00410504615958776		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.00410504615958776 | validation: 0.005436399428957777]
	TIME [epoch: 8.19 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003759768461245501		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.003759768461245501 | validation: 0.0053510338417753055]
	TIME [epoch: 8.18 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004025646979032923		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.004025646979032923 | validation: 0.005492988767219928]
	TIME [epoch: 8.19 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00409054818262214		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.00409054818262214 | validation: 0.00525707777473008]
	TIME [epoch: 8.22 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043608750582495425		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0043608750582495425 | validation: 0.004857754114313818]
	TIME [epoch: 8.19 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004131278899390009		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.004131278899390009 | validation: 0.00501762052719411]
	TIME [epoch: 8.17 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004014517931249061		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.004014517931249061 | validation: 0.005252559358074211]
	TIME [epoch: 8.19 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042365034920500404		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0042365034920500404 | validation: 0.004999114814763755]
	TIME [epoch: 8.17 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041917074570083385		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0041917074570083385 | validation: 0.005470476644533701]
	TIME [epoch: 8.21 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004302612898113485		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.004302612898113485 | validation: 0.004989288399767475]
	TIME [epoch: 8.18 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003840817759730014		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.003840817759730014 | validation: 0.005088562628932424]
	TIME [epoch: 8.18 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004406404957663593		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.004406404957663593 | validation: 0.0066377787339606635]
	TIME [epoch: 8.18 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003983444173490217		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.003983444173490217 | validation: 0.00509429538216816]
	TIME [epoch: 8.18 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004128427427469587		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.004128427427469587 | validation: 0.005247180387806237]
	TIME [epoch: 8.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039956938011432705		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0039956938011432705 | validation: 0.005781231526501975]
	TIME [epoch: 8.21 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003892903900761778		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.003892903900761778 | validation: 0.00583614530961625]
	TIME [epoch: 8.19 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005179371469217055		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.005179371469217055 | validation: 0.0067858115357588705]
	TIME [epoch: 8.19 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004288566288506237		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.004288566288506237 | validation: 0.00576836376973717]
	TIME [epoch: 8.19 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004035326955907986		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.004035326955907986 | validation: 0.004946133313796326]
	TIME [epoch: 8.18 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004201980461172434		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.004201980461172434 | validation: 0.005310141677142747]
	TIME [epoch: 8.21 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004015230705615525		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.004015230705615525 | validation: 0.0051990625996768715]
	TIME [epoch: 8.25 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036582399424116203		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.0036582399424116203 | validation: 0.0045862680295113605]
	TIME [epoch: 8.17 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004035757668593102		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.004035757668593102 | validation: 0.004537837995068762]
	TIME [epoch: 8.18 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003959378834059378		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.003959378834059378 | validation: 0.004840285020347583]
	TIME [epoch: 8.18 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004128945753842324		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.004128945753842324 | validation: 0.004848466018512208]
	TIME [epoch: 8.22 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004149567642375459		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.004149567642375459 | validation: 0.0053449146655426445]
	TIME [epoch: 8.19 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004220381145863714		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.004220381145863714 | validation: 0.004969421857461292]
	TIME [epoch: 8.18 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038595013833350976		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0038595013833350976 | validation: 0.004781710606144236]
	TIME [epoch: 8.17 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003796695382480818		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.003796695382480818 | validation: 0.004287056610341582]
	TIME [epoch: 8.19 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004116729567619121		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.004116729567619121 | validation: 0.012043319170215122]
	TIME [epoch: 8.23 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006151957815684902		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.006151957815684902 | validation: 0.00594409116711818]
	TIME [epoch: 8.18 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043129675069364555		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.0043129675069364555 | validation: 0.005170319313643652]
	TIME [epoch: 8.18 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003951465774383227		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.003951465774383227 | validation: 0.00518950002499056]
	TIME [epoch: 8.17 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034842403653643546		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0034842403653643546 | validation: 0.006103833103462785]
	TIME [epoch: 8.18 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003958768065789691		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.003958768065789691 | validation: 0.005296874696092368]
	TIME [epoch: 8.18 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004072321170077997		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.004072321170077997 | validation: 0.004735770389466637]
	TIME [epoch: 8.22 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003938543552276385		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.003938543552276385 | validation: 0.005104710630227667]
	TIME [epoch: 8.19 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004332173992220065		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.004332173992220065 | validation: 0.006685503212763124]
	TIME [epoch: 8.19 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038614359189736167		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0038614359189736167 | validation: 0.0051512814891499035]
	TIME [epoch: 8.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038771384083728447		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0038771384083728447 | validation: 0.004817820337105798]
	TIME [epoch: 8.18 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003918334876632203		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.003918334876632203 | validation: 0.005168159715683592]
	TIME [epoch: 8.22 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042596957631333785		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0042596957631333785 | validation: 0.004668220471905312]
	TIME [epoch: 8.18 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037967646740347536		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0037967646740347536 | validation: 0.0044882019982559855]
	TIME [epoch: 8.18 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004227760134541615		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.004227760134541615 | validation: 0.004468736001164774]
	TIME [epoch: 8.18 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004480293179294547		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.004480293179294547 | validation: 0.005119386463128435]
	TIME [epoch: 8.18 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036330325112117747		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.0036330325112117747 | validation: 0.004631811820668271]
	TIME [epoch: 8.23 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004077066302567749		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.004077066302567749 | validation: 0.005478857997392355]
	TIME [epoch: 8.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039354787281359925		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0039354787281359925 | validation: 0.0047671285859756714]
	TIME [epoch: 8.16 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038183366906055136		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0038183366906055136 | validation: 0.006265250800415144]
	TIME [epoch: 8.19 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041685795099329894		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0041685795099329894 | validation: 0.005333853699125911]
	TIME [epoch: 8.19 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003910534973149341		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.003910534973149341 | validation: 0.005440284499755288]
	TIME [epoch: 8.21 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00383809008511367		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.00383809008511367 | validation: 0.005084751508874757]
	TIME [epoch: 8.19 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004026429163331025		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.004026429163331025 | validation: 0.005266433779849238]
	TIME [epoch: 8.18 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037064456348832216		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0037064456348832216 | validation: 0.0048559260260832805]
	TIME [epoch: 8.19 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038196203722620893		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.0038196203722620893 | validation: 0.005041083666852169]
	TIME [epoch: 8.17 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004090556880610092		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.004090556880610092 | validation: 0.0049622263774763975]
	TIME [epoch: 8.21 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003669247610300329		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.003669247610300329 | validation: 0.005335249650797018]
	TIME [epoch: 8.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003742722383544558		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.003742722383544558 | validation: 0.004755474026738559]
	TIME [epoch: 8.18 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035704559408286105		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0035704559408286105 | validation: 0.0049323490702118476]
	TIME [epoch: 8.18 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038184115547277315		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.0038184115547277315 | validation: 0.00510768899005766]
	TIME [epoch: 8.18 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036405033679718438		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0036405033679718438 | validation: 0.006272051026149548]
	TIME [epoch: 8.19 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004345999340283513		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.004345999340283513 | validation: 0.004250480614953972]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_993.pth
	Model improved!!!
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003922600847781078		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.003922600847781078 | validation: 0.004772012599206748]
	TIME [epoch: 8.19 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004077534414261405		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.004077534414261405 | validation: 0.004707194289677203]
	TIME [epoch: 8.19 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004192001435930303		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.004192001435930303 | validation: 0.005133368572620336]
	TIME [epoch: 8.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039719846568883835		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0039719846568883835 | validation: 0.004887753849959028]
	TIME [epoch: 8.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003634831651149636		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.003634831651149636 | validation: 0.004894960361385371]
	TIME [epoch: 8.23 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003927758252676659		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.003927758252676659 | validation: 0.005983829399158558]
	TIME [epoch: 8.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004284446390524604		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.004284446390524604 | validation: 0.0044221199900777745]
	TIME [epoch: 8.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003909213702320192		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.003909213702320192 | validation: 0.004418503941040925]
	TIME [epoch: 8.2 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003908008328949008		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.003908008328949008 | validation: 0.005043536015138397]
	TIME [epoch: 8.19 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039595663215920805		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0039595663215920805 | validation: 0.0046084503156179155]
	TIME [epoch: 8.24 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003587051498057595		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.003587051498057595 | validation: 0.004877238710261229]
	TIME [epoch: 8.19 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003963187879687782		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.003963187879687782 | validation: 0.004550095574263011]
	TIME [epoch: 8.2 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038562521594379217		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0038562521594379217 | validation: 0.0055799853666809035]
	TIME [epoch: 8.19 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004086786678450687		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.004086786678450687 | validation: 0.0045871369769382424]
	TIME [epoch: 8.21 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004003660662066313		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.004003660662066313 | validation: 0.004833508033309567]
	TIME [epoch: 8.22 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037335386217620813		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.0037335386217620813 | validation: 0.004671869298808833]
	TIME [epoch: 8.2 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004486176250545913		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.004486176250545913 | validation: 0.004668065208491473]
	TIME [epoch: 8.19 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00375273138100443		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.00375273138100443 | validation: 0.004444888806550489]
	TIME [epoch: 8.19 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003930992484594666		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.003930992484594666 | validation: 0.005456268665598193]
	TIME [epoch: 8.19 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003521859425058148		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.003521859425058148 | validation: 0.004481435076293542]
	TIME [epoch: 8.22 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003662520951770475		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.003662520951770475 | validation: 0.004455282983587007]
	TIME [epoch: 8.21 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037704382004128054		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0037704382004128054 | validation: 0.004270171473625313]
	TIME [epoch: 8.19 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004078603788609396		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.004078603788609396 | validation: 0.005119180323782668]
	TIME [epoch: 8.19 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041888841521978614		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.0041888841521978614 | validation: 0.005022508669855321]
	TIME [epoch: 8.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037657918360964734		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.0037657918360964734 | validation: 0.005239895179374249]
	TIME [epoch: 8.21 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003819723547659741		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.003819723547659741 | validation: 0.004224004511758913]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1019.pth
	Model improved!!!
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036856763711194535		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0036856763711194535 | validation: 0.0048580374982054916]
	TIME [epoch: 8.19 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003599309243227593		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.003599309243227593 | validation: 0.00477635286439341]
	TIME [epoch: 8.18 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038121931430341507		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0038121931430341507 | validation: 0.0045043996976768565]
	TIME [epoch: 8.19 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035884857563481583		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.0035884857563481583 | validation: 0.004714359013998449]
	TIME [epoch: 8.2 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0040075009471147865		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0040075009471147865 | validation: 0.004963945881948978]
	TIME [epoch: 8.22 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036967775414151896		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0036967775414151896 | validation: 0.004711564196391164]
	TIME [epoch: 8.19 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003562356242180747		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.003562356242180747 | validation: 0.0050501922121040385]
	TIME [epoch: 8.19 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003537238319217537		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.003537238319217537 | validation: 0.006305621356821207]
	TIME [epoch: 8.19 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038488113304837738		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.0038488113304837738 | validation: 0.005559922680206168]
	TIME [epoch: 8.19 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003894928677729147		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.003894928677729147 | validation: 0.005379323751412178]
	TIME [epoch: 8.23 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004047533570733569		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.004047533570733569 | validation: 0.004892941648090358]
	TIME [epoch: 8.19 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003562965682414722		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.003562965682414722 | validation: 0.005096545705085975]
	TIME [epoch: 8.18 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035436214432561846		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.0035436214432561846 | validation: 0.004154239925537231]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1032.pth
	Model improved!!!
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038325124527602674		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.0038325124527602674 | validation: 0.005506002735915363]
	TIME [epoch: 8.18 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004032259796742708		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.004032259796742708 | validation: 0.0046584842683409095]
	TIME [epoch: 8.23 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003641386073511444		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.003641386073511444 | validation: 0.0043341544429411575]
	TIME [epoch: 8.19 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038071355115952906		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.0038071355115952906 | validation: 0.0049099952215367875]
	TIME [epoch: 8.19 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004023948137733524		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.004023948137733524 | validation: 0.005235188282360835]
	TIME [epoch: 8.17 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003935503115192589		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.003935503115192589 | validation: 0.005657078885656242]
	TIME [epoch: 8.18 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003743282121560758		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.003743282121560758 | validation: 0.004817748886494483]
	TIME [epoch: 8.22 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003634131081388276		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.003634131081388276 | validation: 0.004523287061726814]
	TIME [epoch: 8.19 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036742340168118585		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0036742340168118585 | validation: 0.004490788713893421]
	TIME [epoch: 8.19 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039102712560806		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.0039102712560806 | validation: 0.005188486526451829]
	TIME [epoch: 8.19 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034466709960720176		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0034466709960720176 | validation: 0.004270898269063228]
	TIME [epoch: 8.19 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003573782987958434		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.003573782987958434 | validation: 0.005216798057053487]
	TIME [epoch: 8.2 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003713734241325118		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.003713734241325118 | validation: 0.00391523850220485]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037594789615782204		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0037594789615782204 | validation: 0.00481535929614579]
	TIME [epoch: 8.17 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003627982685535277		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.003627982685535277 | validation: 0.005309343964796338]
	TIME [epoch: 8.17 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033413365200887575		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0033413365200887575 | validation: 0.005204203634618997]
	TIME [epoch: 8.19 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035512222681541353		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0035512222681541353 | validation: 0.005187773343769518]
	TIME [epoch: 8.21 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003541583879031451		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.003541583879031451 | validation: 0.0055471983240596235]
	TIME [epoch: 8.22 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003637384811794903		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.003637384811794903 | validation: 0.004306601411775537]
	TIME [epoch: 8.18 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003626858013122687		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.003626858013122687 | validation: 0.004577545151193867]
	TIME [epoch: 8.19 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003734465971072314		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.003734465971072314 | validation: 0.004425495385529886]
	TIME [epoch: 8.19 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003871288331235993		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.003871288331235993 | validation: 0.005078937285198641]
	TIME [epoch: 8.19 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003427428092035731		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.003427428092035731 | validation: 0.004946438725924131]
	TIME [epoch: 8.21 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034742795351030377		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.0034742795351030377 | validation: 0.004973156915721451]
	TIME [epoch: 8.19 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035630427320038818		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0035630427320038818 | validation: 0.005013955608040523]
	TIME [epoch: 8.17 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037249831517422623		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0037249831517422623 | validation: 0.004816424701771155]
	TIME [epoch: 8.18 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038187078231958875		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0038187078231958875 | validation: 0.005025649356232861]
	TIME [epoch: 8.18 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003467437594171365		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.003467437594171365 | validation: 0.0044571276572546795]
	TIME [epoch: 8.22 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035691135276423877		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0035691135276423877 | validation: 0.004419707221542729]
	TIME [epoch: 8.18 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036119707878172094		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0036119707878172094 | validation: 0.004746731081251595]
	TIME [epoch: 8.17 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003531836706683534		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.003531836706683534 | validation: 0.005480535239896871]
	TIME [epoch: 8.19 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003557377813882696		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.003557377813882696 | validation: 0.004656682978741692]
	TIME [epoch: 8.18 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033993101125087727		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0033993101125087727 | validation: 0.004671489447577089]
	TIME [epoch: 8.22 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033978767548736195		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0033978767548736195 | validation: 0.004441800753879991]
	TIME [epoch: 8.18 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038754786539922093		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0038754786539922093 | validation: 0.004229386907927162]
	TIME [epoch: 8.18 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034413007517194354		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.0034413007517194354 | validation: 0.004799267422925007]
	TIME [epoch: 8.18 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003533379639855092		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.003533379639855092 | validation: 0.004542560582600151]
	TIME [epoch: 8.18 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034732973277808903		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0034732973277808903 | validation: 0.0047084961429938645]
	TIME [epoch: 8.2 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003637578944711578		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.003637578944711578 | validation: 0.00493202957015407]
	TIME [epoch: 8.21 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003707781562248221		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.003707781562248221 | validation: 0.004475772241857175]
	TIME [epoch: 8.18 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003779506341911901		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.003779506341911901 | validation: 0.00423166674120886]
	TIME [epoch: 8.17 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003642453013371995		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.003642453013371995 | validation: 0.00429632838518294]
	TIME [epoch: 8.18 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036277392328351874		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.0036277392328351874 | validation: 0.004201808662258371]
	TIME [epoch: 8.18 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036729793735624933		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0036729793735624933 | validation: 0.004954565873241125]
	TIME [epoch: 8.22 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004085647634813242		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.004085647634813242 | validation: 0.005265121811280592]
	TIME [epoch: 8.17 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003810594536665926		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.003810594536665926 | validation: 0.005433838892286282]
	TIME [epoch: 8.18 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003607850796606823		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.003607850796606823 | validation: 0.004667294937144082]
	TIME [epoch: 8.18 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003674876296084299		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.003674876296084299 | validation: 0.004611133240340191]
	TIME [epoch: 8.17 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003662483794414967		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.003662483794414967 | validation: 0.0049943319038165245]
	TIME [epoch: 8.22 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033941343457822874		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0033941343457822874 | validation: 0.0045093375279676075]
	TIME [epoch: 8.18 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003653818780610083		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.003653818780610083 | validation: 0.00506659397769949]
	TIME [epoch: 8.18 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003471277244822067		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.003471277244822067 | validation: 0.00494532347066867]
	TIME [epoch: 8.19 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003719209519913371		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.003719209519913371 | validation: 0.004802502822394352]
	TIME [epoch: 8.18 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037370064895271794		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.0037370064895271794 | validation: 0.005500318140544146]
	TIME [epoch: 8.23 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003354085536112018		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.003354085536112018 | validation: 0.0046429291034135334]
	TIME [epoch: 8.19 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035322841491443407		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.0035322841491443407 | validation: 0.004394867430418978]
	TIME [epoch: 8.17 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036649574223474547		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0036649574223474547 | validation: 0.004450959614508334]
	TIME [epoch: 8.18 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038270858846648293		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0038270858846648293 | validation: 0.004905970135804787]
	TIME [epoch: 8.18 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034165027086083756		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0034165027086083756 | validation: 0.004654822910698582]
	TIME [epoch: 8.21 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003773682663928888		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.003773682663928888 | validation: 0.004965033150480805]
	TIME [epoch: 8.21 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034199376614341397		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0034199376614341397 | validation: 0.004473477837457837]
	TIME [epoch: 8.18 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035337511349681763		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0035337511349681763 | validation: 0.004089393458106614]
	TIME [epoch: 8.19 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037097892957035188		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0037097892957035188 | validation: 0.004407777492243435]
	TIME [epoch: 8.17 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036210771002564163		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.0036210771002564163 | validation: 0.004548322234968837]
	TIME [epoch: 8.19 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003294083621543364		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.003294083621543364 | validation: 0.004375430150008409]
	TIME [epoch: 8.21 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035205307759783675		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0035205307759783675 | validation: 0.004489640698092958]
	TIME [epoch: 8.19 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003575992610685219		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.003575992610685219 | validation: 0.004837592425938877]
	TIME [epoch: 8.18 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037370853977543063		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.0037370853977543063 | validation: 0.004985057090858183]
	TIME [epoch: 8.17 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034647142297871674		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0034647142297871674 | validation: 0.004215622960473579]
	TIME [epoch: 8.19 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036789091949575078		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.0036789091949575078 | validation: 0.004427044094316917]
	TIME [epoch: 8.22 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033928036448954515		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0033928036448954515 | validation: 0.005105705529896039]
	TIME [epoch: 8.18 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035314518873720423		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0035314518873720423 | validation: 0.0043524136581137]
	TIME [epoch: 8.18 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003472630474621317		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.003472630474621317 | validation: 0.005446406432424113]
	TIME [epoch: 8.18 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034053410515381705		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0034053410515381705 | validation: 0.004183527845625567]
	TIME [epoch: 8.18 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033440626112045653		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.0033440626112045653 | validation: 0.0051791581461091175]
	TIME [epoch: 8.23 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00352710814363434		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.00352710814363434 | validation: 0.004760348312256332]
	TIME [epoch: 8.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003418827245718346		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.003418827245718346 | validation: 0.005017559697111521]
	TIME [epoch: 8.18 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003566266051251721		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.003566266051251721 | validation: 0.004126815839109996]
	TIME [epoch: 8.19 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035696224937952622		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.0035696224937952622 | validation: 0.00425692409024474]
	TIME [epoch: 8.18 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003584222930088364		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.003584222930088364 | validation: 0.004155717820525423]
	TIME [epoch: 8.22 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032705408362623833		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0032705408362623833 | validation: 0.004647325625556278]
	TIME [epoch: 8.19 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033308036513545313		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0033308036513545313 | validation: 0.004351628134205899]
	TIME [epoch: 8.19 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034314276980190166		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0034314276980190166 | validation: 0.005264057235645678]
	TIME [epoch: 8.19 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033003522432982772		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0033003522432982772 | validation: 0.004191511521897546]
	TIME [epoch: 8.18 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036155190146111116		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0036155190146111116 | validation: 0.00458868254199736]
	TIME [epoch: 8.21 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034901414824122937		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0034901414824122937 | validation: 0.004181587878401507]
	TIME [epoch: 8.2 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003344413005518569		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.003344413005518569 | validation: 0.004904433665377721]
	TIME [epoch: 8.18 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035966857738253056		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0035966857738253056 | validation: 0.003716203113894339]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1120.pth
	Model improved!!!
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034074443807192703		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0034074443807192703 | validation: 0.004289954596164838]
	TIME [epoch: 8.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034156264683143905		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0034156264683143905 | validation: 0.004614432000542186]
	TIME [epoch: 8.2 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003377299473162987		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.003377299473162987 | validation: 0.005258848000591791]
	TIME [epoch: 8.22 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003429384671537651		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.003429384671537651 | validation: 0.004384370284140003]
	TIME [epoch: 8.18 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003520833546294191		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.003520833546294191 | validation: 0.004283398457728449]
	TIME [epoch: 8.19 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003645692117545932		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.003645692117545932 | validation: 0.0042289733409519225]
	TIME [epoch: 8.19 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037033111266296078		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.0037033111266296078 | validation: 0.005942355957856513]
	TIME [epoch: 8.18 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003328636530255641		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.003328636530255641 | validation: 0.00484475743772984]
	TIME [epoch: 8.23 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035856684283657797		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0035856684283657797 | validation: 0.004617204712365725]
	TIME [epoch: 8.19 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035033411776069032		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0035033411776069032 | validation: 0.004658126597840368]
	TIME [epoch: 8.19 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032768796840096917		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0032768796840096917 | validation: 0.004522851684687964]
	TIME [epoch: 8.17 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003357873833596869		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.003357873833596869 | validation: 0.005553820577419658]
	TIME [epoch: 8.19 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034850239905792457		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.0034850239905792457 | validation: 0.005076461063964222]
	TIME [epoch: 8.2 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003688754994861704		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.003688754994861704 | validation: 0.004674760248429777]
	TIME [epoch: 8.19 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003420385626777452		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.003420385626777452 | validation: 0.004959791273986156]
	TIME [epoch: 8.19 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034787579459615277		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0034787579459615277 | validation: 0.0054556643339594086]
	TIME [epoch: 8.18 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00323430555748806		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.00323430555748806 | validation: 0.004261513466920334]
	TIME [epoch: 8.19 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032800591758093203		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0032800591758093203 | validation: 0.004486495057149601]
	TIME [epoch: 8.21 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003556611354298878		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.003556611354298878 | validation: 0.005240864354809313]
	TIME [epoch: 8.19 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003816225645866582		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.003816225645866582 | validation: 0.004789652041875479]
	TIME [epoch: 8.19 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032558098353781583		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.0032558098353781583 | validation: 0.004286278106600103]
	TIME [epoch: 8.17 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003409920988611855		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.003409920988611855 | validation: 0.004818968668464145]
	TIME [epoch: 8.18 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034892172747896036		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.0034892172747896036 | validation: 0.0048141113270119005]
	TIME [epoch: 8.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036398122028253525		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0036398122028253525 | validation: 0.004900262697850132]
	TIME [epoch: 8.21 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003335920904318314		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.003335920904318314 | validation: 0.004118845604379416]
	TIME [epoch: 8.17 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034948781656550915		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0034948781656550915 | validation: 0.004293770933739525]
	TIME [epoch: 8.18 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032531574680249907		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0032531574680249907 | validation: 0.003959057286276522]
	TIME [epoch: 8.18 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003547889243544322		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.003547889243544322 | validation: 0.00462741984121905]
	TIME [epoch: 8.19 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036762259539553583		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0036762259539553583 | validation: 0.004335110839964795]
	TIME [epoch: 8.21 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036010889590809454		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.0036010889590809454 | validation: 0.0052455898421181505]
	TIME [epoch: 8.18 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003283399272563487		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.003283399272563487 | validation: 0.0036598613226080756]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1151.pth
	Model improved!!!
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035028033091625676		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.0035028033091625676 | validation: 0.0049975638038854886]
	TIME [epoch: 8.19 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032887158574350208		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.0032887158574350208 | validation: 0.005830400959617779]
	TIME [epoch: 8.2 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003489727739041883		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.003489727739041883 | validation: 0.004516528763043053]
	TIME [epoch: 8.24 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033136925216270662		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.0033136925216270662 | validation: 0.004909261970944938]
	TIME [epoch: 8.21 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00332058423545955		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.00332058423545955 | validation: 0.004876585762901728]
	TIME [epoch: 8.21 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036752060297274764		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0036752060297274764 | validation: 0.00487747187804261]
	TIME [epoch: 8.2 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034956041547314918		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0034956041547314918 | validation: 0.004917482718201748]
	TIME [epoch: 8.21 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003296311314317648		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.003296311314317648 | validation: 0.0046425134358411505]
	TIME [epoch: 8.25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00323956324437255		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.00323956324437255 | validation: 0.004208028706880185]
	TIME [epoch: 8.2 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035701780963967133		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0035701780963967133 | validation: 0.00497487023033143]
	TIME [epoch: 8.21 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003491285487253926		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.003491285487253926 | validation: 0.005370667160111781]
	TIME [epoch: 8.2 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034520807416070836		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0034520807416070836 | validation: 0.005301427208539645]
	TIME [epoch: 8.2 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003460731735228764		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.003460731735228764 | validation: 0.00411118561559206]
	TIME [epoch: 8.25 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034680045788705567		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0034680045788705567 | validation: 0.004445581576485344]
	TIME [epoch: 8.21 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032878705939181495		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.0032878705939181495 | validation: 0.00420116493198451]
	TIME [epoch: 8.21 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031709420108618613		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0031709420108618613 | validation: 0.004776515106135266]
	TIME [epoch: 8.19 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003628785274479747		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.003628785274479747 | validation: 0.004392096858547483]
	TIME [epoch: 8.19 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003419263773221041		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.003419263773221041 | validation: 0.005009362143857013]
	TIME [epoch: 8.22 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035658892753409276		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0035658892753409276 | validation: 0.004167705512268548]
	TIME [epoch: 8.21 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029317468160201545		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0029317468160201545 | validation: 0.004096783252294577]
	TIME [epoch: 8.19 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033857453355318084		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.0033857453355318084 | validation: 0.004932044864353775]
	TIME [epoch: 8.19 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035255520085904057		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0035255520085904057 | validation: 0.004451804286559699]
	TIME [epoch: 8.19 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030761555549479566		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.0030761555549479566 | validation: 0.004503516850971085]
	TIME [epoch: 8.2 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00320327333025914		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.00320327333025914 | validation: 0.0043272257012257195]
	TIME [epoch: 8.23 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003411557549896087		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.003411557549896087 | validation: 0.004344560302807327]
	TIME [epoch: 8.19 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033354360579293868		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0033354360579293868 | validation: 0.004483268664349063]
	TIME [epoch: 8.19 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034008639918738067		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.0034008639918738067 | validation: 0.004733676455305699]
	TIME [epoch: 8.19 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032473632773673726		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.0032473632773673726 | validation: 0.0048905028661663545]
	TIME [epoch: 8.2 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035064982671380164		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0035064982671380164 | validation: 0.0047308896606533]
	TIME [epoch: 8.24 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003514107224524543		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.003514107224524543 | validation: 0.00422487880373771]
	TIME [epoch: 8.2 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030918934457218115		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0030918934457218115 | validation: 0.004326486065251876]
	TIME [epoch: 8.19 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032753980259823097		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.0032753980259823097 | validation: 0.005233035122867918]
	TIME [epoch: 8.2 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003330360870143751		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.003330360870143751 | validation: 0.004543108584614586]
	TIME [epoch: 8.19 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003257796970427224		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.003257796970427224 | validation: 0.003976048618427203]
	TIME [epoch: 8.24 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032705445301072942		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.0032705445301072942 | validation: 0.004161854902589837]
	TIME [epoch: 8.21 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031127849690985405		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.0031127849690985405 | validation: 0.004201590846510196]
	TIME [epoch: 8.19 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035115105647849556		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.0035115105647849556 | validation: 0.004492195001925021]
	TIME [epoch: 8.19 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032256778088404813		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.0032256778088404813 | validation: 0.004613711080394495]
	TIME [epoch: 8.19 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032218517550518908		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.0032218517550518908 | validation: 0.004908870582435982]
	TIME [epoch: 8.23 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003425068788517272		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.003425068788517272 | validation: 0.004356501962783505]
	TIME [epoch: 8.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032265999377009418		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.0032265999377009418 | validation: 0.0041919008799077406]
	TIME [epoch: 8.19 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003317476260852547		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.003317476260852547 | validation: 0.004881957508492974]
	TIME [epoch: 8.18 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003155323809126802		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.003155323809126802 | validation: 0.004660194057689531]
	TIME [epoch: 8.19 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033268019923080824		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0033268019923080824 | validation: 0.0039739835427505445]
	TIME [epoch: 8.21 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003420862351958401		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.003420862351958401 | validation: 0.004243145312521622]
	TIME [epoch: 8.22 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031213184128871634		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.0031213184128871634 | validation: 0.005240721623983908]
	TIME [epoch: 8.19 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032639466277522575		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.0032639466277522575 | validation: 0.004820187057244912]
	TIME [epoch: 8.19 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00332080062031922		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.00332080062031922 | validation: 0.0044240164602114005]
	TIME [epoch: 8.19 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034201362066319306		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.0034201362066319306 | validation: 0.0044094394825493]
	TIME [epoch: 8.19 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033012124581134556		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.0033012124581134556 | validation: 0.00478752399696931]
	TIME [epoch: 8.22 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003271516403731816		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.003271516403731816 | validation: 0.004907172072364841]
	TIME [epoch: 8.18 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003328951123259303		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.003328951123259303 | validation: 0.004035904634454672]
	TIME [epoch: 8.19 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003342278339184995		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.003342278339184995 | validation: 0.0040914653996113725]
	TIME [epoch: 8.19 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003239674541365208		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.003239674541365208 | validation: 0.0047176104074709985]
	TIME [epoch: 8.18 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032434471265403693		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0032434471265403693 | validation: 0.004126621921018696]
	TIME [epoch: 8.23 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003047854283877361		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.003047854283877361 | validation: 0.0052530493275555305]
	TIME [epoch: 8.19 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003383733911131212		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.003383733911131212 | validation: 0.005142645664174087]
	TIME [epoch: 8.2 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032107207017788683		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.0032107207017788683 | validation: 0.004121912817698325]
	TIME [epoch: 8.19 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033871783482206552		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.0033871783482206552 | validation: 0.004775892559392871]
	TIME [epoch: 8.2 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033444395647265384		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0033444395647265384 | validation: 0.004236185579322042]
	TIME [epoch: 8.22 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003046816130348965		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.003046816130348965 | validation: 0.004746930538447425]
	TIME [epoch: 8.2 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033423777532465555		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0033423777532465555 | validation: 0.004191104277104169]
	TIME [epoch: 8.19 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033238853184708135		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0033238853184708135 | validation: 0.004400860728509046]
	TIME [epoch: 8.18 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035621929875075124		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.0035621929875075124 | validation: 0.0044844820034979525]
	TIME [epoch: 8.19 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031926797493352903		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.0031926797493352903 | validation: 0.004200699925061613]
	TIME [epoch: 8.23 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032536769006182324		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.0032536769006182324 | validation: 0.004847537627395575]
	TIME [epoch: 8.2 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003362954940481185		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.003362954940481185 | validation: 0.004712506730478306]
	TIME [epoch: 8.19 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029197200219748497		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0029197200219748497 | validation: 0.004272222118546792]
	TIME [epoch: 8.19 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00329534702307173		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.00329534702307173 | validation: 0.005459094301288046]
	TIME [epoch: 8.19 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033568879851447932		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0033568879851447932 | validation: 0.004927294860801116]
	TIME [epoch: 8.2 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003250370540702779		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.003250370540702779 | validation: 0.0049936386899712484]
	TIME [epoch: 8.22 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030235839681096136		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0030235839681096136 | validation: 0.004327549107342089]
	TIME [epoch: 8.2 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003187541784146861		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.003187541784146861 | validation: 0.004575204620335319]
	TIME [epoch: 8.2 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00306800510506996		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.00306800510506996 | validation: 0.004514580729141615]
	TIME [epoch: 8.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031629148280322		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.0031629148280322 | validation: 0.0043577149792718]
	TIME [epoch: 8.21 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036091294667305934		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.0036091294667305934 | validation: 0.004822239808863952]
	TIME [epoch: 8.23 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003185916052104993		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.003185916052104993 | validation: 0.004592087834347999]
	TIME [epoch: 8.2 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033085040657473883		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0033085040657473883 | validation: 0.004720535237575235]
	TIME [epoch: 8.18 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031105354320460675		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.0031105354320460675 | validation: 0.004259222353989893]
	TIME [epoch: 8.19 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030437760307554843		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0030437760307554843 | validation: 0.004734255300589718]
	TIME [epoch: 8.18 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035141652617905286		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.0035141652617905286 | validation: 0.004009791571301094]
	TIME [epoch: 8.24 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031121410636320863		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.0031121410636320863 | validation: 0.0043831160077341825]
	TIME [epoch: 8.18 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003210071108455625		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.003210071108455625 | validation: 0.005044261520790122]
	TIME [epoch: 8.19 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031188866989650733		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0031188866989650733 | validation: 0.004599167047065943]
	TIME [epoch: 8.19 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003095509596828792		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.003095509596828792 | validation: 0.003696794664628365]
	TIME [epoch: 8.19 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003238574107951225		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.003238574107951225 | validation: 0.004168369560798548]
	TIME [epoch: 8.23 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031654604112487036		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.0031654604112487036 | validation: 0.00463097221523393]
	TIME [epoch: 8.2 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003026255474266958		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.003026255474266958 | validation: 0.004360612662314815]
	TIME [epoch: 8.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003130704399069515		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.003130704399069515 | validation: 0.004494070459652494]
	TIME [epoch: 8.19 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003264439723178647		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.003264439723178647 | validation: 0.004503237006353774]
	TIME [epoch: 8.19 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003562702409180915		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.003562702409180915 | validation: 0.004182757302829794]
	TIME [epoch: 8.23 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003168425530362575		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.003168425530362575 | validation: 0.004395507633017657]
	TIME [epoch: 8.2 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003373172998947795		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.003373172998947795 | validation: 0.004063426332837832]
	TIME [epoch: 8.18 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003066380365720754		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.003066380365720754 | validation: 0.004240466741178492]
	TIME [epoch: 8.18 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032163789547992503		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.0032163789547992503 | validation: 0.00498631850706339]
	TIME [epoch: 8.19 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003461984524706265		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.003461984524706265 | validation: 0.003393066561183112]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1247.pth
	Model improved!!!
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003156373831983975		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.003156373831983975 | validation: 0.004733621226713075]
	TIME [epoch: 8.21 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003087669068791491		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.003087669068791491 | validation: 0.004366086754890687]
	TIME [epoch: 8.18 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031941100354427572		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.0031941100354427572 | validation: 0.004636187177514667]
	TIME [epoch: 8.19 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003281397559844709		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.003281397559844709 | validation: 0.004570487569369152]
	TIME [epoch: 8.19 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028677319956127907		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0028677319956127907 | validation: 0.004281115121200569]
	TIME [epoch: 8.2 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003359079899081855		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.003359079899081855 | validation: 0.005176989360243532]
	TIME [epoch: 8.23 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034690349894024686		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0034690349894024686 | validation: 0.004933533167707133]
	TIME [epoch: 8.2 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033507667259203605		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0033507667259203605 | validation: 0.004757065218384746]
	TIME [epoch: 8.2 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003281280172147674		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.003281280172147674 | validation: 0.0040986750126119475]
	TIME [epoch: 8.19 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030911988611304654		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.0030911988611304654 | validation: 0.004394725504164722]
	TIME [epoch: 8.2 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031781561494322406		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.0031781561494322406 | validation: 0.004351517295410562]
	TIME [epoch: 8.24 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033848121645470566		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.0033848121645470566 | validation: 0.004878637083189393]
	TIME [epoch: 8.2 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003031042651186696		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.003031042651186696 | validation: 0.004550536550803444]
	TIME [epoch: 8.19 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003359269090718944		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.003359269090718944 | validation: 0.004070429057206571]
	TIME [epoch: 8.2 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003257095975387028		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.003257095975387028 | validation: 0.003985373775928198]
	TIME [epoch: 8.19 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032639769869595436		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0032639769869595436 | validation: 0.004095007220554785]
	TIME [epoch: 8.23 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003181589025441518		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.003181589025441518 | validation: 0.004525115608921382]
	TIME [epoch: 8.2 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003104316032622792		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.003104316032622792 | validation: 0.004091148159573274]
	TIME [epoch: 8.19 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030764883548772223		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0030764883548772223 | validation: 0.004531233742602143]
	TIME [epoch: 8.2 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032533813292477403		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0032533813292477403 | validation: 0.004667695616410637]
	TIME [epoch: 8.2 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003243758089796378		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.003243758089796378 | validation: 0.003987372973252089]
	TIME [epoch: 8.23 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031839514448671956		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.0031839514448671956 | validation: 0.0042309655379833425]
	TIME [epoch: 8.2 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002978973801096012		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.002978973801096012 | validation: 0.003795260172695094]
	TIME [epoch: 8.18 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002958042110083529		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.002958042110083529 | validation: 0.0040292679036879695]
	TIME [epoch: 8.19 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030858078818163425		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.0030858078818163425 | validation: 0.0042777146298171725]
	TIME [epoch: 8.19 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030800475427983495		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.0030800475427983495 | validation: 0.004426148574035895]
	TIME [epoch: 8.2 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003224776966806769		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.003224776966806769 | validation: 0.004421403621238177]
	TIME [epoch: 8.21 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003030249438323661		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.003030249438323661 | validation: 0.004034936714570286]
	TIME [epoch: 8.19 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031116706250216104		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0031116706250216104 | validation: 0.00424236658187762]
	TIME [epoch: 8.18 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003423567796636549		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.003423567796636549 | validation: 0.004311387998341824]
	TIME [epoch: 8.19 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030805865170553306		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.0030805865170553306 | validation: 0.0055961008741394515]
	TIME [epoch: 8.19 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031708021156432228		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0031708021156432228 | validation: 0.003596231824528256]
	TIME [epoch: 8.23 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032452380511203836		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.0032452380511203836 | validation: 0.0039026729788393198]
	TIME [epoch: 8.19 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031088208321579784		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.0031088208321579784 | validation: 0.004120222594803336]
	TIME [epoch: 8.2 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030027406795664234		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.0030027406795664234 | validation: 0.004131373767660008]
	TIME [epoch: 8.18 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029724186509082484		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.0029724186509082484 | validation: 0.004560673597392647]
	TIME [epoch: 8.19 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032352226965953112		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.0032352226965953112 | validation: 0.004095198778166234]
	TIME [epoch: 8.23 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030818020318131006		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.0030818020318131006 | validation: 0.0037703307995881996]
	TIME [epoch: 8.19 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003445827155948507		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.003445827155948507 | validation: 0.0039488150751630455]
	TIME [epoch: 8.19 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032787739472911184		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.0032787739472911184 | validation: 0.003939778501081075]
	TIME [epoch: 8.18 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030377508030837363		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.0030377508030837363 | validation: 0.003998192278101545]
	TIME [epoch: 8.19 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003349553268251125		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.003349553268251125 | validation: 0.005005722026641109]
	TIME [epoch: 8.22 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003070097928682623		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.003070097928682623 | validation: 0.004073639282487356]
	TIME [epoch: 8.19 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031249531311219447		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0031249531311219447 | validation: 0.0046273231879360305]
	TIME [epoch: 8.17 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003042974007505997		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.003042974007505997 | validation: 0.004576756842152885]
	TIME [epoch: 8.19 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031905412031756506		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.0031905412031756506 | validation: 0.004148885070240847]
	TIME [epoch: 8.17 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032362379415101297		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.0032362379415101297 | validation: 0.0050429039736381905]
	TIME [epoch: 8.21 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003277955026304537		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.003277955026304537 | validation: 0.004006297294396478]
	TIME [epoch: 8.22 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030598688017395605		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.0030598688017395605 | validation: 0.004205589136506215]
	TIME [epoch: 8.19 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032044416798235565		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.0032044416798235565 | validation: 0.00430621517693664]
	TIME [epoch: 8.19 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031913220880943017		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0031913220880943017 | validation: 0.004116587331382335]
	TIME [epoch: 8.18 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031583459021828028		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0031583459021828028 | validation: 0.004583558633043521]
	TIME [epoch: 8.2 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031377779285315164		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.0031377779285315164 | validation: 0.00453396752134642]
	TIME [epoch: 8.22 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002884555933800638		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.002884555933800638 | validation: 0.004474431086145952]
	TIME [epoch: 8.18 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031310566106574223		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.0031310566106574223 | validation: 0.004939815088419037]
	TIME [epoch: 8.17 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002842501118999858		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.002842501118999858 | validation: 0.004047134038797405]
	TIME [epoch: 8.18 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030327167845120677		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.0030327167845120677 | validation: 0.0046810111973378515]
	TIME [epoch: 8.19 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033178952777276		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0033178952777276 | validation: 0.004290644033688446]
	TIME [epoch: 8.22 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003147244855177444		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.003147244855177444 | validation: 0.004390077553506574]
	TIME [epoch: 8.18 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003129354199800861		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.003129354199800861 | validation: 0.0038098348373584267]
	TIME [epoch: 8.19 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00311532828485392		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.00311532828485392 | validation: 0.00447615981169551]
	TIME [epoch: 8.19 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030232284727658037		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.0030232284727658037 | validation: 0.0041316016365980845]
	TIME [epoch: 8.19 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003195995648686803		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.003195995648686803 | validation: 0.004316277897752015]
	TIME [epoch: 8.22 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002989265006364945		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.002989265006364945 | validation: 0.0047436224343400885]
	TIME [epoch: 8.2 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030624768870192733		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0030624768870192733 | validation: 0.004336420467576603]
	TIME [epoch: 8.19 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003070384318993897		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.003070384318993897 | validation: 0.0042136365134263585]
	TIME [epoch: 8.17 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003158491794807772		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.003158491794807772 | validation: 0.00454589669494499]
	TIME [epoch: 8.18 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003024453417298299		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.003024453417298299 | validation: 0.004683621530596462]
	TIME [epoch: 8.22 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033327549179218395		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.0033327549179218395 | validation: 0.003957393170472468]
	TIME [epoch: 8.2 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031394701744458416		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0031394701744458416 | validation: 0.004377587323572926]
	TIME [epoch: 8.19 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029709024568300574		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.0029709024568300574 | validation: 0.004003057686222216]
	TIME [epoch: 8.17 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003060412067670709		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.003060412067670709 | validation: 0.0042657454884641455]
	TIME [epoch: 8.18 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003136071289354519		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.003136071289354519 | validation: 0.004490269872201264]
	TIME [epoch: 8.19 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031738497157586653		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0031738497157586653 | validation: 0.004243724036726296]
	TIME [epoch: 8.21 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030197305693328244		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.0030197305693328244 | validation: 0.004757906890838376]
	TIME [epoch: 8.17 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003003297421936754		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.003003297421936754 | validation: 0.004338353502519604]
	TIME [epoch: 8.19 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030433582360800586		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0030433582360800586 | validation: 0.004281384940981729]
	TIME [epoch: 8.19 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031633491088389194		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.0031633491088389194 | validation: 0.004596865004128639]
	TIME [epoch: 8.19 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031186775964356286		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.0031186775964356286 | validation: 0.0039763128569468755]
	TIME [epoch: 8.22 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031500523481835813		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.0031500523481835813 | validation: 0.004145665776474637]
	TIME [epoch: 8.18 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032801038421653305		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0032801038421653305 | validation: 0.004381796867092642]
	TIME [epoch: 8.18 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029834573203928955		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.0029834573203928955 | validation: 0.004133527882884054]
	TIME [epoch: 8.18 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003019166447468133		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.003019166447468133 | validation: 0.004196866333831099]
	TIME [epoch: 8.2 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029511145436956414		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0029511145436956414 | validation: 0.0037666542960828374]
	TIME [epoch: 8.21 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030441761832135585		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.0030441761832135585 | validation: 0.004257490969534722]
	TIME [epoch: 8.19 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032423740982297318		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.0032423740982297318 | validation: 0.004477521197583698]
	TIME [epoch: 8.16 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031804661917548636		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.0031804661917548636 | validation: 0.004097439680236516]
	TIME [epoch: 8.17 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003096645461410962		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.003096645461410962 | validation: 0.004272607612459869]
	TIME [epoch: 8.19 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003201433938613885		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.003201433938613885 | validation: 0.004391796033308602]
	TIME [epoch: 8.2 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028758375605475723		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.0028758375605475723 | validation: 0.004592502750098614]
	TIME [epoch: 8.2 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003184310624446441		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.003184310624446441 | validation: 0.00445747123293873]
	TIME [epoch: 8.17 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003204272259456826		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.003204272259456826 | validation: 0.004610736267343404]
	TIME [epoch: 8.18 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003178655685814575		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.003178655685814575 | validation: 0.004615197286705172]
	TIME [epoch: 8.18 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003192581580823087		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.003192581580823087 | validation: 0.0042198340751997505]
	TIME [epoch: 8.22 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030138717539806093		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.0030138717539806093 | validation: 0.0038866487448744862]
	TIME [epoch: 8.18 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029208336102724518		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.0029208336102724518 | validation: 0.0043780735816030935]
	TIME [epoch: 8.18 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003338062726717955		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.003338062726717955 | validation: 0.003948918963465893]
	TIME [epoch: 8.18 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030196802326456634		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.0030196802326456634 | validation: 0.003941348383179537]
	TIME [epoch: 8.17 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003106471933846171		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.003106471933846171 | validation: 0.004625118556614037]
	TIME [epoch: 8.19 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002955807453135546		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.002955807453135546 | validation: 0.003702944784987758]
	TIME [epoch: 8.2 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002973957814804366		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.002973957814804366 | validation: 0.0040031307344345676]
	TIME [epoch: 8.18 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029623671896146153		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.0029623671896146153 | validation: 0.004186250600575374]
	TIME [epoch: 8.18 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027210434214049086		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0027210434214049086 | validation: 0.003978667987444446]
	TIME [epoch: 8.18 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003093659193526108		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.003093659193526108 | validation: 0.0038932094644041583]
	TIME [epoch: 8.18 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003086344812534188		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.003086344812534188 | validation: 0.004522895310463144]
	TIME [epoch: 8.24 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029365021124676317		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.0029365021124676317 | validation: 0.0039044097259590843]
	TIME [epoch: 8.2 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030203024265251597		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.0030203024265251597 | validation: 0.004595470063786562]
	TIME [epoch: 8.21 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003300664571339774		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.003300664571339774 | validation: 0.004644293821897889]
	TIME [epoch: 8.22 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002890382272181738		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.002890382272181738 | validation: 0.004565247448732912]
	TIME [epoch: 8.19 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030649183209110016		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.0030649183209110016 | validation: 0.003798233056734679]
	TIME [epoch: 8.23 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003218160104521254		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.003218160104521254 | validation: 0.0041503154184540265]
	TIME [epoch: 8.19 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030406528975347813		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.0030406528975347813 | validation: 0.003945158548280418]
	TIME [epoch: 8.19 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002996147290882882		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.002996147290882882 | validation: 0.004166506968238934]
	TIME [epoch: 8.2 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003080887521466186		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.003080887521466186 | validation: 0.004493388887757119]
	TIME [epoch: 8.19 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002879974847195546		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.002879974847195546 | validation: 0.0042862358663088565]
	TIME [epoch: 8.22 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00309573682097582		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.00309573682097582 | validation: 0.004321698175513159]
	TIME [epoch: 8.18 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003182506221950365		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.003182506221950365 | validation: 0.00431024957932241]
	TIME [epoch: 8.17 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032712667643139313		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0032712667643139313 | validation: 0.004015261148238644]
	TIME [epoch: 8.18 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030049423394258165		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.0030049423394258165 | validation: 0.004021930572714517]
	TIME [epoch: 8.19 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031417097634320306		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.0031417097634320306 | validation: 0.004653398423123083]
	TIME [epoch: 8.2 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029753576806052793		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0029753576806052793 | validation: 0.003990537940392159]
	TIME [epoch: 8.21 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030428616558741766		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0030428616558741766 | validation: 0.0040473701107763705]
	TIME [epoch: 8.18 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030251790903428944		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.0030251790903428944 | validation: 0.004413912947325931]
	TIME [epoch: 8.19 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031884153567176272		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.0031884153567176272 | validation: 0.003860129515041236]
	TIME [epoch: 8.18 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028627782428791745		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.0028627782428791745 | validation: 0.004059634713767132]
	TIME [epoch: 8.2 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031962287499066448		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0031962287499066448 | validation: 0.0041084426460213635]
	TIME [epoch: 8.23 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029182641271451116		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.0029182641271451116 | validation: 0.004491476793443913]
	TIME [epoch: 8.19 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030075805318954684		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0030075805318954684 | validation: 0.004238851952891332]
	TIME [epoch: 8.17 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031528316576894507		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.0031528316576894507 | validation: 0.003951110121242609]
	TIME [epoch: 8.18 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031010116154731905		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.0031010116154731905 | validation: 0.00434016178852885]
	TIME [epoch: 8.19 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029431933883817406		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.0029431933883817406 | validation: 0.0036361179181011467]
	TIME [epoch: 8.22 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027458781953479186		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0027458781953479186 | validation: 0.0049417221922067505]
	TIME [epoch: 8.19 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032265023477749295		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0032265023477749295 | validation: 0.004568326461368403]
	TIME [epoch: 8.17 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003020182568322049		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.003020182568322049 | validation: 0.00395709444067202]
	TIME [epoch: 8.19 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031525933497163036		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.0031525933497163036 | validation: 0.00425333722630515]
	TIME [epoch: 8.18 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030737808033565036		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.0030737808033565036 | validation: 0.004196306120755552]
	TIME [epoch: 8.23 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002854270725252696		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.002854270725252696 | validation: 0.004826989278983953]
	TIME [epoch: 8.19 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031834883286704545		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.0031834883286704545 | validation: 0.004251038512527814]
	TIME [epoch: 8.19 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029048308644698878		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0029048308644698878 | validation: 0.004365141883648201]
	TIME [epoch: 8.17 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003118882533890492		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.003118882533890492 | validation: 0.00419249057313983]
	TIME [epoch: 8.18 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003016102540654817		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.003016102540654817 | validation: 0.004257895026469705]
	TIME [epoch: 8.22 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003004460181279105		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.003004460181279105 | validation: 0.004018597939914106]
	TIME [epoch: 8.19 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030421090121779066		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0030421090121779066 | validation: 0.003722101838249535]
	TIME [epoch: 8.19 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030691220776847693		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.0030691220776847693 | validation: 0.0041284448196666785]
	TIME [epoch: 8.19 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027982475382917287		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.0027982475382917287 | validation: 0.004611308450885041]
	TIME [epoch: 8.18 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030386969598033744		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.0030386969598033744 | validation: 0.004360532192924215]
	TIME [epoch: 8.19 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030123776182330642		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.0030123776182330642 | validation: 0.003637495417568937]
	TIME [epoch: 8.21 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028749698900095953		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.0028749698900095953 | validation: 0.004600104764169803]
	TIME [epoch: 8.18 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003116875549013566		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.003116875549013566 | validation: 0.004347917789467084]
	TIME [epoch: 8.17 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027528802821578063		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0027528802821578063 | validation: 0.0051192569918495166]
	TIME [epoch: 8.18 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030644192989525937		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.0030644192989525937 | validation: 0.004451081796953188]
	TIME [epoch: 8.19 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003185624556815378		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.003185624556815378 | validation: 0.004290771576645159]
	TIME [epoch: 8.22 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002991982384725378		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.002991982384725378 | validation: 0.003925060781506559]
	TIME [epoch: 8.18 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028500608154639934		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.0028500608154639934 | validation: 0.004664600862618536]
	TIME [epoch: 8.18 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002983008516020681		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.002983008516020681 | validation: 0.004145810840887942]
	TIME [epoch: 8.18 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002908891196586254		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.002908891196586254 | validation: 0.004422513136034183]
	TIME [epoch: 8.19 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028530677261213045		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0028530677261213045 | validation: 0.004331526684202581]
	TIME [epoch: 8.21 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031179394274110797		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.0031179394274110797 | validation: 0.0038150173830368912]
	TIME [epoch: 8.2 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029990106810875764		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.0029990106810875764 | validation: 0.004347496033687283]
	TIME [epoch: 8.2 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032212544492262107		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0032212544492262107 | validation: 0.005070304868810004]
	TIME [epoch: 8.18 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028115136080744847		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.0028115136080744847 | validation: 0.004045625319499185]
	TIME [epoch: 8.2 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029273312438472428		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.0029273312438472428 | validation: 0.004219549035472963]
	TIME [epoch: 8.21 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002934022321512828		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.002934022321512828 | validation: 0.004578145033755428]
	TIME [epoch: 8.2 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029634273270958992		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0029634273270958992 | validation: 0.004688404092728658]
	TIME [epoch: 8.19 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031432094798794384		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.0031432094798794384 | validation: 0.004147080024277111]
	TIME [epoch: 8.2 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003042470521579813		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.003042470521579813 | validation: 0.0043444951066278]
	TIME [epoch: 8.19 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003276321061393794		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.003276321061393794 | validation: 0.003686167029958049]
	TIME [epoch: 8.23 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003009755469043385		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.003009755469043385 | validation: 0.004122957044421876]
	TIME [epoch: 8.19 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003017054544064547		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.003017054544064547 | validation: 0.004458549433629666]
	TIME [epoch: 8.18 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028172414555681065		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0028172414555681065 | validation: 0.0047867804663631625]
	TIME [epoch: 8.19 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003053647393604828		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.003053647393604828 | validation: 0.004249926649709156]
	TIME [epoch: 8.18 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028988516780768707		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.0028988516780768707 | validation: 0.00448632520453424]
	TIME [epoch: 8.19 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028714526497982873		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.0028714526497982873 | validation: 0.004381061652743102]
	TIME [epoch: 8.2 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029181851189299794		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.0029181851189299794 | validation: 0.004427391136375655]
	TIME [epoch: 8.18 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002659052693917716		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.002659052693917716 | validation: 0.004357568140894032]
	TIME [epoch: 8.18 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003064117631917129		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.003064117631917129 | validation: 0.004382996003629186]
	TIME [epoch: 8.19 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003072117028787764		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.003072117028787764 | validation: 0.004423975419348685]
	TIME [epoch: 8.18 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029798001786477003		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0029798001786477003 | validation: 0.004421102374933198]
	TIME [epoch: 8.23 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029978765864324053		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.0029978765864324053 | validation: 0.004094114356751893]
	TIME [epoch: 8.19 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030240465673271335		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.0030240465673271335 | validation: 0.003610792733560485]
	TIME [epoch: 8.19 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002883128539503403		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.002883128539503403 | validation: 0.004602151467491692]
	TIME [epoch: 8.18 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002961760423468039		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.002961760423468039 | validation: 0.004001315370738163]
	TIME [epoch: 8.18 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030175878143822153		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.0030175878143822153 | validation: 0.004314080165071219]
	TIME [epoch: 8.23 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029775173010812813		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.0029775173010812813 | validation: 0.004537302449412618]
	TIME [epoch: 8.18 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029289663990892632		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.0029289663990892632 | validation: 0.00430374433350966]
	TIME [epoch: 8.18 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033949185439536146		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.0033949185439536146 | validation: 0.004072960970963778]
	TIME [epoch: 8.18 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002889306426365899		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.002889306426365899 | validation: 0.004024448812362806]
	TIME [epoch: 8.18 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028327355245028087		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0028327355245028087 | validation: 0.003998662404802298]
	TIME [epoch: 8.21 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003023157961602539		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.003023157961602539 | validation: 0.003915865102069172]
	TIME [epoch: 8.18 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002862090491261003		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.002862090491261003 | validation: 0.0037924351047150485]
	TIME [epoch: 8.17 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029374660588497347		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0029374660588497347 | validation: 0.004469659023460354]
	TIME [epoch: 8.17 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029505603536702954		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.0029505603536702954 | validation: 0.004366805754413697]
	TIME [epoch: 8.17 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028057791569928705		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0028057791569928705 | validation: 0.004087164593077128]
	TIME [epoch: 8.19 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029736011853810944		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.0029736011853810944 | validation: 0.004327458522055107]
	TIME [epoch: 8.21 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031778322862943418		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.0031778322862943418 | validation: 0.004620658735576596]
	TIME [epoch: 8.17 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029741559443862073		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.0029741559443862073 | validation: 0.004774702594733436]
	TIME [epoch: 8.19 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003132595051083438		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.003132595051083438 | validation: 0.004140925987211538]
	TIME [epoch: 8.18 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002846886039412974		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.002846886039412974 | validation: 0.005031939855329992]
	TIME [epoch: 8.19 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032002798194490593		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.0032002798194490593 | validation: 0.004660064540807965]
	TIME [epoch: 8.21 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030340182538196106		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.0030340182538196106 | validation: 0.004253821402206372]
	TIME [epoch: 8.19 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003127932277415468		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.003127932277415468 | validation: 0.004439429530306817]
	TIME [epoch: 8.19 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032672990216385763		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.0032672990216385763 | validation: 0.004175622193352615]
	TIME [epoch: 8.18 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00290745315573921		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.00290745315573921 | validation: 0.0036622732594072185]
	TIME [epoch: 8.19 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002713102196081676		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.002713102196081676 | validation: 0.004181536287096886]
	TIME [epoch: 8.22 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003156144059749539		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.003156144059749539 | validation: 0.0037930749009285744]
	TIME [epoch: 8.19 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029887019813495124		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.0029887019813495124 | validation: 0.004330550431695241]
	TIME [epoch: 8.17 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028886611051796795		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.0028886611051796795 | validation: 0.0043984943968461065]
	TIME [epoch: 8.19 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029778796054796		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0029778796054796 | validation: 0.004453384032859271]
	TIME [epoch: 8.17 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031019035048331983		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.0031019035048331983 | validation: 0.0042113927092025496]
	TIME [epoch: 8.23 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027667065879354385		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.0027667065879354385 | validation: 0.0037505921784363318]
	TIME [epoch: 8.2 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029583734791348323		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0029583734791348323 | validation: 0.003919320889440383]
	TIME [epoch: 8.19 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002883364738265598		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.002883364738265598 | validation: 0.004268971403470284]
	TIME [epoch: 8.18 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028956168220187644		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.0028956168220187644 | validation: 0.004552569683235607]
	TIME [epoch: 8.17 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028161570853607347		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0028161570853607347 | validation: 0.0042649850489293265]
	TIME [epoch: 8.22 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002802678207124997		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.002802678207124997 | validation: 0.004141439920631681]
	TIME [epoch: 8.19 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028517411607453177		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.0028517411607453177 | validation: 0.0038248137670189794]
	TIME [epoch: 8.19 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030259035755234075		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.0030259035755234075 | validation: 0.004526002073175906]
	TIME [epoch: 8.18 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002843788630339382		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.002843788630339382 | validation: 0.0041703232681390865]
	TIME [epoch: 8.19 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028797844481194415		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.0028797844481194415 | validation: 0.004860496263211285]
	TIME [epoch: 8.19 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002711774326781701		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.002711774326781701 | validation: 0.00397332003689165]
	TIME [epoch: 8.2 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030487870443729383		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.0030487870443729383 | validation: 0.00453199648949362]
	TIME [epoch: 8.18 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029326299037566663		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.0029326299037566663 | validation: 0.003921507713428032]
	TIME [epoch: 8.18 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027885608813858443		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0027885608813858443 | validation: 0.0038760968451717675]
	TIME [epoch: 8.18 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030331642390396714		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.0030331642390396714 | validation: 0.004077544139709299]
	TIME [epoch: 8.19 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030251836237948537		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.0030251836237948537 | validation: 0.004365455765510356]
	TIME [epoch: 8.23 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003019402149528696		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.003019402149528696 | validation: 0.0042229104562555115]
	TIME [epoch: 8.18 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002870502783334532		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.002870502783334532 | validation: 0.0037013149014251097]
	TIME [epoch: 8.19 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030464251092113532		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.0030464251092113532 | validation: 0.004116300665487693]
	TIME [epoch: 8.19 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030978828761896154		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.0030978828761896154 | validation: 0.004473385271215753]
	TIME [epoch: 8.19 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002821519816241724		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.002821519816241724 | validation: 0.004159118018763761]
	TIME [epoch: 8.23 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030799112985575327		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.0030799112985575327 | validation: 0.00424760619127257]
	TIME [epoch: 8.18 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029246260215982102		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.0029246260215982102 | validation: 0.00407887111665256]
	TIME [epoch: 8.19 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030684043115787006		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0030684043115787006 | validation: 0.0045416070126233585]
	TIME [epoch: 8.19 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002991955629381894		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.002991955629381894 | validation: 0.00379384612882007]
	TIME [epoch: 8.19 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027790696586597456		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.0027790696586597456 | validation: 0.004096926851388034]
	TIME [epoch: 8.21 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027804889606675457		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0027804889606675457 | validation: 0.0038740190284841164]
	TIME [epoch: 8.19 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002910013313923729		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.002910013313923729 | validation: 0.003646576081828194]
	TIME [epoch: 8.18 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028134407142988162		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0028134407142988162 | validation: 0.004383669354598493]
	TIME [epoch: 8.18 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002880895757579411		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.002880895757579411 | validation: 0.004547234162552366]
	TIME [epoch: 8.19 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003042883110623917		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.003042883110623917 | validation: 0.0040663468575006315]
	TIME [epoch: 8.22 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029417690859754693		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.0029417690859754693 | validation: 0.004421063336550803]
	TIME [epoch: 8.19 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002820257724298458		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.002820257724298458 | validation: 0.004028468845289069]
	TIME [epoch: 8.17 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028799296515490402		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0028799296515490402 | validation: 0.004167482025189635]
	TIME [epoch: 8.19 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002973390576959731		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.002973390576959731 | validation: 0.0040058170801202785]
	TIME [epoch: 8.18 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003134704121399332		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.003134704121399332 | validation: 0.0042729790879232135]
	TIME [epoch: 8.2 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027223783403562845		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.0027223783403562845 | validation: 0.004320044947637231]
	TIME [epoch: 8.21 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028324045932025307		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.0028324045932025307 | validation: 0.0038820477861305812]
	TIME [epoch: 8.19 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030768621698528077		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0030768621698528077 | validation: 0.0043470755349471965]
	TIME [epoch: 8.17 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028865747386198374		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.0028865747386198374 | validation: 0.0039026252367095147]
	TIME [epoch: 8.18 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002948635667487431		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.002948635667487431 | validation: 0.004344795658307901]
	TIME [epoch: 8.19 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028091223329560077		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.0028091223329560077 | validation: 0.004193984424397786]
	TIME [epoch: 8.21 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030448943447141386		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.0030448943447141386 | validation: 0.0039555020219040025]
	TIME [epoch: 8.2 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002916104290114305		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.002916104290114305 | validation: 0.004009768377264952]
	TIME [epoch: 8.18 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029590660369587037		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.0029590660369587037 | validation: 0.004273453034263934]
	TIME [epoch: 8.19 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028083272487739856		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0028083272487739856 | validation: 0.003924514106067715]
	TIME [epoch: 8.18 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027247620108121506		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.0027247620108121506 | validation: 0.0046492267938842875]
	TIME [epoch: 8.24 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030677675210468098		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.0030677675210468098 | validation: 0.0041108461666103475]
	TIME [epoch: 8.21 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002817373380981424		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.002817373380981424 | validation: 0.0038517752219411065]
	TIME [epoch: 8.2 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002870907029061994		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.002870907029061994 | validation: 0.004648754633229416]
	TIME [epoch: 8.2 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002798721019891644		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.002798721019891644 | validation: 0.0038440826754293643]
	TIME [epoch: 8.19 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027810349182030144		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.0027810349182030144 | validation: 0.003626523276492077]
	TIME [epoch: 8.23 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030595376294809793		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0030595376294809793 | validation: 0.0042944225631495695]
	TIME [epoch: 8.2 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028597150803157624		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0028597150803157624 | validation: 0.003879715627915602]
	TIME [epoch: 8.19 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002949358086992639		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.002949358086992639 | validation: 0.004055650040805865]
	TIME [epoch: 8.19 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031469212235952343		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.0031469212235952343 | validation: 0.005056238675339791]
	TIME [epoch: 8.2 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028235460611180574		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0028235460611180574 | validation: 0.003982912523618329]
	TIME [epoch: 8.23 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00294027674910255		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.00294027674910255 | validation: 0.0038934768208517094]
	TIME [epoch: 8.2 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030297469992652897		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.0030297469992652897 | validation: 0.004085328893844906]
	TIME [epoch: 8.19 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002884031656422083		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.002884031656422083 | validation: 0.004324352612077965]
	TIME [epoch: 8.2 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028678210086747866		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.0028678210086747866 | validation: 0.003860756602294818]
	TIME [epoch: 8.2 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029853324690393805		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0029853324690393805 | validation: 0.004497447487223125]
	TIME [epoch: 8.2 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002711800779263688		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.002711800779263688 | validation: 0.004156403202058313]
	TIME [epoch: 8.22 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00301180916368504		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.00301180916368504 | validation: 0.004129852733531136]
	TIME [epoch: 8.19 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027769064998027773		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.0027769064998027773 | validation: 0.0037041821707416408]
	TIME [epoch: 8.19 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002795285547768424		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.002795285547768424 | validation: 0.0042516005037254835]
	TIME [epoch: 8.18 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002822079352432237		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.002822079352432237 | validation: 0.003934535617880093]
	TIME [epoch: 8.2 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030110323427247417		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0030110323427247417 | validation: 0.004202978041911952]
	TIME [epoch: 8.22 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028707623618741763		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.0028707623618741763 | validation: 0.004432855033278149]
	TIME [epoch: 8.19 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029891365423885766		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.0029891365423885766 | validation: 0.004106638848725525]
	TIME [epoch: 8.18 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025680794529988594		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.0025680794529988594 | validation: 0.004181777602835362]
	TIME [epoch: 8.18 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028652265731328574		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0028652265731328574 | validation: 0.00438052338826489]
	TIME [epoch: 8.19 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027895836007802823		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.0027895836007802823 | validation: 0.004191573198062017]
	TIME [epoch: 8.22 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030519659070368374		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.0030519659070368374 | validation: 0.00460233580684666]
	TIME [epoch: 8.2 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003026954142643196		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.003026954142643196 | validation: 0.003821868906800754]
	TIME [epoch: 8.19 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029494331201990204		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.0029494331201990204 | validation: 0.00390188925577743]
	TIME [epoch: 8.18 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031566527338490425		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0031566527338490425 | validation: 0.0038660155652623543]
	TIME [epoch: 8.19 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027631399739377277		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.0027631399739377277 | validation: 0.0036839918387570614]
	TIME [epoch: 8.22 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029489113592544216		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.0029489113592544216 | validation: 0.0037610815614842934]
	TIME [epoch: 8.2 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029269247899062437		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.0029269247899062437 | validation: 0.004068638985171362]
	TIME [epoch: 8.18 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002729145024650568		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.002729145024650568 | validation: 0.004206768368517943]
	TIME [epoch: 8.18 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002904018935588477		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.002904018935588477 | validation: 0.0043909500472296]
	TIME [epoch: 8.18 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027363462842420897		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.0027363462842420897 | validation: 0.003945731715192698]
	TIME [epoch: 8.21 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002943264563459665		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.002943264563459665 | validation: 0.0039831953411718305]
	TIME [epoch: 8.2 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002890186044468734		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.002890186044468734 | validation: 0.004390230884299969]
	TIME [epoch: 8.18 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027545656707613823		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.0027545656707613823 | validation: 0.0041896947166554024]
	TIME [epoch: 8.18 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002788247766086156		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.002788247766086156 | validation: 0.0037352850208922715]
	TIME [epoch: 8.19 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002919856556829889		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.002919856556829889 | validation: 0.0038004563752951394]
	TIME [epoch: 8.18 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027802994242287216		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.0027802994242287216 | validation: 0.0038861478510437177]
	TIME [epoch: 8.23 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029019336043585283		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.0029019336043585283 | validation: 0.004090308617940501]
	TIME [epoch: 8.18 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031716528397720016		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.0031716528397720016 | validation: 0.004215094335929846]
	TIME [epoch: 8.18 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003090743757150352		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.003090743757150352 | validation: 0.0037331291619631495]
	TIME [epoch: 8.19 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002851279299239059		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.002851279299239059 | validation: 0.004450591486217783]
	TIME [epoch: 8.19 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028673399686943665		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.0028673399686943665 | validation: 0.0034764265558500963]
	TIME [epoch: 8.23 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028669256421454794		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.0028669256421454794 | validation: 0.004097272748642671]
	TIME [epoch: 8.18 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028720840759392362		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.0028720840759392362 | validation: 0.004048024441863463]
	TIME [epoch: 8.18 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031415909405801004		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.0031415909405801004 | validation: 0.0046898001075644825]
	TIME [epoch: 8.19 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002704065023535851		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.002704065023535851 | validation: 0.003612908587471428]
	TIME [epoch: 8.19 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031655721036145		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.0031655721036145 | validation: 0.003484869940680607]
	TIME [epoch: 8.2 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026764875449881375		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0026764875449881375 | validation: 0.004371828508019066]
	TIME [epoch: 8.19 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026913176322768016		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.0026913176322768016 | validation: 0.004363135393169484]
	TIME [epoch: 8.17 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029250847488511305		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.0029250847488511305 | validation: 0.003901369888280608]
	TIME [epoch: 8.18 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028565471731860697		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0028565471731860697 | validation: 0.004128241441821399]
	TIME [epoch: 8.18 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002728128484662094		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.002728128484662094 | validation: 0.003603633148616577]
	TIME [epoch: 8.22 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029430829930751964		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.0029430829930751964 | validation: 0.0043660090107422505]
	TIME [epoch: 8.2 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002733220863243694		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.002733220863243694 | validation: 0.004252096071224905]
	TIME [epoch: 8.19 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002757614990797342		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.002757614990797342 | validation: 0.004189472028659583]
	TIME [epoch: 8.18 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030645801488829866		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.0030645801488829866 | validation: 0.003974920814096464]
	TIME [epoch: 8.17 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028817441514959906		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.0028817441514959906 | validation: 0.003692394619399105]
	TIME [epoch: 8.21 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028114605147050303		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.0028114605147050303 | validation: 0.005519353199430512]
	TIME [epoch: 8.21 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032415431622258017		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.0032415431622258017 | validation: 0.003862417461041456]
	TIME [epoch: 8.18 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031099730989513517		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0031099730989513517 | validation: 0.003942063008429148]
	TIME [epoch: 8.19 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003058159397400642		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.003058159397400642 | validation: 0.004009014987599398]
	TIME [epoch: 8.17 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028722881622788602		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.0028722881622788602 | validation: 0.003462094081059546]
	TIME [epoch: 8.21 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00286690895570846		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.00286690895570846 | validation: 0.004268672246255901]
	TIME [epoch: 8.21 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030109945099980823		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.0030109945099980823 | validation: 0.00422085389179337]
	TIME [epoch: 8.19 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028925664274297644		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.0028925664274297644 | validation: 0.0038537046214849814]
	TIME [epoch: 8.18 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029966663441833978		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.0029966663441833978 | validation: 0.004085684124809415]
	TIME [epoch: 8.19 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028707157756798682		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.0028707157756798682 | validation: 0.0045910097244976685]
	TIME [epoch: 8.18 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027210441379831433		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0027210441379831433 | validation: 0.0051204536070576755]
	TIME [epoch: 8.23 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028305521021156723		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.0028305521021156723 | validation: 0.0038266998897934995]
	TIME [epoch: 8.19 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030665476681415115		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.0030665476681415115 | validation: 0.004026778924832228]
	TIME [epoch: 8.18 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030933793014060445		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.0030933793014060445 | validation: 0.00412560352439134]
	TIME [epoch: 8.19 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029867014891361682		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.0029867014891361682 | validation: 0.0047153880458748266]
	TIME [epoch: 8.18 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029593514354041683		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.0029593514354041683 | validation: 0.004472349557734707]
	TIME [epoch: 8.23 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027739680975852055		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.0027739680975852055 | validation: 0.004243200323770536]
	TIME [epoch: 8.18 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002911906092010013		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.002911906092010013 | validation: 0.004074095052413921]
	TIME [epoch: 8.2 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028719751667137484		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.0028719751667137484 | validation: 0.0040215998202314225]
	TIME [epoch: 8.18 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002669460351117239		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.002669460351117239 | validation: 0.004395636068004342]
	TIME [epoch: 8.18 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002907707966309979		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.002907707966309979 | validation: 0.004102851718985407]
	TIME [epoch: 8.2 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029581612490993748		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.0029581612490993748 | validation: 0.003798677815694867]
	TIME [epoch: 8.21 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026753124388713048		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0026753124388713048 | validation: 0.003540906424897461]
	TIME [epoch: 8.19 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002965436884323264		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.002965436884323264 | validation: 0.004119193817367442]
	TIME [epoch: 8.18 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027867664590995717		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.0027867664590995717 | validation: 0.004453005226703562]
	TIME [epoch: 8.18 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002806105097410617		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.002806105097410617 | validation: 0.003799790716237607]
	TIME [epoch: 8.19 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027872859800665527		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.0027872859800665527 | validation: 0.0038166584900482005]
	TIME [epoch: 8.22 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002968611117414379		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.002968611117414379 | validation: 0.003932897104120425]
	TIME [epoch: 8.18 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028997891536508354		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.0028997891536508354 | validation: 0.003942533096449713]
	TIME [epoch: 8.19 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002791419478271459		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.002791419478271459 | validation: 0.00471476600210176]
	TIME [epoch: 8.18 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028519073028042694		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.0028519073028042694 | validation: 0.004115534589299643]
	TIME [epoch: 8.19 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029218565072593704		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.0029218565072593704 | validation: 0.003859468145485547]
	TIME [epoch: 8.22 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002756145614622419		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.002756145614622419 | validation: 0.0038614843152818493]
	TIME [epoch: 8.18 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002859814595281679		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.002859814595281679 | validation: 0.003832014614000495]
	TIME [epoch: 8.19 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00297601222279953		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.00297601222279953 | validation: 0.004030386412718354]
	TIME [epoch: 8.19 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003039030964479726		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.003039030964479726 | validation: 0.004104160551261347]
	TIME [epoch: 8.2 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002750754755871206		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.002750754755871206 | validation: 0.0038653645530014823]
	TIME [epoch: 8.23 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027611142413235404		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.0027611142413235404 | validation: 0.003951841467627043]
	TIME [epoch: 8.2 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029824833601186564		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.0029824833601186564 | validation: 0.004408316715459954]
	TIME [epoch: 8.18 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002973304409423364		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.002973304409423364 | validation: 0.004152640618277004]
	TIME [epoch: 8.19 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028459121851009523		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.0028459121851009523 | validation: 0.004140543671739027]
	TIME [epoch: 8.18 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002882284775715642		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.002882284775715642 | validation: 0.0045416874068034884]
	TIME [epoch: 8.22 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027624068584281465		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.0027624068584281465 | validation: 0.004372228925097101]
	TIME [epoch: 8.2 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028861285908432705		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.0028861285908432705 | validation: 0.004114202357973273]
	TIME [epoch: 8.18 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027242914164176298		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.0027242914164176298 | validation: 0.004383899330128817]
	TIME [epoch: 8.19 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029822371460779696		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0029822371460779696 | validation: 0.0042546373916376775]
	TIME [epoch: 8.18 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002862932062684721		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.002862932062684721 | validation: 0.004641973822139043]
	TIME [epoch: 8.23 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002765704472127398		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.002765704472127398 | validation: 0.0046869766384433995]
	TIME [epoch: 8.2 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032209408029909175		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.0032209408029909175 | validation: 0.004232067202216983]
	TIME [epoch: 8.19 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002759955905710847		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.002759955905710847 | validation: 0.004524667500827492]
	TIME [epoch: 8.18 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027602885308329827		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0027602885308329827 | validation: 0.003919119189413426]
	TIME [epoch: 8.2 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027900756147858927		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.0027900756147858927 | validation: 0.004552778487638198]
	TIME [epoch: 8.22 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026831805187868853		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.0026831805187868853 | validation: 0.004136931846889689]
	TIME [epoch: 8.22 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002817365212094714		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.002817365212094714 | validation: 0.004218898145264827]
	TIME [epoch: 8.19 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029400528936671033		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.0029400528936671033 | validation: 0.0038071894216557276]
	TIME [epoch: 8.18 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00287340680155402		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.00287340680155402 | validation: 0.003716605669085225]
	TIME [epoch: 8.2 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028347446226318442		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.0028347446226318442 | validation: 0.004329134106166637]
	TIME [epoch: 8.2 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027395150662051886		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.0027395150662051886 | validation: 0.0036220150007383687]
	TIME [epoch: 8.23 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028697784835736663		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.0028697784835736663 | validation: 0.004379353811225665]
	TIME [epoch: 8.19 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002794374291615049		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.002794374291615049 | validation: 0.003552799641425121]
	TIME [epoch: 8.19 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002969960282141658		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.002969960282141658 | validation: 0.003566425048340746]
	TIME [epoch: 8.19 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026588791378017824		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.0026588791378017824 | validation: 0.0039500356306989]
	TIME [epoch: 8.2 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002970554134013245		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.002970554134013245 | validation: 0.003820096720602048]
	TIME [epoch: 8.24 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027900226997238957		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.0027900226997238957 | validation: 0.004594151440012383]
	TIME [epoch: 8.19 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002758052341466592		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.002758052341466592 | validation: 0.004203291187957801]
	TIME [epoch: 8.2 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028010771531453635		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.0028010771531453635 | validation: 0.003862959181673709]
	TIME [epoch: 8.19 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002890804118374099		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.002890804118374099 | validation: 0.004034787852236454]
	TIME [epoch: 8.2 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030793410256223673		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.0030793410256223673 | validation: 0.003797302421623956]
	TIME [epoch: 8.22 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002996843868402115		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.002996843868402115 | validation: 0.004167515120952616]
	TIME [epoch: 8.21 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028509909156192123		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.0028509909156192123 | validation: 0.004176199012308564]
	TIME [epoch: 8.19 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030338143063428774		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.0030338143063428774 | validation: 0.0038661987241919863]
	TIME [epoch: 8.19 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027518990071252972		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.0027518990071252972 | validation: 0.004071278751528551]
	TIME [epoch: 8.2 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032229408741470205		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.0032229408741470205 | validation: 0.004205828455958741]
	TIME [epoch: 8.21 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029369550420229153		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.0029369550420229153 | validation: 0.004459150193912779]
	TIME [epoch: 8.21 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030711359831223782		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0030711359831223782 | validation: 0.0037848244717030017]
	TIME [epoch: 8.18 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002952464399209719		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.002952464399209719 | validation: 0.004470497817823807]
	TIME [epoch: 8.2 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029501576138093654		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0029501576138093654 | validation: 0.0038548849158313424]
	TIME [epoch: 8.19 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027701900259316232		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.0027701900259316232 | validation: 0.004140724242446654]
	TIME [epoch: 8.2 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00303053696259135		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.00303053696259135 | validation: 0.004003603629193202]
	TIME [epoch: 8.23 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002698774552603795		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.002698774552603795 | validation: 0.004233007150946322]
	TIME [epoch: 8.2 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002903204743386686		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.002903204743386686 | validation: 0.003811971456830181]
	TIME [epoch: 8.2 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029838959805595657		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.0029838959805595657 | validation: 0.004240797917040645]
	TIME [epoch: 8.19 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027489097586931477		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.0027489097586931477 | validation: 0.0043905520402018694]
	TIME [epoch: 8.21 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002979141488339854		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.002979141488339854 | validation: 0.004696690406166409]
	TIME [epoch: 8.23 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002625841069114949		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.002625841069114949 | validation: 0.003737793261030818]
	TIME [epoch: 8.19 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028703902936091717		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.0028703902936091717 | validation: 0.004173790107382075]
	TIME [epoch: 8.18 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027249004062167748		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.0027249004062167748 | validation: 0.003834735396769041]
	TIME [epoch: 8.2 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028610507210974374		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0028610507210974374 | validation: 0.004180149339190319]
	TIME [epoch: 8.19 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029249199562010582		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.0029249199562010582 | validation: 0.003957101700588058]
	TIME [epoch: 8.23 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00285468360655732		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.00285468360655732 | validation: 0.004396854471898536]
	TIME [epoch: 8.18 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002718018878921262		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.002718018878921262 | validation: 0.0038726417381176126]
	TIME [epoch: 8.19 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027815229711512794		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.0027815229711512794 | validation: 0.004665797953810075]
	TIME [epoch: 8.19 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025890802477832884		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.0025890802477832884 | validation: 0.00425832271718189]
	TIME [epoch: 8.19 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002780223383237698		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.002780223383237698 | validation: 0.0035248534059353857]
	TIME [epoch: 8.23 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002717130960228831		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.002717130960228831 | validation: 0.0038702372398837313]
	TIME [epoch: 8.19 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002777346655713613		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.002777346655713613 | validation: 0.004016833020754607]
	TIME [epoch: 8.19 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00283554492291073		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.00283554492291073 | validation: 0.004325389874555611]
	TIME [epoch: 8.18 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002742547245226044		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.002742547245226044 | validation: 0.004005310717963374]
	TIME [epoch: 8.19 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028281423137408177		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.0028281423137408177 | validation: 0.004330934821929517]
	TIME [epoch: 8.21 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029180669636644013		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0029180669636644013 | validation: 0.0044001682693666395]
	TIME [epoch: 8.23 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002980593027378963		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.002980593027378963 | validation: 0.004051725582853897]
	TIME [epoch: 8.19 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002896913678958858		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.002896913678958858 | validation: 0.0034860935598362607]
	TIME [epoch: 8.19 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003108162265611371		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.003108162265611371 | validation: 0.004240771788045059]
	TIME [epoch: 8.2 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002787679331510964		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.002787679331510964 | validation: 0.004314402271307078]
	TIME [epoch: 8.19 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026259048697807996		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0026259048697807996 | validation: 0.0036302856042324614]
	TIME [epoch: 8.23 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028597470489797553		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.0028597470489797553 | validation: 0.0035828586407929243]
	TIME [epoch: 8.18 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002555997075881905		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.002555997075881905 | validation: 0.00419086441915548]
	TIME [epoch: 8.19 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028415534872552		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.0028415534872552 | validation: 0.003685695327383402]
	TIME [epoch: 8.19 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002764604878110283		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.002764604878110283 | validation: 0.0036471200110931726]
	TIME [epoch: 8.2 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027344836823498344		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.0027344836823498344 | validation: 0.00408766694518007]
	TIME [epoch: 8.23 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002633239641244849		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.002633239641244849 | validation: 0.004014179752175066]
	TIME [epoch: 8.2 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029042670725347164		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0029042670725347164 | validation: 0.004659632615993946]
	TIME [epoch: 8.19 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026193719427717644		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.0026193719427717644 | validation: 0.004000601375405711]
	TIME [epoch: 8.19 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029653214017277022		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0029653214017277022 | validation: 0.004043791714324129]
	TIME [epoch: 8.19 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027748620172210014		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.0027748620172210014 | validation: 0.0038463739971333084]
	TIME [epoch: 8.22 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026907048524267996		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.0026907048524267996 | validation: 0.004019667294820903]
	TIME [epoch: 8.2 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025816286373412066		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.0025816286373412066 | validation: 0.003763656794646431]
	TIME [epoch: 8.18 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029324752098043756		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.0029324752098043756 | validation: 0.003762033083005459]
	TIME [epoch: 8.2 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027817238471093395		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.0027817238471093395 | validation: 0.004345327436015456]
	TIME [epoch: 8.19 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002788955236881935		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.002788955236881935 | validation: 0.004043798354204305]
	TIME [epoch: 8.23 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002717899732770386		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.002717899732770386 | validation: 0.0039451611518324]
	TIME [epoch: 8.21 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002759623452951856		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.002759623452951856 | validation: 0.004413330823830593]
	TIME [epoch: 8.19 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002747490306917476		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.002747490306917476 | validation: 0.0043989729064316824]
	TIME [epoch: 8.19 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002566068032138746		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.002566068032138746 | validation: 0.004401963499315275]
	TIME [epoch: 8.19 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002856428787625769		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.002856428787625769 | validation: 0.004206181640758089]
	TIME [epoch: 8.21 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002797907360846734		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.002797907360846734 | validation: 0.004506344357363555]
	TIME [epoch: 8.22 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00285285639707148		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.00285285639707148 | validation: 0.004482151770902155]
	TIME [epoch: 8.19 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002788723800858251		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.002788723800858251 | validation: 0.0037643436800396833]
	TIME [epoch: 8.19 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024902923305766505		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.0024902923305766505 | validation: 0.0040351986454187656]
	TIME [epoch: 8.19 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026648158622137267		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.0026648158622137267 | validation: 0.004058521745686708]
	TIME [epoch: 8.18 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027081395820703416		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.0027081395820703416 | validation: 0.003925186488858317]
	TIME [epoch: 8.23 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026979062010286372		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.0026979062010286372 | validation: 0.0039386136411641605]
	TIME [epoch: 8.19 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025511221646612194		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.0025511221646612194 | validation: 0.003784531642610304]
	TIME [epoch: 8.19 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002724871854242682		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.002724871854242682 | validation: 0.004417052882861103]
	TIME [epoch: 8.19 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028010578194085922		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.0028010578194085922 | validation: 0.00440316620336966]
	TIME [epoch: 8.18 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002956393901455158		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.002956393901455158 | validation: 0.003967299496517166]
	TIME [epoch: 8.24 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002845869600679539		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.002845869600679539 | validation: 0.004263391266227927]
	TIME [epoch: 8.18 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027342189106815407		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.0027342189106815407 | validation: 0.004070503515936575]
	TIME [epoch: 8.19 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002871863276205026		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.002871863276205026 | validation: 0.004276504470194114]
	TIME [epoch: 8.18 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027402113056949748		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.0027402113056949748 | validation: 0.0038634103146096914]
	TIME [epoch: 8.19 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002834057438654619		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.002834057438654619 | validation: 0.0042856475201871755]
	TIME [epoch: 8.23 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002696746865109803		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.002696746865109803 | validation: 0.00400023585606519]
	TIME [epoch: 8.19 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002961662122604786		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.002961662122604786 | validation: 0.004261936916101283]
	TIME [epoch: 8.19 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002718747350271607		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.002718747350271607 | validation: 0.004103899944378017]
	TIME [epoch: 8.19 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027150364783392975		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0027150364783392975 | validation: 0.003809542409182848]
	TIME [epoch: 8.19 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028134619268736453		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0028134619268736453 | validation: 0.003868911347289906]
	TIME [epoch: 8.21 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00264262244143131		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.00264262244143131 | validation: 0.004576370754900411]
	TIME [epoch: 8.21 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002742382647220591		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.002742382647220591 | validation: 0.0043210548418661145]
	TIME [epoch: 8.18 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027772545929446607		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.0027772545929446607 | validation: 0.004042711898715728]
	TIME [epoch: 8.18 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002621169392355097		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.002621169392355097 | validation: 0.004084407515475327]
	TIME [epoch: 8.18 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025675519511232535		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.0025675519511232535 | validation: 0.0036727149236966215]
	TIME [epoch: 8.2 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026994057179657704		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.0026994057179657704 | validation: 0.0038862554443706036]
	TIME [epoch: 8.23 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027366066134369145		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.0027366066134369145 | validation: 0.0036537476184273486]
	TIME [epoch: 8.18 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002569350149302363		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.002569350149302363 | validation: 0.004612753347285657]
	TIME [epoch: 8.19 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027172450797067755		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.0027172450797067755 | validation: 0.0034875892855732514]
	TIME [epoch: 8.18 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030565064688963042		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.0030565064688963042 | validation: 0.003804411709720146]
	TIME [epoch: 8.19 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00277448272260852		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.00277448272260852 | validation: 0.0041044403521401695]
	TIME [epoch: 8.22 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002475385453808504		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.002475385453808504 | validation: 0.0040742165533338166]
	TIME [epoch: 8.19 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029041229805879584		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0029041229805879584 | validation: 0.0036050745481035484]
	TIME [epoch: 8.17 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002778980642418982		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.002778980642418982 | validation: 0.003960975064471931]
	TIME [epoch: 8.19 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028119783670494027		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.0028119783670494027 | validation: 0.004224701158705256]
	TIME [epoch: 8.19 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027576348949780683		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.0027576348949780683 | validation: 0.003760553122179356]
	TIME [epoch: 8.23 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002764463778575876		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.002764463778575876 | validation: 0.003897847455004177]
	TIME [epoch: 8.19 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026483698276074745		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.0026483698276074745 | validation: 0.004809853077685609]
	TIME [epoch: 8.18 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026081274802722716		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0026081274802722716 | validation: 0.0039733335251836205]
	TIME [epoch: 8.19 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028510432338897888		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0028510432338897888 | validation: 0.003850832164727162]
	TIME [epoch: 8.2 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028446939307201656		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.0028446939307201656 | validation: 0.004019155000558005]
	TIME [epoch: 8.23 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026093514661588717		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.0026093514661588717 | validation: 0.004475864983131687]
	TIME [epoch: 8.2 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002666493680180301		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.002666493680180301 | validation: 0.004174255435615282]
	TIME [epoch: 8.2 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028456531611115573		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.0028456531611115573 | validation: 0.004312454176240193]
	TIME [epoch: 8.17 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027208852852302046		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.0027208852852302046 | validation: 0.00425876153845297]
	TIME [epoch: 8.19 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002686816745601975		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.002686816745601975 | validation: 0.0034039966878804204]
	TIME [epoch: 8.22 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029744517652811452		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.0029744517652811452 | validation: 0.004350216450991908]
	TIME [epoch: 8.19 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028358680012480477		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.0028358680012480477 | validation: 0.00384106337012544]
	TIME [epoch: 8.19 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002578776247626478		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.002578776247626478 | validation: 0.004011349105539944]
	TIME [epoch: 8.18 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002667497660551521		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.002667497660551521 | validation: 0.003967890071813583]
	TIME [epoch: 8.19 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028175336072935276		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0028175336072935276 | validation: 0.004815533268422425]
	TIME [epoch: 8.19 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002852011033640491		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.002852011033640491 | validation: 0.003623821306262779]
	TIME [epoch: 8.22 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027222800502866335		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.0027222800502866335 | validation: 0.004219916008437329]
	TIME [epoch: 8.17 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002826200845821504		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.002826200845821504 | validation: 0.003329742596389838]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1745.pth
	Model improved!!!
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027041064924212925		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.0027041064924212925 | validation: 0.004104226704233499]
	TIME [epoch: 8.19 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028448020042024075		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0028448020042024075 | validation: 0.004303369952281914]
	TIME [epoch: 8.19 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027299248514716093		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.0027299248514716093 | validation: 0.004545730738029142]
	TIME [epoch: 8.24 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002744988902046043		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.002744988902046043 | validation: 0.004191322902035742]
	TIME [epoch: 8.18 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002839605923865094		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.002839605923865094 | validation: 0.0038021276576556164]
	TIME [epoch: 8.18 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002855908108242878		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.002855908108242878 | validation: 0.0037820397096821096]
	TIME [epoch: 8.18 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028007923724075413		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.0028007923724075413 | validation: 0.004077735573783183]
	TIME [epoch: 8.19 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002981377652882384		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.002981377652882384 | validation: 0.004016071203544092]
	TIME [epoch: 8.23 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028090808547105986		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.0028090808547105986 | validation: 0.003933848945993664]
	TIME [epoch: 8.19 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002673307625858004		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.002673307625858004 | validation: 0.003878475335059097]
	TIME [epoch: 8.19 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002669833647312534		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.002669833647312534 | validation: 0.004861738585880619]
	TIME [epoch: 8.19 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029845468664463676		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.0029845468664463676 | validation: 0.004000074812751658]
	TIME [epoch: 8.19 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030068050821535092		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.0030068050821535092 | validation: 0.004172815729089449]
	TIME [epoch: 8.22 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002849872775703342		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.002849872775703342 | validation: 0.004642474097033051]
	TIME [epoch: 8.19 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027566964669707354		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0027566964669707354 | validation: 0.00407380570304809]
	TIME [epoch: 8.18 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003167847209642913		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.003167847209642913 | validation: 0.004049995829456797]
	TIME [epoch: 8.19 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002663478564536014		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.002663478564536014 | validation: 0.00438062327633189]
	TIME [epoch: 8.18 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029416473409218874		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.0029416473409218874 | validation: 0.0044997566161837435]
	TIME [epoch: 8.22 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002852772660846743		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.002852772660846743 | validation: 0.003988455593283493]
	TIME [epoch: 8.18 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025855204000697434		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0025855204000697434 | validation: 0.0037182390497029856]
	TIME [epoch: 8.17 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002696502050285543		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.002696502050285543 | validation: 0.003821970047083802]
	TIME [epoch: 8.2 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026958076879812884		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.0026958076879812884 | validation: 0.0038707120113769195]
	TIME [epoch: 8.19 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002574868049277868		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.002574868049277868 | validation: 0.003948493021821485]
	TIME [epoch: 8.22 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002661935689078703		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.002661935689078703 | validation: 0.0046471134308691195]
	TIME [epoch: 8.21 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028822400557537826		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.0028822400557537826 | validation: 0.004134789800872464]
	TIME [epoch: 8.2 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029665018330565147		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.0029665018330565147 | validation: 0.004303403993962259]
	TIME [epoch: 8.18 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028652580881488076		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.0028652580881488076 | validation: 0.004662295264969651]
	TIME [epoch: 8.19 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002700277829794188		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.002700277829794188 | validation: 0.0037544258187834725]
	TIME [epoch: 8.19 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030417679320278047		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.0030417679320278047 | validation: 0.0034002464418640965]
	TIME [epoch: 8.23 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002872748997426447		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.002872748997426447 | validation: 0.003718565351615236]
	TIME [epoch: 8.2 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002879580840635382		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.002879580840635382 | validation: 0.004036629948025962]
	TIME [epoch: 8.19 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029007220425087974		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.0029007220425087974 | validation: 0.0040519570850966295]
	TIME [epoch: 8.2 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002861351615861723		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.002861351615861723 | validation: 0.003947521926844332]
	TIME [epoch: 8.19 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028491220237685617		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.0028491220237685617 | validation: 0.0039953286951813285]
	TIME [epoch: 8.23 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027810570109451814		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.0027810570109451814 | validation: 0.003825900171781168]
	TIME [epoch: 8.18 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028244557462679216		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0028244557462679216 | validation: 0.004584193165235114]
	TIME [epoch: 8.18 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030032524187843437		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.0030032524187843437 | validation: 0.004039943577664625]
	TIME [epoch: 8.19 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002632636637255065		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.002632636637255065 | validation: 0.004134909800422498]
	TIME [epoch: 8.19 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027149926603667485		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0027149926603667485 | validation: 0.0037568188549266346]
	TIME [epoch: 8.22 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028454429506996836		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.0028454429506996836 | validation: 0.0036866636981470577]
	TIME [epoch: 8.2 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002984575254032389		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.002984575254032389 | validation: 0.004127351496410223]
	TIME [epoch: 8.2 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002830747759918612		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.002830747759918612 | validation: 0.0036347979790067944]
	TIME [epoch: 8.19 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002803098586274524		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.002803098586274524 | validation: 0.0038791602435809987]
	TIME [epoch: 8.2 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028133664371003215		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.0028133664371003215 | validation: 0.004179756475215361]
	TIME [epoch: 8.22 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025726084987975325		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0025726084987975325 | validation: 0.003887248000748058]
	TIME [epoch: 8.2 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025971565456300145		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0025971565456300145 | validation: 0.00418174055446741]
	TIME [epoch: 8.19 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027809219942638813		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.0027809219942638813 | validation: 0.003755883293157254]
	TIME [epoch: 8.2 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002678009003036885		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.002678009003036885 | validation: 0.004350556321450466]
	TIME [epoch: 8.18 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002914808155654278		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.002914808155654278 | validation: 0.004272263693293944]
	TIME [epoch: 8.21 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002733595255483147		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.002733595255483147 | validation: 0.004400395931890032]
	TIME [epoch: 8.21 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029542013572632147		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.0029542013572632147 | validation: 0.004145417808434817]
	TIME [epoch: 8.18 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026471086680921714		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.0026471086680921714 | validation: 0.0039518905213503175]
	TIME [epoch: 8.19 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028105376322988874		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.0028105376322988874 | validation: 0.004607862308437093]
	TIME [epoch: 8.17 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00265702444122563		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.00265702444122563 | validation: 0.0037866442224127506]
	TIME [epoch: 8.2 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029566760523996186		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.0029566760523996186 | validation: 0.00429165236205685]
	TIME [epoch: 8.22 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027691702868416317		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0027691702868416317 | validation: 0.0046410998540993955]
	TIME [epoch: 8.19 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026916148210135537		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.0026916148210135537 | validation: 0.003726220787676553]
	TIME [epoch: 8.19 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028703611643191144		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.0028703611643191144 | validation: 0.00445786850123124]
	TIME [epoch: 8.19 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027241317422153598		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.0027241317422153598 | validation: 0.0043284366287959005]
	TIME [epoch: 8.19 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029892127970394967		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.0029892127970394967 | validation: 0.003839553404761505]
	TIME [epoch: 8.24 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002917311849618223		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.002917311849618223 | validation: 0.003991247001950509]
	TIME [epoch: 8.19 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002721477015926171		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.002721477015926171 | validation: 0.003645986830510407]
	TIME [epoch: 8.18 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028243570680632816		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.0028243570680632816 | validation: 0.004129876642010258]
	TIME [epoch: 8.18 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026574979327575942		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0026574979327575942 | validation: 0.0036855596267448207]
	TIME [epoch: 8.18 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026949487586669014		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.0026949487586669014 | validation: 0.003552209507876623]
	TIME [epoch: 8.23 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00283606943037998		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.00283606943037998 | validation: 0.0035472466912756864]
	TIME [epoch: 8.19 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025402388417139583		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.0025402388417139583 | validation: 0.003782691759399868]
	TIME [epoch: 8.18 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029105659477211047		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0029105659477211047 | validation: 0.003731811720348253]
	TIME [epoch: 8.16 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028534059750765063		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.0028534059750765063 | validation: 0.003901383652179456]
	TIME [epoch: 8.19 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027644535016324674		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.0027644535016324674 | validation: 0.004406946947201187]
	TIME [epoch: 8.22 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002755432225876128		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.002755432225876128 | validation: 0.004434454704258411]
	TIME [epoch: 8.19 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002775211220507782		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.002775211220507782 | validation: 0.003920975053088305]
	TIME [epoch: 8.19 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026818369937439386		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.0026818369937439386 | validation: 0.0036574759376089964]
	TIME [epoch: 8.18 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002830302424828487		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.002830302424828487 | validation: 0.0035566313624477595]
	TIME [epoch: 8.18 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002920759769192724		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.002920759769192724 | validation: 0.003667136421207801]
	TIME [epoch: 8.19 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026474181593538707		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.0026474181593538707 | validation: 0.004283265159702733]
	TIME [epoch: 8.21 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029614576255114536		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0029614576255114536 | validation: 0.003591995482259085]
	TIME [epoch: 8.17 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028871056209513425		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.0028871056209513425 | validation: 0.003996579724785354]
	TIME [epoch: 8.18 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002778344481113071		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.002778344481113071 | validation: 0.0038105299655285486]
	TIME [epoch: 8.18 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002722009371399421		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.002722009371399421 | validation: 0.0038831670212787495]
	TIME [epoch: 8.18 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029878541084314703		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.0029878541084314703 | validation: 0.0046798804905272915]
	TIME [epoch: 8.22 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026869731276519732		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.0026869731276519732 | validation: 0.004473283054399461]
	TIME [epoch: 8.17 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028799010973428836		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0028799010973428836 | validation: 0.004540276752217231]
	TIME [epoch: 8.19 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026155456183587214		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.0026155456183587214 | validation: 0.003984233345101999]
	TIME [epoch: 8.18 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002860051930381243		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.002860051930381243 | validation: 0.004029986336454518]
	TIME [epoch: 8.19 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002960475609369374		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.002960475609369374 | validation: 0.004329834141482509]
	TIME [epoch: 8.22 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002797863318836986		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.002797863318836986 | validation: 0.004461827570247822]
	TIME [epoch: 8.19 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026822452343358127		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.0026822452343358127 | validation: 0.00434622001274718]
	TIME [epoch: 8.17 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028388672043915646		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.0028388672043915646 | validation: 0.00407153407068854]
	TIME [epoch: 8.18 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026752445003963505		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.0026752445003963505 | validation: 0.00435405938552955]
	TIME [epoch: 8.19 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028234052122715902		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.0028234052122715902 | validation: 0.003967645400587258]
	TIME [epoch: 8.21 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028072774354328247		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0028072774354328247 | validation: 0.003452421394425996]
	TIME [epoch: 8.2 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026371766040347248		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.0026371766040347248 | validation: 0.0035199513416739672]
	TIME [epoch: 8.17 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028000932350156077		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.0028000932350156077 | validation: 0.004528657560191241]
	TIME [epoch: 8.18 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026693302057953943		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.0026693302057953943 | validation: 0.0037964300371953383]
	TIME [epoch: 8.17 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002657247778669312		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.002657247778669312 | validation: 0.004372289266899341]
	TIME [epoch: 8.21 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002722922897843562		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.002722922897843562 | validation: 0.0041614486212339565]
	TIME [epoch: 8.2 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024632301414668624		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0024632301414668624 | validation: 0.0041366158927990514]
	TIME [epoch: 8.19 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003022099843772973		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.003022099843772973 | validation: 0.003978872953523595]
	TIME [epoch: 8.17 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029474528196541897		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.0029474528196541897 | validation: 0.0036946217884398324]
	TIME [epoch: 8.19 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00263063742234063		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.00263063742234063 | validation: 0.003902878335574924]
	TIME [epoch: 8.19 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028131452555308087		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.0028131452555308087 | validation: 0.004049418741360636]
	TIME [epoch: 8.21 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026607925884515465		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.0026607925884515465 | validation: 0.0034488862694287727]
	TIME [epoch: 8.17 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027942006184405754		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.0027942006184405754 | validation: 0.0033058631565260595]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240522_185135/states/model_phi1_1a_v_mmd1_1849.pth
	Model improved!!!
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026260239917320085		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.0026260239917320085 | validation: 0.004227634071022156]
	TIME [epoch: 8.19 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002903631244432079		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.002903631244432079 | validation: 0.0038294723418059373]
	TIME [epoch: 8.19 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027663092231630763		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0027663092231630763 | validation: 0.00410066419400208]
	TIME [epoch: 8.23 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028390497887982227		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.0028390497887982227 | validation: 0.003907120874179802]
	TIME [epoch: 8.17 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002944505660638836		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.002944505660638836 | validation: 0.0037376197484198944]
	TIME [epoch: 8.17 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027702734395735947		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.0027702734395735947 | validation: 0.003921493369113006]
	TIME [epoch: 8.18 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028316522909096996		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.0028316522909096996 | validation: 0.004044066203284773]
	TIME [epoch: 8.19 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002875279501292474		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.002875279501292474 | validation: 0.0048035752699661215]
	TIME [epoch: 8.24 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002649927357836083		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.002649927357836083 | validation: 0.003956947142512045]
	TIME [epoch: 8.18 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027342185721191906		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.0027342185721191906 | validation: 0.0039709778113304365]
	TIME [epoch: 8.19 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026548692510097766		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.0026548692510097766 | validation: 0.0038606465133476046]
	TIME [epoch: 8.18 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027734239806498735		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.0027734239806498735 | validation: 0.004006524694933355]
	TIME [epoch: 8.18 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002794958480004673		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.002794958480004673 | validation: 0.004151068173706607]
	TIME [epoch: 8.22 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030392965537526864		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.0030392965537526864 | validation: 0.004479238603116505]
	TIME [epoch: 8.2 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002869951042152165		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.002869951042152165 | validation: 0.0035338221677085023]
	TIME [epoch: 8.18 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026451773245041656		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0026451773245041656 | validation: 0.003775049753598123]
	TIME [epoch: 8.19 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028559202980998153		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.0028559202980998153 | validation: 0.003995981392011528]
	TIME [epoch: 8.18 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002648530855162655		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.002648530855162655 | validation: 0.003720422467329016]
	TIME [epoch: 8.2 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002776244113007722		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.002776244113007722 | validation: 0.004108706952233617]
	TIME [epoch: 8.2 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028833724148478496		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.0028833724148478496 | validation: 0.004222003690455213]
	TIME [epoch: 8.17 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027324116245210604		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.0027324116245210604 | validation: 0.003478734243154151]
	TIME [epoch: 8.18 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027108384086951603		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.0027108384086951603 | validation: 0.004016484808447992]
	TIME [epoch: 8.19 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002604281045612374		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.002604281045612374 | validation: 0.00371371574283661]
	TIME [epoch: 8.19 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002957170952987205		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.002957170952987205 | validation: 0.004019539627806378]
	TIME [epoch: 8.21 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002947610440160402		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.002947610440160402 | validation: 0.004296729434931737]
	TIME [epoch: 8.17 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002585254655213377		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.002585254655213377 | validation: 0.004309307059116597]
	TIME [epoch: 8.17 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002700858405557653		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.002700858405557653 | validation: 0.00356450914352856]
	TIME [epoch: 8.19 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003000882257251856		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.003000882257251856 | validation: 0.0045841680187078925]
	TIME [epoch: 8.19 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002560690003032469		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.002560690003032469 | validation: 0.003974248562877696]
	TIME [epoch: 8.22 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025839233063488405		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0025839233063488405 | validation: 0.0042104003499632454]
	TIME [epoch: 8.18 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024892031719170042		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.0024892031719170042 | validation: 0.004031586170970408]
	TIME [epoch: 8.17 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002791026123615144		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.002791026123615144 | validation: 0.003700999415587436]
	TIME [epoch: 8.18 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002627647283012205		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.002627647283012205 | validation: 0.004033995020166736]
	TIME [epoch: 8.17 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002523953445980733		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.002523953445980733 | validation: 0.004044226958328402]
	TIME [epoch: 8.22 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003082541271515292		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.003082541271515292 | validation: 0.004261650008565693]
	TIME [epoch: 8.19 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002519268441437506		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.002519268441437506 | validation: 0.0041255912784351504]
	TIME [epoch: 8.17 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029498709115271895		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.0029498709115271895 | validation: 0.0038891847953097633]
	TIME [epoch: 8.19 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026440066507300367		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.0026440066507300367 | validation: 0.004143867581573271]
	TIME [epoch: 8.18 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029350309850676827		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.0029350309850676827 | validation: 0.004226324009816285]
	TIME [epoch: 8.22 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002739592450827998		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.002739592450827998 | validation: 0.003459821921895378]
	TIME [epoch: 8.18 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027513748892749683		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.0027513748892749683 | validation: 0.004148248481650713]
	TIME [epoch: 8.18 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025761594790418216		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.0025761594790418216 | validation: 0.004162209242930853]
	TIME [epoch: 8.17 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028382547860190286		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.0028382547860190286 | validation: 0.003982571102038824]
	TIME [epoch: 8.18 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027871506430530114		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.0027871506430530114 | validation: 0.004055794330478252]
	TIME [epoch: 8.19 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028614657893816908		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.0028614657893816908 | validation: 0.0042640685556742716]
	TIME [epoch: 8.21 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027017233381700975		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.0027017233381700975 | validation: 0.004238935166977962]
	TIME [epoch: 8.18 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028680269286862647		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.0028680269286862647 | validation: 0.003805812203714111]
	TIME [epoch: 8.18 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002502582426681826		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.002502582426681826 | validation: 0.0043485570816543615]
	TIME [epoch: 8.18 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028112432151178404		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.0028112432151178404 | validation: 0.0042127086730635996]
	TIME [epoch: 8.19 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002627253756795808		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.002627253756795808 | validation: 0.00348539277963279]
	TIME [epoch: 8.23 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003058130256393658		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.003058130256393658 | validation: 0.004543634410455878]
	TIME [epoch: 8.18 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026450360894944066		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.0026450360894944066 | validation: 0.0044020754194776975]
	TIME [epoch: 8.17 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002601892106634671		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.002601892106634671 | validation: 0.004072503275516661]
	TIME [epoch: 8.16 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027553611360045024		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0027553611360045024 | validation: 0.0043692840223785645]
	TIME [epoch: 8.2 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027502898357990996		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.0027502898357990996 | validation: 0.004428486166778702]
	TIME [epoch: 8.23 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028917509453700425		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.0028917509453700425 | validation: 0.0036341198658493327]
	TIME [epoch: 8.18 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027625216889985513		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.0027625216889985513 | validation: 0.004089086548610049]
	TIME [epoch: 8.2 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027885183119929304		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.0027885183119929304 | validation: 0.004082511863850506]
	TIME [epoch: 8.18 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002836194288215282		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.002836194288215282 | validation: 0.0038872953262204233]
	TIME [epoch: 8.18 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026824616059249427		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.0026824616059249427 | validation: 0.0037027011593770373]
	TIME [epoch: 8.21 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027636347357553838		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.0027636347357553838 | validation: 0.0036189534608661008]
	TIME [epoch: 8.18 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002735991982032101		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.002735991982032101 | validation: 0.0038008798287869306]
	TIME [epoch: 8.17 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028890160786895556		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.0028890160786895556 | validation: 0.0035507685016328127]
	TIME [epoch: 8.18 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002580103848480397		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.002580103848480397 | validation: 0.003307912510323194]
	TIME [epoch: 8.18 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002913572375622251		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.002913572375622251 | validation: 0.0040555200096913]
	TIME [epoch: 8.22 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027176113917888245		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.0027176113917888245 | validation: 0.004210925484092343]
	TIME [epoch: 8.19 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026354991665362083		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.0026354991665362083 | validation: 0.0038971461488667104]
	TIME [epoch: 8.18 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002570465257730281		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.002570465257730281 | validation: 0.004351641776162018]
	TIME [epoch: 8.17 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002813283877415179		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.002813283877415179 | validation: 0.0036655763035797584]
	TIME [epoch: 8.18 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002739331520277035		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.002739331520277035 | validation: 0.004118198362323648]
	TIME [epoch: 8.19 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028041776756920237		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.0028041776756920237 | validation: 0.004160357871360755]
	TIME [epoch: 8.2 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002628724599451916		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.002628724599451916 | validation: 0.003338172762366611]
	TIME [epoch: 8.18 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027081282641016904		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0027081282641016904 | validation: 0.0037496404943228533]
	TIME [epoch: 8.17 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002822376147475738		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.002822376147475738 | validation: 0.0037203864359513323]
	TIME [epoch: 8.18 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027386419020449504		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.0027386419020449504 | validation: 0.003928940666279153]
	TIME [epoch: 8.18 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002733161602029911		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.002733161602029911 | validation: 0.004219573454960948]
	TIME [epoch: 8.22 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028390594378278414		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.0028390594378278414 | validation: 0.004123790794840137]
	TIME [epoch: 8.18 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002773572865598699		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.002773572865598699 | validation: 0.0037526860208507403]
	TIME [epoch: 8.17 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027401560871922427		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.0027401560871922427 | validation: 0.004191305829325514]
	TIME [epoch: 8.18 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028694215705426453		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.0028694215705426453 | validation: 0.003952301204140283]
	TIME [epoch: 8.18 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002602668051367228		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.002602668051367228 | validation: 0.004368464687242365]
	TIME [epoch: 8.22 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025899227291911768		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.0025899227291911768 | validation: 0.0037569736678489973]
	TIME [epoch: 8.18 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002673682982681028		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.002673682982681028 | validation: 0.004400810547388535]
	TIME [epoch: 8.17 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026793799659446285		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.0026793799659446285 | validation: 0.0036734948202144626]
	TIME [epoch: 8.17 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002716056823285032		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.002716056823285032 | validation: 0.003503608471838864]
	TIME [epoch: 8.17 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002577438945358143		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.002577438945358143 | validation: 0.003668911310752824]
	TIME [epoch: 8.23 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002735858189704913		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.002735858189704913 | validation: 0.003892736735514591]
	TIME [epoch: 8.18 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027368872453247288		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.0027368872453247288 | validation: 0.0043940388948502185]
	TIME [epoch: 8.19 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002622750641659798		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.002622750641659798 | validation: 0.0038839089731705252]
	TIME [epoch: 8.17 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002804726429714675		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.002804726429714675 | validation: 0.004341725388794867]
	TIME [epoch: 8.18 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024878262872268272		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.0024878262872268272 | validation: 0.004338336172809973]
	TIME [epoch: 8.22 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028207226673371273		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.0028207226673371273 | validation: 0.0038536647861966244]
	TIME [epoch: 8.18 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002516375414213622		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.002516375414213622 | validation: 0.0034892226394280072]
	TIME [epoch: 8.17 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028316276037041346		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.0028316276037041346 | validation: 0.004537302139912724]
	TIME [epoch: 8.18 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002787315543769557		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.002787315543769557 | validation: 0.0038725357815087257]
	TIME [epoch: 8.17 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027666495519321392		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.0027666495519321392 | validation: 0.003932651842541203]
	TIME [epoch: 8.21 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027791415535481263		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.0027791415535481263 | validation: 0.003949256200646635]
	TIME [epoch: 8.21 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028036593764600207		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.0028036593764600207 | validation: 0.004041741451497673]
	TIME [epoch: 8.16 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002815303343335125		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.002815303343335125 | validation: 0.0038839833199342086]
	TIME [epoch: 8.18 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026339636039910326		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.0026339636039910326 | validation: 0.0042614870546741086]
	TIME [epoch: 8.18 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027959387883228224		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0027959387883228224 | validation: 0.004225531031287108]
	TIME [epoch: 8.2 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002723154289839969		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.002723154289839969 | validation: 0.004497428868541533]
	TIME [epoch: 8.21 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027161267936095484		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.0027161267936095484 | validation: 0.003963952794370883]
	TIME [epoch: 8.19 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027192454878284694		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.0027192454878284694 | validation: 0.003654036346161677]
	TIME [epoch: 8.17 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028258660393788815		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.0028258660393788815 | validation: 0.0037392911458078064]
	TIME [epoch: 8.18 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027690970971888523		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.0027690970971888523 | validation: 0.004081485685095073]
	TIME [epoch: 8.18 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027807698387683		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.0027807698387683 | validation: 0.0039105455829210305]
	TIME [epoch: 8.22 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027080029985529362		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.0027080029985529362 | validation: 0.004042102849455028]
	TIME [epoch: 8.19 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028377018273981		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.0028377018273981 | validation: 0.0039015712908879634]
	TIME [epoch: 8.18 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025600273699702735		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.0025600273699702735 | validation: 0.004526289532754883]
	TIME [epoch: 8.18 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002893127273700874		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.002893127273700874 | validation: 0.0036720764221015905]
	TIME [epoch: 8.19 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002695219960980902		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.002695219960980902 | validation: 0.0038215294351286256]
	TIME [epoch: 8.22 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002649258136068358		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.002649258136068358 | validation: 0.003922860485368858]
	TIME [epoch: 8.19 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002764344972283535		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.002764344972283535 | validation: 0.004151813528433114]
	TIME [epoch: 8.19 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027546419186750843		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.0027546419186750843 | validation: 0.004094602680347812]
	TIME [epoch: 8.18 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002664646888856308		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.002664646888856308 | validation: 0.004003544977353624]
	TIME [epoch: 8.19 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028611687018119548		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.0028611687018119548 | validation: 0.0035450906387334297]
	TIME [epoch: 8.21 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026375048890073666		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.0026375048890073666 | validation: 0.004117287123031856]
	TIME [epoch: 8.21 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002769243970202169		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.002769243970202169 | validation: 0.0036476952317371887]
	TIME [epoch: 8.19 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027247448689647156		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.0027247448689647156 | validation: 0.0038402451828296377]
	TIME [epoch: 8.18 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027900430355616867		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0027900430355616867 | validation: 0.004515811072164412]
	TIME [epoch: 8.18 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027908829221085117		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.0027908829221085117 | validation: 0.004146893770562546]
	TIME [epoch: 8.19 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026743476685156245		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.0026743476685156245 | validation: 0.0038946804472264674]
	TIME [epoch: 8.22 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027766867399238943		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.0027766867399238943 | validation: 0.004454913106274962]
	TIME [epoch: 8.17 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002657990129632962		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.002657990129632962 | validation: 0.003608879831963578]
	TIME [epoch: 8.18 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026070319658221424		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.0026070319658221424 | validation: 0.004117370354292316]
	TIME [epoch: 8.18 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027463484932225626		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.0027463484932225626 | validation: 0.003590868557271817]
	TIME [epoch: 8.19 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002784299342481051		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.002784299342481051 | validation: 0.003925712163711505]
	TIME [epoch: 8.22 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024666776283247243		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.0024666776283247243 | validation: 0.003327288155979098]
	TIME [epoch: 8.18 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028306840465297323		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.0028306840465297323 | validation: 0.004108200609329281]
	TIME [epoch: 8.19 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028402993252694543		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.0028402993252694543 | validation: 0.003978064718810073]
	TIME [epoch: 8.18 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029416063051007704		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.0029416063051007704 | validation: 0.003971029869290318]
	TIME [epoch: 8.19 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002969061595647202		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.002969061595647202 | validation: 0.003619840051780119]
	TIME [epoch: 8.21 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002607519062123224		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.002607519062123224 | validation: 0.004273435226730545]
	TIME [epoch: 8.2 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026686705756180287		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.0026686705756180287 | validation: 0.003932976225573322]
	TIME [epoch: 8.18 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027882901152580524		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.0027882901152580524 | validation: 0.003330810581971433]
	TIME [epoch: 8.18 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025271483564915003		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.0025271483564915003 | validation: 0.004391040393044891]
	TIME [epoch: 8.18 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002639308706540716		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.002639308706540716 | validation: 0.004176895006666651]
	TIME [epoch: 8.2 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002378001343545567		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.002378001343545567 | validation: 0.004331480209274841]
	TIME [epoch: 8.19 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002761010913542813		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.002761010913542813 | validation: 0.0043390388387746165]
	TIME [epoch: 8.18 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027552408910766417		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.0027552408910766417 | validation: 0.003634012678438637]
	TIME [epoch: 8.18 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002710949128482163		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.002710949128482163 | validation: 0.004517238089379287]
	TIME [epoch: 8.18 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002794153678453353		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.002794153678453353 | validation: 0.0038431309493268083]
	TIME [epoch: 8.2 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002816607741633428		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.002816607741633428 | validation: 0.0044542516384693896]
	TIME [epoch: 8.19 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026062518265307835		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.0026062518265307835 | validation: 0.0038318816023093106]
	TIME [epoch: 8.18 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028243803064353238		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.0028243803064353238 | validation: 0.003577629665461851]
	TIME [epoch: 8.18 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027375833442480277		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.0027375833442480277 | validation: 0.003809020634011877]
	TIME [epoch: 8.18 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029003905043568446		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.0029003905043568446 | validation: 0.004166504833296712]
	TIME [epoch: 8.18 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00299797828039938		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.00299797828039938 | validation: 0.0041928858516883105]
	TIME [epoch: 8.21 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002667850164652522		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.002667850164652522 | validation: 0.0042053237324205395]
	TIME [epoch: 8.18 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002575916214256792		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.002575916214256792 | validation: 0.003964431408271459]
	TIME [epoch: 8.18 sec]
Finished training in 16633.443 seconds.
