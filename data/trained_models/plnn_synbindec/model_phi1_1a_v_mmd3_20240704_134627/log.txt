Args:
Namespace(name='model_phi1_1a_v_mmd3', outdir='out/model_training/model_phi1_1a_v_mmd3', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3311318439

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.562668064271486		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 5.562668064271486 | validation: 6.018428796807871]
	TIME [epoch: 102 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.08624342744365		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 5.08624342744365 | validation: 5.350284137557674]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.617731438526615		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 4.617731438526615 | validation: 4.729168092548598]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0337392089204265		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 4.0337392089204265 | validation: 4.708283125431324]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8248546379161525		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 3.8248546379161525 | validation: 4.0538874744663165]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5032103612058645		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 3.5032103612058645 | validation: 3.8411708138921776]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4391259846973106		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 3.4391259846973106 | validation: 3.5560303850771042]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9044639328994135		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 2.9044639328994135 | validation: 3.4154154861168258]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6107796388192708		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 2.6107796388192708 | validation: 3.6379434785369242]
	TIME [epoch: 8.08 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473591463482871		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 2.473591463482871 | validation: 3.0146106104255708]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326564148530093		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 2.326564148530093 | validation: 2.754758485585172]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.882035404724014		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 1.882035404724014 | validation: 3.607464843959179]
	TIME [epoch: 8.09 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3348998094953455		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 2.3348998094953455 | validation: 3.0388519186566887]
	TIME [epoch: 8.12 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8768512591237896		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 1.8768512591237896 | validation: 2.2993611946002592]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5844577554665062		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 1.5844577554665062 | validation: 2.453985559725541]
	TIME [epoch: 8.09 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5619967063376519		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 1.5619967063376519 | validation: 2.0780453036037927]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482948819939902		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 1.482948819939902 | validation: 2.3007323967841806]
	TIME [epoch: 8.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5720477659197822		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 1.5720477659197822 | validation: 2.0487217780960334]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3370909606780772		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 1.3370909606780772 | validation: 2.0252125777502092]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.529174877750137		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 1.529174877750137 | validation: 2.046151593185778]
	TIME [epoch: 8.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4021114372419372		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 1.4021114372419372 | validation: 1.9921561896988658]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3919164580121755		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 1.3919164580121755 | validation: 2.1258720126885167]
	TIME [epoch: 8.09 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3515008071879577		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 1.3515008071879577 | validation: 2.035970503421828]
	TIME [epoch: 8.09 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4017365673220266		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 1.4017365673220266 | validation: 2.0962022583141318]
	TIME [epoch: 8.14 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5447490113854088		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 1.5447490113854088 | validation: 2.0518747862731193]
	TIME [epoch: 8.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4522757503440153		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 1.4522757503440153 | validation: 1.9657529268757408]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3431387004086999		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 1.3431387004086999 | validation: 1.9198166758231823]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3890268735856282		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 1.3890268735856282 | validation: 1.8578710994142253]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3311789043148812		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 1.3311789043148812 | validation: 1.9129543296934752]
	TIME [epoch: 8.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2466242826973155		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 1.2466242826973155 | validation: 2.273532548601498]
	TIME [epoch: 8.12 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.377136396832216		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 1.377136396832216 | validation: 1.8901895621928855]
	TIME [epoch: 8.08 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3693589110852824		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 1.3693589110852824 | validation: 2.0404012643299767]
	TIME [epoch: 8.09 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2884109023536228		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 1.2884109023536228 | validation: 1.9990469594018767]
	TIME [epoch: 8.08 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4113261353860806		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 1.4113261353860806 | validation: 2.122598873177134]
	TIME [epoch: 8.08 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3661303113597543		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 1.3661303113597543 | validation: 2.010387064139208]
	TIME [epoch: 8.13 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2402209670005444		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 1.2402209670005444 | validation: 2.059397015148493]
	TIME [epoch: 8.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303423818096746		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 1.303423818096746 | validation: 1.9134515899962783]
	TIME [epoch: 8.09 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2167314354584193		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 1.2167314354584193 | validation: 1.8925243952357125]
	TIME [epoch: 8.09 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4643928172199503		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 1.4643928172199503 | validation: 1.9508290881921941]
	TIME [epoch: 8.08 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4990165907080804		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 1.4990165907080804 | validation: 1.8650366929088924]
	TIME [epoch: 8.08 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2642310321672374		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 1.2642310321672374 | validation: 2.3644767564506877]
	TIME [epoch: 8.13 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.692215234823606		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 1.692215234823606 | validation: 1.7668897080548742]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3369509138955642		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 1.3369509138955642 | validation: 1.9214977114041303]
	TIME [epoch: 8.09 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4866689147704417		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 1.4866689147704417 | validation: 1.7526549410772598]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.390873532691224		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 1.390873532691224 | validation: 1.7158328285679714]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3170116049453975		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 1.3170116049453975 | validation: 1.6872471596459255]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1641810945941367		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 1.1641810945941367 | validation: 4.870083843156044]
	TIME [epoch: 8.14 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6039584629133246		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 2.6039584629133246 | validation: 1.7959494074699258]
	TIME [epoch: 8.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.333158839763557		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 1.333158839763557 | validation: 1.221702517031858]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0553991729080927		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 1.0553991729080927 | validation: 1.40994405428745]
	TIME [epoch: 8.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9610465482508279		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.9610465482508279 | validation: 0.9065916569113737]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469438944419614		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.6469438944419614 | validation: 0.7466262825029395]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8773024632110542		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 0.8773024632110542 | validation: 0.6340087737281157]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325091670060988		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 0.6325091670060988 | validation: 0.8067404025639535]
	TIME [epoch: 8.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859822662352563		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 0.6859822662352563 | validation: 0.6802372951655665]
	TIME [epoch: 8.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460666287927299		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 0.5460666287927299 | validation: 0.5400286069388012]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4640055321781412		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 0.4640055321781412 | validation: 0.6203637905781697]
	TIME [epoch: 8.12 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5868855157174224		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 0.5868855157174224 | validation: 0.8172614155609412]
	TIME [epoch: 8.11 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082620216520614		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 0.6082620216520614 | validation: 0.4998222619300835]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734532802568767		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 0.4734532802568767 | validation: 0.6477976616622798]
	TIME [epoch: 8.11 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6184851849408417		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 0.6184851849408417 | validation: 0.6171918166625363]
	TIME [epoch: 8.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4557315357241127		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 0.4557315357241127 | validation: 0.4203450866321118]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38079059400318394		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 0.38079059400318394 | validation: 0.3973114217985727]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505223295958572		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 0.505223295958572 | validation: 0.4779617903548134]
	TIME [epoch: 8.11 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6237325083991432		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 0.6237325083991432 | validation: 0.5491999636651652]
	TIME [epoch: 8.09 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236357530454774		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 0.5236357530454774 | validation: 0.4234456003312859]
	TIME [epoch: 8.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505723067562916		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 0.3505723067562916 | validation: 0.39697784227891886]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47457808971283294		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 0.47457808971283294 | validation: 0.5573931957227503]
	TIME [epoch: 8.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.431690800637126		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 0.431690800637126 | validation: 0.4131494041190563]
	TIME [epoch: 8.14 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677637945194026		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 0.3677637945194026 | validation: 0.5671736375890307]
	TIME [epoch: 8.09 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4149306933544569		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 0.4149306933544569 | validation: 0.31785801524760443]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4742440694199652		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 0.4742440694199652 | validation: 0.4667898156687743]
	TIME [epoch: 8.09 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48700870127071283		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 0.48700870127071283 | validation: 0.3759406154088215]
	TIME [epoch: 8.08 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696803034895057		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 0.3696803034895057 | validation: 0.6782986123754752]
	TIME [epoch: 8.12 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41807218463134554		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 0.41807218463134554 | validation: 0.28200894978775837]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880391697713247		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 0.2880391697713247 | validation: 0.4970417978032094]
	TIME [epoch: 8.08 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643302517065296		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 0.3643302517065296 | validation: 0.36382818030801245]
	TIME [epoch: 8.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4385084201453704		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 0.4385084201453704 | validation: 0.34634564904501974]
	TIME [epoch: 8.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37969843770870304		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 0.37969843770870304 | validation: 0.31156354908815703]
	TIME [epoch: 8.09 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33152812996313535		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 0.33152812996313535 | validation: 0.2655260725694358]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36093459290384505		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 0.36093459290384505 | validation: 0.39272009309050154]
	TIME [epoch: 8.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37298394276212593		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 0.37298394276212593 | validation: 0.43320955512450665]
	TIME [epoch: 8.09 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243197530788216		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 0.3243197530788216 | validation: 0.45088373606756116]
	TIME [epoch: 8.09 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259440764486047		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 0.3259440764486047 | validation: 0.32094788532733765]
	TIME [epoch: 8.08 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364451282920821		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 0.3364451282920821 | validation: 0.34687095755791086]
	TIME [epoch: 8.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33551427961659686		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 0.33551427961659686 | validation: 0.32368621430805367]
	TIME [epoch: 8.13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881817412109672		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 0.2881817412109672 | validation: 0.28134997482525226]
	TIME [epoch: 8.08 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42051850483100706		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 0.42051850483100706 | validation: 0.45582685891074304]
	TIME [epoch: 8.09 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807518005021294		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 0.3807518005021294 | validation: 0.35947295140845503]
	TIME [epoch: 8.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082153216998925		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 0.3082153216998925 | validation: 0.2414521932657673]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26416270267356323		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 0.26416270267356323 | validation: 0.4562728487040061]
	TIME [epoch: 8.14 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4104811931787544		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 0.4104811931787544 | validation: 0.45901935402043414]
	TIME [epoch: 8.11 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449004521077162		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 0.3449004521077162 | validation: 0.45136382659128693]
	TIME [epoch: 8.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34680638595190066		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 0.34680638595190066 | validation: 0.24046076299249503]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318872970314259		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 0.318872970314259 | validation: 0.24592143010566797]
	TIME [epoch: 8.09 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2865032093476213		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 0.2865032093476213 | validation: 0.23243812657553556]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930294314031193		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 0.2930294314031193 | validation: 0.22793350517540098]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942947883760488		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 0.3942947883760488 | validation: 0.28685908060969356]
	TIME [epoch: 8.09 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644894183721368		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 0.3644894183721368 | validation: 0.22930188499209958]
	TIME [epoch: 8.08 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038605998622477		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 0.3038605998622477 | validation: 0.28976927263925245]
	TIME [epoch: 8.21 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30854563823642295		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 0.30854563823642295 | validation: 0.2518481259968153]
	TIME [epoch: 8.09 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428532860398959		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 0.2428532860398959 | validation: 0.3575203792278967]
	TIME [epoch: 8.11 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32768444212035996		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 0.32768444212035996 | validation: 0.5656280287534836]
	TIME [epoch: 8.12 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39816573826216173		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 0.39816573826216173 | validation: 0.2928543241618485]
	TIME [epoch: 8.09 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27270541462468234		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 0.27270541462468234 | validation: 0.22451738276426417]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081559224935868		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 0.3081559224935868 | validation: 0.4403125338092905]
	TIME [epoch: 8.13 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33239542073725814		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 0.33239542073725814 | validation: 0.25313793477412627]
	TIME [epoch: 8.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28760631365111616		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 0.28760631365111616 | validation: 0.23573686223865287]
	TIME [epoch: 8.12 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153588730699396		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 0.3153588730699396 | validation: 0.2552359174446126]
	TIME [epoch: 8.08 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31082467694717714		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 0.31082467694717714 | validation: 0.25856724026201083]
	TIME [epoch: 8.07 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520908902231152		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 0.2520908902231152 | validation: 0.278603716043813]
	TIME [epoch: 8.08 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24388627424084583		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 0.24388627424084583 | validation: 0.3206284081137034]
	TIME [epoch: 8.08 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40201275877642817		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 0.40201275877642817 | validation: 0.35547477772576785]
	TIME [epoch: 8.09 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32357692298456575		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 0.32357692298456575 | validation: 0.26570147620574713]
	TIME [epoch: 8.13 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667960730509004		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 0.2667960730509004 | validation: 0.27734750296834115]
	TIME [epoch: 8.09 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27875765866585234		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 0.27875765866585234 | validation: 0.18171206032718173]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627207304747534		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 0.2627207304747534 | validation: 0.20061948263074197]
	TIME [epoch: 8.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743796992786116		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 0.3743796992786116 | validation: 0.2970609478170619]
	TIME [epoch: 8.09 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604020441218185		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 0.2604020441218185 | validation: 0.20096501487645946]
	TIME [epoch: 8.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31754651992638394		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 0.31754651992638394 | validation: 0.24218158888407015]
	TIME [epoch: 8.12 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427567653985432		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 0.2427567653985432 | validation: 0.191085589743699]
	TIME [epoch: 8.08 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19700913746770096		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 0.19700913746770096 | validation: 0.18288929934026205]
	TIME [epoch: 8.08 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351716385708999		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 0.3351716385708999 | validation: 0.31226445543407866]
	TIME [epoch: 8.08 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537002911832227		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 0.2537002911832227 | validation: 0.28454682744638776]
	TIME [epoch: 8.08 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28284561097296973		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 0.28284561097296973 | validation: 0.23684434410362604]
	TIME [epoch: 8.11 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22292381303002995		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 0.22292381303002995 | validation: 0.17940120680142074]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768377307535137		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 0.2768377307535137 | validation: 0.27954557720476614]
	TIME [epoch: 8.09 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718950858791189		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 0.2718950858791189 | validation: 0.3339363738120701]
	TIME [epoch: 8.08 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.233898738116358		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 0.233898738116358 | validation: 0.1999216111114634]
	TIME [epoch: 8.08 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26289428129642556		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 0.26289428129642556 | validation: 0.192873648699729]
	TIME [epoch: 8.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22121653115922335		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 0.22121653115922335 | validation: 0.2903733978549012]
	TIME [epoch: 8.15 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26637427216837306		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 0.26637427216837306 | validation: 0.26732934098350775]
	TIME [epoch: 8.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30041480447238106		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 0.30041480447238106 | validation: 0.18341983100127646]
	TIME [epoch: 8.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20389099185612336		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 0.20389099185612336 | validation: 0.1844256274688877]
	TIME [epoch: 8.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19633858990633413		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 0.19633858990633413 | validation: 0.28115648979931623]
	TIME [epoch: 8.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752992483252343		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 0.2752992483252343 | validation: 0.42027371955595627]
	TIME [epoch: 8.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133177033683354		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.3133177033683354 | validation: 0.174801804674035]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17118851308165442		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.17118851308165442 | validation: 0.2582068122530083]
	TIME [epoch: 8.11 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23752205939038265		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.23752205939038265 | validation: 0.2383757488496645]
	TIME [epoch: 8.09 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963882859066197		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.2963882859066197 | validation: 0.16469404434339718]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677974541964657		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.16677974541964657 | validation: 0.12175906652656489]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194238106313443		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.194238106313443 | validation: 0.1420692645064561]
	TIME [epoch: 8.14 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24592136489093624		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.24592136489093624 | validation: 0.19051423620222402]
	TIME [epoch: 8.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663925366903134		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.2663925366903134 | validation: 0.13876202666377635]
	TIME [epoch: 8.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19527359596685262		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.19527359596685262 | validation: 0.17622228534504703]
	TIME [epoch: 8.09 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530479522515693		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 0.2530479522515693 | validation: 0.13357475051433954]
	TIME [epoch: 8.09 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16485916067320588		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.16485916067320588 | validation: 0.30753274756598836]
	TIME [epoch: 8.09 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19537855994126288		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.19537855994126288 | validation: 0.18104189825452638]
	TIME [epoch: 8.12 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854883120543357		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.5854883120543357 | validation: 0.9335681204946724]
	TIME [epoch: 8.08 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5097045844667559		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.5097045844667559 | validation: 0.14819765223001016]
	TIME [epoch: 8.08 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683482258072722		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.1683482258072722 | validation: 0.1180745053292846]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673979606685641		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.14673979606685641 | validation: 0.10901082113164531]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632754071634769		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.1632754071634769 | validation: 0.12334999131868034]
	TIME [epoch: 8.11 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15724609565723896		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.15724609565723896 | validation: 0.1660479966604531]
	TIME [epoch: 8.12 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17881195472733377		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.17881195472733377 | validation: 0.128277162762772]
	TIME [epoch: 8.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199109674136797		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.199109674136797 | validation: 0.09952792559996479]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1533404865417507		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.1533404865417507 | validation: 0.20161595008222133]
	TIME [epoch: 8.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14720086096671225		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.14720086096671225 | validation: 0.09180400047308167]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19866560437205785		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.19866560437205785 | validation: 0.14548002342327893]
	TIME [epoch: 8.14 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24571447041849173		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.24571447041849173 | validation: 0.14956710774298024]
	TIME [epoch: 8.09 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16610265046871292		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.16610265046871292 | validation: 0.19975799881092243]
	TIME [epoch: 8.08 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30371441132032817		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.30371441132032817 | validation: 0.2604842180415677]
	TIME [epoch: 8.08 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930163646332259		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.2930163646332259 | validation: 0.39626945349243725]
	TIME [epoch: 8.08 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30832467591629664		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.30832467591629664 | validation: 0.29933931057734253]
	TIME [epoch: 8.09 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38442200647258595		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.38442200647258595 | validation: 0.11900505350276484]
	TIME [epoch: 8.13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15525613019682893		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.15525613019682893 | validation: 0.19872438915066212]
	TIME [epoch: 8.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801429483645896		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.1801429483645896 | validation: 0.08357972826168322]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11864050855684735		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.11864050855684735 | validation: 0.10258049997109495]
	TIME [epoch: 8.11 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540392254193144		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.1540392254193144 | validation: 0.19254871282858568]
	TIME [epoch: 8.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17663204473816266		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 0.17663204473816266 | validation: 0.2693414718751541]
	TIME [epoch: 8.13 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15915854168974464		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.15915854168974464 | validation: 0.1167773338854946]
	TIME [epoch: 8.12 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14698443265263444		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.14698443265263444 | validation: 0.11379589728133659]
	TIME [epoch: 8.09 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801469103550644		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.1801469103550644 | validation: 0.1447507171227801]
	TIME [epoch: 8.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19532849818504938		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.19532849818504938 | validation: 0.12541485668939947]
	TIME [epoch: 8.1 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844326907679905		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.13844326907679905 | validation: 0.2048425609264895]
	TIME [epoch: 8.09 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682488028755197		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.1682488028755197 | validation: 0.0721065948408121]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514649365147011		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 0.1514649365147011 | validation: 0.10729987493288606]
	TIME [epoch: 8.11 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16589187546006368		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 0.16589187546006368 | validation: 0.0700053109075559]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700279376780351		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 0.1700279376780351 | validation: 0.21645972418195458]
	TIME [epoch: 8.09 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605463795763263		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 0.1605463795763263 | validation: 0.07753150563759224]
	TIME [epoch: 8.08 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09845909357008023		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 0.09845909357008023 | validation: 0.2397091445519885]
	TIME [epoch: 8.09 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159348778692677		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 0.15159348778692677 | validation: 0.6136031687282506]
	TIME [epoch: 8.13 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805036572903646		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 0.3805036572903646 | validation: 0.17169371477457496]
	TIME [epoch: 8.09 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20126495996158628		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 0.20126495996158628 | validation: 0.2012895248561778]
	TIME [epoch: 8.09 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695682774826433		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.1695682774826433 | validation: 0.076933007847025]
	TIME [epoch: 8.09 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151900604177575		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.1151900604177575 | validation: 0.10616874400176399]
	TIME [epoch: 8.09 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13057371524141104		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.13057371524141104 | validation: 0.08445966679652478]
	TIME [epoch: 8.12 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16986462639235642		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.16986462639235642 | validation: 0.14836617253849854]
	TIME [epoch: 8.12 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22946953144893684		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.22946953144893684 | validation: 0.12290120661036077]
	TIME [epoch: 8.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13581626714975398		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.13581626714975398 | validation: 0.07603171630365385]
	TIME [epoch: 8.09 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11185589113281846		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.11185589113281846 | validation: 0.09801670050183561]
	TIME [epoch: 8.09 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14120430221918592		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.14120430221918592 | validation: 0.12389787665234714]
	TIME [epoch: 8.09 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286331555901451		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.1286331555901451 | validation: 0.18540923419803795]
	TIME [epoch: 8.14 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260806853097385		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.1260806853097385 | validation: 0.21537715237404206]
	TIME [epoch: 8.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17183413976076517		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.17183413976076517 | validation: 0.07716238716475643]
	TIME [epoch: 8.08 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16144385036597142		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.16144385036597142 | validation: 0.08177105676312896]
	TIME [epoch: 8.08 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16058174507397804		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.16058174507397804 | validation: 0.15449025102253597]
	TIME [epoch: 8.09 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482492542349365		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.11482492542349365 | validation: 0.06862035594013988]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16822039025935437		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.16822039025935437 | validation: 0.14928691292606822]
	TIME [epoch: 8.13 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24235256053674262		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.24235256053674262 | validation: 0.24168506318432986]
	TIME [epoch: 8.08 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15608911792970573		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.15608911792970573 | validation: 0.5095983573978207]
	TIME [epoch: 110 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973083002170357		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.2973083002170357 | validation: 0.19730425451857822]
	TIME [epoch: 16.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16376214772583725		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.16376214772583725 | validation: 0.062002865209598926]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422397351038179		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.10422397351038179 | validation: 0.18818688203583334]
	TIME [epoch: 16 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14468243534683042		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.14468243534683042 | validation: 0.0799070937395641]
	TIME [epoch: 16.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942201750106194		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.1942201750106194 | validation: 0.22804301731017823]
	TIME [epoch: 16 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211387632160972		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.211387632160972 | validation: 0.11091816777005098]
	TIME [epoch: 16 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535641343075273		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.08535641343075273 | validation: 0.0614036902992011]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332941983475973		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.1332941983475973 | validation: 0.14799997025851613]
	TIME [epoch: 16 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250691942177031		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.1250691942177031 | validation: 0.0921190187386116]
	TIME [epoch: 16 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13321276563340567		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.13321276563340567 | validation: 0.08911037205002571]
	TIME [epoch: 16 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420769488719757		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.12420769488719757 | validation: 0.1259861608887284]
	TIME [epoch: 16 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365227675745447		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.13365227675745447 | validation: 0.10726125795142571]
	TIME [epoch: 16 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12030468321572726		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.12030468321572726 | validation: 0.14348686022840906]
	TIME [epoch: 16 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13053488110605252		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.13053488110605252 | validation: 0.055040329074537944]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222814643821658		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.10222814643821658 | validation: 0.09422904265600852]
	TIME [epoch: 16 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773738924469864		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.19773738924469864 | validation: 0.20499271912585065]
	TIME [epoch: 16 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17551068312524704		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.17551068312524704 | validation: 0.19494293913384786]
	TIME [epoch: 16 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239107088503477		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.3239107088503477 | validation: 0.37849870023509796]
	TIME [epoch: 16 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22743452429095512		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.22743452429095512 | validation: 0.09020222500469097]
	TIME [epoch: 16 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09609472322342813		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.09609472322342813 | validation: 0.12169192471046925]
	TIME [epoch: 16 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086683611864157		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.1086683611864157 | validation: 0.044703437680297095]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27019722014394487		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.27019722014394487 | validation: 0.42140731922127195]
	TIME [epoch: 16 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168665750707569		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 1.168665750707569 | validation: 0.4116603687000713]
	TIME [epoch: 16 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147872152642533		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.3147872152642533 | validation: 0.11376230875533969]
	TIME [epoch: 16 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15815760701852255		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.15815760701852255 | validation: 0.14536827810495073]
	TIME [epoch: 16 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229162274108405		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.10229162274108405 | validation: 0.08488466706861514]
	TIME [epoch: 16 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400774187306329		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.10400774187306329 | validation: 0.101569598065119]
	TIME [epoch: 16 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694810910908765		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.09694810910908765 | validation: 0.049462294418788966]
	TIME [epoch: 16 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12483268052990495		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.12483268052990495 | validation: 0.07129419734171694]
	TIME [epoch: 16 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052447935130708		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.08052447935130708 | validation: 0.2565713699577116]
	TIME [epoch: 16 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18016921757627383		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.18016921757627383 | validation: 0.11858245584794763]
	TIME [epoch: 16 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078737014993399		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.1078737014993399 | validation: 0.08523061281970024]
	TIME [epoch: 16 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966336587771744		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.10966336587771744 | validation: 0.06447058193394843]
	TIME [epoch: 16 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1894126445769348		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.1894126445769348 | validation: 0.10774563628378547]
	TIME [epoch: 16 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14244428990160576		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.14244428990160576 | validation: 0.09614957680058633]
	TIME [epoch: 16 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282293852030283		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.08282293852030283 | validation: 0.24222591811717248]
	TIME [epoch: 16 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635335398147005		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.1635335398147005 | validation: 0.100283562641383]
	TIME [epoch: 16 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277223356183633		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.1277223356183633 | validation: 0.18990823118414416]
	TIME [epoch: 16 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689223796294824		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.09689223796294824 | validation: 0.05428133838430631]
	TIME [epoch: 16 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10099565060859345		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.10099565060859345 | validation: 0.1396674901260221]
	TIME [epoch: 16 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13579713648278652		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.13579713648278652 | validation: 0.11494479835503739]
	TIME [epoch: 16 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048403481556803		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.1048403481556803 | validation: 0.09444802246129398]
	TIME [epoch: 16 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11994002267049039		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.11994002267049039 | validation: 0.2643561590228382]
	TIME [epoch: 16 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13014144892240895		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.13014144892240895 | validation: 0.0900252707592926]
	TIME [epoch: 16 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15544755452934597		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.15544755452934597 | validation: 0.2051041779538152]
	TIME [epoch: 16 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189722191320238		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.5189722191320238 | validation: 0.39553104182582843]
	TIME [epoch: 16 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28239810681886807		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.28239810681886807 | validation: 0.10888552195975695]
	TIME [epoch: 16 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13078249975521306		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.13078249975521306 | validation: 0.13689829725153044]
	TIME [epoch: 16 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967823197073237		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.0967823197073237 | validation: 0.054129083175887556]
	TIME [epoch: 16 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12004819587761548		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.12004819587761548 | validation: 0.06868230505785361]
	TIME [epoch: 16 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068583789415368		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.11068583789415368 | validation: 0.15796424572775278]
	TIME [epoch: 16 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14157572026327006		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.14157572026327006 | validation: 0.15676622691744724]
	TIME [epoch: 16 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15060474576893151		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.15060474576893151 | validation: 0.11229338758927612]
	TIME [epoch: 16 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15627873840762094		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.15627873840762094 | validation: 0.08901663162884811]
	TIME [epoch: 16.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695995180895639		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.10695995180895639 | validation: 0.07597592908905695]
	TIME [epoch: 16 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469329301228445		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.2469329301228445 | validation: 0.3833659418725024]
	TIME [epoch: 16 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543582254020639		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 0.2543582254020639 | validation: 0.21044798141875898]
	TIME [epoch: 16 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327190502312883		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.13327190502312883 | validation: 0.1352520800819742]
	TIME [epoch: 16 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780246442416501		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.10780246442416501 | validation: 0.10477271500689234]
	TIME [epoch: 16 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17847767699052544		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.17847767699052544 | validation: 0.2157278204029101]
	TIME [epoch: 16 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17257631782551708		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 0.17257631782551708 | validation: 0.1485345220794943]
	TIME [epoch: 16 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11774614511736947		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.11774614511736947 | validation: 0.2586309587553945]
	TIME [epoch: 16 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14915732059509093		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.14915732059509093 | validation: 0.11323623529996543]
	TIME [epoch: 16 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167049585830381		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.167049585830381 | validation: 0.11445352671319044]
	TIME [epoch: 16 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21887369284127733		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.21887369284127733 | validation: 0.20646658520267958]
	TIME [epoch: 16 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16721753475771048		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.16721753475771048 | validation: 0.2585593982512344]
	TIME [epoch: 16.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616338109923092		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.1616338109923092 | validation: 0.17621908580672893]
	TIME [epoch: 16 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25150572923481207		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 0.25150572923481207 | validation: 0.2682087450849657]
	TIME [epoch: 16.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982405736020467		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.3982405736020467 | validation: 0.40835121015031906]
	TIME [epoch: 16.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574816523536569		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.2574816523536569 | validation: 0.20936639833800286]
	TIME [epoch: 16 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12901224586863053		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 0.12901224586863053 | validation: 0.09279997851094188]
	TIME [epoch: 16 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469580306991078		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.10469580306991078 | validation: 0.08593613066206143]
	TIME [epoch: 16.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08833252705121115		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.08833252705121115 | validation: 0.08554504882957581]
	TIME [epoch: 16 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393553947292576		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.10393553947292576 | validation: 0.08190118837144977]
	TIME [epoch: 16 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243435858566217		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.1243435858566217 | validation: 0.06747455336284575]
	TIME [epoch: 16.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121215127527521		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.11121215127527521 | validation: 0.2459790812469962]
	TIME [epoch: 16 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076670527872003		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.13076670527872003 | validation: 0.1192209329759238]
	TIME [epoch: 16 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274899062894337		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.12274899062894337 | validation: 0.12026219908351868]
	TIME [epoch: 16 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169302082070849		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.12169302082070849 | validation: 0.09087151858904868]
	TIME [epoch: 16 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700230701095238		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.10700230701095238 | validation: 0.09893525914897755]
	TIME [epoch: 16 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12774172980274656		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.12774172980274656 | validation: 0.11107515233078055]
	TIME [epoch: 16.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24543882078348941		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.24543882078348941 | validation: 0.44916430019981923]
	TIME [epoch: 16 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3241964916747577		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.3241964916747577 | validation: 0.30585765930121184]
	TIME [epoch: 16 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536435377299617		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.2536435377299617 | validation: 0.24679136164371202]
	TIME [epoch: 16.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199682919377502		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.199682919377502 | validation: 0.2176253778273036]
	TIME [epoch: 16 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18467616537726023		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.18467616537726023 | validation: 0.19832750373446928]
	TIME [epoch: 16 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14388275837336809		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.14388275837336809 | validation: 0.15164965746425885]
	TIME [epoch: 16.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11587090671735137		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.11587090671735137 | validation: 0.15252165510584412]
	TIME [epoch: 16 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9236794964598817		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.9236794964598817 | validation: 0.3432655473674259]
	TIME [epoch: 16.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29684671895456505		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.29684671895456505 | validation: 0.12519193793719202]
	TIME [epoch: 16.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112897507417918		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.14112897507417918 | validation: 0.08476792214502424]
	TIME [epoch: 16 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293709660204426		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.12293709660204426 | validation: 0.08852329508971879]
	TIME [epoch: 16 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09432459502563678		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.09432459502563678 | validation: 0.10077444757882337]
	TIME [epoch: 16.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10558885531868714		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.10558885531868714 | validation: 0.0539882123567785]
	TIME [epoch: 16 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550307654721936		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.11550307654721936 | validation: 0.10036451611925991]
	TIME [epoch: 16 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074393387698383		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.12074393387698383 | validation: 0.07600399799789712]
	TIME [epoch: 16.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031117952040223		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.1031117952040223 | validation: 0.07842019852445276]
	TIME [epoch: 16 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09869429079928635		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.09869429079928635 | validation: 0.11223238461359628]
	TIME [epoch: 16 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12717753349916913		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.12717753349916913 | validation: 0.1198361027646108]
	TIME [epoch: 16.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115643633346913		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.10115643633346913 | validation: 0.06731374383728154]
	TIME [epoch: 16 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108452058940805		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.1108452058940805 | validation: 0.06808319969896358]
	TIME [epoch: 16 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11733085765485164		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.11733085765485164 | validation: 0.0972742936485067]
	TIME [epoch: 16.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094794719913974		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.1094794719913974 | validation: 0.08880886830639513]
	TIME [epoch: 16 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191691767207221		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.10191691767207221 | validation: 0.04434073479057643]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08996644432702233		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.08996644432702233 | validation: 0.21757170842075851]
	TIME [epoch: 16.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14722670953270664		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.14722670953270664 | validation: 0.13916664306529364]
	TIME [epoch: 16 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433714110606297		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.1433714110606297 | validation: 0.08646203827672921]
	TIME [epoch: 16 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605493559449615		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.10605493559449615 | validation: 0.09393329156978812]
	TIME [epoch: 16.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11086290113252645		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.11086290113252645 | validation: 0.07421454431319105]
	TIME [epoch: 16 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229144898639712		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.08229144898639712 | validation: 0.09004224622454678]
	TIME [epoch: 16 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08578918783347264		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.08578918783347264 | validation: 0.15172774153404778]
	TIME [epoch: 16 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772922389631666		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.09772922389631666 | validation: 0.15362897800596373]
	TIME [epoch: 16 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280861688358619		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.09280861688358619 | validation: 0.12469539841905306]
	TIME [epoch: 16 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13414117786155444		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.13414117786155444 | validation: 0.17477275977169154]
	TIME [epoch: 16.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10551464843901315		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.10551464843901315 | validation: 0.03810814356510256]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335230194677944		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.10335230194677944 | validation: 0.1259302689297958]
	TIME [epoch: 16 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1174825771887803		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.1174825771887803 | validation: 0.054162873132787365]
	TIME [epoch: 16.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345513585640213		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.10345513585640213 | validation: 0.08154468490734006]
	TIME [epoch: 16 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570845618378949		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.07570845618378949 | validation: 0.041122698323545925]
	TIME [epoch: 16 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0798385302381251		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.0798385302381251 | validation: 0.06603335837974174]
	TIME [epoch: 16 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063951227636375		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.07063951227636375 | validation: 0.11338986193311393]
	TIME [epoch: 16 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120567353154471		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.120567353154471 | validation: 0.14354726848087704]
	TIME [epoch: 16 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152642320450156		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.152642320450156 | validation: 0.10969347154868654]
	TIME [epoch: 16.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23645309106578366		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.23645309106578366 | validation: 0.14955871717527308]
	TIME [epoch: 16 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295830838671057		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.11295830838671057 | validation: 0.0580480255030123]
	TIME [epoch: 16 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385114186400829		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.07385114186400829 | validation: 0.09998778765292266]
	TIME [epoch: 16.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023874274570507		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.07023874274570507 | validation: 0.07161156268282423]
	TIME [epoch: 16 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936269997537961		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.06936269997537961 | validation: 0.07870930405020667]
	TIME [epoch: 16 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09290134657029911		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.09290134657029911 | validation: 0.09177791923479388]
	TIME [epoch: 16.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09113200428175154		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.09113200428175154 | validation: 0.12488311269305136]
	TIME [epoch: 16 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845740150202299		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.16845740150202299 | validation: 0.16966001781724643]
	TIME [epoch: 16 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09797992686392375		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.09797992686392375 | validation: 0.07257225468564574]
	TIME [epoch: 16.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09521334986963709		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.09521334986963709 | validation: 0.04607414610284548]
	TIME [epoch: 16 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653066367919749		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.0653066367919749 | validation: 0.1137134359759408]
	TIME [epoch: 16 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766377062810997		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.0766377062810997 | validation: 0.10526832650274932]
	TIME [epoch: 16 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362554272723212		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.10362554272723212 | validation: 0.052162543400045586]
	TIME [epoch: 16 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14091434616093654		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.14091434616093654 | validation: 0.07842918016608688]
	TIME [epoch: 16 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586659081219035		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.10586659081219035 | validation: 0.12084306411617629]
	TIME [epoch: 16 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09123085182790218		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.09123085182790218 | validation: 0.0901476246777587]
	TIME [epoch: 16 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361100992117282		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.07361100992117282 | validation: 0.0983811501785117]
	TIME [epoch: 16 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09225606296778463		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.09225606296778463 | validation: 0.13539299250282455]
	TIME [epoch: 16 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973683838388663		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.0973683838388663 | validation: 0.08858205441476114]
	TIME [epoch: 16 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892169597290152		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.0892169597290152 | validation: 0.08152403432844732]
	TIME [epoch: 16 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08718056703953411		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.08718056703953411 | validation: 0.1762470309056794]
	TIME [epoch: 16 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13573269735029045		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.13573269735029045 | validation: 0.5410259044798374]
	TIME [epoch: 16 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23228412379601918		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.23228412379601918 | validation: 0.1965163654979199]
	TIME [epoch: 16 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481128144546251		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.09481128144546251 | validation: 0.08889188667209807]
	TIME [epoch: 16 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023065523830145		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.08023065523830145 | validation: 0.06431178236896348]
	TIME [epoch: 16 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621242899599322		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.06621242899599322 | validation: 0.05905271580626893]
	TIME [epoch: 16 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485352682997375		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.07485352682997375 | validation: 0.06444918969883921]
	TIME [epoch: 16 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10018261168719157		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.10018261168719157 | validation: 0.08136996911510155]
	TIME [epoch: 16 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07332059050050754		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.07332059050050754 | validation: 0.10812131404193738]
	TIME [epoch: 16 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542744294621065		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.09542744294621065 | validation: 0.07912642819437346]
	TIME [epoch: 16 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834917155833926		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.10834917155833926 | validation: 0.10887822483769413]
	TIME [epoch: 16 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061605903308024484		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.061605903308024484 | validation: 0.179890649521242]
	TIME [epoch: 16 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963203535626436		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.1963203535626436 | validation: 0.21827448577776382]
	TIME [epoch: 16 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687720533418578		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.10687720533418578 | validation: 0.09805687100300298]
	TIME [epoch: 16 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231386214759466		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.08231386214759466 | validation: 0.09042659757545686]
	TIME [epoch: 16 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06986058928848515		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.06986058928848515 | validation: 0.07141729263417834]
	TIME [epoch: 16 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2609910052415184		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.2609910052415184 | validation: 0.21174485088804043]
	TIME [epoch: 16 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12142704455215522		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.12142704455215522 | validation: 0.09332702897908454]
	TIME [epoch: 16 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818794050803496		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.07818794050803496 | validation: 0.06349458102951497]
	TIME [epoch: 16 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188610172743157		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.06188610172743157 | validation: 0.06931132107449617]
	TIME [epoch: 16 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1032558018114074		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.1032558018114074 | validation: 0.1800362769519192]
	TIME [epoch: 16 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023353591050023		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.1023353591050023 | validation: 0.1983859586616164]
	TIME [epoch: 16 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983632342017684		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.09983632342017684 | validation: 0.054145272241115955]
	TIME [epoch: 16 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807003507703517		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.07807003507703517 | validation: 0.08507819697467991]
	TIME [epoch: 16 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783664631420494		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.0783664631420494 | validation: 0.05317359521994912]
	TIME [epoch: 16 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119616064652031		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.09119616064652031 | validation: 0.07729683422312311]
	TIME [epoch: 16 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481329862930396		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.09481329862930396 | validation: 0.1339247685008535]
	TIME [epoch: 16 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12335386383716511		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.12335386383716511 | validation: 0.13549827103620454]
	TIME [epoch: 16.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753852470513364		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.13753852470513364 | validation: 0.13494568429031503]
	TIME [epoch: 16 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21842823954806057		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.21842823954806057 | validation: 0.2594958642298626]
	TIME [epoch: 16 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2565928322915204		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.2565928322915204 | validation: 0.0776066732983211]
	TIME [epoch: 18.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241224209535847		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.10241224209535847 | validation: 0.08723349621475326]
	TIME [epoch: 16 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925460556969879		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.06925460556969879 | validation: 0.08067660088928674]
	TIME [epoch: 16 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792719541098793		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.07792719541098793 | validation: 0.07398384435076304]
	TIME [epoch: 16 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965985027304186		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.07965985027304186 | validation: 0.055886036688261975]
	TIME [epoch: 16 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801268426801996		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.05801268426801996 | validation: 0.06715332152711767]
	TIME [epoch: 16 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147131260818236		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.07147131260818236 | validation: 0.06525297030072205]
	TIME [epoch: 16.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766412649257725		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.0766412649257725 | validation: 0.24768319116085005]
	TIME [epoch: 16 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14118469084136917		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.14118469084136917 | validation: 0.08560044933785046]
	TIME [epoch: 16 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08595112657262753		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.08595112657262753 | validation: 0.059372158990154814]
	TIME [epoch: 16 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811158957486374		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.07811158957486374 | validation: 0.05567667550091343]
	TIME [epoch: 16 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11921620580991232		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.11921620580991232 | validation: 0.0569878456435445]
	TIME [epoch: 16 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09784254064039007		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.09784254064039007 | validation: 0.11582508156772006]
	TIME [epoch: 16 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291607713957229		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.06291607713957229 | validation: 0.08936000285704018]
	TIME [epoch: 16 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983492887956011		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.08983492887956011 | validation: 0.08843176621510362]
	TIME [epoch: 16 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09572736863656262		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.09572736863656262 | validation: 0.21290066066999275]
	TIME [epoch: 16 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510088890696453		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.2510088890696453 | validation: 0.5031406167976342]
	TIME [epoch: 16 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029942075175022		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.5029942075175022 | validation: 1.7233857144718736]
	TIME [epoch: 16 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7007450091345775		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 2.7007450091345775 | validation: 2.6176652355598273]
	TIME [epoch: 16 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3671925853016575		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 2.3671925853016575 | validation: 3.32779884077208]
	TIME [epoch: 16 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.36108496696502		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 2.36108496696502 | validation: 2.5163500526293916]
	TIME [epoch: 16 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126331147735409		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 3.126331147735409 | validation: 2.9835041821780064]
	TIME [epoch: 16 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8878687722588587		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 2.8878687722588587 | validation: 2.842124375160598]
	TIME [epoch: 16.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5921093769206247		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 2.5921093769206247 | validation: 2.465157302460245]
	TIME [epoch: 16 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7965070848102442		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 1.7965070848102442 | validation: 1.4361279165207133]
	TIME [epoch: 16 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9964981360981675		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.9964981360981675 | validation: 1.297738752136357]
	TIME [epoch: 16 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444651338995146		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.7444651338995146 | validation: 0.8793102763618225]
	TIME [epoch: 16 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520373273436535		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 0.5520373273436535 | validation: 0.521359409494714]
	TIME [epoch: 16 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475739107001456		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.3475739107001456 | validation: 0.25804676431157697]
	TIME [epoch: 16 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20449804096307456		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.20449804096307456 | validation: 0.32780377216577017]
	TIME [epoch: 16 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061835106871288		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.3061835106871288 | validation: 0.19360094960021418]
	TIME [epoch: 16.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17309110478348377		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.17309110478348377 | validation: 0.2529075886590897]
	TIME [epoch: 16 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32880987094072833		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.32880987094072833 | validation: 0.26247872649760995]
	TIME [epoch: 16 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31982269880233205		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.31982269880233205 | validation: 0.5873895109060792]
	TIME [epoch: 16 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654951028655289		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.3654951028655289 | validation: 0.1701780819449234]
	TIME [epoch: 16 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960341745649016		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.2960341745649016 | validation: 0.1317487116513546]
	TIME [epoch: 16 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17667356417128885		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.17667356417128885 | validation: 0.20486461220319097]
	TIME [epoch: 16.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40274280665669		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.40274280665669 | validation: 0.8331535171799005]
	TIME [epoch: 16 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442954187286645		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.5442954187286645 | validation: 0.3221811703713653]
	TIME [epoch: 16 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342556633324531		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.2342556633324531 | validation: 1.468911784372477]
	TIME [epoch: 16 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820919598298321		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.8820919598298321 | validation: 0.2559347289145265]
	TIME [epoch: 16 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243751257454747		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.2243751257454747 | validation: 0.2710830027011247]
	TIME [epoch: 16 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18045558400585365		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.18045558400585365 | validation: 0.2472026672227005]
	TIME [epoch: 16 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19986063344044935		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.19986063344044935 | validation: 0.11316385727804616]
	TIME [epoch: 16 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12188010967491128		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.12188010967491128 | validation: 0.13765626897393224]
	TIME [epoch: 16 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14705439577138785		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.14705439577138785 | validation: 0.09957941271326902]
	TIME [epoch: 16 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061211339083752		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.10061211339083752 | validation: 0.13923063295053023]
	TIME [epoch: 16 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15040621308356356		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.15040621308356356 | validation: 0.3516810293839846]
	TIME [epoch: 16 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20664864818665368		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.20664864818665368 | validation: 0.27584121825648533]
	TIME [epoch: 16 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308447559257344		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.1308447559257344 | validation: 0.10953632357770159]
	TIME [epoch: 16 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170876593086261		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.13170876593086261 | validation: 0.09917405182901891]
	TIME [epoch: 16 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14919036113500936		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.14919036113500936 | validation: 0.17243097890131792]
	TIME [epoch: 16.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975667195925951		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.09975667195925951 | validation: 0.07615046755904671]
	TIME [epoch: 16 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09592430854134687		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.09592430854134687 | validation: 0.06048854212455483]
	TIME [epoch: 16 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360579958222497		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.08360579958222497 | validation: 0.12928266992335008]
	TIME [epoch: 16 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15408897462865997		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.15408897462865997 | validation: 0.09167156106758642]
	TIME [epoch: 16 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950615764910116		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.07950615764910116 | validation: 0.0514743075215083]
	TIME [epoch: 16 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05892163321138425		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.05892163321138425 | validation: 0.047521260841494446]
	TIME [epoch: 16 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14556957904348092		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.14556957904348092 | validation: 0.07448016673601701]
	TIME [epoch: 16 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13031642911764674		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.13031642911764674 | validation: 0.21729431178314068]
	TIME [epoch: 16 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18631764231233197		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.18631764231233197 | validation: 0.11484682813280422]
	TIME [epoch: 16 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274317663091796		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.1274317663091796 | validation: 0.19596435994583591]
	TIME [epoch: 16 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750646620535721		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.10750646620535721 | validation: 0.03256162068225115]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773255388426129		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.04773255388426129 | validation: 0.18067214377713453]
	TIME [epoch: 16 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09494662448086214		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.09494662448086214 | validation: 0.08708493672224457]
	TIME [epoch: 16 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10545419234009873		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.10545419234009873 | validation: 0.08457953960153516]
	TIME [epoch: 16 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711280198433055		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.0711280198433055 | validation: 0.15779070225254338]
	TIME [epoch: 16 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564343790825313		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.14564343790825313 | validation: 0.10209276258818922]
	TIME [epoch: 16 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08337308189976163		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.08337308189976163 | validation: 0.05753841993515105]
	TIME [epoch: 16 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922397210767895		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.07922397210767895 | validation: 0.08637469879203807]
	TIME [epoch: 16 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08591567260749214		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.08591567260749214 | validation: 0.14841176334146794]
	TIME [epoch: 16 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17381259147975467		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.17381259147975467 | validation: 0.7483452040121558]
	TIME [epoch: 16 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857106022333129		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.2857106022333129 | validation: 0.12083465628867085]
	TIME [epoch: 16 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233326908606702		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.10233326908606702 | validation: 0.05057255025053958]
	TIME [epoch: 16 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007917767252396		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.09007917767252396 | validation: 0.10734004026492072]
	TIME [epoch: 16 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0981192303376882		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.0981192303376882 | validation: 0.04943092829157215]
	TIME [epoch: 16 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921776901002426		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.05921776901002426 | validation: 0.08889723551645431]
	TIME [epoch: 16 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068625848764065		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.07068625848764065 | validation: 0.06493162820254558]
	TIME [epoch: 16 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105002704390524		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.14105002704390524 | validation: 0.37836983905380633]
	TIME [epoch: 16 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2702391234878322		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.2702391234878322 | validation: 0.3484843484555342]
	TIME [epoch: 16 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22617202251010185		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.22617202251010185 | validation: 0.11352810269485368]
	TIME [epoch: 16 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11577715289526577		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.11577715289526577 | validation: 0.1970655997036874]
	TIME [epoch: 16 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12188641070959988		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.12188641070959988 | validation: 0.20685975021312947]
	TIME [epoch: 16 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117911664379887		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.11117911664379887 | validation: 0.13476023245277]
	TIME [epoch: 16 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999614138752321		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.11999614138752321 | validation: 0.06748597531327441]
	TIME [epoch: 16 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276180411840389		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.1276180411840389 | validation: 0.14671476483640294]
	TIME [epoch: 16 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18070868284379987		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.18070868284379987 | validation: 0.04996239806454149]
	TIME [epoch: 16 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067043818334548		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.09067043818334548 | validation: 0.07353436655804084]
	TIME [epoch: 16 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0706880080338457		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.0706880080338457 | validation: 0.13571777035994273]
	TIME [epoch: 16 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07301029191751815		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.07301029191751815 | validation: 0.06969388321163889]
	TIME [epoch: 16 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641367492947967		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.07641367492947967 | validation: 0.03842375262083367]
	TIME [epoch: 16 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367396072293047		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.06367396072293047 | validation: 0.03834793351286271]
	TIME [epoch: 16 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989984223937597		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.11989984223937597 | validation: 0.0684605199386063]
	TIME [epoch: 16 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772595662494264		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.0772595662494264 | validation: 0.29377915685397415]
	TIME [epoch: 16 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137847195766852		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.4137847195766852 | validation: 0.27171976033105716]
	TIME [epoch: 16 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17442709581858573		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.17442709581858573 | validation: 0.10108199669568278]
	TIME [epoch: 16 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045250373325863		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.1045250373325863 | validation: 0.06838910653386292]
	TIME [epoch: 16 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05333415053463493		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.05333415053463493 | validation: 0.06891469540892994]
	TIME [epoch: 16 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06670897649179314		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.06670897649179314 | validation: 0.05414744167206135]
	TIME [epoch: 16 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058055012783162746		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.058055012783162746 | validation: 0.04817890383514557]
	TIME [epoch: 16 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07362294134441077		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.07362294134441077 | validation: 0.0774671842953017]
	TIME [epoch: 16 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796490162989507		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.06796490162989507 | validation: 0.05261998390744117]
	TIME [epoch: 16 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711371657496396		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.06711371657496396 | validation: 0.08459930367020901]
	TIME [epoch: 16 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07961992919226474		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.07961992919226474 | validation: 0.11068127257585562]
	TIME [epoch: 16 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10763741130339072		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.10763741130339072 | validation: 0.060278502793230326]
	TIME [epoch: 16 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266275952416425		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.06266275952416425 | validation: 0.25887509108038076]
	TIME [epoch: 16 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795025828313449		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.1795025828313449 | validation: 0.06991385205395911]
	TIME [epoch: 16 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10448055818471076		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.10448055818471076 | validation: 0.12597610426343647]
	TIME [epoch: 16.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786051126766963		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.0786051126766963 | validation: 0.041845180260865006]
	TIME [epoch: 16 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08870010041565461		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.08870010041565461 | validation: 0.05212304594277411]
	TIME [epoch: 16 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060201616960072174		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.060201616960072174 | validation: 0.06818171150846136]
	TIME [epoch: 16.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764604129950803		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.0764604129950803 | validation: 0.049607576478750484]
	TIME [epoch: 16 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059408463080363044		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.059408463080363044 | validation: 0.06403514447493616]
	TIME [epoch: 16 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633713178314593		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.0633713178314593 | validation: 0.14430723505556659]
	TIME [epoch: 16.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09261478480549241		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.09261478480549241 | validation: 0.05693246276856832]
	TIME [epoch: 16 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08445585651889552		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.08445585651889552 | validation: 0.09457052029560578]
	TIME [epoch: 16 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08779129292416071		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.08779129292416071 | validation: 0.03867940178073544]
	TIME [epoch: 16.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890799149268375		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.0890799149268375 | validation: 0.2730914872745198]
	TIME [epoch: 16 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18733593617928732		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.18733593617928732 | validation: 0.22345708189515445]
	TIME [epoch: 16 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12076972647342642		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.12076972647342642 | validation: 0.08312825887411482]
	TIME [epoch: 16 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820918584942468		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.13820918584942468 | validation: 0.10145680132933069]
	TIME [epoch: 16 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728151774839777		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.09728151774839777 | validation: 0.05300150651731951]
	TIME [epoch: 16 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05984020206219232		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.05984020206219232 | validation: 0.06857835041647671]
	TIME [epoch: 16 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407408742120178		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.06407408742120178 | validation: 0.07054277922258273]
	TIME [epoch: 16 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706958564158998		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.06706958564158998 | validation: 0.04674143053916446]
	TIME [epoch: 16 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752838355247942		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.07752838355247942 | validation: 0.05679366423037882]
	TIME [epoch: 16 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331340296361124		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.06331340296361124 | validation: 0.05125201529876723]
	TIME [epoch: 128 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793489117271624		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.06793489117271624 | validation: 0.19629137327145585]
	TIME [epoch: 34.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800565266480725		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.09800565266480725 | validation: 0.037429349487983196]
	TIME [epoch: 34.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079916409680348		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.10079916409680348 | validation: 0.16547238086672306]
	TIME [epoch: 34.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09674423986619693		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.09674423986619693 | validation: 0.12554086906243458]
	TIME [epoch: 34.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292771164209507		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.1292771164209507 | validation: 0.08031431828569688]
	TIME [epoch: 34.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443374697111993		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.07443374697111993 | validation: 0.03962336669171615]
	TIME [epoch: 34.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05588313533651845		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.05588313533651845 | validation: 0.07832629624421561]
	TIME [epoch: 34.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462336132848495		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.06462336132848495 | validation: 0.05329611013943003]
	TIME [epoch: 34.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0658896895779338		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.0658896895779338 | validation: 0.05737714826633637]
	TIME [epoch: 34.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08133869744842812		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.08133869744842812 | validation: 0.04092753195861264]
	TIME [epoch: 34.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07576062316286125		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.07576062316286125 | validation: 0.07758471920106567]
	TIME [epoch: 34.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06231067083908792		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.06231067083908792 | validation: 0.04652663721029651]
	TIME [epoch: 34.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06775210072135215		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.06775210072135215 | validation: 0.028333247159364187]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06532430439599801		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.06532430439599801 | validation: 0.09273901125913497]
	TIME [epoch: 34.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059934991608600705		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.059934991608600705 | validation: 0.0912749624104694]
	TIME [epoch: 34.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297441246331793		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.09297441246331793 | validation: 0.09015453154075292]
	TIME [epoch: 34.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831948866865734		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.06831948866865734 | validation: 0.055526905724389966]
	TIME [epoch: 34.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300565455953129		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.07300565455953129 | validation: 0.05560501248249663]
	TIME [epoch: 34.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368823842428035		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.05368823842428035 | validation: 0.06387684720879372]
	TIME [epoch: 34.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059174669820763845		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.059174669820763845 | validation: 0.053067580682601576]
	TIME [epoch: 34.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06226265080389599		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.06226265080389599 | validation: 0.11364476628397802]
	TIME [epoch: 34.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09294795165794516		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.09294795165794516 | validation: 0.04161370499550051]
	TIME [epoch: 34.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484093573784892		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.0484093573784892 | validation: 0.05500318673892306]
	TIME [epoch: 34.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725983748493586		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.0725983748493586 | validation: 0.02932170076491068]
	TIME [epoch: 34.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094961577814137		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.06094961577814137 | validation: 0.0831857428975973]
	TIME [epoch: 34.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386638804038339		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.08386638804038339 | validation: 0.3376284607399562]
	TIME [epoch: 34.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17353389866953614		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.17353389866953614 | validation: 0.07911317737219353]
	TIME [epoch: 34.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594755045640138		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.06594755045640138 | validation: 0.056376748671925776]
	TIME [epoch: 34.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07279532379286716		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.07279532379286716 | validation: 0.06077453102089344]
	TIME [epoch: 34.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310508994164253		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.07310508994164253 | validation: 0.06955874804530893]
	TIME [epoch: 34.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042339187261224		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.08042339187261224 | validation: 0.059053018440717926]
	TIME [epoch: 34.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08721628294981618		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.08721628294981618 | validation: 0.35759343410704714]
	TIME [epoch: 34.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083877209674928		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.2083877209674928 | validation: 0.14608168224433682]
	TIME [epoch: 34.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516346188858811		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.06516346188858811 | validation: 0.06991134466904236]
	TIME [epoch: 34.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07457468756413588		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.07457468756413588 | validation: 0.043669685965825815]
	TIME [epoch: 34.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05134603827488733		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.05134603827488733 | validation: 0.06951896209840594]
	TIME [epoch: 34.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684282634934814		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.04684282634934814 | validation: 0.06729217528503173]
	TIME [epoch: 34.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493896567594524		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.05493896567594524 | validation: 0.07230177852777966]
	TIME [epoch: 34.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420737711198524		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.06420737711198524 | validation: 0.0326321323879917]
	TIME [epoch: 34.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06728841337986549		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.06728841337986549 | validation: 0.15141086648169444]
	TIME [epoch: 34.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08434478569421607		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.08434478569421607 | validation: 0.08581252722779711]
	TIME [epoch: 34.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458682656908354		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.06458682656908354 | validation: 0.19733516760950018]
	TIME [epoch: 34.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13865820922356137		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.13865820922356137 | validation: 0.08318124058603527]
	TIME [epoch: 34.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05761728647818552		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.05761728647818552 | validation: 0.06125820983408744]
	TIME [epoch: 34.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052496955009486805		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.052496955009486805 | validation: 0.05066525640009581]
	TIME [epoch: 34.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553131539163295		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.0553131539163295 | validation: 0.0534553111744365]
	TIME [epoch: 34.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05054866356932665		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.05054866356932665 | validation: 0.17090777793613812]
	TIME [epoch: 34.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214800725583585		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.11214800725583585 | validation: 0.09906866772675296]
	TIME [epoch: 34.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342603558891		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.09342603558891 | validation: 0.0656867372607964]
	TIME [epoch: 34.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743355206367727		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.0743355206367727 | validation: 0.06314286691861631]
	TIME [epoch: 34.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399061096727756		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.07399061096727756 | validation: 0.07225359013782087]
	TIME [epoch: 34.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937294784523279		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.04937294784523279 | validation: 0.0318259647725049]
	TIME [epoch: 34.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047637311542025225		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.047637311542025225 | validation: 0.04300922240203582]
	TIME [epoch: 34.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496102503046697		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.06496102503046697 | validation: 0.10829458865783803]
	TIME [epoch: 34.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738095717951068		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.0738095717951068 | validation: 0.04647484682887659]
	TIME [epoch: 34.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04740203003351839		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.04740203003351839 | validation: 0.04357662789155168]
	TIME [epoch: 34.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572365610612346		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.0572365610612346 | validation: 0.0603085615522692]
	TIME [epoch: 34.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056626854413254143		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.056626854413254143 | validation: 0.1964524636604066]
	TIME [epoch: 34.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839320252240248		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.0839320252240248 | validation: 0.02932039054652856]
	TIME [epoch: 34.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027264374437973		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.11027264374437973 | validation: 0.17980390414418268]
	TIME [epoch: 34.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009729222037426		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.1009729222037426 | validation: 0.12011927577223741]
	TIME [epoch: 34.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2270853970588675		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.2270853970588675 | validation: 0.17530886854137556]
	TIME [epoch: 34.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086031015175935		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.09086031015175935 | validation: 0.046454604382895344]
	TIME [epoch: 34.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04575222045067354		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.04575222045067354 | validation: 0.052130708307463816]
	TIME [epoch: 34.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517333873895501		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.05517333873895501 | validation: 0.036204470422282774]
	TIME [epoch: 34.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036666648459143386		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.036666648459143386 | validation: 0.04026736560787149]
	TIME [epoch: 34.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053087877393896254		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.053087877393896254 | validation: 0.04819824173057602]
	TIME [epoch: 34.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590890699871179		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.07590890699871179 | validation: 0.042948385171982364]
	TIME [epoch: 34.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04432025242769755		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.04432025242769755 | validation: 0.10995377397506098]
	TIME [epoch: 34.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056489327893594225		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.056489327893594225 | validation: 0.06930166556828296]
	TIME [epoch: 34.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412966228730817		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.05412966228730817 | validation: 0.04584906110257228]
	TIME [epoch: 34.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057753662505198866		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.057753662505198866 | validation: 0.16905734406769843]
	TIME [epoch: 34.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667195734453725		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.06667195734453725 | validation: 0.023125113643259247]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04690648945764296		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.04690648945764296 | validation: 0.06150606906578196]
	TIME [epoch: 34.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461448736584191		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.06461448736584191 | validation: 0.039809270903933915]
	TIME [epoch: 34.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493295855125157		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.04493295855125157 | validation: 0.05894364901964541]
	TIME [epoch: 34.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059835399519418464		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.059835399519418464 | validation: 0.11425462182269562]
	TIME [epoch: 34.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09677978242216027		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.09677978242216027 | validation: 0.059932483163044885]
	TIME [epoch: 34.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068046580181261		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.06068046580181261 | validation: 0.04961837481648809]
	TIME [epoch: 34.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03695163267467652		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.03695163267467652 | validation: 0.05700091738783987]
	TIME [epoch: 34.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06055410469665668		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.06055410469665668 | validation: 0.14628735051697772]
	TIME [epoch: 34.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05963798658325499		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.05963798658325499 | validation: 0.0455877239797913]
	TIME [epoch: 34.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598324151110708		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.08598324151110708 | validation: 0.03856314335753259]
	TIME [epoch: 34.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048674449977418655		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.048674449977418655 | validation: 0.0609820851676999]
	TIME [epoch: 34.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05550951457720049		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.05550951457720049 | validation: 0.03837664791358261]
	TIME [epoch: 34.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05218393763850642		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.05218393763850642 | validation: 0.10903232387303707]
	TIME [epoch: 34.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841646566442384		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.10841646566442384 | validation: 0.05226844325353102]
	TIME [epoch: 34.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25640241118647594		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.25640241118647594 | validation: 0.16049807832831597]
	TIME [epoch: 34.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10755327432905046		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.10755327432905046 | validation: 0.04996594199135358]
	TIME [epoch: 34.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05328334197952107		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.05328334197952107 | validation: 0.051347451630231314]
	TIME [epoch: 34.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052641504070690806		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.052641504070690806 | validation: 0.02527373158400296]
	TIME [epoch: 34.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533254170743769		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.05533254170743769 | validation: 0.06300025660782285]
	TIME [epoch: 34.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058196204636465576		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.058196204636465576 | validation: 0.07273010746935621]
	TIME [epoch: 34.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06988023207785006		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.06988023207785006 | validation: 0.04146441613885538]
	TIME [epoch: 34.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057555066122412284		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.057555066122412284 | validation: 0.053030341674068324]
	TIME [epoch: 34.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521781320706097		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.06521781320706097 | validation: 0.04898574235225979]
	TIME [epoch: 34.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317095615702323		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.06317095615702323 | validation: 0.19670494240462172]
	TIME [epoch: 34.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0929138898022413		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.0929138898022413 | validation: 0.02680456313015123]
	TIME [epoch: 34.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022909792375464276		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.022909792375464276 | validation: 0.07574030680550387]
	TIME [epoch: 34.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07614681229729184		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.07614681229729184 | validation: 0.02666681887613731]
	TIME [epoch: 34.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033119897543023094		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.033119897543023094 | validation: 0.10809354358466175]
	TIME [epoch: 34.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07138763713281263		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.07138763713281263 | validation: 0.04762911621987813]
	TIME [epoch: 34.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05807033902510098		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.05807033902510098 | validation: 0.05567329571991561]
	TIME [epoch: 34.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05333943232941901		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.05333943232941901 | validation: 0.054733549636639865]
	TIME [epoch: 34.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028624992702266		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.04028624992702266 | validation: 0.03938992400986302]
	TIME [epoch: 34.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443151448350406		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.07443151448350406 | validation: 0.04399484832551724]
	TIME [epoch: 34.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176248961550123		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.07176248961550123 | validation: 0.053439103220748706]
	TIME [epoch: 34.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05045139617519327		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.05045139617519327 | validation: 0.06755032746759154]
	TIME [epoch: 34.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007930030032445		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.06007930030032445 | validation: 0.026530051992095047]
	TIME [epoch: 34.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061455526598800436		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.061455526598800436 | validation: 0.12178618549305154]
	TIME [epoch: 34.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19944992933832723		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.19944992933832723 | validation: 0.1852120131581293]
	TIME [epoch: 34.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204006278118752		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.10204006278118752 | validation: 0.08318132882245238]
	TIME [epoch: 34.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054273840305363		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.054273840305363 | validation: 0.07908189066243208]
	TIME [epoch: 34.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068004964455018		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.05068004964455018 | validation: 0.046266688504530286]
	TIME [epoch: 34.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053036032213238576		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.053036032213238576 | validation: 0.025625766963735974]
	TIME [epoch: 34.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038662507632007		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.04038662507632007 | validation: 0.04884123952796848]
	TIME [epoch: 34.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930166863634018		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.04930166863634018 | validation: 0.06374278002138964]
	TIME [epoch: 34.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054110883055099035		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.054110883055099035 | validation: 0.07643441047445453]
	TIME [epoch: 34.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742647108788668		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.0742647108788668 | validation: 0.03363561700524098]
	TIME [epoch: 34.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630731621239029		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.0630731621239029 | validation: 0.10830539985844272]
	TIME [epoch: 34.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05757313788764378		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.05757313788764378 | validation: 0.11639200593411789]
	TIME [epoch: 34.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319336828245978		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.08319336828245978 | validation: 0.0691728355852464]
	TIME [epoch: 34.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538796069445701		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.06538796069445701 | validation: 0.06820902612312459]
	TIME [epoch: 34.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834326546975402		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.05834326546975402 | validation: 0.05530794281908698]
	TIME [epoch: 34.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055395387738172826		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.055395387738172826 | validation: 0.04100739269874046]
	TIME [epoch: 34.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244868376140807		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.05244868376140807 | validation: 0.051771480717820575]
	TIME [epoch: 34.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055711590076783696		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.055711590076783696 | validation: 0.08608216184918177]
	TIME [epoch: 34.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275638620760705		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.1275638620760705 | validation: 0.0919546334460915]
	TIME [epoch: 34.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10415319381681376		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.10415319381681376 | validation: 0.04056307698227049]
	TIME [epoch: 34.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613213888116439		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.0613213888116439 | validation: 0.09216786525498535]
	TIME [epoch: 34.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807267421153897		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.06807267421153897 | validation: 0.1046267391082461]
	TIME [epoch: 34.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717678748579734		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.0717678748579734 | validation: 0.037636270935218236]
	TIME [epoch: 34.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785700534278254		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.03785700534278254 | validation: 0.06711494499288122]
	TIME [epoch: 34.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057773436697669864		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.057773436697669864 | validation: 0.04630321521786754]
	TIME [epoch: 34.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456220621328521		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.0456220621328521 | validation: 0.06650788992377339]
	TIME [epoch: 34.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819138065973677		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.0819138065973677 | validation: 0.03548831715679017]
	TIME [epoch: 34.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056006666810677		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.1056006666810677 | validation: 0.0705255725625123]
	TIME [epoch: 34.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584075503336915		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.04584075503336915 | validation: 0.051076186685499514]
	TIME [epoch: 34.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486465073720723		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.07486465073720723 | validation: 0.04194720395025092]
	TIME [epoch: 34.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025415628156851403		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.025415628156851403 | validation: 0.0776149741921415]
	TIME [epoch: 34.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643303577515029		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.07643303577515029 | validation: 0.05807315774330224]
	TIME [epoch: 34.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054877135812250996		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.054877135812250996 | validation: 0.13052174660744437]
	TIME [epoch: 34.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817492637051254		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.07817492637051254 | validation: 0.038273603447613894]
	TIME [epoch: 34.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045653805066833676		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.045653805066833676 | validation: 0.062166035165744066]
	TIME [epoch: 34.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956183396345949		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.04956183396345949 | validation: 0.035474792010389306]
	TIME [epoch: 34.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968214460949425		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.03968214460949425 | validation: 0.053964879548753626]
	TIME [epoch: 34.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0554713874740357		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.0554713874740357 | validation: 0.03839720230121963]
	TIME [epoch: 34.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563633766736993		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.0563633766736993 | validation: 0.024514739164602783]
	TIME [epoch: 34.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345289667796263		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.04345289667796263 | validation: 0.05517645049335303]
	TIME [epoch: 34.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04554720331297149		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.04554720331297149 | validation: 0.07419040121379006]
	TIME [epoch: 34.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05311635335742182		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.05311635335742182 | validation: 0.06512943055017821]
	TIME [epoch: 34.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081071439283087		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.06081071439283087 | validation: 0.03745612186945411]
	TIME [epoch: 34.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05555570436700774		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.05555570436700774 | validation: 0.1065598479633221]
	TIME [epoch: 34.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339075524940103		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.10339075524940103 | validation: 0.05957773208191343]
	TIME [epoch: 34.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060613417942497395		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.060613417942497395 | validation: 0.12152600665914204]
	TIME [epoch: 34.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897794327595776		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.06897794327595776 | validation: 0.04288961594653591]
	TIME [epoch: 34.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156645785136871		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.04156645785136871 | validation: 0.03606719688481342]
	TIME [epoch: 34.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049311732494309285		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.049311732494309285 | validation: 0.05637182365761878]
	TIME [epoch: 34.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426184161502797		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.0426184161502797 | validation: 0.05591020303939016]
	TIME [epoch: 34.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050774371966008286		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.050774371966008286 | validation: 0.03522565941345698]
	TIME [epoch: 34.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06422402144435675		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.06422402144435675 | validation: 0.03432603316090556]
	TIME [epoch: 34.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646076352471936		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.0646076352471936 | validation: 0.054923068052910654]
	TIME [epoch: 34.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470097606220891		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.0470097606220891 | validation: 0.09238152726817835]
	TIME [epoch: 34.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057219959377291935		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.057219959377291935 | validation: 0.05283968921586839]
	TIME [epoch: 34.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557936996900586		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.06557936996900586 | validation: 0.022708641645093806]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022666780348060626		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.022666780348060626 | validation: 0.04417675454809453]
	TIME [epoch: 34.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07893380270784321		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.07893380270784321 | validation: 0.04136186552981587]
	TIME [epoch: 34.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05005868656597316		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.05005868656597316 | validation: 0.04427129374472094]
	TIME [epoch: 34.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976177623232793		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.04976177623232793 | validation: 0.04482025903735875]
	TIME [epoch: 34.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346723615581988		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.03346723615581988 | validation: 0.06693460930517786]
	TIME [epoch: 34.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07153060893329272		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.07153060893329272 | validation: 0.048377522019872186]
	TIME [epoch: 34.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668880472618108		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.06668880472618108 | validation: 0.06579204601128263]
	TIME [epoch: 34.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047280948602029464		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.047280948602029464 | validation: 0.1632459716198213]
	TIME [epoch: 34.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797625416062003		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.0797625416062003 | validation: 0.08323641619433961]
	TIME [epoch: 34.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05619559493002367		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.05619559493002367 | validation: 0.057642420102290405]
	TIME [epoch: 34.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046597487770298304		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.046597487770298304 | validation: 0.023651158394937366]
	TIME [epoch: 34.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041094176736450015		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.041094176736450015 | validation: 0.046750203203452245]
	TIME [epoch: 34.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04344073302825717		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.04344073302825717 | validation: 0.11417094956777665]
	TIME [epoch: 34.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800582272131345		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.0800582272131345 | validation: 0.07042765151800069]
	TIME [epoch: 34.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04784585684674611		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.04784585684674611 | validation: 0.07934649942569559]
	TIME [epoch: 34.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611251066958116		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.10611251066958116 | validation: 0.0652135749371825]
	TIME [epoch: 34.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04890420256416644		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.04890420256416644 | validation: 0.06981116505338081]
	TIME [epoch: 34.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287658737932256		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.06287658737932256 | validation: 0.0629175795310373]
	TIME [epoch: 34.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068970426670784		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.07068970426670784 | validation: 0.06426702622102724]
	TIME [epoch: 34.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040147566486392346		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.040147566486392346 | validation: 0.04420078206336919]
	TIME [epoch: 34.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035321547015784174		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.035321547015784174 | validation: 0.05650587736871038]
	TIME [epoch: 34.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06786098491648104		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.06786098491648104 | validation: 0.02199503466117336]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0315437666561072		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.0315437666561072 | validation: 0.0779400861547553]
	TIME [epoch: 34.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04682760514623466		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.04682760514623466 | validation: 0.08847044315201655]
	TIME [epoch: 34.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790170597761351		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.09790170597761351 | validation: 0.07341365496496864]
	TIME [epoch: 34.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071886522259599		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.07071886522259599 | validation: 0.035257916586064975]
	TIME [epoch: 34.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06368435150321058		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.06368435150321058 | validation: 0.03715162014290779]
	TIME [epoch: 34.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03413851543121677		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.03413851543121677 | validation: 0.05462434691658559]
	TIME [epoch: 34.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860051753393576		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.05860051753393576 | validation: 0.11961495388507226]
	TIME [epoch: 34.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548536862369076		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.05548536862369076 | validation: 0.05395196646479696]
	TIME [epoch: 34.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04358460499179795		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.04358460499179795 | validation: 0.08485673022565104]
	TIME [epoch: 34.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635286747169279		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.0635286747169279 | validation: 0.07898502080501901]
	TIME [epoch: 34.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740406542857902		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.06740406542857902 | validation: 0.0791032796033458]
	TIME [epoch: 34.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096455514631754		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.04096455514631754 | validation: 0.21541629644167626]
	TIME [epoch: 34.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10254523264534818		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.10254523264534818 | validation: 0.03821667747707126]
	TIME [epoch: 34.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802818990680185		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.03802818990680185 | validation: 0.06584254902918782]
	TIME [epoch: 34.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153573079401782		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.08153573079401782 | validation: 0.05984370128310105]
	TIME [epoch: 34.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05293354619459306		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.05293354619459306 | validation: 0.04069031706459529]
	TIME [epoch: 34.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03615088691889928		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.03615088691889928 | validation: 0.05416518486284495]
	TIME [epoch: 34.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841961516813853		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.03841961516813853 | validation: 0.04130838859494942]
	TIME [epoch: 34.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04140478974264942		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.04140478974264942 | validation: 0.06893619491215494]
	TIME [epoch: 34.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033419513762411444		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.033419513762411444 | validation: 0.06410152339026894]
	TIME [epoch: 34.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888590973734429		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.0888590973734429 | validation: 0.05605417831470037]
	TIME [epoch: 34.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10904933875322062		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.10904933875322062 | validation: 0.07096402551415626]
	TIME [epoch: 34.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06709052271640138		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.06709052271640138 | validation: 0.06726176998544645]
	TIME [epoch: 34.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035238006476686005		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.035238006476686005 | validation: 0.0483350176588163]
	TIME [epoch: 34.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04008287533412526		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.04008287533412526 | validation: 0.06620905156238419]
	TIME [epoch: 34.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04783013583348939		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.04783013583348939 | validation: 0.050899713472069785]
	TIME [epoch: 34.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558975739831249		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.05558975739831249 | validation: 0.06829246611682532]
	TIME [epoch: 34.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137014205217554		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.04137014205217554 | validation: 0.06824789350483969]
	TIME [epoch: 34.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323858520940639		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.04323858520940639 | validation: 0.029931758653473858]
	TIME [epoch: 34.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724159238332597		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.0724159238332597 | validation: 0.02557255279381977]
	TIME [epoch: 34.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044696862476742594		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.044696862476742594 | validation: 0.06080228603470304]
	TIME [epoch: 34.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03771525836321735		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.03771525836321735 | validation: 0.03778997471001224]
	TIME [epoch: 34.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046495967573314284		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.046495967573314284 | validation: 0.13250418494728944]
	TIME [epoch: 34.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019348433972384		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.08019348433972384 | validation: 0.07724530911452415]
	TIME [epoch: 34.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04344643357678382		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.04344643357678382 | validation: 0.04502450307625389]
	TIME [epoch: 34.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470302836909574		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.05470302836909574 | validation: 0.09471308935971885]
	TIME [epoch: 34.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05056606315339948		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.05056606315339948 | validation: 0.060719176482683955]
	TIME [epoch: 34.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07706398710006972		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.07706398710006972 | validation: 0.020883598767123403]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028692938057645678		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.028692938057645678 | validation: 0.0971620841389626]
	TIME [epoch: 34.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733045986405066		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.04733045986405066 | validation: 0.034903271498124985]
	TIME [epoch: 34.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052171495856838085		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.052171495856838085 | validation: 0.02263051243827431]
	TIME [epoch: 34.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058018014514195033		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.058018014514195033 | validation: 0.06735407997516309]
	TIME [epoch: 34.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054367409285453916		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.054367409285453916 | validation: 0.0893199115117561]
	TIME [epoch: 34.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05231515712015261		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.05231515712015261 | validation: 0.05426360704354283]
	TIME [epoch: 34.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209475192685371		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.04209475192685371 | validation: 0.06974501905569147]
	TIME [epoch: 34.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258378948437769		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.06258378948437769 | validation: 0.05781034957076128]
	TIME [epoch: 34.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06102337516174661		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.06102337516174661 | validation: 0.05045069058055842]
	TIME [epoch: 34.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850051041059197		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.04850051041059197 | validation: 0.037070159605535974]
	TIME [epoch: 34.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622550173300232		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.03622550173300232 | validation: 0.043814858935866126]
	TIME [epoch: 34.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06240942320403645		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.06240942320403645 | validation: 0.04869851445591285]
	TIME [epoch: 34.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814456216041508		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.04814456216041508 | validation: 0.04159763560094248]
	TIME [epoch: 34.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048814990765104885		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.048814990765104885 | validation: 0.08534022653572008]
	TIME [epoch: 34.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237403605714809		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.04237403605714809 | validation: 0.04994103334220722]
	TIME [epoch: 34.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04514242514389246		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.04514242514389246 | validation: 0.07884945566231782]
	TIME [epoch: 34.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06764600012743417		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.06764600012743417 | validation: 0.04522682402125962]
	TIME [epoch: 34.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054995112744508745		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.054995112744508745 | validation: 0.02584155123463063]
	TIME [epoch: 34.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367837638333407		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.03367837638333407 | validation: 0.026944181638378625]
	TIME [epoch: 34.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179690162205039		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.04179690162205039 | validation: 0.12990235352071328]
	TIME [epoch: 34.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950968945789233		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.05950968945789233 | validation: 0.06615820603498446]
	TIME [epoch: 34.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05490649036992994		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.05490649036992994 | validation: 0.048685696956925276]
	TIME [epoch: 34.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774433822664629		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.05774433822664629 | validation: 0.028816391325142625]
	TIME [epoch: 34.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05663956552503235		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.05663956552503235 | validation: 0.038707634763864913]
	TIME [epoch: 34.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0495222597235985		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.0495222597235985 | validation: 0.0597838581951767]
	TIME [epoch: 34.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04877615754682776		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.04877615754682776 | validation: 0.04635655107433239]
	TIME [epoch: 34.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043208706746460136		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.043208706746460136 | validation: 0.04431662156849279]
	TIME [epoch: 34.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03895975704195633		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.03895975704195633 | validation: 0.02537466473387469]
	TIME [epoch: 34.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045645621854196385		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.045645621854196385 | validation: 0.13373127652673994]
	TIME [epoch: 34.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296756928580718		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.09296756928580718 | validation: 0.04805284149834817]
	TIME [epoch: 34.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447827114545308		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.04447827114545308 | validation: 0.13619555994064075]
	TIME [epoch: 34.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04916028847493205		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.04916028847493205 | validation: 0.05271247945988275]
	TIME [epoch: 34.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548746463263379		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.0548746463263379 | validation: 0.029452692629781327]
	TIME [epoch: 34.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603174427887987		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.05603174427887987 | validation: 0.05065320863556046]
	TIME [epoch: 34.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025831602710949		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.05025831602710949 | validation: 0.025441040232595108]
	TIME [epoch: 34.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926994270705797		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.03926994270705797 | validation: 0.08387223134960956]
	TIME [epoch: 34.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498766559974308		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.05498766559974308 | validation: 0.04875293113415807]
	TIME [epoch: 34.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055378425317879766		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.055378425317879766 | validation: 0.03873543119248477]
	TIME [epoch: 34.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030668163238407		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.030668163238407 | validation: 0.04616768243849158]
	TIME [epoch: 34.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033706108292623445		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.033706108292623445 | validation: 0.09977918480342055]
	TIME [epoch: 34.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052138960454429895		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.052138960454429895 | validation: 0.10817680008375347]
	TIME [epoch: 34.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054977882688086996		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.054977882688086996 | validation: 0.0323751685875501]
	TIME [epoch: 34.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275626343239459		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.03275626343239459 | validation: 0.12140749779297333]
	TIME [epoch: 34.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050349713276398395		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.050349713276398395 | validation: 0.0348523478536659]
	TIME [epoch: 34.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997134905705216		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.05997134905705216 | validation: 0.05152950524837967]
	TIME [epoch: 34.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054532939914876864		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.054532939914876864 | validation: 0.05072778306625992]
	TIME [epoch: 34.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0520394811835276		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.0520394811835276 | validation: 0.03720117779114504]
	TIME [epoch: 34.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03190290987406886		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.03190290987406886 | validation: 0.03742629878474799]
	TIME [epoch: 34.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651713411693125		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.0651713411693125 | validation: 0.06413425962840537]
	TIME [epoch: 34.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031652943229663597		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.031652943229663597 | validation: 0.056934799739745974]
	TIME [epoch: 34.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04790981950959554		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.04790981950959554 | validation: 0.04407812954246476]
	TIME [epoch: 34.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0547606632425128		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.0547606632425128 | validation: 0.07989856438124436]
	TIME [epoch: 34.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878394298756732		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.09878394298756732 | validation: 0.09379588342883662]
	TIME [epoch: 34.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722610658138188		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.07722610658138188 | validation: 0.06957342786632706]
	TIME [epoch: 34.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09011215934119533		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.09011215934119533 | validation: 0.06775668803781501]
	TIME [epoch: 34.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408703818288702		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.0408703818288702 | validation: 0.10009058549369022]
	TIME [epoch: 34.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860595948144127		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.05860595948144127 | validation: 0.032031843751419084]
	TIME [epoch: 34.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05083711250905625		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.05083711250905625 | validation: 0.021917781956588302]
	TIME [epoch: 34.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047280392549278905		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.047280392549278905 | validation: 0.11306230945679513]
	TIME [epoch: 34.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874981408100092		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.05874981408100092 | validation: 0.06391752919451323]
	TIME [epoch: 34.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565333969452132		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.0565333969452132 | validation: 0.085565465235412]
	TIME [epoch: 34.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04627248364279448		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.04627248364279448 | validation: 0.08878103060532705]
	TIME [epoch: 34.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640544320937304		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.0640544320937304 | validation: 0.04252304167586003]
	TIME [epoch: 34.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047873081818389826		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.047873081818389826 | validation: 0.023279940990070806]
	TIME [epoch: 34.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049130083219344645		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.049130083219344645 | validation: 0.07421994485605582]
	TIME [epoch: 34.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047299168103886624		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.047299168103886624 | validation: 0.08284001527754595]
	TIME [epoch: 34.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048302536777595724		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.048302536777595724 | validation: 0.05134224021901525]
	TIME [epoch: 34.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564674969460267		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.0564674969460267 | validation: 0.03239693217531693]
	TIME [epoch: 34.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058161519565657044		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.058161519565657044 | validation: 0.036352976278044465]
	TIME [epoch: 34.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041037985274072764		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.041037985274072764 | validation: 0.025639247280871445]
	TIME [epoch: 34.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262373378338594		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.03262373378338594 | validation: 0.0985179399231752]
	TIME [epoch: 34.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09664568327365008		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.09664568327365008 | validation: 0.030986898828319065]
	TIME [epoch: 34.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756316060679301		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.05756316060679301 | validation: 0.05482069175230318]
	TIME [epoch: 34.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041332382064616965		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.041332382064616965 | validation: 0.03492684721933626]
	TIME [epoch: 34.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771501973066254		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.1771501973066254 | validation: 0.3025203775385735]
	TIME [epoch: 34.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3201507531084938		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.3201507531084938 | validation: 0.05283396901417009]
	TIME [epoch: 34.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786372769236739		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.04786372769236739 | validation: 0.03059342110041023]
	TIME [epoch: 34.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264743460737123		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.03264743460737123 | validation: 0.03948423577385152]
	TIME [epoch: 34.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040758158374906685		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.040758158374906685 | validation: 0.047152110103285676]
	TIME [epoch: 34.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03829133802393266		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.03829133802393266 | validation: 0.030366940344079177]
	TIME [epoch: 34.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972034357320388		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.03972034357320388 | validation: 0.03825926889959713]
	TIME [epoch: 34.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530496243051399		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.04530496243051399 | validation: 0.026150704509242215]
	TIME [epoch: 34.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042295707383359034		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.042295707383359034 | validation: 0.05998270728809878]
	TIME [epoch: 34.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04971045852838906		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.04971045852838906 | validation: 0.07182490472387604]
	TIME [epoch: 34.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956131273254971		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.03956131273254971 | validation: 0.06422218422712425]
	TIME [epoch: 34.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151363132889723		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.06151363132889723 | validation: 0.05866509932933803]
	TIME [epoch: 34.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530008929902414		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.0530008929902414 | validation: 0.09395243035322882]
	TIME [epoch: 34.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07185320966683849		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.07185320966683849 | validation: 0.059177374985887855]
	TIME [epoch: 34.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050547001635603585		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.050547001635603585 | validation: 0.040549852154629994]
	TIME [epoch: 34.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412172488863484		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.04412172488863484 | validation: 0.03627951231630338]
	TIME [epoch: 34.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446414314833822		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.04446414314833822 | validation: 0.028104365340432452]
	TIME [epoch: 34.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03490637230467848		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.03490637230467848 | validation: 0.08030866454128816]
	TIME [epoch: 34.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448926730762163		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.05448926730762163 | validation: 0.05597597358679132]
	TIME [epoch: 34.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04633794289611763		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.04633794289611763 | validation: 0.06769635865271181]
	TIME [epoch: 34.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039951484816928895		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.039951484816928895 | validation: 0.0560313634020802]
	TIME [epoch: 34.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04532785649862611		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.04532785649862611 | validation: 0.0289139908055285]
	TIME [epoch: 34.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534117362466686		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.04534117362466686 | validation: 0.03639165396638753]
	TIME [epoch: 34.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035270129645680985		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.035270129645680985 | validation: 0.04881078650339139]
	TIME [epoch: 34.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05331548295818034		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.05331548295818034 | validation: 0.029925375034814586]
	TIME [epoch: 34.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052373399031914486		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.052373399031914486 | validation: 0.04647398430172514]
	TIME [epoch: 34.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002074024608556		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.04002074024608556 | validation: 0.04229639138978135]
	TIME [epoch: 34.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769761508428999		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.03769761508428999 | validation: 0.26342002452092883]
	TIME [epoch: 34.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08479967639056936		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.08479967639056936 | validation: 0.06268233269253391]
	TIME [epoch: 34.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847657886736713		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.04847657886736713 | validation: 0.06971203297319944]
	TIME [epoch: 34.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03737693944680836		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.03737693944680836 | validation: 0.01867768833370102]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03836661337796697		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.03836661337796697 | validation: 0.038928748867615985]
	TIME [epoch: 34.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0706039305056205		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.0706039305056205 | validation: 0.07341224189023336]
	TIME [epoch: 34.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947099456204759		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.04947099456204759 | validation: 0.037671948598624314]
	TIME [epoch: 34.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045902321598648675		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.045902321598648675 | validation: 0.02874621507285801]
	TIME [epoch: 34.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237403704021081		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.04237403704021081 | validation: 0.030534440823918492]
	TIME [epoch: 34.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03450358991121052		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.03450358991121052 | validation: 0.03463930199924634]
	TIME [epoch: 34.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038423313465657846		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.038423313465657846 | validation: 0.03120332757051232]
	TIME [epoch: 34.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03746085685722705		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.03746085685722705 | validation: 0.040211921862563144]
	TIME [epoch: 34.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402547056999673		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.03402547056999673 | validation: 0.026329460132766033]
	TIME [epoch: 34.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699460394445228		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.03699460394445228 | validation: 0.035689385120924406]
	TIME [epoch: 34.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388287484536844		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.03388287484536844 | validation: 0.03521586541294003]
	TIME [epoch: 34.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634666890759091		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.03634666890759091 | validation: 0.032436605040628896]
	TIME [epoch: 34.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04189204087585374		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.04189204087585374 | validation: 0.0722872563380948]
	TIME [epoch: 34.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030168125019879536		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.030168125019879536 | validation: 0.045307466352017975]
	TIME [epoch: 34.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04432646921337348		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.04432646921337348 | validation: 0.07280330470423726]
	TIME [epoch: 34.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505126199884184		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.03505126199884184 | validation: 0.05212055913170491]
	TIME [epoch: 34.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03365981456996901		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.03365981456996901 | validation: 0.0733468458582491]
	TIME [epoch: 34.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044743159855059327		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.044743159855059327 | validation: 0.04215816530717041]
	TIME [epoch: 34.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528794546379141		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.0528794546379141 | validation: 0.01516026802610787]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040490701202953526		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.040490701202953526 | validation: 0.11017818709723491]
	TIME [epoch: 34.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854857640968009		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.04854857640968009 | validation: 0.01362568606210034]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03835306278377207		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.03835306278377207 | validation: 0.0458656180209414]
	TIME [epoch: 34.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030692571221041763		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.030692571221041763 | validation: 0.018368420032987273]
	TIME [epoch: 34.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693124762237018		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.03693124762237018 | validation: 0.02824562948722604]
	TIME [epoch: 34.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029241417170880486		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.029241417170880486 | validation: 0.06547739077016901]
	TIME [epoch: 34.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315557850046938		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.05315557850046938 | validation: 0.06089068131136344]
	TIME [epoch: 34.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855861860541712		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.12855861860541712 | validation: 0.054797018682261375]
	TIME [epoch: 34.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046841756964276546		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.046841756964276546 | validation: 0.11496410522838227]
	TIME [epoch: 34.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078800362373253		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.05078800362373253 | validation: 0.038542952038830375]
	TIME [epoch: 34.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03548774818955676		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.03548774818955676 | validation: 0.03758629803358019]
	TIME [epoch: 34.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023857647086109733		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.023857647086109733 | validation: 0.01920688921096029]
	TIME [epoch: 34.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02491221223354537		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.02491221223354537 | validation: 0.03228132001920207]
	TIME [epoch: 34.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026731088647689662		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.026731088647689662 | validation: 0.05714649523223689]
	TIME [epoch: 34.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04173968218146187		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.04173968218146187 | validation: 0.025860190371167942]
	TIME [epoch: 34.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03059842025522961		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.03059842025522961 | validation: 0.016141910446253682]
	TIME [epoch: 34.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028488549129482666		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.028488549129482666 | validation: 0.05936544720663931]
	TIME [epoch: 34.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03376138992644238		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.03376138992644238 | validation: 0.038218739363883536]
	TIME [epoch: 34.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046461248821302		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.046461248821302 | validation: 0.01927015454674581]
	TIME [epoch: 34.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02017648476379912		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.02017648476379912 | validation: 0.08218862115942957]
	TIME [epoch: 34.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043285414965355		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.05043285414965355 | validation: 0.03308268416617167]
	TIME [epoch: 34.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03366661460926433		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.03366661460926433 | validation: 0.05588248220560945]
	TIME [epoch: 34.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029091562428388354		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.029091562428388354 | validation: 0.04210631180575376]
	TIME [epoch: 34.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038799361816689484		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.038799361816689484 | validation: 0.024832540515729237]
	TIME [epoch: 34.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386760815898154		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.0386760815898154 | validation: 0.049053969499113774]
	TIME [epoch: 34.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035082816673193434		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.035082816673193434 | validation: 0.02765775879201928]
	TIME [epoch: 34.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02460156233129272		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.02460156233129272 | validation: 0.02286109302428866]
	TIME [epoch: 34.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267166473570166		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.03267166473570166 | validation: 0.030164446850966087]
	TIME [epoch: 34.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403075547563368		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.02403075547563368 | validation: 0.03828318721078707]
	TIME [epoch: 34.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684637115928203		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.0684637115928203 | validation: 0.2769962882635003]
	TIME [epoch: 34.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2287434615527804		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 1.2287434615527804 | validation: 1.1271597839649]
	TIME [epoch: 34.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.856814000745959		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 1.856814000745959 | validation: 1.9948207172589498]
	TIME [epoch: 34.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8742302648232922		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 1.8742302648232922 | validation: 0.8201473473598901]
	TIME [epoch: 34.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202039592742408		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.9202039592742408 | validation: 0.7311567619059295]
	TIME [epoch: 34.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723326893577883		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.6723326893577883 | validation: 0.34529356789887]
	TIME [epoch: 34.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41010665430463716		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.41010665430463716 | validation: 0.2371600242218323]
	TIME [epoch: 34.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20288057919651883		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.20288057919651883 | validation: 0.12175738545720459]
	TIME [epoch: 34.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863498787289481		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.08863498787289481 | validation: 0.045914230990015806]
	TIME [epoch: 34.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038952086852246194		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.038952086852246194 | validation: 0.043615170274270615]
	TIME [epoch: 34.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729978405772526		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.03729978405772526 | validation: 0.03605095922031337]
	TIME [epoch: 34.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03845669666286287		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.03845669666286287 | validation: 0.030572596263947732]
	TIME [epoch: 34.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037936728029552405		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.037936728029552405 | validation: 0.03293072667827501]
	TIME [epoch: 34.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721781452636967		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.03721781452636967 | validation: 0.01837791289896048]
	TIME [epoch: 34.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035113804255264815		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.035113804255264815 | validation: 0.05408069222340049]
	TIME [epoch: 34.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322075026896142		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.0322075026896142 | validation: 0.04146970961357886]
	TIME [epoch: 34.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03161205202014651		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.03161205202014651 | validation: 0.03629854893410818]
	TIME [epoch: 34.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430105299228822		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.05430105299228822 | validation: 0.032575891365117404]
	TIME [epoch: 34.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037097273662622124		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.037097273662622124 | validation: 0.028751483867506467]
	TIME [epoch: 34.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0385410294623483		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.0385410294623483 | validation: 0.03181042231584606]
	TIME [epoch: 34.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047903430066333366		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.047903430066333366 | validation: 0.04895983693269666]
	TIME [epoch: 34.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027388156049659676		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.027388156049659676 | validation: 0.05057403171482078]
	TIME [epoch: 34.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04652100670631751		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.04652100670631751 | validation: 0.017768649959962732]
	TIME [epoch: 34.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027805083128669375		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.027805083128669375 | validation: 0.058966162341321286]
	TIME [epoch: 34.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126273246482243		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.03126273246482243 | validation: 0.034040253430102516]
	TIME [epoch: 34.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044418934088832816		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.044418934088832816 | validation: 0.02063828694503045]
	TIME [epoch: 34.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037225140769506976		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.037225140769506976 | validation: 0.09764965158787686]
	TIME [epoch: 34.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05019681263831443		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.05019681263831443 | validation: 0.03766838961469164]
	TIME [epoch: 34.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029275932694971613		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.029275932694971613 | validation: 0.037755494528503325]
	TIME [epoch: 34.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03754666538789328		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.03754666538789328 | validation: 0.026385571435473876]
	TIME [epoch: 34.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04528845603029583		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.04528845603029583 | validation: 0.020328029471068335]
	TIME [epoch: 34.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026315332565249604		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.026315332565249604 | validation: 0.014321495806999446]
	TIME [epoch: 34.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03208326106768997		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.03208326106768997 | validation: 0.03738105754052546]
	TIME [epoch: 34.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02452109300082437		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.02452109300082437 | validation: 0.04821938337997046]
	TIME [epoch: 34.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031979129560731706		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.031979129560731706 | validation: 0.03279374081829812]
	TIME [epoch: 34.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670224217876795		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.0670224217876795 | validation: 0.04160618669319574]
	TIME [epoch: 34.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029864387755710733		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.029864387755710733 | validation: 0.017305308550093497]
	TIME [epoch: 34.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03343536403821701		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.03343536403821701 | validation: 0.06855045599605511]
	TIME [epoch: 34.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577885677474323		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.03577885677474323 | validation: 0.03542160105961251]
	TIME [epoch: 34.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02731180476432595		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.02731180476432595 | validation: 0.028786241437473006]
	TIME [epoch: 34.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023830866137589203		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.023830866137589203 | validation: 0.039331374175069975]
	TIME [epoch: 34.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11020799975380863		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.11020799975380863 | validation: 0.11014939297429244]
	TIME [epoch: 34.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828917930307226		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.05828917930307226 | validation: 0.037268747628165524]
	TIME [epoch: 34.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02360608516587589		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.02360608516587589 | validation: 0.056382667117558044]
	TIME [epoch: 34.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199623163295534		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.03199623163295534 | validation: 0.02789711262583776]
	TIME [epoch: 34.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02333856273672102		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.02333856273672102 | validation: 0.037616058827754456]
	TIME [epoch: 34.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239797458452211		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.03239797458452211 | validation: 0.03323629403903338]
	TIME [epoch: 34.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715998630736514		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.03715998630736514 | validation: 0.0379771269713768]
	TIME [epoch: 34.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188701220108733		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.03188701220108733 | validation: 0.02466130602262028]
	TIME [epoch: 34.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035606690331970246		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.035606690331970246 | validation: 0.02250728250227848]
	TIME [epoch: 34.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371940383858804		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.03371940383858804 | validation: 0.02891405726409515]
	TIME [epoch: 34.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02868813574692937		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.02868813574692937 | validation: 0.10473696485117726]
	TIME [epoch: 34.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08998496984400356		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.08998496984400356 | validation: 0.0304529129666707]
	TIME [epoch: 34.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424879012229257		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.03424879012229257 | validation: 0.025240747217225117]
	TIME [epoch: 34.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020976565337652027		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.020976565337652027 | validation: 0.02743792072088076]
	TIME [epoch: 34.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269958338160432		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.03269958338160432 | validation: 0.028034200188381056]
	TIME [epoch: 34.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019109796598444567		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.019109796598444567 | validation: 0.05573656216144961]
	TIME [epoch: 34.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09571796384627951		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.09571796384627951 | validation: 0.03637126161547391]
	TIME [epoch: 34.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563077114806501		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.06563077114806501 | validation: 0.02389610487079996]
	TIME [epoch: 34.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0192566690180846		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.0192566690180846 | validation: 0.018031987207389896]
	TIME [epoch: 34.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023093326528782793		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.023093326528782793 | validation: 0.04723842977363764]
	TIME [epoch: 34.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029637116069861434		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.029637116069861434 | validation: 0.015464043133598327]
	TIME [epoch: 34.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029818250238939983		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.029818250238939983 | validation: 0.0243416677965497]
	TIME [epoch: 34.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02362122224333383		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.02362122224333383 | validation: 0.02432878660308579]
	TIME [epoch: 34.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030108804366841452		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.030108804366841452 | validation: 0.05553614669438173]
	TIME [epoch: 34.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026787813854480924		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.026787813854480924 | validation: 0.04509148611639616]
	TIME [epoch: 34.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051394685252636886		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.051394685252636886 | validation: 0.022057445016440975]
	TIME [epoch: 34.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021713180273705904		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.021713180273705904 | validation: 0.052018484530800636]
	TIME [epoch: 34.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309461445870026		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.04309461445870026 | validation: 0.05091818934385484]
	TIME [epoch: 34.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02591509236610516		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.02591509236610516 | validation: 0.049119792853744765]
	TIME [epoch: 34.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789425960078249		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.04789425960078249 | validation: 0.01040571503994078]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_950.pth
	Model improved!!!
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023024176465341085		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.023024176465341085 | validation: 0.09379275441791861]
	TIME [epoch: 34.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04497570014878862		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.04497570014878862 | validation: 0.04176763511012235]
	TIME [epoch: 34.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026038509343596566		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.026038509343596566 | validation: 0.04624450177208213]
	TIME [epoch: 34.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192202684848638		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.03192202684848638 | validation: 0.012912462749336669]
	TIME [epoch: 34.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017179428147882318		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.017179428147882318 | validation: 0.09231613355870193]
	TIME [epoch: 34.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051295157413252794		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.051295157413252794 | validation: 0.02706812278557333]
	TIME [epoch: 34.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421325597352515		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.06421325597352515 | validation: 0.029716592324147258]
	TIME [epoch: 34.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519299613269982		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.03519299613269982 | validation: 0.016703789044534928]
	TIME [epoch: 34.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015950664381095193		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.015950664381095193 | validation: 0.0335978457363458]
	TIME [epoch: 34.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04215566904797845		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.04215566904797845 | validation: 0.023231140196881814]
	TIME [epoch: 34.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018997313964523282		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.018997313964523282 | validation: 0.05811399492652142]
	TIME [epoch: 34.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05055000516693938		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.05055000516693938 | validation: 0.01813654001424491]
	TIME [epoch: 34.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02747838309040343		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.02747838309040343 | validation: 0.05934567929906599]
	TIME [epoch: 34.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02937457581191388		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.02937457581191388 | validation: 0.020358979430249453]
	TIME [epoch: 34.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353121560896412		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.06353121560896412 | validation: 0.04013573791290775]
	TIME [epoch: 34.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520830443106939		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.04520830443106939 | validation: 0.07499439681843856]
	TIME [epoch: 34.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790478055721994		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.05790478055721994 | validation: 0.0397360652246294]
	TIME [epoch: 34.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078294440608506		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.05078294440608506 | validation: 0.03200282030365194]
	TIME [epoch: 34.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03701719133424662		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.03701719133424662 | validation: 0.060839826801855165]
	TIME [epoch: 34.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045278854215650643		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.045278854215650643 | validation: 0.020190356455602222]
	TIME [epoch: 34.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039058206764329466		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.039058206764329466 | validation: 0.03528649913304019]
	TIME [epoch: 34.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659869340200961		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.05659869340200961 | validation: 0.013687713837368776]
	TIME [epoch: 34.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902371890836971		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.03902371890836971 | validation: 0.037351961427327884]
	TIME [epoch: 34.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038367318101769285		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.038367318101769285 | validation: 0.05701685535425845]
	TIME [epoch: 34.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03768101016093716		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.03768101016093716 | validation: 0.055551151621622316]
	TIME [epoch: 34.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041818601298241206		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.041818601298241206 | validation: 0.07814908558119107]
	TIME [epoch: 34.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715543914992703		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.05715543914992703 | validation: 0.03506066906131314]
	TIME [epoch: 34.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049314194750236684		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.049314194750236684 | validation: 0.0451333093549772]
	TIME [epoch: 34.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030991475203566793		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.030991475203566793 | validation: 0.053609164813651994]
	TIME [epoch: 34.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03698565039296088		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.03698565039296088 | validation: 0.044434139745774905]
	TIME [epoch: 34.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265253873093125		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.06265253873093125 | validation: 0.01649431291513967]
	TIME [epoch: 34.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02141714064932822		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.02141714064932822 | validation: 0.04732081181630756]
	TIME [epoch: 34.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042664565839024476		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.042664565839024476 | validation: 0.04031308447577362]
	TIME [epoch: 34.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172314125979415		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.03172314125979415 | validation: 0.036321714550281686]
	TIME [epoch: 34.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041975418602644525		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.041975418602644525 | validation: 0.023622761285293385]
	TIME [epoch: 34.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026044928734060585		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.026044928734060585 | validation: 0.07283824321227049]
	TIME [epoch: 34.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463618666466829		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.0463618666466829 | validation: 0.06948270802965295]
	TIME [epoch: 34.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05076583241724178		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.05076583241724178 | validation: 0.03490101051785461]
	TIME [epoch: 34.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539347152898417		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.06539347152898417 | validation: 0.08110934063633993]
	TIME [epoch: 34.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746568692604935		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.07746568692604935 | validation: 0.04994663200578156]
	TIME [epoch: 34.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02386696975158191		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.02386696975158191 | validation: 0.022794815619456368]
	TIME [epoch: 34.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284773175323686		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.03284773175323686 | validation: 0.40912585341968666]
	TIME [epoch: 34.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26788646888907214		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.26788646888907214 | validation: 0.13704347290597962]
	TIME [epoch: 34.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08306538633188638		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.08306538633188638 | validation: 0.026474375328806685]
	TIME [epoch: 34.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19480928930251895		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.19480928930251895 | validation: 1.068675432310149]
	TIME [epoch: 34.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605422652049639		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.7605422652049639 | validation: 1.3719220933021838]
	TIME [epoch: 34.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8564226558681737		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.8564226558681737 | validation: 1.1081538068447963]
	TIME [epoch: 34.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604175579480682		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.604175579480682 | validation: 0.7430876567453375]
	TIME [epoch: 34.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3834756930284875		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.3834756930284875 | validation: 0.5090807242490976]
	TIME [epoch: 34.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26036213731883034		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.26036213731883034 | validation: 0.24355379617795284]
	TIME [epoch: 34.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848034744452245		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.13848034744452245 | validation: 0.11023148389530119]
	TIME [epoch: 167 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022034743158658		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.08022034743158658 | validation: 0.06580372756495254]
	TIME [epoch: 74.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675646277492762		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.06675646277492762 | validation: 0.06406564311392661]
	TIME [epoch: 74.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193220276272246		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.04193220276272246 | validation: 0.039332545397694665]
	TIME [epoch: 74.2 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209148202546047		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.04209148202546047 | validation: 0.020237471418267507]
	TIME [epoch: 74.2 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038419683145523846		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.038419683145523846 | validation: 0.029352927993874837]
	TIME [epoch: 74.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02481720546799058		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.02481720546799058 | validation: 0.0376458835131685]
	TIME [epoch: 74.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682469217844463		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.03682469217844463 | validation: 0.028086417309485048]
	TIME [epoch: 74.2 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482830867132588		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.02482830867132588 | validation: 0.031361821547879726]
	TIME [epoch: 74.2 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704423166955508		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.03704423166955508 | validation: 0.044471033547751906]
	TIME [epoch: 74.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411772997764857		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.03411772997764857 | validation: 0.10708297952941456]
	TIME [epoch: 74.2 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045270072536587734		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.045270072536587734 | validation: 0.029918707006239]
	TIME [epoch: 74.2 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06730296552041944		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.06730296552041944 | validation: 0.08292403496710785]
	TIME [epoch: 74.2 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0550752911309536		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.0550752911309536 | validation: 0.04373668411771185]
	TIME [epoch: 74.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452586336482525		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.0452586336482525 | validation: 0.04753294211484067]
	TIME [epoch: 74.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047762993391378926		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.047762993391378926 | validation: 0.03438405597994049]
	TIME [epoch: 74.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042198979644366835		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.042198979644366835 | validation: 0.01585786482625158]
	TIME [epoch: 74.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03400118357389453		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.03400118357389453 | validation: 0.03144993865166961]
	TIME [epoch: 74.2 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040735205356929274		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.040735205356929274 | validation: 0.040305891570406725]
	TIME [epoch: 74.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028969280187602517		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.028969280187602517 | validation: 0.06462365273091507]
	TIME [epoch: 74.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315653057302096		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.04315653057302096 | validation: 0.0955535315611784]
	TIME [epoch: 74.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063712924932146		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.063712924932146 | validation: 0.026276472056895307]
	TIME [epoch: 74.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127061696136174		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.03127061696136174 | validation: 0.02626943559691395]
	TIME [epoch: 74.4 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03131451731586192		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.03131451731586192 | validation: 0.06822672509701577]
	TIME [epoch: 74.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040829018795082946		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.040829018795082946 | validation: 0.013242263400260423]
	TIME [epoch: 74.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067071933568378		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.03067071933568378 | validation: 0.03852867993954609]
	TIME [epoch: 74.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03696590783377438		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.03696590783377438 | validation: 0.03766975870190799]
	TIME [epoch: 74.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033179834260735445		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.033179834260735445 | validation: 0.03716992278890987]
	TIME [epoch: 74.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03104951117368022		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.03104951117368022 | validation: 0.032385817057278936]
	TIME [epoch: 74.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028445104338678896		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.028445104338678896 | validation: 0.026678611698267723]
	TIME [epoch: 74.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030453055643326496		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.030453055643326496 | validation: 0.04476795463704944]
	TIME [epoch: 74.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03827098202890131		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.03827098202890131 | validation: 0.06110874878989554]
	TIME [epoch: 74.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036728962269388515		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.036728962269388515 | validation: 0.018639001445524522]
	TIME [epoch: 74.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031634293751367275		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.031634293751367275 | validation: 0.015415248993345624]
	TIME [epoch: 74.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03213050409716891		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.03213050409716891 | validation: 0.07085362266361173]
	TIME [epoch: 74.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040586345406340416		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.040586345406340416 | validation: 0.023941386046042575]
	TIME [epoch: 74.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020798708272473303		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.020798708272473303 | validation: 0.03985385150179646]
	TIME [epoch: 74.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038170372495473254		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.038170372495473254 | validation: 0.02586128560099975]
	TIME [epoch: 74.2 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0247827645722102		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.0247827645722102 | validation: 0.0162308008410988]
	TIME [epoch: 74.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04040410619677342		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.04040410619677342 | validation: 0.01709452822514339]
	TIME [epoch: 74.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028566194510194785		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.028566194510194785 | validation: 0.05106365765614039]
	TIME [epoch: 74.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03439446761252199		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.03439446761252199 | validation: 0.016068653652881945]
	TIME [epoch: 74.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022179063796078653		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.022179063796078653 | validation: 0.10160300053082823]
	TIME [epoch: 74.4 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333605081766597		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.04333605081766597 | validation: 0.017565824333770803]
	TIME [epoch: 74.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563375255418151		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.0563375255418151 | validation: 0.05022439185554568]
	TIME [epoch: 74.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030700891769664097		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.030700891769664097 | validation: 0.014065385094091946]
	TIME [epoch: 74.4 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027223864709784624		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.027223864709784624 | validation: 0.039641565350830466]
	TIME [epoch: 74.4 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03756648219727315		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.03756648219727315 | validation: 0.008041322379492483]
	TIME [epoch: 74.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_1048.pth
	Model improved!!!
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030019056585499516		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.030019056585499516 | validation: 0.032450828720666]
	TIME [epoch: 74.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023195352684557736		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.023195352684557736 | validation: 0.0268734556670354]
	TIME [epoch: 74.4 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129182665368555		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.03129182665368555 | validation: 0.01745901085439263]
	TIME [epoch: 74.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027948707917769627		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.027948707917769627 | validation: 0.023550328772202894]
	TIME [epoch: 74.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023746135626546462		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.023746135626546462 | validation: 0.029906104679861326]
	TIME [epoch: 74.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11270882367111923		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.11270882367111923 | validation: 0.35175639645993306]
	TIME [epoch: 74.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16030318539243377		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.16030318539243377 | validation: 0.03528267598539037]
	TIME [epoch: 74.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029902443780139693		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.029902443780139693 | validation: 0.018526720502839086]
	TIME [epoch: 74.4 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02137126733447537		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.02137126733447537 | validation: 0.022339601588629292]
	TIME [epoch: 74.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021510345563785917		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.021510345563785917 | validation: 0.013763530476044086]
	TIME [epoch: 74.4 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020276418901849683		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.020276418901849683 | validation: 0.01158417299060981]
	TIME [epoch: 74.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019564362619593045		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.019564362619593045 | validation: 0.04093662079467036]
	TIME [epoch: 74.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032306185295264404		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.032306185295264404 | validation: 0.008902389240267521]
	TIME [epoch: 74.4 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015592234458974227		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.015592234458974227 | validation: 0.01608671324934606]
	TIME [epoch: 74.4 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481598343810701		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.03481598343810701 | validation: 0.0389773502795063]
	TIME [epoch: 74.2 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542229933316178		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.02542229933316178 | validation: 0.02393807747477797]
	TIME [epoch: 74.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02194388209013617		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.02194388209013617 | validation: 0.033167252189378826]
	TIME [epoch: 74.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023644408235841786		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.023644408235841786 | validation: 0.04104848456470087]
	TIME [epoch: 74.4 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723847921051265		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.02723847921051265 | validation: 0.018979462014795806]
	TIME [epoch: 74.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02235036583466024		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.02235036583466024 | validation: 0.019746809627323506]
	TIME [epoch: 74.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02033390665472249		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.02033390665472249 | validation: 0.02845127869813974]
	TIME [epoch: 74.4 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12534200011799632		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.12534200011799632 | validation: 0.062197347098009365]
	TIME [epoch: 74.4 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717415005194418		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.05717415005194418 | validation: 0.01952923166456394]
	TIME [epoch: 74.2 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026951904889944756		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.026951904889944756 | validation: 0.015896857625393827]
	TIME [epoch: 74.2 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022906811613870717		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.022906811613870717 | validation: 0.03826200850646859]
	TIME [epoch: 74.2 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02518468529590472		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.02518468529590472 | validation: 0.014573138579299299]
	TIME [epoch: 74.2 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017449982801985432		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.017449982801985432 | validation: 0.0312351367053603]
	TIME [epoch: 74.2 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02471012388725149		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.02471012388725149 | validation: 0.024446116328360176]
	TIME [epoch: 74.2 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024716859179516028		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.024716859179516028 | validation: 0.051834030352388594]
	TIME [epoch: 74.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030681350298690676		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.030681350298690676 | validation: 0.023190766920969774]
	TIME [epoch: 74.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014833093641357337		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.014833093641357337 | validation: 0.01883914157965548]
	TIME [epoch: 74.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041384651484850404		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.041384651484850404 | validation: 0.02210450581293614]
	TIME [epoch: 74.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02538978447701813		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.02538978447701813 | validation: 0.03597906311298306]
	TIME [epoch: 74.4 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030929943366540653		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.030929943366540653 | validation: 0.02820682057557265]
	TIME [epoch: 74.2 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251464557300021		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.03251464557300021 | validation: 0.02564102767843177]
	TIME [epoch: 74.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0231207358605774		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.0231207358605774 | validation: 0.18237311228520048]
	TIME [epoch: 74.2 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028938208183694		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.07028938208183694 | validation: 0.033464349232843145]
	TIME [epoch: 74.2 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303020426255464		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.03303020426255464 | validation: 0.037137613221738155]
	TIME [epoch: 74.2 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884038897666757		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.03884038897666757 | validation: 0.03638716661574618]
	TIME [epoch: 74.2 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605652309251296		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.03605652309251296 | validation: 0.08646353561073818]
	TIME [epoch: 74.2 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683430705185603		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.04683430705185603 | validation: 0.018357970819680623]
	TIME [epoch: 74.2 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02931761568686777		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.02931761568686777 | validation: 0.054503275007018466]
	TIME [epoch: 74.2 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037615769356041606		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.037615769356041606 | validation: 0.049744398830141076]
	TIME [epoch: 74.2 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029620463180491087		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.029620463180491087 | validation: 0.011019327356852075]
	TIME [epoch: 74.2 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034655305213221306		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.034655305213221306 | validation: 0.022915481829113002]
	TIME [epoch: 74.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06261927143215654		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.06261927143215654 | validation: 0.041986815925986735]
	TIME [epoch: 74.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061691620350377875		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.061691620350377875 | validation: 0.03833947544714439]
	TIME [epoch: 74.2 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145397337057541		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.03145397337057541 | validation: 0.01818584666837289]
	TIME [epoch: 74.2 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023730434441209987		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.023730434441209987 | validation: 0.07882954574531559]
	TIME [epoch: 74.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05331043619568458		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.05331043619568458 | validation: 0.009543165340235719]
	TIME [epoch: 74.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214960783335681		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.03214960783335681 | validation: 0.027842770030797194]
	TIME [epoch: 74.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04268348118012057		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.04268348118012057 | validation: 0.029187036075688077]
	TIME [epoch: 74.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027830240064150396		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.027830240064150396 | validation: 0.008106341773115918]
	TIME [epoch: 74.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037829922438741566		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.037829922438741566 | validation: 0.04270160979030881]
	TIME [epoch: 74.2 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023235015927286693		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.023235015927286693 | validation: 0.05789058899926672]
	TIME [epoch: 74.2 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04314347418665744		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.04314347418665744 | validation: 0.06376303245090317]
	TIME [epoch: 74.1 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047470442194862725		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.047470442194862725 | validation: 0.02749246300256073]
	TIME [epoch: 74.2 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04927815216325217		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.04927815216325217 | validation: 0.03085682634674622]
	TIME [epoch: 74.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437997863520096		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.03437997863520096 | validation: 0.013363163249703101]
	TIME [epoch: 74.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183678105945753		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.04183678105945753 | validation: 0.02454426814590454]
	TIME [epoch: 74.2 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717614854494408		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.03717614854494408 | validation: 0.04548940540528133]
	TIME [epoch: 74.2 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05241230241190756		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.05241230241190756 | validation: 0.06379692294403216]
	TIME [epoch: 74.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03938012703312502		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.03938012703312502 | validation: 0.01911662953299538]
	TIME [epoch: 74.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04391905587276475		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.04391905587276475 | validation: 0.04691907970682522]
	TIME [epoch: 74.2 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027720656337248517		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.027720656337248517 | validation: 0.027443447638035537]
	TIME [epoch: 74.2 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039253136751571174		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.039253136751571174 | validation: 0.04912900762106095]
	TIME [epoch: 74.1 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033598086034660316		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.033598086034660316 | validation: 0.031266599781522936]
	TIME [epoch: 74.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030822411562733444		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.030822411562733444 | validation: 0.026585189280182987]
	TIME [epoch: 74.2 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482296545978606		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.02482296545978606 | validation: 0.02250631522685343]
	TIME [epoch: 74.2 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020776327914777883		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.020776327914777883 | validation: 0.02372349722542525]
	TIME [epoch: 74.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06213834574150251		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.06213834574150251 | validation: 0.012386718987008044]
	TIME [epoch: 74.2 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02430644991492447		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.02430644991492447 | validation: 0.06704400877213001]
	TIME [epoch: 74.2 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04070504013632625		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.04070504013632625 | validation: 0.08586059369431906]
	TIME [epoch: 74.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07482229983068284		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.07482229983068284 | validation: 0.03578919357385865]
	TIME [epoch: 74.1 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003275419637537		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.05003275419637537 | validation: 0.13630091004892772]
	TIME [epoch: 74.2 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550892277915043		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.09550892277915043 | validation: 0.0561574092796564]
	TIME [epoch: 74.2 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911596688743134		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.09911596688743134 | validation: 0.10626680413993378]
	TIME [epoch: 74.2 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11449025186060607		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.11449025186060607 | validation: 0.046124116561450636]
	TIME [epoch: 74.2 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05098259330363132		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.05098259330363132 | validation: 0.027954872708327957]
	TIME [epoch: 74.1 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057626316381722074		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.057626316381722074 | validation: 0.027030409899897453]
	TIME [epoch: 74.1 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04219584155819338		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.04219584155819338 | validation: 0.11548904177713201]
	TIME [epoch: 74.2 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058913580954823436		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.058913580954823436 | validation: 0.019878496986424056]
	TIME [epoch: 74.2 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09828745901823696		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.09828745901823696 | validation: 0.11116348874585312]
	TIME [epoch: 74.2 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06273891793014262		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.06273891793014262 | validation: 0.028539999140002704]
	TIME [epoch: 74.2 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104123968166993		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.04104123968166993 | validation: 0.048948266033851474]
	TIME [epoch: 74.1 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04357215678258471		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.04357215678258471 | validation: 0.03526117668806079]
	TIME [epoch: 74.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701011622782242		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.04701011622782242 | validation: 0.08636626795897034]
	TIME [epoch: 74.1 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525369045594818		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.19525369045594818 | validation: 0.17253458945698835]
	TIME [epoch: 74.2 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13098940992920255		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.13098940992920255 | validation: 0.043944402016155446]
	TIME [epoch: 74.2 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926552316860954		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.09926552316860954 | validation: 0.08830564072656517]
	TIME [epoch: 74.2 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341544585431415		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.08341544585431415 | validation: 0.03153770024086801]
	TIME [epoch: 74.2 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817214528870728		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.07817214528870728 | validation: 0.14244102867284153]
	TIME [epoch: 74.2 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900363866712234		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.11900363866712234 | validation: 0.04845215168143964]
	TIME [epoch: 74.2 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05169923360269678		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.05169923360269678 | validation: 0.0480817725636976]
	TIME [epoch: 74.2 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657343533856944		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.05657343533856944 | validation: 0.029042387428240585]
	TIME [epoch: 74.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469795253645708		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.05469795253645708 | validation: 0.07915074278749834]
	TIME [epoch: 74.2 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552151183608845		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.06552151183608845 | validation: 0.023426321831926902]
	TIME [epoch: 74.2 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0307481874976264		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.0307481874976264 | validation: 0.07420681188350824]
	TIME [epoch: 74.2 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647492750251114		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.0647492750251114 | validation: 0.02161947747602215]
	TIME [epoch: 74.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183731793810394		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.04183731793810394 | validation: 0.04955759232238776]
	TIME [epoch: 74.2 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472549578881695		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.06472549578881695 | validation: 0.03722009352755029]
	TIME [epoch: 74.2 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033391821609874556		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.033391821609874556 | validation: 0.2877106082402559]
	TIME [epoch: 74.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476916072391324		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.12476916072391324 | validation: 0.03827829054791017]
	TIME [epoch: 74.2 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034301684742546815		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.034301684742546815 | validation: 0.04274718729740394]
	TIME [epoch: 74.2 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045925321601251366		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.045925321601251366 | validation: 0.036180479465519375]
	TIME [epoch: 74.2 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036380268475280586		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.036380268475280586 | validation: 0.137275802621484]
	TIME [epoch: 74.2 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051912257465788016		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.051912257465788016 | validation: 0.058563833540273114]
	TIME [epoch: 74.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040703804476599666		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.040703804476599666 | validation: 0.028570660566427764]
	TIME [epoch: 74.2 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250900497789207		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.03250900497789207 | validation: 0.08485429611399486]
	TIME [epoch: 74.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045850484376302014		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.045850484376302014 | validation: 0.1717336676903093]
	TIME [epoch: 74.2 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653347811832134		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.08653347811832134 | validation: 0.02648353370757]
	TIME [epoch: 74.1 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020898099340657207		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.020898099340657207 | validation: 0.036017261187128044]
	TIME [epoch: 74.2 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815400069670326		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.03815400069670326 | validation: 0.02460201000607209]
	TIME [epoch: 74.2 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02733273473820006		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.02733273473820006 | validation: 0.09420186720907964]
	TIME [epoch: 74.2 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059284898236504895		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.059284898236504895 | validation: 0.027594512049448815]
	TIME [epoch: 74.2 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025287611814690233		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.025287611814690233 | validation: 0.022863016456745912]
	TIME [epoch: 74.2 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0218380724469707		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.0218380724469707 | validation: 0.0396995348959137]
	TIME [epoch: 74.2 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029160306927719846		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.029160306927719846 | validation: 0.01660045713141865]
	TIME [epoch: 74.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333994232544328		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.03333994232544328 | validation: 0.08430067617605244]
	TIME [epoch: 74.2 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201489290776527		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.03201489290776527 | validation: 0.014711136162936069]
	TIME [epoch: 74.2 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012333036480020949		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.012333036480020949 | validation: 0.03549155410845588]
	TIME [epoch: 74.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049963891757637775		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.049963891757637775 | validation: 0.014249925468333882]
	TIME [epoch: 74.2 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01452621550663424		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.01452621550663424 | validation: 0.029609425677512038]
	TIME [epoch: 74.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410835828374718		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.03410835828374718 | validation: 0.023050274099296723]
	TIME [epoch: 74.2 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01551621260835676		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.01551621260835676 | validation: 0.027356638363739333]
	TIME [epoch: 74.2 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055929647767567786		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.055929647767567786 | validation: 0.01719326851759179]
	TIME [epoch: 74.2 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886964869794257		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.02886964869794257 | validation: 0.025097225549579633]
	TIME [epoch: 74.2 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014767800170071718		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.014767800170071718 | validation: 0.018454375667344376]
	TIME [epoch: 74.1 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0192149777923305		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.0192149777923305 | validation: 0.03150312802432506]
	TIME [epoch: 74.2 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02230049692610579		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.02230049692610579 | validation: 0.03074648947964398]
	TIME [epoch: 74.1 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023017888915724566		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.023017888915724566 | validation: 0.03884805071839521]
	TIME [epoch: 74.1 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884853070230693		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.01884853070230693 | validation: 0.01691859238273967]
	TIME [epoch: 74.2 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024284751114656136		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.024284751114656136 | validation: 0.057126099418853896]
	TIME [epoch: 74.1 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029089873778542028		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.029089873778542028 | validation: 0.010681834306179437]
	TIME [epoch: 74.2 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019088353539490083		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.019088353539490083 | validation: 0.028376309844610325]
	TIME [epoch: 74.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040814373129929186		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.040814373129929186 | validation: 0.0621794862923426]
	TIME [epoch: 74.2 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03000360931314812		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.03000360931314812 | validation: 0.018565575695506688]
	TIME [epoch: 74.2 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015882329175897617		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.015882329175897617 | validation: 0.014628070635301565]
	TIME [epoch: 74.2 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021140845248801908		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.021140845248801908 | validation: 0.020571553173089382]
	TIME [epoch: 74.2 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015675174252392735		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.015675174252392735 | validation: 0.016952554144730337]
	TIME [epoch: 74.1 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041281469498097606		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.041281469498097606 | validation: 0.05033708410773877]
	TIME [epoch: 74.2 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02753229104767665		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.02753229104767665 | validation: 0.012435832741246208]
	TIME [epoch: 74.2 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018844188276678546		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.018844188276678546 | validation: 0.016964290106284023]
	TIME [epoch: 74.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023508465731172018		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.023508465731172018 | validation: 0.03243087162675024]
	TIME [epoch: 74.2 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133012681704387		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.03133012681704387 | validation: 0.023771196786799762]
	TIME [epoch: 74.2 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600625914801941		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.01600625914801941 | validation: 0.012307207292992908]
	TIME [epoch: 74.2 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021568770922630112		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.021568770922630112 | validation: 0.030497216700891422]
	TIME [epoch: 74.2 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028840002835002987		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.028840002835002987 | validation: 0.024587306975084246]
	TIME [epoch: 74.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021587023354343177		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.021587023354343177 | validation: 0.023754901151532663]
	TIME [epoch: 74.1 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023745334596915343		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.023745334596915343 | validation: 0.02239820250563504]
	TIME [epoch: 74.1 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022541981446469836		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.022541981446469836 | validation: 0.02995297415165906]
	TIME [epoch: 74.1 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0166242779887046		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.0166242779887046 | validation: 0.010739440529693733]
	TIME [epoch: 74.1 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008762631092016339		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.008762631092016339 | validation: 0.02474367702611694]
	TIME [epoch: 74.2 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02947995755870028		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.02947995755870028 | validation: 0.06716938621443833]
	TIME [epoch: 74.2 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028958368427893674		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.028958368427893674 | validation: 0.01377463937256521]
	TIME [epoch: 74.2 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008716392374011325		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.008716392374011325 | validation: 0.014563447665118318]
	TIME [epoch: 74.2 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01170224704766439		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.01170224704766439 | validation: 0.029526382330600225]
	TIME [epoch: 74.2 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031737853495448075		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.031737853495448075 | validation: 0.015862702310839805]
	TIME [epoch: 74.2 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825151870401036		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.03825151870401036 | validation: 0.02845044312664575]
	TIME [epoch: 74.1 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595445851510731		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.03595445851510731 | validation: 0.011142625209823374]
	TIME [epoch: 74.2 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012493144565569743		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.012493144565569743 | validation: 0.018452230179056756]
	TIME [epoch: 74.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01443880723562671		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.01443880723562671 | validation: 0.009758549166696719]
	TIME [epoch: 74.2 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01784689972034203		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.01784689972034203 | validation: 0.01655608800249975]
	TIME [epoch: 74.2 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023746564429170836		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.023746564429170836 | validation: 0.032246001461879614]
	TIME [epoch: 74.1 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015046415287734025		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.015046415287734025 | validation: 0.009691772133779801]
	TIME [epoch: 74.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008906195423231665		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.008906195423231665 | validation: 0.007780714393274509]
	TIME [epoch: 74.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240704_134627/states/model_phi1_1a_v_mmd3_1214.pth
	Model improved!!!
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025773820043132705		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.025773820043132705 | validation: 0.06198740409185702]
	TIME [epoch: 74.2 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244644237133262		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.02244644237133262 | validation: 0.015390326056132959]
	TIME [epoch: 74.2 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02330552274180833		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.02330552274180833 | validation: 0.026884847424674112]
	TIME [epoch: 74.2 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013075839361603812		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.013075839361603812 | validation: 0.020490808092479582]
	TIME [epoch: 74.2 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032542564824789594		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.032542564824789594 | validation: 0.018369209917043994]
	TIME [epoch: 74.2 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013892856106529666		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.013892856106529666 | validation: 0.015632001441026083]
	TIME [epoch: 74.2 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013878192722752612		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.013878192722752612 | validation: 0.02146375819137955]
	TIME [epoch: 74.2 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016920085346221192		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.016920085346221192 | validation: 0.018924662746844845]
	TIME [epoch: 74.2 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012047622014108885		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.012047622014108885 | validation: 0.015820801161724816]
	TIME [epoch: 74.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015389506330880025		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.015389506330880025 | validation: 0.021786267002656304]
	TIME [epoch: 74.2 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014693346409059083		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.014693346409059083 | validation: 0.01652433462092579]
	TIME [epoch: 74.1 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013819183679264532		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.013819183679264532 | validation: 0.0795261201539436]
	TIME [epoch: 74.2 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968162866542503		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.04968162866542503 | validation: 0.03160093678289555]
	TIME [epoch: 74.2 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01556063888923157		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.01556063888923157 | validation: 0.014286571295712923]
	TIME [epoch: 74.2 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012728005254962553		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.012728005254962553 | validation: 0.01937366613888529]
	TIME [epoch: 74.2 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02096305953866772		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.02096305953866772 | validation: 0.015402401343843939]
	TIME [epoch: 74.2 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026355019229078874		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.026355019229078874 | validation: 0.03097511396304757]
	TIME [epoch: 74.2 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01526727676336981		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.01526727676336981 | validation: 0.01678365271257846]
	TIME [epoch: 74.2 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011319778283370425		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.011319778283370425 | validation: 0.008783791574635262]
	TIME [epoch: 74.1 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014928877439932584		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.014928877439932584 | validation: 0.045337588809153326]
	TIME [epoch: 74.2 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029281390134674762		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.029281390134674762 | validation: 0.02156599516296561]
	TIME [epoch: 74.2 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010537736979594198		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.010537736979594198 | validation: 0.011336460155486538]
	TIME [epoch: 74.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012380030449233616		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.012380030449233616 | validation: 0.01227462041458487]
	TIME [epoch: 74.1 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014582861537932548		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.014582861537932548 | validation: 0.042874940949381504]
	TIME [epoch: 74.2 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031246692021797254		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.031246692021797254 | validation: 0.010758155810083825]
	TIME [epoch: 74.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009017121629581959		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.009017121629581959 | validation: 0.010152483758153462]
	TIME [epoch: 74.2 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010101248224826973		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.010101248224826973 | validation: 0.015801250911212178]
	TIME [epoch: 74.1 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023453473515073486		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.023453473515073486 | validation: 0.010315909008972786]
	TIME [epoch: 74.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009653323703623873		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.009653323703623873 | validation: 0.009663746362083737]
	TIME [epoch: 74.1 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007800953047537984		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.007800953047537984 | validation: 0.023804475925558913]
	TIME [epoch: 74.1 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027690402709749852		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.027690402709749852 | validation: 0.02827387867026026]
	TIME [epoch: 74.2 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945238030187694		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.01945238030187694 | validation: 0.020876132101225516]
	TIME [epoch: 74.2 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013042866640080813		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.013042866640080813 | validation: 0.011045269661297496]
	TIME [epoch: 74.2 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00886641412110704		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.00886641412110704 | validation: 0.010625970026691944]
	TIME [epoch: 74.1 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014535770288113464		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.014535770288113464 | validation: 0.02660757381812445]
	TIME [epoch: 74.2 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015496702296869863		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.015496702296869863 | validation: 0.010728281299731295]
	TIME [epoch: 74.2 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008177360489096366		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.008177360489096366 | validation: 0.015141718099986004]
	TIME [epoch: 74.2 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825895173349399		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.01825895173349399 | validation: 0.01489807254466335]
	TIME [epoch: 74.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0120677552255575		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.0120677552255575 | validation: 0.011577103741723434]
	TIME [epoch: 74.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00902809104405517		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.00902809104405517 | validation: 0.019333188833946115]
	TIME [epoch: 74.1 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01622782888446609		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.01622782888446609 | validation: 0.010105149369255566]
	TIME [epoch: 74.1 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008643638665482963		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.008643638665482963 | validation: 0.015450062614049485]
	TIME [epoch: 74.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0249744856886963		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.0249744856886963 | validation: 0.02609652955931309]
	TIME [epoch: 74.2 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014966082737584525		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.014966082737584525 | validation: 0.013156879576449315]
	TIME [epoch: 74.2 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010189222642609958		[learning rate: 0.0058581]
