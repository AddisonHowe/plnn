Args:
Namespace(name='model_phi1_1a_v_kl5', outdir='out/model_training/model_phi1_1a_v_kl5', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4264884355

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.936124898607478		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 11.936124898607478 | validation: 11.755163273899962]
	TIME [epoch: 102 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.625460989092124		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 11.625460989092124 | validation: 11.758355292887625]
	TIME [epoch: 9.78 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.11424030875094		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 11.11424030875094 | validation: 11.310604974760405]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.931011487852405		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 10.931011487852405 | validation: 11.34654034841665]
	TIME [epoch: 9.68 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.539561996891335		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 11.539561996891335 | validation: 10.601071492370892]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.02171381485594		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 10.02171381485594 | validation: 10.459557819538052]
	TIME [epoch: 9.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.485129087533807		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 10.485129087533807 | validation: 10.255127214425205]
	TIME [epoch: 9.71 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.910941070984773		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 9.910941070984773 | validation: 9.082240939685157]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.149508768994696		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 9.149508768994696 | validation: 10.125212226115806]
	TIME [epoch: 9.68 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.026135946727525		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 9.026135946727525 | validation: 8.635846626037559]
	TIME [epoch: 9.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.455474419733829		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 9.455474419733829 | validation: 8.670037066619424]
	TIME [epoch: 9.73 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.437564117862031		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 8.437564117862031 | validation: 8.514285464113406]
	TIME [epoch: 9.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.997594458031164		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 8.997594458031164 | validation: 9.391094009858014]
	TIME [epoch: 9.69 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.243545347041373		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 8.243545347041373 | validation: 7.698516114401626]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.635719768740601		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 7.635719768740601 | validation: 7.593829193682807]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.437414636145059		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 8.437414636145059 | validation: 7.660559594696222]
	TIME [epoch: 9.73 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.271434385471547		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 8.271434385471547 | validation: 10.15301008922685]
	TIME [epoch: 9.68 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.347545645314543		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 8.347545645314543 | validation: 7.033153629051267]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.258608651574653		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 7.258608651574653 | validation: 7.235433039470218]
	TIME [epoch: 9.69 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.527429723942902		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 7.527429723942902 | validation: 7.366613127635981]
	TIME [epoch: 9.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.928521290006057		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 6.928521290006057 | validation: 7.445842979254342]
	TIME [epoch: 9.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.854322107812525		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 6.854322107812525 | validation: 6.767791215438201]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.868144613737152		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 6.868144613737152 | validation: 6.762908708360879]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.124025071414531		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 7.124025071414531 | validation: 7.451748000021538]
	TIME [epoch: 9.68 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.575470964072093		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 8.575470964072093 | validation: 9.71302977187554]
	TIME [epoch: 9.73 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.570554979292915		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 7.570554979292915 | validation: 6.773545206421215]
	TIME [epoch: 9.69 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.956321108163296		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 6.956321108163296 | validation: 6.905783357050331]
	TIME [epoch: 9.68 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.51837263040431		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 6.51837263040431 | validation: 8.476066919154238]
	TIME [epoch: 9.69 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.238883992857495		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 7.238883992857495 | validation: 6.949996380049576]
	TIME [epoch: 9.68 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.78327318544301		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 6.78327318544301 | validation: 7.898183545322487]
	TIME [epoch: 9.73 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.815407319220896		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 7.815407319220896 | validation: 7.344603640290394]
	TIME [epoch: 9.69 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8402827496428875		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 6.8402827496428875 | validation: 8.056229902510383]
	TIME [epoch: 9.69 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.1165182719462114		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 7.1165182719462114 | validation: 7.200411727281797]
	TIME [epoch: 9.68 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.302744373709034		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 7.302744373709034 | validation: 7.686219043198848]
	TIME [epoch: 9.69 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.8605323398920826		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 7.8605323398920826 | validation: 7.278873935739063]
	TIME [epoch: 9.72 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.423160834775391		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 6.423160834775391 | validation: 6.923750434005478]
	TIME [epoch: 9.69 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.104821055072774		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 6.104821055072774 | validation: 5.451056227020944]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7589887769336165		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 6.7589887769336165 | validation: 6.412915553147425]
	TIME [epoch: 9.68 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5902035169508215		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 6.5902035169508215 | validation: 5.516899019947152]
	TIME [epoch: 9.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.92584635027556		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 5.92584635027556 | validation: 5.433220166502812]
	TIME [epoch: 9.71 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7453362441842035		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 5.7453362441842035 | validation: 6.944905680684196]
	TIME [epoch: 9.68 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.795601254929872		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 5.795601254929872 | validation: 5.0143325501577785]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.101555290114517		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 6.101555290114517 | validation: 5.3822003844589075]
	TIME [epoch: 9.68 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.267933632890244		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 5.267933632890244 | validation: 5.547745196553315]
	TIME [epoch: 9.72 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.645018319091229		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 5.645018319091229 | validation: 5.732615476846129]
	TIME [epoch: 9.69 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.985066919506344		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 4.985066919506344 | validation: 7.723184827407797]
	TIME [epoch: 9.68 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760677327561245		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 5.760677327561245 | validation: 5.434652081831793]
	TIME [epoch: 9.67 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6056655915697515		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 5.6056655915697515 | validation: 4.861043172624087]
	TIME [epoch: 9.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85964716868725		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 4.85964716868725 | validation: 5.872860752439432]
	TIME [epoch: 9.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.073584621613925		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 5.073584621613925 | validation: 4.691590376125718]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.098920976297502		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.098920976297502 | validation: 5.637898714934129]
	TIME [epoch: 9.67 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.936446025480839		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 4.936446025480839 | validation: 4.304060335623847]
	TIME [epoch: 9.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.347157804763906		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 5.347157804763906 | validation: 5.276637150251556]
	TIME [epoch: 9.68 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.086830943068084		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 5.086830943068084 | validation: 4.580153292977098]
	TIME [epoch: 9.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.964578076376263		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 4.964578076376263 | validation: 3.8478378235002975]
	TIME [epoch: 9.96 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.956515204703626		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 4.956515204703626 | validation: 4.718731591277052]
	TIME [epoch: 9.69 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.97735131313034		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 4.97735131313034 | validation: 4.9117428367278695]
	TIME [epoch: 9.68 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.024764293069284		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 4.024764293069284 | validation: 4.449967357928196]
	TIME [epoch: 9.72 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7691662371642396		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 3.7691662371642396 | validation: 5.4201247510607455]
	TIME [epoch: 9.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8346501869587097		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 3.8346501869587097 | validation: 3.2072511682958726]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0841736036561676		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 4.0841736036561676 | validation: 4.155286266329966]
	TIME [epoch: 9.69 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7086516723518166		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 3.7086516723518166 | validation: 2.918623897974373]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.397642376326722		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 3.397642376326722 | validation: 3.8992417823929895]
	TIME [epoch: 9.73 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.129710565375607		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 3.129710565375607 | validation: 2.7601985416671613]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8172064020227428		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 2.8172064020227428 | validation: 9.021999279607591]
	TIME [epoch: 9.68 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836902201829854		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 5.836902201829854 | validation: 3.238315162189244]
	TIME [epoch: 9.68 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8572664983582783		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 2.8572664983582783 | validation: 2.4589465610566217]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.265704524286124		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 3.265704524286124 | validation: 2.846092977503459]
	TIME [epoch: 9.72 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7807971253800536		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 2.7807971253800536 | validation: 2.5556314342878457]
	TIME [epoch: 9.67 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6481524780817107		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 2.6481524780817107 | validation: 2.7356921265778746]
	TIME [epoch: 9.67 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506745869108842		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 2.506745869108842 | validation: 3.573081564852779]
	TIME [epoch: 9.67 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8831618180203242		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 2.8831618180203242 | validation: 2.6874847035247598]
	TIME [epoch: 9.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5579193665556694		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 2.5579193665556694 | validation: 2.2280668461057953]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386543979805872		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 2.386543979805872 | validation: 2.4527580475762987]
	TIME [epoch: 9.69 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6077372239856036		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 2.6077372239856036 | validation: 3.2910458894517842]
	TIME [epoch: 9.68 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.860214484421938		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 2.860214484421938 | validation: 2.1725973514259933]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6801136030388415		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 2.6801136030388415 | validation: 3.556581968629513]
	TIME [epoch: 9.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21907850051424		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 3.21907850051424 | validation: 2.544519851885191]
	TIME [epoch: 9.68 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4003990906351493		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 2.4003990906351493 | validation: 2.3521747634149817]
	TIME [epoch: 9.67 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.464744158377305		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 2.464744158377305 | validation: 2.907937078116646]
	TIME [epoch: 9.69 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5417497501780444		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 2.5417497501780444 | validation: 2.397870011029686]
	TIME [epoch: 9.67 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.403689352156175		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 2.403689352156175 | validation: 2.5967838777070886]
	TIME [epoch: 9.71 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4140801017176985		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 2.4140801017176985 | validation: 2.715610659406509]
	TIME [epoch: 9.68 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5617886620824706		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 2.5617886620824706 | validation: 2.189534214343414]
	TIME [epoch: 9.67 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6267023077504694		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 3.6267023077504694 | validation: 2.652616283574684]
	TIME [epoch: 9.67 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3777374936413214		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 2.3777374936413214 | validation: 2.2374332658348317]
	TIME [epoch: 9.68 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299049340523466		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 2.299049340523466 | validation: 2.4996814927938615]
	TIME [epoch: 9.69 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4123769282819096		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 2.4123769282819096 | validation: 2.1872046919719805]
	TIME [epoch: 9.67 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333674553270508		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 2.333674553270508 | validation: 2.229953166841972]
	TIME [epoch: 9.67 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4953388555222658		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 2.4953388555222658 | validation: 2.199411437952314]
	TIME [epoch: 9.66 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3331380510032256		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 2.3331380510032256 | validation: 2.210579081266549]
	TIME [epoch: 9.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341630436760541		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 2.341630436760541 | validation: 2.3072032189362295]
	TIME [epoch: 9.67 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432264752744683		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 2.432264752744683 | validation: 2.6814497645308917]
	TIME [epoch: 9.66 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2922036425144183		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 2.2922036425144183 | validation: 2.0534149441370895]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6100370322467863		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 2.6100370322467863 | validation: 2.198060541677041]
	TIME [epoch: 9.69 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3073180104267967		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 2.3073180104267967 | validation: 2.511531987643242]
	TIME [epoch: 9.73 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.433442842997283		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 2.433442842997283 | validation: 2.2356444910602167]
	TIME [epoch: 9.69 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2588251885167865		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 2.2588251885167865 | validation: 2.778122241338427]
	TIME [epoch: 9.68 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327650880120444		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 2.327650880120444 | validation: 2.611576523148777]
	TIME [epoch: 9.69 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.185318885070358		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 2.185318885070358 | validation: 2.14476882151387]
	TIME [epoch: 9.69 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109366801583384		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 2.109366801583384 | validation: 4.161318622144594]
	TIME [epoch: 9.73 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.961838476578581		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 2.961838476578581 | validation: 2.7337754203607965]
	TIME [epoch: 9.69 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250479680343728		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 2.250479680343728 | validation: 2.4420038603931395]
	TIME [epoch: 9.69 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2974622013081314		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 2.2974622013081314 | validation: 2.005725458568725]
	TIME [epoch: 9.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.259214326965799		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 2.259214326965799 | validation: 2.091191320591823]
	TIME [epoch: 9.71 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332363400613973		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 2.332363400613973 | validation: 2.0818398702938294]
	TIME [epoch: 9.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2697339189720283		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 2.2697339189720283 | validation: 2.2641163891320364]
	TIME [epoch: 9.68 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32459565272751		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 2.32459565272751 | validation: 2.2544167983714822]
	TIME [epoch: 9.68 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2939262429827583		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 2.2939262429827583 | validation: 2.178137715651991]
	TIME [epoch: 9.68 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.212961001951163		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 2.212961001951163 | validation: 2.1635705652135844]
	TIME [epoch: 9.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231514681127626		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 2.231514681127626 | validation: 2.318660671803223]
	TIME [epoch: 9.69 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7075347838929584		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 2.7075347838929584 | validation: 2.2045493780030117]
	TIME [epoch: 9.68 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316194371069571		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 2.316194371069571 | validation: 2.4994496093649503]
	TIME [epoch: 9.68 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1874324413747273		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 2.1874324413747273 | validation: 2.334833292366344]
	TIME [epoch: 9.68 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276144753592772		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 2.276144753592772 | validation: 2.195206331335057]
	TIME [epoch: 9.72 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1745041901433426		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 2.1745041901433426 | validation: 2.092043680545379]
	TIME [epoch: 9.68 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.202848681686171		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 2.202848681686171 | validation: 1.9871084140623998]
	TIME [epoch: 9.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306025744600494		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 2.306025744600494 | validation: 2.280189867578529]
	TIME [epoch: 9.67 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.197900923878983		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 2.197900923878983 | validation: 2.0949573562246924]
	TIME [epoch: 9.68 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.217796992760221		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 2.217796992760221 | validation: 2.12485222271415]
	TIME [epoch: 9.72 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5749917408489473		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 2.5749917408489473 | validation: 2.181865389724813]
	TIME [epoch: 9.68 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1977733139220668		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 2.1977733139220668 | validation: 2.0025730564145583]
	TIME [epoch: 9.68 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2145797833481558		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 2.2145797833481558 | validation: 1.9158517752570723]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7261446741573034		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 2.7261446741573034 | validation: 2.2339491540213747]
	TIME [epoch: 9.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2802138932423803		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 2.2802138932423803 | validation: 6.901639783529365]
	TIME [epoch: 9.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.853805406984257		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 7.853805406984257 | validation: 7.398099516857067]
	TIME [epoch: 9.68 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.114060843650494		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 7.114060843650494 | validation: 7.106689131686305]
	TIME [epoch: 9.67 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.962827242900923		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 6.962827242900923 | validation: 7.514581506422763]
	TIME [epoch: 9.69 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.0984129059768915		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 7.0984129059768915 | validation: 7.280153252552162]
	TIME [epoch: 9.72 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.0118830086303845		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 7.0118830086303845 | validation: 6.183809967213587]
	TIME [epoch: 9.68 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.234055362795578		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 4.234055362795578 | validation: 2.8050224164899102]
	TIME [epoch: 9.68 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366614736794147		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 2.366614736794147 | validation: 2.243850175240472]
	TIME [epoch: 9.67 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.127454010389913		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 2.127454010389913 | validation: 2.014070636293045]
	TIME [epoch: 9.68 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0759222852844736		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 2.0759222852844736 | validation: 2.13639642401099]
	TIME [epoch: 9.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360735835439325		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 2.360735835439325 | validation: 2.1422364005144083]
	TIME [epoch: 9.69 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2063417934586336		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 2.2063417934586336 | validation: 1.8767687811798703]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9492670956566656		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 1.9492670956566656 | validation: 1.7620038142800651]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.181166490797876		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 2.181166490797876 | validation: 2.2165683318885834]
	TIME [epoch: 9.68 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.629547232957915		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 2.629547232957915 | validation: 1.9841222910794625]
	TIME [epoch: 9.71 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098730110624218		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 2.098730110624218 | validation: 2.7937732358887155]
	TIME [epoch: 9.67 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2156908036104124		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 2.2156908036104124 | validation: 2.1629909216323964]
	TIME [epoch: 9.67 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1379166308958637		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 2.1379166308958637 | validation: 1.9620237279623631]
	TIME [epoch: 9.67 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1206706200929926		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 2.1206706200929926 | validation: 2.2693034502123774]
	TIME [epoch: 9.72 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087444053982992		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 2.087444053982992 | validation: 2.1327180730932325]
	TIME [epoch: 9.68 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.136411740502692		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 2.136411740502692 | validation: 2.078334073835924]
	TIME [epoch: 9.67 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088420586397467		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 2.088420586397467 | validation: 1.9791433105213967]
	TIME [epoch: 9.67 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0420491859324557		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 2.0420491859324557 | validation: 2.1434051411468475]
	TIME [epoch: 9.67 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4805004861323696		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 2.4805004861323696 | validation: 1.8321179055763817]
	TIME [epoch: 9.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9314043854840612		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 1.9314043854840612 | validation: 1.7719577441184904]
	TIME [epoch: 9.69 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7929158877554983		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 1.7929158877554983 | validation: 1.9868351599321599]
	TIME [epoch: 9.67 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4887350976404936		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 2.4887350976404936 | validation: 1.9014316545576135]
	TIME [epoch: 9.68 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8096307496331967		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 1.8096307496331967 | validation: 2.0299191725961365]
	TIME [epoch: 9.67 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9027794350286418		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 2.9027794350286418 | validation: 1.8201646588787375]
	TIME [epoch: 9.72 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8657607319750236		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 1.8657607319750236 | validation: 1.842125388515563]
	TIME [epoch: 9.68 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4163659163178193		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 2.4163659163178193 | validation: 1.8380279381126599]
	TIME [epoch: 9.96 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9222169334467365		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 1.9222169334467365 | validation: 2.397670464645083]
	TIME [epoch: 9.68 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9692060581849866		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 1.9692060581849866 | validation: 2.7381197906854418]
	TIME [epoch: 9.68 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0094062316275227		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 2.0094062316275227 | validation: 1.962616799939719]
	TIME [epoch: 9.73 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9242297722319908		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 1.9242297722319908 | validation: 1.9943300198789768]
	TIME [epoch: 9.68 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8774641309529136		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 1.8774641309529136 | validation: 1.7993331483252466]
	TIME [epoch: 9.68 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7282192122322746		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 1.7282192122322746 | validation: 2.755936544592566]
	TIME [epoch: 9.68 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1458557415326887		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 2.1458557415326887 | validation: 1.9714061466267507]
	TIME [epoch: 9.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7444242618028993		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 1.7444242618028993 | validation: 2.130124295147657]
	TIME [epoch: 9.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0478079897915284		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 2.0478079897915284 | validation: 2.157158197835977]
	TIME [epoch: 9.68 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288008007586655		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 2.288008007586655 | validation: 1.7810856320083317]
	TIME [epoch: 9.68 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.986339144315968		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 1.986339144315968 | validation: 1.8515137695595336]
	TIME [epoch: 9.67 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9465453539054203		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 1.9465453539054203 | validation: 2.008603264711883]
	TIME [epoch: 9.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9533342996105203		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 1.9533342996105203 | validation: 1.9920335317661804]
	TIME [epoch: 9.68 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.884278695336941		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 1.884278695336941 | validation: 1.8348902493114454]
	TIME [epoch: 9.68 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886893834881005		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 1.886893834881005 | validation: 1.8828154159208608]
	TIME [epoch: 9.68 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7946621300228045		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 1.7946621300228045 | validation: 1.8281612412248696]
	TIME [epoch: 9.68 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9449230121918482		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 1.9449230121918482 | validation: 1.6809846600806153]
	TIME [epoch: 9.72 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8109551016794527		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 1.8109551016794527 | validation: 1.770392057716577]
	TIME [epoch: 9.68 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.82278268943295		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 1.82278268943295 | validation: 2.07900559810793]
	TIME [epoch: 9.67 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8984869589127669		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 1.8984869589127669 | validation: 1.7055742628427968]
	TIME [epoch: 9.67 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.70743085782799		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 1.70743085782799 | validation: 1.6336214604381796]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6537620498717702		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 1.6537620498717702 | validation: 2.2473077961330254]
	TIME [epoch: 9.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7586288044282008		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 1.7586288044282008 | validation: 1.7355868489219806]
	TIME [epoch: 9.68 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6970075377320406		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 1.6970075377320406 | validation: 2.0795893686435307]
	TIME [epoch: 9.68 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1140598127991552		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 2.1140598127991552 | validation: 1.8132036214400182]
	TIME [epoch: 9.68 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7499295838974698		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 1.7499295838974698 | validation: 1.6233137998239546]
	TIME [epoch: 9.71 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7124466583938223		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 1.7124466583938223 | validation: 1.6295588458173635]
	TIME [epoch: 9.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.745530962898001		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 1.745530962898001 | validation: 1.672228912055655]
	TIME [epoch: 9.68 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6211369303016443		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 1.6211369303016443 | validation: 1.7653462407873501]
	TIME [epoch: 9.67 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8871948839544146		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 1.8871948839544146 | validation: 1.5910734444443349]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7905125864990525		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 1.7905125864990525 | validation: 1.6609481146586131]
	TIME [epoch: 9.72 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.625655402681502		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 1.625655402681502 | validation: 1.8573742372040063]
	TIME [epoch: 9.68 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.688156259188144		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 1.688156259188144 | validation: 1.447703213230485]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4727192275593186		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 1.4727192275593186 | validation: 2.2287271559815034]
	TIME [epoch: 9.67 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8905714556038076		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 1.8905714556038076 | validation: 1.7356511613433965]
	TIME [epoch: 9.67 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7964182036333698		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 1.7964182036333698 | validation: 1.753440375395202]
	TIME [epoch: 9.71 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6847804785397487		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 1.6847804785397487 | validation: 1.9191381098274407]
	TIME [epoch: 9.67 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7084207368442161		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 1.7084207368442161 | validation: 2.0626589365111103]
	TIME [epoch: 9.67 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.851617194452166		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 1.851617194452166 | validation: 1.732537769722274]
	TIME [epoch: 9.67 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.715556979114507		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 1.715556979114507 | validation: 1.495553393178683]
	TIME [epoch: 9.68 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5943025750441708		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 1.5943025750441708 | validation: 2.2219897888910944]
	TIME [epoch: 9.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6739968590426428		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 1.6739968590426428 | validation: 1.462735829805975]
	TIME [epoch: 9.67 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.763295331000903		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 1.763295331000903 | validation: 1.8088983579423297]
	TIME [epoch: 9.67 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5374328375336124		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 1.5374328375336124 | validation: 1.8700071381920735]
	TIME [epoch: 9.67 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6184117154574715		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 1.6184117154574715 | validation: 1.5985940818328879]
	TIME [epoch: 9.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6463144288890428		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 1.6463144288890428 | validation: 2.4522597964673323]
	TIME [epoch: 111 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8272011765079386		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 1.8272011765079386 | validation: 2.0182612838829628]
	TIME [epoch: 19.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.544632691764677		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 1.544632691764677 | validation: 1.6138858981322248]
	TIME [epoch: 19.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5815686787012593		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 1.5815686787012593 | validation: 1.6561069436934512]
	TIME [epoch: 19.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5006479249971678		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 1.5006479249971678 | validation: 2.052120670979945]
	TIME [epoch: 19.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6408680454738547		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 1.6408680454738547 | validation: 1.46857171905878]
	TIME [epoch: 19.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6230968268356365		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 1.6230968268356365 | validation: 1.402365703036491]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5221734955912154		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 1.5221734955912154 | validation: 1.5701534929175127]
	TIME [epoch: 19.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6184520348187919		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 1.6184520348187919 | validation: 1.3852567487574206]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6044118138343118		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 1.6044118138343118 | validation: 1.7639518451855207]
	TIME [epoch: 19.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4637032645875978		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 1.4637032645875978 | validation: 1.4442913313471346]
	TIME [epoch: 19.1 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.647674214919911		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 1.647674214919911 | validation: 1.9631652868064153]
	TIME [epoch: 19.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5520949159932376		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 1.5520949159932376 | validation: 1.4090795196980674]
	TIME [epoch: 19.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4383244390841656		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 1.4383244390841656 | validation: 1.3766658397965663]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5533530397280635		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 1.5533530397280635 | validation: 1.4388174391535233]
	TIME [epoch: 19.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4653003446972068		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 1.4653003446972068 | validation: 1.610841899634722]
	TIME [epoch: 19.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4021370786186194		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 1.4021370786186194 | validation: 1.5269170006722397]
	TIME [epoch: 19.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5322658020514108		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 1.5322658020514108 | validation: 1.3562034518159685]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5509617378473888		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 1.5509617378473888 | validation: 1.690778433078353]
	TIME [epoch: 19.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5874328781332634		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 1.5874328781332634 | validation: 1.6281062531570059]
	TIME [epoch: 19.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4787864026238784		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 1.4787864026238784 | validation: 1.5320719351170853]
	TIME [epoch: 19.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43886233969925		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 1.43886233969925 | validation: 1.828195964413863]
	TIME [epoch: 19.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4856289062098935		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 1.4856289062098935 | validation: 1.1161047543400304]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.328703769800102		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 1.328703769800102 | validation: 1.5080701287948504]
	TIME [epoch: 19.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4698790545801466		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 1.4698790545801466 | validation: 1.684911108229591]
	TIME [epoch: 19.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4083093862302272		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 1.4083093862302272 | validation: 1.1576551303072464]
	TIME [epoch: 19.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2728711192394866		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 1.2728711192394866 | validation: 1.1360596113360608]
	TIME [epoch: 19.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2844076192188134		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 1.2844076192188134 | validation: 1.7811243446004617]
	TIME [epoch: 19.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4645088845049727		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 1.4645088845049727 | validation: 1.2006075806866454]
	TIME [epoch: 19.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569735946098156		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 1.1569735946098156 | validation: 1.0812029064810884]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2686959257896286		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 1.2686959257896286 | validation: 1.6696174050530153]
	TIME [epoch: 19.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2967332841941392		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 1.2967332841941392 | validation: 1.4056113597540278]
	TIME [epoch: 19.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301836913996055		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 1.301836913996055 | validation: 0.9987298991220046]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2004455889106933		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 1.2004455889106933 | validation: 1.3724061469408433]
	TIME [epoch: 19.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2330097479644024		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 1.2330097479644024 | validation: 1.0833206228306962]
	TIME [epoch: 19.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2696716205906298		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 1.2696716205906298 | validation: 2.2955788687560608]
	TIME [epoch: 19.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4072766474664866		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 1.4072766474664866 | validation: 1.2767687545463962]
	TIME [epoch: 19.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2613186910096426		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 1.2613186910096426 | validation: 1.0668968751242511]
	TIME [epoch: 19.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0673248584967772		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 1.0673248584967772 | validation: 1.3631550001179433]
	TIME [epoch: 19.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391184423207802		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 1.391184423207802 | validation: 1.3312883389843169]
	TIME [epoch: 19.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2277939703539213		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 1.2277939703539213 | validation: 0.9823411072825275]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933973212801987		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 1.1933973212801987 | validation: 0.9221872333689926]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0517307406349157		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 1.0517307406349157 | validation: 1.0234310650178018]
	TIME [epoch: 19.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1803350795703658		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 1.1803350795703658 | validation: 1.204455551075323]
	TIME [epoch: 19.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702372985720342		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 1.1702372985720342 | validation: 1.3883504363920047]
	TIME [epoch: 19.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1680474004518235		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 1.1680474004518235 | validation: 1.2624642335222074]
	TIME [epoch: 19.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2038115766615314		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 1.2038115766615314 | validation: 1.0479877684057228]
	TIME [epoch: 19.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867363383271973		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 1.0867363383271973 | validation: 1.1567869347097015]
	TIME [epoch: 19.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6449415915004288		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 1.6449415915004288 | validation: 1.2933737722389398]
	TIME [epoch: 19.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196507316114419		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 1.196507316114419 | validation: 0.8441172835473274]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1445070068581251		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 1.1445070068581251 | validation: 0.9586107523954847]
	TIME [epoch: 19.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9371698843524585		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.9371698843524585 | validation: 1.3532096383365433]
	TIME [epoch: 19.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9883087230486338		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.9883087230486338 | validation: 1.1422044697237927]
	TIME [epoch: 19.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1540889255282174		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 1.1540889255282174 | validation: 1.2071197399141749]
	TIME [epoch: 19.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2096630756585596		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 1.2096630756585596 | validation: 1.6720710318511303]
	TIME [epoch: 19.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1095704074163892		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 1.1095704074163892 | validation: 0.925717351216897]
	TIME [epoch: 19.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1141495554020457		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 1.1141495554020457 | validation: 0.9823992480217432]
	TIME [epoch: 19.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1103672353175837		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.1103672353175837 | validation: 1.1371835858875659]
	TIME [epoch: 19.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0438140354942116		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 1.0438140354942116 | validation: 0.9330416993282643]
	TIME [epoch: 19.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0952724123179685		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 1.0952724123179685 | validation: 0.8677025793454598]
	TIME [epoch: 19.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9819563207881299		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.9819563207881299 | validation: 1.2912962456418735]
	TIME [epoch: 19.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0773891430595726		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 1.0773891430595726 | validation: 1.184433902988708]
	TIME [epoch: 19.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0827517677444227		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 1.0827517677444227 | validation: 1.2198669384737975]
	TIME [epoch: 19.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1153261457716246		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 1.1153261457716246 | validation: 1.0167518979736916]
	TIME [epoch: 19.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9966199529529058		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.9966199529529058 | validation: 0.937986676997143]
	TIME [epoch: 19.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2926136955126502		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 1.2926136955126502 | validation: 1.108803981419464]
	TIME [epoch: 19.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090255754734105		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 1.090255754734105 | validation: 1.1677734047173889]
	TIME [epoch: 19.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9252676565827147		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.9252676565827147 | validation: 1.7014398683908774]
	TIME [epoch: 19.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3375507944600065		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 1.3375507944600065 | validation: 0.9624095119812348]
	TIME [epoch: 19.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0516049445030347		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 1.0516049445030347 | validation: 0.9561607334569455]
	TIME [epoch: 19.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0036012201689908		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 1.0036012201689908 | validation: 1.09427356748721]
	TIME [epoch: 19.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0706034857490168		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 1.0706034857490168 | validation: 2.21549070425338]
	TIME [epoch: 19.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3626114991972924		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 1.3626114991972924 | validation: 0.9361031371561472]
	TIME [epoch: 19.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0644226039161218		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 1.0644226039161218 | validation: 0.9560950123913077]
	TIME [epoch: 19.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9796536916915461		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.9796536916915461 | validation: 0.7918499771410187]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0491915525598166		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 1.0491915525598166 | validation: 1.2687942819575837]
	TIME [epoch: 19.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0812223126475775		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 1.0812223126475775 | validation: 0.8769607888654238]
	TIME [epoch: 19.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0011884655841918		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 1.0011884655841918 | validation: 1.1413975716311482]
	TIME [epoch: 19.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666811174529602		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 1.0666811174529602 | validation: 0.9636518103142975]
	TIME [epoch: 19.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248285175613585		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 1.0248285175613585 | validation: 0.8092132493321227]
	TIME [epoch: 19.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8271850911698511		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.8271850911698511 | validation: 1.4484550970455587]
	TIME [epoch: 19.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.200261702601877		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 1.200261702601877 | validation: 0.7596410648874694]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1172013518667472		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 1.1172013518667472 | validation: 1.1522616389286577]
	TIME [epoch: 19.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077821823111623		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 1.0077821823111623 | validation: 0.9855089408792633]
	TIME [epoch: 19.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0439910090396798		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 1.0439910090396798 | validation: 1.0287816633918774]
	TIME [epoch: 19.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275572283506285		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 1.0275572283506285 | validation: 0.9057833643965696]
	TIME [epoch: 19.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9973822889798817		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.9973822889798817 | validation: 1.0389764271228208]
	TIME [epoch: 19.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0991689992640747		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 1.0991689992640747 | validation: 1.1576727681747452]
	TIME [epoch: 19.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0830365406596076		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 1.0830365406596076 | validation: 1.0490032166909313]
	TIME [epoch: 19.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9545647845762388		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.9545647845762388 | validation: 0.7977371285179772]
	TIME [epoch: 19.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8811735281243366		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.8811735281243366 | validation: 0.6659512029886965]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1157220479498093		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 1.1157220479498093 | validation: 1.0169583721798061]
	TIME [epoch: 19.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0768364882530703		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 1.0768364882530703 | validation: 0.8300302453356667]
	TIME [epoch: 19.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2356747372527677		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 1.2356747372527677 | validation: 1.0904401678501798]
	TIME [epoch: 19.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9834088371981817		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.9834088371981817 | validation: 0.8220678479688749]
	TIME [epoch: 19.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060874790987517		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 1.060874790987517 | validation: 1.0580042767420117]
	TIME [epoch: 19.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186484513744574		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.8186484513744574 | validation: 0.8310978598213685]
	TIME [epoch: 19.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1327757339305542		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 1.1327757339305542 | validation: 1.006042907305987]
	TIME [epoch: 19.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0537739662269687		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 1.0537739662269687 | validation: 0.9029584886633999]
	TIME [epoch: 19.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0821910126641456		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 1.0821910126641456 | validation: 0.9038694183259472]
	TIME [epoch: 19.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9367647939072998		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.9367647939072998 | validation: 0.9526594356193556]
	TIME [epoch: 19.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8925824315285132		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.8925824315285132 | validation: 1.1907437603772113]
	TIME [epoch: 19.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0852427194101515		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 1.0852427194101515 | validation: 1.1277616037797549]
	TIME [epoch: 19.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304376210602104		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 1.0304376210602104 | validation: 0.9852982787053535]
	TIME [epoch: 19.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9972315756873126		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.9972315756873126 | validation: 1.013075589764674]
	TIME [epoch: 19.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037548615819872		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 1.1037548615819872 | validation: 0.9748467657842796]
	TIME [epoch: 19.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9811183236020429		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.9811183236020429 | validation: 1.219105241487946]
	TIME [epoch: 19.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194678757204164		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 1.1194678757204164 | validation: 0.9541812640983285]
	TIME [epoch: 19.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0063860207334026		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 1.0063860207334026 | validation: 1.043802678037102]
	TIME [epoch: 19.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9381231614304955		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.9381231614304955 | validation: 1.006845266112951]
	TIME [epoch: 19.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008859735263586		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 1.008859735263586 | validation: 1.1026449180038362]
	TIME [epoch: 19.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9472369427613587		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.9472369427613587 | validation: 0.7620455821994112]
	TIME [epoch: 19.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9372718632073219		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.9372718632073219 | validation: 0.7487284039503584]
	TIME [epoch: 19.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9924169745550627		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.9924169745550627 | validation: 1.0045145360392618]
	TIME [epoch: 19.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013280478395264		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 1.013280478395264 | validation: 1.1388041127752961]
	TIME [epoch: 19.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8913252248734809		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.8913252248734809 | validation: 0.7858721562681541]
	TIME [epoch: 19.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0496291092145627		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 1.0496291092145627 | validation: 1.0159283163139183]
	TIME [epoch: 19.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355437764614552		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 1.0355437764614552 | validation: 0.8322695825921398]
	TIME [epoch: 19.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487908216065146		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.9487908216065146 | validation: 0.8460264520232516]
	TIME [epoch: 19.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9683028997292166		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.9683028997292166 | validation: 0.9786798671739788]
	TIME [epoch: 19.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9281917530250717		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.9281917530250717 | validation: 1.1224763767774109]
	TIME [epoch: 19.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.182929271993353		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 1.182929271993353 | validation: 0.8090051364804843]
	TIME [epoch: 19.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9731516955631916		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.9731516955631916 | validation: 0.8721728177461159]
	TIME [epoch: 19.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.784277020773198		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.784277020773198 | validation: 0.7955167454968113]
	TIME [epoch: 19.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597035547034172		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.9597035547034172 | validation: 1.0456664924765418]
	TIME [epoch: 19.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9214055325445438		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.9214055325445438 | validation: 1.1164860093389617]
	TIME [epoch: 19.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9863448254622416		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.9863448254622416 | validation: 1.0850775195733848]
	TIME [epoch: 19.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081996563097493		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 1.081996563097493 | validation: 0.9591167160695633]
	TIME [epoch: 19.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838686102466037		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.9838686102466037 | validation: 1.1643753999288764]
	TIME [epoch: 19.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0215738107091812		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 1.0215738107091812 | validation: 0.9151897170294011]
	TIME [epoch: 19.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8722369657988589		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.8722369657988589 | validation: 1.5479651072027676]
	TIME [epoch: 19.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078573248848221		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 1.078573248848221 | validation: 0.9866038118381845]
	TIME [epoch: 19.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9283779278244368		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.9283779278244368 | validation: 0.9897344696062442]
	TIME [epoch: 19.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0434711058707786		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 1.0434711058707786 | validation: 0.8540730786111365]
	TIME [epoch: 19.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9985342113800184		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.9985342113800184 | validation: 1.381713421485667]
	TIME [epoch: 19.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421084416355392		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 1.1421084416355392 | validation: 0.81975414461087]
	TIME [epoch: 19.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9014365038369174		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.9014365038369174 | validation: 0.829346647953578]
	TIME [epoch: 19.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0015532185106468		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 1.0015532185106468 | validation: 0.8609584520464685]
	TIME [epoch: 19.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9708601382976123		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.9708601382976123 | validation: 0.7764346647505276]
	TIME [epoch: 19.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9594498167180248		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.9594498167180248 | validation: 0.8125657994997166]
	TIME [epoch: 19.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9639874038468657		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.9639874038468657 | validation: 1.0484687718588552]
	TIME [epoch: 19.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684131270240715		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.9684131270240715 | validation: 0.9210695977042784]
	TIME [epoch: 19.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9069596340284288		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.9069596340284288 | validation: 1.1407873314470178]
	TIME [epoch: 19.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9956001386254194		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.9956001386254194 | validation: 0.9798102496968921]
	TIME [epoch: 19.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853347953236024		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.853347953236024 | validation: 1.082663902123576]
	TIME [epoch: 19.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0140958209730815		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 1.0140958209730815 | validation: 0.8778427334169676]
	TIME [epoch: 19.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.970243210404836		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.970243210404836 | validation: 0.8613695414526703]
	TIME [epoch: 19.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.944273899801518		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.944273899801518 | validation: 0.9029981490251087]
	TIME [epoch: 19.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9882674355961697		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.9882674355961697 | validation: 1.066922656115166]
	TIME [epoch: 19.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9552788823979091		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.9552788823979091 | validation: 0.7732638308629605]
	TIME [epoch: 19.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7936204458423589		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.7936204458423589 | validation: 1.0085535413097906]
	TIME [epoch: 19.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9257338748818644		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.9257338748818644 | validation: 1.130875858134326]
	TIME [epoch: 19.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.011691639578473		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 1.011691639578473 | validation: 0.8723847828286098]
	TIME [epoch: 19.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9440879736855929		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.9440879736855929 | validation: 0.7933370161724668]
	TIME [epoch: 19.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.898527017802109		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.898527017802109 | validation: 1.0694891364978203]
	TIME [epoch: 19.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046396309703487		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 1.046396309703487 | validation: 0.775812486867139]
	TIME [epoch: 19.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215661899877835		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.8215661899877835 | validation: 1.1840809069381568]
	TIME [epoch: 19.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0402462781459902		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 1.0402462781459902 | validation: 1.2936606784957803]
	TIME [epoch: 19.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646289835333478		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 1.0646289835333478 | validation: 2.032389956536989]
	TIME [epoch: 19.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1130266397423223		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 1.1130266397423223 | validation: 0.8397451749751798]
	TIME [epoch: 19.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9297207846747061		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.9297207846747061 | validation: 0.828742400098226]
	TIME [epoch: 19.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1614416905943097		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 1.1614416905943097 | validation: 0.7737878923685638]
	TIME [epoch: 19.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9467042955324632		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.9467042955324632 | validation: 0.6652411824231474]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9276827939932559		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.9276827939932559 | validation: 0.9850361376258625]
	TIME [epoch: 19.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0983137574741613		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 1.0983137574741613 | validation: 0.8623462045728467]
	TIME [epoch: 19.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9328385987133494		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.9328385987133494 | validation: 0.7963197659934982]
	TIME [epoch: 19.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9388340878551991		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.9388340878551991 | validation: 1.1113795139119573]
	TIME [epoch: 19.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9992442274742642		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.9992442274742642 | validation: 0.7802326994002635]
	TIME [epoch: 19.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934416747443399		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.8934416747443399 | validation: 1.1109661051526079]
	TIME [epoch: 19.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9816556989627022		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.9816556989627022 | validation: 0.8539330952617337]
	TIME [epoch: 19.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9269019702600126		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.9269019702600126 | validation: 0.9443819621257066]
	TIME [epoch: 19.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.94900067459745		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.94900067459745 | validation: 1.0955373303784592]
	TIME [epoch: 19.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8831825621495044		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.8831825621495044 | validation: 1.069504017707731]
	TIME [epoch: 19.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9181865223895859		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.9181865223895859 | validation: 1.5464891178859004]
	TIME [epoch: 19.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1220529720615626		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 1.1220529720615626 | validation: 0.8765678048891594]
	TIME [epoch: 19.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.999220590463479		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.999220590463479 | validation: 0.9222724147840378]
	TIME [epoch: 19.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0098659427700676		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 1.0098659427700676 | validation: 1.045811681203543]
	TIME [epoch: 19.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0173879598900548		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 1.0173879598900548 | validation: 0.8829795342541602]
	TIME [epoch: 19.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1002131611319887		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 1.1002131611319887 | validation: 0.9569389773203604]
	TIME [epoch: 19.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425053389305266		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.8425053389305266 | validation: 0.7314612771751257]
	TIME [epoch: 19.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170686888542725		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.8170686888542725 | validation: 0.671856766800652]
	TIME [epoch: 19.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179319545282582		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 1.179319545282582 | validation: 0.8948981344802607]
	TIME [epoch: 19.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8733772349202433		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.8733772349202433 | validation: 1.0879905432607386]
	TIME [epoch: 19.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0031727111557882		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 1.0031727111557882 | validation: 0.766603006496793]
	TIME [epoch: 19.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9013924098746106		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.9013924098746106 | validation: 1.4130677651528591]
	TIME [epoch: 19.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385036162431118		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 1.0385036162431118 | validation: 0.8885758845780536]
	TIME [epoch: 19.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0821865042784498		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 1.0821865042784498 | validation: 0.6951429696026588]
	TIME [epoch: 19.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023409760397923		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.7023409760397923 | validation: 1.699709533955203]
	TIME [epoch: 19.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632240057422937		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 1.0632240057422937 | validation: 0.8941488409765184]
	TIME [epoch: 19.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9178787501100077		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.9178787501100077 | validation: 1.116014180385359]
	TIME [epoch: 19.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8403238768858678		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.8403238768858678 | validation: 0.9974761244640007]
	TIME [epoch: 19.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283005654602135		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 1.0283005654602135 | validation: 0.8791561168890019]
	TIME [epoch: 19.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8855993006256574		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 0.8855993006256574 | validation: 1.128241669197938]
	TIME [epoch: 19.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337059855627281		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.9337059855627281 | validation: 1.0502431061960085]
	TIME [epoch: 19.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9657600794879899		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.9657600794879899 | validation: 0.8465001291674583]
	TIME [epoch: 19.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9462739127464227		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.9462739127464227 | validation: 0.9623495263861285]
	TIME [epoch: 19.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8277825739188003		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 0.8277825739188003 | validation: 0.7541779086061412]
	TIME [epoch: 19.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008960037811252		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.9008960037811252 | validation: 1.0047594208992097]
	TIME [epoch: 19.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374173103380083		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.8374173103380083 | validation: 0.9575324998069551]
	TIME [epoch: 19.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083992189150972		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.9083992189150972 | validation: 0.7767225498536854]
	TIME [epoch: 19.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7930077612028418		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.7930077612028418 | validation: 1.0788142987869453]
	TIME [epoch: 19.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3428750459449563		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.3428750459449563 | validation: 0.7074874399943129]
	TIME [epoch: 19.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8441307998783933		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.8441307998783933 | validation: 1.3479212590577117]
	TIME [epoch: 19.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6544584430023304		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 1.6544584430023304 | validation: 1.0179115960168594]
	TIME [epoch: 19.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8203855028272403		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.8203855028272403 | validation: 0.8735847590127972]
	TIME [epoch: 19.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9470429799980862		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.9470429799980862 | validation: 1.8480454074149344]
	TIME [epoch: 19.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036238995212924		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 1.036238995212924 | validation: 1.0711969606764338]
	TIME [epoch: 19.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673855230059931		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.8673855230059931 | validation: 0.8136352001171446]
	TIME [epoch: 19.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9651269317993346		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.9651269317993346 | validation: 0.8280109309948972]
	TIME [epoch: 19.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874450524281803		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.874450524281803 | validation: 0.8693822687937706]
	TIME [epoch: 19.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8504478460088389		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.8504478460088389 | validation: 0.8582099536362268]
	TIME [epoch: 19.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0015852877102769		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 1.0015852877102769 | validation: 2.2249163392964606]
	TIME [epoch: 19.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4236315652147105		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 1.4236315652147105 | validation: 1.262247427424953]
	TIME [epoch: 19.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2383611942440393		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 1.2383611942440393 | validation: 1.1382440674999352]
	TIME [epoch: 19.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480266791025862		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 1.480266791025862 | validation: 1.1264853007545486]
	TIME [epoch: 19.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1015521401645088		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 1.1015521401645088 | validation: 1.403554523728931]
	TIME [epoch: 19.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503081192910705		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 1.1503081192910705 | validation: 1.1051906260637914]
	TIME [epoch: 19.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0932493570722623		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 1.0932493570722623 | validation: 0.8753040108404356]
	TIME [epoch: 19.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1583147761595054		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 1.1583147761595054 | validation: 0.8183226568383597]
	TIME [epoch: 19.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941379034237164		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.941379034237164 | validation: 1.285156690460876]
	TIME [epoch: 19.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192763496794112		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 1.192763496794112 | validation: 0.9769821286984025]
	TIME [epoch: 19.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0660112869393896		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 1.0660112869393896 | validation: 1.0770203266800487]
	TIME [epoch: 19.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461264272994665		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 1.1461264272994665 | validation: 1.023257157039089]
	TIME [epoch: 19.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0905135505949626		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 1.0905135505949626 | validation: 0.9212382180098866]
	TIME [epoch: 19.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205002035970432		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 1.0205002035970432 | validation: 1.2182418448277623]
	TIME [epoch: 19.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3178187322644408		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 1.3178187322644408 | validation: 1.04274814354253]
	TIME [epoch: 19.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9795461797626528		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.9795461797626528 | validation: 0.8708250217553036]
	TIME [epoch: 19.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.829162887094903		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.829162887094903 | validation: 0.8746964690366548]
	TIME [epoch: 19.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0314055156016626		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 1.0314055156016626 | validation: 0.8195299096253772]
	TIME [epoch: 19.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9874042783029301		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.9874042783029301 | validation: 0.8721475802210421]
	TIME [epoch: 19.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9065959420020795		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.9065959420020795 | validation: 0.8623135773534327]
	TIME [epoch: 19.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8579784731190484		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.8579784731190484 | validation: 0.7717992335780453]
	TIME [epoch: 19.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9919194367175352		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.9919194367175352 | validation: 0.7642496617976061]
	TIME [epoch: 19.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896347393555676		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.8896347393555676 | validation: 0.8792211162668253]
	TIME [epoch: 19.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.942851824598149		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.942851824598149 | validation: 0.9938318021713584]
	TIME [epoch: 19.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003370681855384		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 1.003370681855384 | validation: 0.8472676049574245]
	TIME [epoch: 19.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8289038373968461		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.8289038373968461 | validation: 0.8295210964794579]
	TIME [epoch: 19.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9465297067232201		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.9465297067232201 | validation: 1.1700177703067085]
	TIME [epoch: 19.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9387381397677736		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.9387381397677736 | validation: 0.9159107217701925]
	TIME [epoch: 19.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.885162080607133		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.885162080607133 | validation: 0.807054399291758]
	TIME [epoch: 19.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8848326423611612		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.8848326423611612 | validation: 0.9301822522337425]
	TIME [epoch: 19.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0001994399052383		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 1.0001994399052383 | validation: 0.6541976216442262]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623739109787205		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.7623739109787205 | validation: 0.9720181352865684]
	TIME [epoch: 19.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9362860044654926		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.9362860044654926 | validation: 0.778708707762321]
	TIME [epoch: 19.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.809763291065107		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.809763291065107 | validation: 0.8120467986503203]
	TIME [epoch: 19.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876590008070168		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.7876590008070168 | validation: 0.9209769421115325]
	TIME [epoch: 19.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8474125307407663		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.8474125307407663 | validation: 0.9776095790117864]
	TIME [epoch: 19.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9488484280104208		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.9488484280104208 | validation: 0.7614818293673636]
	TIME [epoch: 19.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7897656713011094		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.7897656713011094 | validation: 0.7107832097835897]
	TIME [epoch: 19.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640892534799792		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.7640892534799792 | validation: 1.3571398738651081]
	TIME [epoch: 19.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9199252641813441		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.9199252641813441 | validation: 1.2818775403702445]
	TIME [epoch: 19.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9848196677989187		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.9848196677989187 | validation: 1.0153350189108217]
	TIME [epoch: 19.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759306781647944		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.9759306781647944 | validation: 1.0246650439196179]
	TIME [epoch: 19.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9236646168595066		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.9236646168595066 | validation: 0.9120788200240877]
	TIME [epoch: 19.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8567418024295214		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.8567418024295214 | validation: 0.9543584482491216]
	TIME [epoch: 19.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9583952335017163		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.9583952335017163 | validation: 0.779006365239926]
	TIME [epoch: 19.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8019244166439231		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.8019244166439231 | validation: 0.7926203239795786]
	TIME [epoch: 19.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8260801022307438		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.8260801022307438 | validation: 1.0878190245851087]
	TIME [epoch: 19.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8784683353346344		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.8784683353346344 | validation: 0.7698212835431668]
	TIME [epoch: 19.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244704650122566		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.7244704650122566 | validation: 0.8945060929911113]
	TIME [epoch: 19.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9778997329722627		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.9778997329722627 | validation: 0.8097066525847376]
	TIME [epoch: 19.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9555582358083681		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.9555582358083681 | validation: 0.8381977615623966]
	TIME [epoch: 19.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176682529014992		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.9176682529014992 | validation: 0.612701189975654]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8389573465634942		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.8389573465634942 | validation: 0.6493786292163972]
	TIME [epoch: 19.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701708732431716		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.7701708732431716 | validation: 1.1649527273959284]
	TIME [epoch: 19.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010234676531479		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 1.010234676531479 | validation: 0.7586660342190926]
	TIME [epoch: 19.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819677816826253		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.6819677816826253 | validation: 0.9399382828471059]
	TIME [epoch: 19.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9296435414017957		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.9296435414017957 | validation: 0.7778164717845806]
	TIME [epoch: 19.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9290852933956032		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.9290852933956032 | validation: 1.2268323338490785]
	TIME [epoch: 19.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412309977893316		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.8412309977893316 | validation: 0.8648756821328798]
	TIME [epoch: 19.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0662443232342158		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 1.0662443232342158 | validation: 1.1015205906136007]
	TIME [epoch: 19.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8620262419116236		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.8620262419116236 | validation: 0.8156321106412658]
	TIME [epoch: 19.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.887621350293219		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.887621350293219 | validation: 0.8386245993588184]
	TIME [epoch: 19.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.015197922147975		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 1.015197922147975 | validation: 0.8295478583034422]
	TIME [epoch: 19.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074169645039114		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.8074169645039114 | validation: 1.1168150831145656]
	TIME [epoch: 19.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8092513092025024		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.8092513092025024 | validation: 0.7691203228469377]
	TIME [epoch: 19.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8403028934865651		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.8403028934865651 | validation: 0.9253214827322147]
	TIME [epoch: 19.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876190623189836		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.7876190623189836 | validation: 0.7444212213056185]
	TIME [epoch: 19.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.819141298201314		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.819141298201314 | validation: 2.4204511446707757]
	TIME [epoch: 19.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2234457164852233		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 1.2234457164852233 | validation: 0.6731213021222626]
	TIME [epoch: 19.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7440526683642157		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.7440526683642157 | validation: 0.7069954723966088]
	TIME [epoch: 19.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276110306356078		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.7276110306356078 | validation: 0.9148388581671636]
	TIME [epoch: 19.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8997284400087177		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.8997284400087177 | validation: 0.9648670857224524]
	TIME [epoch: 19.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7645389053851099		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.7645389053851099 | validation: 1.0538239513489234]
	TIME [epoch: 19.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9835182432013363		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.9835182432013363 | validation: 0.731149704446168]
	TIME [epoch: 19.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8125709232772088		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.8125709232772088 | validation: 0.811213149408842]
	TIME [epoch: 19.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8381393160238343		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.8381393160238343 | validation: 0.638047993671616]
	TIME [epoch: 19.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748230098814658		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.7748230098814658 | validation: 0.91452364391812]
	TIME [epoch: 19.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8559693967665518		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.8559693967665518 | validation: 0.6575948274899215]
	TIME [epoch: 19.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576767283442548		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.7576767283442548 | validation: 0.6411033116737431]
	TIME [epoch: 19.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7368468580418792		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.7368468580418792 | validation: 0.62676372671624]
	TIME [epoch: 19.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035888976018798		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.9035888976018798 | validation: 0.6389854196061469]
	TIME [epoch: 19.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8915199764610935		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.8915199764610935 | validation: 0.568658928407966]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7906935231183612		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.7906935231183612 | validation: 0.7893881253510625]
	TIME [epoch: 19.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337792760666995		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.9337792760666995 | validation: 0.8441999152804567]
	TIME [epoch: 19.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76561079682118		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.76561079682118 | validation: 1.1582601034942261]
	TIME [epoch: 19.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8950124868463627		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.8950124868463627 | validation: 0.817923490536175]
	TIME [epoch: 19.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7650059537209556		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.7650059537209556 | validation: 0.8098763794441743]
	TIME [epoch: 19.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148842994987564		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.7148842994987564 | validation: 0.9227397699084243]
	TIME [epoch: 19.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.944042862220295		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.944042862220295 | validation: 0.9010327438079588]
	TIME [epoch: 19.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8919234114927601		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.8919234114927601 | validation: 0.8248870792785172]
	TIME [epoch: 135 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8530274970730966		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.8530274970730966 | validation: 1.1576835652208262]
	TIME [epoch: 41.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275152060905454		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.8275152060905454 | validation: 0.8841201391919368]
	TIME [epoch: 41.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7951389096303145		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.7951389096303145 | validation: 0.8273039929926445]
	TIME [epoch: 41.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525066853328746		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.7525066853328746 | validation: 0.9387882225572529]
	TIME [epoch: 41.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.83814225109978		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.83814225109978 | validation: 0.806073923504579]
	TIME [epoch: 41.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7851107117917686		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.7851107117917686 | validation: 1.0861107982129425]
	TIME [epoch: 41.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213125630855325		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.8213125630855325 | validation: 0.7285663512156231]
	TIME [epoch: 41.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7649871435648224		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.7649871435648224 | validation: 0.7162761696246609]
	TIME [epoch: 41.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392060357258654		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.7392060357258654 | validation: 1.1628944961017516]
	TIME [epoch: 41.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.962606618978741		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.962606618978741 | validation: 0.8461866590879354]
	TIME [epoch: 41.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7729991837673719		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.7729991837673719 | validation: 0.9551445166687982]
	TIME [epoch: 41.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7828533767685029		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.7828533767685029 | validation: 0.7444457377530656]
	TIME [epoch: 41.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651146460627904		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.7651146460627904 | validation: 0.641939719795948]
	TIME [epoch: 41.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177169438295989		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.6177169438295989 | validation: 0.7056995339941188]
	TIME [epoch: 41.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483243834933867		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.7483243834933867 | validation: 0.7262391351789322]
	TIME [epoch: 41.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8080135154737083		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.8080135154737083 | validation: 0.801014883641292]
	TIME [epoch: 41.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432053061609104		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.7432053061609104 | validation: 0.7299961282615997]
	TIME [epoch: 41.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834909370293752		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.834909370293752 | validation: 0.7120747116626766]
	TIME [epoch: 41.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8810651047507515		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.8810651047507515 | validation: 0.6874505293159785]
	TIME [epoch: 41.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422214088987029		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.7422214088987029 | validation: 0.6200364789996385]
	TIME [epoch: 41.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7940542525392975		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.7940542525392975 | validation: 0.8585338953971606]
	TIME [epoch: 41.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904605733044425		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.7904605733044425 | validation: 0.645594919953913]
	TIME [epoch: 41.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734203162594155		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.7734203162594155 | validation: 0.7872386169530174]
	TIME [epoch: 41.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870931736674744		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.6870931736674744 | validation: 0.7521628145589547]
	TIME [epoch: 41.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71969694064502		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.71969694064502 | validation: 0.8239954626421389]
	TIME [epoch: 41.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8122606099827445		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.8122606099827445 | validation: 1.208332542570694]
	TIME [epoch: 41.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9015462744174216		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.9015462744174216 | validation: 0.7321973839926423]
	TIME [epoch: 41.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6653428474357022		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.6653428474357022 | validation: 0.6648665522391864]
	TIME [epoch: 41.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9039593927155142		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.9039593927155142 | validation: 0.7628581458365047]
	TIME [epoch: 41.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916947300403877		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.7916947300403877 | validation: 0.7248065854440557]
	TIME [epoch: 41.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118719336996054		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.8118719336996054 | validation: 1.0384839348385908]
	TIME [epoch: 41.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.660518424537496		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.660518424537496 | validation: 0.7761098048490873]
	TIME [epoch: 41.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8052609836726093		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.8052609836726093 | validation: 0.8361581316091286]
	TIME [epoch: 41.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8224160651612419		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.8224160651612419 | validation: 0.6760812417544038]
	TIME [epoch: 41.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7656429056874645		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.7656429056874645 | validation: 0.6230177550412972]
	TIME [epoch: 41.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613140072850815		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.8613140072850815 | validation: 0.8092942437846449]
	TIME [epoch: 41.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549989227965971		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.7549989227965971 | validation: 0.7193216584618078]
	TIME [epoch: 41.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424466106763642		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.7424466106763642 | validation: 0.6035657198860787]
	TIME [epoch: 41.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720989498010871		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.720989498010871 | validation: 0.7403145876833346]
	TIME [epoch: 41.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237062054394929		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.7237062054394929 | validation: 0.5320504315224954]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3609857155938625		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 1.3609857155938625 | validation: 0.6877958420646693]
	TIME [epoch: 41.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7991533144114015		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.7991533144114015 | validation: 0.8118230268384781]
	TIME [epoch: 41.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7762249043360265		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.7762249043360265 | validation: 0.6414353211839348]
	TIME [epoch: 41.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9975753662376172		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.9975753662376172 | validation: 0.6191600951382453]
	TIME [epoch: 41.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72090886902764		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.72090886902764 | validation: 0.9432127201269749]
	TIME [epoch: 41.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233841553762142		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.8233841553762142 | validation: 0.7282130971487694]
	TIME [epoch: 41.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8681696080158674		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.8681696080158674 | validation: 0.63745189562243]
	TIME [epoch: 41.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143178069666991		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.7143178069666991 | validation: 0.6799161461583705]
	TIME [epoch: 41.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.78054611988071		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.78054611988071 | validation: 0.5801843012050716]
	TIME [epoch: 41.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743829203397169		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.6743829203397169 | validation: 0.4866744900282164]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8452912960694599		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.8452912960694599 | validation: 0.817942858904183]
	TIME [epoch: 41.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6488864254540307		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.6488864254540307 | validation: 0.8907607171042828]
	TIME [epoch: 41.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128299726866579		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.8128299726866579 | validation: 0.5801114661332518]
	TIME [epoch: 41.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240627459599657		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.6240627459599657 | validation: 0.9865375496730875]
	TIME [epoch: 41.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84624301911881		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.84624301911881 | validation: 0.6493506636438637]
	TIME [epoch: 41.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7092756747274287		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.7092756747274287 | validation: 0.6532481712244055]
	TIME [epoch: 41.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481505001464122		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.7481505001464122 | validation: 0.5885000714088641]
	TIME [epoch: 41.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071962778923996		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.7071962778923996 | validation: 0.8394353032227213]
	TIME [epoch: 41.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.913876948307117		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.913876948307117 | validation: 0.6474311943435153]
	TIME [epoch: 41.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280055313538223		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.7280055313538223 | validation: 0.6987496861665959]
	TIME [epoch: 41.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856931305112247		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.7856931305112247 | validation: 0.7796064781114838]
	TIME [epoch: 41.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7656043411082611		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.7656043411082611 | validation: 0.593566358860948]
	TIME [epoch: 41.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656416121899335		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.656416121899335 | validation: 0.7759985915144643]
	TIME [epoch: 41.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173645730777628		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.8173645730777628 | validation: 0.5811376066915528]
	TIME [epoch: 41.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149367990056865		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.8149367990056865 | validation: 0.9196347703422828]
	TIME [epoch: 41.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834353122962341		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.7834353122962341 | validation: 0.685322851456593]
	TIME [epoch: 41.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050145929103465		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.7050145929103465 | validation: 0.8216171425752731]
	TIME [epoch: 41.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7931432689481841		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.7931432689481841 | validation: 0.7565754837145786]
	TIME [epoch: 41.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091412217093668		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.7091412217093668 | validation: 0.8876108167587273]
	TIME [epoch: 41.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912853716777086		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.7912853716777086 | validation: 0.9639460632018091]
	TIME [epoch: 41.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895388278523334		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.7895388278523334 | validation: 0.801726973917528]
	TIME [epoch: 41.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748411749756627		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.7748411749756627 | validation: 0.553032229494461]
	TIME [epoch: 41.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020947729085826		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.7020947729085826 | validation: 0.7037271235787643]
	TIME [epoch: 41.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7284984341396462		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.7284984341396462 | validation: 0.5814069631786365]
	TIME [epoch: 41.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7459820074573831		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.7459820074573831 | validation: 0.6984179189630284]
	TIME [epoch: 41.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906471589017962		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.6906471589017962 | validation: 0.8319200511303017]
	TIME [epoch: 41.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8230095294874781		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.8230095294874781 | validation: 0.8466650066828698]
	TIME [epoch: 41.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570349905495467		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.6570349905495467 | validation: 0.7096266291245952]
	TIME [epoch: 41.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8097801951031455		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.8097801951031455 | validation: 0.5610202154520714]
	TIME [epoch: 41.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167157700470994		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.9167157700470994 | validation: 0.7595643996029557]
	TIME [epoch: 41 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261736606872049		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.7261736606872049 | validation: 0.7572795281081985]
	TIME [epoch: 41.1 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683108234886621		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.6683108234886621 | validation: 0.7277779911570876]
	TIME [epoch: 41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7960570037049295		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.7960570037049295 | validation: 0.5995176264230337]
	TIME [epoch: 41.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915275331375389		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.6915275331375389 | validation: 0.5638866647338037]
	TIME [epoch: 41 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858308574752903		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.6858308574752903 | validation: 0.8000016216653888]
	TIME [epoch: 41.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556287906974111		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.7556287906974111 | validation: 0.6720097065119673]
	TIME [epoch: 41 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623563011797385		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.7623563011797385 | validation: 0.7142404901804682]
	TIME [epoch: 41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796946824543648		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.7796946824543648 | validation: 0.6812808112148512]
	TIME [epoch: 41.1 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099024658073583		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.7099024658073583 | validation: 0.7045381636008117]
	TIME [epoch: 41.1 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652222091113625		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.652222091113625 | validation: 0.649841197986595]
	TIME [epoch: 41.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286132158268814		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.7286132158268814 | validation: 0.7785410477734476]
	TIME [epoch: 41.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764555684720631		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.764555684720631 | validation: 0.8343017052450667]
	TIME [epoch: 41.1 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267674647233923		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.7267674647233923 | validation: 0.670264515600815]
	TIME [epoch: 41.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775683845795996		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.7775683845795996 | validation: 0.932640301267663]
	TIME [epoch: 41 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609876144217461		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.8609876144217461 | validation: 0.9379738395203454]
	TIME [epoch: 41.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7964016251052803		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.7964016251052803 | validation: 1.0771443722252783]
	TIME [epoch: 41.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7753358460445479		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.7753358460445479 | validation: 0.8561184293304237]
	TIME [epoch: 41.1 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8103042289215573		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.8103042289215573 | validation: 0.951687656830303]
	TIME [epoch: 41.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064629171122649		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.7064629171122649 | validation: 0.7932604399609933]
	TIME [epoch: 41.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8053366657934209		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.8053366657934209 | validation: 1.1243008385347923]
	TIME [epoch: 41 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088635621987207		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.8088635621987207 | validation: 0.5735872812123534]
	TIME [epoch: 41 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214348301636149		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.7214348301636149 | validation: 0.8823728600125309]
	TIME [epoch: 41 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8032920938282825		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.8032920938282825 | validation: 0.8165600716573554]
	TIME [epoch: 41.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799320257699915		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.799320257699915 | validation: 0.865403977271191]
	TIME [epoch: 41.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360037606082579		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.7360037606082579 | validation: 0.6933629098009324]
	TIME [epoch: 41 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.767228954136464		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.767228954136464 | validation: 0.6801974533938888]
	TIME [epoch: 41 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951085969899653		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.6951085969899653 | validation: 0.7754564168382905]
	TIME [epoch: 41.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7435022351499156		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.7435022351499156 | validation: 0.6490647955811222]
	TIME [epoch: 41.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126497306582109		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.7126497306582109 | validation: 0.8826612155370102]
	TIME [epoch: 41.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919281540214861		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.6919281540214861 | validation: 0.9568084084188695]
	TIME [epoch: 41.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650468893959711		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.650468893959711 | validation: 0.7837242824383805]
	TIME [epoch: 41.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147564145459857		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.6147564145459857 | validation: 1.0499168175305436]
	TIME [epoch: 41.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8470729454423787		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.8470729454423787 | validation: 0.7637007658906212]
	TIME [epoch: 41.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826025486479609		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.6826025486479609 | validation: 0.6136374449804987]
	TIME [epoch: 41.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752919061281093		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.7752919061281093 | validation: 0.5574823269900648]
	TIME [epoch: 41.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902072591628734		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.6902072591628734 | validation: 0.7159729955618597]
	TIME [epoch: 41.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6726721117072405		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.6726721117072405 | validation: 0.4171431231156608]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942740882183409		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.5942740882183409 | validation: 1.1495850208923954]
	TIME [epoch: 41.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7883093843366894		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.7883093843366894 | validation: 0.7856651498657103]
	TIME [epoch: 41.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661969150847773		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.6661969150847773 | validation: 0.7884189300731623]
	TIME [epoch: 41 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696730508764626		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.696730508764626 | validation: 1.0194980584714233]
	TIME [epoch: 41 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6572656124053986		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.6572656124053986 | validation: 0.5270013625998818]
	TIME [epoch: 41.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241869844561457		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.7241869844561457 | validation: 0.655857862455899]
	TIME [epoch: 41.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7495130974964488		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.7495130974964488 | validation: 0.7460307952667056]
	TIME [epoch: 41.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623069488053883		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.7623069488053883 | validation: 0.9419095576840731]
	TIME [epoch: 41 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778014356136081		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.6778014356136081 | validation: 0.7105570439831739]
	TIME [epoch: 41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542670200300855		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.6542670200300855 | validation: 0.7250561679793341]
	TIME [epoch: 41.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8630714357388065		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.8630714357388065 | validation: 0.7988799378648448]
	TIME [epoch: 41.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209344670925437		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.7209344670925437 | validation: 0.717306327884798]
	TIME [epoch: 41.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148513795439625		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.7148513795439625 | validation: 0.6102326825366486]
	TIME [epoch: 41.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530231848064615		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.7530231848064615 | validation: 0.6179897952315248]
	TIME [epoch: 41.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782056342379248		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.6782056342379248 | validation: 0.6953894966989345]
	TIME [epoch: 41.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6372105277297417		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.6372105277297417 | validation: 0.6244244145523989]
	TIME [epoch: 41.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711054533199659		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.711054533199659 | validation: 0.883631647228323]
	TIME [epoch: 41.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201156847697898		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.7201156847697898 | validation: 0.6340860208293149]
	TIME [epoch: 41.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390341804094355		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.7390341804094355 | validation: 0.6358113462365593]
	TIME [epoch: 41.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6150826476185571		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.6150826476185571 | validation: 0.8086989476434496]
	TIME [epoch: 41.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655870776776345		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.7655870776776345 | validation: 0.624786407106237]
	TIME [epoch: 41.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760769175269191		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.5760769175269191 | validation: 0.956793495307701]
	TIME [epoch: 41.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8008457291452862		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.8008457291452862 | validation: 0.6909707869538158]
	TIME [epoch: 41 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131242674587963		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.7131242674587963 | validation: 0.8058097074719859]
	TIME [epoch: 41.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593947657179147		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.6593947657179147 | validation: 0.7017172126270965]
	TIME [epoch: 41.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555607886217416		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.6555607886217416 | validation: 0.7646512942364192]
	TIME [epoch: 41.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743923328543129		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.5743923328543129 | validation: 1.4306007926844082]
	TIME [epoch: 41.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9080229050513314		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.9080229050513314 | validation: 0.6584904366852528]
	TIME [epoch: 41.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6718289699426371		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.6718289699426371 | validation: 0.5352350289783325]
	TIME [epoch: 41.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477300936322258		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.6477300936322258 | validation: 0.7580478661041854]
	TIME [epoch: 41.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865865222492877		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.6865865222492877 | validation: 0.6095782911151264]
	TIME [epoch: 41.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421364933957652		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.6421364933957652 | validation: 0.679532639500428]
	TIME [epoch: 41.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796870517697775		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.5796870517697775 | validation: 0.6445079472917677]
	TIME [epoch: 41.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.800756291494157		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.800756291494157 | validation: 0.46195737759642574]
	TIME [epoch: 41.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983691286428051		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.6983691286428051 | validation: 0.6218884998671605]
	TIME [epoch: 41.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6747008018152694		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.6747008018152694 | validation: 0.7744198352639755]
	TIME [epoch: 41.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783426579179706		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.7783426579179706 | validation: 0.6928965093558129]
	TIME [epoch: 41.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7817782758477538		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.7817782758477538 | validation: 0.5984149263055445]
	TIME [epoch: 41 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501541641183787		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.7501541641183787 | validation: 0.601472142624041]
	TIME [epoch: 41.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7457855465123487		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.7457855465123487 | validation: 0.606089714227644]
	TIME [epoch: 41.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588035215338506		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.7588035215338506 | validation: 0.6824330173033115]
	TIME [epoch: 41.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287014414577969		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.6287014414577969 | validation: 0.8655722886439703]
	TIME [epoch: 41.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192919706514124		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.7192919706514124 | validation: 0.5596137009185587]
	TIME [epoch: 41 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161007442197597		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.6161007442197597 | validation: 0.6582162836172476]
	TIME [epoch: 41.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8799093641841179		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.8799093641841179 | validation: 0.4827442790344493]
	TIME [epoch: 41.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281759000964203		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.5281759000964203 | validation: 2.242832444829065]
	TIME [epoch: 41.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406907692813754		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.9406907692813754 | validation: 1.032344636701151]
	TIME [epoch: 41.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843619140710272		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.6843619140710272 | validation: 0.6675920263962882]
	TIME [epoch: 41 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8046948637267564		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.8046948637267564 | validation: 0.5770726701228821]
	TIME [epoch: 41.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917176639463437		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.5917176639463437 | validation: 0.7799197548468952]
	TIME [epoch: 41.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7795317293322465		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.7795317293322465 | validation: 0.7227617603077043]
	TIME [epoch: 41.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358701997661287		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.7358701997661287 | validation: 0.6200540804099612]
	TIME [epoch: 41.1 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328493418558909		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.6328493418558909 | validation: 0.44773542738743116]
	TIME [epoch: 41 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504246856886875		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.6504246856886875 | validation: 0.6687135463598443]
	TIME [epoch: 41.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198448289037104		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.7198448289037104 | validation: 0.9106645616528404]
	TIME [epoch: 41.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108979174856973		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.7108979174856973 | validation: 0.8007633599245931]
	TIME [epoch: 41.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821170416839576		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.6821170416839576 | validation: 0.9050070424161145]
	TIME [epoch: 41.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.649245656071593		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.649245656071593 | validation: 2.490106167205864]
	TIME [epoch: 41 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.185877095536467		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 1.185877095536467 | validation: 0.789154239920335]
	TIME [epoch: 41.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8544985656558148		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.8544985656558148 | validation: 0.5425189840280316]
	TIME [epoch: 41.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888157903067871		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.6888157903067871 | validation: 0.5892844894438323]
	TIME [epoch: 41.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684165044281641		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.684165044281641 | validation: 0.5316043743004579]
	TIME [epoch: 41.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5226029187934236		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.5226029187934236 | validation: 0.6465914510927709]
	TIME [epoch: 41.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6584331700458296		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.6584331700458296 | validation: 0.5972894307542845]
	TIME [epoch: 41.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211685348032597		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.7211685348032597 | validation: 0.8562635693222758]
	TIME [epoch: 41.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625229404924794		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.7625229404924794 | validation: 0.7016663076503507]
	TIME [epoch: 41.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871949637937087		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.6871949637937087 | validation: 0.520679668284714]
	TIME [epoch: 41.1 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49914144761020285		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.49914144761020285 | validation: 0.7832247510455275]
	TIME [epoch: 41 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225292412393522		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.7225292412393522 | validation: 0.5625005700344661]
	TIME [epoch: 41.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.795648582593875		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.795648582593875 | validation: 0.6770491061396593]
	TIME [epoch: 41.1 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608245477919332		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.6608245477919332 | validation: 0.6052574738727743]
	TIME [epoch: 41.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278737656750323		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.6278737656750323 | validation: 0.5822732007404134]
	TIME [epoch: 41.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346965646888225		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.6346965646888225 | validation: 0.7501830900983906]
	TIME [epoch: 41 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616105648471389		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.6616105648471389 | validation: 0.6687580454037603]
	TIME [epoch: 41.1 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8344773652876735		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.8344773652876735 | validation: 0.5581262605051693]
	TIME [epoch: 41.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599629320858033		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.599629320858033 | validation: 0.6002825231068957]
	TIME [epoch: 41.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948680219706504		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.5948680219706504 | validation: 0.9803074096974724]
	TIME [epoch: 41.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6794891011956337		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.6794891011956337 | validation: 0.709439781372555]
	TIME [epoch: 41 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657898572122962		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.6657898572122962 | validation: 0.6780183508550248]
	TIME [epoch: 41.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532354836918478		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.6532354836918478 | validation: 0.6497308160227675]
	TIME [epoch: 41.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7778912181628257		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.7778912181628257 | validation: 0.6035461553376106]
	TIME [epoch: 41.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738332170822192		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.6738332170822192 | validation: 0.5144398713841127]
	TIME [epoch: 41.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676099128998851		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.6676099128998851 | validation: 0.5477425393436328]
	TIME [epoch: 41 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6195674030275027		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.6195674030275027 | validation: 0.5241137544094117]
	TIME [epoch: 41.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938650609892968		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.5938650609892968 | validation: 1.1667428069067567]
	TIME [epoch: 41.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319955460883616		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.7319955460883616 | validation: 0.6319210833585567]
	TIME [epoch: 41.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365700328254309		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.6365700328254309 | validation: 0.8220363839529294]
	TIME [epoch: 41.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965956732669357		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.5965956732669357 | validation: 0.6071240377589765]
	TIME [epoch: 41 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8009274979493788		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.8009274979493788 | validation: 0.8137242107722765]
	TIME [epoch: 41 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201504511640719		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.6201504511640719 | validation: 0.5569068689033219]
	TIME [epoch: 41 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375633483146856		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.7375633483146856 | validation: 0.6471538845793956]
	TIME [epoch: 41.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6639342751965629		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.6639342751965629 | validation: 1.0287259668441173]
	TIME [epoch: 41 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587837433496835		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.6587837433496835 | validation: 0.5821529462750678]
	TIME [epoch: 41 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660220742430868		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.5660220742430868 | validation: 0.5916193023264229]
	TIME [epoch: 41 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702220821233494		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.702220821233494 | validation: 0.4848184351596372]
	TIME [epoch: 41.1 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660161982834061		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.6660161982834061 | validation: 0.6849002951513459]
	TIME [epoch: 41.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5304907279837718		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.5304907279837718 | validation: 0.7608053054144971]
	TIME [epoch: 41 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824172695649492		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.6824172695649492 | validation: 0.7818920886835541]
	TIME [epoch: 41 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856472688077945		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.6856472688077945 | validation: 0.6668095598021271]
	TIME [epoch: 41 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975273668132006		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.5975273668132006 | validation: 0.8694334421175065]
	TIME [epoch: 41.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313265988269683		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.7313265988269683 | validation: 0.4746003663478291]
	TIME [epoch: 41.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6429285650216954		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.6429285650216954 | validation: 0.6733634546861071]
	TIME [epoch: 41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940474036401743		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.5940474036401743 | validation: 0.7633735154206709]
	TIME [epoch: 41 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678428442713065		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.6678428442713065 | validation: 0.7316477649661037]
	TIME [epoch: 41 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128029461989369		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.6128029461989369 | validation: 0.7456046351470267]
	TIME [epoch: 41.1 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6343517803010186		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.6343517803010186 | validation: 0.7678095006100192]
	TIME [epoch: 41 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625951019287737		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.625951019287737 | validation: 0.6369682509113976]
	TIME [epoch: 41.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732825676065988		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.5732825676065988 | validation: 0.5823022017094993]
	TIME [epoch: 41 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396152679778989		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.5396152679778989 | validation: 0.9518614453615754]
	TIME [epoch: 41 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616120474437323		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.6616120474437323 | validation: 0.7649906544814015]
	TIME [epoch: 41 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5781019171551627		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.5781019171551627 | validation: 0.7744885939106689]
	TIME [epoch: 41.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391149034269951		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.6391149034269951 | validation: 0.41075509723336273]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066391653428165		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.6066391653428165 | validation: 0.6320047532588172]
	TIME [epoch: 41 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.639831813543416		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.639831813543416 | validation: 0.5666477387115443]
	TIME [epoch: 41 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6546114719476919		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.6546114719476919 | validation: 0.6129165688962014]
	TIME [epoch: 41.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303426352499837		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.6303426352499837 | validation: 1.091691024180887]
	TIME [epoch: 41.1 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7947341248560159		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.7947341248560159 | validation: 0.6065771715587157]
	TIME [epoch: 41.1 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921562011874276		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.5921562011874276 | validation: 0.5453659318515265]
	TIME [epoch: 41 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338292894131164		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.6338292894131164 | validation: 0.4560903750145288]
	TIME [epoch: 41.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.574791781402453		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.574791781402453 | validation: 0.9360622188793962]
	TIME [epoch: 41 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916614893750135		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.6916614893750135 | validation: 0.5722302578024976]
	TIME [epoch: 41.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6110227639934271		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.6110227639934271 | validation: 0.5818183345431629]
	TIME [epoch: 41.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030665102427216		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.5030665102427216 | validation: 0.6094036095095783]
	TIME [epoch: 41.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203705710173127		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.6203705710173127 | validation: 0.5376816930823334]
	TIME [epoch: 41 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770822692444539		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.5770822692444539 | validation: 0.705270971378607]
	TIME [epoch: 41.1 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636143749594086		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.5636143749594086 | validation: 0.5397915035086178]
	TIME [epoch: 41.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7041372714326275		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.7041372714326275 | validation: 0.6624546709690969]
	TIME [epoch: 41.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6770100613866334		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.6770100613866334 | validation: 0.6725026724963767]
	TIME [epoch: 41 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572940167824875		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.572940167824875 | validation: 0.5969349164837003]
	TIME [epoch: 41.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137013137041016		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.6137013137041016 | validation: 0.6950818825505106]
	TIME [epoch: 41.1 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6198753866280082		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.6198753866280082 | validation: 0.7250471987132989]
	TIME [epoch: 41.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137650730192536		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.6137650730192536 | validation: 0.6458142159181844]
	TIME [epoch: 41.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112220654840346		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.6112220654840346 | validation: 0.44924356864307097]
	TIME [epoch: 41 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48949158204498133		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.48949158204498133 | validation: 0.6793057201793082]
	TIME [epoch: 41.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8414369842259598		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.8414369842259598 | validation: 0.5793404954844934]
	TIME [epoch: 41.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201178185498186		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.6201178185498186 | validation: 0.5817441704550357]
	TIME [epoch: 41.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718821383789046		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.5718821383789046 | validation: 0.5350325858256685]
	TIME [epoch: 41.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587038387136308		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.5587038387136308 | validation: 0.4535234625576189]
	TIME [epoch: 41 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6145449549892213		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.6145449549892213 | validation: 0.6561556337323946]
	TIME [epoch: 41.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.635009599937032		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.635009599937032 | validation: 0.6991074230965462]
	TIME [epoch: 41.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127158774928856		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.6127158774928856 | validation: 0.8087308928715475]
	TIME [epoch: 41.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566070005521716		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.566070005521716 | validation: 0.6637705601228487]
	TIME [epoch: 41.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913795531137362		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.5913795531137362 | validation: 0.4051788869423155]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_761.pth
	Model improved!!!
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602579010948563		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.5602579010948563 | validation: 0.8776707570001472]
	TIME [epoch: 41 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057736874615635		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.6057736874615635 | validation: 0.41965291322863174]
	TIME [epoch: 41 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334654516270634		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.5334654516270634 | validation: 0.846284688484688]
	TIME [epoch: 41.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737442723915833		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.6737442723915833 | validation: 0.514279445135674]
	TIME [epoch: 41.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821526796813866		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.5821526796813866 | validation: 0.6070581002104689]
	TIME [epoch: 41 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189401265895844		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.6189401265895844 | validation: 0.6065547619047031]
	TIME [epoch: 41 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033783866317483		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.5033783866317483 | validation: 0.603221863509696]
	TIME [epoch: 41.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016984233162424		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.5016984233162424 | validation: 1.113239229807116]
	TIME [epoch: 41.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326916312688148		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.6326916312688148 | validation: 0.7381782562416073]
	TIME [epoch: 41 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943162495327776		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.5943162495327776 | validation: 0.44259475017377703]
	TIME [epoch: 41 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737994028526221		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.5737994028526221 | validation: 0.6499396230111619]
	TIME [epoch: 41.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5309372826612206		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.5309372826612206 | validation: 0.7687433243559907]
	TIME [epoch: 41 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6144431711535163		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.6144431711535163 | validation: 0.48656929950396766]
	TIME [epoch: 41.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6181343509960362		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.6181343509960362 | validation: 0.4955735051341734]
	TIME [epoch: 41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458213982691438		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.458213982691438 | validation: 0.6181114958282686]
	TIME [epoch: 41 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916584650098587		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.5916584650098587 | validation: 0.5227576581718625]
	TIME [epoch: 41 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497163063461892		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.6497163063461892 | validation: 0.5501944370525106]
	TIME [epoch: 41.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563370207249245		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.5563370207249245 | validation: 0.34762804367299416]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287055159671198		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.5287055159671198 | validation: 0.6082661251245136]
	TIME [epoch: 41 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234509715635943		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.5234509715635943 | validation: 0.42924548763907533]
	TIME [epoch: 41 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315007541455689		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.5315007541455689 | validation: 0.5495758278373462]
	TIME [epoch: 41.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296336502525879		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.6296336502525879 | validation: 0.6807692206773526]
	TIME [epoch: 41.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8018443182760256		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.8018443182760256 | validation: 0.5236963349514676]
	TIME [epoch: 41 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.594040884508755		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.594040884508755 | validation: 0.7710214378179308]
	TIME [epoch: 41 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.60044514914445		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.60044514914445 | validation: 0.6310438324737955]
	TIME [epoch: 41 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228324892757193		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.6228324892757193 | validation: 0.49582810185777987]
	TIME [epoch: 41 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173308122916724		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.5173308122916724 | validation: 0.4492746616042546]
	TIME [epoch: 41.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662923723776001		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.5662923723776001 | validation: 0.6178563109567607]
	TIME [epoch: 41 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038333574396006		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.6038333574396006 | validation: 0.6251044473098999]
	TIME [epoch: 41 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894977495215431		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.5894977495215431 | validation: 0.48674417586942587]
	TIME [epoch: 41 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838078422611682		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.6838078422611682 | validation: 0.8394761569177143]
	TIME [epoch: 41.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059309688434009		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.6059309688434009 | validation: 0.47283643984310986]
	TIME [epoch: 41.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613735138278471		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.5613735138278471 | validation: 0.3615202497339566]
	TIME [epoch: 41.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7168485032141879		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.7168485032141879 | validation: 0.5338273356145651]
	TIME [epoch: 41.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101483978988203		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.5101483978988203 | validation: 0.4581859309391523]
	TIME [epoch: 41 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576970028508076		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.6576970028508076 | validation: 0.8300623113858696]
	TIME [epoch: 41.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107223972323965		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.7107223972323965 | validation: 0.516644410356452]
	TIME [epoch: 41.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351087749245472		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.5351087749245472 | validation: 0.5118194560197717]
	TIME [epoch: 41.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6007058283131618		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.6007058283131618 | validation: 0.7165634363660025]
	TIME [epoch: 41.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6437836545053225		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.6437836545053225 | validation: 0.4798964710861156]
	TIME [epoch: 41 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757641464512117		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.6757641464512117 | validation: 0.6712640470021586]
	TIME [epoch: 41.1 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697775754787162		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.5697775754787162 | validation: 0.5323768543433471]
	TIME [epoch: 41.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6007894964399336		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.6007894964399336 | validation: 0.5407862093305744]
	TIME [epoch: 41 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5283029035733949		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.5283029035733949 | validation: 0.5829642882442121]
	TIME [epoch: 41.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482907549442781		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.5482907549442781 | validation: 0.45758154774392296]
	TIME [epoch: 41 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184121909844455		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.5184121909844455 | validation: 0.5945699424497963]
	TIME [epoch: 41 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865548118042321		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.6865548118042321 | validation: 0.4522285870860224]
	TIME [epoch: 41.1 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4397606857419774		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.4397606857419774 | validation: 0.815709940451683]
	TIME [epoch: 41.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432939163608993		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.6432939163608993 | validation: 0.3771261103653568]
	TIME [epoch: 41.1 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454576570894885		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.5454576570894885 | validation: 0.5757329976385857]
	TIME [epoch: 41 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6019391555108666		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.6019391555108666 | validation: 0.5881140275530392]
	TIME [epoch: 41 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45744061118317		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.45744061118317 | validation: 0.41755248329258055]
	TIME [epoch: 41.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900297812522032		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.5900297812522032 | validation: 0.644745503809453]
	TIME [epoch: 41.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519074025506752		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.5519074025506752 | validation: 0.5326105224760864]
	TIME [epoch: 41.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994173406561851		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.5994173406561851 | validation: 0.5471542723543958]
	TIME [epoch: 41 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470497178515202		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.5470497178515202 | validation: 0.5645889422650866]
	TIME [epoch: 41.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962891521824923		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.5962891521824923 | validation: 0.5128676793815985]
	TIME [epoch: 41.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302384299002896		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.5302384299002896 | validation: 0.5758562020639992]
	TIME [epoch: 41.1 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113109004920613		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.5113109004920613 | validation: 0.6104679352278422]
	TIME [epoch: 41 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334766698350537		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.5334766698350537 | validation: 0.4694614177998542]
	TIME [epoch: 41 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508468249438424		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.6508468249438424 | validation: 0.5665025575975053]
	TIME [epoch: 41 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576713005602771		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.576713005602771 | validation: 0.6344169044765766]
	TIME [epoch: 41.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529999052605332		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.5529999052605332 | validation: 0.39107616135206197]
	TIME [epoch: 41.1 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023935985348265		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.5023935985348265 | validation: 0.5921668924419483]
	TIME [epoch: 41 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321836309657968		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.5321836309657968 | validation: 0.5717924555024652]
	TIME [epoch: 41 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287662322169064		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.5287662322169064 | validation: 0.5196045649297802]
	TIME [epoch: 41 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512480073750745		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.512480073750745 | validation: 0.3675270829074626]
	TIME [epoch: 41 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5566698571385813		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.5566698571385813 | validation: 0.6397099655426577]
	TIME [epoch: 41 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4595813513777268		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.4595813513777268 | validation: 0.49476078579700666]
	TIME [epoch: 41 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520598895029654		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.5520598895029654 | validation: 0.5984364214905555]
	TIME [epoch: 41 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800429722906696		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.5800429722906696 | validation: 0.4470617252353829]
	TIME [epoch: 41 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517313388495809		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.517313388495809 | validation: 0.6269970834895409]
	TIME [epoch: 41 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218546594369902		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.5218546594369902 | validation: 0.5505913764421735]
	TIME [epoch: 41 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183236384260999		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.4183236384260999 | validation: 0.44272343137596937]
	TIME [epoch: 41 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6426044149552936		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.6426044149552936 | validation: 0.5203376864718954]
	TIME [epoch: 41 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426162354340657		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.5426162354340657 | validation: 0.4043013257897891]
	TIME [epoch: 41 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032228076195072		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.6032228076195072 | validation: 0.46151747230306894]
	TIME [epoch: 41.1 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44753452316513115		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.44753452316513115 | validation: 0.5175482520693184]
	TIME [epoch: 41.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5555392210688708		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.5555392210688708 | validation: 0.6372428869438773]
	TIME [epoch: 41.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852001394209872		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.4852001394209872 | validation: 0.562503979567297]
	TIME [epoch: 41 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5084778965950602		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.5084778965950602 | validation: 0.4920462006314864]
	TIME [epoch: 41 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47192733827408617		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.47192733827408617 | validation: 0.5091927555214434]
	TIME [epoch: 41.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271284669207508		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.5271284669207508 | validation: 0.4089273899715592]
	TIME [epoch: 41.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295622401019565		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.6295622401019565 | validation: 0.4708429144522248]
	TIME [epoch: 41 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6652491438804495		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.6652491438804495 | validation: 0.361324375091918]
	TIME [epoch: 41 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037408987066021		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.4037408987066021 | validation: 0.49298730981076766]
	TIME [epoch: 41.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563093898034972		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.5563093898034972 | validation: 0.5215450233340911]
	TIME [epoch: 41 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5671193283604816		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.5671193283604816 | validation: 0.5258432720978748]
	TIME [epoch: 41 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4859885025615531		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.4859885025615531 | validation: 0.44981872143211055]
	TIME [epoch: 41.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861360411472059		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.4861360411472059 | validation: 0.6457442961951503]
	TIME [epoch: 41 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230331996243245		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.5230331996243245 | validation: 0.7556650477232925]
	TIME [epoch: 41.1 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666686826403203		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.5666686826403203 | validation: 0.6429215373950135]
	TIME [epoch: 41.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316202106241675		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.5316202106241675 | validation: 0.6002787933144413]
	TIME [epoch: 41.1 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785675551601012		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.4785675551601012 | validation: 0.3928899166882572]
	TIME [epoch: 41 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489033009683157		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.4489033009683157 | validation: 0.4060290746571952]
	TIME [epoch: 41 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852467643903079		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.4852467643903079 | validation: 0.4666333096744816]
	TIME [epoch: 41 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381566727255768		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.5381566727255768 | validation: 0.47557586745264135]
	TIME [epoch: 41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545293883535148		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.545293883535148 | validation: 0.4168351435039766]
	TIME [epoch: 41 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4902374551290738		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.4902374551290738 | validation: 0.5222292995340272]
	TIME [epoch: 41 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302022576272682		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.5302022576272682 | validation: 0.6232949828781704]
	TIME [epoch: 41 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49554363186886535		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.49554363186886535 | validation: 0.47755649677705114]
	TIME [epoch: 41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5006073947172477		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.5006073947172477 | validation: 0.5444454831595439]
	TIME [epoch: 41 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376123871865		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.5376123871865 | validation: 0.44831021559202655]
	TIME [epoch: 41.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048795164234248		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.5048795164234248 | validation: 0.5196853518538679]
	TIME [epoch: 41 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367445957724647		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.4367445957724647 | validation: 0.5283169534692472]
	TIME [epoch: 41 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589119973439631		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.4589119973439631 | validation: 0.5474051220153515]
	TIME [epoch: 41 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407604727524371		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.4407604727524371 | validation: 0.4069748921521757]
	TIME [epoch: 41 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554137488672329		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.5554137488672329 | validation: 0.40442819234277194]
	TIME [epoch: 41 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062099045031638		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.5062099045031638 | validation: 0.6228173350563025]
	TIME [epoch: 41 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456959132783807		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.5456959132783807 | validation: 0.7222025434926687]
	TIME [epoch: 41 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5092930159722515		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.5092930159722515 | validation: 0.4829781614929296]
	TIME [epoch: 41.1 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190051583241438		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.5190051583241438 | validation: 0.49958181969258497]
	TIME [epoch: 41 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044631033162406		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.5044631033162406 | validation: 0.6268727771287113]
	TIME [epoch: 41 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47142491136487485		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.47142491136487485 | validation: 0.6909208016296173]
	TIME [epoch: 41.1 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336007069818651		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.5336007069818651 | validation: 0.448213106528119]
	TIME [epoch: 41 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4508124021756423		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.4508124021756423 | validation: 0.5360698100065941]
	TIME [epoch: 41 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5526461552809763		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.5526461552809763 | validation: 0.42851635142553823]
	TIME [epoch: 41.1 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500017379605934		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.500017379605934 | validation: 0.5163396821467506]
	TIME [epoch: 41 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532093058578626		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.4532093058578626 | validation: 0.5721667977354149]
	TIME [epoch: 41 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184687522318393		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.5184687522318393 | validation: 0.49433967717694005]
	TIME [epoch: 41 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49556159542231026		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.49556159542231026 | validation: 0.7187698493610586]
	TIME [epoch: 41.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191267829860015		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.5191267829860015 | validation: 1.0723968147557257]
	TIME [epoch: 41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5571946264806451		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.5571946264806451 | validation: 0.4934620897911113]
	TIME [epoch: 41.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022199307276558		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.5022199307276558 | validation: 0.4864762234594151]
	TIME [epoch: 41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48547334382576646		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.48547334382576646 | validation: 0.3254405561956491]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_886.pth
	Model improved!!!
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193158121990844		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.4193158121990844 | validation: 0.4680300039973464]
	TIME [epoch: 41 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48888042806622967		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.48888042806622967 | validation: 0.7466987711017068]
	TIME [epoch: 41 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971057571442662		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.4971057571442662 | validation: 0.4119563109044514]
	TIME [epoch: 41 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49264201315380685		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.49264201315380685 | validation: 0.5295364090130921]
	TIME [epoch: 41 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4606982790395697		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.4606982790395697 | validation: 0.5224125056480395]
	TIME [epoch: 41 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47066041799379776		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.47066041799379776 | validation: 0.286135652345239]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220448144269954		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.5220448144269954 | validation: 0.41685986155208493]
	TIME [epoch: 41 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629768589281005		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.4629768589281005 | validation: 0.7335298414403479]
	TIME [epoch: 41 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.534260152598268		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.534260152598268 | validation: 0.6137830972471854]
	TIME [epoch: 41 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128711051043124		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.5128711051043124 | validation: 0.3902745101723517]
	TIME [epoch: 40.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150205006841841		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.5150205006841841 | validation: 0.9722683759533464]
	TIME [epoch: 41 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815896700714022		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.5815896700714022 | validation: 0.3788472415336751]
	TIME [epoch: 41 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109215414549751		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.5109215414549751 | validation: 0.5448446010898249]
	TIME [epoch: 41 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46552332992688694		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.46552332992688694 | validation: 0.6435597924542813]
	TIME [epoch: 41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004912649195559		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.5004912649195559 | validation: 0.49343608332384314]
	TIME [epoch: 41 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4161030081788322		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.4161030081788322 | validation: 0.37162974101884827]
	TIME [epoch: 41 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4353411748371291		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.4353411748371291 | validation: 0.4923329655514088]
	TIME [epoch: 41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651029160987791		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.651029160987791 | validation: 0.37569356118512304]
	TIME [epoch: 41 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40711704973477864		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.40711704973477864 | validation: 0.5685330856774664]
	TIME [epoch: 41 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51525836918741		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.51525836918741 | validation: 0.5053164422382497]
	TIME [epoch: 41 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435034972449559		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.4435034972449559 | validation: 0.348643970796177]
	TIME [epoch: 41 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4926476928213094		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.4926476928213094 | validation: 0.30634088462551273]
	TIME [epoch: 41 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4310965985842389		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.4310965985842389 | validation: 0.7784370605052335]
	TIME [epoch: 41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779403432130694		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.5779403432130694 | validation: 0.5089867849737858]
	TIME [epoch: 41 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693279679019823		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.4693279679019823 | validation: 0.9612403918407073]
	TIME [epoch: 41 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6601140058367252		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.6601140058367252 | validation: 0.39598149299928265]
	TIME [epoch: 41 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.403385032348364		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.403385032348364 | validation: 0.3951846552831187]
	TIME [epoch: 41 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34960743357603496		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.34960743357603496 | validation: 0.3997020051086795]
	TIME [epoch: 41.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151625158416349		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.4151625158416349 | validation: 0.665083771659497]
	TIME [epoch: 41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515547313702815		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.5515547313702815 | validation: 0.37040808837768124]
	TIME [epoch: 41 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679355771769551		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.4679355771769551 | validation: 0.6706144327920719]
	TIME [epoch: 41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059454359410288		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.5059454359410288 | validation: 0.5652227497136286]
	TIME [epoch: 41 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39500761602577533		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.39500761602577533 | validation: 0.5058801268691144]
	TIME [epoch: 41 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261986371728924		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.3261986371728924 | validation: 0.9227049869924244]
	TIME [epoch: 41 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758604762601596		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.5758604762601596 | validation: 0.402377007401234]
	TIME [epoch: 41 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771831025310948		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.4771831025310948 | validation: 0.44331240927888804]
	TIME [epoch: 41 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4292850075036505		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.4292850075036505 | validation: 0.520491649953057]
	TIME [epoch: 41.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389059540553117		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.389059540553117 | validation: 0.5098205806540154]
	TIME [epoch: 41 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46628501298644687		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.46628501298644687 | validation: 0.36791501379559644]
	TIME [epoch: 41 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709996307969445		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.4709996307969445 | validation: 0.47960252425277144]
	TIME [epoch: 41 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424755094028251		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.4424755094028251 | validation: 0.6402643202358589]
	TIME [epoch: 41.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311487293303758		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.5311487293303758 | validation: 0.5994324578785077]
	TIME [epoch: 41 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4167283791867386		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.4167283791867386 | validation: 0.3317227379401353]
	TIME [epoch: 41 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45278808194044806		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.45278808194044806 | validation: 0.44148035782822537]
	TIME [epoch: 41 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760336831931459		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.3760336831931459 | validation: 0.656105762191833]
	TIME [epoch: 41 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608853370247182		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.608853370247182 | validation: 0.44778257761427254]
	TIME [epoch: 41 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892519673140675		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.3892519673140675 | validation: 0.40659823098677583]
	TIME [epoch: 41 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045879619973553		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.4045879619973553 | validation: 0.4219711332175115]
	TIME [epoch: 41 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177462829555043		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.5177462829555043 | validation: 0.3920601883668343]
	TIME [epoch: 41 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4261136739505542		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.4261136739505542 | validation: 0.38968573451919225]
	TIME [epoch: 41 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713384394003272		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.5713384394003272 | validation: 0.455132387449867]
	TIME [epoch: 41 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4725935026935964		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.4725935026935964 | validation: 0.5906614661580635]
	TIME [epoch: 41 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5352353852488454		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.5352353852488454 | validation: 0.4953000208750131]
	TIME [epoch: 41 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515840657846427		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.515840657846427 | validation: 0.4086706364652113]
	TIME [epoch: 41 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050316923410965		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.5050316923410965 | validation: 0.5176166991691744]
	TIME [epoch: 41 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42240479955229404		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.42240479955229404 | validation: 0.43707210993556245]
	TIME [epoch: 41 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45750762860912353		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.45750762860912353 | validation: 0.46087115453909966]
	TIME [epoch: 41 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422528774963294		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.422528774963294 | validation: 0.4558790481178768]
	TIME [epoch: 41 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428193898152782		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.4428193898152782 | validation: 0.5530347405156248]
	TIME [epoch: 41 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282112538229102		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.6282112538229102 | validation: 0.3461036409672171]
	TIME [epoch: 41 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43464453884532306		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.43464453884532306 | validation: 0.37825078186999095]
	TIME [epoch: 41 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4439555402912714		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.4439555402912714 | validation: 0.42526008046549196]
	TIME [epoch: 41 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731318497502488		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.3731318497502488 | validation: 0.3706850348968948]
	TIME [epoch: 41 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.430158099562685		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.430158099562685 | validation: 0.40698060097715527]
	TIME [epoch: 41 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4520111135810804		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.4520111135810804 | validation: 0.5194539982790735]
	TIME [epoch: 41 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4886959192088933		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.4886959192088933 | validation: 0.4130842127931293]
	TIME [epoch: 41 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481797859956502		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.4481797859956502 | validation: 0.6604881628292303]
	TIME [epoch: 41 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722123768965248		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.3722123768965248 | validation: 0.2894192351250467]
	TIME [epoch: 41 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4396663776836249		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.4396663776836249 | validation: 0.47430457795251046]
	TIME [epoch: 41 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4765479481790353		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.4765479481790353 | validation: 0.5195812037233783]
	TIME [epoch: 41 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49641591912516564		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.49641591912516564 | validation: 0.48620614492512204]
	TIME [epoch: 41 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41361064078132204		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.41361064078132204 | validation: 0.4659567678262112]
	TIME [epoch: 41 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44539119461664867		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.44539119461664867 | validation: 0.3204246107675983]
	TIME [epoch: 41 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011627681171754		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.4011627681171754 | validation: 0.4194872190697988]
	TIME [epoch: 41 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38246575037793096		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.38246575037793096 | validation: 0.4028979626989233]
	TIME [epoch: 41 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42251509230004974		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.42251509230004974 | validation: 0.5437258515594697]
	TIME [epoch: 41 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4699688566374598		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.4699688566374598 | validation: 0.327774568787516]
	TIME [epoch: 41 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4429318690683295		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.4429318690683295 | validation: 0.3544997854990627]
	TIME [epoch: 41 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424272011393513		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.4424272011393513 | validation: 0.3339704747755243]
	TIME [epoch: 41 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42162099397076563		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.42162099397076563 | validation: 0.4439118209645318]
	TIME [epoch: 41 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40095640993898957		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.40095640993898957 | validation: 0.4189077398367564]
	TIME [epoch: 41.1 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189200570850289		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.4189200570850289 | validation: 0.5751795786090028]
	TIME [epoch: 41 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38425425242843214		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.38425425242843214 | validation: 0.34421377475645853]
	TIME [epoch: 41 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34345079412023805		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.34345079412023805 | validation: 0.43864571456151086]
	TIME [epoch: 41 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491153600327828		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.491153600327828 | validation: 0.3408990125853506]
	TIME [epoch: 41 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47550046811689484		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.47550046811689484 | validation: 0.35418477245322977]
	TIME [epoch: 41.1 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36402015894543277		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.36402015894543277 | validation: 0.353730519768107]
	TIME [epoch: 41 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4104126481447183		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.4104126481447183 | validation: 0.47218066522685564]
	TIME [epoch: 41 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824564055232159		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.3824564055232159 | validation: 0.3098296546588597]
	TIME [epoch: 41 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634639505460737		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.4634639505460737 | validation: 0.36991635684323404]
	TIME [epoch: 41 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911900258676157		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.3911900258676157 | validation: 0.5634038016479849]
	TIME [epoch: 41 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591192219652377		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.3591192219652377 | validation: 0.6440852276222115]
	TIME [epoch: 41 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651428902948028		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.5651428902948028 | validation: 0.3720814246095535]
	TIME [epoch: 41 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3690361425930544		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.3690361425930544 | validation: 0.38242928120381336]
	TIME [epoch: 41.1 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4400777101444399		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.4400777101444399 | validation: 0.342560175296867]
	TIME [epoch: 41 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37654586529733336		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.37654586529733336 | validation: 0.393236689446094]
	TIME [epoch: 41 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688106530657791		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.4688106530657791 | validation: 0.547396291984271]
	TIME [epoch: 41 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4422784339524709		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.4422784339524709 | validation: 0.567399371159534]
	TIME [epoch: 41 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3459932253937187		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.3459932253937187 | validation: 0.7211439350163549]
	TIME [epoch: 41 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44455408933534535		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.44455408933534535 | validation: 0.42339037812919184]
	TIME [epoch: 41 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137344833934059		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.4137344833934059 | validation: 0.33187137332696265]
	TIME [epoch: 41 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39240179207357123		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.39240179207357123 | validation: 0.3471020142099724]
	TIME [epoch: 41.1 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33853828373034156		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.33853828373034156 | validation: 0.4710928088565977]
	TIME [epoch: 41.1 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40108471291041115		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.40108471291041115 | validation: 0.39192599237811293]
	TIME [epoch: 41 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39811564777132713		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.39811564777132713 | validation: 0.5188434958994004]
	TIME [epoch: 41 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3834737253202114		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.3834737253202114 | validation: 0.4181651039103659]
	TIME [epoch: 41 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49012946325502815		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.49012946325502815 | validation: 0.369264037965719]
	TIME [epoch: 41 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573283271265367		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.3573283271265367 | validation: 0.2578091373535367]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_994.pth
	Model improved!!!
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4178865522171849		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.4178865522171849 | validation: 0.450192576593457]
	TIME [epoch: 41 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779678018437469		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.3779678018437469 | validation: 0.33095062857593105]
	TIME [epoch: 41 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123006392350864		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.3123006392350864 | validation: 0.4608042002867598]
	TIME [epoch: 41 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44184401024961883		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.44184401024961883 | validation: 0.3242388552564869]
	TIME [epoch: 41 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42991290874334465		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.42991290874334465 | validation: 0.5412433672872574]
	TIME [epoch: 41 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42281098724648536		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.42281098724648536 | validation: 0.43817139481965844]
	TIME [epoch: 41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814607998524575		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.3814607998524575 | validation: 0.5695439378135313]
	TIME [epoch: 180 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41100822027662876		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.41100822027662876 | validation: 0.49111665601891574]
	TIME [epoch: 87.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931748389660238		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.3931748389660238 | validation: 0.3145354938058651]
	TIME [epoch: 87.1 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971376542425227		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.3971376542425227 | validation: 0.36886971870407814]
	TIME [epoch: 87.1 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38951813762909687		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.38951813762909687 | validation: 0.47106879532458534]
	TIME [epoch: 87.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542873789957596		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.3542873789957596 | validation: 0.33226950762516133]
	TIME [epoch: 87.1 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303208696510982		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.3303208696510982 | validation: 0.4246414095718525]
	TIME [epoch: 87.1 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202318277751333		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.4202318277751333 | validation: 0.34215123023476324]
	TIME [epoch: 87.1 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268230927830765		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.4268230927830765 | validation: 0.4298934068972421]
	TIME [epoch: 87.1 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44078771662231103		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.44078771662231103 | validation: 0.31414657562457193]
	TIME [epoch: 87.1 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36027357271149674		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.36027357271149674 | validation: 0.34655118871639495]
	TIME [epoch: 87.1 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32560028249522777		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.32560028249522777 | validation: 0.4767202825192708]
	TIME [epoch: 87.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618089844702089		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.3618089844702089 | validation: 0.31208855033966787]
	TIME [epoch: 87 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32176227592126594		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.32176227592126594 | validation: 0.30650117163893753]
	TIME [epoch: 86.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871532995853137		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.3871532995853137 | validation: 0.3387396755015584]
	TIME [epoch: 86.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41783825941345687		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.41783825941345687 | validation: 0.3223414216356425]
	TIME [epoch: 86.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42375520145552786		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.42375520145552786 | validation: 0.3186980294094788]
	TIME [epoch: 86.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35650344633820785		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.35650344633820785 | validation: 0.3076436642596668]
	TIME [epoch: 86.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4344124475184841		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.4344124475184841 | validation: 0.3375187151930201]
	TIME [epoch: 86.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705119280690261		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.3705119280690261 | validation: 0.4221753964327954]
	TIME [epoch: 86.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895958541221965		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.3895958541221965 | validation: 0.3405058855181529]
	TIME [epoch: 86.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255725856096606		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.3255725856096606 | validation: 0.4060031779865078]
	TIME [epoch: 86.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131309183049877		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.4131309183049877 | validation: 0.3139998468704355]
	TIME [epoch: 86.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34151568302535995		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.34151568302535995 | validation: 0.32992560574443]
	TIME [epoch: 86.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32812880368463193		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.32812880368463193 | validation: 0.34239419994666226]
	TIME [epoch: 86.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40994238546560696		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.40994238546560696 | validation: 0.3708212346833119]
	TIME [epoch: 86.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153945305741891		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.4153945305741891 | validation: 0.3879851448265287]
	TIME [epoch: 86.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448390512481936		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.3448390512481936 | validation: 0.30284792011159845]
	TIME [epoch: 86.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308037229483167		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.3308037229483167 | validation: 0.30414559542533637]
	TIME [epoch: 86.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34760725299933337		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.34760725299933337 | validation: 0.35350884303631647]
	TIME [epoch: 86.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591241948817021		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.3591241948817021 | validation: 0.2562014601026099]
	TIME [epoch: 86.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_1031.pth
	Model improved!!!
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508555710917158		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.3508555710917158 | validation: 0.33149831509170397]
	TIME [epoch: 86.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47491627351281324		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.47491627351281324 | validation: 0.4460490236947562]
	TIME [epoch: 86.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35476697913249144		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.35476697913249144 | validation: 0.2980198366053487]
	TIME [epoch: 86.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778192206618622		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.3778192206618622 | validation: 0.3227725658350873]
	TIME [epoch: 86.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37472059465671764		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.37472059465671764 | validation: 0.28669474441478005]
	TIME [epoch: 86.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519394050210931		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.3519394050210931 | validation: 0.5187579351828571]
	TIME [epoch: 86.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621418956391407		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.3621418956391407 | validation: 0.28368436685256115]
	TIME [epoch: 86.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34575179844255477		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.34575179844255477 | validation: 0.37288843721290477]
	TIME [epoch: 86.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4145288803566754		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.4145288803566754 | validation: 0.37472853190594646]
	TIME [epoch: 86.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3557939053598453		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.3557939053598453 | validation: 0.374522214062768]
	TIME [epoch: 86.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3272397055109941		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.3272397055109941 | validation: 0.4600200500040589]
	TIME [epoch: 86.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39364084117776826		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.39364084117776826 | validation: 0.3262606051131546]
	TIME [epoch: 86.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184078832280094		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.3184078832280094 | validation: 0.4777665435158931]
	TIME [epoch: 86.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41957472996396106		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.41957472996396106 | validation: 0.22590527138191455]
	TIME [epoch: 86.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31572067996478936		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.31572067996478936 | validation: 0.2757963339491086]
	TIME [epoch: 86.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35169171563324525		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.35169171563324525 | validation: 0.50311956213968]
	TIME [epoch: 86.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001442790604197		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.4001442790604197 | validation: 0.23628434494146738]
	TIME [epoch: 86.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41510975396906874		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.41510975396906874 | validation: 0.3065840673158535]
	TIME [epoch: 86.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521688823237239		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.3521688823237239 | validation: 0.36049612809202713]
	TIME [epoch: 86.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32928060094972056		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.32928060094972056 | validation: 0.4059176872734728]
	TIME [epoch: 86.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533109447159511		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.4533109447159511 | validation: 0.34631180463352895]
	TIME [epoch: 86.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36678734177952926		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.36678734177952926 | validation: 0.36019814245112636]
	TIME [epoch: 86.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909457409196978		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.2909457409196978 | validation: 0.27569307537920623]
	TIME [epoch: 86.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27509884609863977		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.27509884609863977 | validation: 0.3934866692445923]
	TIME [epoch: 86.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40315645675752404		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.40315645675752404 | validation: 0.34119457451403734]
	TIME [epoch: 86.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31462973563171936		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.31462973563171936 | validation: 0.4049852624981881]
	TIME [epoch: 86.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30712088078671046		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.30712088078671046 | validation: 0.3201929128740455]
	TIME [epoch: 86.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220826345897802		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.3220826345897802 | validation: 0.6659386900688604]
	TIME [epoch: 86.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42722611925190596		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.42722611925190596 | validation: 0.33819316557385504]
	TIME [epoch: 86.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41091674396419325		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.41091674396419325 | validation: 0.35674882668526575]
	TIME [epoch: 86.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36758216030266067		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.36758216030266067 | validation: 0.5155670672694557]
	TIME [epoch: 86.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454205220234267		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.5454205220234267 | validation: 0.3427694288446186]
	TIME [epoch: 86.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36885768363351457		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.36885768363351457 | validation: 0.5949773453050362]
	TIME [epoch: 86.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46325865271974864		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.46325865271974864 | validation: 0.41589518923961266]
	TIME [epoch: 86.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602012308507678		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.3602012308507678 | validation: 0.24815176136100786]
	TIME [epoch: 86.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915202920933945		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.2915202920933945 | validation: 0.3677466073218657]
	TIME [epoch: 86.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155090140085545		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.4155090140085545 | validation: 0.44130164316858017]
	TIME [epoch: 86.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284583472566399		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.3284583472566399 | validation: 0.38654575203409636]
	TIME [epoch: 86.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30708133657862835		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.30708133657862835 | validation: 0.24120154710353298]
	TIME [epoch: 86.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33848551478232913		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.33848551478232913 | validation: 0.47639311999898815]
	TIME [epoch: 86.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996771094106631		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.3996771094106631 | validation: 0.38458653060579995]
	TIME [epoch: 86.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667580351661166		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.3667580351661166 | validation: 0.28586938533913675]
	TIME [epoch: 86.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334846327691748		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.3334846327691748 | validation: 0.27937150569452757]
	TIME [epoch: 86.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31944289285378313		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.31944289285378313 | validation: 0.5791742833276897]
	TIME [epoch: 86.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182879691031282		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.3182879691031282 | validation: 0.4191690717078843]
	TIME [epoch: 86.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746486919987301		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.3746486919987301 | validation: 0.29530122417592986]
	TIME [epoch: 86.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418006830668121		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.3418006830668121 | validation: 0.5256574357877463]
	TIME [epoch: 86.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4235072892722057		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.4235072892722057 | validation: 0.6223589402521719]
	TIME [epoch: 86.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40595102289633617		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.40595102289633617 | validation: 0.3911617496212507]
	TIME [epoch: 86.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326476722864205		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.4326476722864205 | validation: 0.27671410808034547]
	TIME [epoch: 86.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3057106317577456		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.3057106317577456 | validation: 0.2775361675241099]
	TIME [epoch: 86.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30524556275563763		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.30524556275563763 | validation: 0.37888258235039574]
	TIME [epoch: 86.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588435331009607		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.3588435331009607 | validation: 0.272941225205485]
	TIME [epoch: 86.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38044811817730007		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.38044811817730007 | validation: 0.2624027790748429]
	TIME [epoch: 86.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538050652351915		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.3538050652351915 | validation: 0.5313270926561017]
	TIME [epoch: 86.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36493916405170934		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.36493916405170934 | validation: 0.26597875578110497]
	TIME [epoch: 86.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658708502845567		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.3658708502845567 | validation: 0.3091630597203465]
	TIME [epoch: 86.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3305224026013894		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.3305224026013894 | validation: 0.26345675782533223]
	TIME [epoch: 86.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930281025991087		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.2930281025991087 | validation: 0.2685221297086397]
	TIME [epoch: 86.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34630865767302466		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.34630865767302466 | validation: 0.5472909954968843]
	TIME [epoch: 86.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38843744755958665		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.38843744755958665 | validation: 0.26378492880423987]
	TIME [epoch: 86.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266735961386819		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.266735961386819 | validation: 0.37188444657333775]
	TIME [epoch: 86.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234091072559995		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.3234091072559995 | validation: 0.4047313970976961]
	TIME [epoch: 86.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353556601436348		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.3353556601436348 | validation: 0.2701496163334839]
	TIME [epoch: 86.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328139207151567		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.328139207151567 | validation: 0.2864862872517012]
	TIME [epoch: 86.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406307207249829		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.3406307207249829 | validation: 0.27638065759756436]
	TIME [epoch: 86.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267927337641988		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.3267927337641988 | validation: 0.2619489525397462]
	TIME [epoch: 86.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287650515965952		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.3287650515965952 | validation: 0.9098242525410623]
	TIME [epoch: 86.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090325782513541		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.4090325782513541 | validation: 0.6288570060448044]
	TIME [epoch: 86.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3150825828138783		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.3150825828138783 | validation: 0.5314502059962125]
	TIME [epoch: 86.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454607817876236		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.3454607817876236 | validation: 0.24862904497669347]
	TIME [epoch: 86.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24909182458011916		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.24909182458011916 | validation: 0.16048380324331912]
	TIME [epoch: 86.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240705_085735/states/model_phi1_1a_v_kl5_1103.pth
	Model improved!!!
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30898460875306055		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.30898460875306055 | validation: 0.341352807263934]
	TIME [epoch: 86.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713852925028494		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.3713852925028494 | validation: 0.2314358238304479]
	TIME [epoch: 86.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25839820763695354		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.25839820763695354 | validation: 0.31867304990464274]
	TIME [epoch: 86.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4244099895725024		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.4244099895725024 | validation: 0.2751045448700052]
	TIME [epoch: 86.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34162594077066283		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.34162594077066283 | validation: 0.41297041196534534]
	TIME [epoch: 86.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30939485383764026		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.30939485383764026 | validation: 0.2697465184089483]
	TIME [epoch: 86.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735145451814571		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.3735145451814571 | validation: 0.22803465401480932]
	TIME [epoch: 86.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27039062535077335		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.27039062535077335 | validation: 0.43738681209984065]
	TIME [epoch: 86.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758942271727378		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.2758942271727378 | validation: 0.4425201520442088]
	TIME [epoch: 86.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879189601068366		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.3879189601068366 | validation: 0.324598299147629]
	TIME [epoch: 86.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031483544462186		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.3031483544462186 | validation: 0.25130022764839016]
	TIME [epoch: 86.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923039814095525		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.2923039814095525 | validation: 0.21543335208602077]
	TIME [epoch: 86.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2717544904364231		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.2717544904364231 | validation: 0.4944276448286392]
	TIME [epoch: 86.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31640979670129205		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.31640979670129205 | validation: 0.2423093216698115]
	TIME [epoch: 86.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3206220638582056		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.3206220638582056 | validation: 0.2933540732300807]
	TIME [epoch: 86.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36547827692613555		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.36547827692613555 | validation: 0.22942643934695056]
	TIME [epoch: 86.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872048505405961		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.2872048505405961 | validation: 0.2900056149845288]
	TIME [epoch: 86.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131441705000999		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.3131441705000999 | validation: 0.30587575811233086]
	TIME [epoch: 86.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036906149578773		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.3036906149578773 | validation: 0.4020122487325583]
	TIME [epoch: 86.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29647148304738224		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.29647148304738224 | validation: 0.2864858272818326]
	TIME [epoch: 86.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311592730117882		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.3311592730117882 | validation: 0.3357668265308411]
	TIME [epoch: 86.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858687418628253		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.2858687418628253 | validation: 0.3224434065813982]
	TIME [epoch: 86.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846111525216882		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.2846111525216882 | validation: 0.4174365927140927]
	TIME [epoch: 86.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32912059181057207		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.32912059181057207 | validation: 0.2891727719700987]
	TIME [epoch: 86.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41118094293388213		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.41118094293388213 | validation: 0.4671470513925924]
	TIME [epoch: 86.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686917608728926		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.3686917608728926 | validation: 0.3207357434105078]
	TIME [epoch: 86.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23161035251122508		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.23161035251122508 | validation: 0.4103094679994398]
	TIME [epoch: 86.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737009799174727		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.2737009799174727 | validation: 0.3517332905689641]
	TIME [epoch: 86.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350434590553228		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.350434590553228 | validation: 0.2739077571585943]
	TIME [epoch: 86.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3050373283345988		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.3050373283345988 | validation: 0.27941512208943275]
	TIME [epoch: 86.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420533321150231		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.3420533321150231 | validation: 0.42742762091578046]
	TIME [epoch: 86.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30474460026736666		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.30474460026736666 | validation: 0.4070332069348679]
	TIME [epoch: 86.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3235235417144188		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.3235235417144188 | validation: 0.3412879428315896]
	TIME [epoch: 86.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34463285738357097		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.34463285738357097 | validation: 0.45542549334573545]
	TIME [epoch: 86.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034380073897339		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.3034380073897339 | validation: 0.3298193863290306]
	TIME [epoch: 86.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32816010481425406		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.32816010481425406 | validation: 0.4082391610026847]
	TIME [epoch: 86.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33548508301226165		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.33548508301226165 | validation: 0.3780817060381213]
	TIME [epoch: 86.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3150058172458286		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.3150058172458286 | validation: 0.21781185558292848]
	TIME [epoch: 86.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074775241117327		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.3074775241117327 | validation: 0.2437447280854671]
	TIME [epoch: 86.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21810611115846557		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.21810611115846557 | validation: 0.28646586964352]
	TIME [epoch: 86.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28751478287322774		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.28751478287322774 | validation: 0.3235704198328825]
	TIME [epoch: 86.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32056900997197535		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.32056900997197535 | validation: 0.2248377649874756]
	TIME [epoch: 86.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2865313513737778		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.2865313513737778 | validation: 0.26627079350604466]
	TIME [epoch: 86.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32394604463107657		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.32394604463107657 | validation: 0.23413878936616114]
	TIME [epoch: 86.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259005534880617		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.3259005534880617 | validation: 0.3460932673405463]
	TIME [epoch: 86.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28367435026407317		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.28367435026407317 | validation: 0.36327997976793713]
	TIME [epoch: 86.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734546276539025		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.2734546276539025 | validation: 0.22866052917397434]
	TIME [epoch: 86.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273160239592847		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.3273160239592847 | validation: 0.5863069481195433]
	TIME [epoch: 86.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46917360885057297		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.46917360885057297 | validation: 0.46030394398038754]
	TIME [epoch: 86.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38699887409025313		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.38699887409025313 | validation: 0.20371354519631807]
	TIME [epoch: 86.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29801028229125437		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.29801028229125437 | validation: 0.2680821995377324]
	TIME [epoch: 86.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29369165836261457		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.29369165836261457 | validation: 0.21933352579381787]
	TIME [epoch: 86.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174279701708141		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.2174279701708141 | validation: 0.3202933825401544]
	TIME [epoch: 86.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29730209114545314		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.29730209114545314 | validation: 0.3382402101943016]
	TIME [epoch: 86.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000007203626567		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.3000007203626567 | validation: 0.23121387585145892]
	TIME [epoch: 86.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23044046795196482		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.23044046795196482 | validation: 0.3218829758177606]
	TIME [epoch: 86.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23536886150956532		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.23536886150956532 | validation: 0.5305176740351447]
	TIME [epoch: 86.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362626375714658		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.362626375714658 | validation: 0.22582481594588005]
	TIME [epoch: 86.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32393943015768334		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.32393943015768334 | validation: 0.3796934038470619]
	TIME [epoch: 86.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868622394286533		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.2868622394286533 | validation: 0.3349799647950907]
	TIME [epoch: 86.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870478426174443		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.2870478426174443 | validation: 0.44012198554958204]
	TIME [epoch: 86.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3251520118596001		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.3251520118596001 | validation: 0.2593486340133053]
	TIME [epoch: 86.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24771754048522612		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.24771754048522612 | validation: 0.3567178326409396]
	TIME [epoch: 86.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772428810028243		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.2772428810028243 | validation: 0.28915420662075175]
	TIME [epoch: 86.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2862063510910493		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.2862063510910493 | validation: 0.24606050366256071]
	TIME [epoch: 86.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680133207999107		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.2680133207999107 | validation: 0.4328290852828305]
	TIME [epoch: 86.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27801224670648084		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.27801224670648084 | validation: 0.2527906923637524]
	TIME [epoch: 86.8 sec]
EPOCH 1171/2000:
	Training over batches...
