Args:
Namespace(name='model_phi1_3c_v_mmd1', outdir='out/model_training/model_phi1_3c_v_mmd1', training_data='data/training_data/data_phi1_3c/training', validation_data='data/training_data/data_phi1_3c/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1471354672

Training model...

Saving initial model state to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.8395417159284255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8395417159284255 | validation: 6.58291570946897]
	TIME [epoch: 28.4 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.464289913280354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.464289913280354 | validation: 6.068973354231781]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.8928639016918805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8928639016918805 | validation: 5.288965413932655]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.973621991776264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.973621991776264 | validation: 6.492421504576004]
	TIME [epoch: 3.79 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.455525331927312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.455525331927312 | validation: 5.501999887840949]
	TIME [epoch: 3.78 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.134725069245826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.134725069245826 | validation: 5.468703399468308]
	TIME [epoch: 3.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.235062373150739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.235062373150739 | validation: 5.19271249453108]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.885582721692401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.885582721692401 | validation: 5.22719219333314]
	TIME [epoch: 3.86 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.84500394931741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.84500394931741 | validation: 4.901956281779168]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.472458109117799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.472458109117799 | validation: 4.8938942150569]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.520594300905097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.520594300905097 | validation: 4.782045554095274]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.361430742909463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.361430742909463 | validation: 4.709233092791811]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.313081607060085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.313081607060085 | validation: 4.66488031884121]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.27889415535053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.27889415535053 | validation: 4.656087276738453]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.243222911709057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.243222911709057 | validation: 4.565280303943456]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.206156396683706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.206156396683706 | validation: 4.559356976961233]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.18768013909459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.18768013909459 | validation: 4.524352243009892]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.184074269821698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.184074269821698 | validation: 4.527032528882045]
	TIME [epoch: 3.78 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.181564471573662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.181564471573662 | validation: 4.444059293344383]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.1205133410025425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1205133410025425 | validation: 4.422585583128428]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.0851040691244975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0851040691244975 | validation: 4.363128796462756]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.041330030335429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.041330030335429 | validation: 4.348515220249786]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.025034168960044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.025034168960044 | validation: 4.325838423476341]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.010203998982617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.010203998982617 | validation: 4.335966459690067]
	TIME [epoch: 3.78 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.017247321659994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.017247321659994 | validation: 4.302488622327547]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9809095682580127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9809095682580127 | validation: 4.265834087832435]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.964799477400302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.964799477400302 | validation: 4.252763612513905]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.932155695987556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.932155695987556 | validation: 4.1854590848876905]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9032488793093836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9032488793093836 | validation: 4.254781478203017]
	TIME [epoch: 3.79 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9239690843936614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9239690843936614 | validation: 4.158604812850629]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.913218952178539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.913218952178539 | validation: 4.247389021227273]
	TIME [epoch: 3.77 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.929623485265225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.929623485265225 | validation: 4.144268783141193]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8559933470681402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8559933470681402 | validation: 4.133107678111665]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8417000130423937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8417000130423937 | validation: 4.090217678089596]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7932810278521614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7932810278521614 | validation: 4.049186949726068]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7576106631901305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7576106631901305 | validation: 4.011837563924051]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7416636061791166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7416636061791166 | validation: 4.031373374201964]
	TIME [epoch: 3.79 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7371908130911407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7371908130911407 | validation: 4.003497558030787]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7357503377382666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7357503377382666 | validation: 4.052734576449013]
	TIME [epoch: 3.78 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7708969387413447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7708969387413447 | validation: 4.000380366775795]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.721263226489038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.721263226489038 | validation: 3.991378141002794]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7206032058827567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7206032058827567 | validation: 3.953196441158673]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6651991807800357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6651991807800357 | validation: 3.9112941097141007]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6444616219686203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6444616219686203 | validation: 3.900431347514794]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.618018532874712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.618018532874712 | validation: 3.8502476327001207]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.592332185757828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.592332185757828 | validation: 3.838503555891968]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.577331188047448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.577331188047448 | validation: 3.81460152723794]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.560545761173405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.560545761173405 | validation: 3.812784122377078]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.558308992225833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.558308992225833 | validation: 3.8655524794888736]
	TIME [epoch: 3.79 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.592861410333133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.592861410333133 | validation: 3.8265803634131714]
	TIME [epoch: 3.78 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5945156735944592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5945156735944592 | validation: 3.8751107801182196]
	TIME [epoch: 3.79 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6051614857613363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6051614857613363 | validation: 3.718373138115739]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.473825015149364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.473825015149364 | validation: 3.694203144836489]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4595373369072515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4595373369072515 | validation: 3.714248881831583]
	TIME [epoch: 3.77 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4602975557856537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4602975557856537 | validation: 3.668130447715487]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.43917247041342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.43917247041342 | validation: 3.6932909705654198]
	TIME [epoch: 3.78 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.445501427906983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.445501427906983 | validation: 3.7379284053489856]
	TIME [epoch: 3.78 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.479299540544046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.479299540544046 | validation: 3.711315244107759]
	TIME [epoch: 3.78 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4663014528283282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4663014528283282 | validation: 3.7362028199036375]
	TIME [epoch: 3.78 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.46843669664451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.46843669664451 | validation: 3.6086810644325826]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3698808115756993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3698808115756993 | validation: 3.578681375423446]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3565923980588095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3565923980588095 | validation: 3.60226132622513]
	TIME [epoch: 3.77 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3557601718602212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3557601718602212 | validation: 3.572794285513745]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3512674454876867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3512674454876867 | validation: 3.6240229396090538]
	TIME [epoch: 3.78 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3628251766777444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3628251766777444 | validation: 3.5762932792294864]
	TIME [epoch: 3.77 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3428606571456805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3428606571456805 | validation: 3.5821977191852072]
	TIME [epoch: 3.77 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.336161705588541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.336161705588541 | validation: 3.5172244583989767]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2963003371856407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2963003371856407 | validation: 3.510288087116507]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2747359522720276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2747359522720276 | validation: 3.497358567160944]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.264611519506584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.264611519506584 | validation: 3.4964385512978624]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2596987862168714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2596987862168714 | validation: 3.478464156404514]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2603365956716073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2603365956716073 | validation: 3.5843870413348555]
	TIME [epoch: 3.78 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.328264656794555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.328264656794555 | validation: 3.575194746189125]
	TIME [epoch: 3.78 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3479214986145873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3479214986145873 | validation: 3.4949606586500965]
	TIME [epoch: 3.78 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.247862899494835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.247862899494835 | validation: 3.434147654015888]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2116226632314517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2116226632314517 | validation: 3.421466652914751]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2049887933624492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2049887933624492 | validation: 3.427356427401957]
	TIME [epoch: 3.78 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1985645385628705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1985645385628705 | validation: 3.4023060593192307]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1777329379416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1777329379416 | validation: 3.3980990693207973]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.176455285352637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.176455285352637 | validation: 3.3933146398768588]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1813940586587526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1813940586587526 | validation: 3.4462194120908833]
	TIME [epoch: 3.77 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2131818248888977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2131818248888977 | validation: 3.425633925230703]
	TIME [epoch: 3.77 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2117407514815572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2117407514815572 | validation: 3.4039062832173985]
	TIME [epoch: 3.77 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1760297778924556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1760297778924556 | validation: 3.3327343718320357]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.127031221584358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.127031221584358 | validation: 3.3233371132296257]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.112708531073719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.112708531073719 | validation: 3.3164394962489596]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1077807829811843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1077807829811843 | validation: 3.3156034018468965]
	TIME [epoch: 3.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1047706749018347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1047706749018347 | validation: 3.3849365605529464]
	TIME [epoch: 3.79 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.152870301708999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.152870301708999 | validation: 3.400673619952878]
	TIME [epoch: 3.78 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.194252725356382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.194252725356382 | validation: 3.3478259837889013]
	TIME [epoch: 3.78 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1236703504246788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1236703504246788 | validation: 3.2774477952246515]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0704108210599803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0704108210599803 | validation: 3.2889547499725147]
	TIME [epoch: 3.78 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.079838381414611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.079838381414611 | validation: 3.259576098092906]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.059493734993939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.059493734993939 | validation: 3.1740602387136376]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9973711711993656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9973711711993656 | validation: 3.0901227910620883]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.932068379374614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.932068379374614 | validation: 2.897475009404947]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.750275759691391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.750275759691391 | validation: 2.2901941152208307]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.167498534804193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.167498534804193 | validation: 2.168780575605963]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.4283790294087217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4283790294087217 | validation: 3.04860985419354]
	TIME [epoch: 3.79 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2640924958781365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2640924958781365 | validation: 1.2309232269613912]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2630499863731346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2630499863731346 | validation: 1.325911071110059]
	TIME [epoch: 3.78 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.450006917175831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.450006917175831 | validation: 1.1745737625186496]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.182679834074007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.182679834074007 | validation: 1.0362114585724926]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0399944418620388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0399944418620388 | validation: 0.9370547850469916]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9366656614672393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9366656614672393 | validation: 0.9474907386612877]
	TIME [epoch: 3.78 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9437207507845236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9437207507845236 | validation: 0.9537905368052748]
	TIME [epoch: 3.77 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9713155136969445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9713155136969445 | validation: 0.9042576369940559]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9047323337316167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9047323337316167 | validation: 0.8659978217272356]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8552959104661886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8552959104661886 | validation: 0.8446561040013647]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8418073428307971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8418073428307971 | validation: 0.8382264564314229]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8390330969751778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8390330969751778 | validation: 0.8259394492080813]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8172922716743583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8172922716743583 | validation: 0.8197041387410068]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8020706356750523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8020706356750523 | validation: 0.8148093778473945]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8095701807082442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8095701807082442 | validation: 0.9295547200904708]
	TIME [epoch: 3.78 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9790119133514787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9790119133514787 | validation: 0.9824479768255685]
	TIME [epoch: 3.78 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9964303800802803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9964303800802803 | validation: 0.819153942033141]
	TIME [epoch: 3.78 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8007734447133186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8007734447133186 | validation: 0.8712523112238039]
	TIME [epoch: 3.78 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8914516055140014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8914516055140014 | validation: 0.8435752585051397]
	TIME [epoch: 3.78 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.846627110817691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.846627110817691 | validation: 0.7731595440046234]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.773639647729251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.773639647729251 | validation: 0.8070141293272481]
	TIME [epoch: 3.78 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7864317928758249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7864317928758249 | validation: 0.7878728522942411]
	TIME [epoch: 3.78 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7732947570132916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7732947570132916 | validation: 0.7612707970060945]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7550971287086543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7550971287086543 | validation: 0.7976943634457738]
	TIME [epoch: 3.78 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7482792896251819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7482792896251819 | validation: 0.7714414970144271]
	TIME [epoch: 3.79 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7591578352510806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7591578352510806 | validation: 0.7266568307235602]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.724863440060349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.724863440060349 | validation: 0.7556462812411711]
	TIME [epoch: 3.79 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7229074327495971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7229074327495971 | validation: 0.7702477827251987]
	TIME [epoch: 3.78 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.735452778274273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.735452778274273 | validation: 0.7530489467191379]
	TIME [epoch: 3.79 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7349946869459915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7349946869459915 | validation: 0.7294712169706001]
	TIME [epoch: 3.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.695134953235246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.695134953235246 | validation: 0.7284105804470093]
	TIME [epoch: 3.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6905875113939092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6905875113939092 | validation: 0.7258376464472609]
	TIME [epoch: 3.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.689167738353228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.689167738353228 | validation: 0.7285606563209321]
	TIME [epoch: 3.79 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6874773606871114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6874773606871114 | validation: 0.7115313523252521]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6929446940038763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6929446940038763 | validation: 0.7301556649158789]
	TIME [epoch: 3.81 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6873346412314618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6873346412314618 | validation: 0.7357083233168563]
	TIME [epoch: 3.82 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.691329904430061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.691329904430061 | validation: 0.8290877592447821]
	TIME [epoch: 3.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7965544798044245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7965544798044245 | validation: 1.0815604584757545]
	TIME [epoch: 3.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.121215386472808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.121215386472808 | validation: 0.803848691582248]
	TIME [epoch: 3.81 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8274690761840003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8274690761840003 | validation: 0.9618247472731837]
	TIME [epoch: 3.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9287641207746922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9287641207746922 | validation: 0.7555114163867327]
	TIME [epoch: 3.79 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7331057309588528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7331057309588528 | validation: 0.7661766850009766]
	TIME [epoch: 3.79 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7920142764601869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7920142764601869 | validation: 0.7073643441931328]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6780982516848526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6780982516848526 | validation: 0.7663661897766704]
	TIME [epoch: 3.79 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7415351441233117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7415351441233117 | validation: 0.8228766561721002]
	TIME [epoch: 3.79 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8170526511366022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8170526511366022 | validation: 0.6960894954727599]
	TIME [epoch: 3.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7080795102292704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7080795102292704 | validation: 0.7710548111629966]
	TIME [epoch: 3.79 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7310550778122817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7310550778122817 | validation: 0.7017583047305705]
	TIME [epoch: 3.79 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6812586108591614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6812586108591614 | validation: 0.6851368628763324]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.666531627505064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.666531627505064 | validation: 0.7358078513623427]
	TIME [epoch: 3.78 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6678496918616834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6678496918616834 | validation: 0.6878369603753095]
	TIME [epoch: 3.79 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6607302951616171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6607302951616171 | validation: 0.6996092890227942]
	TIME [epoch: 3.79 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6557398653610276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6557398653610276 | validation: 0.7276088998499577]
	TIME [epoch: 3.78 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6962185062936099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6962185062936099 | validation: 0.8945366655167263]
	TIME [epoch: 3.79 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9141080158125959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9141080158125959 | validation: 0.6785735786875716]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7009707102609976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7009707102609976 | validation: 0.8272080215595052]
	TIME [epoch: 3.78 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8229618846883952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8229618846883952 | validation: 0.8529930636809034]
	TIME [epoch: 3.78 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8679579479798949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8679579479798949 | validation: 0.7486665365374494]
	TIME [epoch: 3.77 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7565810920654447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7565810920654447 | validation: 0.7477720362570306]
	TIME [epoch: 3.79 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.708908082603505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.708908082603505 | validation: 0.68909393472516]
	TIME [epoch: 3.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6612169615618705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6612169615618705 | validation: 0.7056229968385761]
	TIME [epoch: 3.78 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6582157885002934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6582157885002934 | validation: 0.7006602939314563]
	TIME [epoch: 3.79 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6581194574486214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6581194574486214 | validation: 0.7078358957285894]
	TIME [epoch: 3.78 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6937610669153382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6937610669153382 | validation: 0.708008415275581]
	TIME [epoch: 3.78 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6644848333076968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6644848333076968 | validation: 0.6630551947786363]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6529538858068921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6529538858068921 | validation: 0.703647461416348]
	TIME [epoch: 3.78 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6514854933996429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6514854933996429 | validation: 0.6802827878394365]
	TIME [epoch: 3.79 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6603386062419645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6603386062419645 | validation: 0.7066753783841498]
	TIME [epoch: 3.79 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6781738789400019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6781738789400019 | validation: 0.6940412458447681]
	TIME [epoch: 3.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7202287409035413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7202287409035413 | validation: 0.6826633505296302]
	TIME [epoch: 3.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6476698372701176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6476698372701176 | validation: 0.6993148129899022]
	TIME [epoch: 3.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.674958319293946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.674958319293946 | validation: 0.6868923201718121]
	TIME [epoch: 3.79 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7184710933251909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7184710933251909 | validation: 0.8654485237247166]
	TIME [epoch: 3.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8701705145944405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8701705145944405 | validation: 0.679173789536768]
	TIME [epoch: 3.78 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6520284276650969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6520284276650969 | validation: 0.7256278473614102]
	TIME [epoch: 3.79 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7075378698963176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7075378698963176 | validation: 0.7414614385639926]
	TIME [epoch: 3.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7224469480645404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7224469480645404 | validation: 0.7363952702246691]
	TIME [epoch: 3.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.694257238196339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.694257238196339 | validation: 0.7296278696190686]
	TIME [epoch: 3.78 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7507908828693787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7507908828693787 | validation: 0.6681566198587482]
	TIME [epoch: 3.78 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6650328988264189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6650328988264189 | validation: 0.7667046827076052]
	TIME [epoch: 3.79 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7230270418083572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7230270418083572 | validation: 0.7001269271265178]
	TIME [epoch: 3.79 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7094265674555291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7094265674555291 | validation: 0.6759292647320281]
	TIME [epoch: 3.78 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6560207177730201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6560207177730201 | validation: 0.7314340607337595]
	TIME [epoch: 3.78 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.718451007673751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.718451007673751 | validation: 0.6714824641079984]
	TIME [epoch: 3.78 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6595819428416628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6595819428416628 | validation: 0.6865953094469561]
	TIME [epoch: 3.79 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6721298338017959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6721298338017959 | validation: 0.7488633160584021]
	TIME [epoch: 3.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7318421557474949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7318421557474949 | validation: 0.6796473499601602]
	TIME [epoch: 3.79 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6285566319026745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6285566319026745 | validation: 0.6951354732356534]
	TIME [epoch: 3.79 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7410139121745332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7410139121745332 | validation: 0.7564468038114053]
	TIME [epoch: 3.78 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7299725164070741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7299725164070741 | validation: 0.7398268145524547]
	TIME [epoch: 3.78 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7282277134615737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7282277134615737 | validation: 0.6774115861785703]
	TIME [epoch: 3.78 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6792167606510426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6792167606510426 | validation: 0.6786672378900682]
	TIME [epoch: 3.79 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6504084073048373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6504084073048373 | validation: 0.7145175485597446]
	TIME [epoch: 3.79 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7127158146913252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7127158146913252 | validation: 0.666815197898844]
	TIME [epoch: 3.79 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6499481919923167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6499481919923167 | validation: 0.6998066517175922]
	TIME [epoch: 3.79 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6686022783957273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6686022783957273 | validation: 0.7477673003066845]
	TIME [epoch: 3.79 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7382861883046676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7382861883046676 | validation: 0.6872525343176212]
	TIME [epoch: 3.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6250396393918486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6250396393918486 | validation: 0.6947015649376018]
	TIME [epoch: 3.79 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6749534131442756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6749534131442756 | validation: 0.7043816067681254]
	TIME [epoch: 3.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6714170622799628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6714170622799628 | validation: 0.6919427657384398]
	TIME [epoch: 3.78 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6291244358618697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6291244358618697 | validation: 0.6622825719426901]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6820161613346253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6820161613346253 | validation: 0.6752346233771546]
	TIME [epoch: 31 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6139551447927826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6139551447927826 | validation: 0.6724996949087139]
	TIME [epoch: 8.27 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6243163856858894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6243163856858894 | validation: 0.680016895993722]
	TIME [epoch: 8.28 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7040932874973612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7040932874973612 | validation: 0.7780912546711902]
	TIME [epoch: 8.24 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7168467068645242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7168467068645242 | validation: 0.7944411114076582]
	TIME [epoch: 8.23 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7745887623179882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7745887623179882 | validation: 0.6610095964392313]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6088829671530415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6088829671530415 | validation: 0.684802072579117]
	TIME [epoch: 8.21 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6259668940961772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6259668940961772 | validation: 0.6962598424415463]
	TIME [epoch: 8.21 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6716695926506502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6716695926506502 | validation: 0.69801867665292]
	TIME [epoch: 8.24 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6449750396677416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6449750396677416 | validation: 0.6541044986347364]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7184608617337702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7184608617337702 | validation: 0.6724290197589105]
	TIME [epoch: 8.22 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6213887135377151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6213887135377151 | validation: 0.7219452214218567]
	TIME [epoch: 8.22 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6759404600478118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6759404600478118 | validation: 0.6631853479529464]
	TIME [epoch: 8.21 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6995195229057208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6995195229057208 | validation: 0.6761943613430802]
	TIME [epoch: 8.23 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6024550430344421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6024550430344421 | validation: 0.6919121603539495]
	TIME [epoch: 8.22 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6618769913832631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6618769913832631 | validation: 0.6374655274346929]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6619166043631859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6619166043631859 | validation: 0.6412476651993025]
	TIME [epoch: 8.21 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.610422279188751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.610422279188751 | validation: 0.7834939192401728]
	TIME [epoch: 8.22 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7840669230384935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7840669230384935 | validation: 0.6542498782586498]
	TIME [epoch: 8.22 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6395063372734086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6395063372734086 | validation: 0.6135806198425255]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.610212750337953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.610212750337953 | validation: 0.659562037448643]
	TIME [epoch: 8.21 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5937218492851487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5937218492851487 | validation: 0.6451717486737336]
	TIME [epoch: 8.21 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5806497427369837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5806497427369837 | validation: 0.7080570450934262]
	TIME [epoch: 8.22 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6061843250180464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6061843250180464 | validation: 0.793297105557653]
	TIME [epoch: 8.22 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.845292389699724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.845292389699724 | validation: 0.9501657773227908]
	TIME [epoch: 8.22 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.002208344959136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.002208344959136 | validation: 0.6032707863783205]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6321294342717362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6321294342717362 | validation: 0.6336442822022446]
	TIME [epoch: 8.23 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6431870582916391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6431870582916391 | validation: 0.6563169365468928]
	TIME [epoch: 8.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6074500768174893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6074500768174893 | validation: 0.6308431566490258]
	TIME [epoch: 8.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5846169054610592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5846169054610592 | validation: 0.6262413450104807]
	TIME [epoch: 8.22 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5785141273697851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5785141273697851 | validation: 0.6311469690383797]
	TIME [epoch: 8.22 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5709279126108594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5709279126108594 | validation: 0.6258106472201934]
	TIME [epoch: 8.23 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5607379333321455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5607379333321455 | validation: 0.6191743811693258]
	TIME [epoch: 8.21 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5592252173401283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5592252173401283 | validation: 0.6175981152000983]
	TIME [epoch: 8.22 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5573468527944724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5573468527944724 | validation: 0.6093159251294009]
	TIME [epoch: 8.22 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5432217657987439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5432217657987439 | validation: 0.562751430523323]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5343953022840446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5343953022840446 | validation: 0.7487867584722601]
	TIME [epoch: 8.23 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7071764032259538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7071764032259538 | validation: 0.7508406748526776]
	TIME [epoch: 8.23 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8582419273513946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8582419273513946 | validation: 0.6163194079570428]
	TIME [epoch: 8.23 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7532733031505597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7532733031505597 | validation: 0.7939905030425183]
	TIME [epoch: 8.23 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7922046289637865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7922046289637865 | validation: 0.6218110626747572]
	TIME [epoch: 8.23 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.603309810919393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.603309810919393 | validation: 0.651572103485861]
	TIME [epoch: 8.24 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6678413715930921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6678413715930921 | validation: 0.595485418611319]
	TIME [epoch: 8.23 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5632053234713091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5632053234713091 | validation: 0.6242482078089178]
	TIME [epoch: 8.24 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5618997537912721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5618997537912721 | validation: 0.6126948071941181]
	TIME [epoch: 8.24 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5305729405572351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5305729405572351 | validation: 0.5805439682175549]
	TIME [epoch: 8.24 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.518472014518649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.518472014518649 | validation: 0.6060229489540797]
	TIME [epoch: 8.25 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.509299234093411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.509299234093411 | validation: 0.5413925525538191]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5354892912071827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5354892912071827 | validation: 0.7167179172401892]
	TIME [epoch: 8.19 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6608544899419772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6608544899419772 | validation: 0.6125911373445481]
	TIME [epoch: 8.21 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6548228196727999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6548228196727999 | validation: 0.5967870858683215]
	TIME [epoch: 8.21 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5823015944884322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5823015944884322 | validation: 0.6168851804838589]
	TIME [epoch: 8.22 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5759274684104225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5759274684104225 | validation: 0.5550930799865944]
	TIME [epoch: 8.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5060885840588057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5060885840588057 | validation: 0.5833522897891981]
	TIME [epoch: 8.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4819986632534058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4819986632534058 | validation: 0.5461766883050836]
	TIME [epoch: 8.18 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.517925808195859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.517925808195859 | validation: 0.6431602320823112]
	TIME [epoch: 8.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6404939905560819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6404939905560819 | validation: 0.6354746142030585]
	TIME [epoch: 8.19 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.599631673247035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.599631673247035 | validation: 0.5665206514704414]
	TIME [epoch: 8.22 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4928701113081544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4928701113081544 | validation: 0.5919084373587264]
	TIME [epoch: 8.22 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4885500663929057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4885500663929057 | validation: 0.5244520716948927]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5037704898915082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5037704898915082 | validation: 0.7374260689238594]
	TIME [epoch: 8.19 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7143006314779003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7143006314779003 | validation: 0.721271904676764]
	TIME [epoch: 8.22 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7974968197250192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7974968197250192 | validation: 0.5970544010583309]
	TIME [epoch: 8.24 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5375055104984516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5375055104984516 | validation: 0.63727970915752]
	TIME [epoch: 8.24 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5722870192246733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5722870192246733 | validation: 0.5180589624187538]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5030445649376096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5030445649376096 | validation: 0.5231137841970277]
	TIME [epoch: 8.23 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49478716611190643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49478716611190643 | validation: 0.5019400343559326]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4417063394640863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4417063394640863 | validation: 0.5239869210132503]
	TIME [epoch: 8.23 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4472765151300577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4472765151300577 | validation: 0.5402732593157954]
	TIME [epoch: 8.26 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4539013204241318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4539013204241318 | validation: 0.5256788720405332]
	TIME [epoch: 8.25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5394337273712674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5394337273712674 | validation: 0.7018635166266574]
	TIME [epoch: 8.23 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6607626208865085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6607626208865085 | validation: 0.4859914607501873]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47126200639765814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47126200639765814 | validation: 0.48084944480598146]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43494976601047486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43494976601047486 | validation: 0.5359024454067959]
	TIME [epoch: 8.22 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4453680165369855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4453680165369855 | validation: 0.5888951863461166]
	TIME [epoch: 8.23 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6112702666094103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6112702666094103 | validation: 0.5813042014908726]
	TIME [epoch: 8.21 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7047301902860913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7047301902860913 | validation: 0.4740540647248816]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6660995880309984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6660995880309984 | validation: 0.5469488467165381]
	TIME [epoch: 8.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5686052231834005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5686052231834005 | validation: 0.5470867221539782]
	TIME [epoch: 8.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.543192167619036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.543192167619036 | validation: 0.5317000637187779]
	TIME [epoch: 8.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.504699297389691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.504699297389691 | validation: 0.5142630571927004]
	TIME [epoch: 8.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4368901118761239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4368901118761239 | validation: 0.48913666986460796]
	TIME [epoch: 8.21 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4283924408412243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4283924408412243 | validation: 0.4494735989055853]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4259536795952113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4259536795952113 | validation: 0.5074471088438757]
	TIME [epoch: 8.19 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4312057563407751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4312057563407751 | validation: 0.46046118420409565]
	TIME [epoch: 8.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47762951439065915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47762951439065915 | validation: 0.6270058796580718]
	TIME [epoch: 8.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5564489612749652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5564489612749652 | validation: 0.6351199058325991]
	TIME [epoch: 8.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7057965378369461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7057965378369461 | validation: 0.47727478439974846]
	TIME [epoch: 8.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.438248385808097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.438248385808097 | validation: 0.4919030431873651]
	TIME [epoch: 8.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4181731084132801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4181731084132801 | validation: 0.4298284119297252]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3977505984171984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3977505984171984 | validation: 0.4566135262354248]
	TIME [epoch: 8.22 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37903964484031494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37903964484031494 | validation: 0.4203348899181137]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39458271649863763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39458271649863763 | validation: 0.49650443715717857]
	TIME [epoch: 8.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4617280187561065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4617280187561065 | validation: 0.4451766020688904]
	TIME [epoch: 8.19 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48824079782955104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48824079782955104 | validation: 0.4690452934056487]
	TIME [epoch: 8.21 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3816726544565133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3816726544565133 | validation: 0.3804492178983761]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.370968033576613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.370968033576613 | validation: 0.36823531266197285]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34933537832738487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34933537832738487 | validation: 0.37644611103480125]
	TIME [epoch: 8.21 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3527192299029006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3527192299029006 | validation: 0.41573853472704236]
	TIME [epoch: 8.23 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38047516710653184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38047516710653184 | validation: 0.43639818219757665]
	TIME [epoch: 8.21 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4435265652769404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4435265652769404 | validation: 0.5175854686514598]
	TIME [epoch: 8.23 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5119310631668946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5119310631668946 | validation: 0.4894349019792711]
	TIME [epoch: 8.21 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4367034574675748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4367034574675748 | validation: 0.46687972847867826]
	TIME [epoch: 8.22 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4505761631838337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4505761631838337 | validation: 0.431040096999514]
	TIME [epoch: 8.21 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37282665761717565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37282665761717565 | validation: 0.3700318749961334]
	TIME [epoch: 8.21 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34530601883238293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34530601883238293 | validation: 0.3501473270167346]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33380348945888844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33380348945888844 | validation: 0.3079036830254297]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34077639718868624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34077639718868624 | validation: 0.3494603325923974]
	TIME [epoch: 8.22 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3115749610812383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3115749610812383 | validation: 0.35027705141596654]
	TIME [epoch: 8.23 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3255363738911049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3255363738911049 | validation: 0.424651119603811]
	TIME [epoch: 8.22 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.366201545453997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.366201545453997 | validation: 0.3588576842463678]
	TIME [epoch: 8.22 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4008887560361859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4008887560361859 | validation: 0.39589343677123057]
	TIME [epoch: 8.22 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33482244611995216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33482244611995216 | validation: 0.3127796216833764]
	TIME [epoch: 8.25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30754263209122235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30754263209122235 | validation: 0.35426505359125576]
	TIME [epoch: 8.22 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3142981036510928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3142981036510928 | validation: 0.3499796185362633]
	TIME [epoch: 8.23 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3048615472480903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3048615472480903 | validation: 0.3020146571731493]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.300379424606199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.300379424606199 | validation: 0.2966069664982075]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.273997737387947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.273997737387947 | validation: 0.33300773921912]
	TIME [epoch: 8.21 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3016976602464282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3016976602464282 | validation: 0.29274643905408865]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32134338615102437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32134338615102437 | validation: 0.4290777591053139]
	TIME [epoch: 8.23 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36958311086487766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36958311086487766 | validation: 0.3087701245773159]
	TIME [epoch: 8.22 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.324558653790466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.324558653790466 | validation: 0.353648712848093]
	TIME [epoch: 8.21 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3212649513833192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3212649513833192 | validation: 0.3938124423748166]
	TIME [epoch: 8.24 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32211449332394054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32211449332394054 | validation: 0.2552040249787841]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2796523696864775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2796523696864775 | validation: 0.31387259149721974]
	TIME [epoch: 8.22 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3057537830470915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3057537830470915 | validation: 0.2866167009043494]
	TIME [epoch: 8.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.283917283627371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.283917283627371 | validation: 0.2659319980207619]
	TIME [epoch: 8.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26735729086348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26735729086348 | validation: 0.2731042450364957]
	TIME [epoch: 8.23 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22867259738243628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22867259738243628 | validation: 0.2701372349076411]
	TIME [epoch: 8.22 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24423992222993426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24423992222993426 | validation: 0.296278445418483]
	TIME [epoch: 8.22 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27342638474950476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27342638474950476 | validation: 0.24002138618002397]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2775754455923195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2775754455923195 | validation: 0.29521941816364317]
	TIME [epoch: 8.21 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23857911830125936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23857911830125936 | validation: 0.23244110012251587]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.206120173626149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.206120173626149 | validation: 0.24032777769290392]
	TIME [epoch: 8.23 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2199385434066915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2199385434066915 | validation: 0.22804098568438108]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1985973485965073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1985973485965073 | validation: 0.2820463113290709]
	TIME [epoch: 8.21 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26691371572093264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26691371572093264 | validation: 0.38938252527442274]
	TIME [epoch: 8.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3817759979485878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3817759979485878 | validation: 0.37429119719165377]
	TIME [epoch: 8.21 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3671394530790769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3671394530790769 | validation: 0.3971160944185989]
	TIME [epoch: 8.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3175768469210819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3175768469210819 | validation: 0.2423462951896684]
	TIME [epoch: 8.23 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24040819652958628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24040819652958628 | validation: 0.2601792135464283]
	TIME [epoch: 8.22 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26997528420200984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26997528420200984 | validation: 0.2300965652341443]
	TIME [epoch: 8.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22114390208354578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22114390208354578 | validation: 0.2380145186702241]
	TIME [epoch: 8.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20641498661659577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20641498661659577 | validation: 0.22952550109131106]
	TIME [epoch: 8.21 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1916999212113053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1916999212113053 | validation: 0.21112755165908698]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.178318698708534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.178318698708534 | validation: 0.19109738638718174]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.174946823649313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.174946823649313 | validation: 0.20235857187534273]
	TIME [epoch: 8.19 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17072704280028617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17072704280028617 | validation: 0.1873109583675172]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17424094670538154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17424094670538154 | validation: 0.2156379028083948]
	TIME [epoch: 8.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17832182210026445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17832182210026445 | validation: 0.19182323757655115]
	TIME [epoch: 8.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2188114432625784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2188114432625784 | validation: 0.21884745596302949]
	TIME [epoch: 8.22 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17061332932533546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17061332932533546 | validation: 0.20015341703409742]
	TIME [epoch: 8.19 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1727313108210385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1727313108210385 | validation: 0.2268020912386267]
	TIME [epoch: 8.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21717986149815677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21717986149815677 | validation: 0.3928175575766318]
	TIME [epoch: 8.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3689358821069358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3689358821069358 | validation: 0.41674536638662574]
	TIME [epoch: 8.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3649872075248196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3649872075248196 | validation: 0.27969181053394565]
	TIME [epoch: 8.19 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20277453069459073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20277453069459073 | validation: 0.2045324173121107]
	TIME [epoch: 8.23 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2513344807350279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2513344807350279 | validation: 0.4452968154644967]
	TIME [epoch: 8.19 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5145662085030234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5145662085030234 | validation: 0.318061918564828]
	TIME [epoch: 8.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23526599014470143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23526599014470143 | validation: 0.3549137715302229]
	TIME [epoch: 8.19 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2742917859525818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2742917859525818 | validation: 0.21583085441365288]
	TIME [epoch: 8.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17915863600596382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17915863600596382 | validation: 0.17497201994905273]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19931782141816434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19931782141816434 | validation: 0.2238763693331471]
	TIME [epoch: 8.23 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21082852339870137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21082852339870137 | validation: 0.19227869618873927]
	TIME [epoch: 8.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17666182271815895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17666182271815895 | validation: 0.2058159257128938]
	TIME [epoch: 8.21 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16654860073604236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16654860073604236 | validation: 0.18814429852188314]
	TIME [epoch: 8.21 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15959827808563765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15959827808563765 | validation: 0.17381963248644383]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1634222848418377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1634222848418377 | validation: 0.1789284940247553]
	TIME [epoch: 8.21 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15693131798162135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15693131798162135 | validation: 0.18094180700332507]
	TIME [epoch: 8.22 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15029748066907567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15029748066907567 | validation: 0.1769599214936217]
	TIME [epoch: 8.21 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14452915452094622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14452915452094622 | validation: 0.1682665760054579]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14279598096212026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14279598096212026 | validation: 0.1717113956368432]
	TIME [epoch: 8.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14742095011107523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14742095011107523 | validation: 0.17804436942416552]
	TIME [epoch: 8.21 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17334766716487046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17334766716487046 | validation: 0.20761949702483173]
	TIME [epoch: 8.22 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1735583422233468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1735583422233468 | validation: 0.3252359020170014]
	TIME [epoch: 8.22 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.273789300421423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.273789300421423 | validation: 0.34694572597158]
	TIME [epoch: 8.21 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26208953020254766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26208953020254766 | validation: 0.17503096706360688]
	TIME [epoch: 8.21 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15415050102111796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15415050102111796 | validation: 0.1633928164671109]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1773600656162634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1773600656162634 | validation: 0.14416863315921521]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1477958900992752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1477958900992752 | validation: 0.1952378532148001]
	TIME [epoch: 8.23 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1721657168791393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1721657168791393 | validation: 0.19569955968295266]
	TIME [epoch: 8.24 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2595647409160379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2595647409160379 | validation: 0.18948432589592007]
	TIME [epoch: 8.21 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21836136450046567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21836136450046567 | validation: 0.2267811124875154]
	TIME [epoch: 8.22 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22115850127143144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22115850127143144 | validation: 0.3668468387698748]
	TIME [epoch: 8.22 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30111000136047716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30111000136047716 | validation: 0.32740153461160393]
	TIME [epoch: 8.21 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26411829856136054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26411829856136054 | validation: 0.22621026645868866]
	TIME [epoch: 8.25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19398182942623823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19398182942623823 | validation: 0.1762662875205066]
	TIME [epoch: 8.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21006731862818523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21006731862818523 | validation: 0.22522895002553878]
	TIME [epoch: 8.22 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25639874448053995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25639874448053995 | validation: 0.19137866541822737]
	TIME [epoch: 8.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22090197092809122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22090197092809122 | validation: 0.1572485372423381]
	TIME [epoch: 8.22 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14632102059351998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14632102059351998 | validation: 0.20698207005444733]
	TIME [epoch: 8.22 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20050022779769816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20050022779769816 | validation: 0.1797740133599024]
	TIME [epoch: 8.24 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20740676698149618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20740676698149618 | validation: 0.13882503983870062]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20700730016991814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20700730016991814 | validation: 0.16382588333080034]
	TIME [epoch: 8.22 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15225062260795957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15225062260795957 | validation: 0.21704770356720735]
	TIME [epoch: 8.22 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15896259645541835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15896259645541835 | validation: 0.14444294750624562]
	TIME [epoch: 8.23 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1412468390744726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1412468390744726 | validation: 0.15653425256473452]
	TIME [epoch: 8.24 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14305776910719745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14305776910719745 | validation: 0.2053165887883447]
	TIME [epoch: 8.23 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14076056170210208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14076056170210208 | validation: 0.1580149956544196]
	TIME [epoch: 8.22 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15535185742253826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15535185742253826 | validation: 0.2534963088978244]
	TIME [epoch: 8.22 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17167599165003858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17167599165003858 | validation: 0.15895616931648823]
	TIME [epoch: 8.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16515188508701187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16515188508701187 | validation: 0.13622621220462156]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16291935017845635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16291935017845635 | validation: 0.20475422611730354]
	TIME [epoch: 8.22 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1440692326352101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1440692326352101 | validation: 0.17976237193682193]
	TIME [epoch: 8.23 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1360944637183098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1360944637183098 | validation: 0.15689535980786543]
	TIME [epoch: 8.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16409082215924412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16409082215924412 | validation: 0.323315219808728]
	TIME [epoch: 8.23 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23903278186897678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23903278186897678 | validation: 0.17218548858219324]
	TIME [epoch: 8.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14146891113186494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14146891113186494 | validation: 0.20668013880921365]
	TIME [epoch: 8.21 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20426073371596792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20426073371596792 | validation: 0.20033094518354383]
	TIME [epoch: 8.21 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22844373816320726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22844373816320726 | validation: 0.1979660640621159]
	TIME [epoch: 8.21 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1820077251979763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1820077251979763 | validation: 0.14412732922305374]
	TIME [epoch: 8.19 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1361741695019467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1361741695019467 | validation: 0.1773465172754201]
	TIME [epoch: 8.21 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14783107201615037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14783107201615037 | validation: 0.16052801891801238]
	TIME [epoch: 8.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16240323516305977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16240323516305977 | validation: 0.13512382297496855]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13359401141733204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13359401141733204 | validation: 0.23759976683420156]
	TIME [epoch: 8.21 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19468552775823045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19468552775823045 | validation: 0.2631849409971634]
	TIME [epoch: 8.21 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23680814777076414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23680814777076414 | validation: 0.26304594026943035]
	TIME [epoch: 8.21 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2381563742023443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2381563742023443 | validation: 0.16940892673729657]
	TIME [epoch: 8.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16006480470358475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16006480470358475 | validation: 0.17850084859828594]
	TIME [epoch: 8.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2081409439120219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2081409439120219 | validation: 0.18447016892177182]
	TIME [epoch: 8.21 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16279097079438798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16279097079438798 | validation: 0.25516998771322386]
	TIME [epoch: 8.21 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18652401279828965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18652401279828965 | validation: 0.11767383609541598]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1291102054269661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1291102054269661 | validation: 0.12007322377745387]
	TIME [epoch: 8.19 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11556975723722579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11556975723722579 | validation: 0.12405051045989533]
	TIME [epoch: 8.19 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12927755375496752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12927755375496752 | validation: 0.18528783479161623]
	TIME [epoch: 8.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13320056275553627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13320056275553627 | validation: 0.19260233924489645]
	TIME [epoch: 8.21 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1965145545371606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1965145545371606 | validation: 0.2616978712958661]
	TIME [epoch: 8.22 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19440326409513453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19440326409513453 | validation: 0.1994827493452628]
	TIME [epoch: 8.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15069900296375133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15069900296375133 | validation: 0.14747778796144528]
	TIME [epoch: 8.19 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13432831367679351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13432831367679351 | validation: 0.14024901234245912]
	TIME [epoch: 8.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14186555994693598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14186555994693598 | validation: 0.13387336921199033]
	TIME [epoch: 8.21 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10911169465693504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10911169465693504 | validation: 0.16013076142249277]
	TIME [epoch: 8.21 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12232723397588106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12232723397588106 | validation: 0.11169510329290695]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12376957176491563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12376957176491563 | validation: 0.2233906285718447]
	TIME [epoch: 8.19 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1413523628176324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1413523628176324 | validation: 0.12446090396549975]
	TIME [epoch: 8.19 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1356218430523021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1356218430523021 | validation: 0.22892663363525356]
	TIME [epoch: 8.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16177184477946113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16177184477946113 | validation: 0.15966147330171185]
	TIME [epoch: 8.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12854008410946152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12854008410946152 | validation: 0.18410065835253686]
	TIME [epoch: 8.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.176491677267367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.176491677267367 | validation: 0.24323497826165405]
	TIME [epoch: 8.19 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20854879769211487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20854879769211487 | validation: 0.16225846891761608]
	TIME [epoch: 8.21 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12954845637411036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12954845637411036 | validation: 0.12762499336340502]
	TIME [epoch: 8.19 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1111025447197268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1111025447197268 | validation: 0.15307308870037628]
	TIME [epoch: 8.21 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13158647591460215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13158647591460215 | validation: 0.10697572467262778]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09615422411749759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09615422411749759 | validation: 0.143215290245459]
	TIME [epoch: 8.19 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12163919036217104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12163919036217104 | validation: 0.21136048053458145]
	TIME [epoch: 8.19 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14056684131348982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14056684131348982 | validation: 0.2882639880639305]
	TIME [epoch: 8.19 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2347053659065562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2347053659065562 | validation: 0.27480745345616325]
	TIME [epoch: 8.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20658779096711016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20658779096711016 | validation: 0.14729761244333203]
	TIME [epoch: 8.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14413749547286864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14413749547286864 | validation: 0.14546961641861014]
	TIME [epoch: 8.22 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1399487533216852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1399487533216852 | validation: 0.184042520163464]
	TIME [epoch: 8.19 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1311645663697282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1311645663697282 | validation: 0.1440616718677524]
	TIME [epoch: 8.21 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11273431567339713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11273431567339713 | validation: 0.14129826527290076]
	TIME [epoch: 8.18 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11849847703728081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11849847703728081 | validation: 0.1388642294958519]
	TIME [epoch: 8.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13008407292685142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13008407292685142 | validation: 0.23344439602002542]
	TIME [epoch: 8.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14466145461880361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14466145461880361 | validation: 0.14811549869918572]
	TIME [epoch: 8.22 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11054145153837996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11054145153837996 | validation: 0.16224842769467307]
	TIME [epoch: 8.21 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13217691418064786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13217691418064786 | validation: 0.17855329236113635]
	TIME [epoch: 8.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1213977406490169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1213977406490169 | validation: 0.14470295498884164]
	TIME [epoch: 8.21 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11485981422536429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11485981422536429 | validation: 0.14927483927287663]
	TIME [epoch: 8.21 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1388619354726996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1388619354726996 | validation: 0.22586120823264133]
	TIME [epoch: 8.23 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16805464500256018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16805464500256018 | validation: 0.1347415708346502]
	TIME [epoch: 8.23 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1440951858148478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1440951858148478 | validation: 0.20927763685282633]
	TIME [epoch: 8.19 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18184338813034606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18184338813034606 | validation: 0.1969273630148437]
	TIME [epoch: 8.21 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15802651578551338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15802651578551338 | validation: 0.15462846819828094]
	TIME [epoch: 8.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19279260798055287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19279260798055287 | validation: 0.1403666797544824]
	TIME [epoch: 8.19 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10933292435141628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10933292435141628 | validation: 0.12305416860623215]
	TIME [epoch: 8.19 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10939084435449363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10939084435449363 | validation: 0.11522516145574198]
	TIME [epoch: 8.21 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10617090007643196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10617090007643196 | validation: 0.1035346709480523]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09958173477166714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09958173477166714 | validation: 0.20907414626705392]
	TIME [epoch: 8.22 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1342825205378199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1342825205378199 | validation: 0.12971997190171494]
	TIME [epoch: 8.22 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1334956930826659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1334956930826659 | validation: 0.20564964156067683]
	TIME [epoch: 8.25 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1417053266600819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1417053266600819 | validation: 0.15334074828996652]
	TIME [epoch: 8.25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11933315883133613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11933315883133613 | validation: 0.12189613844585444]
	TIME [epoch: 8.23 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13568707807185942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13568707807185942 | validation: 0.2301313526012316]
	TIME [epoch: 8.23 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1562513690312104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1562513690312104 | validation: 0.10331338393767697]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09756704735501416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09756704735501416 | validation: 0.09391705172626946]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10173982420571868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10173982420571868 | validation: 0.21148495043972498]
	TIME [epoch: 8.25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1379724075564731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1379724075564731 | validation: 0.12104069725054677]
	TIME [epoch: 8.23 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13829397918837316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13829397918837316 | validation: 0.18483498351924466]
	TIME [epoch: 8.22 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15820816220884953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15820816220884953 | validation: 0.18659675019718996]
	TIME [epoch: 8.23 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13311934880198034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13311934880198034 | validation: 0.146412646226112]
	TIME [epoch: 8.22 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14012190499836474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14012190499836474 | validation: 0.1701859938041602]
	TIME [epoch: 8.23 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14987449244062614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14987449244062614 | validation: 0.1646515771573705]
	TIME [epoch: 8.24 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1283223010712177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1283223010712177 | validation: 0.11892086257621232]
	TIME [epoch: 8.23 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12159469050163901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12159469050163901 | validation: 0.14599512608773524]
	TIME [epoch: 8.22 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1056977540551716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1056977540551716 | validation: 0.12831534944044637]
	TIME [epoch: 8.23 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10181706238228308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10181706238228308 | validation: 0.15445939978858597]
	TIME [epoch: 8.22 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12656974460826398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12656974460826398 | validation: 0.12409493347556406]
	TIME [epoch: 8.23 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1447063292314245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1447063292314245 | validation: 0.14981491679691464]
	TIME [epoch: 8.25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11056577563633596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11056577563633596 | validation: 0.19727877103738356]
	TIME [epoch: 8.23 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19577758435456394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19577758435456394 | validation: 0.3153794956960103]
	TIME [epoch: 8.23 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2239489061112365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2239489061112365 | validation: 0.3426539216326255]
	TIME [epoch: 8.23 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24567574279138576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24567574279138576 | validation: 0.18398647337317603]
	TIME [epoch: 8.23 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.148561012990197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.148561012990197 | validation: 0.12357892384366985]
	TIME [epoch: 8.23 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1420160134259604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1420160134259604 | validation: 0.12084663089710455]
	TIME [epoch: 8.24 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1282527355329206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1282527355329206 | validation: 0.2062130312466035]
	TIME [epoch: 8.23 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15742615625061696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15742615625061696 | validation: 0.11209096081397352]
	TIME [epoch: 8.22 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1619396297783198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1619396297783198 | validation: 0.10430330984665469]
	TIME [epoch: 8.22 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.134370850086909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.134370850086909 | validation: 0.11341029460180625]
	TIME [epoch: 8.23 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10517792929023533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10517792929023533 | validation: 0.13443312712935648]
	TIME [epoch: 8.24 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.115216063708904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.115216063708904 | validation: 0.11281049884614994]
	TIME [epoch: 40.2 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11329972056229566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11329972056229566 | validation: 0.12846325448920015]
	TIME [epoch: 17.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10774912424042046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10774912424042046 | validation: 0.14357165495052168]
	TIME [epoch: 17.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1328808246594544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1328808246594544 | validation: 0.139713796247645]
	TIME [epoch: 17.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13989057265386468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13989057265386468 | validation: 0.29979325730422623]
	TIME [epoch: 17.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19743593163897213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19743593163897213 | validation: 0.18585755001184548]
	TIME [epoch: 17.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18955389985307725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18955389985307725 | validation: 0.17241133129515318]
	TIME [epoch: 17.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12086042569081606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12086042569081606 | validation: 0.18492845906820696]
	TIME [epoch: 17.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13506248710017016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13506248710017016 | validation: 0.11166271716887155]
	TIME [epoch: 17.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1093366602276958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1093366602276958 | validation: 0.10539577781453378]
	TIME [epoch: 17.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11442206670419663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11442206670419663 | validation: 0.1454249057258827]
	TIME [epoch: 17.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10821771257776483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10821771257776483 | validation: 0.12772600325146286]
	TIME [epoch: 17.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11079418819071163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11079418819071163 | validation: 0.12202944040766994]
	TIME [epoch: 17.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12330739803443035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12330739803443035 | validation: 0.1247723555222954]
	TIME [epoch: 17.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10851746130978686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10851746130978686 | validation: 0.10285765894102306]
	TIME [epoch: 17.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09447326065052288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09447326065052288 | validation: 0.09233856715438915]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09085510176173683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09085510176173683 | validation: 0.10687617716557814]
	TIME [epoch: 17.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09126084831489634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09126084831489634 | validation: 0.09046014844223299]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09488014966860953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09488014966860953 | validation: 0.1656150143945294]
	TIME [epoch: 17.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1139596677296862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1139596677296862 | validation: 0.09299451344410559]
	TIME [epoch: 17.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12622230390379066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12622230390379066 | validation: 0.2804354108511483]
	TIME [epoch: 17.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18610461065193484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18610461065193484 | validation: 0.16468696123510562]
	TIME [epoch: 17.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10637906246206419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10637906246206419 | validation: 0.10834156488286051]
	TIME [epoch: 17.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1254120372371159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1254120372371159 | validation: 0.1617703063267321]
	TIME [epoch: 17.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11796436743324584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11796436743324584 | validation: 0.1614306693267135]
	TIME [epoch: 17.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12203891477635231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12203891477635231 | validation: 0.13166326604669346]
	TIME [epoch: 17.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12151881518584201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12151881518584201 | validation: 0.14418949547026227]
	TIME [epoch: 17.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12219781437608256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12219781437608256 | validation: 0.11393295120676472]
	TIME [epoch: 17.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10710535183854003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10710535183854003 | validation: 0.09268868907994032]
	TIME [epoch: 17.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10104901052671988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10104901052671988 | validation: 0.21931147995917613]
	TIME [epoch: 17.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14228417396102547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14228417396102547 | validation: 0.09498407575140108]
	TIME [epoch: 17.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09072593256453024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09072593256453024 | validation: 0.1178621182861051]
	TIME [epoch: 17.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0896225072669193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0896225072669193 | validation: 0.11303125338350793]
	TIME [epoch: 17.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09345752448828144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09345752448828144 | validation: 0.1317104600208518]
	TIME [epoch: 17.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10885474604858107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10885474604858107 | validation: 0.1533673638103069]
	TIME [epoch: 17.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14942741209250648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14942741209250648 | validation: 0.20532541832068285]
	TIME [epoch: 17.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15107307416714155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15107307416714155 | validation: 0.32335997956602314]
	TIME [epoch: 17.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2635263293123876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2635263293123876 | validation: 0.1618126214475525]
	TIME [epoch: 17.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16764241546367015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16764241546367015 | validation: 0.17980494752603673]
	TIME [epoch: 17.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12086094789587812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12086094789587812 | validation: 0.16135843909761693]
	TIME [epoch: 17.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12086098232897342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12086098232897342 | validation: 0.10422441021439229]
	TIME [epoch: 17.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0939896255449839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0939896255449839 | validation: 0.10011665552920275]
	TIME [epoch: 17.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09980664799211678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09980664799211678 | validation: 0.09750189088665462]
	TIME [epoch: 17.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08844490131527284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08844490131527284 | validation: 0.10041526886498123]
	TIME [epoch: 17.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08541355118800838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08541355118800838 | validation: 0.13433258544302512]
	TIME [epoch: 17.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10495887922828147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10495887922828147 | validation: 0.10527929815794308]
	TIME [epoch: 17.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10282124243602869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10282124243602869 | validation: 0.09594375413375657]
	TIME [epoch: 17.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0941143209109147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0941143209109147 | validation: 0.11686240994926296]
	TIME [epoch: 17.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09276173991228821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09276173991228821 | validation: 0.09668750086561957]
	TIME [epoch: 17.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10213338256311669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10213338256311669 | validation: 0.11734610903277663]
	TIME [epoch: 17.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09045972143925447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09045972143925447 | validation: 0.0897037059310366]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09935084972295039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09935084972295039 | validation: 0.2117837138616433]
	TIME [epoch: 17.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15914209891783687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15914209891783687 | validation: 0.14483547446906084]
	TIME [epoch: 17.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14384248773971867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14384248773971867 | validation: 0.12685425935622904]
	TIME [epoch: 17.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11937429075476957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11937429075476957 | validation: 0.2135384032671749]
	TIME [epoch: 17.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1320342845299895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1320342845299895 | validation: 0.1435410607358429]
	TIME [epoch: 17.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10990048664314676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10990048664314676 | validation: 0.10891436412763689]
	TIME [epoch: 17.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08954454885172254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08954454885172254 | validation: 0.14048648647199835]
	TIME [epoch: 17.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10254984090909411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10254984090909411 | validation: 0.08395565488612566]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10290593620213823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10290593620213823 | validation: 0.07830819704003728]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08705105548160283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08705105548160283 | validation: 0.12086918730818637]
	TIME [epoch: 17.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10470669302939978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10470669302939978 | validation: 0.16774624235582603]
	TIME [epoch: 17.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1242672336716897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1242672336716897 | validation: 0.10222355853933154]
	TIME [epoch: 17.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11392700202355246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11392700202355246 | validation: 0.13946057609864024]
	TIME [epoch: 17.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1239673953773667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1239673953773667 | validation: 0.12181551810685352]
	TIME [epoch: 17.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10790597708713373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10790597708713373 | validation: 0.07176719321335465]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07801225797255336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07801225797255336 | validation: 0.1327840635310091]
	TIME [epoch: 17.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09058248726919793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09058248726919793 | validation: 0.10686205829875073]
	TIME [epoch: 17.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11378046215086202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11378046215086202 | validation: 0.20104901790462737]
	TIME [epoch: 17.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14317308615302493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14317308615302493 | validation: 0.15936089733150982]
	TIME [epoch: 17.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1086973157146749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1086973157146749 | validation: 0.08847399171273393]
	TIME [epoch: 17.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1029411578041808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1029411578041808 | validation: 0.11862921877028774]
	TIME [epoch: 17.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10801996348391998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10801996348391998 | validation: 0.09811565404778026]
	TIME [epoch: 17.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0947055352753464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0947055352753464 | validation: 0.0951649593557985]
	TIME [epoch: 17.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0783098501789994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0783098501789994 | validation: 0.08246338463737227]
	TIME [epoch: 17.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07478881481676472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07478881481676472 | validation: 0.10506648910972483]
	TIME [epoch: 17.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09911426871297531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09911426871297531 | validation: 0.20344171847522652]
	TIME [epoch: 17.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13370660576394086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13370660576394086 | validation: 0.12645942735001792]
	TIME [epoch: 17.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09042866194115622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09042866194115622 | validation: 0.08422820709461518]
	TIME [epoch: 17.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09146193036628547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09146193036628547 | validation: 0.15945526555478617]
	TIME [epoch: 17.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12184180789192145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12184180789192145 | validation: 0.08288400341265366]
	TIME [epoch: 17.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10456704455154509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10456704455154509 | validation: 0.07078929016712643]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10177475119119361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10177475119119361 | validation: 0.11432195558045831]
	TIME [epoch: 17.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.083976311785647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.083976311785647 | validation: 0.08700854950678368]
	TIME [epoch: 17.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08469149457431539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08469149457431539 | validation: 0.13782666003971666]
	TIME [epoch: 17.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11960203078655994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11960203078655994 | validation: 0.09881425537474753]
	TIME [epoch: 17.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09458894524810305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09458894524810305 | validation: 0.1286283105068324]
	TIME [epoch: 17.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12185562414710965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12185562414710965 | validation: 0.12450572964099496]
	TIME [epoch: 17.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1386984594574845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1386984594574845 | validation: 0.11064345850731035]
	TIME [epoch: 17.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09008269157417599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09008269157417599 | validation: 0.12471382825963338]
	TIME [epoch: 17.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11364710656493764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11364710656493764 | validation: 0.11089952665094219]
	TIME [epoch: 17.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10027252913650342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10027252913650342 | validation: 0.07781057243961458]
	TIME [epoch: 17.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07592943232122207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07592943232122207 | validation: 0.0966936892338687]
	TIME [epoch: 17.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0768772019032644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0768772019032644 | validation: 0.07335999869473571]
	TIME [epoch: 17.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0938473983257648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0938473983257648 | validation: 0.1761199012850574]
	TIME [epoch: 17.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1234456645175467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1234456645175467 | validation: 0.10042583760130877]
	TIME [epoch: 17.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09651596888435751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09651596888435751 | validation: 0.08616889913500124]
	TIME [epoch: 17.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0807074298752815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0807074298752815 | validation: 0.09917284579290317]
	TIME [epoch: 17.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.077662530427303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.077662530427303 | validation: 0.09633932028436604]
	TIME [epoch: 17.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09457287763017068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09457287763017068 | validation: 0.14945412016570886]
	TIME [epoch: 17.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12302970364505171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12302970364505171 | validation: 0.12672352301804635]
	TIME [epoch: 17.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1222459246831037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1222459246831037 | validation: 0.08015256955141703]
	TIME [epoch: 17.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07940360046041565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07940360046041565 | validation: 0.11164664625217594]
	TIME [epoch: 17.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07262489134069827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07262489134069827 | validation: 0.09561940598699725]
	TIME [epoch: 17.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10488768551641844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10488768551641844 | validation: 0.2689898380298869]
	TIME [epoch: 17.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17627370588793972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17627370588793972 | validation: 0.09537890477549335]
	TIME [epoch: 17.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0991766658250398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0991766658250398 | validation: 0.07368687506242716]
	TIME [epoch: 17.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10131130971436282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10131130971436282 | validation: 0.13737157353592191]
	TIME [epoch: 17.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11526091966936929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11526091966936929 | validation: 0.12726818474196175]
	TIME [epoch: 17.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10569148476027994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10569148476027994 | validation: 0.09644566343058267]
	TIME [epoch: 17.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09829362787436349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09829362787436349 | validation: 0.06114872983260761]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06971942716331478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06971942716331478 | validation: 0.07913284005303518]
	TIME [epoch: 17.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06350354123969792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06350354123969792 | validation: 0.07387490584869803]
	TIME [epoch: 17.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06130607069795561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06130607069795561 | validation: 0.060501091694081015]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08282647690515436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08282647690515436 | validation: 0.20047081379115764]
	TIME [epoch: 17.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12402843027450555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12402843027450555 | validation: 0.09314156843965615]
	TIME [epoch: 17.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10217423040784177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10217423040784177 | validation: 0.09225184589263621]
	TIME [epoch: 17.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09202331828959792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09202331828959792 | validation: 0.0869885739756325]
	TIME [epoch: 17.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07471919772871888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07471919772871888 | validation: 0.09352691283071518]
	TIME [epoch: 17.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08901765910068538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08901765910068538 | validation: 0.09679625829444079]
	TIME [epoch: 17.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1099712149215069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1099712149215069 | validation: 0.14057307303829678]
	TIME [epoch: 17.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13021129515514973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13021129515514973 | validation: 0.10688071778497168]
	TIME [epoch: 17.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10138676032920182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10138676032920182 | validation: 0.06979892251477086]
	TIME [epoch: 17.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06290462010576665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06290462010576665 | validation: 0.07234767953994126]
	TIME [epoch: 17.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062481121240587606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.062481121240587606 | validation: 0.08941741909892661]
	TIME [epoch: 17.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07049940812838973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07049940812838973 | validation: 0.07756608873598758]
	TIME [epoch: 17.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09917856818750007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09917856818750007 | validation: 0.22398320635894034]
	TIME [epoch: 17.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1553544272405261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1553544272405261 | validation: 0.10253713728761227]
	TIME [epoch: 17.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08577635062948266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08577635062948266 | validation: 0.06853101789982109]
	TIME [epoch: 17.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08087537967090708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08087537967090708 | validation: 0.11052589218462071]
	TIME [epoch: 17.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08177062918151115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08177062918151115 | validation: 0.08178455198513158]
	TIME [epoch: 17.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06950345436515647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06950345436515647 | validation: 0.06458298009499637]
	TIME [epoch: 17.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08842400917081118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08842400917081118 | validation: 0.14237805139836796]
	TIME [epoch: 17.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1321160412052138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1321160412052138 | validation: 0.0806383439181182]
	TIME [epoch: 17.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.086513687166491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.086513687166491 | validation: 0.06783836825505309]
	TIME [epoch: 17.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09455777440711449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09455777440711449 | validation: 0.2371255688002839]
	TIME [epoch: 17.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16411627330446746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16411627330446746 | validation: 0.17319548775796711]
	TIME [epoch: 17.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1729359197315001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1729359197315001 | validation: 0.11205107993247627]
	TIME [epoch: 17.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11230922278668533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11230922278668533 | validation: 0.1736860234539075]
	TIME [epoch: 17.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10041894203295783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10041894203295783 | validation: 0.14649708029960218]
	TIME [epoch: 17.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09290321409735972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09290321409735972 | validation: 0.09035817565201239]
	TIME [epoch: 17.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0747804596703494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0747804596703494 | validation: 0.07805157683347766]
	TIME [epoch: 17.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07113453328569411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07113453328569411 | validation: 0.07605808397590753]
	TIME [epoch: 17.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06459645271386838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06459645271386838 | validation: 0.10587246707063597]
	TIME [epoch: 17.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07236901825417846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07236901825417846 | validation: 0.0805175722399737]
	TIME [epoch: 17.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06975593124138199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06975593124138199 | validation: 0.06111243712605022]
	TIME [epoch: 17.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06832501883284485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06832501883284485 | validation: 0.12267883555849926]
	TIME [epoch: 17.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08045113526719164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08045113526719164 | validation: 0.09334582025432804]
	TIME [epoch: 17.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08980930176557048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08980930176557048 | validation: 0.10754957641260554]
	TIME [epoch: 17.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11460526166468743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11460526166468743 | validation: 0.09344723814367885]
	TIME [epoch: 17.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08644034477228678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08644034477228678 | validation: 0.08451084485261666]
	TIME [epoch: 17.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08801817478593989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08801817478593989 | validation: 0.16691737016950917]
	TIME [epoch: 17.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12285654304627393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12285654304627393 | validation: 0.07639481835886819]
	TIME [epoch: 17.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07642770056495224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07642770056495224 | validation: 0.07503748448589731]
	TIME [epoch: 17.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06186381511559622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06186381511559622 | validation: 0.0752363818765756]
	TIME [epoch: 17.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06219211486378973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06219211486378973 | validation: 0.07123338733317323]
	TIME [epoch: 17.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08967479051311798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08967479051311798 | validation: 0.2464099447605529]
	TIME [epoch: 17.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16325100245318755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16325100245318755 | validation: 0.13059509583176898]
	TIME [epoch: 17.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09872104015110328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09872104015110328 | validation: 0.06843721774089186]
	TIME [epoch: 17.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10765228731647845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10765228731647845 | validation: 0.11638374613866992]
	TIME [epoch: 17.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08490223624712881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08490223624712881 | validation: 0.11076102530385956]
	TIME [epoch: 17.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10400715145358971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10400715145358971 | validation: 0.07696134633896595]
	TIME [epoch: 17.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08796648881238349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08796648881238349 | validation: 0.07341546512993728]
	TIME [epoch: 17.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08778655593924527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08778655593924527 | validation: 0.09081559973923571]
	TIME [epoch: 17.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08322109511003539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08322109511003539 | validation: 0.08240895813842035]
	TIME [epoch: 17.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07250021332921562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07250021332921562 | validation: 0.0744686830559786]
	TIME [epoch: 17.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05922209326232899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05922209326232899 | validation: 0.05178354414234965]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0575194668305737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0575194668305737 | validation: 0.08882119198889898]
	TIME [epoch: 17.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06413308845106007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06413308845106007 | validation: 0.05818463840342705]
	TIME [epoch: 17.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08106118084845118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08106118084845118 | validation: 0.1563502980741495]
	TIME [epoch: 17.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11252914070910092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11252914070910092 | validation: 0.08890105945587219]
	TIME [epoch: 17.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0993175925693982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0993175925693982 | validation: 0.11314615282358083]
	TIME [epoch: 17.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07316278506258324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07316278506258324 | validation: 0.06913915300053115]
	TIME [epoch: 17.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06213171237960305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06213171237960305 | validation: 0.06170296502403369]
	TIME [epoch: 17.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07546336711255217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07546336711255217 | validation: 0.11861272501120908]
	TIME [epoch: 17.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10780480122788688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10780480122788688 | validation: 0.09054405375555562]
	TIME [epoch: 17.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08701695924702786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08701695924702786 | validation: 0.09544137351380348]
	TIME [epoch: 17.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10575285620976614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10575285620976614 | validation: 0.0558051099590178]
	TIME [epoch: 17.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0528792822622221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0528792822622221 | validation: 0.05573540639373521]
	TIME [epoch: 17.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05856412485588395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05856412485588395 | validation: 0.1345323459209787]
	TIME [epoch: 17.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09489664790821489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09489664790821489 | validation: 0.1608108056400378]
	TIME [epoch: 17.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17288431052157677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17288431052157677 | validation: 0.17015037910394862]
	TIME [epoch: 17.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11774861563247198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11774861563247198 | validation: 0.1459580818376349]
	TIME [epoch: 17.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08756166413851071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08756166413851071 | validation: 0.11180013929444686]
	TIME [epoch: 17.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09451505107305003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09451505107305003 | validation: 0.10437043449337727]
	TIME [epoch: 17.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08640402102485321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08640402102485321 | validation: 0.07519443751045889]
	TIME [epoch: 17.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06722212684367926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06722212684367926 | validation: 0.07260729381200057]
	TIME [epoch: 17.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05840406633910725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05840406633910725 | validation: 0.05479935853277021]
	TIME [epoch: 17.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05323087964852812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05323087964852812 | validation: 0.04814796953562668]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05226100952801192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05226100952801192 | validation: 0.07151168679436819]
	TIME [epoch: 17.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06461854500643463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06461854500643463 | validation: 0.05615692617307777]
	TIME [epoch: 17.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07086236112761977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07086236112761977 | validation: 0.10896418310004169]
	TIME [epoch: 17.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0976231662330228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0976231662330228 | validation: 0.12431654053897244]
	TIME [epoch: 17.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14273738224597948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14273738224597948 | validation: 0.10533674509062939]
	TIME [epoch: 17.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1026249244247854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1026249244247854 | validation: 0.2777627356871791]
	TIME [epoch: 17.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22516456329777298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22516456329777298 | validation: 0.08050405298167573]
	TIME [epoch: 17.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08499495215384961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08499495215384961 | validation: 0.2097078410585491]
	TIME [epoch: 17.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1302102387809313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1302102387809313 | validation: 0.1309988659909463]
	TIME [epoch: 17.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08942670412119301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08942670412119301 | validation: 0.061461062414888294]
	TIME [epoch: 17.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06443924534423194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06443924534423194 | validation: 0.059055459285404316]
	TIME [epoch: 17.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05051789114389556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05051789114389556 | validation: 0.07050417964614276]
	TIME [epoch: 17.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054443336680163094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054443336680163094 | validation: 0.05831981021410622]
	TIME [epoch: 17.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052374949127108814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052374949127108814 | validation: 0.04936193026733559]
	TIME [epoch: 17.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06853526557770233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06853526557770233 | validation: 0.15087184819729776]
	TIME [epoch: 17.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10033957505311525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10033957505311525 | validation: 0.10740290207404611]
	TIME [epoch: 17.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11103422768353406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11103422768353406 | validation: 0.12643600764300186]
	TIME [epoch: 17.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10504660110708475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10504660110708475 | validation: 0.09425844695961727]
	TIME [epoch: 17.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09728440368054209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09728440368054209 | validation: 0.07735339281577051]
	TIME [epoch: 17.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06805846145299527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06805846145299527 | validation: 0.04652079105338095]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06121618055361502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06121618055361502 | validation: 0.086737136720436]
	TIME [epoch: 17.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06728702740754587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06728702740754587 | validation: 0.08355082781652068]
	TIME [epoch: 17.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09105883040176363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09105883040176363 | validation: 0.14391259446177085]
	TIME [epoch: 17.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11243807939140464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11243807939140464 | validation: 0.08193414407735986]
	TIME [epoch: 17.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08024259819527242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08024259819527242 | validation: 0.09984957360141035]
	TIME [epoch: 17.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06621501338065709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06621501338065709 | validation: 0.05346787491662839]
	TIME [epoch: 17.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054709315737996596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054709315737996596 | validation: 0.04960456090982375]
	TIME [epoch: 17.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05231301953621475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05231301953621475 | validation: 0.056142775759343636]
	TIME [epoch: 17.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05284966567000291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05284966567000291 | validation: 0.05084100046341305]
	TIME [epoch: 17.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06575680381642733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06575680381642733 | validation: 0.111104633079042]
	TIME [epoch: 17.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08644729108733465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08644729108733465 | validation: 0.0852831581926444]
	TIME [epoch: 17.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07464343250670506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07464343250670506 | validation: 0.08678690512230712]
	TIME [epoch: 17.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08870593132292812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08870593132292812 | validation: 0.09829463144761141]
	TIME [epoch: 17.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11635620722343039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11635620722343039 | validation: 0.16536236514051064]
	TIME [epoch: 17.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13005245321159195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13005245321159195 | validation: 0.35464252586080863]
	TIME [epoch: 17.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2991523074296709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2991523074296709 | validation: 0.16370034386045323]
	TIME [epoch: 17.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16489606058090886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16489606058090886 | validation: 0.16413278662559455]
	TIME [epoch: 17.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10082949479882175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10082949479882175 | validation: 0.17973701611734522]
	TIME [epoch: 17.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0935323077038062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0935323077038062 | validation: 0.18043839284374996]
	TIME [epoch: 17.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09320455448231439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09320455448231439 | validation: 0.1708459882484521]
	TIME [epoch: 17.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09727337187298965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09727337187298965 | validation: 0.10784890914008166]
	TIME [epoch: 17.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07689122867855419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07689122867855419 | validation: 0.0810777553007847]
	TIME [epoch: 17.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07133535099937147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07133535099937147 | validation: 0.05239890991430072]
	TIME [epoch: 17.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06207515377597357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06207515377597357 | validation: 0.07398510721114433]
	TIME [epoch: 17.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053079976751368045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053079976751368045 | validation: 0.05805918383867345]
	TIME [epoch: 17.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05159138929929084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05159138929929084 | validation: 0.06874523531473738]
	TIME [epoch: 17.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0558032660816014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0558032660816014 | validation: 0.08935279321985037]
	TIME [epoch: 17.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10945023781127657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10945023781127657 | validation: 0.15188750637187742]
	TIME [epoch: 17.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10742287524214675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10742287524214675 | validation: 0.08933589478700321]
	TIME [epoch: 17.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0708799801447037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0708799801447037 | validation: 0.05611163337830998]
	TIME [epoch: 17.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06772051282665081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06772051282665081 | validation: 0.0926201728618653]
	TIME [epoch: 17.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08594544183115485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08594544183115485 | validation: 0.09975612295054018]
	TIME [epoch: 17.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10944055524973986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10944055524973986 | validation: 0.08394417609794687]
	TIME [epoch: 17.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09113823338268078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09113823338268078 | validation: 0.07146629622649674]
	TIME [epoch: 17.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05746224977354768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05746224977354768 | validation: 0.057236393163283196]
	TIME [epoch: 17.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06742746210834968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06742746210834968 | validation: 0.10112780111959588]
	TIME [epoch: 17.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07665547720042133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07665547720042133 | validation: 0.05205562600396257]
	TIME [epoch: 17.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06682654469557975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06682654469557975 | validation: 0.1447659592352046]
	TIME [epoch: 17.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09992255395892918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09992255395892918 | validation: 0.06976771094436232]
	TIME [epoch: 17.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06690707635094306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06690707635094306 | validation: 0.0498424169895757]
	TIME [epoch: 17.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07082829506723665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07082829506723665 | validation: 0.0716746439840377]
	TIME [epoch: 17.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058926446572544366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058926446572544366 | validation: 0.059209175705803245]
	TIME [epoch: 17.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06292608886253033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06292608886253033 | validation: 0.08305783641308115]
	TIME [epoch: 17.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0625067481041326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0625067481041326 | validation: 0.04100144377982168]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_753.pth
	Model improved!!!
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06305545134830784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06305545134830784 | validation: 0.06600482078580003]
	TIME [epoch: 17.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053220978012127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053220978012127 | validation: 0.05734978448079066]
	TIME [epoch: 17.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07092410918756273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07092410918756273 | validation: 0.09321945853335654]
	TIME [epoch: 17.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08062210185379201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08062210185379201 | validation: 0.06604579668452425]
	TIME [epoch: 17.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0708886534032775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0708886534032775 | validation: 0.09181490230822853]
	TIME [epoch: 17.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09232911359418887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09232911359418887 | validation: 0.14663409605474756]
	TIME [epoch: 17.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10726560703585471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10726560703585471 | validation: 0.12683048236370958]
	TIME [epoch: 17.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11812108976829006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11812108976829006 | validation: 0.1164803128885428]
	TIME [epoch: 17.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09134998310712238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09134998310712238 | validation: 0.05625981868455076]
	TIME [epoch: 17.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0914394053927139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0914394053927139 | validation: 0.13650228362821948]
	TIME [epoch: 17.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09398325401180305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09398325401180305 | validation: 0.11740317882423851]
	TIME [epoch: 17.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06718233071742655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06718233071742655 | validation: 0.05607824464681741]
	TIME [epoch: 17.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06946071434028342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06946071434028342 | validation: 0.06508207165027634]
	TIME [epoch: 17.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06013690239351473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06013690239351473 | validation: 0.07970466409926469]
	TIME [epoch: 17.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060309217842330086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060309217842330086 | validation: 0.057840101252585034]
	TIME [epoch: 17.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06392786774107483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06392786774107483 | validation: 0.06432786381468873]
	TIME [epoch: 17.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06491410080998213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06491410080998213 | validation: 0.05208669268173737]
	TIME [epoch: 17.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07414585858321013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07414585858321013 | validation: 0.10767508933401332]
	TIME [epoch: 17.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06951323065055963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06951323065055963 | validation: 0.06208525320538928]
	TIME [epoch: 17.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06178419939125372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06178419939125372 | validation: 0.05516766166516396]
	TIME [epoch: 17.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.064137132966801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.064137132966801 | validation: 0.06213893853110818]
	TIME [epoch: 17.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0559986939213722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0559986939213722 | validation: 0.1003694369906028]
	TIME [epoch: 17.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09230142850636953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09230142850636953 | validation: 0.12537155659938573]
	TIME [epoch: 17.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12347518121310785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12347518121310785 | validation: 0.07229483458253964]
	TIME [epoch: 17.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08090600344049743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08090600344049743 | validation: 0.06951442104269961]
	TIME [epoch: 17.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06357947554339316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06357947554339316 | validation: 0.04168082397917433]
	TIME [epoch: 17.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06830355365167444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06830355365167444 | validation: 0.14576810398895]
	TIME [epoch: 17.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08917965937167345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08917965937167345 | validation: 0.08879562579268475]
	TIME [epoch: 17.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07493897181892697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07493897181892697 | validation: 0.05943149480830188]
	TIME [epoch: 17.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056588340795323815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056588340795323815 | validation: 0.04715538652087873]
	TIME [epoch: 17.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04231522849023904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04231522849023904 | validation: 0.056975893979095964]
	TIME [epoch: 17.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05195167550232143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05195167550232143 | validation: 0.04450514291172067]
	TIME [epoch: 17.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04854337120290401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04854337120290401 | validation: 0.04108129068354941]
	TIME [epoch: 17.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05777190407803353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05777190407803353 | validation: 0.10545970752372642]
	TIME [epoch: 17.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07902643323757967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07902643323757967 | validation: 0.10970897741604997]
	TIME [epoch: 17.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1245560990876798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1245560990876798 | validation: 0.11968093653432113]
	TIME [epoch: 17.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11362448734551421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11362448734551421 | validation: 0.0536739926076807]
	TIME [epoch: 17.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054126425328312355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054126425328312355 | validation: 0.04881771894456587]
	TIME [epoch: 17.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05205210352046637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05205210352046637 | validation: 0.07695394032011985]
	TIME [epoch: 17.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07175613599589849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07175613599589849 | validation: 0.06251790825372111]
	TIME [epoch: 17.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05200526145604046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05200526145604046 | validation: 0.1643936249231211]
	TIME [epoch: 17.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11523239517336119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11523239517336119 | validation: 0.07270738670667497]
	TIME [epoch: 17.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10049067197100892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10049067197100892 | validation: 0.11127826953569744]
	TIME [epoch: 17.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10499770557045741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10499770557045741 | validation: 0.049073616507838105]
	TIME [epoch: 17.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055815062569746374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055815062569746374 | validation: 0.07616303085402004]
	TIME [epoch: 17.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07131540084830207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07131540084830207 | validation: 0.08034515682132422]
	TIME [epoch: 17.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.084317535823141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.084317535823141 | validation: 0.07809471924517314]
	TIME [epoch: 17.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07282638639063327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07282638639063327 | validation: 0.040403275112138086]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046020405995193886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046020405995193886 | validation: 0.03366054004697682]
	TIME [epoch: 17.6 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04422560536703246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04422560536703246 | validation: 0.03885377171449281]
	TIME [epoch: 17.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0531217883372872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0531217883372872 | validation: 0.1253268671664059]
	TIME [epoch: 17.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08938674283546276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08938674283546276 | validation: 0.13224781169059527]
	TIME [epoch: 17.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13907334520505626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13907334520505626 | validation: 0.11397031674495028]
	TIME [epoch: 17.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10167981099614562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10167981099614562 | validation: 0.08275237309576922]
	TIME [epoch: 17.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060286470844490625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060286470844490625 | validation: 0.08559703873209237]
	TIME [epoch: 17.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0685288584142002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0685288584142002 | validation: 0.0746432005808707]
	TIME [epoch: 17.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06336817546313482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06336817546313482 | validation: 0.04207854446871698]
	TIME [epoch: 17.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05876797307322306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05876797307322306 | validation: 0.0998179006513094]
	TIME [epoch: 17.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06972832822245328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06972832822245328 | validation: 0.06480384273975101]
	TIME [epoch: 17.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07796636134485879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07796636134485879 | validation: 0.09891059380706424]
	TIME [epoch: 17.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07170427335550189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07170427335550189 | validation: 0.09552681166558402]
	TIME [epoch: 17.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07792805068384735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07792805068384735 | validation: 0.07002169852577537]
	TIME [epoch: 17.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06164140894728689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06164140894728689 | validation: 0.03512338395677853]
	TIME [epoch: 17.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05472232033150757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05472232033150757 | validation: 0.049120485014602366]
	TIME [epoch: 17.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054614746690455754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054614746690455754 | validation: 0.060995135265192735]
	TIME [epoch: 17.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08807346145122232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08807346145122232 | validation: 0.11573813564749909]
	TIME [epoch: 17.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09014598559274462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09014598559274462 | validation: 0.09190211289995312]
	TIME [epoch: 17.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10449803378839473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10449803378839473 | validation: 0.14238481868979144]
	TIME [epoch: 17.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10701831470227852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10701831470227852 | validation: 0.07423368656363848]
	TIME [epoch: 17.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07273974156614207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07273974156614207 | validation: 0.04323871027613452]
	TIME [epoch: 17.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05242098580451083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05242098580451083 | validation: 0.044148479721870304]
	TIME [epoch: 17.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050219117037429144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050219117037429144 | validation: 0.043283788781644496]
	TIME [epoch: 17.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05663796617713428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05663796617713428 | validation: 0.04695830226649053]
	TIME [epoch: 17.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04754035925190352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04754035925190352 | validation: 0.03725755429297789]
	TIME [epoch: 17.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042593543753996745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042593543753996745 | validation: 0.032462442482849484]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03891541339072082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03891541339072082 | validation: 0.05347259556445222]
	TIME [epoch: 17.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04102863112643317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04102863112643317 | validation: 0.04202683053612676]
	TIME [epoch: 17.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04518319255102318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04518319255102318 | validation: 0.07205729116849753]
	TIME [epoch: 17.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0541352546626877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0541352546626877 | validation: 0.08393416538894594]
	TIME [epoch: 17.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12271720232955918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12271720232955918 | validation: 0.23149666165211508]
	TIME [epoch: 17.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1742992265161061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1742992265161061 | validation: 1.5540794420818171]
	TIME [epoch: 17.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8211283441086057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8211283441086057 | validation: 2.5914670110839237]
	TIME [epoch: 17.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.799709158081857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.799709158081857 | validation: 3.2407728996894067]
	TIME [epoch: 17.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1387487653372115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1387487653372115 | validation: 3.561767146803389]
	TIME [epoch: 17.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3571888803553054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3571888803553054 | validation: 3.6158646344970222]
	TIME [epoch: 17.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3846425480207296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3846425480207296 | validation: 3.70907187992282]
	TIME [epoch: 17.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.422400287315251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.422400287315251 | validation: 3.7763133569934975]
	TIME [epoch: 17.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4989291459582534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4989291459582534 | validation: 3.76782640688956]
	TIME [epoch: 17.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4755266151748656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4755266151748656 | validation: 3.821585745450374]
	TIME [epoch: 19.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5161395865652203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5161395865652203 | validation: 3.8275733942385943]
	TIME [epoch: 17.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5151491847162744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5151491847162744 | validation: 3.8243276080794573]
	TIME [epoch: 17.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.534510052439764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.534510052439764 | validation: 3.8429393091560353]
	TIME [epoch: 17.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5421514076579195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5421514076579195 | validation: 3.8301222424866603]
	TIME [epoch: 17.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.548558043060508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.548558043060508 | validation: 3.8385316961394267]
	TIME [epoch: 17.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5575177688988475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5575177688988475 | validation: 3.8114485979089032]
	TIME [epoch: 17.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.538700584660525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.538700584660525 | validation: 3.879446044847236]
	TIME [epoch: 17.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.592583630894453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.592583630894453 | validation: 3.8319482881806004]
	TIME [epoch: 17.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.560208222682487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.560208222682487 | validation: 3.8079903124778696]
	TIME [epoch: 17.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5439168384609943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5439168384609943 | validation: 3.748583353236193]
	TIME [epoch: 17.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.496725378497242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.496725378497242 | validation: 3.77524677991936]
	TIME [epoch: 17.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4950193024262477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4950193024262477 | validation: 3.7968527031882027]
	TIME [epoch: 17.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.507349384495443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.507349384495443 | validation: 3.78478336245256]
	TIME [epoch: 17.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.508638808512419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.508638808512419 | validation: 3.8057848361383773]
	TIME [epoch: 17.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.526625081325873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.526625081325873 | validation: 3.819787053158978]
	TIME [epoch: 17.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.533231269785008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.533231269785008 | validation: 3.924336903987157]
	TIME [epoch: 17.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.622752033041457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.622752033041457 | validation: 3.917128599328676]
	TIME [epoch: 17.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.688982177032597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.688982177032597 | validation: 3.782912066989441]
	TIME [epoch: 17.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5193484337347414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5193484337347414 | validation: 3.947156718012903]
	TIME [epoch: 17.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6643424323727847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6643424323727847 | validation: 3.7859137233740783]
	TIME [epoch: 17.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.520695254194213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.520695254194213 | validation: 3.779177838857804]
	TIME [epoch: 17.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5185113338317264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5185113338317264 | validation: 3.8159897423731723]
	TIME [epoch: 17.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5351918169251677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5351918169251677 | validation: 3.7636185781446247]
	TIME [epoch: 17.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5118171151727986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5118171151727986 | validation: 3.7789836545022824]
	TIME [epoch: 17.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5135642217143728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5135642217143728 | validation: 3.7592825015775504]
	TIME [epoch: 17.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.499644294783014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.499644294783014 | validation: 3.713227442803461]
	TIME [epoch: 17.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.452525950821903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.452525950821903 | validation: 3.6503451363522625]
	TIME [epoch: 17.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.403050848105317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.403050848105317 | validation: 3.7392574342737435]
	TIME [epoch: 17.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.454263448850692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.454263448850692 | validation: 3.5493492115107523]
	TIME [epoch: 17.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.363285202973604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.363285202973604 | validation: 1.0819133492045807]
	TIME [epoch: 17.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3502820318811406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3502820318811406 | validation: 2.8750087614045277]
	TIME [epoch: 17.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0896221062358915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0896221062358915 | validation: 2.6137445992593604]
	TIME [epoch: 17.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8305492259772316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8305492259772316 | validation: 2.1220512312702935]
	TIME [epoch: 17.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.297114749246144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.297114749246144 | validation: 1.0186812677390322]
	TIME [epoch: 17.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.330048206042399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.330048206042399 | validation: 0.5260839263623073]
	TIME [epoch: 17.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5121013340422702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5121013340422702 | validation: 0.6304978221507401]
	TIME [epoch: 17.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6372806891418273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6372806891418273 | validation: 0.4754040937901993]
	TIME [epoch: 17.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47460595800901206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47460595800901206 | validation: 0.536828544066763]
	TIME [epoch: 17.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5078164961523787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5078164961523787 | validation: 0.4374936844701228]
	TIME [epoch: 17.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4516223284451016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4516223284451016 | validation: 0.7130280067584487]
	TIME [epoch: 17.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7481936667558747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7481936667558747 | validation: 0.6725477045371924]
	TIME [epoch: 17.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7545676819115383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7545676819115383 | validation: 0.6169041908728783]
	TIME [epoch: 17.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47541846854568676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47541846854568676 | validation: 0.5669620347235088]
	TIME [epoch: 17.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47191612775056013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47191612775056013 | validation: 0.5377780865932186]
	TIME [epoch: 17.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4574456905086724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4574456905086724 | validation: 0.4072729855273082]
	TIME [epoch: 17.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36042733953005895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36042733953005895 | validation: 0.4901684972944936]
	TIME [epoch: 17.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3873000792087365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3873000792087365 | validation: 0.39295426850002824]
	TIME [epoch: 17.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31346009654154083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31346009654154083 | validation: 0.3707611918744729]
	TIME [epoch: 17.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3085821519261883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3085821519261883 | validation: 0.34843846149006164]
	TIME [epoch: 17.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2947410561057708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2947410561057708 | validation: 0.463348883043631]
	TIME [epoch: 17.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3799944836875828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3799944836875828 | validation: 0.329125569055387]
	TIME [epoch: 17.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2846025199599804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2846025199599804 | validation: 0.49788101810674273]
	TIME [epoch: 17.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44168809370699874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44168809370699874 | validation: 0.37606778885043946]
	TIME [epoch: 17.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3341620910907452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3341620910907452 | validation: 0.34035141486367276]
	TIME [epoch: 17.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30142893762302053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30142893762302053 | validation: 0.3839437011207063]
	TIME [epoch: 17.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30901172190066445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30901172190066445 | validation: 0.32223735397461367]
	TIME [epoch: 17.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26025898031445116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26025898031445116 | validation: 0.28631397985914797]
	TIME [epoch: 17.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23086565126666453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23086565126666453 | validation: 0.30181352275319734]
	TIME [epoch: 17.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2735215903624153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2735215903624153 | validation: 0.4208654358643596]
	TIME [epoch: 17.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3573249620273724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3573249620273724 | validation: 0.3787011996734034]
	TIME [epoch: 17.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3275724595716826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3275724595716826 | validation: 0.36291437698623347]
	TIME [epoch: 17.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3045615261431447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3045615261431447 | validation: 0.48331992953292313]
	TIME [epoch: 17.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48808608045802815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48808608045802815 | validation: 0.4337254056366453]
	TIME [epoch: 17.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3541760446998296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3541760446998296 | validation: 0.40567892667091004]
	TIME [epoch: 17.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34883683299062723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34883683299062723 | validation: 0.29150280939319934]
	TIME [epoch: 17.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.250057271351231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.250057271351231 | validation: 0.2658050112738452]
	TIME [epoch: 17.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2150870911285533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2150870911285533 | validation: 0.2509929216376722]
	TIME [epoch: 17.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21781574188814878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21781574188814878 | validation: 0.2827235071497597]
	TIME [epoch: 17.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2329906411799432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2329906411799432 | validation: 0.258438538956593]
	TIME [epoch: 17.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23522335431418456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23522335431418456 | validation: 0.2331269900367756]
	TIME [epoch: 17.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17548499182397073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17548499182397073 | validation: 0.2028755544803812]
	TIME [epoch: 17.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17161744218881844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17161744218881844 | validation: 0.19803741112836148]
	TIME [epoch: 17.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1641451584968162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1641451584968162 | validation: 0.26658685081282424]
	TIME [epoch: 17.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21444170126676462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21444170126676462 | validation: 0.38476002456718783]
	TIME [epoch: 17.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3032301690244157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3032301690244157 | validation: 0.3478145072176353]
	TIME [epoch: 17.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2794455431812408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2794455431812408 | validation: 0.3179692563384963]
	TIME [epoch: 17.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21969557141292728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21969557141292728 | validation: 0.22956679291045648]
	TIME [epoch: 17.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18293636130902385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18293636130902385 | validation: 0.21886564882585208]
	TIME [epoch: 17.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18289877356787201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18289877356787201 | validation: 0.20158325322028997]
	TIME [epoch: 17.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1911276056103839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1911276056103839 | validation: 0.2080768093653542]
	TIME [epoch: 17.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17065958016609997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17065958016609997 | validation: 0.17201186158009346]
	TIME [epoch: 17.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1468174174513457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1468174174513457 | validation: 0.3157845069000607]
	TIME [epoch: 17.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2612590042969526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2612590042969526 | validation: 0.3731107526539568]
	TIME [epoch: 17.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28535394682154663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28535394682154663 | validation: 0.3147758583934076]
	TIME [epoch: 17.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28385783960581645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28385783960581645 | validation: 0.24228873477144122]
	TIME [epoch: 17.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19614040641527028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19614040641527028 | validation: 0.19726526377860562]
	TIME [epoch: 17.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17531320101612544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17531320101612544 | validation: 0.17020244590212436]
	TIME [epoch: 17.7 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20240823_172231/states/model_phi1_3c_v_mmd1_929.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 10982.785 seconds.
