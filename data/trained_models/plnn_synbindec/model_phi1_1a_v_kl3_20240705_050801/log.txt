Args:
Namespace(name='model_phi1_1a_v_kl3', outdir='out/model_training/model_phi1_1a_v_kl3', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2200748217

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.179375326078336		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 11.179375326078336 | validation: 12.529413661943716]
	TIME [epoch: 104 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.001593874516013		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 11.001593874516013 | validation: 10.689091705661614]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.7722099050294		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 10.7722099050294 | validation: 12.998275520687677]
	TIME [epoch: 8.08 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.33340857779184		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 12.33340857779184 | validation: 12.19754705713375]
	TIME [epoch: 8.08 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.466158257505501		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 10.466158257505501 | validation: 9.677329642789074]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.341521528063335		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 8.341521528063335 | validation: 9.07584643587834]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.093429164042032		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 8.093429164042032 | validation: 8.906956713542023]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.932676767797495		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 7.932676767797495 | validation: 8.991617545522864]
	TIME [epoch: 8.13 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.825396691933685		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 7.825396691933685 | validation: 9.27088692885986]
	TIME [epoch: 8.08 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.681144447257127		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 7.681144447257127 | validation: 9.291683899085701]
	TIME [epoch: 8.08 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.835225289382439		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 7.835225289382439 | validation: 9.769758786839706]
	TIME [epoch: 8.09 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.670333145518409		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 7.670333145518409 | validation: 8.988698187369472]
	TIME [epoch: 8.09 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.62489217551814		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 7.62489217551814 | validation: 8.517582804670845]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.166085190958901		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 7.166085190958901 | validation: 8.170955423899535]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.975380537058033		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 6.975380537058033 | validation: 8.063289769545964]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.990805733679626		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 6.990805733679626 | validation: 7.932332300457912]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.683271458349426		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 7.683271458349426 | validation: 7.982133541625146]
	TIME [epoch: 8.08 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4847882897556826		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 6.4847882897556826 | validation: 7.357976166578237]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.239751386141739		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 6.239751386141739 | validation: 7.130301899840989]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1010720471328765		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 6.1010720471328765 | validation: 7.321238123147966]
	TIME [epoch: 8.08 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1007533776352485		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 6.1007533776352485 | validation: 6.792042055683362]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.941391531488684		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 5.941391531488684 | validation: 6.733164741845434]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.95970218211429		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 5.95970218211429 | validation: 6.584165878960269]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.683250807902497		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 5.683250807902497 | validation: 6.219230398920503]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.79607854113932		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 5.79607854113932 | validation: 6.251759447218772]
	TIME [epoch: 8.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.012717343311604		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 6.012717343311604 | validation: 5.958444221521824]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666939114228446		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 5.666939114228446 | validation: 5.644846885339934]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.565057990935138		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 5.565057990935138 | validation: 5.679673273447184]
	TIME [epoch: 8.08 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.392617844440007		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 5.392617844440007 | validation: 5.829654191545663]
	TIME [epoch: 8.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.481716177932581		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 5.481716177932581 | validation: 5.9378860536382]
	TIME [epoch: 8.13 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7589465276229115		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 5.7589465276229115 | validation: 6.121673621544832]
	TIME [epoch: 8.08 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.695321995648157		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 5.695321995648157 | validation: 5.504197534859864]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.282847523083082		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 5.282847523083082 | validation: 5.219693661626055]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.325407060684725		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 5.325407060684725 | validation: 5.357124354003821]
	TIME [epoch: 8.09 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0065428657958275		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 6.0065428657958275 | validation: 6.2495543723832]
	TIME [epoch: 8.13 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.466275050376467		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 5.466275050376467 | validation: 5.296798867629631]
	TIME [epoch: 8.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.118760955536633		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 5.118760955536633 | validation: 5.027957192042159]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3424200169646845		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 5.3424200169646845 | validation: 5.2874282996647235]
	TIME [epoch: 8.08 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.241702085514374		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 5.241702085514374 | validation: 6.663388455745556]
	TIME [epoch: 8.08 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.650357741473476		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 5.650357741473476 | validation: 6.085375627528219]
	TIME [epoch: 8.09 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.474844145071393		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 5.474844145071393 | validation: 5.505734727067265]
	TIME [epoch: 8.12 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9956162656782555		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 4.9956162656782555 | validation: 4.555919216575338]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.423768216906254		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 4.423768216906254 | validation: 5.5521431585351095]
	TIME [epoch: 8.09 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.169937063221392		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 5.169937063221392 | validation: 5.812373588203208]
	TIME [epoch: 8.09 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.848155819123372		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 4.848155819123372 | validation: 4.597811224583665]
	TIME [epoch: 8.1 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.281377269324477		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 4.281377269324477 | validation: 5.126448950091944]
	TIME [epoch: 8.14 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.126951408293622		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 4.126951408293622 | validation: 3.896886965978995]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6353178933777546		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 3.6353178933777546 | validation: 5.013501007889365]
	TIME [epoch: 8.09 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042894969856286		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 4.042894969856286 | validation: 4.052117299105176]
	TIME [epoch: 8.09 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0122495122327155		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 4.0122495122327155 | validation: 4.0377805659025]
	TIME [epoch: 8.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.301928740407108		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.301928740407108 | validation: 8.55677437434193]
	TIME [epoch: 8.08 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.559542103092177		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 9.559542103092177 | validation: 8.952753534566266]
	TIME [epoch: 8.14 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725081196475679		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 6.725081196475679 | validation: 6.343983537663108]
	TIME [epoch: 8.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1484128380862195		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 5.1484128380862195 | validation: 5.9572410810345815]
	TIME [epoch: 8.09 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.585963845699234		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 4.585963845699234 | validation: 4.47855639022379]
	TIME [epoch: 8.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9432928311733084		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 3.9432928311733084 | validation: 3.7522067058576347]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4212281806304565		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 3.4212281806304565 | validation: 3.837723120014445]
	TIME [epoch: 8.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7794941142077083		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 3.7794941142077083 | validation: 3.6646341960600672]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4478476917145526		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 3.4478476917145526 | validation: 3.0868936054131844]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4952140726856333		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 3.4952140726856333 | validation: 3.3424449288995137]
	TIME [epoch: 8.08 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9374257887776576		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 2.9374257887776576 | validation: 3.282809408450002]
	TIME [epoch: 8.09 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4051140101805926		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 3.4051140101805926 | validation: 3.215060585799497]
	TIME [epoch: 8.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.319560378070516		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 3.319560378070516 | validation: 3.4970441011522557]
	TIME [epoch: 8.13 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039130142899756		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 4.039130142899756 | validation: 6.649740580824233]
	TIME [epoch: 8.09 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.841226171532953		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 4.841226171532953 | validation: 3.063257684478186]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.063599408706006		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 3.063599408706006 | validation: 2.8026337555971743]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7593206823733607		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 2.7593206823733607 | validation: 4.853852683594232]
	TIME [epoch: 8.08 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6099847376963754		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 3.6099847376963754 | validation: 5.15617143597062]
	TIME [epoch: 8.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464799738500133		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 4.464799738500133 | validation: 3.0164722233086825]
	TIME [epoch: 8.13 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.625537193517213		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 6.625537193517213 | validation: 6.888503832638053]
	TIME [epoch: 8.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3060583834299875		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 5.3060583834299875 | validation: 3.696213376190066]
	TIME [epoch: 8.09 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.851399701314985		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 3.851399701314985 | validation: 3.5992172781908485]
	TIME [epoch: 8.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514059401657092		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 4.514059401657092 | validation: 4.624220665965365]
	TIME [epoch: 8.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.147189366674292		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 4.147189366674292 | validation: 3.0603793171134743]
	TIME [epoch: 8.12 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231882962231833		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 3.231882962231833 | validation: 5.027087300484338]
	TIME [epoch: 8.12 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.425944270725364		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 3.425944270725364 | validation: 3.5885034316098623]
	TIME [epoch: 8.08 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.062865264653285		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 3.062865264653285 | validation: 4.337632659539371]
	TIME [epoch: 8.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5866087224094536		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 3.5866087224094536 | validation: 4.610920898837431]
	TIME [epoch: 8.09 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.888449026340341		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 3.888449026340341 | validation: 2.574190161809641]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.486461980739652		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 3.486461980739652 | validation: 3.677061482056253]
	TIME [epoch: 8.15 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5200158106180477		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 3.5200158106180477 | validation: 2.5043069404603395]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.925598655448476		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 2.925598655448476 | validation: 3.2199515754767143]
	TIME [epoch: 8.09 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5526882046822115		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 3.5526882046822115 | validation: 3.469630506979922]
	TIME [epoch: 8.08 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2532424287844712		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 3.2532424287844712 | validation: 2.9843561925098587]
	TIME [epoch: 8.09 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8144490249940075		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 3.8144490249940075 | validation: 3.224974064496131]
	TIME [epoch: 8.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1389469965985732		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 3.1389469965985732 | validation: 3.44611459182722]
	TIME [epoch: 8.13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1149381990770566		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 3.1149381990770566 | validation: 2.563756483145319]
	TIME [epoch: 8.08 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2606719798674995		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 3.2606719798674995 | validation: 3.2296742502481957]
	TIME [epoch: 8.09 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.235950295776963		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 4.235950295776963 | validation: 2.7297659262571266]
	TIME [epoch: 8.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.163389572186759		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 7.163389572186759 | validation: 11.104713554375891]
	TIME [epoch: 8.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.638539699944575		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 9.638539699944575 | validation: 8.206783233266304]
	TIME [epoch: 8.12 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.625069007372531		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 6.625069007372531 | validation: 4.481781929169271]
	TIME [epoch: 8.12 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073012918029377		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 4.073012918029377 | validation: 3.773730822071014]
	TIME [epoch: 8.08 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6060185539450953		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 3.6060185539450953 | validation: 3.525827982740794]
	TIME [epoch: 8.09 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.819019964887918		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 3.819019964887918 | validation: 3.24440839537825]
	TIME [epoch: 8.09 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.071300184751955		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 3.071300184751955 | validation: 4.550222241330383]
	TIME [epoch: 8.08 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.87915434439549		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 4.87915434439549 | validation: 6.749191146380204]
	TIME [epoch: 8.14 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.328383795397147		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 6.328383795397147 | validation: 6.485546133351706]
	TIME [epoch: 8.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.719550415782377		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 4.719550415782377 | validation: 5.946575675611553]
	TIME [epoch: 8.08 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.549736111297168		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 5.549736111297168 | validation: 8.048212567076865]
	TIME [epoch: 8.09 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.423044840543978		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 8.423044840543978 | validation: 10.248709249674711]
	TIME [epoch: 8.08 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.353664694940187		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 9.353664694940187 | validation: 9.58063122848096]
	TIME [epoch: 8.09 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.425981692488499		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 8.425981692488499 | validation: 8.950968939422573]
	TIME [epoch: 8.12 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.33080697986487		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 7.33080697986487 | validation: 5.8532343136529565]
	TIME [epoch: 8.09 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.396749962714713		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 4.396749962714713 | validation: 3.9247971884499595]
	TIME [epoch: 8.09 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535403881597885		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 4.535403881597885 | validation: 4.379273936736838]
	TIME [epoch: 8.08 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.030076923420194		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 4.030076923420194 | validation: 3.6102980584745232]
	TIME [epoch: 8.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7021504511054375		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 3.7021504511054375 | validation: 4.776069929671225]
	TIME [epoch: 8.11 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1676915828763255		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 4.1676915828763255 | validation: 3.8085535311399576]
	TIME [epoch: 8.12 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.57747593761366		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 3.57747593761366 | validation: 3.724806104882415]
	TIME [epoch: 8.09 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.555812487428737		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 3.555812487428737 | validation: 5.221594769867499]
	TIME [epoch: 8.09 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.27902941744575		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 4.27902941744575 | validation: 4.521343397078182]
	TIME [epoch: 8.09 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.536915715179003		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 4.536915715179003 | validation: 3.514337589991973]
	TIME [epoch: 8.08 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6111097200105995		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 3.6111097200105995 | validation: 5.326402194968875]
	TIME [epoch: 8.13 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.070740477396631		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 7.070740477396631 | validation: 8.455025363754263]
	TIME [epoch: 8.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.362772212332732		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 9.362772212332732 | validation: 7.052401716228661]
	TIME [epoch: 8.09 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.389994144685715		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 6.389994144685715 | validation: 6.970459063103361]
	TIME [epoch: 8.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.174455439677464		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 8.174455439677464 | validation: 9.242877520771351]
	TIME [epoch: 8.08 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.365603415588856		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 7.365603415588856 | validation: 4.705843785918308]
	TIME [epoch: 8.09 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529805978849818		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 4.529805978849818 | validation: 6.748000964386993]
	TIME [epoch: 8.14 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.360117689782658		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 4.360117689782658 | validation: 4.097893595775261]
	TIME [epoch: 8.09 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569674258696498		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 3.569674258696498 | validation: 3.320966589481573]
	TIME [epoch: 8.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304808642081861		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 3.304808642081861 | validation: 3.7985675893880853]
	TIME [epoch: 8.08 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6002004914034025		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 3.6002004914034025 | validation: 3.1568819039921303]
	TIME [epoch: 8.09 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.285248323230685		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 3.285248323230685 | validation: 3.159415018995878]
	TIME [epoch: 8.09 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.504548371952988		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 3.504548371952988 | validation: 3.2376645016645753]
	TIME [epoch: 8.13 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243171221152466		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 4.243171221152466 | validation: 4.422880116850363]
	TIME [epoch: 8.09 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297920324783575		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 3.297920324783575 | validation: 3.290148896264485]
	TIME [epoch: 8.09 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2052730650995995		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 3.2052730650995995 | validation: 2.5868792525146116]
	TIME [epoch: 8.09 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7283684015822547		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 2.7283684015822547 | validation: 2.632148387195555]
	TIME [epoch: 8.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7421751216509573		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 2.7421751216509573 | validation: 4.842319450845052]
	TIME [epoch: 8.13 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.693687954369473		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 3.693687954369473 | validation: 3.744730366005217]
	TIME [epoch: 8.11 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9151584160375794		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 2.9151584160375794 | validation: 2.8432633755431205]
	TIME [epoch: 8.09 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8264625464239823		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 2.8264625464239823 | validation: 4.0539045974219965]
	TIME [epoch: 8.09 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0541452968460057		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 3.0541452968460057 | validation: 2.5518299816180674]
	TIME [epoch: 8.08 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2142213285533665		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 3.2142213285533665 | validation: 2.9593164623815307]
	TIME [epoch: 8.09 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0717233234474692		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 3.0717233234474692 | validation: 3.4116740606455775]
	TIME [epoch: 8.12 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0610740006346564		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 3.0610740006346564 | validation: 3.3182017575323117]
	TIME [epoch: 8.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.846339727210579		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 2.846339727210579 | validation: 2.967294742454307]
	TIME [epoch: 8.08 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91913076479482		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 2.91913076479482 | validation: 3.5564986578032487]
	TIME [epoch: 8.09 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.108221809653321		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 3.108221809653321 | validation: 3.282833845058419]
	TIME [epoch: 8.09 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9411428798668586		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 2.9411428798668586 | validation: 2.591378529375011]
	TIME [epoch: 8.09 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.995950521950823		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 2.995950521950823 | validation: 2.990220195884603]
	TIME [epoch: 8.12 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.051409904445152		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 3.051409904445152 | validation: 3.541922730611211]
	TIME [epoch: 8.08 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9500419167810947		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 2.9500419167810947 | validation: 3.0313570730271833]
	TIME [epoch: 8.09 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7129711500751093		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 2.7129711500751093 | validation: 4.219879037094637]
	TIME [epoch: 8.08 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0502431750861554		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 3.0502431750861554 | validation: 3.0251169533639164]
	TIME [epoch: 8.09 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.033950359941902		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 3.033950359941902 | validation: 4.067095718277724]
	TIME [epoch: 8.11 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938651377313263		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 2.938651377313263 | validation: 3.20751903819515]
	TIME [epoch: 8.13 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6575912122976715		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 2.6575912122976715 | validation: 2.2564739420896123]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.929348804967975		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 3.929348804967975 | validation: 4.109146028820267]
	TIME [epoch: 8.09 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4151810156633484		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 3.4151810156633484 | validation: 3.0759432317582043]
	TIME [epoch: 8.07 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.311768807046655		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 3.311768807046655 | validation: 2.9350821170101]
	TIME [epoch: 8.08 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6228933937527024		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 2.6228933937527024 | validation: 2.652226754266394]
	TIME [epoch: 8.12 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0479889033914715		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 3.0479889033914715 | validation: 3.6726104192157116]
	TIME [epoch: 8.09 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1176467101053307		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 3.1176467101053307 | validation: 2.4234271247618944]
	TIME [epoch: 8.08 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1348446610767833		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 3.1348446610767833 | validation: 2.7108735579096503]
	TIME [epoch: 8.08 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8192337494543174		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 2.8192337494543174 | validation: 2.4953316141768127]
	TIME [epoch: 8.08 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.508593594923892		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 2.508593594923892 | validation: 3.109836669959945]
	TIME [epoch: 8.08 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7135148596475895		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 2.7135148596475895 | validation: 3.4083293280148297]
	TIME [epoch: 8.12 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.162045678127433		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 3.162045678127433 | validation: 2.955765290660736]
	TIME [epoch: 8.09 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879244560293082		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 2.879244560293082 | validation: 2.9778594187966956]
	TIME [epoch: 8.08 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7543718235733676		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 2.7543718235733676 | validation: 2.490896031224513]
	TIME [epoch: 8.09 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6130013370293517		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 2.6130013370293517 | validation: 2.3950436003386266]
	TIME [epoch: 8.08 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5274297607666742		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 2.5274297607666742 | validation: 3.0759010600512906]
	TIME [epoch: 8.11 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6144229224475195		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 2.6144229224475195 | validation: 2.7720412165156216]
	TIME [epoch: 8.11 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.682928448863156		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 2.682928448863156 | validation: 2.531696647427288]
	TIME [epoch: 8.09 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841884702505282		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 2.841884702505282 | validation: 3.66759154522945]
	TIME [epoch: 8.08 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64649648856658		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 2.64649648856658 | validation: 2.3963979236418815]
	TIME [epoch: 8.08 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6308347153215523		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 2.6308347153215523 | validation: 3.582498650650809]
	TIME [epoch: 8.08 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.964470401236524		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 2.964470401236524 | validation: 2.845491321202911]
	TIME [epoch: 8.13 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.660913981020921		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 2.660913981020921 | validation: 4.557889341446796]
	TIME [epoch: 8.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91697973338543		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 2.91697973338543 | validation: 2.333304898670815]
	TIME [epoch: 8.09 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386719794145637		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 2.386719794145637 | validation: 3.0147304291787527]
	TIME [epoch: 8.09 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1622932944571516		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 3.1622932944571516 | validation: 3.0651711272368685]
	TIME [epoch: 8.09 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3861762168505294		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 2.3861762168505294 | validation: 2.6663371397684523]
	TIME [epoch: 8.09 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3449263426275877		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 2.3449263426275877 | validation: 3.3270581938018866]
	TIME [epoch: 8.13 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6755616028890166		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 2.6755616028890166 | validation: 2.3611689055559744]
	TIME [epoch: 8.09 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258787454856968		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 2.258787454856968 | validation: 2.4081565276953336]
	TIME [epoch: 8.08 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677712968386817		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 2.6677712968386817 | validation: 2.3061950566685194]
	TIME [epoch: 8.08 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2257550510543496		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 2.2257550510543496 | validation: 2.3309502746040756]
	TIME [epoch: 8.08 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6454861482569547		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 2.6454861482569547 | validation: 3.780291189749894]
	TIME [epoch: 8.09 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7942567980534525		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 2.7942567980534525 | validation: 2.5473883003718876]
	TIME [epoch: 8.12 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2961690455658497		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 2.2961690455658497 | validation: 2.6227126764326036]
	TIME [epoch: 8.08 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142003807820098		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 2.142003807820098 | validation: 2.210348883927962]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.477760902578543		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 2.477760902578543 | validation: 4.681244028512905]
	TIME [epoch: 8.08 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.132453063524956		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 3.132453063524956 | validation: 2.7953939573600595]
	TIME [epoch: 8.08 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5395742917026194		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 2.5395742917026194 | validation: 3.359953233790027]
	TIME [epoch: 8.11 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.919615703919169		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 2.919615703919169 | validation: 2.4544744241824117]
	TIME [epoch: 8.11 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6691407558595714		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 2.6691407558595714 | validation: 2.707583628569375]
	TIME [epoch: 8.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64217317351199		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 2.64217317351199 | validation: 2.527574450039781]
	TIME [epoch: 8.08 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60946364969229		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 2.60946364969229 | validation: 2.4099453949540095]
	TIME [epoch: 8.09 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37510274031719		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 2.37510274031719 | validation: 2.2399339603949198]
	TIME [epoch: 8.08 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6585154418965136		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 2.6585154418965136 | validation: 2.7232362257137126]
	TIME [epoch: 8.12 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.746884363795677		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 2.746884363795677 | validation: 3.195402088669885]
	TIME [epoch: 8.09 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.825673944622782		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 2.825673944622782 | validation: 2.6187179329771766]
	TIME [epoch: 8.09 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.709501072671099		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 2.709501072671099 | validation: 2.539866130730799]
	TIME [epoch: 8.07 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.501766226181214		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 2.501766226181214 | validation: 2.523506460147061]
	TIME [epoch: 8.09 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2970938083232744		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 3.2970938083232744 | validation: 3.330854513766165]
	TIME [epoch: 8.09 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2041240292209165		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 3.2041240292209165 | validation: 3.2058938124457]
	TIME [epoch: 8.13 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9398928671151205		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 2.9398928671151205 | validation: 2.4375194262419324]
	TIME [epoch: 112 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393114553257521		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 2.393114553257521 | validation: 2.1454731209792355]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320585820582567		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 2.320585820582567 | validation: 3.626515152312006]
	TIME [epoch: 16 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5001508813086915		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 2.5001508813086915 | validation: 2.180347783939]
	TIME [epoch: 16 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129550503649212		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 2.129550503649212 | validation: 3.194769915977796]
	TIME [epoch: 16 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.681620060054703		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 2.681620060054703 | validation: 2.188895076961071]
	TIME [epoch: 15.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4883704763381638		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 2.4883704763381638 | validation: 2.763242446867457]
	TIME [epoch: 16 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8396417593865095		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 3.8396417593865095 | validation: 7.047725572170439]
	TIME [epoch: 16 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.238364458235984		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 5.238364458235984 | validation: 3.1623438967557136]
	TIME [epoch: 15.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5759316201546953		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 3.5759316201546953 | validation: 2.9861818337951624]
	TIME [epoch: 15.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9350193377897433		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 2.9350193377897433 | validation: 3.0786025854092887]
	TIME [epoch: 16 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8323367598677036		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 2.8323367598677036 | validation: 2.5016888272213382]
	TIME [epoch: 16 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.406610187564944		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 2.406610187564944 | validation: 2.888629202692849]
	TIME [epoch: 16 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5236847318076543		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 2.5236847318076543 | validation: 3.374951024824093]
	TIME [epoch: 16 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879045436992438		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 2.879045436992438 | validation: 2.1223172850356766]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317866673666451		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 2.317866673666451 | validation: 3.314487837747848]
	TIME [epoch: 16 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9587769182515222		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 2.9587769182515222 | validation: 3.708349798411853]
	TIME [epoch: 16 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7047908080813974		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 2.7047908080813974 | validation: 2.9476081382239006]
	TIME [epoch: 16 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.448779074721107		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 2.448779074721107 | validation: 2.3482720735650604]
	TIME [epoch: 16 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.774677916909785		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 2.774677916909785 | validation: 2.1400271615993276]
	TIME [epoch: 16 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6819420418265527		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 2.6819420418265527 | validation: 2.3780946886827365]
	TIME [epoch: 16 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621587230096261		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 2.621587230096261 | validation: 2.6839352059679404]
	TIME [epoch: 16 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.412530622547018		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 2.412530622547018 | validation: 2.7328445218134982]
	TIME [epoch: 16 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416425149784034		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 2.416425149784034 | validation: 2.361497382127848]
	TIME [epoch: 16 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072521526733035		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 2.072521526733035 | validation: 2.903334558519376]
	TIME [epoch: 16 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6418418096740504		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 2.6418418096740504 | validation: 2.801690339783113]
	TIME [epoch: 16 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3088571244133385		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 2.3088571244133385 | validation: 2.363674098080816]
	TIME [epoch: 16 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3141128157858875		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 2.3141128157858875 | validation: 2.6091473257391566]
	TIME [epoch: 16 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523854077848695		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 2.523854077848695 | validation: 2.056203519609019]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.413570629026169		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 2.413570629026169 | validation: 2.3991925845577935]
	TIME [epoch: 15.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.523520553089642		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 3.523520553089642 | validation: 3.124171558166066]
	TIME [epoch: 15.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5931402722728274		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 2.5931402722728274 | validation: 2.907768934013649]
	TIME [epoch: 16 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6056130676565323		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 2.6056130676565323 | validation: 2.186976465385529]
	TIME [epoch: 15.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4494504570953453		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 2.4494504570953453 | validation: 2.467324633917765]
	TIME [epoch: 16 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8037319485772105		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 2.8037319485772105 | validation: 2.1939354676350025]
	TIME [epoch: 16 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.522567717933718		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 2.522567717933718 | validation: 4.309796944919226]
	TIME [epoch: 15.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9892129823590365		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 3.9892129823590365 | validation: 3.080792459678765]
	TIME [epoch: 16 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87885873000232		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 2.87885873000232 | validation: 2.3174357034523494]
	TIME [epoch: 16 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4614431480277394		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 2.4614431480277394 | validation: 3.359203053615535]
	TIME [epoch: 16 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.626122637024561		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 2.626122637024561 | validation: 2.1548954240597147]
	TIME [epoch: 16 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362846532338236		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 2.362846532338236 | validation: 2.0784822994706387]
	TIME [epoch: 16 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512080992525767		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 2.512080992525767 | validation: 2.7207691977433885]
	TIME [epoch: 16 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5079143014163265		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 2.5079143014163265 | validation: 2.2628517658212455]
	TIME [epoch: 16 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.599936836311185		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 2.599936836311185 | validation: 2.024152995200884]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.259349877183895		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 2.259349877183895 | validation: 3.4521776706545335]
	TIME [epoch: 16 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.69958054318342		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 2.69958054318342 | validation: 2.384750193820679]
	TIME [epoch: 16 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0045405408343995		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 2.0045405408343995 | validation: 2.7015407232509205]
	TIME [epoch: 16 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.018921222604053		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 3.018921222604053 | validation: 2.1360132974899497]
	TIME [epoch: 16 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596033719262197		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 2.0596033719262197 | validation: 3.407377336592231]
	TIME [epoch: 16 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9615010846317684		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 2.9615010846317684 | validation: 2.626926120344728]
	TIME [epoch: 16 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061359643355717		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 2.061359643355717 | validation: 2.911547749989899]
	TIME [epoch: 16 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484174129933258		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 2.484174129933258 | validation: 1.7311959758930118]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0965419343140397		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 2.0965419343140397 | validation: 2.8841277574784208]
	TIME [epoch: 16 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8653175013170267		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 2.8653175013170267 | validation: 2.703081328667504]
	TIME [epoch: 16 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.20262924253227		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 2.20262924253227 | validation: 2.1879292813502627]
	TIME [epoch: 16 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1668058411180056		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 2.1668058411180056 | validation: 3.1266381020776106]
	TIME [epoch: 16 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.427915889915279		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 2.427915889915279 | validation: 2.1050194959950694]
	TIME [epoch: 15.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8974262506491009		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.8974262506491009 | validation: 1.86681697631625]
	TIME [epoch: 16 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.632783890510511		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 2.632783890510511 | validation: 2.0408549797472344]
	TIME [epoch: 16 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2695617795209477		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 2.2695617795209477 | validation: 2.2490593583381973]
	TIME [epoch: 16 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.600231695609968		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 2.600231695609968 | validation: 2.105386486307027]
	TIME [epoch: 16 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273708916363393		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 2.273708916363393 | validation: 2.5970081790409427]
	TIME [epoch: 16 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.017669159246728		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 2.017669159246728 | validation: 1.5800303265908138]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1605194347608685		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 2.1605194347608685 | validation: 2.03739014193824]
	TIME [epoch: 16 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8480002813165541		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 1.8480002813165541 | validation: 1.7503744931466587]
	TIME [epoch: 16 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795479144891903		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 2.795479144891903 | validation: 2.9937502723376865]
	TIME [epoch: 16 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4866801365881157		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 2.4866801365881157 | validation: 2.1854600562862214]
	TIME [epoch: 16 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344312686743886		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 2.344312686743886 | validation: 1.6306605642194478]
	TIME [epoch: 16 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1643248775507633		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 2.1643248775507633 | validation: 2.8511702162821337]
	TIME [epoch: 15.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.127538641917962		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 2.127538641917962 | validation: 2.3367242828327037]
	TIME [epoch: 16 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45068589698691		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 2.45068589698691 | validation: 2.100659341971135]
	TIME [epoch: 16 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.676443845578723		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 2.676443845578723 | validation: 3.7057718249619507]
	TIME [epoch: 15.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.727240866568584		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 2.727240866568584 | validation: 2.12383323299944]
	TIME [epoch: 16 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.725519827955434		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 2.725519827955434 | validation: 2.1046247248765746]
	TIME [epoch: 16 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.765684466974151		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 2.765684466974151 | validation: 2.8076177370988575]
	TIME [epoch: 15.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2994944638413095		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 2.2994944638413095 | validation: 2.4011721546483753]
	TIME [epoch: 16 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.174733264147034		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 2.174733264147034 | validation: 3.9080176019404416]
	TIME [epoch: 16 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418245773255895		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 2.418245773255895 | validation: 2.4332004709649335]
	TIME [epoch: 16 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5030959966620303		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 2.5030959966620303 | validation: 1.902008849005444]
	TIME [epoch: 16 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.954276973038263		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 5.954276973038263 | validation: 3.8573089855607456]
	TIME [epoch: 16 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2456184303720508		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 3.2456184303720508 | validation: 3.6574096721660547]
	TIME [epoch: 15.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368365835788304		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 2.368365835788304 | validation: 5.116858711244415]
	TIME [epoch: 16 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4401636956108588		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 3.4401636956108588 | validation: 4.464560317377958]
	TIME [epoch: 16 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9957011196166192		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 2.9957011196166192 | validation: 2.2072969906305095]
	TIME [epoch: 15.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.50794611097988		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 3.50794611097988 | validation: 8.115429699427564]
	TIME [epoch: 16 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.986837033051793		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 7.986837033051793 | validation: 6.828958132541232]
	TIME [epoch: 16 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.470861985935074		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 5.470861985935074 | validation: 2.4224009968625295]
	TIME [epoch: 16 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.712961170422807		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 2.712961170422807 | validation: 2.6174994058918326]
	TIME [epoch: 16 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4358904653054654		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 2.4358904653054654 | validation: 3.594903464612491]
	TIME [epoch: 16 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6536188598801838		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 2.6536188598801838 | validation: 1.8249939707368312]
	TIME [epoch: 16 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0025258937869634		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 2.0025258937869634 | validation: 2.216696943007641]
	TIME [epoch: 16 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9673868789896258		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 1.9673868789896258 | validation: 2.3041613930717766]
	TIME [epoch: 16 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9919773192060533		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 1.9919773192060533 | validation: 2.020202220836181]
	TIME [epoch: 16 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794117626821951		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 1.794117626821951 | validation: 2.7888733370460703]
	TIME [epoch: 16 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.031961711054868		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 2.031961711054868 | validation: 2.281156616850584]
	TIME [epoch: 16 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3448079047546897		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 2.3448079047546897 | validation: 2.064191945123306]
	TIME [epoch: 16 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239054509166402		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 2.239054509166402 | validation: 2.88075036182724]
	TIME [epoch: 16 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424828303805687		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 2.424828303805687 | validation: 2.030728556121535]
	TIME [epoch: 16 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8832735914283893		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 1.8832735914283893 | validation: 1.5677086304490166]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.971040694446601		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 2.971040694446601 | validation: 2.303790555223971]
	TIME [epoch: 16 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1268382341105116		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 3.1268382341105116 | validation: 2.130572281718181]
	TIME [epoch: 16 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7913113225738484		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 2.7913113225738484 | validation: 3.004753491366622]
	TIME [epoch: 16 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6680760613128096		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 2.6680760613128096 | validation: 3.5627604191639497]
	TIME [epoch: 16 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.426026476354943		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 5.426026476354943 | validation: 5.2654896914659055]
	TIME [epoch: 16 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.936995642879598		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 5.936995642879598 | validation: 6.374631478257143]
	TIME [epoch: 16 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.946771259635273		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 3.946771259635273 | validation: 4.375270250009524]
	TIME [epoch: 16 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8738472147557497		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 2.8738472147557497 | validation: 2.510777150988443]
	TIME [epoch: 16 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133282441434877		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 2.133282441434877 | validation: 3.6490875435674965]
	TIME [epoch: 16 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380301846168454		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 2.380301846168454 | validation: 2.7611766608479154]
	TIME [epoch: 16 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5148291720776137		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 3.5148291720776137 | validation: 2.3866159649832293]
	TIME [epoch: 16 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2778241574745515		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 2.2778241574745515 | validation: 1.8171182513502986]
	TIME [epoch: 16 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6189668482355453		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 2.6189668482355453 | validation: 1.8105834352231498]
	TIME [epoch: 16 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1845266690213117		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 2.1845266690213117 | validation: 2.5683961095283596]
	TIME [epoch: 16 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065933703501016		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 2.065933703501016 | validation: 1.9048394861812126]
	TIME [epoch: 15.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9374525189039242		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 1.9374525189039242 | validation: 3.083452013710689]
	TIME [epoch: 16 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.029042628341771		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 2.029042628341771 | validation: 1.9565979530991955]
	TIME [epoch: 16 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068397708501108		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 2.068397708501108 | validation: 2.110821878315722]
	TIME [epoch: 16 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.615174049512519		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 2.615174049512519 | validation: 3.5396376317672633]
	TIME [epoch: 16 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4746046173814737		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 2.4746046173814737 | validation: 1.9335842284064788]
	TIME [epoch: 16 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148906528203035		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 2.148906528203035 | validation: 1.617121035590567]
	TIME [epoch: 16 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046908266174005		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 2.046908266174005 | validation: 2.6809397759511677]
	TIME [epoch: 16 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053981788962254		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 2.053981788962254 | validation: 2.0572135771990316]
	TIME [epoch: 16 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418255582425531		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 2.418255582425531 | validation: 2.6654410397183836]
	TIME [epoch: 16 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26193951468164		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 2.26193951468164 | validation: 2.1180208783972665]
	TIME [epoch: 16 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.157279665812707		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 2.157279665812707 | validation: 1.5319144269160598]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.753341172070116		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 2.753341172070116 | validation: 2.1348748520289558]
	TIME [epoch: 16 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309046387330069		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 2.309046387330069 | validation: 2.4594007847392145]
	TIME [epoch: 16 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227443379393443		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 2.227443379393443 | validation: 2.274059830339819]
	TIME [epoch: 16 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4477660611980525		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 2.4477660611980525 | validation: 1.9255682656975552]
	TIME [epoch: 16 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.795909784978754		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 1.795909784978754 | validation: 1.793823285793822]
	TIME [epoch: 16 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1580273865000725		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 2.1580273865000725 | validation: 1.5097986059361617]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8065562692941037		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 1.8065562692941037 | validation: 2.365060328307189]
	TIME [epoch: 15.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9692465797670526		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 1.9692465797670526 | validation: 1.4981897156943618]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124881644167989		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 2.124881644167989 | validation: 4.251876385158345]
	TIME [epoch: 16 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9003448966091643		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 2.9003448966091643 | validation: 2.512216290747431]
	TIME [epoch: 15.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030756986552129		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 2.030756986552129 | validation: 1.4468991758280132]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6852061964402074		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 1.6852061964402074 | validation: 2.9959623087974467]
	TIME [epoch: 16 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9149285596524606		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 1.9149285596524606 | validation: 2.2524603282690974]
	TIME [epoch: 15.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2658866948801704		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 2.2658866948801704 | validation: 1.5835990463258076]
	TIME [epoch: 16 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2836870704700094		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 2.2836870704700094 | validation: 2.2835294011568035]
	TIME [epoch: 15.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.419226864553659		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 2.419226864553659 | validation: 1.8048587694948344]
	TIME [epoch: 16 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.592067476278205		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 2.592067476278205 | validation: 1.7242929129786984]
	TIME [epoch: 16 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8693823911317824		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 1.8693823911317824 | validation: 1.8998506153743404]
	TIME [epoch: 16 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9078801443151918		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 1.9078801443151918 | validation: 1.6160411699296464]
	TIME [epoch: 16 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6270641781660802		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 1.6270641781660802 | validation: 1.1968135096182362]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4410516975954604		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 1.4410516975954604 | validation: 2.246594437718092]
	TIME [epoch: 16 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0923603111711633		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 2.0923603111711633 | validation: 2.400314674494236]
	TIME [epoch: 16 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2348449433890845		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 2.2348449433890845 | validation: 1.498000352831341]
	TIME [epoch: 16 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397388246058115		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 2.397388246058115 | validation: 2.821276613226324]
	TIME [epoch: 15.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.881811153355099		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 1.881811153355099 | validation: 2.270039994643003]
	TIME [epoch: 16 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.240132051816369		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 2.240132051816369 | validation: 2.733786389285479]
	TIME [epoch: 16.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9283071547030624		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 1.9283071547030624 | validation: 1.5980626049675744]
	TIME [epoch: 16 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5112226707623568		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 1.5112226707623568 | validation: 0.8974028462944939]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4961345201024852		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 1.4961345201024852 | validation: 2.2637183855671266]
	TIME [epoch: 16 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6398286739387276		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 1.6398286739387276 | validation: 1.5713118885022115]
	TIME [epoch: 16 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.632423945016281		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 1.632423945016281 | validation: 1.96151306201182]
	TIME [epoch: 16 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6922794417036784		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 1.6922794417036784 | validation: 1.4539348269106616]
	TIME [epoch: 16 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4911026439017727		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 1.4911026439017727 | validation: 1.6346340635506813]
	TIME [epoch: 15.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.570968806407284		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 1.570968806407284 | validation: 1.223513174524598]
	TIME [epoch: 15.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.530157200837369		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 1.530157200837369 | validation: 1.6436964268166938]
	TIME [epoch: 16 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5613614221298007		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 1.5613614221298007 | validation: 1.651538818187234]
	TIME [epoch: 15.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3721233010024911		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 1.3721233010024911 | validation: 1.3030224972802946]
	TIME [epoch: 15.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.905591140244024		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 1.905591140244024 | validation: 2.8504891669719026]
	TIME [epoch: 16 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0519614477252097		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 3.0519614477252097 | validation: 2.4366217934800014]
	TIME [epoch: 15.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8319382318411401		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 1.8319382318411401 | validation: 1.8352338823317944]
	TIME [epoch: 16 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8858123083759208		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 1.8858123083759208 | validation: 1.65235418476286]
	TIME [epoch: 16 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6005421084407816		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 1.6005421084407816 | validation: 1.4654958429936844]
	TIME [epoch: 16 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5460757765504045		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 1.5460757765504045 | validation: 1.9738736200455436]
	TIME [epoch: 15.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918730867706703		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 1.918730867706703 | validation: 3.0154321887950504]
	TIME [epoch: 16 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399153604697913		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 2.399153604697913 | validation: 2.4012464777058016]
	TIME [epoch: 16 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9833877851591866		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 1.9833877851591866 | validation: 1.8244039475321192]
	TIME [epoch: 16 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6418943220450657		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 1.6418943220450657 | validation: 1.6665624185884418]
	TIME [epoch: 16 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6184189057563356		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 1.6184189057563356 | validation: 1.463153513644134]
	TIME [epoch: 16 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6778107137003857		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 1.6778107137003857 | validation: 2.8822347756566256]
	TIME [epoch: 16 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099989115780566		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 2.099989115780566 | validation: 1.6927779031818528]
	TIME [epoch: 16 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6810336975189368		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 1.6810336975189368 | validation: 1.3713807178336839]
	TIME [epoch: 16 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3959400275635971		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 1.3959400275635971 | validation: 1.2252232395665614]
	TIME [epoch: 16 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8482659494237947		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 1.8482659494237947 | validation: 8.274429574258164]
	TIME [epoch: 16 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.777534221739127		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 5.777534221739127 | validation: 4.025799406330212]
	TIME [epoch: 16 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.86727089629044		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 2.86727089629044 | validation: 2.708308799031107]
	TIME [epoch: 15.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091407172429455		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 2.091407172429455 | validation: 1.774179006861325]
	TIME [epoch: 16 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6585707589180645		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 1.6585707589180645 | validation: 1.3756099326129563]
	TIME [epoch: 16 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.641666825894347		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 1.641666825894347 | validation: 2.984359508195806]
	TIME [epoch: 16 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3081284205971904		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 2.3081284205971904 | validation: 1.9096431783674976]
	TIME [epoch: 16 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7424283610689657		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 1.7424283610689657 | validation: 1.9134901295464757]
	TIME [epoch: 16 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7014562298409424		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 1.7014562298409424 | validation: 1.8729261920256954]
	TIME [epoch: 16 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7153683360088356		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 1.7153683360088356 | validation: 1.6589739919533182]
	TIME [epoch: 16 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6653750071865219		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 1.6653750071865219 | validation: 1.7117388910741254]
	TIME [epoch: 16 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7158218426020875		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 1.7158218426020875 | validation: 1.4698639589473497]
	TIME [epoch: 16 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6564386171287717		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 1.6564386171287717 | validation: 1.4960314097517762]
	TIME [epoch: 16 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4931025352530742		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 1.4931025352530742 | validation: 1.6069307129319865]
	TIME [epoch: 15.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6943499771122592		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 1.6943499771122592 | validation: 1.1239250413197523]
	TIME [epoch: 16 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2927986453066567		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 1.2927986453066567 | validation: 0.9459978469569723]
	TIME [epoch: 16 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6552995260670431		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 1.6552995260670431 | validation: 1.066303267936585]
	TIME [epoch: 15.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3945429041511932		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 1.3945429041511932 | validation: 2.381199644374243]
	TIME [epoch: 16 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095238086691175		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 2.095238086691175 | validation: 1.0661742232136886]
	TIME [epoch: 16 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3894847527684244		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 2.3894847527684244 | validation: 2.026659385866619]
	TIME [epoch: 16 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2135710623593017		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 2.2135710623593017 | validation: 3.027695698008518]
	TIME [epoch: 16 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9817523113488709		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 1.9817523113488709 | validation: 1.2713429646272103]
	TIME [epoch: 16 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6909060224071941		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 1.6909060224071941 | validation: 1.6268255388830015]
	TIME [epoch: 15.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7561313519891226		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 1.7561313519891226 | validation: 2.299407503243747]
	TIME [epoch: 15.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309106231425133		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.7309106231425133 | validation: 1.8651111933350646]
	TIME [epoch: 16 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0063988961749453		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 2.0063988961749453 | validation: 1.5402537483596284]
	TIME [epoch: 15.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1284808428810162		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 2.1284808428810162 | validation: 2.2362891305836854]
	TIME [epoch: 15.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.168744497808294		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 4.168744497808294 | validation: 3.250041248166302]
	TIME [epoch: 16 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8727840508115086		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 2.8727840508115086 | validation: 2.815646539162125]
	TIME [epoch: 15.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4748312053117107		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 2.4748312053117107 | validation: 1.7032498144377346]
	TIME [epoch: 16 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.652196816237926		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 1.652196816237926 | validation: 1.8772031077835507]
	TIME [epoch: 16 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.944271675179197		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 1.944271675179197 | validation: 1.4355877494497769]
	TIME [epoch: 15.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4616523802176777		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 1.4616523802176777 | validation: 3.1184130490196384]
	TIME [epoch: 15.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8624755853634403		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 1.8624755853634403 | validation: 0.9449261086157958]
	TIME [epoch: 16 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7764281008562608		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 1.7764281008562608 | validation: 1.302481902478089]
	TIME [epoch: 16 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6445513998589285		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 1.6445513998589285 | validation: 1.1559953841715558]
	TIME [epoch: 16 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249487237437955		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 2.249487237437955 | validation: 2.6724550985817612]
	TIME [epoch: 16 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9490686732543578		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 1.9490686732543578 | validation: 1.5152058926518799]
	TIME [epoch: 15.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3928873647595512		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 1.3928873647595512 | validation: 1.0902819042349057]
	TIME [epoch: 16 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.431471882255829		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 1.431471882255829 | validation: 1.4752756999032888]
	TIME [epoch: 16 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6120128365193436		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 1.6120128365193436 | validation: 1.564338748231236]
	TIME [epoch: 15.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4480853330597405		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 1.4480853330597405 | validation: 1.0655222803234374]
	TIME [epoch: 16 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3835095530360788		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 1.3835095530360788 | validation: 1.1113614702169183]
	TIME [epoch: 16 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4401598388314132		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 1.4401598388314132 | validation: 1.0629902178089359]
	TIME [epoch: 15.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.577348044255141		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 1.577348044255141 | validation: 1.8185853652790729]
	TIME [epoch: 16 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3829268294421047		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 1.3829268294421047 | validation: 1.2717012366152831]
	TIME [epoch: 16 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1877351400862235		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 1.1877351400862235 | validation: 1.8491219499861367]
	TIME [epoch: 15.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8073831261784554		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 1.8073831261784554 | validation: 1.3287551621554987]
	TIME [epoch: 16 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1845942694513714		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 1.1845942694513714 | validation: 1.7126813515293553]
	TIME [epoch: 16 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5385380810891103		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 1.5385380810891103 | validation: 1.2196611888839137]
	TIME [epoch: 15.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2223425549659903		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 1.2223425549659903 | validation: 1.499442559434033]
	TIME [epoch: 16 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3345440500264045		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 1.3345440500264045 | validation: 0.9274251461149365]
	TIME [epoch: 16 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0780093564291287		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 1.0780093564291287 | validation: 1.4519647274077594]
	TIME [epoch: 16 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3385550625027431		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 1.3385550625027431 | validation: 1.5552805231878666]
	TIME [epoch: 16 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5838306801703625		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 1.5838306801703625 | validation: 2.261848994753123]
	TIME [epoch: 16 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8370068292995425		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 1.8370068292995425 | validation: 1.6080004920789628]
	TIME [epoch: 15.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7261521951154417		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 1.7261521951154417 | validation: 1.0364187962988707]
	TIME [epoch: 16 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3869496142379734		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 1.3869496142379734 | validation: 1.0961731596302644]
	TIME [epoch: 16 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1434155716388048		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 1.1434155716388048 | validation: 2.962714432555606]
	TIME [epoch: 15.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2290532501170897		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 2.2290532501170897 | validation: 1.2122064180689498]
	TIME [epoch: 16 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2753932713887508		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 1.2753932713887508 | validation: 0.9480527198472208]
	TIME [epoch: 16 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1049726660640167		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 1.1049726660640167 | validation: 1.2901771585895476]
	TIME [epoch: 15.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2855061342165768		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 1.2855061342165768 | validation: 1.0065153190604577]
	TIME [epoch: 16 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1551809337585723		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 1.1551809337585723 | validation: 1.5226013192147159]
	TIME [epoch: 16 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2773331156994208		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 1.2773331156994208 | validation: 1.6415465789943045]
	TIME [epoch: 16 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6273572931434719		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 1.6273572931434719 | validation: 1.2937480203305882]
	TIME [epoch: 16 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5849797041099456		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 1.5849797041099456 | validation: 1.7494317597575586]
	TIME [epoch: 16 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5777783986865208		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 1.5777783986865208 | validation: 1.6959023900577486]
	TIME [epoch: 15.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.365470885793564		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 1.365470885793564 | validation: 1.4460403537306519]
	TIME [epoch: 16 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.375768412143959		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 1.375768412143959 | validation: 1.2356003536855986]
	TIME [epoch: 16 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4645813298186754		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 1.4645813298186754 | validation: 1.0057350569270458]
	TIME [epoch: 16 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4917165363841676		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 1.4917165363841676 | validation: 0.8250719396425623]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1058434507022092		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 1.1058434507022092 | validation: 0.8523562725019196]
	TIME [epoch: 16 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084548974843216		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 1.084548974843216 | validation: 0.9014337561216954]
	TIME [epoch: 15.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096627087954323		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 1.096627087954323 | validation: 0.9284158162697069]
	TIME [epoch: 16 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2343524835479174		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 1.2343524835479174 | validation: 1.4576533392959636]
	TIME [epoch: 15.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0936571396257886		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 1.0936571396257886 | validation: 0.9994526726984451]
	TIME [epoch: 15.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1743803494838043		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 1.1743803494838043 | validation: 1.0977788399154575]
	TIME [epoch: 16 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2588918561875877		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 1.2588918561875877 | validation: 1.3380732039765668]
	TIME [epoch: 16 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.358013414946765		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 1.358013414946765 | validation: 1.688952399914168]
	TIME [epoch: 15.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4302587899317076		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 1.4302587899317076 | validation: 1.485150730706099]
	TIME [epoch: 16 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3026715285223252		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 1.3026715285223252 | validation: 1.384999553990974]
	TIME [epoch: 15.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1648558969178748		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 1.1648558969178748 | validation: 1.2054371080573638]
	TIME [epoch: 15.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609852881478914		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 1.0609852881478914 | validation: 1.1537641347820142]
	TIME [epoch: 16 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0464434768138229		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 1.0464434768138229 | validation: 1.2254617032019182]
	TIME [epoch: 15.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5296933183082961		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 1.5296933183082961 | validation: 1.5044399515949591]
	TIME [epoch: 15.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3408527985160419		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 1.3408527985160419 | validation: 0.8761115603100413]
	TIME [epoch: 16 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0906047373246373		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 1.0906047373246373 | validation: 2.0038689621342685]
	TIME [epoch: 16 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3678749590624653		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 1.3678749590624653 | validation: 1.3888041322179312]
	TIME [epoch: 15.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6586357303075203		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 1.6586357303075203 | validation: 1.8163405697760762]
	TIME [epoch: 16 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4571702826586086		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 1.4571702826586086 | validation: 1.3403490089914016]
	TIME [epoch: 15.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3770311681620184		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 1.3770311681620184 | validation: 1.2012183272868981]
	TIME [epoch: 15.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4406569292052838		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 1.4406569292052838 | validation: 1.8998520805906511]
	TIME [epoch: 16 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2435027091800799		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 1.2435027091800799 | validation: 1.8265623628544094]
	TIME [epoch: 16 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2243674398347455		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 1.2243674398347455 | validation: 1.255788702629176]
	TIME [epoch: 15.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3637076120859335		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 1.3637076120859335 | validation: 1.1844216227041753]
	TIME [epoch: 16 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244595286631242		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 1.244595286631242 | validation: 1.5005135444671138]
	TIME [epoch: 15.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076894790883391		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 1.076894790883391 | validation: 0.8799333716452471]
	TIME [epoch: 16 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164872722755368		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 1.164872722755368 | validation: 1.8926002910763926]
	TIME [epoch: 16 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2898559827801264		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 1.2898559827801264 | validation: 1.6086557470573362]
	TIME [epoch: 15.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3566827875188356		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 1.3566827875188356 | validation: 1.0677200078426772]
	TIME [epoch: 15.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2337482522761385		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 1.2337482522761385 | validation: 0.6873251524177304]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280904133557287		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 1.0280904133557287 | validation: 1.8567129162849425]
	TIME [epoch: 16 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43905949076932		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 1.43905949076932 | validation: 0.8260175016001421]
	TIME [epoch: 15.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276465089260199		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 1.276465089260199 | validation: 0.8052344091876865]
	TIME [epoch: 16 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1958250039847291		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 1.1958250039847291 | validation: 0.8349934046049352]
	TIME [epoch: 15.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2750199553049997		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 1.2750199553049997 | validation: 1.1358342751509305]
	TIME [epoch: 15.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6263603404671851		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 1.6263603404671851 | validation: 1.5431223691088916]
	TIME [epoch: 16 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5802514456294015		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 1.5802514456294015 | validation: 1.1778791035321818]
	TIME [epoch: 15.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2455517350912229		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 1.2455517350912229 | validation: 1.0468360569895583]
	TIME [epoch: 15.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1833576959286025		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 1.1833576959286025 | validation: 1.4224801130925497]
	TIME [epoch: 16 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982993592181696		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 1.0982993592181696 | validation: 1.3487640396043497]
	TIME [epoch: 15.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374836099169925		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 1.1374836099169925 | validation: 1.1868032097474672]
	TIME [epoch: 15.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2259242709461862		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 1.2259242709461862 | validation: 0.6906015922711515]
	TIME [epoch: 16 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794508336716212		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.9794508336716212 | validation: 0.8068785814781709]
	TIME [epoch: 15.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9509847859927627		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.9509847859927627 | validation: 1.0687277581399603]
	TIME [epoch: 15.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478422615317336		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 1.1478422615317336 | validation: 1.1909826713373892]
	TIME [epoch: 16 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8963721018719842		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.8963721018719842 | validation: 1.3383142712956686]
	TIME [epoch: 16 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3174828045480287		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 1.3174828045480287 | validation: 1.3690640302583517]
	TIME [epoch: 15.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577733875105815		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 1.0577733875105815 | validation: 1.5575153758646407]
	TIME [epoch: 16 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1886938636897326		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 1.1886938636897326 | validation: 0.7871303846679669]
	TIME [epoch: 15.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9672108075353201		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.9672108075353201 | validation: 1.1775838829479972]
	TIME [epoch: 15.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2343153068813035		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 1.2343153068813035 | validation: 0.7779185556085904]
	TIME [epoch: 16 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329319810796686		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 1.2329319810796686 | validation: 1.4804354651495246]
	TIME [epoch: 131 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1910551300179781		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 1.1910551300179781 | validation: 1.0927505963269557]
	TIME [epoch: 34.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1200829991571046		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 1.1200829991571046 | validation: 1.1769406541274257]
	TIME [epoch: 34.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2314767575191954		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 1.2314767575191954 | validation: 1.190196687406491]
	TIME [epoch: 34.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3047150894229333		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 1.3047150894229333 | validation: 1.2361388882019098]
	TIME [epoch: 34.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2706950880105987		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 1.2706950880105987 | validation: 1.0670596971262585]
	TIME [epoch: 34.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8852057027916828		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.8852057027916828 | validation: 2.0595229098192815]
	TIME [epoch: 34.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3340931793439137		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 1.3340931793439137 | validation: 1.4904497307458895]
	TIME [epoch: 34.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3997282374493745		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 1.3997282374493745 | validation: 0.705209253883163]
	TIME [epoch: 34.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390195480628142		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 1.0390195480628142 | validation: 1.2410703233380032]
	TIME [epoch: 34.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0697683081979152		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 1.0697683081979152 | validation: 1.0297633217667248]
	TIME [epoch: 34.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552583409381475		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 1.0552583409381475 | validation: 0.8002946619906688]
	TIME [epoch: 34.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616520816828108		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 1.0616520816828108 | validation: 1.3045971764987971]
	TIME [epoch: 34.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4254227349975466		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 1.4254227349975466 | validation: 0.7976407706237312]
	TIME [epoch: 34.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103397987594363		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 1.103397987594363 | validation: 0.687237435459535]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2986929648754209		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 1.2986929648754209 | validation: 1.4999806961939477]
	TIME [epoch: 34.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1586280792427412		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 1.1586280792427412 | validation: 0.9400386077671061]
	TIME [epoch: 34.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8342576553655294		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.8342576553655294 | validation: 0.8713880425834031]
	TIME [epoch: 34.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13746672144865		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 1.13746672144865 | validation: 0.8928073559650911]
	TIME [epoch: 34.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2172839489226002		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 1.2172839489226002 | validation: 0.8659575760288334]
	TIME [epoch: 34.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9340409489458597		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.9340409489458597 | validation: 0.7747716775113249]
	TIME [epoch: 34.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462107618059633		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.8462107618059633 | validation: 1.4939845301813048]
	TIME [epoch: 34.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691507262704076		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 1.0691507262704076 | validation: 1.2283445674805162]
	TIME [epoch: 34.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3150725217053814		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 1.3150725217053814 | validation: 2.699734077158519]
	TIME [epoch: 34.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8083265580724386		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 1.8083265580724386 | validation: 1.0438591880845913]
	TIME [epoch: 34.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0615518333170504		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 1.0615518333170504 | validation: 1.087967227844647]
	TIME [epoch: 34.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009830322025439		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 1.009830322025439 | validation: 1.6357974929898091]
	TIME [epoch: 34.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240183343211666		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 1.240183343211666 | validation: 0.8745133488161845]
	TIME [epoch: 34.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9820615050570282		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.9820615050570282 | validation: 0.6954994863577917]
	TIME [epoch: 34.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9161119513022611		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.9161119513022611 | validation: 0.8509234375511856]
	TIME [epoch: 34.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547780773145852		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.8547780773145852 | validation: 0.9493303622328801]
	TIME [epoch: 34.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9625987149484712		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.9625987149484712 | validation: 1.052111633891296]
	TIME [epoch: 34.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404239067101418		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 1.1404239067101418 | validation: 0.613255016957833]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878995571727968		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.9878995571727968 | validation: 0.8298506202932044]
	TIME [epoch: 34.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792798628820634		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.7792798628820634 | validation: 0.8555278006819446]
	TIME [epoch: 34.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8914937596051553		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.8914937596051553 | validation: 0.43444562851754104]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0498366167622812		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 1.0498366167622812 | validation: 1.5789844644758775]
	TIME [epoch: 34.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284507394978255		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 2.284507394978255 | validation: 3.119393546458566]
	TIME [epoch: 34.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7625194282457914		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 1.7625194282457914 | validation: 1.425187963597732]
	TIME [epoch: 34.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8348308935154436		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 1.8348308935154436 | validation: 2.6415152836623683]
	TIME [epoch: 34.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1961287379147632		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 1.1961287379147632 | validation: 0.8278829679130915]
	TIME [epoch: 34.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0356973429252698		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 1.0356973429252698 | validation: 1.4195628342711535]
	TIME [epoch: 34.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307972111733005		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 1.2307972111733005 | validation: 0.8687220633891237]
	TIME [epoch: 34.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0167496610913798		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 1.0167496610913798 | validation: 1.022837384191573]
	TIME [epoch: 34.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9023719971878745		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.9023719971878745 | validation: 1.2794015257452642]
	TIME [epoch: 34.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3418110225830562		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 1.3418110225830562 | validation: 1.119858811301854]
	TIME [epoch: 34.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245017679244168		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 1.0245017679244168 | validation: 0.8781200267764471]
	TIME [epoch: 34.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236978317369774		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 1.0236978317369774 | validation: 0.7408848697984773]
	TIME [epoch: 34.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9290629821465788		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.9290629821465788 | validation: 0.7748035692330049]
	TIME [epoch: 34.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381892842057315		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 1.1381892842057315 | validation: 0.7989713153712891]
	TIME [epoch: 34.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689018897281532		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.7689018897281532 | validation: 0.6937063772495207]
	TIME [epoch: 34.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8642914714986611		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.8642914714986611 | validation: 1.0692001309619181]
	TIME [epoch: 34.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4230670953734914		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 1.4230670953734914 | validation: 1.191517870338732]
	TIME [epoch: 34.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8792731225878814		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.8792731225878814 | validation: 1.130331597356034]
	TIME [epoch: 34.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837859953386949		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 1.1837859953386949 | validation: 0.7821633885437517]
	TIME [epoch: 34.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9311426383313551		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.9311426383313551 | validation: 0.7158639897964112]
	TIME [epoch: 34.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8252469994185525		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.8252469994185525 | validation: 0.7640874890588427]
	TIME [epoch: 34.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333558924386859		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.8333558924386859 | validation: 0.648437076895448]
	TIME [epoch: 34.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547403556515129		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.7547403556515129 | validation: 0.9240110217389592]
	TIME [epoch: 34.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1592810538865663		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 1.1592810538865663 | validation: 1.1376574507465227]
	TIME [epoch: 34.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292124367037656		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.9292124367037656 | validation: 0.8104694487086909]
	TIME [epoch: 34.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9527404360080594		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.9527404360080594 | validation: 2.6656036013847246]
	TIME [epoch: 34.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7011256823415155		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 1.7011256823415155 | validation: 0.9838659954274689]
	TIME [epoch: 34.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1209972286698964		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 1.1209972286698964 | validation: 2.359220176828876]
	TIME [epoch: 34.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3541067733631311		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 1.3541067733631311 | validation: 2.972903503357585]
	TIME [epoch: 34.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8665742371832321		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 1.8665742371832321 | validation: 1.4881663007064452]
	TIME [epoch: 34.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852037954628156		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 1.1852037954628156 | validation: 1.486342397808051]
	TIME [epoch: 34.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086545441933095		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 1.086545441933095 | validation: 0.8845372149052471]
	TIME [epoch: 34.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8693173353470327		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.8693173353470327 | validation: 1.522553802442472]
	TIME [epoch: 34.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9454383983920077		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.9454383983920077 | validation: 0.8173488924288169]
	TIME [epoch: 34.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8670940327657346		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.8670940327657346 | validation: 0.5282798600444056]
	TIME [epoch: 34.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8853204566617272		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.8853204566617272 | validation: 0.7489958223245237]
	TIME [epoch: 34.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.895705088130088		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.895705088130088 | validation: 0.6288485993266917]
	TIME [epoch: 34.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0396980971409964		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 1.0396980971409964 | validation: 1.8264892423876367]
	TIME [epoch: 34.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0762843525027794		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 1.0762843525027794 | validation: 1.3485872365143248]
	TIME [epoch: 34.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9554268641569279		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.9554268641569279 | validation: 1.0339628797217641]
	TIME [epoch: 34.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9420938202178426		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.9420938202178426 | validation: 1.110786125125784]
	TIME [epoch: 34.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9098514441847309		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.9098514441847309 | validation: 0.7922078619764699]
	TIME [epoch: 34.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582925769762123		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.7582925769762123 | validation: 1.1290073781155219]
	TIME [epoch: 34.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2651784830441293		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 1.2651784830441293 | validation: 0.7347059384706889]
	TIME [epoch: 34.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9813304567436241		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.9813304567436241 | validation: 0.6909511773519657]
	TIME [epoch: 34.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8127886069447471		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.8127886069447471 | validation: 0.6764424723759718]
	TIME [epoch: 34.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9802309732423238		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.9802309732423238 | validation: 0.7114830326040873]
	TIME [epoch: 34.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1307568955181249		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 1.1307568955181249 | validation: 1.3144295557359986]
	TIME [epoch: 34.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0085007494520213		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 1.0085007494520213 | validation: 0.9614797555042955]
	TIME [epoch: 34.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9651537897629132		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.9651537897629132 | validation: 1.2850396160553965]
	TIME [epoch: 34.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9144903935055957		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.9144903935055957 | validation: 0.8308024206737945]
	TIME [epoch: 34.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9024971118694682		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.9024971118694682 | validation: 1.046094957934221]
	TIME [epoch: 34.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9280978684039077		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.9280978684039077 | validation: 1.2639781799160748]
	TIME [epoch: 34.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1785023397426535		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 1.1785023397426535 | validation: 0.6777709159736548]
	TIME [epoch: 34.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7980992607675104		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.7980992607675104 | validation: 0.636508833942681]
	TIME [epoch: 34.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7893124206186288		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.7893124206186288 | validation: 0.8729323756472944]
	TIME [epoch: 34.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8335032529557254		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.8335032529557254 | validation: 1.0552752225646713]
	TIME [epoch: 34.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619296426976029		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.8619296426976029 | validation: 0.4908638768960357]
	TIME [epoch: 34.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9626070997815395		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.9626070997815395 | validation: 0.7536756828264932]
	TIME [epoch: 34.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.754160777989212		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.754160777989212 | validation: 1.5174671014646395]
	TIME [epoch: 34.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.289369889913296		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 1.289369889913296 | validation: 0.9440266040057295]
	TIME [epoch: 34.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1065402541982785		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 1.1065402541982785 | validation: 0.6015628966465756]
	TIME [epoch: 34.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9157665766980256		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.9157665766980256 | validation: 0.9656916823693827]
	TIME [epoch: 34.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.124917160387356		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 1.124917160387356 | validation: 1.279007960244467]
	TIME [epoch: 34.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0962544593760848		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 1.0962544593760848 | validation: 2.8006146344929066]
	TIME [epoch: 34.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2667485724766077		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 2.2667485724766077 | validation: 2.262228434863644]
	TIME [epoch: 34.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4332203335750853		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 1.4332203335750853 | validation: 0.9877133972905121]
	TIME [epoch: 34.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8765950905672544		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.8765950905672544 | validation: 0.844205754664839]
	TIME [epoch: 34.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9169490864838856		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.9169490864838856 | validation: 0.8330886233091476]
	TIME [epoch: 34.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8398499413370097		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.8398499413370097 | validation: 1.017351907685295]
	TIME [epoch: 34.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1214498740560628		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 1.1214498740560628 | validation: 1.0140028973864712]
	TIME [epoch: 34.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9702269782844979		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.9702269782844979 | validation: 0.7091658220434148]
	TIME [epoch: 34.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877297222155458		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 1.0877297222155458 | validation: 2.127021003315861]
	TIME [epoch: 34.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.46463834520373		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 1.46463834520373 | validation: 2.6676062241386544]
	TIME [epoch: 34.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9748300914298833		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 1.9748300914298833 | validation: 1.5329405402803582]
	TIME [epoch: 34.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499020204355874		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 1.1499020204355874 | validation: 1.8806374061128985]
	TIME [epoch: 34.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4221765404587687		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 1.4221765404587687 | validation: 1.1367143988451143]
	TIME [epoch: 34.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9964089913862297		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.9964089913862297 | validation: 0.7886368237922425]
	TIME [epoch: 34.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8529689805619043		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 1.8529689805619043 | validation: 1.3644725870965426]
	TIME [epoch: 34.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2262341257455112		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 1.2262341257455112 | validation: 1.378645363823273]
	TIME [epoch: 34.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388850237687893		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 1.1388850237687893 | validation: 0.6634929479432314]
	TIME [epoch: 34.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838509249347008		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.9838509249347008 | validation: 1.3284936753655434]
	TIME [epoch: 34.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413405862809163		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 1.1413405862809163 | validation: 0.961325463526615]
	TIME [epoch: 34.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542122831395309		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.9542122831395309 | validation: 0.9745137684551552]
	TIME [epoch: 34.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1772989476202855		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 1.1772989476202855 | validation: 1.0027457681782546]
	TIME [epoch: 34.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0096292838970047		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 1.0096292838970047 | validation: 1.2863324311246687]
	TIME [epoch: 34.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453827980322894		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 1.2453827980322894 | validation: 1.038074007366355]
	TIME [epoch: 34.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9298440330804254		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.9298440330804254 | validation: 0.9278497188276515]
	TIME [epoch: 34.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029959761750132		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 1.029959761750132 | validation: 1.3570028583930247]
	TIME [epoch: 34.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9004858372389418		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.9004858372389418 | validation: 0.6095418928618588]
	TIME [epoch: 34.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421681316128503		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.8421681316128503 | validation: 0.7031202849497891]
	TIME [epoch: 34.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8418659452294863		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.8418659452294863 | validation: 0.9132324433776028]
	TIME [epoch: 34.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833492130594013		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.8833492130594013 | validation: 1.0018718111780203]
	TIME [epoch: 34.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143504408207021		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.8143504408207021 | validation: 0.7688178355462598]
	TIME [epoch: 34.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625658976249698		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.7625658976249698 | validation: 1.1130442390862652]
	TIME [epoch: 34.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956995577210834		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.7956995577210834 | validation: 0.8166214577577853]
	TIME [epoch: 34.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1543378340809003		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 1.1543378340809003 | validation: 0.7591269243709935]
	TIME [epoch: 34.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1141582125113851		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 1.1141582125113851 | validation: 0.7979456729238403]
	TIME [epoch: 34.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453411258654677		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.7453411258654677 | validation: 0.5957809990297156]
	TIME [epoch: 34.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8117698261739082		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.8117698261739082 | validation: 1.2846482925882388]
	TIME [epoch: 34.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0422094205597885		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 1.0422094205597885 | validation: 1.6122655966608201]
	TIME [epoch: 34.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0978798385547173		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 1.0978798385547173 | validation: 0.7374110183312796]
	TIME [epoch: 34.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7445256858862475		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.7445256858862475 | validation: 1.2913638818400508]
	TIME [epoch: 34.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8426215571762421		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.8426215571762421 | validation: 0.8731404164602818]
	TIME [epoch: 34.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641935967252363		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.641935967252363 | validation: 2.5002646434616675]
	TIME [epoch: 34.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4851939238387053		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 1.4851939238387053 | validation: 1.1945437601263675]
	TIME [epoch: 34.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293264715313097		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 1.0293264715313097 | validation: 1.602032607995088]
	TIME [epoch: 34.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052475923594077		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 1.052475923594077 | validation: 0.734411547104724]
	TIME [epoch: 34.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8209034506836553		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.8209034506836553 | validation: 1.1546148679242716]
	TIME [epoch: 34.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563059948082281		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.7563059948082281 | validation: 0.975060123874802]
	TIME [epoch: 34.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8869934221276958		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.8869934221276958 | validation: 1.027442962640274]
	TIME [epoch: 34.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9345641763636974		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.9345641763636974 | validation: 1.164125421882356]
	TIME [epoch: 34.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700864510244676		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.7700864510244676 | validation: 1.3748267822289209]
	TIME [epoch: 34.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985740535608965		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 1.0985740535608965 | validation: 0.5491836024228121]
	TIME [epoch: 34.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9558245999676638		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.9558245999676638 | validation: 0.4985018290172903]
	TIME [epoch: 34.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8357308376711986		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.8357308376711986 | validation: 0.5463683859106783]
	TIME [epoch: 34.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8724805264748358		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.8724805264748358 | validation: 0.730843501851393]
	TIME [epoch: 34.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862046753620406		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.862046753620406 | validation: 0.7056833985853793]
	TIME [epoch: 34.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838179742474478		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.7838179742474478 | validation: 1.3656597112840427]
	TIME [epoch: 34.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9002438268943219		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.9002438268943219 | validation: 1.2368702195966328]
	TIME [epoch: 34.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7718161969524174		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.7718161969524174 | validation: 0.6764717544664196]
	TIME [epoch: 34.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7643396564383267		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.7643396564383267 | validation: 0.7308457537782721]
	TIME [epoch: 34.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024973928410283		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.7024973928410283 | validation: 0.6634976664069387]
	TIME [epoch: 34.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7538443266070896		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.7538443266070896 | validation: 0.8370501849488532]
	TIME [epoch: 34.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347566651363725		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.7347566651363725 | validation: 0.7172633433514016]
	TIME [epoch: 34.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963858620069357		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.7963858620069357 | validation: 0.37410747924506854]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706704852245226		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.6706704852245226 | validation: 1.234328364639349]
	TIME [epoch: 34.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9352118943254073		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.9352118943254073 | validation: 0.7279602195598371]
	TIME [epoch: 34.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9116906018763933		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.9116906018763933 | validation: 0.4939890307194962]
	TIME [epoch: 34.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738524454723601		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.738524454723601 | validation: 1.181350037705223]
	TIME [epoch: 34.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517127538501448		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.7517127538501448 | validation: 0.5949558676031071]
	TIME [epoch: 34.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851011139984526		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.8851011139984526 | validation: 1.0710185622008614]
	TIME [epoch: 34.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0911195180459372		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 1.0911195180459372 | validation: 0.7468272809132653]
	TIME [epoch: 34.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036395235173873		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.7036395235173873 | validation: 0.5253440921645762]
	TIME [epoch: 34.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8909198082956808		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.8909198082956808 | validation: 1.164170698898248]
	TIME [epoch: 34.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2168639689169547		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 1.2168639689169547 | validation: 1.345208942701562]
	TIME [epoch: 34.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8974470218617956		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.8974470218617956 | validation: 0.6664498575846074]
	TIME [epoch: 34.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885008904872028		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.7885008904872028 | validation: 0.6813035821551388]
	TIME [epoch: 34.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7721763517551279		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.7721763517551279 | validation: 1.1045710044074573]
	TIME [epoch: 34.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8645784759036009		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.8645784759036009 | validation: 0.48894503325792515]
	TIME [epoch: 34.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9362340128464078		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.9362340128464078 | validation: 0.4854298792593438]
	TIME [epoch: 34.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075725232625653		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 1.075725232625653 | validation: 1.0586331103415723]
	TIME [epoch: 34.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9795522450607004		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.9795522450607004 | validation: 0.7373680531163742]
	TIME [epoch: 34.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105922003022021		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.8105922003022021 | validation: 0.394213377671667]
	TIME [epoch: 34.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7536348497107404		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.7536348497107404 | validation: 0.9650782769477882]
	TIME [epoch: 34.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9119229004897318		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.9119229004897318 | validation: 0.5488656925396325]
	TIME [epoch: 34.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8112451121139808		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.8112451121139808 | validation: 1.819658349203114]
	TIME [epoch: 34.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9242305440221423		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.9242305440221423 | validation: 0.6630126095602624]
	TIME [epoch: 34.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825994866963538		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.6825994866963538 | validation: 1.12559812504136]
	TIME [epoch: 34.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187025587575935		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.7187025587575935 | validation: 0.8507702983970284]
	TIME [epoch: 34.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9774058353991073		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.9774058353991073 | validation: 0.4765930334123619]
	TIME [epoch: 34.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879394523942651		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.5879394523942651 | validation: 1.0841048129431319]
	TIME [epoch: 34.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7942254978828917		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.7942254978828917 | validation: 0.3741047288535434]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661896641127855		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.6661896641127855 | validation: 0.49744105832242524]
	TIME [epoch: 34.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8608921764359543		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.8608921764359543 | validation: 0.9844921929157266]
	TIME [epoch: 34.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9462501797772817		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.9462501797772817 | validation: 0.9840407565344536]
	TIME [epoch: 34.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8910358658929385		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.8910358658929385 | validation: 0.7249018853478789]
	TIME [epoch: 34.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693537176282447		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.6693537176282447 | validation: 0.8445830408251838]
	TIME [epoch: 34.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.632861100193735		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.632861100193735 | validation: 0.3763719541900294]
	TIME [epoch: 34.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7999624131095624		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.7999624131095624 | validation: 0.5548009219397716]
	TIME [epoch: 34.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8567502711304832		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.8567502711304832 | validation: 0.4775955721959295]
	TIME [epoch: 34.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6527207560814019		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.6527207560814019 | validation: 0.6289635076447374]
	TIME [epoch: 34.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875972435590122		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.5875972435590122 | validation: 0.7333650419389529]
	TIME [epoch: 34.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779341804881116		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.6779341804881116 | validation: 0.6455270051367274]
	TIME [epoch: 34.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761639401807937		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.8761639401807937 | validation: 2.237221421257984]
	TIME [epoch: 34.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0979823489451666		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 1.0979823489451666 | validation: 0.5756759397171075]
	TIME [epoch: 34.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325226794511672		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.7325226794511672 | validation: 0.5230043712318959]
	TIME [epoch: 34.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243761567177198		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.7243761567177198 | validation: 0.5390506922329419]
	TIME [epoch: 34.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.562976835459831		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.562976835459831 | validation: 0.7323888646302631]
	TIME [epoch: 34.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077281833284432		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.8077281833284432 | validation: 0.8863086979759623]
	TIME [epoch: 34.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8479555058439957		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.8479555058439957 | validation: 0.4695527202780655]
	TIME [epoch: 34.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472798180276913		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.6472798180276913 | validation: 0.945758972754376]
	TIME [epoch: 34.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915766397651157		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.6915766397651157 | validation: 0.48962412095902286]
	TIME [epoch: 34.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441079354084721		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.5441079354084721 | validation: 1.0409303744655802]
	TIME [epoch: 34.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033834073174086		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.7033834073174086 | validation: 1.5466013909176919]
	TIME [epoch: 34.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8981001366912348		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.8981001366912348 | validation: 0.9168084986838427]
	TIME [epoch: 34.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9025151297973343		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.9025151297973343 | validation: 0.5607869296435897]
	TIME [epoch: 34.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8718186430885608		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.8718186430885608 | validation: 0.6872807442145261]
	TIME [epoch: 34.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089322514064398		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.7089322514064398 | validation: 0.7257248505633342]
	TIME [epoch: 34.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0400310409654356		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 1.0400310409654356 | validation: 0.5299856657926892]
	TIME [epoch: 34.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757440125275026		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.7757440125275026 | validation: 0.6479295164819519]
	TIME [epoch: 34.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9205312758037998		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.9205312758037998 | validation: 0.5921591583969181]
	TIME [epoch: 34.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010676075903045		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.7010676075903045 | validation: 0.5195584363972165]
	TIME [epoch: 34.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056107475807729		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.8056107475807729 | validation: 0.9904399295217813]
	TIME [epoch: 34.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8029158898533133		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.8029158898533133 | validation: 0.9491504916664265]
	TIME [epoch: 34.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7598528772855354		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.7598528772855354 | validation: 0.8176238805850863]
	TIME [epoch: 34.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213444604617408		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.8213444604617408 | validation: 0.7332097081235766]
	TIME [epoch: 34.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7586407169392755		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.7586407169392755 | validation: 0.4875992712695537]
	TIME [epoch: 34.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011811295824278		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.6011811295824278 | validation: 0.9399451989569854]
	TIME [epoch: 34.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708736812963906		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.7708736812963906 | validation: 0.7239368500206663]
	TIME [epoch: 34.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978971785700068		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.6978971785700068 | validation: 0.7050991737491465]
	TIME [epoch: 34.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6241599607422651		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.6241599607422651 | validation: 0.4788414517903882]
	TIME [epoch: 34.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345423736568305		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.7345423736568305 | validation: 0.7301332466263204]
	TIME [epoch: 34.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480571914019121		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.6480571914019121 | validation: 0.7270013526769836]
	TIME [epoch: 34.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558784598009611		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.7558784598009611 | validation: 0.5520468331321349]
	TIME [epoch: 34.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6710522787410225		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.6710522787410225 | validation: 0.5451698995597227]
	TIME [epoch: 34.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669032317789788		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.5669032317789788 | validation: 0.733542047385402]
	TIME [epoch: 34.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333118453179402		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.7333118453179402 | validation: 1.073056226541805]
	TIME [epoch: 34.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7398622385795988		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.7398622385795988 | validation: 0.6115910594648201]
	TIME [epoch: 34.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909932535054644		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.5909932535054644 | validation: 1.212041728324957]
	TIME [epoch: 34.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760907938326086		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.8760907938326086 | validation: 0.4897454362239345]
	TIME [epoch: 34.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.643655942740805		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.643655942740805 | validation: 0.35852216783554663]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383207747179407		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.6383207747179407 | validation: 0.5981293840323791]
	TIME [epoch: 34.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2957342683187378		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 1.2957342683187378 | validation: 0.39059728709179187]
	TIME [epoch: 34.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066521003104222		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.6066521003104222 | validation: 0.5219594180910547]
	TIME [epoch: 34.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322694090521533		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.7322694090521533 | validation: 0.7522969310839702]
	TIME [epoch: 34.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300221235069726		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.7300221235069726 | validation: 0.5559689034296569]
	TIME [epoch: 34.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982265564608066		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.6982265564608066 | validation: 0.4044184918766205]
	TIME [epoch: 34.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313841291713631		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.6313841291713631 | validation: 0.4425202760593455]
	TIME [epoch: 34.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7946278861633614		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.7946278861633614 | validation: 0.4575439598875585]
	TIME [epoch: 34.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665193765142977		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.7665193765142977 | validation: 0.5777281517471948]
	TIME [epoch: 34.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261359397768489		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.6261359397768489 | validation: 1.360358801470419]
	TIME [epoch: 34.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839871795407262		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.6839871795407262 | validation: 0.8210587046122255]
	TIME [epoch: 34.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865216313811564		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.5865216313811564 | validation: 0.43237739678192644]
	TIME [epoch: 34.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461224947597084		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.6461224947597084 | validation: 0.5222137003468827]
	TIME [epoch: 34.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7703873930212711		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.7703873930212711 | validation: 0.8589369069635253]
	TIME [epoch: 34.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581793531999662		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.7581793531999662 | validation: 0.8402192263886714]
	TIME [epoch: 34.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591941071151829		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.7591941071151829 | validation: 1.9470579786490143]
	TIME [epoch: 34.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0489907092389086		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 1.0489907092389086 | validation: 0.667658371978946]
	TIME [epoch: 34.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084609724444366		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.7084609724444366 | validation: 0.8421829504581865]
	TIME [epoch: 34.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8525716431891499		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.8525716431891499 | validation: 0.6866511831870872]
	TIME [epoch: 34.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.809519927665165		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.809519927665165 | validation: 0.5501297869350597]
	TIME [epoch: 34.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929104312213348		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.6929104312213348 | validation: 0.5094789205873465]
	TIME [epoch: 34.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6932688142090031		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.6932688142090031 | validation: 1.0932044022452636]
	TIME [epoch: 34.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8559096072846921		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.8559096072846921 | validation: 0.5502255225769421]
	TIME [epoch: 34.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033588088801365		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.6033588088801365 | validation: 0.6149850312387146]
	TIME [epoch: 34.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092203625450518		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 1.092203625450518 | validation: 0.46586664703957786]
	TIME [epoch: 34.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8874211460787143		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.8874211460787143 | validation: 0.6469033225283921]
	TIME [epoch: 34.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8423014693727985		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.8423014693727985 | validation: 0.8566016349415485]
	TIME [epoch: 34.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625701940859186		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.7625701940859186 | validation: 0.5653889497715794]
	TIME [epoch: 34.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104418553988212		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.6104418553988212 | validation: 0.600372371151857]
	TIME [epoch: 34.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515763764612303		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.6515763764612303 | validation: 0.8959376255346605]
	TIME [epoch: 34.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555772042402584		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.6555772042402584 | validation: 1.0112327013155986]
	TIME [epoch: 34.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318738962907696		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.5318738962907696 | validation: 0.5774483104620406]
	TIME [epoch: 34.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8722104374389091		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.8722104374389091 | validation: 0.6701765735985175]
	TIME [epoch: 34.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8480813266963124		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.8480813266963124 | validation: 0.624597845402187]
	TIME [epoch: 34.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107559421626388		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.7107559421626388 | validation: 1.213951763702477]
	TIME [epoch: 34.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819002889729099		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.6819002889729099 | validation: 0.9541350042693213]
	TIME [epoch: 34.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750609494511491		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.7750609494511491 | validation: 0.44051496996287026]
	TIME [epoch: 34.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6659869977395596		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.6659869977395596 | validation: 1.2559845710050335]
	TIME [epoch: 34.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8877070266972156		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.8877070266972156 | validation: 0.9010681287812394]
	TIME [epoch: 34.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7452337521491944		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.7452337521491944 | validation: 0.7461476944350172]
	TIME [epoch: 34.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8809086324230847		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.8809086324230847 | validation: 0.8312219689376886]
	TIME [epoch: 34.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7839659160505791		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.7839659160505791 | validation: 2.0404288605154766]
	TIME [epoch: 34.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2845646027510011		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 1.2845646027510011 | validation: 1.0381608563641294]
	TIME [epoch: 34.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700381665251058		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.700381665251058 | validation: 0.7171533329813768]
	TIME [epoch: 34.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959947214435447		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.7959947214435447 | validation: 1.1430057807752285]
	TIME [epoch: 34.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808065137451433		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.8808065137451433 | validation: 1.1646228227668791]
	TIME [epoch: 34.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889564875187785		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.8889564875187785 | validation: 0.6088063290805676]
	TIME [epoch: 34.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6116611197621366		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.6116611197621366 | validation: 0.9567182305169648]
	TIME [epoch: 34.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562991328049897		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.7562991328049897 | validation: 0.7466469410055276]
	TIME [epoch: 34.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141295012994589		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.6141295012994589 | validation: 0.5444186519455068]
	TIME [epoch: 34.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994939488504202		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.6994939488504202 | validation: 0.6576043837649269]
	TIME [epoch: 34.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749771898568987		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.5749771898568987 | validation: 1.1236892175863271]
	TIME [epoch: 34.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798959740300758		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.6798959740300758 | validation: 1.7306844967823194]
	TIME [epoch: 34.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8731570506619414		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.8731570506619414 | validation: 1.319107023232974]
	TIME [epoch: 34.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752290518448034		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.8752290518448034 | validation: 0.6371716318730853]
	TIME [epoch: 34.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7637636940818973		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.7637636940818973 | validation: 0.9921786726321911]
	TIME [epoch: 34.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626083516513074		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.7626083516513074 | validation: 0.5680570979863335]
	TIME [epoch: 34.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7122264471598954		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.7122264471598954 | validation: 0.46645789342659927]
	TIME [epoch: 34.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7121736260918572		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.7121736260918572 | validation: 0.507949554940537]
	TIME [epoch: 34.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6764070598187173		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.6764070598187173 | validation: 0.7304268128577092]
	TIME [epoch: 34.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6690433576596292		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.6690433576596292 | validation: 0.6489378158164625]
	TIME [epoch: 34.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9735420351309821		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.9735420351309821 | validation: 0.575512634322136]
	TIME [epoch: 34.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283049298743183		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.6283049298743183 | validation: 0.48707711923734043]
	TIME [epoch: 34.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482485894574793		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.7482485894574793 | validation: 0.7424582574915779]
	TIME [epoch: 34.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6744026112273411		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.6744026112273411 | validation: 0.5486949047611474]
	TIME [epoch: 34.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938846152238915		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.5938846152238915 | validation: 0.5666112298227073]
	TIME [epoch: 34.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258552372271302		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.6258552372271302 | validation: 1.491639465597321]
	TIME [epoch: 34.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8255629604986136		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.8255629604986136 | validation: 0.5891385357040013]
	TIME [epoch: 34.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693762640677924		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.7693762640677924 | validation: 0.9171392657376964]
	TIME [epoch: 34.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6292739506131793		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.6292739506131793 | validation: 1.8816719980143026]
	TIME [epoch: 34.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3648362514038461		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 1.3648362514038461 | validation: 0.4910941530592705]
	TIME [epoch: 34.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155086508912434		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 1.155086508912434 | validation: 0.9228672657790356]
	TIME [epoch: 34.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611768983114387		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.8611768983114387 | validation: 1.018132973969581]
	TIME [epoch: 34.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563794886551853		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.6563794886551853 | validation: 0.7476120737218759]
	TIME [epoch: 34.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275805290370212		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.6275805290370212 | validation: 0.5486906725003322]
	TIME [epoch: 34.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013331713136582		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.7013331713136582 | validation: 0.9478841452648411]
	TIME [epoch: 34.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615373464344705		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.6615373464344705 | validation: 0.5984352491456468]
	TIME [epoch: 34.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709152371049073		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.6709152371049073 | validation: 0.5988681550972954]
	TIME [epoch: 34.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333392363573906		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.7333392363573906 | validation: 0.5721809253655042]
	TIME [epoch: 34.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179922138171142		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.6179922138171142 | validation: 0.7618463860649319]
	TIME [epoch: 34.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7812509137114896		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.7812509137114896 | validation: 0.6135984824770244]
	TIME [epoch: 34.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012576073563		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.6012576073563 | validation: 0.690214255632337]
	TIME [epoch: 34.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466587352993263		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.6466587352993263 | validation: 0.5609951447654316]
	TIME [epoch: 34.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032576638094662		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.6032576638094662 | validation: 0.9480335075432031]
	TIME [epoch: 34.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5725717851723718		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.5725717851723718 | validation: 0.7639034930284219]
	TIME [epoch: 34.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170981004429784		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.7170981004429784 | validation: 0.5331253881000764]
	TIME [epoch: 34.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6431324750555036		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.6431324750555036 | validation: 0.6075101626028578]
	TIME [epoch: 34.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805837237440436		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.7805837237440436 | validation: 0.7570783580182482]
	TIME [epoch: 34.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1216863020420198		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 1.1216863020420198 | validation: 0.9492053877516275]
	TIME [epoch: 34.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8359439277728652		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.8359439277728652 | validation: 0.7208036605038852]
	TIME [epoch: 34.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7505875295297564		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.7505875295297564 | validation: 1.6673019134737577]
	TIME [epoch: 34.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9132172597233199		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.9132172597233199 | validation: 0.7525576366252327]
	TIME [epoch: 34.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942151151361844		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.6942151151361844 | validation: 0.7876222290817803]
	TIME [epoch: 34.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442702413600639		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.5442702413600639 | validation: 0.48121175960736623]
	TIME [epoch: 34.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7987772619687827		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.7987772619687827 | validation: 0.6392009063534676]
	TIME [epoch: 34.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150579855983357		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 1.150579855983357 | validation: 0.9898325715901024]
	TIME [epoch: 34.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0562333511796527		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 1.0562333511796527 | validation: 1.009492407662016]
	TIME [epoch: 34.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9330855058841143		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.9330855058841143 | validation: 0.7377892667059962]
	TIME [epoch: 34.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605484192798795		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.5605484192798795 | validation: 0.9593275067292331]
	TIME [epoch: 34.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118481225260072		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.5118481225260072 | validation: 1.3192542329695505]
	TIME [epoch: 34.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694244718501623		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.694244718501623 | validation: 0.29849432481133864]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205105053090492		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.5205105053090492 | validation: 0.5346620795983024]
	TIME [epoch: 34.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236993300420405		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.5236993300420405 | validation: 0.5608182444477061]
	TIME [epoch: 34.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847883967217728		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.6847883967217728 | validation: 0.7186186113119764]
	TIME [epoch: 34.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126534271770011		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.6126534271770011 | validation: 0.7777831624119022]
	TIME [epoch: 34.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217692376171731		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.6217692376171731 | validation: 0.339925454285628]
	TIME [epoch: 34.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5523194413516417		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.5523194413516417 | validation: 0.7265797673093088]
	TIME [epoch: 34.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894054573965923		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.5894054573965923 | validation: 0.6773935480576313]
	TIME [epoch: 34.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5274032828080562		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.5274032828080562 | validation: 0.4095954189034732]
	TIME [epoch: 34.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7516483518936364		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.7516483518936364 | validation: 0.5488162110718053]
	TIME [epoch: 34.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548127882323085		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.6548127882323085 | validation: 0.6957524224138043]
	TIME [epoch: 34.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624298025610808		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.624298025610808 | validation: 0.7267773919535958]
	TIME [epoch: 34.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270763148456651		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.6270763148456651 | validation: 0.736272349590319]
	TIME [epoch: 34.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6712199677951163		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.6712199677951163 | validation: 0.7211240076218747]
	TIME [epoch: 34.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337682841191566		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.6337682841191566 | validation: 0.6856341197054144]
	TIME [epoch: 34.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582580944122743		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.582580944122743 | validation: 0.5137507384124373]
	TIME [epoch: 34.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316993709773414		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.5316993709773414 | validation: 0.6362773116049854]
	TIME [epoch: 34.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827342034511729		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.6827342034511729 | validation: 0.702608437004105]
	TIME [epoch: 34.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619040248715218		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.619040248715218 | validation: 0.4830822562083992]
	TIME [epoch: 34.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4870426110997135		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.4870426110997135 | validation: 0.5599167465004957]
	TIME [epoch: 34.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469970603494052		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.5469970603494052 | validation: 0.32002395901837566]
	TIME [epoch: 34.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200464815859481		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.5200464815859481 | validation: 0.4478998471939818]
	TIME [epoch: 34.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349393922330211		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.5349393922330211 | validation: 0.6565287615719342]
	TIME [epoch: 34.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792517094235037		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.6792517094235037 | validation: 0.9313249371772268]
	TIME [epoch: 34.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339436756504436		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.7339436756504436 | validation: 0.6365855810287233]
	TIME [epoch: 34.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016985270534355		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.5016985270534355 | validation: 0.594373125340369]
	TIME [epoch: 34.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458219118972685		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.5458219118972685 | validation: 0.709009783032944]
	TIME [epoch: 34.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730144452469899		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.730144452469899 | validation: 1.097798135792737]
	TIME [epoch: 34.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.602011871244087		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.602011871244087 | validation: 1.1209380854758688]
	TIME [epoch: 34.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.87975463994346		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.87975463994346 | validation: 0.6624932175956807]
	TIME [epoch: 34.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559871742422503		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.559871742422503 | validation: 0.691181190733396]
	TIME [epoch: 34.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5152696602901348		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.5152696602901348 | validation: 0.6173070678517285]
	TIME [epoch: 34.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.870331535011356		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.870331535011356 | validation: 0.5743649162363637]
	TIME [epoch: 34.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177120643176343		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.8177120643176343 | validation: 0.5981744086339619]
	TIME [epoch: 34.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122423739737689		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.6122423739737689 | validation: 0.64102243046586]
	TIME [epoch: 34.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633773778341862		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.4633773778341862 | validation: 0.8436086490855272]
	TIME [epoch: 34.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8674718610629806		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.8674718610629806 | validation: 0.5853601047401789]
	TIME [epoch: 34.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154688029923617		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.6154688029923617 | validation: 0.5342139479370926]
	TIME [epoch: 34.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181347073064031		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.5181347073064031 | validation: 0.8317574239344427]
	TIME [epoch: 34.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6431804920598703		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.6431804920598703 | validation: 0.910282097556832]
	TIME [epoch: 34.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5610122283347307		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.5610122283347307 | validation: 0.43208007406381993]
	TIME [epoch: 34.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48545688628916134		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.48545688628916134 | validation: 0.49028707933026194]
	TIME [epoch: 34.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143393843216682		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.8143393843216682 | validation: 0.8205459461493427]
	TIME [epoch: 34.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6531695916637902		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.6531695916637902 | validation: 0.6739714267535075]
	TIME [epoch: 34.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435642899848259		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.4435642899848259 | validation: 2.0903363059092066]
	TIME [epoch: 34.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9817113972316303		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.9817113972316303 | validation: 0.4554795801277459]
	TIME [epoch: 34.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49165508969487404		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.49165508969487404 | validation: 0.4810887211289213]
	TIME [epoch: 34.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141472119191233		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.4141472119191233 | validation: 0.5442458968926365]
	TIME [epoch: 34.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381145195249996		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.5381145195249996 | validation: 0.3638758539817148]
	TIME [epoch: 34.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40913837749922644		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.40913837749922644 | validation: 0.48283786005183327]
	TIME [epoch: 34.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382404889562774		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.5382404889562774 | validation: 0.8752053453422934]
	TIME [epoch: 34.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660078934490886		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.5660078934490886 | validation: 0.6642425034399073]
	TIME [epoch: 34.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352745297562087		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.4352745297562087 | validation: 0.4048440868083008]
	TIME [epoch: 34.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5555694890001577		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.5555694890001577 | validation: 0.5891746886740811]
	TIME [epoch: 34.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688046281106936		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.688046281106936 | validation: 0.9006255566238114]
	TIME [epoch: 34.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9450560838743438		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.9450560838743438 | validation: 1.0049588641540255]
	TIME [epoch: 34.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9842908718012942		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.9842908718012942 | validation: 0.8854857426621121]
	TIME [epoch: 34.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8731323177622501		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.8731323177622501 | validation: 0.5953168700637299]
	TIME [epoch: 34.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579132309442431		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.6579132309442431 | validation: 1.313254936077885]
	TIME [epoch: 34.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285365017214416		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.7285365017214416 | validation: 0.45638113162223876]
	TIME [epoch: 34.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5522549540218699		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.5522549540218699 | validation: 0.32311341787831993]
	TIME [epoch: 34.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6302170680305005		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.6302170680305005 | validation: 0.5888141342714992]
	TIME [epoch: 34.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014947876869217		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.5014947876869217 | validation: 0.652037433447938]
	TIME [epoch: 34.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974401456354421		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.5974401456354421 | validation: 0.6279633090234636]
	TIME [epoch: 34.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955927457408177		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.4955927457408177 | validation: 0.3979221958401842]
	TIME [epoch: 34.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535557765783509		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.535557765783509 | validation: 0.4990187526288928]
	TIME [epoch: 34.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341546254672521		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.5341546254672521 | validation: 0.6870037028433302]
	TIME [epoch: 34.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349056379426624		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.5349056379426624 | validation: 0.4715268652073071]
	TIME [epoch: 34.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150285352139709		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.5150285352139709 | validation: 1.3091716033267273]
	TIME [epoch: 34.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908901793526667		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.7908901793526667 | validation: 0.6067004866111618]
	TIME [epoch: 34.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553018866834909		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.553018866834909 | validation: 0.4952848956681015]
	TIME [epoch: 34.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043108062548909		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.5043108062548909 | validation: 0.9325331331263167]
	TIME [epoch: 34.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786512142815032		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.5786512142815032 | validation: 0.490540350149098]
	TIME [epoch: 34.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40813169185804765		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.40813169185804765 | validation: 0.5476572963184674]
	TIME [epoch: 34.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285601683686694		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.5285601683686694 | validation: 0.37147056665565514]
	TIME [epoch: 34.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385211843138864		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.5385211843138864 | validation: 0.5757466996169591]
	TIME [epoch: 34.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220377872762177		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.5220377872762177 | validation: 0.6256582627503993]
	TIME [epoch: 34.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197810650978666		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.5197810650978666 | validation: 0.7107190490850777]
	TIME [epoch: 34.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255311744640753		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.5255311744640753 | validation: 0.5486898547553479]
	TIME [epoch: 34.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500455908937152		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.6500455908937152 | validation: 0.4663946595355022]
	TIME [epoch: 34.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536174656329975		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.5536174656329975 | validation: 0.324093236169289]
	TIME [epoch: 34.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42923995106836815		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.42923995106836815 | validation: 0.3126721305643473]
	TIME [epoch: 34.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41013414370135726		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.41013414370135726 | validation: 0.4093874735919612]
	TIME [epoch: 34.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048456665769449		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.7048456665769449 | validation: 0.9364453974896569]
	TIME [epoch: 34.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147595474473857		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.7147595474473857 | validation: 0.5814283103501454]
	TIME [epoch: 34.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865255394322456		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.5865255394322456 | validation: 0.657992521212711]
	TIME [epoch: 34.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763967506294052		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.5763967506294052 | validation: 0.36314594596487887]
	TIME [epoch: 34.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587551620810163		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.587551620810163 | validation: 0.8011362775398596]
	TIME [epoch: 34.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5704200476710964		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.5704200476710964 | validation: 0.5226299409677748]
	TIME [epoch: 34.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49372139387561637		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.49372139387561637 | validation: 0.45160223205405914]
	TIME [epoch: 34.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6249591906370892		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.6249591906370892 | validation: 0.39086993359919686]
	TIME [epoch: 34.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4665950893971147		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.4665950893971147 | validation: 0.48483897619994043]
	TIME [epoch: 34.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5339147683698708		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.5339147683698708 | validation: 0.6493454067517634]
	TIME [epoch: 34.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261212962330714		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.6261212962330714 | validation: 0.5274266140870892]
	TIME [epoch: 34.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556369169684368		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.5556369169684368 | validation: 0.9577529624965664]
	TIME [epoch: 34.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115233213424999		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.6115233213424999 | validation: 0.6145732495793742]
	TIME [epoch: 34.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019331223851907		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.5019331223851907 | validation: 0.9348391919398118]
	TIME [epoch: 34.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630743475251456		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.5630743475251456 | validation: 0.7200508755092949]
	TIME [epoch: 34.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49921200345411904		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.49921200345411904 | validation: 1.1672998237205872]
	TIME [epoch: 34.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6506117735621991		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.6506117735621991 | validation: 0.5060868872827274]
	TIME [epoch: 34.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823180119110764		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.4823180119110764 | validation: 0.7639189097314356]
	TIME [epoch: 34.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937265941448675		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.4937265941448675 | validation: 0.35391052246255106]
	TIME [epoch: 34.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5393268901741508		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.5393268901741508 | validation: 0.3335227213787977]
	TIME [epoch: 34.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4306316591673838		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.4306316591673838 | validation: 0.7816606863792823]
	TIME [epoch: 34.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7121107860568024		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.7121107860568024 | validation: 0.7860679525842297]
	TIME [epoch: 34.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596857761053979		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.6596857761053979 | validation: 0.4268103241672325]
	TIME [epoch: 34.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586842412866454		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.586842412866454 | validation: 0.9252317338966948]
	TIME [epoch: 34.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368134847597945		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.6368134847597945 | validation: 0.8877591699190077]
	TIME [epoch: 34.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634946450369527		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.634946450369527 | validation: 0.47263592009394617]
	TIME [epoch: 34.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799133788126878		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.6799133788126878 | validation: 0.31299318183051106]
	TIME [epoch: 34.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.593077609866571		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.593077609866571 | validation: 0.8756490491727111]
	TIME [epoch: 34.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986164932223198		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.5986164932223198 | validation: 0.5133469200793244]
	TIME [epoch: 34.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548667351231225		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.548667351231225 | validation: 0.3093268846574173]
	TIME [epoch: 34.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.429618526976904		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.429618526976904 | validation: 0.9716992718026671]
	TIME [epoch: 34.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7739637171389111		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.7739637171389111 | validation: 1.053530821153276]
	TIME [epoch: 34.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775176286570483		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.7775176286570483 | validation: 0.3848043955603559]
	TIME [epoch: 34.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348076867989889		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.5348076867989889 | validation: 0.9504100137929301]
	TIME [epoch: 34.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177150929864007		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.8177150929864007 | validation: 0.6803899202792002]
	TIME [epoch: 34.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6150145632875131		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.6150145632875131 | validation: 1.0960889314114892]
	TIME [epoch: 34.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997323088029951		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.5997323088029951 | validation: 0.809290094056499]
	TIME [epoch: 34.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590083754267814		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.590083754267814 | validation: 0.7345245726292395]
	TIME [epoch: 34.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44282813036915547		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.44282813036915547 | validation: 0.33699624959084395]
	TIME [epoch: 34.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748737667430188		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.3748737667430188 | validation: 0.4069941484461114]
	TIME [epoch: 34.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144780616170278		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.5144780616170278 | validation: 0.7028102731825958]
	TIME [epoch: 34.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4757409545433024		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.4757409545433024 | validation: 0.49450578567982384]
	TIME [epoch: 34.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059768612335818		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.4059768612335818 | validation: 0.7918854185469918]
	TIME [epoch: 34.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604341905740684		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.5604341905740684 | validation: 0.49439664753236623]
	TIME [epoch: 34.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46396936864358945		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.46396936864358945 | validation: 1.0545343935017812]
	TIME [epoch: 34.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.749462226407601		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.749462226407601 | validation: 1.6183800541688873]
	TIME [epoch: 34.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8578460687155337		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.8578460687155337 | validation: 0.9677592328067752]
	TIME [epoch: 34.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140753829625137		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.8140753829625137 | validation: 0.7856449868940345]
	TIME [epoch: 34.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481427132960828		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.5481427132960828 | validation: 0.361946588607426]
	TIME [epoch: 34.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48647635646937615		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.48647635646937615 | validation: 0.35170410133882474]
	TIME [epoch: 34.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46201317940099657		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.46201317940099657 | validation: 0.3370092260838519]
	TIME [epoch: 34.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38434672287388255		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.38434672287388255 | validation: 0.7259248204685629]
	TIME [epoch: 34.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6195684576932392		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.6195684576932392 | validation: 0.4337544427911768]
	TIME [epoch: 34.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3730765240261716		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.3730765240261716 | validation: 0.7724260642033806]
	TIME [epoch: 34.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40676742392390797		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.40676742392390797 | validation: 0.2929427026325173]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044907978655732		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.5044907978655732 | validation: 0.5989394528740323]
	TIME [epoch: 34.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440973265599063		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.440973265599063 | validation: 0.44991698474324193]
	TIME [epoch: 34.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034773391436378		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.5034773391436378 | validation: 0.24841713137294025]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423159842288358		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.4423159842288358 | validation: 0.5816777236590569]
	TIME [epoch: 34.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43260128021091965		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.43260128021091965 | validation: 0.6037296883562868]
	TIME [epoch: 34.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41365449344802474		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.41365449344802474 | validation: 0.48092413701949355]
	TIME [epoch: 34.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517168258187468		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.5517168258187468 | validation: 0.6813840659753023]
	TIME [epoch: 34.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552378135687967		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.552378135687967 | validation: 0.6871320624505428]
	TIME [epoch: 34.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269099228436117		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.6269099228436117 | validation: 0.6350211824183014]
	TIME [epoch: 34.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49917072415407004		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.49917072415407004 | validation: 0.3939228494333349]
	TIME [epoch: 34.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185505181653658		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.5185505181653658 | validation: 0.2957609411007315]
	TIME [epoch: 34.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066912960821449		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.5066912960821449 | validation: 0.3082942509966796]
	TIME [epoch: 34.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33915796275488286		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.33915796275488286 | validation: 0.3755711450065612]
	TIME [epoch: 34.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248743379392595		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.7248743379392595 | validation: 0.3820500964729213]
	TIME [epoch: 34.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315739011083147		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.5315739011083147 | validation: 0.833662063970148]
	TIME [epoch: 34.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5360793218356671		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.5360793218356671 | validation: 0.4640329148064674]
	TIME [epoch: 34.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45352141342509933		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.45352141342509933 | validation: 0.45055697317553695]
	TIME [epoch: 34.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49608715432520434		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.49608715432520434 | validation: 0.3054844777732631]
	TIME [epoch: 34.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4915563998995421		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.4915563998995421 | validation: 0.5034509151641526]
	TIME [epoch: 34.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48565660277886336		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.48565660277886336 | validation: 0.4479220255252198]
	TIME [epoch: 34.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938783521823338		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.3938783521823338 | validation: 0.2672097020476395]
	TIME [epoch: 34.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234118787659106		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.5234118787659106 | validation: 0.4573640208635513]
	TIME [epoch: 34.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324258023619018		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.4324258023619018 | validation: 0.3787995575303804]
	TIME [epoch: 34.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125743127800531		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.4125743127800531 | validation: 0.8995474481218764]
	TIME [epoch: 34.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968044554781501		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.5968044554781501 | validation: 0.5443143300361564]
	TIME [epoch: 171 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296929058151881		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.6296929058151881 | validation: 0.5853716122108854]
	TIME [epoch: 74.1 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40194145818804616		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.40194145818804616 | validation: 0.6195802705438177]
	TIME [epoch: 73.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5010046584133365		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.5010046584133365 | validation: 0.5127889126178012]
	TIME [epoch: 73.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4385349290144851		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.4385349290144851 | validation: 0.6018221193498603]
	TIME [epoch: 73.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637343348761771		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.637343348761771 | validation: 0.5245134852916591]
	TIME [epoch: 73.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48456126686843454		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.48456126686843454 | validation: 0.8062609839664712]
	TIME [epoch: 73.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565031446346538		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.5565031446346538 | validation: 0.47240045446422385]
	TIME [epoch: 73.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9600778116272252		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.9600778116272252 | validation: 0.4974998426522422]
	TIME [epoch: 73.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49928160150829765		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.49928160150829765 | validation: 0.6692939074903255]
	TIME [epoch: 73.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716877708292352		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.4716877708292352 | validation: 0.3879747968897078]
	TIME [epoch: 73.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47664943068464205		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.47664943068464205 | validation: 0.3916653786480591]
	TIME [epoch: 73.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808255163064125		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.5808255163064125 | validation: 1.6582339358821994]
	TIME [epoch: 73.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2681135616031727		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 1.2681135616031727 | validation: 0.7188573071102902]
	TIME [epoch: 73.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6617412615523315		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.6617412615523315 | validation: 0.42317170632982426]
	TIME [epoch: 73.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808981590052449		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.4808981590052449 | validation: 0.5614137539958486]
	TIME [epoch: 73.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4318971343270638		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.4318971343270638 | validation: 0.5537150795151927]
	TIME [epoch: 73.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46424721351553777		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.46424721351553777 | validation: 0.44284092382356577]
	TIME [epoch: 74 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38440586790773623		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.38440586790773623 | validation: 0.46728027313300025]
	TIME [epoch: 73.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4929582354199552		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.4929582354199552 | validation: 0.5319243891825625]
	TIME [epoch: 73.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4696527756920279		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.4696527756920279 | validation: 0.4195641039172605]
	TIME [epoch: 73.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656649648954444		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.5656649648954444 | validation: 0.32737998657515316]
	TIME [epoch: 74 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219041133599974		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.5219041133599974 | validation: 0.42778844633509683]
	TIME [epoch: 73.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554033094130804		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.5554033094130804 | validation: 0.3461437745423942]
	TIME [epoch: 73.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47519567031320775		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.47519567031320775 | validation: 0.36922632690233825]
	TIME [epoch: 73.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259369892268618		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.4259369892268618 | validation: 0.3519364371201209]
	TIME [epoch: 74 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42391218310513823		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.42391218310513823 | validation: 0.45713736156010387]
	TIME [epoch: 73.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591228709203848		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.591228709203848 | validation: 0.8192699082494275]
	TIME [epoch: 73.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716467809655552		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.716467809655552 | validation: 0.5284746691271691]
	TIME [epoch: 73.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132439682744303		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.6132439682744303 | validation: 0.415211034920168]
	TIME [epoch: 74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681074571884628		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.4681074571884628 | validation: 0.6250276886063816]
	TIME [epoch: 74.2 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688075707337314		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.7688075707337314 | validation: 0.39346790242434154]
	TIME [epoch: 74 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5169024128425214		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.5169024128425214 | validation: 0.5799082657662964]
	TIME [epoch: 74.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714149382264061		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.5714149382264061 | validation: 0.3232711772156906]
	TIME [epoch: 74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424854875040032		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.4424854875040032 | validation: 0.8054989827993955]
	TIME [epoch: 74 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470235997638505		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.6470235997638505 | validation: 0.4085817356899983]
	TIME [epoch: 74 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45212820476672305		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.45212820476672305 | validation: 1.0675585356641444]
	TIME [epoch: 74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5010021493505662		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.5010021493505662 | validation: 0.8111739093094015]
	TIME [epoch: 73.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889070657596809		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.5889070657596809 | validation: 0.4558303845351314]
	TIME [epoch: 74 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46665071369017497		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.46665071369017497 | validation: 0.4036357503907707]
	TIME [epoch: 74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486443880848805		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.3486443880848805 | validation: 0.4512339276388849]
	TIME [epoch: 74 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36395299610555454		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.36395299610555454 | validation: 0.35977518222788035]
	TIME [epoch: 73.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36025371605813167		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.36025371605813167 | validation: 1.2229317310963435]
	TIME [epoch: 73.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609845574754007		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.609845574754007 | validation: 1.032773071833553]
	TIME [epoch: 73.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5523945990338508		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.5523945990338508 | validation: 0.9967164646476752]
	TIME [epoch: 73.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277205832985131		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.6277205832985131 | validation: 0.444463058245953]
	TIME [epoch: 73.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416712230022873		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.4416712230022873 | validation: 0.561454712260842]
	TIME [epoch: 73.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4463770646490669		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.4463770646490669 | validation: 0.5607881770039256]
	TIME [epoch: 73.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45261396087979305		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.45261396087979305 | validation: 0.3754831175574834]
	TIME [epoch: 73.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278756739193438		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.5278756739193438 | validation: 0.35751854614102063]
	TIME [epoch: 73.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600878893186267		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.4600878893186267 | validation: 0.5033365023671131]
	TIME [epoch: 73.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41125140276322625		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.41125140276322625 | validation: 0.428821121716711]
	TIME [epoch: 73.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234536545640719		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.4234536545640719 | validation: 0.36134046584124113]
	TIME [epoch: 73.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42858704370727757		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.42858704370727757 | validation: 0.5357600556579188]
	TIME [epoch: 73.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41392870980192		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.41392870980192 | validation: 0.2604821998688653]
	TIME [epoch: 73.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33882042212165714		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.33882042212165714 | validation: 0.6075944599679326]
	TIME [epoch: 73.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4354995976592929		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.4354995976592929 | validation: 0.3006466086545375]
	TIME [epoch: 73.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4138784376791733		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.4138784376791733 | validation: 0.386039822817851]
	TIME [epoch: 73.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479506567123163		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.4479506567123163 | validation: 0.47064624681017675]
	TIME [epoch: 73.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658208940909388		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.4658208940909388 | validation: 0.2778049277004543]
	TIME [epoch: 73.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3690646400250534		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.3690646400250534 | validation: 0.3928735712309738]
	TIME [epoch: 73.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33485205377223903		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.33485205377223903 | validation: 0.38137175593130257]
	TIME [epoch: 73.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848817304543424		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.3848817304543424 | validation: 0.31770018051900706]
	TIME [epoch: 73.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627445626938642		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.3627445626938642 | validation: 0.46469650651181027]
	TIME [epoch: 73.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38267791534468343		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.38267791534468343 | validation: 0.7125522889235467]
	TIME [epoch: 73.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463302520226103		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.5463302520226103 | validation: 0.6123730470530284]
	TIME [epoch: 73.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46794742152057156		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.46794742152057156 | validation: 0.4348720207959066]
	TIME [epoch: 73.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7106055783377105		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.7106055783377105 | validation: 0.9031328470227551]
	TIME [epoch: 73.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5368501083608315		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.5368501083608315 | validation: 0.2890567331143013]
	TIME [epoch: 73.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297597371967753		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.4297597371967753 | validation: 0.9068014941527844]
	TIME [epoch: 73.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697020974788925		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.6697020974788925 | validation: 0.39076301599757646]
	TIME [epoch: 73.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4684699411205754		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.4684699411205754 | validation: 0.7145194821668532]
	TIME [epoch: 73.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642507925578098		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.4642507925578098 | validation: 0.5273206277401981]
	TIME [epoch: 73.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923639699644428		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.5923639699644428 | validation: 0.5474952622394214]
	TIME [epoch: 74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514792085363443		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.4514792085363443 | validation: 0.4914572792902693]
	TIME [epoch: 74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428682619636187		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.3428682619636187 | validation: 0.2698728177619423]
	TIME [epoch: 73.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37194443729253845		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.37194443729253845 | validation: 0.41109945612512505]
	TIME [epoch: 73.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122420736905385		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.5122420736905385 | validation: 0.48821462024667167]
	TIME [epoch: 74 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4720164847484485		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.4720164847484485 | validation: 0.8439245906028544]
	TIME [epoch: 74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46926179448483313		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.46926179448483313 | validation: 0.5402826357178302]
	TIME [epoch: 74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3903436605517996		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.3903436605517996 | validation: 0.2185831656069059]
	TIME [epoch: 73.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4639803181194677		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.4639803181194677 | validation: 0.5888692712172461]
	TIME [epoch: 74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46673146177700675		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.46673146177700675 | validation: 0.496963862162347]
	TIME [epoch: 74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355459768615807		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.5355459768615807 | validation: 0.5009535612276423]
	TIME [epoch: 74 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44492566413082585		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.44492566413082585 | validation: 0.3144693998217184]
	TIME [epoch: 74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556087937559172		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.4556087937559172 | validation: 0.3258569901132444]
	TIME [epoch: 74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37677146299047426		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.37677146299047426 | validation: 0.25420957908625486]
	TIME [epoch: 74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40034047290692487		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.40034047290692487 | validation: 0.46773311684383795]
	TIME [epoch: 74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676977055234971		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.4676977055234971 | validation: 0.39082128161318974]
	TIME [epoch: 74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38225685576696833		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.38225685576696833 | validation: 0.5114121880427536]
	TIME [epoch: 74 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637310820875771		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.4637310820875771 | validation: 0.3325474009743995]
	TIME [epoch: 73.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497913458920555		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.3497913458920555 | validation: 0.26679797124225346]
	TIME [epoch: 74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105825152875197		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.3105825152875197 | validation: 0.41746551495447165]
	TIME [epoch: 74 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718455332823282		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.5718455332823282 | validation: 0.639105710802851]
	TIME [epoch: 74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813543906485853		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.4813543906485853 | validation: 0.367146759240647]
	TIME [epoch: 74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662738162083607		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.3662738162083607 | validation: 0.4478789555320778]
	TIME [epoch: 73.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330016390114523		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.5330016390114523 | validation: 1.172244864582864]
	TIME [epoch: 74 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638662414510455		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.638662414510455 | validation: 0.7114185425675805]
	TIME [epoch: 73.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45155219896209375		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.45155219896209375 | validation: 0.2862123109423948]
	TIME [epoch: 73.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32909032043908637		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.32909032043908637 | validation: 0.2703993889732626]
	TIME [epoch: 73.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906687090575373		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.3906687090575373 | validation: 0.6066296277080208]
	TIME [epoch: 74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014149229900353		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.5014149229900353 | validation: 0.36888086119333974]
	TIME [epoch: 73.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992137616052906		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.3992137616052906 | validation: 1.5702879041421105]
	TIME [epoch: 73.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7404492984068856		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.7404492984068856 | validation: 0.3206146036211712]
	TIME [epoch: 74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300112708258876		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.3300112708258876 | validation: 0.3050536141506266]
	TIME [epoch: 73.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29615598363109435		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.29615598363109435 | validation: 0.4352008269545683]
	TIME [epoch: 74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38249399174413723		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.38249399174413723 | validation: 0.24496944615909508]
	TIME [epoch: 73.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051389002702956		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.3051389002702956 | validation: 0.6717090945152406]
	TIME [epoch: 74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4092533787934588		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.4092533787934588 | validation: 0.4628035410564508]
	TIME [epoch: 73.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30008228159982325		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.30008228159982325 | validation: 0.39729775427103253]
	TIME [epoch: 74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33428737391376817		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.33428737391376817 | validation: 0.441313668501532]
	TIME [epoch: 73.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444024534378898		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.3444024534378898 | validation: 0.38358860928306887]
	TIME [epoch: 73.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976008816714033		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.3976008816714033 | validation: 0.3601781185835788]
	TIME [epoch: 73.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31532667447488627		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.31532667447488627 | validation: 0.4135366667230097]
	TIME [epoch: 73.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29291742554809275		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.29291742554809275 | validation: 0.4889794259760161]
	TIME [epoch: 73.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39485674527128		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.39485674527128 | validation: 0.271202613422196]
	TIME [epoch: 73.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043648601607229		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.4043648601607229 | validation: 0.46838007726499736]
	TIME [epoch: 73.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008140395731152		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.3008140395731152 | validation: 0.5810062111332439]
	TIME [epoch: 73.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48150421099857726		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.48150421099857726 | validation: 0.3719954967621296]
	TIME [epoch: 73.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115930921687009		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.3115930921687009 | validation: 0.4351854387316748]
	TIME [epoch: 73.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502677304357105		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.502677304357105 | validation: 0.4204381395685466]
	TIME [epoch: 73.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5444742768991102		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.5444742768991102 | validation: 0.5105216234632431]
	TIME [epoch: 73.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43822937024360886		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.43822937024360886 | validation: 0.5224086383451092]
	TIME [epoch: 73.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571589161017815		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.3571589161017815 | validation: 0.4757363112552122]
	TIME [epoch: 73.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591109519972312		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.3591109519972312 | validation: 0.5714416318944843]
	TIME [epoch: 73.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3995541006396524		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.3995541006396524 | validation: 0.729925480126072]
	TIME [epoch: 73.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36666759996708986		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.36666759996708986 | validation: 0.253077538157542]
	TIME [epoch: 73.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26417463078527686		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.26417463078527686 | validation: 0.212455614712381]
	TIME [epoch: 73.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1128.pth
	Model improved!!!
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116740319683408		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.3116740319683408 | validation: 0.2913068470213067]
	TIME [epoch: 73.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4026091920487781		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.4026091920487781 | validation: 0.39960455168791986]
	TIME [epoch: 73.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828291985249461		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.2828291985249461 | validation: 0.1622771288956935]
	TIME [epoch: 73.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1131.pth
	Model improved!!!
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28669540456846454		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.28669540456846454 | validation: 0.141603663463806]
	TIME [epoch: 73.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1132.pth
	Model improved!!!
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868838116434719		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.3868838116434719 | validation: 0.5502107564300762]
	TIME [epoch: 73.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993389773099531		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.4993389773099531 | validation: 0.33430105275241095]
	TIME [epoch: 73.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953797188491965		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.2953797188491965 | validation: 0.1939671968821638]
	TIME [epoch: 73.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28701499606202263		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.28701499606202263 | validation: 0.24624249881881904]
	TIME [epoch: 73.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434262401060514		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.2434262401060514 | validation: 0.2942861969917396]
	TIME [epoch: 73.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663035383345106		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.2663035383345106 | validation: 0.2163704664671144]
	TIME [epoch: 73.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771558897596126		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.2771558897596126 | validation: 0.36685403616850853]
	TIME [epoch: 73.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29072910819224496		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.29072910819224496 | validation: 0.36620009647896407]
	TIME [epoch: 73.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33495305740075243		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.33495305740075243 | validation: 0.5375445131810478]
	TIME [epoch: 73.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871071028341195		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.3871071028341195 | validation: 0.6313108425350138]
	TIME [epoch: 73.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285655471017512		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.5285655471017512 | validation: 0.22421191738984209]
	TIME [epoch: 73.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830482129179554		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.2830482129179554 | validation: 0.2402741554725223]
	TIME [epoch: 73.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29351470322963447		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.29351470322963447 | validation: 0.23808869997127782]
	TIME [epoch: 73.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273970613514295		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.2273970613514295 | validation: 0.28371199832692867]
	TIME [epoch: 73.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23067768667035946		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.23067768667035946 | validation: 0.6233474705013294]
	TIME [epoch: 73.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38600337106443533		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.38600337106443533 | validation: 0.2227681477082662]
	TIME [epoch: 73.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153144780075417		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.3153144780075417 | validation: 0.538892261328057]
	TIME [epoch: 73.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48701098045924485		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.48701098045924485 | validation: 0.5295901015136667]
	TIME [epoch: 73.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4073152116429063		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.4073152116429063 | validation: 0.6235860067630274]
	TIME [epoch: 73.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652747317183426		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.3652747317183426 | validation: 0.6254908796293639]
	TIME [epoch: 73.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473605153993661		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.473605153993661 | validation: 0.22174926450792692]
	TIME [epoch: 73.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319724078068739		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.3319724078068739 | validation: 0.27389499520667626]
	TIME [epoch: 73.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614792970662895		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.3614792970662895 | validation: 0.25237340980271483]
	TIME [epoch: 73.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774633064533989		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.2774633064533989 | validation: 0.4043121442754031]
	TIME [epoch: 73.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069015257937986		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.3069015257937986 | validation: 0.4152414016995689]
	TIME [epoch: 73.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810030703494446		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.3810030703494446 | validation: 0.3576964938077062]
	TIME [epoch: 73.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806531341461947		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.3806531341461947 | validation: 0.36124171276878325]
	TIME [epoch: 73.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401844151476758		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.3401844151476758 | validation: 0.16971618772608638]
	TIME [epoch: 73.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28440737297339935		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.28440737297339935 | validation: 0.30681712201574846]
	TIME [epoch: 74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603933404873053		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.2603933404873053 | validation: 0.4790234880448424]
	TIME [epoch: 73.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693407822563954		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.2693407822563954 | validation: 0.23588564309314278]
	TIME [epoch: 74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26672862846597367		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.26672862846597367 | validation: 0.18314227792281093]
	TIME [epoch: 73.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26478163261239296		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.26478163261239296 | validation: 0.33142849330914703]
	TIME [epoch: 73.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537703562311693		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.3537703562311693 | validation: 0.22480328141543454]
	TIME [epoch: 73.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32132508293785245		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.32132508293785245 | validation: 0.3355990781350887]
	TIME [epoch: 73.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160002838651375		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.3160002838651375 | validation: 0.5133725968411006]
	TIME [epoch: 73.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821033010287697		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.2821033010287697 | validation: 0.45551318384182116]
	TIME [epoch: 73.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037665539438941		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.5037665539438941 | validation: 0.6271406845420054]
	TIME [epoch: 73.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32827576005232445		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.32827576005232445 | validation: 0.2543507674731335]
	TIME [epoch: 73.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.237677952719001		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.237677952719001 | validation: 0.20563166950965764]
	TIME [epoch: 73.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261092153248654		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.3261092153248654 | validation: 0.5111464924287169]
	TIME [epoch: 73.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689785183641028		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.5689785183641028 | validation: 0.3040158473745963]
	TIME [epoch: 74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657659287353633		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.6657659287353633 | validation: 0.29313105500988423]
	TIME [epoch: 73.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25070362042530436		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.25070362042530436 | validation: 0.3142295581400547]
	TIME [epoch: 73.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278650016354631		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.278650016354631 | validation: 0.41316449877032996]
	TIME [epoch: 73.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34934110162378784		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.34934110162378784 | validation: 0.24133712011291447]
	TIME [epoch: 73.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071118108953921		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.3071118108953921 | validation: 0.33307008809669125]
	TIME [epoch: 73.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347867070519818		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.347867070519818 | validation: 0.1834074482768081]
	TIME [epoch: 73.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795045137095775		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.2795045137095775 | validation: 0.2932546172497158]
	TIME [epoch: 73.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2678049214732702		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.2678049214732702 | validation: 0.20916925145894547]
	TIME [epoch: 73.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626921745601486		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.2626921745601486 | validation: 0.42881664573399]
	TIME [epoch: 73.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933481606615999		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.3933481606615999 | validation: 0.5401176581593108]
	TIME [epoch: 73.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014952164989674		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.3014952164989674 | validation: 0.250576942799562]
	TIME [epoch: 73.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3266309367320733		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.3266309367320733 | validation: 0.4596504016692569]
	TIME [epoch: 73.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744833390680838		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.2744833390680838 | validation: 0.21642605049078625]
	TIME [epoch: 73.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23176978108029203		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.23176978108029203 | validation: 0.22858573833473073]
	TIME [epoch: 73.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22666988168402205		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.22666988168402205 | validation: 0.2837018399748938]
	TIME [epoch: 73.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17996788305445938		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.17996788305445938 | validation: 0.4273955572684953]
	TIME [epoch: 73.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32469082541025035		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.32469082541025035 | validation: 0.5359059178104912]
	TIME [epoch: 73.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417964426630611		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.3417964426630611 | validation: 0.25581325524779963]
	TIME [epoch: 73.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191413479689425		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.3191413479689425 | validation: 0.2457438278661726]
	TIME [epoch: 73.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343812718300263		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.3343812718300263 | validation: 0.4161754501655833]
	TIME [epoch: 73.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695568566345044		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.2695568566345044 | validation: 0.24921287053159985]
	TIME [epoch: 73.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571305460009695		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.2571305460009695 | validation: 0.18542951115049086]
	TIME [epoch: 73.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880224779344517		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.2880224779344517 | validation: 0.22230436460475417]
	TIME [epoch: 73.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873858060693434		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.2873858060693434 | validation: 0.356080680710537]
	TIME [epoch: 73.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2426793096573241		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.2426793096573241 | validation: 0.1862081939924224]
	TIME [epoch: 73.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696880662541267		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.1696880662541267 | validation: 0.17282896674159698]
	TIME [epoch: 73.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20705934011600458		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.20705934011600458 | validation: 0.22439097898670268]
	TIME [epoch: 73.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21696684192423493		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.21696684192423493 | validation: 0.5295990247650619]
	TIME [epoch: 73.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39347717544720473		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.39347717544720473 | validation: 0.29700208790273785]
	TIME [epoch: 73.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27869872232905235		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.27869872232905235 | validation: 0.3501631221838274]
	TIME [epoch: 73.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26277251198962526		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.26277251198962526 | validation: 0.8838810605786382]
	TIME [epoch: 73.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109472751342811		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.5109472751342811 | validation: 0.5604046866510616]
	TIME [epoch: 73.8 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533950394944872		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.533950394944872 | validation: 0.358769255723563]
	TIME [epoch: 73.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27847160209722		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.27847160209722 | validation: 0.26053434519028107]
	TIME [epoch: 73.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24431750575752756		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.24431750575752756 | validation: 0.1626347998888502]
	TIME [epoch: 73.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20319374411931324		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.20319374411931324 | validation: 0.16443138699108661]
	TIME [epoch: 73.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24467456835347615		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.24467456835347615 | validation: 0.1352946699112889]
	TIME [epoch: 73.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl3_20240705_050801/states/model_phi1_1a_v_kl3_1211.pth
	Model improved!!!
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039324213145226		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.3039324213145226 | validation: 0.24210019230758179]
	TIME [epoch: 73.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739105341525515		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.2739105341525515 | validation: 0.4244975238391473]
	TIME [epoch: 73.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29195267660176494		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.29195267660176494 | validation: 0.24352703902171122]
	TIME [epoch: 73.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24078108855148422		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.24078108855148422 | validation: 0.5954553059649381]
	TIME [epoch: 73.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143504563996695		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.3143504563996695 | validation: 0.21996413086483524]
	TIME [epoch: 73.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24589749999335178		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.24589749999335178 | validation: 0.1375778529696531]
	TIME [epoch: 73.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698865302735352		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.2698865302735352 | validation: 0.38381350527918934]
	TIME [epoch: 73.8 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644634290159509		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.2644634290159509 | validation: 0.2534303403580755]
	TIME [epoch: 73.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26548246472696435		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.26548246472696435 | validation: 0.5004586075657669]
	TIME [epoch: 73.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45004194543612186		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.45004194543612186 | validation: 0.3948345501014038]
	TIME [epoch: 73.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30105072428549656		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.30105072428549656 | validation: 0.3207987374746326]
	TIME [epoch: 73.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377305157700756		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.5377305157700756 | validation: 0.26815079107251244]
	TIME [epoch: 73.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20065289210562348		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.20065289210562348 | validation: 0.2629494506212847]
	TIME [epoch: 73.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24862728245122354		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.24862728245122354 | validation: 0.1827777983905704]
	TIME [epoch: 73.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408765513640576		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.2408765513640576 | validation: 0.3630377963015173]
	TIME [epoch: 73.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33092923219288883		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.33092923219288883 | validation: 0.28947150043284675]
	TIME [epoch: 73.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40971792501949744		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.40971792501949744 | validation: 0.3587962904134578]
	TIME [epoch: 73.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27077076997139704		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.27077076997139704 | validation: 0.24607275962932648]
	TIME [epoch: 73.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251100927718794		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.251100927718794 | validation: 0.2468091938782232]
	TIME [epoch: 73.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19040396513393723		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.19040396513393723 | validation: 0.24152741134718733]
	TIME [epoch: 73.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21094477657720317		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.21094477657720317 | validation: 0.1998957043245389]
	TIME [epoch: 73.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35708083494426757		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.35708083494426757 | validation: 0.3681527763805759]
	TIME [epoch: 73.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27355936360044586		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.27355936360044586 | validation: 0.2264782273705157]
	TIME [epoch: 73.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37042292006990646		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.37042292006990646 | validation: 0.3640923686625971]
	TIME [epoch: 73.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089820744840365		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.3089820744840365 | validation: 0.2890247990034928]
	TIME [epoch: 73.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30866002404685244		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.30866002404685244 | validation: 0.2844840922051469]
	TIME [epoch: 73.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804419314948858		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.3804419314948858 | validation: 0.6491950759739167]
	TIME [epoch: 73.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404095255920334		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.404095255920334 | validation: 0.274811647891052]
	TIME [epoch: 73.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24108112269448023		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.24108112269448023 | validation: 0.507892940198552]
	TIME [epoch: 73.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637144728421357		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.3637144728421357 | validation: 0.21555016474026711]
	TIME [epoch: 73.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30999552401184155		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.30999552401184155 | validation: 0.29885645123521676]
	TIME [epoch: 73.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740497353269886		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.2740497353269886 | validation: 0.22863892551232]
	TIME [epoch: 73.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20840453618370886		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.20840453618370886 | validation: 0.33333182458417054]
	TIME [epoch: 73.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25996242064066377		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.25996242064066377 | validation: 0.16119238508791633]
	TIME [epoch: 73.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23339987787323013		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.23339987787323013 | validation: 0.21239851034469007]
	TIME [epoch: 73.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22718479707647227		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.22718479707647227 | validation: 0.2320580504055511]
	TIME [epoch: 73.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22082827564927793		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.22082827564927793 | validation: 0.2088046199916882]
	TIME [epoch: 73.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29358688678396744		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.29358688678396744 | validation: 0.27070127945735417]
	TIME [epoch: 73.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310511410102836		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.2310511410102836 | validation: 0.14877426831934493]
	TIME [epoch: 73.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198172653950123		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.198172653950123 | validation: 0.18290163750011554]
	TIME [epoch: 73.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866293465622586		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.18866293465622586 | validation: 0.32118938402424524]
	TIME [epoch: 73.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20665824001862138		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.20665824001862138 | validation: 0.15015943217568845]
	TIME [epoch: 73.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266286501667515		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.2266286501667515 | validation: 0.3309928414533294]
	TIME [epoch: 73.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24656221728496625		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.24656221728496625 | validation: 0.18898788650751142]
	TIME [epoch: 73.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084998051400244		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.20084998051400244 | validation: 0.32712473324321867]
	TIME [epoch: 73.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311940320710782		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.2311940320710782 | validation: 0.1871548967039057]
	TIME [epoch: 73.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20176369569818425		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.20176369569818425 | validation: 0.2923279514683762]
	TIME [epoch: 73.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22811201203306025		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.22811201203306025 | validation: 0.3708927855604581]
	TIME [epoch: 73.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27693040454375717		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.27693040454375717 | validation: 0.1449250079856747]
	TIME [epoch: 73.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2217426159733085		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.2217426159733085 | validation: 0.1733207244226557]
	TIME [epoch: 73.8 sec]
EPOCH 1262/2000:
	Training over batches...
