Args:
Namespace(name='model_phi1_1a_v_mmd2', outdir='out/model_training/model_phi1_1a_v_mmd2', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=10.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3584894607

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.954767577750248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.954767577750248 | validation: 4.852242654885895]
	TIME [epoch: 121 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.353333335490031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.353333335490031 | validation: 3.9676320689962252]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8967463753965887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8967463753965887 | validation: 3.7526429764072313]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.588915844852228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.588915844852228 | validation: 3.604194440840371]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.42566338350702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.42566338350702 | validation: 3.684083410815969]
	TIME [epoch: 7.44 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.333555869485841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.333555869485841 | validation: 3.409224714035661]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.142935954597283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.142935954597283 | validation: 3.2428456114334248]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.894349326144367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.894349326144367 | validation: 3.465727778351008]
	TIME [epoch: 7.44 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8840260836696774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8840260836696774 | validation: 2.7979062344512484]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.495477704672682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.495477704672682 | validation: 2.5895547733802173]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6589788701113273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6589788701113273 | validation: 2.4560524467243647]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328717382021443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.328717382021443 | validation: 2.479239474185621]
	TIME [epoch: 7.45 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357929469647368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.357929469647368 | validation: 2.422821780578434]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27448561981516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.27448561981516 | validation: 2.2279837938303446]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335559529908589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.335559529908589 | validation: 2.4021359698081612]
	TIME [epoch: 7.47 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256779278978459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.256779278978459 | validation: 2.21117962784308]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115366830629722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.115366830629722 | validation: 1.9120011537394324]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1906819919672826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1906819919672826 | validation: 2.8358247435653827]
	TIME [epoch: 7.45 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381553306392859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.381553306392859 | validation: 2.4272526208589587]
	TIME [epoch: 7.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1217242282297506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1217242282297506 | validation: 2.34403718237868]
	TIME [epoch: 7.48 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01066169573132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.01066169573132 | validation: 1.9751221890278352]
	TIME [epoch: 7.48 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0247587076357245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0247587076357245 | validation: 2.652448875757248]
	TIME [epoch: 7.43 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9108954788431292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9108954788431292 | validation: 2.348832437676935]
	TIME [epoch: 7.44 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.611493465165995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.611493465165995 | validation: 1.1465084670426404]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554530318501404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1554530318501404 | validation: 1.1471366147692863]
	TIME [epoch: 7.48 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209738474779586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0209738474779586 | validation: 1.1649090729369527]
	TIME [epoch: 7.47 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277576005376752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.277576005376752 | validation: 1.2162410367729968]
	TIME [epoch: 7.45 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696623839734088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8696623839734088 | validation: 0.8480765287408188]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034383246307905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.034383246307905 | validation: 0.8670075248491058]
	TIME [epoch: 7.45 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.996894666340252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.996894666340252 | validation: 0.9362234831521258]
	TIME [epoch: 7.49 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242671808913321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7242671808913321 | validation: 0.7660836772726051]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7943435919273751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7943435919273751 | validation: 0.6012123688062061]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714502070642747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.714502070642747 | validation: 0.579342243959651]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9195039400561121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9195039400561121 | validation: 0.7281421927612106]
	TIME [epoch: 7.47 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359559333246683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6359559333246683 | validation: 0.5073700393487799]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265270018458701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5265270018458701 | validation: 0.722604062147863]
	TIME [epoch: 7.46 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545400880862077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6545400880862077 | validation: 0.5367628211834696]
	TIME [epoch: 7.44 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8115674137687067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8115674137687067 | validation: 0.770330106270331]
	TIME [epoch: 7.45 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031340009013619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6031340009013619 | validation: 0.4329515230451497]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40492325322861084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40492325322861084 | validation: 0.4553003289423063]
	TIME [epoch: 7.51 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4866881911716796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4866881911716796 | validation: 1.456236259406709]
	TIME [epoch: 7.44 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0832062273757725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0832062273757725 | validation: 0.7037661194142493]
	TIME [epoch: 7.45 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6537369989377445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6537369989377445 | validation: 0.4008045489252262]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42082273956697713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42082273956697713 | validation: 0.6772796043965912]
	TIME [epoch: 7.45 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856536021664319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5856536021664319 | validation: 0.5962955867749984]
	TIME [epoch: 7.51 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034140766991987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4034140766991987 | validation: 0.33602386504178733]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42675801718967654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42675801718967654 | validation: 0.7754432630442688]
	TIME [epoch: 7.44 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483940761082742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4483940761082742 | validation: 0.9400857675164975]
	TIME [epoch: 7.44 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804873943045228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6804873943045228 | validation: 0.5002257297549617]
	TIME [epoch: 7.44 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990999606229891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3990999606229891 | validation: 0.34011631508782525]
	TIME [epoch: 7.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32675947364507896		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.32675947364507896 | validation: 0.5614245113167643]
	TIME [epoch: 7.45 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46188328705860965		[learning rate: 0.0099588]
	Learning Rate: 0.00995876
	LOSS [training: 0.46188328705860965 | validation: 0.42613702791755104]
	TIME [epoch: 7.44 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4791671213533287		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.4791671213533287 | validation: 0.3600886419647986]
	TIME [epoch: 7.44 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31453584331643314		[learning rate: 0.0099118]
	Learning Rate: 0.00991183
	LOSS [training: 0.31453584331643314 | validation: 0.2937318791735961]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6290880379211659		[learning rate: 0.0098884]
	Learning Rate: 0.00988845
	LOSS [training: 0.6290880379211659 | validation: 0.4021467824005627]
	TIME [epoch: 7.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769974893822394		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3769974893822394 | validation: 0.31856593564830793]
	TIME [epoch: 7.44 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741557085373969		[learning rate: 0.0098419]
	Learning Rate: 0.00984185
	LOSS [training: 0.2741557085373969 | validation: 0.45021267283556177]
	TIME [epoch: 7.44 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40299301362351697		[learning rate: 0.0098186]
	Learning Rate: 0.00981864
	LOSS [training: 0.40299301362351697 | validation: 0.7562661227713423]
	TIME [epoch: 7.43 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800453980700393		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.4800453980700393 | validation: 0.38948241003031925]
	TIME [epoch: 7.43 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952401053899507		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 0.2952401053899507 | validation: 0.3413519833241476]
	TIME [epoch: 7.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4897451948484538		[learning rate: 0.0097493]
	Learning Rate: 0.00974932
	LOSS [training: 0.4897451948484538 | validation: 0.4461916381916646]
	TIME [epoch: 7.44 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37179300865370885		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.37179300865370885 | validation: 0.30324534037846146]
	TIME [epoch: 7.43 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591245079551195		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2591245079551195 | validation: 0.2527617844164817]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471902753131529		[learning rate: 0.0096805]
	Learning Rate: 0.00968049
	LOSS [training: 0.3471902753131529 | validation: 0.41140323548488655]
	TIME [epoch: 7.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809370994265646		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.2809370994265646 | validation: 0.21133091149031955]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33549919998792593		[learning rate: 0.0096349]
	Learning Rate: 0.00963488
	LOSS [training: 0.33549919998792593 | validation: 0.34539910222219583]
	TIME [epoch: 7.45 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39422135618852155		[learning rate: 0.0096121]
	Learning Rate: 0.00961215
	LOSS [training: 0.39422135618852155 | validation: 0.3922646745018553]
	TIME [epoch: 7.44 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42593544141786893		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.42593544141786893 | validation: 0.4828750190446329]
	TIME [epoch: 7.47 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36520964393142474		[learning rate: 0.0095669]
	Learning Rate: 0.00956686
	LOSS [training: 0.36520964393142474 | validation: 0.22927417599033278]
	TIME [epoch: 7.46 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2678555914318729		[learning rate: 0.0095443]
	Learning Rate: 0.00954429
	LOSS [training: 0.2678555914318729 | validation: 0.29840449548968573]
	TIME [epoch: 7.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703682777349403		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2703682777349403 | validation: 0.33184860948064215]
	TIME [epoch: 7.45 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647853958780088		[learning rate: 0.0094993]
	Learning Rate: 0.00949931
	LOSS [training: 0.2647853958780088 | validation: 0.3462145191275615]
	TIME [epoch: 7.45 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39567854131572594		[learning rate: 0.0094769]
	Learning Rate: 0.00947691
	LOSS [training: 0.39567854131572594 | validation: 0.2642451582707239]
	TIME [epoch: 7.45 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592245065993112		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.2592245065993112 | validation: 0.2190653388830661]
	TIME [epoch: 7.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26208924007841444		[learning rate: 0.0094323]
	Learning Rate: 0.00943225
	LOSS [training: 0.26208924007841444 | validation: 0.16054540438593817]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22976073781170042		[learning rate: 0.00941]
	Learning Rate: 0.00941
	LOSS [training: 0.22976073781170042 | validation: 0.4293144536378267]
	TIME [epoch: 7.45 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822494519297217		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.2822494519297217 | validation: 0.5681158454883268]
	TIME [epoch: 7.45 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435220360812127		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.3435220360812127 | validation: 0.19251903872777137]
	TIME [epoch: 7.45 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26912242251659246		[learning rate: 0.0093436]
	Learning Rate: 0.00934357
	LOSS [training: 0.26912242251659246 | validation: 0.2282780554492989]
	TIME [epoch: 7.46 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3157484153307057		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.3157484153307057 | validation: 0.3581398162837954]
	TIME [epoch: 7.49 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652182744737887		[learning rate: 0.0092995]
	Learning Rate: 0.00929954
	LOSS [training: 0.2652182744737887 | validation: 0.3586202322147831]
	TIME [epoch: 7.45 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29381263838602456		[learning rate: 0.0092776]
	Learning Rate: 0.00927761
	LOSS [training: 0.29381263838602456 | validation: 0.19358933936741046]
	TIME [epoch: 7.45 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19253194885285638		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.19253194885285638 | validation: 0.254101542958133]
	TIME [epoch: 7.45 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29340520443564405		[learning rate: 0.0092339]
	Learning Rate: 0.00923389
	LOSS [training: 0.29340520443564405 | validation: 0.23915041644938298]
	TIME [epoch: 7.47 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394951522607389		[learning rate: 0.0092121]
	Learning Rate: 0.00921211
	LOSS [training: 0.2394951522607389 | validation: 0.15554969927517892]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23490832839981582		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.23490832839981582 | validation: 0.5001490285609532]
	TIME [epoch: 7.45 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338800412483331		[learning rate: 0.0091687]
	Learning Rate: 0.0091687
	LOSS [training: 0.3338800412483331 | validation: 0.2780974439531798]
	TIME [epoch: 7.44 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2494762025262358		[learning rate: 0.0091471]
	Learning Rate: 0.00914707
	LOSS [training: 0.2494762025262358 | validation: 0.21270142210427911]
	TIME [epoch: 7.44 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16753710163945018		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.16753710163945018 | validation: 0.1261463323584313]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19937890926555063		[learning rate: 0.009104]
	Learning Rate: 0.00910397
	LOSS [training: 0.19937890926555063 | validation: 0.47332395400688965]
	TIME [epoch: 7.49 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3847105018209653		[learning rate: 0.0090825]
	Learning Rate: 0.00908249
	LOSS [training: 0.3847105018209653 | validation: 0.18759491781168186]
	TIME [epoch: 7.45 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19452199683017177		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.19452199683017177 | validation: 0.35606425730796715]
	TIME [epoch: 7.45 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23202681753575083		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.23202681753575083 | validation: 0.13640037836594965]
	TIME [epoch: 7.43 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615320655929584		[learning rate: 0.0090184]
	Learning Rate: 0.00901837
	LOSS [training: 0.1615320655929584 | validation: 0.15297778168034593]
	TIME [epoch: 7.45 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739901341468832		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.1739901341468832 | validation: 0.19650323681302445]
	TIME [epoch: 7.48 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151618488212441		[learning rate: 0.0089759]
	Learning Rate: 0.00897588
	LOSS [training: 0.3151618488212441 | validation: 0.2805005142062778]
	TIME [epoch: 7.43 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589196423660576		[learning rate: 0.0089547]
	Learning Rate: 0.0089547
	LOSS [training: 0.2589196423660576 | validation: 0.29621200204379017]
	TIME [epoch: 7.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568237337899068		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.2568237337899068 | validation: 0.1659969105293839]
	TIME [epoch: 7.45 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19715948449985946		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.19715948449985946 | validation: 0.13445920085405244]
	TIME [epoch: 7.45 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14082036640605455		[learning rate: 0.0088915]
	Learning Rate: 0.00889149
	LOSS [training: 0.14082036640605455 | validation: 0.10086609507889352]
	TIME [epoch: 7.48 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826857466160311		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.1826857466160311 | validation: 0.35534347934307475]
	TIME [epoch: 7.43 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34885893213897223		[learning rate: 0.0088496]
	Learning Rate: 0.00884959
	LOSS [training: 0.34885893213897223 | validation: 0.30888170611037935]
	TIME [epoch: 7.44 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23116864988634106		[learning rate: 0.0088287]
	Learning Rate: 0.00882871
	LOSS [training: 0.23116864988634106 | validation: 0.12158532902787725]
	TIME [epoch: 7.48 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427381556193881		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.2427381556193881 | validation: 0.22879111495865376]
	TIME [epoch: 7.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938629354775548		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.1938629354775548 | validation: 0.14957217370834808]
	TIME [epoch: 7.48 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18126333056477278		[learning rate: 0.0087664]
	Learning Rate: 0.00876638
	LOSS [training: 0.18126333056477278 | validation: 0.24848228594967292]
	TIME [epoch: 7.44 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19141553035408243		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.19141553035408243 | validation: 0.2598074678200676]
	TIME [epoch: 7.43 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849059846814742		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1849059846814742 | validation: 0.18336224752800054]
	TIME [epoch: 7.44 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24896758896104018		[learning rate: 0.0087045]
	Learning Rate: 0.00870449
	LOSS [training: 0.24896758896104018 | validation: 0.5192969168719219]
	TIME [epoch: 7.46 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29836174529417103		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29836174529417103 | validation: 0.2670696850700685]
	TIME [epoch: 7.48 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18570613051559606		[learning rate: 0.0086635]
	Learning Rate: 0.00866348
	LOSS [training: 0.18570613051559606 | validation: 0.14752815526988755]
	TIME [epoch: 7.43 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379967939141266		[learning rate: 0.008643]
	Learning Rate: 0.00864304
	LOSS [training: 0.17379967939141266 | validation: 0.14423871714528558]
	TIME [epoch: 7.43 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12696012716145866		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.12696012716145866 | validation: 0.15599073426722923]
	TIME [epoch: 7.43 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2207554712550562		[learning rate: 0.0086023]
	Learning Rate: 0.00860232
	LOSS [training: 0.2207554712550562 | validation: 0.22259640140561704]
	TIME [epoch: 7.45 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22514972584343942		[learning rate: 0.008582]
	Learning Rate: 0.00858202
	LOSS [training: 0.22514972584343942 | validation: 0.14532208160551122]
	TIME [epoch: 7.51 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29584086918572805		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.29584086918572805 | validation: 0.202365902428207]
	TIME [epoch: 7.43 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21418756493689672		[learning rate: 0.0085416]
	Learning Rate: 0.00854158
	LOSS [training: 0.21418756493689672 | validation: 0.12022931864459535]
	TIME [epoch: 7.44 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12504635007175852		[learning rate: 0.0085214]
	Learning Rate: 0.00852144
	LOSS [training: 0.12504635007175852 | validation: 0.13449201140816008]
	TIME [epoch: 7.45 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17386333792971048		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.17386333792971048 | validation: 0.23918373625621026]
	TIME [epoch: 7.46 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21967185621138588		[learning rate: 0.0084813]
	Learning Rate: 0.00848128
	LOSS [training: 0.21967185621138588 | validation: 0.20513268747109223]
	TIME [epoch: 7.49 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675891591647578		[learning rate: 0.0084613]
	Learning Rate: 0.00846128
	LOSS [training: 0.15675891591647578 | validation: 0.21914439436993208]
	TIME [epoch: 7.46 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16408485111320384		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.16408485111320384 | validation: 0.1241486310282127]
	TIME [epoch: 7.46 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10877159371714266		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.10877159371714266 | validation: 0.12132101972953738]
	TIME [epoch: 7.45 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404612002973956		[learning rate: 0.0084015]
	Learning Rate: 0.00840154
	LOSS [training: 0.2404612002973956 | validation: 0.2874261843097765]
	TIME [epoch: 7.48 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631536971144353		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2631536971144353 | validation: 0.14374047930359016]
	TIME [epoch: 7.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044476774587013		[learning rate: 0.008362]
	Learning Rate: 0.00836195
	LOSS [training: 0.13044476774587013 | validation: 0.11473398143780739]
	TIME [epoch: 7.47 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12170540715786517		[learning rate: 0.0083422]
	Learning Rate: 0.00834223
	LOSS [training: 0.12170540715786517 | validation: 0.14162655051547515]
	TIME [epoch: 7.47 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21532447584408299		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.21532447584408299 | validation: 0.1970718119709043]
	TIME [epoch: 7.46 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626081392065366		[learning rate: 0.0083029]
	Learning Rate: 0.00830292
	LOSS [training: 0.1626081392065366 | validation: 0.09140753656511111]
	TIME [epoch: 7.48 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263703261902906		[learning rate: 0.0082833]
	Learning Rate: 0.00828333
	LOSS [training: 0.1263703261902906 | validation: 0.14289079531747775]
	TIME [epoch: 7.49 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24991148875853625		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.24991148875853625 | validation: 0.14039297208903667]
	TIME [epoch: 7.47 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12356821120695595		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12356821120695595 | validation: 0.13123884602114322]
	TIME [epoch: 7.46 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17812766417591902		[learning rate: 0.0082249]
	Learning Rate: 0.00822485
	LOSS [training: 0.17812766417591902 | validation: 0.2663182851536441]
	TIME [epoch: 7.48 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17779972645144534		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.17779972645144534 | validation: 0.11078533662484474]
	TIME [epoch: 7.47 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724815345561503		[learning rate: 0.0081861]
	Learning Rate: 0.0081861
	LOSS [training: 0.13724815345561503 | validation: 0.07652791245355758]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106994017404522		[learning rate: 0.0081668]
	Learning Rate: 0.00816679
	LOSS [training: 0.106994017404522 | validation: 0.3663671971546382]
	TIME [epoch: 7.45 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28389103002657806		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.28389103002657806 | validation: 0.14467268200040573]
	TIME [epoch: 7.46 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484684450919842		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.1484684450919842 | validation: 0.204173700261162]
	TIME [epoch: 7.48 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18157780549813926		[learning rate: 0.0081091]
	Learning Rate: 0.00810913
	LOSS [training: 0.18157780549813926 | validation: 0.0968361377788509]
	TIME [epoch: 7.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153369934969811		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.12153369934969811 | validation: 0.14575523263916984]
	TIME [epoch: 7.51 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12491805678024925		[learning rate: 0.0080709]
	Learning Rate: 0.00807092
	LOSS [training: 0.12491805678024925 | validation: 0.17165931862151046]
	TIME [epoch: 7.45 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558153137268453		[learning rate: 0.0080519]
	Learning Rate: 0.00805188
	LOSS [training: 0.13558153137268453 | validation: 0.12842320702206522]
	TIME [epoch: 7.45 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142723511424579		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.11142723511424579 | validation: 0.13060323213805414]
	TIME [epoch: 7.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575809614245316		[learning rate: 0.0080139]
	Learning Rate: 0.00801394
	LOSS [training: 0.13575809614245316 | validation: 0.21370018532960514]
	TIME [epoch: 7.47 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712063660621965		[learning rate: 0.007995]
	Learning Rate: 0.00799504
	LOSS [training: 0.13712063660621965 | validation: 0.07938215255148692]
	TIME [epoch: 7.51 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11413520293887455		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.11413520293887455 | validation: 0.12564314470148033]
	TIME [epoch: 7.45 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017051688333196		[learning rate: 0.0079574]
	Learning Rate: 0.00795736
	LOSS [training: 0.14017051688333196 | validation: 0.09762499967606526]
	TIME [epoch: 7.46 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14425570126053694		[learning rate: 0.0079386]
	Learning Rate: 0.00793859
	LOSS [training: 0.14425570126053694 | validation: 0.10226755683779196]
	TIME [epoch: 7.45 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679874652158736		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.10679874652158736 | validation: 0.1328977623035527]
	TIME [epoch: 7.46 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119296335551335		[learning rate: 0.0079012]
	Learning Rate: 0.00790119
	LOSS [training: 0.11119296335551335 | validation: 0.5231594450498285]
	TIME [epoch: 7.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667673746162525		[learning rate: 0.0078825]
	Learning Rate: 0.00788255
	LOSS [training: 0.2667673746162525 | validation: 0.07644598535206724]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936273899233875		[learning rate: 0.007864]
	Learning Rate: 0.00786396
	LOSS [training: 0.08936273899233875 | validation: 0.08731037499256064]
	TIME [epoch: 7.45 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705058692842994		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.09705058692842994 | validation: 0.06849657685291653]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133665131233087		[learning rate: 0.0078269]
	Learning Rate: 0.0078269
	LOSS [training: 0.133665131233087 | validation: 0.1365890628001232]
	TIME [epoch: 7.47 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043519408222561		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.12043519408222561 | validation: 0.21220714888834077]
	TIME [epoch: 7.47 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11455218679653846		[learning rate: 0.00779]
	Learning Rate: 0.00779002
	LOSS [training: 0.11455218679653846 | validation: 0.08479547069761106]
	TIME [epoch: 7.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14300998419214636		[learning rate: 0.0077716]
	Learning Rate: 0.00777164
	LOSS [training: 0.14300998419214636 | validation: 0.2822563323108777]
	TIME [epoch: 7.43 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756350667952894		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2756350667952894 | validation: 0.142754804142868]
	TIME [epoch: 7.43 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870841299796846		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.10870841299796846 | validation: 0.1152042241947389]
	TIME [epoch: 7.47 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201052216978064		[learning rate: 0.0077168]
	Learning Rate: 0.00771678
	LOSS [training: 0.08201052216978064 | validation: 0.07272378895965388]
	TIME [epoch: 7.47 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616516213599747		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.10616516213599747 | validation: 0.12867931532725907]
	TIME [epoch: 7.44 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991659350655986		[learning rate: 0.0076804]
	Learning Rate: 0.00768041
	LOSS [training: 0.0991659350655986 | validation: 0.09663711472674871]
	TIME [epoch: 7.43 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050654668107325		[learning rate: 0.0076623]
	Learning Rate: 0.0076623
	LOSS [training: 0.12050654668107325 | validation: 0.10318935413140429]
	TIME [epoch: 7.44 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383224486449113		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.11383224486449113 | validation: 0.07000787539761721]
	TIME [epoch: 7.45 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203954394514166		[learning rate: 0.0076262]
	Learning Rate: 0.00762619
	LOSS [training: 0.1203954394514166 | validation: 0.11785895817727243]
	TIME [epoch: 7.48 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252769208659854		[learning rate: 0.0076082]
	Learning Rate: 0.0076082
	LOSS [training: 0.12252769208659854 | validation: 0.0726926430411727]
	TIME [epoch: 7.44 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020632903195709		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.10020632903195709 | validation: 0.0901726982702075]
	TIME [epoch: 7.43 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186589758053991		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.1186589758053991 | validation: 0.06241803918471035]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1072244420101763		[learning rate: 0.0075545]
	Learning Rate: 0.00755449
	LOSS [training: 0.1072244420101763 | validation: 0.06714249041350023]
	TIME [epoch: 7.46 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06231217175216308		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.06231217175216308 | validation: 0.09074576381005994]
	TIME [epoch: 7.47 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2105962606014119		[learning rate: 0.0075189]
	Learning Rate: 0.00751889
	LOSS [training: 0.2105962606014119 | validation: 0.20115748159233132]
	TIME [epoch: 7.43 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630149430821935		[learning rate: 0.0075012]
	Learning Rate: 0.00750116
	LOSS [training: 0.12630149430821935 | validation: 0.05524032946346803]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058732647313979425		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.058732647313979425 | validation: 0.07692079731806795]
	TIME [epoch: 7.46 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17791980710939923		[learning rate: 0.0074658]
	Learning Rate: 0.00746581
	LOSS [training: 0.17791980710939923 | validation: 0.24505740875557136]
	TIME [epoch: 7.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18335782530582373		[learning rate: 0.0074482]
	Learning Rate: 0.0074482
	LOSS [training: 0.18335782530582373 | validation: 0.10038749973532442]
	TIME [epoch: 7.47 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214667121670233		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.08214667121670233 | validation: 0.04860400407497702]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07191241195146383		[learning rate: 0.0074131]
	Learning Rate: 0.0074131
	LOSS [training: 0.07191241195146383 | validation: 0.14908676684790315]
	TIME [epoch: 7.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237224018946109		[learning rate: 0.0073956]
	Learning Rate: 0.00739562
	LOSS [training: 0.12237224018946109 | validation: 0.22700601633631706]
	TIME [epoch: 7.46 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646254709947021		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.11646254709947021 | validation: 0.04054424817845659]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344372552300595		[learning rate: 0.0073608]
	Learning Rate: 0.00736077
	LOSS [training: 0.06344372552300595 | validation: 0.06537428244727032]
	TIME [epoch: 7.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297852718401739		[learning rate: 0.0073434]
	Learning Rate: 0.0073434
	LOSS [training: 0.06297852718401739 | validation: 0.19226794414294673]
	TIME [epoch: 7.45 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13000359344688908		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.13000359344688908 | validation: 0.07684859369329587]
	TIME [epoch: 7.46 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13997645102550305		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.13997645102550305 | validation: 0.06548743799510348]
	TIME [epoch: 7.45 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060188198192899944		[learning rate: 0.0072916]
	Learning Rate: 0.00729156
	LOSS [training: 0.060188198192899944 | validation: 0.08156126900604461]
	TIME [epoch: 7.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835035756805245		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.10835035756805245 | validation: 0.1458958634080289]
	TIME [epoch: 7.49 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09371400930256965		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.09371400930256965 | validation: 0.05885548018152007]
	TIME [epoch: 7.45 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22349272596556138		[learning rate: 0.0072401]
	Learning Rate: 0.00724008
	LOSS [training: 0.22349272596556138 | validation: 0.39278141293266394]
	TIME [epoch: 7.46 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339875546877428		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.3339875546877428 | validation: 0.16907259402738467]
	TIME [epoch: 7.46 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552656275586909		[learning rate: 0.007206]
	Learning Rate: 0.00720597
	LOSS [training: 0.1552656275586909 | validation: 0.1074476736761577]
	TIME [epoch: 7.51 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969748338216885		[learning rate: 0.007189]
	Learning Rate: 0.00718897
	LOSS [training: 0.0969748338216885 | validation: 0.06017938638196171]
	TIME [epoch: 7.46 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762917463400436		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.05762917463400436 | validation: 0.05926961654271194]
	TIME [epoch: 7.48 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11608199647343267		[learning rate: 0.0071551]
	Learning Rate: 0.00715509
	LOSS [training: 0.11608199647343267 | validation: 0.07704780992748086]
	TIME [epoch: 7.45 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510977887881447		[learning rate: 0.0071382]
	Learning Rate: 0.00713822
	LOSS [training: 0.06510977887881447 | validation: 0.10930124938255656]
	TIME [epoch: 7.46 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09815926714018255		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.09815926714018255 | validation: 0.06263854295775946]
	TIME [epoch: 7.49 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123983713482495		[learning rate: 0.0071046]
	Learning Rate: 0.00710458
	LOSS [training: 0.08123983713482495 | validation: 0.05113684222199455]
	TIME [epoch: 7.49 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830340761869901		[learning rate: 0.0070878]
	Learning Rate: 0.00708782
	LOSS [training: 0.08830340761869901 | validation: 0.17810423953073454]
	TIME [epoch: 7.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15252164521343128		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.15252164521343128 | validation: 0.0880490429506914]
	TIME [epoch: 7.49 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073546961338869		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.06073546961338869 | validation: 0.04692702504739754]
	TIME [epoch: 7.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05428086283197385		[learning rate: 0.0070378]
	Learning Rate: 0.00703778
	LOSS [training: 0.05428086283197385 | validation: 0.060543546513821656]
	TIME [epoch: 7.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928953665437244		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.10928953665437244 | validation: 0.07173545468464795]
	TIME [epoch: 7.47 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06053921638785177		[learning rate: 0.0070046]
	Learning Rate: 0.00700462
	LOSS [training: 0.06053921638785177 | validation: 0.07247172429999565]
	TIME [epoch: 129 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203752403712049		[learning rate: 0.0069881]
	Learning Rate: 0.0069881
	LOSS [training: 0.07203752403712049 | validation: 0.060050743818806276]
	TIME [epoch: 14.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09035938976150097		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.09035938976150097 | validation: 0.09752225849176738]
	TIME [epoch: 14.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186636965550869		[learning rate: 0.0069552]
	Learning Rate: 0.00695517
	LOSS [training: 0.07186636965550869 | validation: 0.04926120651440329]
	TIME [epoch: 14.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416334066906748		[learning rate: 0.0069388]
	Learning Rate: 0.00693876
	LOSS [training: 0.06416334066906748 | validation: 0.08426667145563688]
	TIME [epoch: 14.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187198423963942		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.06187198423963942 | validation: 0.07440744077388159]
	TIME [epoch: 14.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08566681589678155		[learning rate: 0.0069061]
	Learning Rate: 0.00690607
	LOSS [training: 0.08566681589678155 | validation: 0.06857706656520791]
	TIME [epoch: 14.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539698605063353		[learning rate: 0.0068898]
	Learning Rate: 0.00688978
	LOSS [training: 0.08539698605063353 | validation: 0.08113665784557642]
	TIME [epoch: 14.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07368986429974937		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.07368986429974937 | validation: 0.04813339762606195]
	TIME [epoch: 14.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876486757224923		[learning rate: 0.0068573]
	Learning Rate: 0.00685731
	LOSS [training: 0.08876486757224923 | validation: 0.11748118185652094]
	TIME [epoch: 14.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832830266586391		[learning rate: 0.0068411]
	Learning Rate: 0.00684114
	LOSS [training: 0.0832830266586391 | validation: 0.08429544265498626]
	TIME [epoch: 14.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242878925980497		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.12242878925980497 | validation: 0.12225577215426614]
	TIME [epoch: 14.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691326982542268		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.0691326982542268 | validation: 0.04145816932095761]
	TIME [epoch: 14.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03993145753214161		[learning rate: 0.0067928]
	Learning Rate: 0.00679284
	LOSS [training: 0.03993145753214161 | validation: 0.04910613328748538]
	TIME [epoch: 14.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508153462689509		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.05508153462689509 | validation: 0.07024833559273788]
	TIME [epoch: 14.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07207494877589123		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.07207494877589123 | validation: 0.05763246713064725]
	TIME [epoch: 14.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175927509822754		[learning rate: 0.0067449]
	Learning Rate: 0.00674488
	LOSS [training: 0.09175927509822754 | validation: 0.05870218647275077]
	TIME [epoch: 14.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489570764211703		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.10489570764211703 | validation: 0.10067215195596947]
	TIME [epoch: 14.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0514221553337114		[learning rate: 0.0067131]
	Learning Rate: 0.0067131
	LOSS [training: 0.0514221553337114 | validation: 0.04985686310857969]
	TIME [epoch: 14.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354878741886583		[learning rate: 0.0066973]
	Learning Rate: 0.00669726
	LOSS [training: 0.08354878741886583 | validation: 0.037588102466891926]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04070953660420111		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.04070953660420111 | validation: 1.1620897711840548]
	TIME [epoch: 14.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273152731692494		[learning rate: 0.0066657]
	Learning Rate: 0.00666571
	LOSS [training: 0.4273152731692494 | validation: 0.1014786012225965]
	TIME [epoch: 14.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823826890672476		[learning rate: 0.00665]
	Learning Rate: 0.00664998
	LOSS [training: 0.0823826890672476 | validation: 0.07090090900975543]
	TIME [epoch: 14.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07247503583010419		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.07247503583010419 | validation: 0.05694935553331507]
	TIME [epoch: 14.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723058110065423		[learning rate: 0.0066186]
	Learning Rate: 0.00661865
	LOSS [training: 0.0723058110065423 | validation: 0.102111623952649]
	TIME [epoch: 14.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964621580168959		[learning rate: 0.006603]
	Learning Rate: 0.00660304
	LOSS [training: 0.06964621580168959 | validation: 0.07146601643568062]
	TIME [epoch: 14.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05248139101909902		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.05248139101909902 | validation: 0.08614127407702979]
	TIME [epoch: 14.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956275477250123		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.0956275477250123 | validation: 0.07211021603140189]
	TIME [epoch: 14.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045979153949872176		[learning rate: 0.0065564]
	Learning Rate: 0.00655642
	LOSS [training: 0.045979153949872176 | validation: 0.1515933999406059]
	TIME [epoch: 14.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064129088133048		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.11064129088133048 | validation: 0.03295579600849556]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416872987208682		[learning rate: 0.0065255]
	Learning Rate: 0.00652552
	LOSS [training: 0.05416872987208682 | validation: 0.0424319986899986]
	TIME [epoch: 14.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04995390023410015		[learning rate: 0.0065101]
	Learning Rate: 0.00651013
	LOSS [training: 0.04995390023410015 | validation: 0.0964316516015794]
	TIME [epoch: 14.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429409725878313		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.05429409725878313 | validation: 0.04109919132625217]
	TIME [epoch: 14.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492818941376115		[learning rate: 0.0064795]
	Learning Rate: 0.00647945
	LOSS [training: 0.05492818941376115 | validation: 0.11388995201339144]
	TIME [epoch: 14.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07710172003662323		[learning rate: 0.0064642]
	Learning Rate: 0.00646417
	LOSS [training: 0.07710172003662323 | validation: 0.038301373185506055]
	TIME [epoch: 14.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383932017047447		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.04383932017047447 | validation: 0.0596477071038645]
	TIME [epoch: 14.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060175535314732194		[learning rate: 0.0064337]
	Learning Rate: 0.00643371
	LOSS [training: 0.060175535314732194 | validation: 0.04007692264187683]
	TIME [epoch: 14.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03839159284361345		[learning rate: 0.0064185]
	Learning Rate: 0.00641853
	LOSS [training: 0.03839159284361345 | validation: 0.06454736719148112]
	TIME [epoch: 14.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05846678072473157		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.05846678072473157 | validation: 0.052410571705374845]
	TIME [epoch: 14.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969044585222917		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.06969044585222917 | validation: 0.07843757746388323]
	TIME [epoch: 14.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574105868953271		[learning rate: 0.0063732]
	Learning Rate: 0.00637322
	LOSS [training: 0.0574105868953271 | validation: 0.0712662935528375]
	TIME [epoch: 14.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623955356785413		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.04623955356785413 | validation: 0.06296558130000351]
	TIME [epoch: 14.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053178104621353854		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.053178104621353854 | validation: 0.03531535123884026]
	TIME [epoch: 14.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08378129144255703		[learning rate: 0.0063282]
	Learning Rate: 0.00632823
	LOSS [training: 0.08378129144255703 | validation: 0.0593224260377056]
	TIME [epoch: 14.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04904818421919238		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.04904818421919238 | validation: 0.025320395370543543]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04567665892546344		[learning rate: 0.0062984]
	Learning Rate: 0.00629841
	LOSS [training: 0.04567665892546344 | validation: 0.03299996544959557]
	TIME [epoch: 14.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789675597863344		[learning rate: 0.0062836]
	Learning Rate: 0.00628355
	LOSS [training: 0.07789675597863344 | validation: 0.04728030556474064]
	TIME [epoch: 14.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057628300581001206		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.057628300581001206 | validation: 0.0367765136171256]
	TIME [epoch: 14.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423239146976338		[learning rate: 0.0062539]
	Learning Rate: 0.00625394
	LOSS [training: 0.04423239146976338 | validation: 0.07243526193956856]
	TIME [epoch: 14.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0411282372844977		[learning rate: 0.0062392]
	Learning Rate: 0.00623919
	LOSS [training: 0.0411282372844977 | validation: 0.04584914374217964]
	TIME [epoch: 14.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377866082781074		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.03377866082781074 | validation: 0.03446799264208888]
	TIME [epoch: 14.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06111979884430664		[learning rate: 0.0062098]
	Learning Rate: 0.00620979
	LOSS [training: 0.06111979884430664 | validation: 0.10078752774325814]
	TIME [epoch: 14.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050434292549647104		[learning rate: 0.0061951]
	Learning Rate: 0.00619514
	LOSS [training: 0.050434292549647104 | validation: 0.028220443798346647]
	TIME [epoch: 14.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116166757141685		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.05116166757141685 | validation: 0.06744414956169889]
	TIME [epoch: 14.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101735771804344		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.04101735771804344 | validation: 0.051299432251947566]
	TIME [epoch: 14.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05014825729607322		[learning rate: 0.0061514]
	Learning Rate: 0.00615141
	LOSS [training: 0.05014825729607322 | validation: 0.06357001206799426]
	TIME [epoch: 14.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049840755497815		[learning rate: 0.0061369]
	Learning Rate: 0.0061369
	LOSS [training: 0.049840755497815 | validation: 0.056294433816060974]
	TIME [epoch: 14.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03643750328179238		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.03643750328179238 | validation: 0.019547911108191957]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802347461890024		[learning rate: 0.006108]
	Learning Rate: 0.00610798
	LOSS [training: 0.03802347461890024 | validation: 0.06427726425329144]
	TIME [epoch: 14.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991444373700836		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.0991444373700836 | validation: 0.06573026731583059]
	TIME [epoch: 14.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056948124307118625		[learning rate: 0.0060792]
	Learning Rate: 0.0060792
	LOSS [training: 0.056948124307118625 | validation: 0.0785810590878102]
	TIME [epoch: 14.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056222729907124167		[learning rate: 0.0060649]
	Learning Rate: 0.00606486
	LOSS [training: 0.056222729907124167 | validation: 0.04720720777651873]
	TIME [epoch: 14.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035238639583256195		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.035238639583256195 | validation: 0.025761059774875375]
	TIME [epoch: 14.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624330463215028		[learning rate: 0.0060363]
	Learning Rate: 0.00603628
	LOSS [training: 0.12624330463215028 | validation: 0.07174440867776782]
	TIME [epoch: 14.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168361095630797		[learning rate: 0.006022]
	Learning Rate: 0.00602204
	LOSS [training: 0.04168361095630797 | validation: 0.02549083962830006]
	TIME [epoch: 14.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019997440959977936		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.019997440959977936 | validation: 0.018994608573107027]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025717948060339682		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.025717948060339682 | validation: 0.06943572672265969]
	TIME [epoch: 14.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06765050560270502		[learning rate: 0.0059795]
	Learning Rate: 0.00597952
	LOSS [training: 0.06765050560270502 | validation: 0.034164195150497484]
	TIME [epoch: 14.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025803474295769506		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.025803474295769506 | validation: 0.028924031799003876]
	TIME [epoch: 14.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02721440782075569		[learning rate: 0.0059513]
	Learning Rate: 0.00595135
	LOSS [training: 0.02721440782075569 | validation: 0.0441633854777851]
	TIME [epoch: 14.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06153708674665815		[learning rate: 0.0059373]
	Learning Rate: 0.00593731
	LOSS [training: 0.06153708674665815 | validation: 0.05128502854905383]
	TIME [epoch: 14.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040864554203079106		[learning rate: 0.0059233]
	Learning Rate: 0.00592331
	LOSS [training: 0.040864554203079106 | validation: 0.026918320943830256]
	TIME [epoch: 14.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027183458111296376		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.027183458111296376 | validation: 0.06435061112880291]
	TIME [epoch: 14.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08673401583295261		[learning rate: 0.0058954]
	Learning Rate: 0.00589539
	LOSS [training: 0.08673401583295261 | validation: 0.048376696407809415]
	TIME [epoch: 14.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04014168380628673		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.04014168380628673 | validation: 0.054589792418503466]
	TIME [epoch: 14.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668750032500336		[learning rate: 0.0058676]
	Learning Rate: 0.00586761
	LOSS [training: 0.02668750032500336 | validation: 0.04925008614092865]
	TIME [epoch: 14.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968408182818683		[learning rate: 0.0058538]
	Learning Rate: 0.00585377
	LOSS [training: 0.05968408182818683 | validation: 0.04221580017825794]
	TIME [epoch: 14.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022984529298073493		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.022984529298073493 | validation: 0.0285424183288833]
	TIME [epoch: 14.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577575154462196		[learning rate: 0.0058262]
	Learning Rate: 0.00582619
	LOSS [training: 0.03577575154462196 | validation: 0.03835282530856818]
	TIME [epoch: 14.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035292920629927296		[learning rate: 0.0058124]
	Learning Rate: 0.00581245
	LOSS [training: 0.035292920629927296 | validation: 0.035439460074714595]
	TIME [epoch: 14.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037638746949057		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.037638746949057 | validation: 0.020523020096782425]
	TIME [epoch: 14.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367717219971273		[learning rate: 0.0057851]
	Learning Rate: 0.00578506
	LOSS [training: 0.03367717219971273 | validation: 0.028001126125191476]
	TIME [epoch: 14.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033766383055934414		[learning rate: 0.0057714]
	Learning Rate: 0.00577141
	LOSS [training: 0.033766383055934414 | validation: 0.07798623948373029]
	TIME [epoch: 14.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06433447088826713		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.06433447088826713 | validation: 0.03073046527971339]
	TIME [epoch: 14.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742110893677271		[learning rate: 0.0057442]
	Learning Rate: 0.00574422
	LOSS [training: 0.0742110893677271 | validation: 0.14607843386111669]
	TIME [epoch: 14.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10383778590178412		[learning rate: 0.0057307]
	Learning Rate: 0.00573067
	LOSS [training: 0.10383778590178412 | validation: 0.04252166782737674]
	TIME [epoch: 14.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125301257748531		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.05125301257748531 | validation: 0.08869901282796414]
	TIME [epoch: 14.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035151918623343735		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.035151918623343735 | validation: 0.05508764235319094]
	TIME [epoch: 14.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02840610361770514		[learning rate: 0.0056902]
	Learning Rate: 0.00569021
	LOSS [training: 0.02840610361770514 | validation: 0.05984008352616535]
	TIME [epoch: 14.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721667754432962		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.03721667754432962 | validation: 0.03584510414726888]
	TIME [epoch: 14.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887842826111072		[learning rate: 0.0056634]
	Learning Rate: 0.0056634
	LOSS [training: 0.03887842826111072 | validation: 0.07862118913179542]
	TIME [epoch: 14.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041095350541526715		[learning rate: 0.00565]
	Learning Rate: 0.00565004
	LOSS [training: 0.041095350541526715 | validation: 0.04276826933314118]
	TIME [epoch: 14.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040837857436545326		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.040837857436545326 | validation: 0.02201401988493837]
	TIME [epoch: 14.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017605552559675032		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.017605552559675032 | validation: 0.06106454164453398]
	TIME [epoch: 14.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05374489718819914		[learning rate: 0.0056101]
	Learning Rate: 0.00561015
	LOSS [training: 0.05374489718819914 | validation: 0.04003806975657609]
	TIME [epoch: 14.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0416869155303347		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.0416869155303347 | validation: 0.020192209601707083]
	TIME [epoch: 14.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025540310944318093		[learning rate: 0.0055837]
	Learning Rate: 0.00558371
	LOSS [training: 0.025540310944318093 | validation: 0.029976115067227027]
	TIME [epoch: 14.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242299122792981		[learning rate: 0.0055705]
	Learning Rate: 0.00557054
	LOSS [training: 0.04242299122792981 | validation: 0.03296011967867415]
	TIME [epoch: 14.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023415964669923767		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.023415964669923767 | validation: 0.017273174655195407]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986013258284647		[learning rate: 0.0055443]
	Learning Rate: 0.00554429
	LOSS [training: 0.03986013258284647 | validation: 0.044875391042055984]
	TIME [epoch: 14.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034016914424950986		[learning rate: 0.0055312]
	Learning Rate: 0.00553121
	LOSS [training: 0.034016914424950986 | validation: 0.041904777709686966]
	TIME [epoch: 14.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022997657778246874		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.022997657778246874 | validation: 0.02646726924314305]
	TIME [epoch: 14.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039447607431905306		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.039447607431905306 | validation: 0.03527334320521255]
	TIME [epoch: 14.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028434143785323145		[learning rate: 0.0054922]
	Learning Rate: 0.00549216
	LOSS [training: 0.028434143785323145 | validation: 0.026095291156413573]
	TIME [epoch: 14.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034885042346097905		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.034885042346097905 | validation: 0.07448267408274398]
	TIME [epoch: 14.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708447628545968		[learning rate: 0.0054663]
	Learning Rate: 0.00546629
	LOSS [training: 0.03708447628545968 | validation: 0.03344145826598551]
	TIME [epoch: 14.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028185814778771804		[learning rate: 0.0054534]
	Learning Rate: 0.00545339
	LOSS [training: 0.028185814778771804 | validation: 0.03425461737710658]
	TIME [epoch: 14.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02835491165300082		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.02835491165300082 | validation: 0.03460921180831092]
	TIME [epoch: 14.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02945767329547507		[learning rate: 0.0054277]
	Learning Rate: 0.00542769
	LOSS [training: 0.02945767329547507 | validation: 0.02755507869471272]
	TIME [epoch: 14.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02463100518844651		[learning rate: 0.0054149]
	Learning Rate: 0.00541489
	LOSS [training: 0.02463100518844651 | validation: 0.042576584352620614]
	TIME [epoch: 14.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03134275197321027		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.03134275197321027 | validation: 0.05257499999133228]
	TIME [epoch: 14.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02983182531400757		[learning rate: 0.0053894]
	Learning Rate: 0.00538938
	LOSS [training: 0.02983182531400757 | validation: 0.14163674209820107]
	TIME [epoch: 14.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294725073307939		[learning rate: 0.0053767]
	Learning Rate: 0.00537666
	LOSS [training: 0.08294725073307939 | validation: 0.03157111648741974]
	TIME [epoch: 14.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022680322420616288		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.022680322420616288 | validation: 0.020090861208101104]
	TIME [epoch: 14.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024654845140779896		[learning rate: 0.0053513]
	Learning Rate: 0.00535133
	LOSS [training: 0.024654845140779896 | validation: 0.04053062338515126]
	TIME [epoch: 14.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04960257104217884		[learning rate: 0.0053387]
	Learning Rate: 0.00533871
	LOSS [training: 0.04960257104217884 | validation: 0.03754521024715282]
	TIME [epoch: 14.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031205013802377522		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.031205013802377522 | validation: 0.07107255362410639]
	TIME [epoch: 14.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037101427252647805		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.037101427252647805 | validation: 0.014666842212007624]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020382297224364937		[learning rate: 0.005301]
	Learning Rate: 0.00530101
	LOSS [training: 0.020382297224364937 | validation: 0.027600738209937282]
	TIME [epoch: 14.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016619785720189087		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.016619785720189087 | validation: 0.018173097040827927]
	TIME [epoch: 14.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02664482483622213		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.02664482483622213 | validation: 0.06502414639584504]
	TIME [epoch: 14.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03690174992870632		[learning rate: 0.0052636]
	Learning Rate: 0.00526359
	LOSS [training: 0.03690174992870632 | validation: 0.06402865121001011]
	TIME [epoch: 14.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153876055465251		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.03153876055465251 | validation: 0.017372091155885474]
	TIME [epoch: 14.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022514676500429515		[learning rate: 0.0052388]
	Learning Rate: 0.00523879
	LOSS [training: 0.022514676500429515 | validation: 0.08073548489845606]
	TIME [epoch: 14.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04497340034732075		[learning rate: 0.0052264]
	Learning Rate: 0.00522643
	LOSS [training: 0.04497340034732075 | validation: 0.01779906656414657]
	TIME [epoch: 14.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014475708622172293		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.014475708622172293 | validation: 0.042702142323279874]
	TIME [epoch: 14.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029844151164408382		[learning rate: 0.0052018]
	Learning Rate: 0.0052018
	LOSS [training: 0.029844151164408382 | validation: 0.01873939774705039]
	TIME [epoch: 14.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298457783485097		[learning rate: 0.0051895]
	Learning Rate: 0.00518953
	LOSS [training: 0.04298457783485097 | validation: 0.04423544775362496]
	TIME [epoch: 14.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041181319693226096		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.041181319693226096 | validation: 0.02915145188031158]
	TIME [epoch: 14.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01471067045188551		[learning rate: 0.0051651]
	Learning Rate: 0.00516508
	LOSS [training: 0.01471067045188551 | validation: 0.013434415209684431]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021708855439880076		[learning rate: 0.0051529]
	Learning Rate: 0.00515289
	LOSS [training: 0.021708855439880076 | validation: 0.04267107030801743]
	TIME [epoch: 14.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047859434244680324		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.047859434244680324 | validation: 0.03130479015994155]
	TIME [epoch: 14.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019114855041232302		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.019114855041232302 | validation: 0.013682251737594943]
	TIME [epoch: 14.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050899221375595		[learning rate: 0.0051165]
	Learning Rate: 0.00511652
	LOSS [training: 0.03050899221375595 | validation: 0.05384753059009477]
	TIME [epoch: 14.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346153557824679		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.03346153557824679 | validation: 0.020300413171960303]
	TIME [epoch: 14.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012948185446181348		[learning rate: 0.0050924]
	Learning Rate: 0.00509241
	LOSS [training: 0.012948185446181348 | validation: 0.012862593001234695]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027380036730339372		[learning rate: 0.0050804]
	Learning Rate: 0.00508039
	LOSS [training: 0.027380036730339372 | validation: 0.030928585802624014]
	TIME [epoch: 14.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032878882449250066		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.032878882449250066 | validation: 0.018151987883608944]
	TIME [epoch: 14.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028534247179466767		[learning rate: 0.0050565]
	Learning Rate: 0.00505645
	LOSS [training: 0.028534247179466767 | validation: 0.02040099728747831]
	TIME [epoch: 14.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013819641520071445		[learning rate: 0.0050445]
	Learning Rate: 0.00504453
	LOSS [training: 0.013819641520071445 | validation: 0.015204798966613618]
	TIME [epoch: 14.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023962564277944524		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.023962564277944524 | validation: 0.07858865876175523]
	TIME [epoch: 14.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03854550794957497		[learning rate: 0.0050208]
	Learning Rate: 0.00502076
	LOSS [training: 0.03854550794957497 | validation: 0.0162070570304541]
	TIME [epoch: 14.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011855587296367232		[learning rate: 0.0050089]
	Learning Rate: 0.00500891
	LOSS [training: 0.011855587296367232 | validation: 0.02730889696155482]
	TIME [epoch: 14.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387215970702496		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.03387215970702496 | validation: 0.02707853212658422]
	TIME [epoch: 14.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019838194219012496		[learning rate: 0.0049853]
	Learning Rate: 0.00498531
	LOSS [training: 0.019838194219012496 | validation: 0.02016326883166572]
	TIME [epoch: 14.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026311569090294952		[learning rate: 0.0049736]
	Learning Rate: 0.00497355
	LOSS [training: 0.026311569090294952 | validation: 0.03917976037216685]
	TIME [epoch: 14.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640364898159679		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.03640364898159679 | validation: 0.018648283163760417]
	TIME [epoch: 14.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01446623327166129		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.01446623327166129 | validation: 0.027011933541125105]
	TIME [epoch: 14.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017600754323188597		[learning rate: 0.0049384]
	Learning Rate: 0.00493844
	LOSS [training: 0.017600754323188597 | validation: 0.013512633814162331]
	TIME [epoch: 14.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803567497684782		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.03803567497684782 | validation: 0.04353996958987248]
	TIME [epoch: 14.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022122843240466906		[learning rate: 0.0049152]
	Learning Rate: 0.00491517
	LOSS [training: 0.022122843240466906 | validation: 0.021447240770345207]
	TIME [epoch: 14.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013363759157791595		[learning rate: 0.0049036]
	Learning Rate: 0.00490357
	LOSS [training: 0.013363759157791595 | validation: 0.011677523430412728]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022739117853182507		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.022739117853182507 | validation: 0.05448668394520257]
	TIME [epoch: 14.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673756127527242		[learning rate: 0.0048805]
	Learning Rate: 0.00488047
	LOSS [training: 0.03673756127527242 | validation: 0.03280172415701649]
	TIME [epoch: 14.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02306228479239584		[learning rate: 0.004869]
	Learning Rate: 0.00486896
	LOSS [training: 0.02306228479239584 | validation: 0.014645067333636408]
	TIME [epoch: 14.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02958610990661144		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.02958610990661144 | validation: 0.05591902469726061]
	TIME [epoch: 14.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02609163229957797		[learning rate: 0.004846]
	Learning Rate: 0.00484601
	LOSS [training: 0.02609163229957797 | validation: 0.014281227777319485]
	TIME [epoch: 14.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019250573767339955		[learning rate: 0.0048346]
	Learning Rate: 0.00483458
	LOSS [training: 0.019250573767339955 | validation: 0.021336266609671386]
	TIME [epoch: 14.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01332833091107681		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.01332833091107681 | validation: 0.01800770165489603]
	TIME [epoch: 14.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039311357066694724		[learning rate: 0.0048118]
	Learning Rate: 0.0048118
	LOSS [training: 0.039311357066694724 | validation: 0.025360935275019744]
	TIME [epoch: 14.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013038468399072587		[learning rate: 0.0048005]
	Learning Rate: 0.00480045
	LOSS [training: 0.013038468399072587 | validation: 0.0122622365978501]
	TIME [epoch: 14.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014039324420930217		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.014039324420930217 | validation: 0.023204473556550927]
	TIME [epoch: 14.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528972248741388		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.03528972248741388 | validation: 0.03608152003717764]
	TIME [epoch: 14.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024065365277313355		[learning rate: 0.0047666]
	Learning Rate: 0.00476656
	LOSS [training: 0.024065365277313355 | validation: 0.03610348189188897]
	TIME [epoch: 14.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019015083719771737		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.019015083719771737 | validation: 0.016375161671110385]
	TIME [epoch: 14.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029993217106763077		[learning rate: 0.0047441]
	Learning Rate: 0.0047441
	LOSS [training: 0.029993217106763077 | validation: 0.011721783119453271]
	TIME [epoch: 14.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020300460172095483		[learning rate: 0.0047329]
	Learning Rate: 0.00473291
	LOSS [training: 0.020300460172095483 | validation: 0.01865924845201964]
	TIME [epoch: 14.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011105500353352008		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.011105500353352008 | validation: 0.02189365529262494]
	TIME [epoch: 14.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621771734018213		[learning rate: 0.0047106]
	Learning Rate: 0.00471061
	LOSS [training: 0.03621771734018213 | validation: 0.02423130911525139]
	TIME [epoch: 14.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09110282193866034		[learning rate: 0.0046995]
	Learning Rate: 0.0046995
	LOSS [training: 0.09110282193866034 | validation: 0.3312424399821621]
	TIME [epoch: 14.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554059830607986		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.1554059830607986 | validation: 0.05861087875162372]
	TIME [epoch: 14.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660472502044985		[learning rate: 0.0046774]
	Learning Rate: 0.00467735
	LOSS [training: 0.04660472502044985 | validation: 0.03195286066313585]
	TIME [epoch: 14.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248308144461044		[learning rate: 0.0046663]
	Learning Rate: 0.00466632
	LOSS [training: 0.0248308144461044 | validation: 0.01275470651289966]
	TIME [epoch: 14.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015082448571707395		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.015082448571707395 | validation: 0.011335269921220525]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018723246525623002		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.018723246525623002 | validation: 0.016860948166533524]
	TIME [epoch: 14.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451013335032257		[learning rate: 0.0046334]
	Learning Rate: 0.00463338
	LOSS [training: 0.03451013335032257 | validation: 0.02041509882721032]
	TIME [epoch: 14.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018740821867516022		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.018740821867516022 | validation: 0.03054068170611282]
	TIME [epoch: 14.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013656371078057		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.02013656371078057 | validation: 0.012398323404095074]
	TIME [epoch: 14.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011489018978406935		[learning rate: 0.0046007]
	Learning Rate: 0.00460066
	LOSS [training: 0.011489018978406935 | validation: 0.03306922388703919]
	TIME [epoch: 14.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02913509734000619		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.02913509734000619 | validation: 0.05274011878924674]
	TIME [epoch: 14.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02350449739192189		[learning rate: 0.004579]
	Learning Rate: 0.00457899
	LOSS [training: 0.02350449739192189 | validation: 0.017422575258207285]
	TIME [epoch: 14.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014051238410201946		[learning rate: 0.0045682]
	Learning Rate: 0.00456818
	LOSS [training: 0.014051238410201946 | validation: 0.03399866603864205]
	TIME [epoch: 14.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023292745841302885		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.023292745841302885 | validation: 0.021029143720150224]
	TIME [epoch: 14.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01602850911771423		[learning rate: 0.0045467]
	Learning Rate: 0.00454666
	LOSS [training: 0.01602850911771423 | validation: 0.047716974161689005]
	TIME [epoch: 14.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154440264955672		[learning rate: 0.0045359]
	Learning Rate: 0.00453593
	LOSS [training: 0.03154440264955672 | validation: 0.02683140279278097]
	TIME [epoch: 14.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012058017896432596		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.012058017896432596 | validation: 0.019377093085892205]
	TIME [epoch: 14.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020923834450149753		[learning rate: 0.0045146]
	Learning Rate: 0.00451456
	LOSS [training: 0.020923834450149753 | validation: 0.027631159414421482]
	TIME [epoch: 14.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026335452224269897		[learning rate: 0.0045039]
	Learning Rate: 0.00450391
	LOSS [training: 0.026335452224269897 | validation: 0.02585245111511776]
	TIME [epoch: 14.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024054973587335333		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.024054973587335333 | validation: 0.02050979675484564]
	TIME [epoch: 14.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013662518259364022		[learning rate: 0.0044827]
	Learning Rate: 0.00448269
	LOSS [training: 0.013662518259364022 | validation: 0.02461153267482904]
	TIME [epoch: 14.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028955466805887634		[learning rate: 0.0044721]
	Learning Rate: 0.00447211
	LOSS [training: 0.028955466805887634 | validation: 0.018352117189595302]
	TIME [epoch: 14.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012174939970619853		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.012174939970619853 | validation: 0.02322187198917007]
	TIME [epoch: 14.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024952826189490535		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.024952826189490535 | validation: 0.039457837259866915]
	TIME [epoch: 14.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01766344106702692		[learning rate: 0.0044405]
	Learning Rate: 0.00444054
	LOSS [training: 0.01766344106702692 | validation: 0.018571447336586486]
	TIME [epoch: 14.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015689272492316452		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.015689272492316452 | validation: 0.024502507896160243]
	TIME [epoch: 14.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022449143570020782		[learning rate: 0.0044196]
	Learning Rate: 0.00441962
	LOSS [training: 0.022449143570020782 | validation: 0.023503884114172428]
	TIME [epoch: 14.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017446323327042688		[learning rate: 0.0044092]
	Learning Rate: 0.00440919
	LOSS [training: 0.017446323327042688 | validation: 0.03411902952027471]
	TIME [epoch: 14.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016917207631916346		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.016917207631916346 | validation: 0.021173711229134362]
	TIME [epoch: 14.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01993385288817994		[learning rate: 0.0043884]
	Learning Rate: 0.00438841
	LOSS [training: 0.01993385288817994 | validation: 0.036612263927088565]
	TIME [epoch: 14.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02218815882571321		[learning rate: 0.0043781]
	Learning Rate: 0.00437806
	LOSS [training: 0.02218815882571321 | validation: 0.020192000513866784]
	TIME [epoch: 14.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015688912875481575		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.015688912875481575 | validation: 0.015565326350442882]
	TIME [epoch: 14.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012892479964824373		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.012892479964824373 | validation: 0.022860881921113928]
	TIME [epoch: 14.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025527934529321356		[learning rate: 0.0043472]
	Learning Rate: 0.00434715
	LOSS [training: 0.025527934529321356 | validation: 0.03893612354015047]
	TIME [epoch: 14.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017250545997736996		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.017250545997736996 | validation: 0.010477385686902157]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007414258335446556		[learning rate: 0.0043267]
	Learning Rate: 0.00432667
	LOSS [training: 0.007414258335446556 | validation: 0.025106243475250638]
	TIME [epoch: 14.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032639717190957686		[learning rate: 0.0043165]
	Learning Rate: 0.00431646
	LOSS [training: 0.032639717190957686 | validation: 0.017374503989602594]
	TIME [epoch: 14.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014402991231672747		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.014402991231672747 | validation: 0.02506564460259675]
	TIME [epoch: 14.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019913827314981508		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.019913827314981508 | validation: 0.008145213804119467]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007513365425856896		[learning rate: 0.004286]
	Learning Rate: 0.00428599
	LOSS [training: 0.007513365425856896 | validation: 0.01258031557349332]
	TIME [epoch: 14.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017936609243956868		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.017936609243956868 | validation: 0.06417981888518648]
	TIME [epoch: 14.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030852944681994086		[learning rate: 0.0042658]
	Learning Rate: 0.0042658
	LOSS [training: 0.030852944681994086 | validation: 0.013702841083406662]
	TIME [epoch: 14.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010009579234732658		[learning rate: 0.0042557]
	Learning Rate: 0.00425573
	LOSS [training: 0.010009579234732658 | validation: 0.01870782449201534]
	TIME [epoch: 14.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025655366183529267		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.025655366183529267 | validation: 0.021801849568216528]
	TIME [epoch: 14.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012159167373949578		[learning rate: 0.0042357]
	Learning Rate: 0.00423568
	LOSS [training: 0.012159167373949578 | validation: 0.010390605475991344]
	TIME [epoch: 14.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013881580992885528		[learning rate: 0.0042257]
	Learning Rate: 0.00422569
	LOSS [training: 0.013881580992885528 | validation: 0.028621776322756705]
	TIME [epoch: 14.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02186316500530519		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.02186316500530519 | validation: 0.03229991014752963]
	TIME [epoch: 14.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018136146312396458		[learning rate: 0.0042058]
	Learning Rate: 0.00420578
	LOSS [training: 0.018136146312396458 | validation: 0.008890174816483142]
	TIME [epoch: 14.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018971873411544535		[learning rate: 0.0041959]
	Learning Rate: 0.00419585
	LOSS [training: 0.018971873411544535 | validation: 0.016932827715021026]
	TIME [epoch: 14.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019896764754041434		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.019896764754041434 | validation: 0.01908904384236853]
	TIME [epoch: 14.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012069199727848654		[learning rate: 0.0041761]
	Learning Rate: 0.00417608
	LOSS [training: 0.012069199727848654 | validation: 0.018542085240763603]
	TIME [epoch: 14.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01915044568994979		[learning rate: 0.0041662]
	Learning Rate: 0.00416623
	LOSS [training: 0.01915044568994979 | validation: 0.027483991272483334]
	TIME [epoch: 14.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016738953992302748		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.016738953992302748 | validation: 0.008001927343973897]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0078834934151574		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.0078834934151574 | validation: 0.011045336406829434]
	TIME [epoch: 14.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014895661711797995		[learning rate: 0.0041368]
	Learning Rate: 0.00413682
	LOSS [training: 0.014895661711797995 | validation: 0.04186509095915786]
	TIME [epoch: 14.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030128829402667517		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.030128829402667517 | validation: 0.010348769838566908]
	TIME [epoch: 14.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069993615192954235		[learning rate: 0.0041173]
	Learning Rate: 0.00411733
	LOSS [training: 0.0069993615192954235 | validation: 0.01084694400368497]
	TIME [epoch: 14.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026683387829369496		[learning rate: 0.0041076]
	Learning Rate: 0.00410762
	LOSS [training: 0.026683387829369496 | validation: 0.019970781280785617]
	TIME [epoch: 14.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01799926691008311		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.01799926691008311 | validation: 0.013707612370260022]
	TIME [epoch: 14.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011556277049276958		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.011556277049276958 | validation: 0.020177210884266952]
	TIME [epoch: 14.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018455418976205125		[learning rate: 0.0040786]
	Learning Rate: 0.00407862
	LOSS [training: 0.018455418976205125 | validation: 0.01940925842439324]
	TIME [epoch: 14.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014246105334023308		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.014246105334023308 | validation: 0.014233491800150225]
	TIME [epoch: 14.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009173975240345454		[learning rate: 0.0040594]
	Learning Rate: 0.0040594
	LOSS [training: 0.009173975240345454 | validation: 0.01666715806938269]
	TIME [epoch: 14.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01783612313586926		[learning rate: 0.0040498]
	Learning Rate: 0.00404982
	LOSS [training: 0.01783612313586926 | validation: 0.04520919073656077]
	TIME [epoch: 14.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03326592704562044		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.03326592704562044 | validation: 0.025660453039814242]
	TIME [epoch: 14.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014342982099941408		[learning rate: 0.0040307]
	Learning Rate: 0.00403074
	LOSS [training: 0.014342982099941408 | validation: 0.012966243545354614]
	TIME [epoch: 14.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006823123316414095		[learning rate: 0.0040212]
	Learning Rate: 0.00402123
	LOSS [training: 0.006823123316414095 | validation: 0.011710089757781835]
	TIME [epoch: 14.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025160168593294112		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.025160168593294112 | validation: 0.024173877956970298]
	TIME [epoch: 14.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012725980282353949		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.012725980282353949 | validation: 0.01284290430647602]
	TIME [epoch: 14.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009886035382941966		[learning rate: 0.0039928]
	Learning Rate: 0.00399284
	LOSS [training: 0.009886035382941966 | validation: 0.012740392314706118]
	TIME [epoch: 14.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023451780450941373		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.023451780450941373 | validation: 0.03394710164392792]
	TIME [epoch: 14.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016960928358190495		[learning rate: 0.003974]
	Learning Rate: 0.00397403
	LOSS [training: 0.016960928358190495 | validation: 0.01969120179265378]
	TIME [epoch: 14.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013805703583611316		[learning rate: 0.0039647]
	Learning Rate: 0.00396465
	LOSS [training: 0.013805703583611316 | validation: 0.016945086987619033]
	TIME [epoch: 14.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012140033865709325		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.012140033865709325 | validation: 0.018884526419263272]
	TIME [epoch: 14.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210529007650853		[learning rate: 0.003946]
	Learning Rate: 0.00394597
	LOSS [training: 0.0210529007650853 | validation: 0.007169775770024785]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010546955461345753		[learning rate: 0.0039367]
	Learning Rate: 0.00393666
	LOSS [training: 0.010546955461345753 | validation: 0.019779748547686875]
	TIME [epoch: 14.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013046963085701874		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.013046963085701874 | validation: 0.031269242650686695]
	TIME [epoch: 14.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02108181285503308		[learning rate: 0.0039181]
	Learning Rate: 0.00391811
	LOSS [training: 0.02108181285503308 | validation: 0.01769346318357723]
	TIME [epoch: 16.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014172917807861445		[learning rate: 0.0039089]
	Learning Rate: 0.00390887
	LOSS [training: 0.014172917807861445 | validation: 0.007658492779175819]
	TIME [epoch: 14.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006560106836975636		[learning rate: 0.0038996]
	Learning Rate: 0.00389965
	LOSS [training: 0.006560106836975636 | validation: 0.019461756744592003]
	TIME [epoch: 14.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023784870412822963		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.023784870412822963 | validation: 0.015645724623079397]
	TIME [epoch: 14.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012716462335558888		[learning rate: 0.0038813]
	Learning Rate: 0.00388127
	LOSS [training: 0.012716462335558888 | validation: 0.013719485917362502]
	TIME [epoch: 14.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00944712448413836		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.00944712448413836 | validation: 0.009655594814843928]
	TIME [epoch: 14.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017128176244018273		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.017128176244018273 | validation: 0.02337636709765556]
	TIME [epoch: 14.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013626466508076453		[learning rate: 0.0038539]
	Learning Rate: 0.00385387
	LOSS [training: 0.013626466508076453 | validation: 0.019144653141756077]
	TIME [epoch: 14.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0201222317653138		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.0201222317653138 | validation: 0.031584231580281424]
	TIME [epoch: 14.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017806517033766466		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.017806517033766466 | validation: 0.01614736709517869]
	TIME [epoch: 14.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652429176273983		[learning rate: 0.0038267]
	Learning Rate: 0.00382667
	LOSS [training: 0.01652429176273983 | validation: 0.0215981467092881]
	TIME [epoch: 14.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011104042546101749		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.011104042546101749 | validation: 0.007471997975022762]
	TIME [epoch: 14.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799431142479893		[learning rate: 0.0038086]
	Learning Rate: 0.00380863
	LOSS [training: 0.0799431142479893 | validation: 0.05459768168431807]
	TIME [epoch: 14.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027012308904235345		[learning rate: 0.0037996]
	Learning Rate: 0.00379965
	LOSS [training: 0.027012308904235345 | validation: 0.016700326147751587]
	TIME [epoch: 14.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011951535022082266		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.011951535022082266 | validation: 0.008165791690205478]
	TIME [epoch: 14.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007501271682090228		[learning rate: 0.0037817]
	Learning Rate: 0.00378175
	LOSS [training: 0.007501271682090228 | validation: 0.01264543538599486]
	TIME [epoch: 14.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01950600578801603		[learning rate: 0.0037728]
	Learning Rate: 0.00377283
	LOSS [training: 0.01950600578801603 | validation: 0.0089056306626604]
	TIME [epoch: 14.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009223514864081062		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.009223514864081062 | validation: 0.017448341890633295]
	TIME [epoch: 14.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018707981916124668		[learning rate: 0.003755]
	Learning Rate: 0.00375505
	LOSS [training: 0.018707981916124668 | validation: 0.00885299758796156]
	TIME [epoch: 14.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009170717399113907		[learning rate: 0.0037462]
	Learning Rate: 0.00374619
	LOSS [training: 0.009170717399113907 | validation: 0.014311462625561851]
	TIME [epoch: 14.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018101578932544382		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.018101578932544382 | validation: 0.009767258099482755]
	TIME [epoch: 14.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007585995493987455		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.007585995493987455 | validation: 0.009127010952411582]
	TIME [epoch: 14.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210733123986103		[learning rate: 0.0037197]
	Learning Rate: 0.00371974
	LOSS [training: 0.0210733123986103 | validation: 0.01301104247438132]
	TIME [epoch: 14.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00730124191362257		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.00730124191362257 | validation: 0.007298391657116811]
	TIME [epoch: 14.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013687190953550862		[learning rate: 0.0037022]
	Learning Rate: 0.00370221
	LOSS [training: 0.013687190953550862 | validation: 0.030497077116711874]
	TIME [epoch: 14.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026550765769908634		[learning rate: 0.0036935]
	Learning Rate: 0.00369348
	LOSS [training: 0.026550765769908634 | validation: 0.013305773321069136]
	TIME [epoch: 14.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01157719281852551		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.01157719281852551 | validation: 0.007742654122550561]
	TIME [epoch: 14.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005058085900164723		[learning rate: 0.0036761]
	Learning Rate: 0.00367608
	LOSS [training: 0.005058085900164723 | validation: 0.008112917523640054]
	TIME [epoch: 14.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009590691572897969		[learning rate: 0.0036674]
	Learning Rate: 0.00366741
	LOSS [training: 0.009590691572897969 | validation: 0.02678517395575577]
	TIME [epoch: 14.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017515556206637427		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.017515556206637427 | validation: 0.018226761644450876]
	TIME [epoch: 14.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01594080524819224		[learning rate: 0.0036501]
	Learning Rate: 0.00365012
	LOSS [training: 0.01594080524819224 | validation: 0.018775852828697343]
	TIME [epoch: 14.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011960343487934715		[learning rate: 0.0036415]
	Learning Rate: 0.00364151
	LOSS [training: 0.011960343487934715 | validation: 0.009525184718509598]
	TIME [epoch: 14.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072112829541901135		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.0072112829541901135 | validation: 0.01349830796933994]
	TIME [epoch: 14.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026868520239667744		[learning rate: 0.0036244]
	Learning Rate: 0.00362436
	LOSS [training: 0.026868520239667744 | validation: 0.013028801267495097]
	TIME [epoch: 14.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015246286423153333		[learning rate: 0.0036158]
	Learning Rate: 0.00361581
	LOSS [training: 0.015246286423153333 | validation: 0.015857169333033883]
	TIME [epoch: 14.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010211409310993012		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.010211409310993012 | validation: 0.005922513750793713]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005977983540903935		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.005977983540903935 | validation: 0.007494010044622293]
	TIME [epoch: 14.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015648156072759635		[learning rate: 0.0035903]
	Learning Rate: 0.00359028
	LOSS [training: 0.015648156072759635 | validation: 0.030582302430724233]
	TIME [epoch: 14.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016117281991067336		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.016117281991067336 | validation: 0.016766215076965563]
	TIME [epoch: 14.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009871618811951496		[learning rate: 0.0035734]
	Learning Rate: 0.00357336
	LOSS [training: 0.009871618811951496 | validation: 0.01020145817271288]
	TIME [epoch: 14.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007374279713642544		[learning rate: 0.0035649]
	Learning Rate: 0.00356493
	LOSS [training: 0.007374279713642544 | validation: 0.023177665251254066]
	TIME [epoch: 14.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015551304193492262		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.015551304193492262 | validation: 0.02104050451178132]
	TIME [epoch: 14.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015095488678128568		[learning rate: 0.0035481]
	Learning Rate: 0.00354813
	LOSS [training: 0.015095488678128568 | validation: 0.011309471025499382]
	TIME [epoch: 14.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007529220327018431		[learning rate: 0.0035398]
	Learning Rate: 0.00353976
	LOSS [training: 0.007529220327018431 | validation: 0.016156395048418128]
	TIME [epoch: 14.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01221904665307422		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.01221904665307422 | validation: 0.030802984272809503]
	TIME [epoch: 14.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01678287580483165		[learning rate: 0.0035231]
	Learning Rate: 0.00352308
	LOSS [training: 0.01678287580483165 | validation: 0.020675112521730092]
	TIME [epoch: 14.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009416866009679397		[learning rate: 0.0035148]
	Learning Rate: 0.00351477
	LOSS [training: 0.009416866009679397 | validation: 0.021993558107929342]
	TIME [epoch: 14.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01480667219642878		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.01480667219642878 | validation: 0.021206763787073157]
	TIME [epoch: 14.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013119445376363942		[learning rate: 0.0034982]
	Learning Rate: 0.00349821
	LOSS [training: 0.013119445376363942 | validation: 0.014875181953113192]
	TIME [epoch: 14.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010156057058261395		[learning rate: 0.00349]
	Learning Rate: 0.00348996
	LOSS [training: 0.010156057058261395 | validation: 0.01658190614515432]
	TIME [epoch: 14.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010638827330033334		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.010638827330033334 | validation: 0.012671790265928136]
	TIME [epoch: 14.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008352111260919965		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.008352111260919965 | validation: 0.009624692954933792]
	TIME [epoch: 14.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022213472526074765		[learning rate: 0.0034653]
	Learning Rate: 0.00346532
	LOSS [training: 0.022213472526074765 | validation: 0.017624459414279633]
	TIME [epoch: 14.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011115325122913204		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.011115325122913204 | validation: 0.0070703624540826345]
	TIME [epoch: 14.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007131955704102175		[learning rate: 0.003449]
	Learning Rate: 0.00344899
	LOSS [training: 0.007131955704102175 | validation: 0.013355767693538849]
	TIME [epoch: 147 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00951923610486098		[learning rate: 0.0034409]
	Learning Rate: 0.00344086
	LOSS [training: 0.00951923610486098 | validation: 0.018311495814775546]
	TIME [epoch: 32.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015337609478464579		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.015337609478464579 | validation: 0.02968723152519868]
	TIME [epoch: 32.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01372731071125406		[learning rate: 0.0034246]
	Learning Rate: 0.00342464
	LOSS [training: 0.01372731071125406 | validation: 0.0066132208009178645]
	TIME [epoch: 32.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009869109629545477		[learning rate: 0.0034166]
	Learning Rate: 0.00341657
	LOSS [training: 0.009869109629545477 | validation: 0.020814771177223797]
	TIME [epoch: 32.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010960270921480988		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.010960270921480988 | validation: 0.008207316358788123]
	TIME [epoch: 32.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010882231599812116		[learning rate: 0.0034005]
	Learning Rate: 0.00340047
	LOSS [training: 0.010882231599812116 | validation: 0.021759251189321777]
	TIME [epoch: 32 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014663859011617233		[learning rate: 0.0033924]
	Learning Rate: 0.00339244
	LOSS [training: 0.014663859011617233 | validation: 0.011567191023083909]
	TIME [epoch: 32 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00915449184266472		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.00915449184266472 | validation: 0.02544324012618866]
	TIME [epoch: 32.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010771442553221794		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.010771442553221794 | validation: 0.024422138631766233]
	TIME [epoch: 32.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012700644102653499		[learning rate: 0.0033685]
	Learning Rate: 0.0033685
	LOSS [training: 0.012700644102653499 | validation: 0.01288461610129141]
	TIME [epoch: 32.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01644939309334138		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.01644939309334138 | validation: 0.014192141160980437]
	TIME [epoch: 32 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007730012899068145		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.007730012899068145 | validation: 0.010367507089079096]
	TIME [epoch: 32.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00922241361617686		[learning rate: 0.0033447]
	Learning Rate: 0.00334471
	LOSS [training: 0.00922241361617686 | validation: 0.010634292510733973]
	TIME [epoch: 32.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013889019606828982		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.013889019606828982 | validation: 0.026894688999335288]
	TIME [epoch: 32 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012023695988029218		[learning rate: 0.003329]
	Learning Rate: 0.00332895
	LOSS [training: 0.012023695988029218 | validation: 0.011454973879332666]
	TIME [epoch: 32 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005694119903546645		[learning rate: 0.0033211]
	Learning Rate: 0.0033211
	LOSS [training: 0.005694119903546645 | validation: 0.009649227940865]
	TIME [epoch: 32.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013978057735965544		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.013978057735965544 | validation: 0.02469068531735464]
	TIME [epoch: 32.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017463201084395866		[learning rate: 0.0033055]
	Learning Rate: 0.00330545
	LOSS [training: 0.017463201084395866 | validation: 0.006858552158829801]
	TIME [epoch: 32.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006594994011660899		[learning rate: 0.0032977]
	Learning Rate: 0.00329765
	LOSS [training: 0.006594994011660899 | validation: 0.007910150098603949]
	TIME [epoch: 33.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01644846576824481		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.01644846576824481 | validation: 0.020321201287417878]
	TIME [epoch: 32.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010895487665492375		[learning rate: 0.0032821]
	Learning Rate: 0.00328212
	LOSS [training: 0.010895487665492375 | validation: 0.013163356644690795]
	TIME [epoch: 32.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010542112354581471		[learning rate: 0.0032744]
	Learning Rate: 0.00327437
	LOSS [training: 0.010542112354581471 | validation: 0.006343530505465418]
	TIME [epoch: 32.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069900421929704245		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.0069900421929704245 | validation: 0.020185057135292155]
	TIME [epoch: 32.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015144974910946166		[learning rate: 0.0032589]
	Learning Rate: 0.00325894
	LOSS [training: 0.015144974910946166 | validation: 0.006557046915874383]
	TIME [epoch: 32.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005270580470975273		[learning rate: 0.0032513]
	Learning Rate: 0.00325126
	LOSS [training: 0.005270580470975273 | validation: 0.01135880542697116]
	TIME [epoch: 32.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012499341174894922		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.012499341174894922 | validation: 0.009706938487417448]
	TIME [epoch: 32.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009332759617446293		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.009332759617446293 | validation: 0.006688718125736552]
	TIME [epoch: 32.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008523295105784885		[learning rate: 0.0032283]
	Learning Rate: 0.0032283
	LOSS [training: 0.008523295105784885 | validation: 0.017135127761828312]
	TIME [epoch: 32.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01440389351544964		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.01440389351544964 | validation: 0.009791619172485763]
	TIME [epoch: 32.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006433814937358573		[learning rate: 0.0032131]
	Learning Rate: 0.00321309
	LOSS [training: 0.006433814937358573 | validation: 0.008805559866903508]
	TIME [epoch: 32.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013450037786574802		[learning rate: 0.0032055]
	Learning Rate: 0.00320551
	LOSS [training: 0.013450037786574802 | validation: 0.014774984980990197]
	TIME [epoch: 32.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009470776494350137		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.009470776494350137 | validation: 0.012129028568837215]
	TIME [epoch: 32 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011032286353071017		[learning rate: 0.0031904]
	Learning Rate: 0.00319041
	LOSS [training: 0.011032286353071017 | validation: 0.006833763119965818]
	TIME [epoch: 31.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008051989745021259		[learning rate: 0.0031829]
	Learning Rate: 0.00318288
	LOSS [training: 0.008051989745021259 | validation: 0.017782891448362245]
	TIME [epoch: 32 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015810969579256432		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.015810969579256432 | validation: 0.012316090983503981]
	TIME [epoch: 31.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009260007098955277		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.009260007098955277 | validation: 0.007563678282578628]
	TIME [epoch: 32 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064769286614772175		[learning rate: 0.0031604]
	Learning Rate: 0.00316041
	LOSS [training: 0.0064769286614772175 | validation: 0.005701448456925556]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010843111246096243		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.010843111246096243 | validation: 0.028449666382160357]
	TIME [epoch: 32.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011819859475288378		[learning rate: 0.0031455]
	Learning Rate: 0.00314552
	LOSS [training: 0.011819859475288378 | validation: 0.005936977899360877]
	TIME [epoch: 32.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00792490011739375		[learning rate: 0.0031381]
	Learning Rate: 0.0031381
	LOSS [training: 0.00792490011739375 | validation: 0.012945157679073702]
	TIME [epoch: 32 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01279642393109104		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.01279642393109104 | validation: 0.005148994510619]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007040837528284043		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.007040837528284043 | validation: 0.014356838381599284]
	TIME [epoch: 32.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009748339887841774		[learning rate: 0.0031159]
	Learning Rate: 0.00311594
	LOSS [training: 0.009748339887841774 | validation: 0.010782100150677279]
	TIME [epoch: 31.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01269008827703746		[learning rate: 0.0031086]
	Learning Rate: 0.0031086
	LOSS [training: 0.01269008827703746 | validation: 0.011760497312264188]
	TIME [epoch: 31.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008547778805756101		[learning rate: 0.0031013]
	Learning Rate: 0.00310126
	LOSS [training: 0.008547778805756101 | validation: 0.010064495012209816]
	TIME [epoch: 31.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062772955071460695		[learning rate: 0.0030939]
	Learning Rate: 0.00309395
	LOSS [training: 0.0062772955071460695 | validation: 0.009028593466108589]
	TIME [epoch: 31.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013567118202689306		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.013567118202689306 | validation: 0.012376113461849948]
	TIME [epoch: 31.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008438832667185744		[learning rate: 0.0030794]
	Learning Rate: 0.00307937
	LOSS [training: 0.008438832667185744 | validation: 0.009178711383914646]
	TIME [epoch: 31.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006427135838838427		[learning rate: 0.0030721]
	Learning Rate: 0.0030721
	LOSS [training: 0.006427135838838427 | validation: 0.020286629515415742]
	TIME [epoch: 31.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009637735021845662		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.009637735021845662 | validation: 0.009303039928742145]
	TIME [epoch: 31.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016214861379397684		[learning rate: 0.0030576]
	Learning Rate: 0.00305763
	LOSS [training: 0.016214861379397684 | validation: 0.00657626250336467]
	TIME [epoch: 31.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005199193676360609		[learning rate: 0.0030504]
	Learning Rate: 0.00305042
	LOSS [training: 0.005199193676360609 | validation: 0.012058356912111498]
	TIME [epoch: 31.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008019081106155289		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.008019081106155289 | validation: 0.01266460482492916]
	TIME [epoch: 31.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014636545650756947		[learning rate: 0.003036]
	Learning Rate: 0.00303604
	LOSS [training: 0.014636545650756947 | validation: 0.022504481988851268]
	TIME [epoch: 31.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00820776509682092		[learning rate: 0.0030289]
	Learning Rate: 0.00302888
	LOSS [training: 0.00820776509682092 | validation: 0.007966490187396213]
	TIME [epoch: 31.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007290663461256135		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.007290663461256135 | validation: 0.004698265313821633]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00442903959774983		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.00442903959774983 | validation: 0.007414333820391451]
	TIME [epoch: 31.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016616297657319236		[learning rate: 0.0030075]
	Learning Rate: 0.0030075
	LOSS [training: 0.016616297657319236 | validation: 0.01803031274480301]
	TIME [epoch: 31.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010455846899500588		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.010455846899500588 | validation: 0.006757612919317212]
	TIME [epoch: 31.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005099958723504566		[learning rate: 0.0029933]
	Learning Rate: 0.00299332
	LOSS [training: 0.005099958723504566 | validation: 0.004696799491420394]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_561.pth
	Model improved!!!
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006447059363208316		[learning rate: 0.0029863]
	Learning Rate: 0.00298626
	LOSS [training: 0.006447059363208316 | validation: 0.020526509600348727]
	TIME [epoch: 31.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011345763358378369		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.011345763358378369 | validation: 0.019138544423365086]
	TIME [epoch: 31.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012640509465055145		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.012640509465055145 | validation: 0.008086969494643126]
	TIME [epoch: 31.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005872092958623496		[learning rate: 0.0029652]
	Learning Rate: 0.00296518
	LOSS [training: 0.005872092958623496 | validation: 0.006884450626570561]
	TIME [epoch: 31.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009154758378928625		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.009154758378928625 | validation: 0.007690463140595426]
	TIME [epoch: 31.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075892352513295324		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.0075892352513295324 | validation: 0.005586866015665886]
	TIME [epoch: 32 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00947948460779175		[learning rate: 0.0029442]
	Learning Rate: 0.00294425
	LOSS [training: 0.00947948460779175 | validation: 0.017791549902010324]
	TIME [epoch: 32 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01237018351007494		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.01237018351007494 | validation: 0.0040175991361818516]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053730320267824285		[learning rate: 0.0029304]
	Learning Rate: 0.00293037
	LOSS [training: 0.0053730320267824285 | validation: 0.007301543490621251]
	TIME [epoch: 31.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009374648033384312		[learning rate: 0.0029235]
	Learning Rate: 0.00292346
	LOSS [training: 0.009374648033384312 | validation: 0.010403041162202722]
	TIME [epoch: 31.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007570756203747269		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.007570756203747269 | validation: 0.00797525791105361]
	TIME [epoch: 31.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010852022137447154		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.010852022137447154 | validation: 0.011113858000166624]
	TIME [epoch: 31.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006549146217049597		[learning rate: 0.0029028]
	Learning Rate: 0.00290282
	LOSS [training: 0.006549146217049597 | validation: 0.007336646365239124]
	TIME [epoch: 31.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007280058701799174		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.007280058701799174 | validation: 0.012869372344393563]
	TIME [epoch: 31.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015319056772852235		[learning rate: 0.0028891]
	Learning Rate: 0.00288914
	LOSS [training: 0.015319056772852235 | validation: 0.01305823308535339]
	TIME [epoch: 31.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006839922733008		[learning rate: 0.0028823]
	Learning Rate: 0.00288233
	LOSS [training: 0.006839922733008 | validation: 0.004925902687995984]
	TIME [epoch: 31.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068886669443117155		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.0068886669443117155 | validation: 0.008482459491720122]
	TIME [epoch: 31.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009167418351975617		[learning rate: 0.0028687]
	Learning Rate: 0.00286875
	LOSS [training: 0.009167418351975617 | validation: 0.009672116151995508]
	TIME [epoch: 31.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006907692692616563		[learning rate: 0.002862]
	Learning Rate: 0.00286198
	LOSS [training: 0.006907692692616563 | validation: 0.017636570023456907]
	TIME [epoch: 31.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010947732324245585		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.010947732324245585 | validation: 0.004566449869062483]
	TIME [epoch: 31.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038131321944237166		[learning rate: 0.0028485]
	Learning Rate: 0.00284849
	LOSS [training: 0.0038131321944237166 | validation: 0.008736129390345161]
	TIME [epoch: 31.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01242419379309052		[learning rate: 0.0028418]
	Learning Rate: 0.00284178
	LOSS [training: 0.01242419379309052 | validation: 0.005567488475151198]
	TIME [epoch: 31.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007691918588363509		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.007691918588363509 | validation: 0.006625375216754152]
	TIME [epoch: 31.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006533889582186763		[learning rate: 0.0028284]
	Learning Rate: 0.00282838
	LOSS [training: 0.006533889582186763 | validation: 0.008284676609832087]
	TIME [epoch: 31.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006806566841636019		[learning rate: 0.0028217]
	Learning Rate: 0.00282171
	LOSS [training: 0.006806566841636019 | validation: 0.0163989837919519]
	TIME [epoch: 31.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011826640675581344		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.011826640675581344 | validation: 0.006527619059592692]
	TIME [epoch: 31.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005752762842004303		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.005752762842004303 | validation: 0.0076342447103036]
	TIME [epoch: 31.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007720226892972529		[learning rate: 0.0028018]
	Learning Rate: 0.00280179
	LOSS [training: 0.007720226892972529 | validation: 0.007909851582172618]
	TIME [epoch: 31.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007164638683527589		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.007164638683527589 | validation: 0.008408024644950026]
	TIME [epoch: 31.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008481197156008294		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.008481197156008294 | validation: 0.021960326240121147]
	TIME [epoch: 31.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008099913376852192		[learning rate: 0.002782]
	Learning Rate: 0.00278201
	LOSS [training: 0.008099913376852192 | validation: 0.006443272143659295]
	TIME [epoch: 31.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006306458403577696		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.006306458403577696 | validation: 0.02471975507958203]
	TIME [epoch: 31.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01656874618381688		[learning rate: 0.0027689]
	Learning Rate: 0.0027689
	LOSS [training: 0.01656874618381688 | validation: 0.012766006535385586]
	TIME [epoch: 31.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059524222977269045		[learning rate: 0.0027624]
	Learning Rate: 0.00276237
	LOSS [training: 0.0059524222977269045 | validation: 0.005236854848202294]
	TIME [epoch: 31.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005610912919114462		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.005610912919114462 | validation: 0.00828886689441739]
	TIME [epoch: 31.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007205231288513979		[learning rate: 0.0027494]
	Learning Rate: 0.00274936
	LOSS [training: 0.007205231288513979 | validation: 0.014772988225365652]
	TIME [epoch: 31.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010221557418372766		[learning rate: 0.0027429]
	Learning Rate: 0.00274287
	LOSS [training: 0.010221557418372766 | validation: 0.011278949739654919]
	TIME [epoch: 31.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005467622697612154		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.005467622697612154 | validation: 0.009002177223729549]
	TIME [epoch: 31.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011337948811393867		[learning rate: 0.0027299]
	Learning Rate: 0.00272994
	LOSS [training: 0.011337948811393867 | validation: 0.02197335030801009]
	TIME [epoch: 31.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008638451068263008		[learning rate: 0.0027235]
	Learning Rate: 0.00272351
	LOSS [training: 0.008638451068263008 | validation: 0.006876359218213389]
	TIME [epoch: 31.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005301253305097219		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.005301253305097219 | validation: 0.0085946736711763]
	TIME [epoch: 32 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013264941478104081		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.013264941478104081 | validation: 0.01658554756090731]
	TIME [epoch: 31.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008277647714806026		[learning rate: 0.0027043]
	Learning Rate: 0.00270428
	LOSS [training: 0.008277647714806026 | validation: 0.0075995731763912455]
	TIME [epoch: 31.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007495602480321513		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.007495602480321513 | validation: 0.008598007218898094]
	TIME [epoch: 31.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008512538043126117		[learning rate: 0.0026915]
	Learning Rate: 0.00269153
	LOSS [training: 0.008512538043126117 | validation: 0.010770965079668057]
	TIME [epoch: 32 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052423604035803945		[learning rate: 0.0026852]
	Learning Rate: 0.00268519
	LOSS [training: 0.0052423604035803945 | validation: 0.007257713303906026]
	TIME [epoch: 32 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009817096035378442		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.009817096035378442 | validation: 0.010609141069994464]
	TIME [epoch: 31.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006470837106229157		[learning rate: 0.0026725]
	Learning Rate: 0.00267253
	LOSS [training: 0.006470837106229157 | validation: 0.010056562645491665]
	TIME [epoch: 31.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003955271828994543		[learning rate: 0.0026662]
	Learning Rate: 0.00266623
	LOSS [training: 0.003955271828994543 | validation: 0.0033248190035974666]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_610.pth
	Model improved!!!
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007520800401459103		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.007520800401459103 | validation: 0.012607302135493846]
	TIME [epoch: 31.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006327557548151352		[learning rate: 0.0026537]
	Learning Rate: 0.00265367
	LOSS [training: 0.006327557548151352 | validation: 0.005057523222631704]
	TIME [epoch: 31.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008131519417966575		[learning rate: 0.0026474]
	Learning Rate: 0.00264741
	LOSS [training: 0.008131519417966575 | validation: 0.03280065231293805]
	TIME [epoch: 31.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014266635160805076		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.014266635160805076 | validation: 0.012862890182982393]
	TIME [epoch: 31.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007101928196792788		[learning rate: 0.0026349]
	Learning Rate: 0.00263493
	LOSS [training: 0.007101928196792788 | validation: 0.004793082981072196]
	TIME [epoch: 31.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003541762300572421		[learning rate: 0.0026287]
	Learning Rate: 0.00262872
	LOSS [training: 0.003541762300572421 | validation: 0.004009348285156783]
	TIME [epoch: 31.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006994665901586506		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.006994665901586506 | validation: 0.025536314741573564]
	TIME [epoch: 31.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011351281578595808		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.011351281578595808 | validation: 0.006890595893765094]
	TIME [epoch: 31.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006738817020562082		[learning rate: 0.0026102]
	Learning Rate: 0.00261016
	LOSS [training: 0.006738817020562082 | validation: 0.007212198859627101]
	TIME [epoch: 31.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006078472557919448		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.006078472557919448 | validation: 0.012268443283201574]
	TIME [epoch: 32 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008782884018058426		[learning rate: 0.0025979]
	Learning Rate: 0.00259786
	LOSS [training: 0.008782884018058426 | validation: 0.008591747043662288]
	TIME [epoch: 31.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005502801023680516		[learning rate: 0.0025917]
	Learning Rate: 0.00259173
	LOSS [training: 0.005502801023680516 | validation: 0.005581411633140213]
	TIME [epoch: 31.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009446824466591015		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.009446824466591015 | validation: 0.015405580528593555]
	TIME [epoch: 31.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006788767885943672		[learning rate: 0.0025795]
	Learning Rate: 0.00257952
	LOSS [training: 0.006788767885943672 | validation: 0.005378267056432891]
	TIME [epoch: 31.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005197901025079221		[learning rate: 0.0025734]
	Learning Rate: 0.00257343
	LOSS [training: 0.005197901025079221 | validation: 0.012341811114493121]
	TIME [epoch: 31.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009330819415708607		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.009330819415708607 | validation: 0.0043536186982803945]
	TIME [epoch: 31.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038451030934464458		[learning rate: 0.0025613]
	Learning Rate: 0.00256131
	LOSS [training: 0.0038451030934464458 | validation: 0.008441296644234528]
	TIME [epoch: 31.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009224638108898068		[learning rate: 0.0025553]
	Learning Rate: 0.00255526
	LOSS [training: 0.009224638108898068 | validation: 0.008956419217057733]
	TIME [epoch: 31.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004909290148548295		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.004909290148548295 | validation: 0.008545517156771567]
	TIME [epoch: 31.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008873708974994513		[learning rate: 0.0025432]
	Learning Rate: 0.00254322
	LOSS [training: 0.008873708974994513 | validation: 0.006721749505773659]
	TIME [epoch: 31.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005401918717125983		[learning rate: 0.0025372]
	Learning Rate: 0.00253722
	LOSS [training: 0.005401918717125983 | validation: 0.011462377435933027]
	TIME [epoch: 31.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012880769756779044		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.012880769756779044 | validation: 0.0066833546100070786]
	TIME [epoch: 31.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004095033200843459		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.004095033200843459 | validation: 0.004761999510859691]
	TIME [epoch: 31.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008192514377014674		[learning rate: 0.0025193]
	Learning Rate: 0.00251931
	LOSS [training: 0.008192514377014674 | validation: 0.009288572349184487]
	TIME [epoch: 31.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007326841497525164		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.007326841497525164 | validation: 0.007884487946323699]
	TIME [epoch: 31.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007724833667184895		[learning rate: 0.0025074]
	Learning Rate: 0.00250744
	LOSS [training: 0.007724833667184895 | validation: 0.006225782267822652]
	TIME [epoch: 31.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005553612571709792		[learning rate: 0.0025015]
	Learning Rate: 0.00250153
	LOSS [training: 0.005553612571709792 | validation: 0.0058096053517140015]
	TIME [epoch: 31.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005249351609805042		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.005249351609805042 | validation: 0.01437966547146892]
	TIME [epoch: 31.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010939662452537986		[learning rate: 0.0024897]
	Learning Rate: 0.00248974
	LOSS [training: 0.010939662452537986 | validation: 0.008375722888154758]
	TIME [epoch: 31.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005452310935379431		[learning rate: 0.0024839]
	Learning Rate: 0.00248387
	LOSS [training: 0.005452310935379431 | validation: 0.005908841990961472]
	TIME [epoch: 31.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005824914319429479		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.005824914319429479 | validation: 0.00677761636680928]
	TIME [epoch: 31.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005601727128637815		[learning rate: 0.0024722]
	Learning Rate: 0.00247216
	LOSS [training: 0.005601727128637815 | validation: 0.009324379733851178]
	TIME [epoch: 31.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065290207527298316		[learning rate: 0.0024663]
	Learning Rate: 0.00246633
	LOSS [training: 0.0065290207527298316 | validation: 0.015148259019688205]
	TIME [epoch: 31.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005850443950949682		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.005850443950949682 | validation: 0.008043853158598856]
	TIME [epoch: 31.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010892085582404938		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.010892085582404938 | validation: 0.006610414389103204]
	TIME [epoch: 31.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004396356982689753		[learning rate: 0.0024489]
	Learning Rate: 0.00244892
	LOSS [training: 0.004396356982689753 | validation: 0.006014889517967977]
	TIME [epoch: 31.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004946890927223986		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.004946890927223986 | validation: 0.006060016215155313]
	TIME [epoch: 31.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00423967743548818		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.00423967743548818 | validation: 0.007619989190687007]
	TIME [epoch: 31.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010179582232362297		[learning rate: 0.0024316]
	Learning Rate: 0.00243163
	LOSS [training: 0.010179582232362297 | validation: 0.014826345262871882]
	TIME [epoch: 31.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008176398035390128		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.008176398035390128 | validation: 0.00554363786067527]
	TIME [epoch: 31.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005046926788691805		[learning rate: 0.0024202]
	Learning Rate: 0.00242017
	LOSS [training: 0.005046926788691805 | validation: 0.011274251708389488]
	TIME [epoch: 31.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004511973820929861		[learning rate: 0.0024145]
	Learning Rate: 0.00241446
	LOSS [training: 0.004511973820929861 | validation: 0.0044503196313661845]
	TIME [epoch: 31.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010547614293464465		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.010547614293464465 | validation: 0.008129283380697544]
	TIME [epoch: 31.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005206232739820628		[learning rate: 0.0024031]
	Learning Rate: 0.00240309
	LOSS [training: 0.005206232739820628 | validation: 0.007211047318992931]
	TIME [epoch: 31.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006159588380275006		[learning rate: 0.0023974]
	Learning Rate: 0.00239742
	LOSS [training: 0.006159588380275006 | validation: 0.007064819478118467]
	TIME [epoch: 31.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006535740377443535		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.006535740377443535 | validation: 0.01308876353464264]
	TIME [epoch: 31.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009743986698680668		[learning rate: 0.0023861]
	Learning Rate: 0.00238612
	LOSS [training: 0.009743986698680668 | validation: 0.0058872585686202215]
	TIME [epoch: 31.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00402216958616888		[learning rate: 0.0023805]
	Learning Rate: 0.00238049
	LOSS [training: 0.00402216958616888 | validation: 0.006654273994217369]
	TIME [epoch: 31.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003661997987620311		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.003661997987620311 | validation: 0.004240771657652493]
	TIME [epoch: 31.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008868607103440408		[learning rate: 0.0023693]
	Learning Rate: 0.00236927
	LOSS [training: 0.008868607103440408 | validation: 0.011228613429788401]
	TIME [epoch: 31.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009273399414587827		[learning rate: 0.0023637]
	Learning Rate: 0.00236369
	LOSS [training: 0.009273399414587827 | validation: 0.007034300423787672]
	TIME [epoch: 31.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004810806609740461		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.004810806609740461 | validation: 0.004876612981970393]
	TIME [epoch: 31.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036961893623445683		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.0036961893623445683 | validation: 0.006003931439724682]
	TIME [epoch: 31.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010080892608231442		[learning rate: 0.002347]
	Learning Rate: 0.002347
	LOSS [training: 0.010080892608231442 | validation: 0.005089861006091541]
	TIME [epoch: 31.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006262745947126284		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.006262745947126284 | validation: 0.005062551956968889]
	TIME [epoch: 31.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003755498379909918		[learning rate: 0.0023359]
	Learning Rate: 0.00233594
	LOSS [training: 0.003755498379909918 | validation: 0.009482267618019947]
	TIME [epoch: 31.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007034447869001586		[learning rate: 0.0023304]
	Learning Rate: 0.00233043
	LOSS [training: 0.007034447869001586 | validation: 0.009987142673963343]
	TIME [epoch: 31.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006514678541795067		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.006514678541795067 | validation: 0.007404927906505373]
	TIME [epoch: 31.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006847016283105151		[learning rate: 0.0023194]
	Learning Rate: 0.00231945
	LOSS [training: 0.006847016283105151 | validation: 0.006458070594878819]
	TIME [epoch: 31.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005211094040009139		[learning rate: 0.002314]
	Learning Rate: 0.00231398
	LOSS [training: 0.005211094040009139 | validation: 0.0055234798409167386]
	TIME [epoch: 31.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003632421699751995		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.003632421699751995 | validation: 0.007182940814197552]
	TIME [epoch: 31.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00562769965684894		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.00562769965684894 | validation: 0.007857379886516259]
	TIME [epoch: 31.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009492283760246434		[learning rate: 0.0022976]
	Learning Rate: 0.00229764
	LOSS [training: 0.009492283760246434 | validation: 0.007409128269842949]
	TIME [epoch: 31.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00653172219441738		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.00653172219441738 | validation: 0.005245481665592942]
	TIME [epoch: 31.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036963083204096777		[learning rate: 0.0022868]
	Learning Rate: 0.00228681
	LOSS [training: 0.0036963083204096777 | validation: 0.007888537054835389]
	TIME [epoch: 31.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00702027703038757		[learning rate: 0.0022814]
	Learning Rate: 0.00228142
	LOSS [training: 0.00702027703038757 | validation: 0.010207269667642658]
	TIME [epoch: 31.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075717970543071385		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.0075717970543071385 | validation: 0.005230849996613578]
	TIME [epoch: 31.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005054046716017639		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.005054046716017639 | validation: 0.006417562771629037]
	TIME [epoch: 31.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037824493307315266		[learning rate: 0.0022653]
	Learning Rate: 0.00226531
	LOSS [training: 0.0037824493307315266 | validation: 0.009887180106373607]
	TIME [epoch: 31.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006638004716215288		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.006638004716215288 | validation: 0.008050342477822763]
	TIME [epoch: 31.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042576542893989966		[learning rate: 0.0022546]
	Learning Rate: 0.00225464
	LOSS [training: 0.0042576542893989966 | validation: 0.00548591122293362]
	TIME [epoch: 32 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009802955574003108		[learning rate: 0.0022493]
	Learning Rate: 0.00224932
	LOSS [training: 0.009802955574003108 | validation: 0.006084514300172194]
	TIME [epoch: 32 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004020749498487926		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.004020749498487926 | validation: 0.0037701089003432525]
	TIME [epoch: 31.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006052943339006404		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.006052943339006404 | validation: 0.005745116086730144]
	TIME [epoch: 31.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034734676640237098		[learning rate: 0.0022334]
	Learning Rate: 0.00223344
	LOSS [training: 0.0034734676640237098 | validation: 0.0052281581019017675]
	TIME [epoch: 31.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009168793738121952		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.009168793738121952 | validation: 0.006687739997962769]
	TIME [epoch: 31.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004073047214744984		[learning rate: 0.0022229]
	Learning Rate: 0.00222292
	LOSS [training: 0.004073047214744984 | validation: 0.006524506754003963]
	TIME [epoch: 31.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004313935952839592		[learning rate: 0.0022177]
	Learning Rate: 0.00221767
	LOSS [training: 0.004313935952839592 | validation: 0.006434348936400859]
	TIME [epoch: 31.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005474040349427031		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.005474040349427031 | validation: 0.018904289771794543]
	TIME [epoch: 31.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010795864240150102		[learning rate: 0.0022072]
	Learning Rate: 0.00220722
	LOSS [training: 0.010795864240150102 | validation: 0.004912016575748649]
	TIME [epoch: 32 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004090885627613021		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.004090885627613021 | validation: 0.00341877694638941]
	TIME [epoch: 31.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004847687281936885		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.004847687281936885 | validation: 0.009291590181842491]
	TIME [epoch: 31.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004998364306005126		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.004998364306005126 | validation: 0.0070017891934203436]
	TIME [epoch: 31.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004782589421099567		[learning rate: 0.0021865]
	Learning Rate: 0.00218647
	LOSS [training: 0.004782589421099567 | validation: 0.006916697265174228]
	TIME [epoch: 31.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006377963776818275		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.006377963776818275 | validation: 0.005246222667312053]
	TIME [epoch: 31.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004247196585260843		[learning rate: 0.0021762]
	Learning Rate: 0.00217617
	LOSS [training: 0.004247196585260843 | validation: 0.0030277585092675424]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005852055890440086		[learning rate: 0.002171]
	Learning Rate: 0.00217103
	LOSS [training: 0.005852055890440086 | validation: 0.008250772469822653]
	TIME [epoch: 31.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006087568203184256		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.006087568203184256 | validation: 0.00748327006351268]
	TIME [epoch: 31.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005823884936503545		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.005823884936503545 | validation: 0.0030852729675174793]
	TIME [epoch: 31.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00491413398418658		[learning rate: 0.0021557]
	Learning Rate: 0.00215571
	LOSS [training: 0.00491413398418658 | validation: 0.0062290607335957395]
	TIME [epoch: 32 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007100330124125767		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.007100330124125767 | validation: 0.005297400359634042]
	TIME [epoch: 32 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003982856170447306		[learning rate: 0.0021455]
	Learning Rate: 0.00214555
	LOSS [training: 0.003982856170447306 | validation: 0.003545631880781462]
	TIME [epoch: 31.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035492084859966313		[learning rate: 0.0021405]
	Learning Rate: 0.00214049
	LOSS [training: 0.0035492084859966313 | validation: 0.010471268000867966]
	TIME [epoch: 31.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007504490435143391		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.007504490435143391 | validation: 0.0038294645203656363]
	TIME [epoch: 31.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004255865557545281		[learning rate: 0.0021304]
	Learning Rate: 0.0021304
	LOSS [training: 0.004255865557545281 | validation: 0.005871123165144749]
	TIME [epoch: 32 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004868681900311001		[learning rate: 0.0021254]
	Learning Rate: 0.00212538
	LOSS [training: 0.004868681900311001 | validation: 0.00583102837252635]
	TIME [epoch: 31.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005863164216945701		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.005863164216945701 | validation: 0.004638135330570148]
	TIME [epoch: 31.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002561954841946967		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.002561954841946967 | validation: 0.004312432087437821]
	TIME [epoch: 31.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007499332550270393		[learning rate: 0.0021104]
	Learning Rate: 0.00211037
	LOSS [training: 0.007499332550270393 | validation: 0.004290830012280533]
	TIME [epoch: 32 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004808919272811847		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.004808919272811847 | validation: 0.004726612746623885]
	TIME [epoch: 32 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00302310759850623		[learning rate: 0.0021004]
	Learning Rate: 0.00210043
	LOSS [training: 0.00302310759850623 | validation: 0.0047661280415906655]
	TIME [epoch: 32 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00850638781656722		[learning rate: 0.0020955]
	Learning Rate: 0.00209547
	LOSS [training: 0.00850638781656722 | validation: 0.004860953869133654]
	TIME [epoch: 31.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038425862205887585		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.0038425862205887585 | validation: 0.004203819529018071]
	TIME [epoch: 31.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004164319905272434		[learning rate: 0.0020856]
	Learning Rate: 0.0020856
	LOSS [training: 0.004164319905272434 | validation: 0.005391418372133645]
	TIME [epoch: 31.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00487760435471922		[learning rate: 0.0020807]
	Learning Rate: 0.00208068
	LOSS [training: 0.00487760435471922 | validation: 0.006150280945260756]
	TIME [epoch: 32 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065357105760197225		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.0065357105760197225 | validation: 0.005493281784071918]
	TIME [epoch: 32 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00354075391614748		[learning rate: 0.0020709]
	Learning Rate: 0.00207087
	LOSS [training: 0.00354075391614748 | validation: 0.0036135570036886842]
	TIME [epoch: 31.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008179036079262948		[learning rate: 0.002066]
	Learning Rate: 0.00206599
	LOSS [training: 0.008179036079262948 | validation: 0.0042831597822805415]
	TIME [epoch: 31.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005341680546606616		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.005341680546606616 | validation: 0.007593280050453309]
	TIME [epoch: 32 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004020198640696604		[learning rate: 0.0020563]
	Learning Rate: 0.00205626
	LOSS [training: 0.004020198640696604 | validation: 0.006476671587158548]
	TIME [epoch: 31.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034407106254175077		[learning rate: 0.0020514]
	Learning Rate: 0.0020514
	LOSS [training: 0.0034407106254175077 | validation: 0.006051135796187931]
	TIME [epoch: 31.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006199593901127482		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.006199593901127482 | validation: 0.003591342976657696]
	TIME [epoch: 31.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004682483659155744		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.004682483659155744 | validation: 0.00750831245247715]
	TIME [epoch: 31.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005885949496912499		[learning rate: 0.0020369]
	Learning Rate: 0.00203692
	LOSS [training: 0.005885949496912499 | validation: 0.005891455563123817]
	TIME [epoch: 32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003826448052620081		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.003826448052620081 | validation: 0.003391406242002846]
	TIME [epoch: 32 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004574321964864712		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.004574321964864712 | validation: 0.015608798876256793]
	TIME [epoch: 31.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007656002525904252		[learning rate: 0.0020225]
	Learning Rate: 0.00202254
	LOSS [training: 0.007656002525904252 | validation: 0.005670576042372674]
	TIME [epoch: 31.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004409424686070008		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.004409424686070008 | validation: 0.0031300170382935503]
	TIME [epoch: 32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002415731637233423		[learning rate: 0.002013]
	Learning Rate: 0.00201301
	LOSS [training: 0.002415731637233423 | validation: 0.0034226749424726127]
	TIME [epoch: 32 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00820945955922332		[learning rate: 0.0020083]
	Learning Rate: 0.00200826
	LOSS [training: 0.00820945955922332 | validation: 0.008108570059943889]
	TIME [epoch: 32.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004035078356738954		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.004035078356738954 | validation: 0.005089142363274996]
	TIME [epoch: 32.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003474956230889393		[learning rate: 0.0019988]
	Learning Rate: 0.0019988
	LOSS [training: 0.003474956230889393 | validation: 0.005989917071531148]
	TIME [epoch: 32 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006460813031116428		[learning rate: 0.0019941]
	Learning Rate: 0.00199408
	LOSS [training: 0.006460813031116428 | validation: 0.008670293957108707]
	TIME [epoch: 32.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004728107616260779		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.004728107616260779 | validation: 0.005541169265370823]
	TIME [epoch: 32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003793981710176716		[learning rate: 0.0019847]
	Learning Rate: 0.00198469
	LOSS [training: 0.003793981710176716 | validation: 0.004217685357615063]
	TIME [epoch: 32.1 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005138905036409525		[learning rate: 0.00198]
	Learning Rate: 0.00198001
	LOSS [training: 0.005138905036409525 | validation: 0.0035836715844020342]
	TIME [epoch: 32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035435665537905253		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.0035435665537905253 | validation: 0.01138196496802453]
	TIME [epoch: 32 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00587954611891323		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.00587954611891323 | validation: 0.004574748150758768]
	TIME [epoch: 31.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004118673907690623		[learning rate: 0.001966]
	Learning Rate: 0.00196603
	LOSS [training: 0.004118673907690623 | validation: 0.006120153765508219]
	TIME [epoch: 31.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032109939009528528		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.0032109939009528528 | validation: 0.0031195466593035752]
	TIME [epoch: 32 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00307765400359979		[learning rate: 0.0019568]
	Learning Rate: 0.00195676
	LOSS [training: 0.00307765400359979 | validation: 0.006228635456661002]
	TIME [epoch: 31.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00910637548414774		[learning rate: 0.0019521]
	Learning Rate: 0.00195215
	LOSS [training: 0.00910637548414774 | validation: 0.004468015488985301]
	TIME [epoch: 31.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036805218187458836		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.0036805218187458836 | validation: 0.0057100581743797126]
	TIME [epoch: 31.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004826046816835095		[learning rate: 0.0019429]
	Learning Rate: 0.00194295
	LOSS [training: 0.004826046816835095 | validation: 0.004315620021981775]
	TIME [epoch: 31.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035191450105930134		[learning rate: 0.0019384]
	Learning Rate: 0.00193837
	LOSS [training: 0.0035191450105930134 | validation: 0.002472840553891067]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004465124715591722		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.004465124715591722 | validation: 0.007638690718714755]
	TIME [epoch: 31.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005865343619902597		[learning rate: 0.0019292]
	Learning Rate: 0.00192923
	LOSS [training: 0.005865343619902597 | validation: 0.0033650755701749952]
	TIME [epoch: 31.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036815544450776927		[learning rate: 0.0019247]
	Learning Rate: 0.00192468
	LOSS [training: 0.0036815544450776927 | validation: 0.005873526034375343]
	TIME [epoch: 31.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005446797720434114		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.005446797720434114 | validation: 0.003028890861523541]
	TIME [epoch: 31.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003294614546306611		[learning rate: 0.0019156]
	Learning Rate: 0.00191561
	LOSS [training: 0.003294614546306611 | validation: 0.007213955798919436]
	TIME [epoch: 31.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006159460625287471		[learning rate: 0.0019111]
	Learning Rate: 0.00191109
	LOSS [training: 0.006159460625287471 | validation: 0.005615516617071366]
	TIME [epoch: 31.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044612141682019504		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.0044612141682019504 | validation: 0.006269302170051994]
	TIME [epoch: 31.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004177094962565667		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.004177094962565667 | validation: 0.004021323162988982]
	TIME [epoch: 31.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003858676834323589		[learning rate: 0.0018976]
	Learning Rate: 0.0018976
	LOSS [training: 0.003858676834323589 | validation: 0.00749829063107056]
	TIME [epoch: 31.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004563953910471161		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.004563953910471161 | validation: 0.002811068765968084]
	TIME [epoch: 31.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027594907182286995		[learning rate: 0.0018887]
	Learning Rate: 0.00188866
	LOSS [training: 0.0027594907182286995 | validation: 0.005843357607397261]
	TIME [epoch: 31.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005536238931624735		[learning rate: 0.0018842]
	Learning Rate: 0.00188421
	LOSS [training: 0.005536238931624735 | validation: 0.003078747537972404]
	TIME [epoch: 31.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052779998651052325		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.0052779998651052325 | validation: 0.0062125595623643715]
	TIME [epoch: 31.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029269385245387835		[learning rate: 0.0018753]
	Learning Rate: 0.00187533
	LOSS [training: 0.0029269385245387835 | validation: 0.003585599325169826]
	TIME [epoch: 31.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005627002404044288		[learning rate: 0.0018709]
	Learning Rate: 0.0018709
	LOSS [training: 0.005627002404044288 | validation: 0.006464074015086807]
	TIME [epoch: 31.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031344015758909168		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.0031344015758909168 | validation: 0.007806645117730952]
	TIME [epoch: 31.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036365659359206795		[learning rate: 0.0018621]
	Learning Rate: 0.00186209
	LOSS [training: 0.0036365659359206795 | validation: 0.002958249857554659]
	TIME [epoch: 31.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038304017394597337		[learning rate: 0.0018577]
	Learning Rate: 0.00185769
	LOSS [training: 0.0038304017394597337 | validation: 0.0038773511109582515]
	TIME [epoch: 32 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004747029692969923		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.004747029692969923 | validation: 0.014125750174588017]
	TIME [epoch: 31.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006033836802995427		[learning rate: 0.0018489]
	Learning Rate: 0.00184894
	LOSS [training: 0.006033836802995427 | validation: 0.008034794207444624]
	TIME [epoch: 31.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031993867029486093		[learning rate: 0.0018446]
	Learning Rate: 0.00184458
	LOSS [training: 0.0031993867029486093 | validation: 0.00550558907862601]
	TIME [epoch: 31.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003170090511570806		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.003170090511570806 | validation: 0.005161119804790521]
	TIME [epoch: 32 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004899383989434678		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.004899383989434678 | validation: 0.003782875174861847]
	TIME [epoch: 32 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026991797217177913		[learning rate: 0.0018316]
	Learning Rate: 0.00183156
	LOSS [training: 0.0026991797217177913 | validation: 0.008662537754111795]
	TIME [epoch: 32.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006357600225820199		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.006357600225820199 | validation: 0.003683656672482396]
	TIME [epoch: 31.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029897210326929736		[learning rate: 0.0018229]
	Learning Rate: 0.00182293
	LOSS [training: 0.0029897210326929736 | validation: 0.0044097200576195]
	TIME [epoch: 32 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004230682470366586		[learning rate: 0.0018186]
	Learning Rate: 0.00181863
	LOSS [training: 0.004230682470366586 | validation: 0.006900299914928522]
	TIME [epoch: 32 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003603799815941641		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.003603799815941641 | validation: 0.0028054947152910464]
	TIME [epoch: 31.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036082748722183955		[learning rate: 0.0018101]
	Learning Rate: 0.00181006
	LOSS [training: 0.0036082748722183955 | validation: 0.0042738461142311215]
	TIME [epoch: 32 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003328246660416217		[learning rate: 0.0018058]
	Learning Rate: 0.00180579
	LOSS [training: 0.003328246660416217 | validation: 0.007281942731590855]
	TIME [epoch: 31.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061339713826059315		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.0061339713826059315 | validation: 0.0041085781150680175]
	TIME [epoch: 31.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003604807748479954		[learning rate: 0.0017973]
	Learning Rate: 0.00179728
	LOSS [training: 0.003604807748479954 | validation: 0.008151195186467865]
	TIME [epoch: 32 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032375751175039587		[learning rate: 0.001793]
	Learning Rate: 0.00179304
	LOSS [training: 0.0032375751175039587 | validation: 0.0032112741932007554]
	TIME [epoch: 31.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038123863682627676		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.0038123863682627676 | validation: 0.011496224725627885]
	TIME [epoch: 31.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005110386638006122		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.005110386638006122 | validation: 0.0028861751337200007]
	TIME [epoch: 31.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024965593531754214		[learning rate: 0.0017804]
	Learning Rate: 0.00178038
	LOSS [training: 0.0024965593531754214 | validation: 0.006541256670709996]
	TIME [epoch: 31.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005895807676271257		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.005895807676271257 | validation: 0.007181298020316399]
	TIME [epoch: 31.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00491760551320642		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.00491760551320642 | validation: 0.003601695859431543]
	TIME [epoch: 31.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033009058510299573		[learning rate: 0.0017678]
	Learning Rate: 0.00176781
	LOSS [training: 0.0033009058510299573 | validation: 0.003731589401060604]
	TIME [epoch: 31.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003350328123414642		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.003350328123414642 | validation: 0.005971537230066498]
	TIME [epoch: 31.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00501574263739747		[learning rate: 0.0017595]
	Learning Rate: 0.00175948
	LOSS [training: 0.00501574263739747 | validation: 0.0035604746201044844]
	TIME [epoch: 31.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003888929133440738		[learning rate: 0.0017553]
	Learning Rate: 0.00175533
	LOSS [training: 0.003888929133440738 | validation: 0.0038573146687460843]
	TIME [epoch: 31.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002666826636597629		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.002666826636597629 | validation: 0.005446243287464143]
	TIME [epoch: 31.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043298785414328115		[learning rate: 0.0017471]
	Learning Rate: 0.00174706
	LOSS [training: 0.0043298785414328115 | validation: 0.006022880581828587]
	TIME [epoch: 31.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005352764982963479		[learning rate: 0.0017429]
	Learning Rate: 0.00174294
	LOSS [training: 0.005352764982963479 | validation: 0.003524803473748531]
	TIME [epoch: 31.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002940685476915958		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.002940685476915958 | validation: 0.0034610231509256376]
	TIME [epoch: 31.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004170653094587529		[learning rate: 0.0017347]
	Learning Rate: 0.00173473
	LOSS [training: 0.004170653094587529 | validation: 0.00408432519032096]
	TIME [epoch: 31.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002643338186814851		[learning rate: 0.0017306]
	Learning Rate: 0.00173063
	LOSS [training: 0.002643338186814851 | validation: 0.0035258510713741236]
	TIME [epoch: 31.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003212311837097915		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.003212311837097915 | validation: 0.004658618070646628]
	TIME [epoch: 31.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048575696294276514		[learning rate: 0.0017225]
	Learning Rate: 0.00172248
	LOSS [training: 0.0048575696294276514 | validation: 0.005609815383990289]
	TIME [epoch: 31.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004010748708112216		[learning rate: 0.0017184]
	Learning Rate: 0.00171842
	LOSS [training: 0.004010748708112216 | validation: 0.003665587494117915]
	TIME [epoch: 32 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029099067847185266		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.0029099067847185266 | validation: 0.003150359905946098]
	TIME [epoch: 32 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004178731218705331		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.004178731218705331 | validation: 0.004924986548103742]
	TIME [epoch: 31.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037750768791254474		[learning rate: 0.0017063]
	Learning Rate: 0.00170628
	LOSS [training: 0.0037750768791254474 | validation: 0.006545605255469508]
	TIME [epoch: 32 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037978171713217005		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.0037978171713217005 | validation: 0.0031830958473483576]
	TIME [epoch: 32 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033226808668777143		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.0033226808668777143 | validation: 0.004508342502622352]
	TIME [epoch: 32.1 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006472636338182302		[learning rate: 0.0016942]
	Learning Rate: 0.00169424
	LOSS [training: 0.006472636338182302 | validation: 0.003658024912112927]
	TIME [epoch: 32 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002642492735395715		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.002642492735395715 | validation: 0.0018602918451630526]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002049382276154218		[learning rate: 0.0016863]
	Learning Rate: 0.00168625
	LOSS [training: 0.002049382276154218 | validation: 0.005256865156200021]
	TIME [epoch: 32 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005823615383934087		[learning rate: 0.0016823]
	Learning Rate: 0.00168228
	LOSS [training: 0.005823615383934087 | validation: 0.004439882019110953]
	TIME [epoch: 32.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035072415264269362		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.0035072415264269362 | validation: 0.005133715553207168]
	TIME [epoch: 34.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00279262015504788		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.00279262015504788 | validation: 0.005576344493785577]
	TIME [epoch: 32.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004611426055084246		[learning rate: 0.0016704]
	Learning Rate: 0.0016704
	LOSS [training: 0.004611426055084246 | validation: 0.0066119590119171085]
	TIME [epoch: 32 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030702900491337724		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.0030702900491337724 | validation: 0.005048536552298689]
	TIME [epoch: 32.2 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004024075185685745		[learning rate: 0.0016625]
	Learning Rate: 0.00166253
	LOSS [training: 0.004024075185685745 | validation: 0.005684584802730271]
	TIME [epoch: 32.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002888433336687253		[learning rate: 0.0016586]
	Learning Rate: 0.00165861
	LOSS [training: 0.002888433336687253 | validation: 0.00408498385481048]
	TIME [epoch: 32.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003836120757756082		[learning rate: 0.0016547]
	Learning Rate: 0.0016547
	LOSS [training: 0.003836120757756082 | validation: 0.003669293764354582]
	TIME [epoch: 32.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044443702263267815		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.0044443702263267815 | validation: 0.00523990069051517]
	TIME [epoch: 32.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033552169980894117		[learning rate: 0.0016469]
	Learning Rate: 0.0016469
	LOSS [training: 0.0033552169980894117 | validation: 0.0027691755278332845]
	TIME [epoch: 32.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002911232970958494		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.002911232970958494 | validation: 0.005642534820416748]
	TIME [epoch: 32.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003738408450649786		[learning rate: 0.0016391]
	Learning Rate: 0.00163914
	LOSS [training: 0.003738408450649786 | validation: 0.0037535067431180005]
	TIME [epoch: 32.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00233853106636195		[learning rate: 0.0016353]
	Learning Rate: 0.00163527
	LOSS [training: 0.00233853106636195 | validation: 0.004703468225830899]
	TIME [epoch: 32.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003685930521172707		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.003685930521172707 | validation: 0.003877813586294322]
	TIME [epoch: 32.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035669233929756833		[learning rate: 0.0016276]
	Learning Rate: 0.00162757
	LOSS [training: 0.0035669233929756833 | validation: 0.006836784448500197]
	TIME [epoch: 32.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004603236367596076		[learning rate: 0.0016237]
	Learning Rate: 0.00162373
	LOSS [training: 0.004603236367596076 | validation: 0.003490342514466894]
	TIME [epoch: 32.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028155926025314974		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.0028155926025314974 | validation: 0.008850466328338216]
	TIME [epoch: 32.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037124133897032227		[learning rate: 0.0016161]
	Learning Rate: 0.00161608
	LOSS [training: 0.0037124133897032227 | validation: 0.0028055405275739654]
	TIME [epoch: 32.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019224508684991942		[learning rate: 0.0016123]
	Learning Rate: 0.00161226
	LOSS [training: 0.0019224508684991942 | validation: 0.002627965013525272]
	TIME [epoch: 32 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005768992308172574		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.005768992308172574 | validation: 0.005242971297499422]
	TIME [epoch: 32 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003474745025545756		[learning rate: 0.0016047]
	Learning Rate: 0.00160467
	LOSS [training: 0.003474745025545756 | validation: 0.00244526915739376]
	TIME [epoch: 32.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002285449527574878		[learning rate: 0.0016009]
	Learning Rate: 0.00160088
	LOSS [training: 0.002285449527574878 | validation: 0.0021829583598626874]
	TIME [epoch: 32.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025214630248896704		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.0025214630248896704 | validation: 0.002980038347150741]
	TIME [epoch: 32.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004616577353747658		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.004616577353747658 | validation: 0.0032283739466547746]
	TIME [epoch: 31.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00363032809175816		[learning rate: 0.0015896]
	Learning Rate: 0.00158958
	LOSS [training: 0.00363032809175816 | validation: 0.004844887722818017]
	TIME [epoch: 32.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026197211451937617		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.0026197211451937617 | validation: 0.003107841953275303]
	TIME [epoch: 32.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002424852824148041		[learning rate: 0.0015821]
	Learning Rate: 0.00158209
	LOSS [training: 0.002424852824148041 | validation: 0.0038202949888234044]
	TIME [epoch: 32.1 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005647833467479378		[learning rate: 0.0015784]
	Learning Rate: 0.00157836
	LOSS [training: 0.005647833467479378 | validation: 0.00506669048680887]
	TIME [epoch: 31.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002529601143040268		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.002529601143040268 | validation: 0.00276469258824212]
	TIME [epoch: 32 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019466714829857305		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.0019466714829857305 | validation: 0.0027200077330184497]
	TIME [epoch: 32 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003956265629106475		[learning rate: 0.0015672]
	Learning Rate: 0.00156721
	LOSS [training: 0.003956265629106475 | validation: 0.00514000828746802]
	TIME [epoch: 32 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030616918656137613		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.0030616918656137613 | validation: 0.0038174151025400383]
	TIME [epoch: 32 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030696309908395322		[learning rate: 0.0015598]
	Learning Rate: 0.00155983
	LOSS [training: 0.0030696309908395322 | validation: 0.004109001430929586]
	TIME [epoch: 32 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002747304455331145		[learning rate: 0.0015561]
	Learning Rate: 0.00155615
	LOSS [training: 0.002747304455331145 | validation: 0.007665370552304788]
	TIME [epoch: 31.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004003175814236476		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.004003175814236476 | validation: 0.0038545919989247087]
	TIME [epoch: 32 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025246259483532115		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.0025246259483532115 | validation: 0.0025880724440784392]
	TIME [epoch: 32.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033739426681011113		[learning rate: 0.0015452]
	Learning Rate: 0.00154516
	LOSS [training: 0.0033739426681011113 | validation: 0.003993051519455226]
	TIME [epoch: 32 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035304578293545476		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.0035304578293545476 | validation: 0.0028033347577351418]
	TIME [epoch: 32 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020391448306574344		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.0020391448306574344 | validation: 0.002713086670274479]
	TIME [epoch: 32.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024255739649907846		[learning rate: 0.0015343]
	Learning Rate: 0.00153425
	LOSS [training: 0.0024255739649907846 | validation: 0.006233795453342551]
	TIME [epoch: 32 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043851552963852306		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.0043851552963852306 | validation: 0.0031820568767956534]
	TIME [epoch: 31.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032341043685092923		[learning rate: 0.001527]
	Learning Rate: 0.00152703
	LOSS [training: 0.0032341043685092923 | validation: 0.003999641284689266]
	TIME [epoch: 32 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034608063018253315		[learning rate: 0.0015234]
	Learning Rate: 0.00152342
	LOSS [training: 0.0034608063018253315 | validation: 0.004545379755108528]
	TIME [epoch: 31.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031719236871190094		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.0031719236871190094 | validation: 0.0026408830318167694]
	TIME [epoch: 31.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002583569723282134		[learning rate: 0.0015162]
	Learning Rate: 0.00151624
	LOSS [training: 0.002583569723282134 | validation: 0.004334972991568738]
	TIME [epoch: 31.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002912716159233855		[learning rate: 0.0015127]
	Learning Rate: 0.00151267
	LOSS [training: 0.002912716159233855 | validation: 0.003910409327513282]
	TIME [epoch: 32 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004624174113450085		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.004624174113450085 | validation: 0.00297036737460723]
	TIME [epoch: 32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00273190057076229		[learning rate: 0.0015055]
	Learning Rate: 0.00150554
	LOSS [training: 0.00273190057076229 | validation: 0.005187692324263768]
	TIME [epoch: 31.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002584749543219462		[learning rate: 0.001502]
	Learning Rate: 0.00150199
	LOSS [training: 0.002584749543219462 | validation: 0.0024028907494175362]
	TIME [epoch: 31.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023848887643245524		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.0023848887643245524 | validation: 0.006994747440611456]
	TIME [epoch: 31.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028051484703004977		[learning rate: 0.0014949]
	Learning Rate: 0.00149491
	LOSS [training: 0.0028051484703004977 | validation: 0.0050465095341687095]
	TIME [epoch: 31.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006316281735745025		[learning rate: 0.0014914]
	Learning Rate: 0.00149139
	LOSS [training: 0.006316281735745025 | validation: 0.002121277621767571]
	TIME [epoch: 31.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002281223172170763		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.002281223172170763 | validation: 0.002474274829694105]
	TIME [epoch: 31.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002298659390862758		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.002298659390862758 | validation: 0.004971340439423874]
	TIME [epoch: 31.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035107972793840913		[learning rate: 0.0014809]
	Learning Rate: 0.00148086
	LOSS [training: 0.0035107972793840913 | validation: 0.0020778639230336947]
	TIME [epoch: 31.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016525239403472549		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.0016525239403472549 | validation: 0.002070366038442419]
	TIME [epoch: 31.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004654412880281074		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.004654412880281074 | validation: 0.005372605195171709]
	TIME [epoch: 31.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00314907263245969		[learning rate: 0.0014704]
	Learning Rate: 0.0014704
	LOSS [training: 0.00314907263245969 | validation: 0.0029160886639031285]
	TIME [epoch: 31.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002809175548268531		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.002809175548268531 | validation: 0.002745702173446553]
	TIME [epoch: 31.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002773812344224061		[learning rate: 0.0014635]
	Learning Rate: 0.00146347
	LOSS [training: 0.002773812344224061 | validation: 0.004635640476062956]
	TIME [epoch: 31.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003315993655070388		[learning rate: 0.00146]
	Learning Rate: 0.00146002
	LOSS [training: 0.003315993655070388 | validation: 0.002671546408283965]
	TIME [epoch: 31.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001778455624940669		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.001778455624940669 | validation: 0.00323303087129874]
	TIME [epoch: 31.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003583241280361249		[learning rate: 0.0014531]
	Learning Rate: 0.00145314
	LOSS [training: 0.003583241280361249 | validation: 0.0063301696494802865]
	TIME [epoch: 31.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038109041652744846		[learning rate: 0.0014497]
	Learning Rate: 0.00144971
	LOSS [training: 0.0038109041652744846 | validation: 0.003774495541753341]
	TIME [epoch: 31.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022304376473257855		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.0022304376473257855 | validation: 0.004153040496501427]
	TIME [epoch: 32 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030854267318473905		[learning rate: 0.0014429]
	Learning Rate: 0.00144288
	LOSS [training: 0.0030854267318473905 | validation: 0.002607940478242075]
	TIME [epoch: 31.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029980241656251357		[learning rate: 0.0014395]
	Learning Rate: 0.00143948
	LOSS [training: 0.0029980241656251357 | validation: 0.003782809038783791]
	TIME [epoch: 31.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024059987358715524		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.0024059987358715524 | validation: 0.006111144864170722]
	TIME [epoch: 32 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024652602807764623		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.0024652602807764623 | validation: 0.00458134027165026]
	TIME [epoch: 31.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004821248928647664		[learning rate: 0.0014293]
	Learning Rate: 0.00142932
	LOSS [training: 0.004821248928647664 | validation: 0.0023727368160550693]
	TIME [epoch: 31.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021249733038471103		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.0021249733038471103 | validation: 0.004575189624765507]
	TIME [epoch: 31.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025254497309106414		[learning rate: 0.0014226]
	Learning Rate: 0.00142258
	LOSS [training: 0.0025254497309106414 | validation: 0.004910942208629199]
	TIME [epoch: 31.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034650915229126134		[learning rate: 0.0014192]
	Learning Rate: 0.00141923
	LOSS [training: 0.0034650915229126134 | validation: 0.0030164225983385267]
	TIME [epoch: 32 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002585975357373821		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.002585975357373821 | validation: 0.003947980561040445]
	TIME [epoch: 31.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003138271964964515		[learning rate: 0.0014125]
	Learning Rate: 0.00141254
	LOSS [training: 0.003138271964964515 | validation: 0.0026202570854790006]
	TIME [epoch: 32 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017136468341161953		[learning rate: 0.0014092]
	Learning Rate: 0.00140921
	LOSS [training: 0.0017136468341161953 | validation: 0.003224428954779395]
	TIME [epoch: 32.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004101836560795209		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.004101836560795209 | validation: 0.003488567418410997]
	TIME [epoch: 31.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024376858227554143		[learning rate: 0.0014026]
	Learning Rate: 0.00140257
	LOSS [training: 0.0024376858227554143 | validation: 0.004110874523352158]
	TIME [epoch: 31.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004433816245316104		[learning rate: 0.0013993]
	Learning Rate: 0.00139926
	LOSS [training: 0.004433816245316104 | validation: 0.006138443337515181]
	TIME [epoch: 31.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003916241676377004		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.003916241676377004 | validation: 0.0036599023483223697]
	TIME [epoch: 32 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024881836688110666		[learning rate: 0.0013927]
	Learning Rate: 0.00139266
	LOSS [training: 0.0024881836688110666 | validation: 0.003104170812567962]
	TIME [epoch: 31.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016425551544462034		[learning rate: 0.0013894]
	Learning Rate: 0.00138938
	LOSS [training: 0.0016425551544462034 | validation: 0.0025603297725337224]
	TIME [epoch: 32.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030363017366362268		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.0030363017366362268 | validation: 0.002692533875396782]
	TIME [epoch: 32.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026532529112689995		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.0026532529112689995 | validation: 0.0028378220173665893]
	TIME [epoch: 32.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002467271565158646		[learning rate: 0.0013796]
	Learning Rate: 0.00137957
	LOSS [training: 0.002467271565158646 | validation: 0.0021741945880207956]
	TIME [epoch: 32.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026879097940808996		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.0026879097940808996 | validation: 0.004346184690078084]
	TIME [epoch: 32.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022107120073145735		[learning rate: 0.0013731]
	Learning Rate: 0.00137307
	LOSS [training: 0.0022107120073145735 | validation: 0.004134773649337769]
	TIME [epoch: 32.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003019748235758916		[learning rate: 0.0013698]
	Learning Rate: 0.00136983
	LOSS [training: 0.003019748235758916 | validation: 0.0028910553714385943]
	TIME [epoch: 32.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002634994332859038		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.002634994332859038 | validation: 0.0024124747984316276]
	TIME [epoch: 32.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004115822069419478		[learning rate: 0.0013634]
	Learning Rate: 0.00136338
	LOSS [training: 0.004115822069419478 | validation: 0.0031958592266078507]
	TIME [epoch: 32.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026818715260012015		[learning rate: 0.0013602]
	Learning Rate: 0.00136016
	LOSS [training: 0.0026818715260012015 | validation: 0.0017813720772542681]
	TIME [epoch: 32.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_895.pth
	Model improved!!!
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021545019508151146		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.0021545019508151146 | validation: 0.0029573482983571023]
	TIME [epoch: 32.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002126126286634285		[learning rate: 0.0013538]
	Learning Rate: 0.00135375
	LOSS [training: 0.002126126286634285 | validation: 0.002654108574268716]
	TIME [epoch: 32.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034066745712973473		[learning rate: 0.0013506]
	Learning Rate: 0.00135056
	LOSS [training: 0.0034066745712973473 | validation: 0.004013386969338754]
	TIME [epoch: 32.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020285494306871935		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.0020285494306871935 | validation: 0.0026425765505312935]
	TIME [epoch: 32.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024377283336647843		[learning rate: 0.0013442]
	Learning Rate: 0.00134419
	LOSS [training: 0.0024377283336647843 | validation: 0.003948454487205888]
	TIME [epoch: 32.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003751253011989524		[learning rate: 0.001341]
	Learning Rate: 0.00134102
	LOSS [training: 0.003751253011989524 | validation: 0.002060477286359929]
	TIME [epoch: 32.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002045059426082101		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.002045059426082101 | validation: 0.004300340507365036]
	TIME [epoch: 32.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002844230405441099		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.002844230405441099 | validation: 0.00314400510616486]
	TIME [epoch: 32.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020939432172119095		[learning rate: 0.0013316]
	Learning Rate: 0.00133155
	LOSS [training: 0.0020939432172119095 | validation: 0.006213764565814545]
	TIME [epoch: 32.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003022692069481049		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.003022692069481049 | validation: 0.00287144305398858]
	TIME [epoch: 32.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018977447619151857		[learning rate: 0.0013253]
	Learning Rate: 0.00132528
	LOSS [training: 0.0018977447619151857 | validation: 0.003298307565451717]
	TIME [epoch: 32.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00315357179439472		[learning rate: 0.0013222]
	Learning Rate: 0.00132215
	LOSS [training: 0.00315357179439472 | validation: 0.0055237523535275924]
	TIME [epoch: 32.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002737700913756768		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.002737700913756768 | validation: 0.002688525860257043]
	TIME [epoch: 32.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003195879113597041		[learning rate: 0.0013159]
	Learning Rate: 0.00131592
	LOSS [training: 0.003195879113597041 | validation: 0.0022177895145519644]
	TIME [epoch: 32.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002105926534632571		[learning rate: 0.0013128]
	Learning Rate: 0.00131282
	LOSS [training: 0.002105926534632571 | validation: 0.0019486094650950155]
	TIME [epoch: 32.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001619368433127622		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.001619368433127622 | validation: 0.0024719983700285412]
	TIME [epoch: 32.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038660102829939755		[learning rate: 0.0013066]
	Learning Rate: 0.00130663
	LOSS [training: 0.0038660102829939755 | validation: 0.0023372448584415392]
	TIME [epoch: 32.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020008628025310594		[learning rate: 0.0013036]
	Learning Rate: 0.00130355
	LOSS [training: 0.0020008628025310594 | validation: 0.0015990556514989427]
	TIME [epoch: 32.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018195666028483987		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.0018195666028483987 | validation: 0.0034158337889380343]
	TIME [epoch: 32.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002700892659809255		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.002700892659809255 | validation: 0.00206947552053596]
	TIME [epoch: 32.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001953563422541344		[learning rate: 0.0012943]
	Learning Rate: 0.00129435
	LOSS [training: 0.001953563422541344 | validation: 0.00431275001786467]
	TIME [epoch: 32.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032745598489403623		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.0032745598489403623 | validation: 0.002716886285370106]
	TIME [epoch: 32.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022292032293248394		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.0022292032293248394 | validation: 0.0030540176419098656]
	TIME [epoch: 32.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024333653050036966		[learning rate: 0.0012852]
	Learning Rate: 0.00128521
	LOSS [training: 0.0024333653050036966 | validation: 0.002989231542066336]
	TIME [epoch: 32.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023347774328113784		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.0023347774328113784 | validation: 0.003834271592631187]
	TIME [epoch: 32.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023107189060010093		[learning rate: 0.0012792]
	Learning Rate: 0.00127915
	LOSS [training: 0.0023107189060010093 | validation: 0.00331276525380451]
	TIME [epoch: 32.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002372402761426449		[learning rate: 0.0012761]
	Learning Rate: 0.00127614
	LOSS [training: 0.002372402761426449 | validation: 0.00413796625558811]
	TIME [epoch: 32.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038835509238698716		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.0038835509238698716 | validation: 0.003652278405029452]
	TIME [epoch: 32.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020857359450765535		[learning rate: 0.0012701]
	Learning Rate: 0.00127012
	LOSS [training: 0.0020857359450765535 | validation: 0.003567209348027337]
	TIME [epoch: 32.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024133232355220114		[learning rate: 0.0012671]
	Learning Rate: 0.00126713
	LOSS [training: 0.0024133232355220114 | validation: 0.002177427010541493]
	TIME [epoch: 32.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021504806195189533		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.0021504806195189533 | validation: 0.0019120716459251606]
	TIME [epoch: 32.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017808343394268861		[learning rate: 0.0012612]
	Learning Rate: 0.00126116
	LOSS [training: 0.0017808343394268861 | validation: 0.003178710269574185]
	TIME [epoch: 32.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003353670094833043		[learning rate: 0.0012582]
	Learning Rate: 0.00125818
	LOSS [training: 0.003353670094833043 | validation: 0.001879847197576403]
	TIME [epoch: 32.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018477835444792822		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.0018477835444792822 | validation: 0.003031217041812268]
	TIME [epoch: 32.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002050868459941534		[learning rate: 0.0012523]
	Learning Rate: 0.00125225
	LOSS [training: 0.002050868459941534 | validation: 0.005420340301260633]
	TIME [epoch: 32.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031112166790361285		[learning rate: 0.0012493]
	Learning Rate: 0.0012493
	LOSS [training: 0.0031112166790361285 | validation: 0.0019540988018074586]
	TIME [epoch: 32.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001920903343893564		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.001920903343893564 | validation: 0.0032685258223182105]
	TIME [epoch: 32.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002227721456350911		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.002227721456350911 | validation: 0.0034101093239444404]
	TIME [epoch: 32.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037077596285071054		[learning rate: 0.0012405]
	Learning Rate: 0.00124048
	LOSS [training: 0.0037077596285071054 | validation: 0.0022003793569064694]
	TIME [epoch: 32.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002213501730711176		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.002213501730711176 | validation: 0.003473384246029081]
	TIME [epoch: 32.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017674821669149716		[learning rate: 0.0012346]
	Learning Rate: 0.00123463
	LOSS [training: 0.0017674821669149716 | validation: 0.0018937148724147653]
	TIME [epoch: 32.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001807387484081083		[learning rate: 0.0012317]
	Learning Rate: 0.00123172
	LOSS [training: 0.001807387484081083 | validation: 0.0033465304411643857]
	TIME [epoch: 32.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028320343522218808		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.0028320343522218808 | validation: 0.0025456870103478767]
	TIME [epoch: 32.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001621405752718242		[learning rate: 0.0012259]
	Learning Rate: 0.00122592
	LOSS [training: 0.001621405752718242 | validation: 0.002949116862208645]
	TIME [epoch: 32.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018091501299450016		[learning rate: 0.001223]
	Learning Rate: 0.00122303
	LOSS [training: 0.0018091501299450016 | validation: 0.0021181373832226047]
	TIME [epoch: 32.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033617068221529498		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.0033617068221529498 | validation: 0.0017665838041291304]
	TIME [epoch: 32.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025364043414940218		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.0025364043414940218 | validation: 0.0021020042922099743]
	TIME [epoch: 32.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017023714148374802		[learning rate: 0.0012144]
	Learning Rate: 0.00121439
	LOSS [training: 0.0017023714148374802 | validation: 0.002289715590266443]
	TIME [epoch: 32.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022021139739645573		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.0022021139739645573 | validation: 0.0026586343540177613]
	TIME [epoch: 32.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019833162610709137		[learning rate: 0.0012087]
	Learning Rate: 0.00120867
	LOSS [training: 0.0019833162610709137 | validation: 0.002549885246682416]
	TIME [epoch: 32.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016487265518046275		[learning rate: 0.0012058]
	Learning Rate: 0.00120582
	LOSS [training: 0.0016487265518046275 | validation: 0.005255061206154193]
	TIME [epoch: 32.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003274508803946919		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.003274508803946919 | validation: 0.001482891274423638]
	TIME [epoch: 32.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014042058352956733		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.0014042058352956733 | validation: 0.0019609923872367496]
	TIME [epoch: 32.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002075163809653654		[learning rate: 0.0011973]
	Learning Rate: 0.00119731
	LOSS [training: 0.002075163809653654 | validation: 0.0030041987939685992]
	TIME [epoch: 32.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015401649362007399		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.0015401649362007399 | validation: 0.003388654439258073]
	TIME [epoch: 32.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002869037894834873		[learning rate: 0.0011917]
	Learning Rate: 0.00119166
	LOSS [training: 0.002869037894834873 | validation: 0.005275744497123455]
	TIME [epoch: 32.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037256658985364557		[learning rate: 0.0011889]
	Learning Rate: 0.00118885
	LOSS [training: 0.0037256658985364557 | validation: 0.0027489194947340314]
	TIME [epoch: 32.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017778507872237494		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.0017778507872237494 | validation: 0.002539846403136962]
	TIME [epoch: 32.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018441122832788936		[learning rate: 0.0011833]
	Learning Rate: 0.00118325
	LOSS [training: 0.0018441122832788936 | validation: 0.0026473767359912314]
	TIME [epoch: 32.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018649213401720887		[learning rate: 0.0011805]
	Learning Rate: 0.00118046
	LOSS [training: 0.0018649213401720887 | validation: 0.0028399382302654813]
	TIME [epoch: 32.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001525495621188778		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.001525495621188778 | validation: 0.0028909118168125173]
	TIME [epoch: 32.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028185940361717195		[learning rate: 0.0011749]
	Learning Rate: 0.0011749
	LOSS [training: 0.0028185940361717195 | validation: 0.005732331501403806]
	TIME [epoch: 32.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022465965254460686		[learning rate: 0.0011721]
	Learning Rate: 0.00117213
	LOSS [training: 0.0022465965254460686 | validation: 0.0026990397408563262]
	TIME [epoch: 32.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001746929561452136		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.001746929561452136 | validation: 0.0022230067338369405]
	TIME [epoch: 32.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014738715843004959		[learning rate: 0.0011666]
	Learning Rate: 0.0011666
	LOSS [training: 0.0014738715843004959 | validation: 0.0030613994375265933]
	TIME [epoch: 32.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003297484020172925		[learning rate: 0.0011639]
	Learning Rate: 0.00116385
	LOSS [training: 0.003297484020172925 | validation: 0.003103854022304889]
	TIME [epoch: 32.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015180557397714255		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.0015180557397714255 | validation: 0.0031153850347494377]
	TIME [epoch: 32.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002097182614461668		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.002097182614461668 | validation: 0.0026277320036172647]
	TIME [epoch: 32.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001889282581045755		[learning rate: 0.0011556]
	Learning Rate: 0.00115563
	LOSS [training: 0.001889282581045755 | validation: 0.0016105530737584397]
	TIME [epoch: 32.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001583744435761832		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.001583744435761832 | validation: 0.002834766752050068]
	TIME [epoch: 32.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017207614585051836		[learning rate: 0.0011502]
	Learning Rate: 0.00115019
	LOSS [training: 0.0017207614585051836 | validation: 0.008294313750628796]
	TIME [epoch: 32.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003673899963234943		[learning rate: 0.0011475]
	Learning Rate: 0.00114748
	LOSS [training: 0.003673899963234943 | validation: 0.0023301441885036304]
	TIME [epoch: 32.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013063865754286154		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.0013063865754286154 | validation: 0.0021853845380242747]
	TIME [epoch: 32.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002075470508976195		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.002075470508976195 | validation: 0.003884499353123562]
	TIME [epoch: 32.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018076231935819002		[learning rate: 0.0011394]
	Learning Rate: 0.00113937
	LOSS [training: 0.0018076231935819002 | validation: 0.002603710520936318]
	TIME [epoch: 32.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027235101729793515		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.0027235101729793515 | validation: 0.0027934635520391648]
	TIME [epoch: 32.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018697573336583936		[learning rate: 0.001134]
	Learning Rate: 0.00113401
	LOSS [training: 0.0018697573336583936 | validation: 0.0035729224193788837]
	TIME [epoch: 32.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001910307789975596		[learning rate: 0.0011313]
	Learning Rate: 0.00113133
	LOSS [training: 0.001910307789975596 | validation: 0.002778864130268519]
	TIME [epoch: 32.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024726505155117273		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.0024726505155117273 | validation: 0.0016777847985624385]
	TIME [epoch: 32.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015053169955801722		[learning rate: 0.001126]
	Learning Rate: 0.001126
	LOSS [training: 0.0015053169955801722 | validation: 0.0023745787549595294]
	TIME [epoch: 32.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002136925074469907		[learning rate: 0.0011233]
	Learning Rate: 0.00112334
	LOSS [training: 0.002136925074469907 | validation: 0.002607610307927101]
	TIME [epoch: 32.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002986644939494019		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.002986644939494019 | validation: 0.004244286579132948]
	TIME [epoch: 32.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022706772702571804		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.0022706772702571804 | validation: 0.0016819918753821046]
	TIME [epoch: 32.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012793606333902385		[learning rate: 0.0011154]
	Learning Rate: 0.00111541
	LOSS [training: 0.0012793606333902385 | validation: 0.002028249821536073]
	TIME [epoch: 32.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017274919889977052		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.0017274919889977052 | validation: 0.0024082967626796545]
	TIME [epoch: 32.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028766643160429693		[learning rate: 0.0011102]
	Learning Rate: 0.00111016
	LOSS [training: 0.0028766643160429693 | validation: 0.0037511252001627346]
	TIME [epoch: 32.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022624832040565317		[learning rate: 0.0011075]
	Learning Rate: 0.00110754
	LOSS [training: 0.0022624832040565317 | validation: 0.0017631341195772682]
	TIME [epoch: 32.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020569518790440645		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.0020569518790440645 | validation: 0.0029454173988597105]
	TIME [epoch: 32.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015546063274403115		[learning rate: 0.0011023]
	Learning Rate: 0.00110232
	LOSS [training: 0.0015546063274403115 | validation: 0.003834042739784196]
	TIME [epoch: 32.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002102603032361535		[learning rate: 0.0010997]
	Learning Rate: 0.00109972
	LOSS [training: 0.002102603032361535 | validation: 0.003208506249823967]
	TIME [epoch: 32.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002276056331042972		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.002276056331042972 | validation: 0.0028139391339224488]
	TIME [epoch: 32.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002708552147451756		[learning rate: 0.0010945]
	Learning Rate: 0.00109454
	LOSS [training: 0.002708552147451756 | validation: 0.001631333239992233]
	TIME [epoch: 32.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001440594924059898		[learning rate: 0.001092]
	Learning Rate: 0.00109196
	LOSS [training: 0.001440594924059898 | validation: 0.003285909016213406]
	TIME [epoch: 32.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001982475741995826		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.001982475741995826 | validation: 0.0021282434192961223]
	TIME [epoch: 32.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010161537662905084		[learning rate: 0.0010868]
	Learning Rate: 0.00108681
	LOSS [training: 0.0010161537662905084 | validation: 0.0016708915071633995]
	TIME [epoch: 32.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030545992529396743		[learning rate: 0.0010842]
	Learning Rate: 0.00108425
	LOSS [training: 0.0030545992529396743 | validation: 0.0019421659243091627]
	TIME [epoch: 32.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00175561141955122		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.00175561141955122 | validation: 0.00300722813398179]
	TIME [epoch: 32.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011488084037562935		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.0011488084037562935 | validation: 0.001888671367758259]
	TIME [epoch: 32.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018031893046661278		[learning rate: 0.0010766]
	Learning Rate: 0.00107659
	LOSS [training: 0.0018031893046661278 | validation: 0.0021806760937274775]
	TIME [epoch: 32.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028216377873250572		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.0028216377873250572 | validation: 0.003332886764427922]
	TIME [epoch: 32.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016161208996459718		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.0016161208996459718 | validation: 0.0026691491965862707]
	TIME [epoch: 32.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013704513500754508		[learning rate: 0.001069]
	Learning Rate: 0.00106899
	LOSS [training: 0.0013704513500754508 | validation: 0.0023838412719336148]
	TIME [epoch: 32.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021102693007604588		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.0021102693007604588 | validation: 0.0018220218931198282]
	TIME [epoch: 32.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002017737650793773		[learning rate: 0.001064]
	Learning Rate: 0.00106395
	LOSS [training: 0.002017737650793773 | validation: 0.004414804578473449]
	TIME [epoch: 32.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023867753343292043		[learning rate: 0.0010614]
	Learning Rate: 0.00106144
	LOSS [training: 0.0023867753343292043 | validation: 0.0017489297432301445]
	TIME [epoch: 32.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001466558914168547		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.001466558914168547 | validation: 0.0025751630600086292]
	TIME [epoch: 174 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021863085574942813		[learning rate: 0.0010564]
	Learning Rate: 0.00105644
	LOSS [training: 0.0021863085574942813 | validation: 0.0033929446132518024]
	TIME [epoch: 69.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002835527082456848		[learning rate: 0.001054]
	Learning Rate: 0.00105395
	LOSS [training: 0.002835527082456848 | validation: 0.004709398932829779]
	TIME [epoch: 69.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002402849817925761		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.002402849817925761 | validation: 0.0024993276832716467]
	TIME [epoch: 69.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002076536246848978		[learning rate: 0.001049]
	Learning Rate: 0.00104898
	LOSS [training: 0.002076536246848978 | validation: 0.004138454569887812]
	TIME [epoch: 69.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018120735730831818		[learning rate: 0.0010465]
	Learning Rate: 0.00104651
	LOSS [training: 0.0018120735730831818 | validation: 0.0023028261416071726]
	TIME [epoch: 69.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019413000969957597		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.0019413000969957597 | validation: 0.0020286614839268744]
	TIME [epoch: 69.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015260926221164414		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.0015260926221164414 | validation: 0.001954240234862552]
	TIME [epoch: 69.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013473329279271745		[learning rate: 0.0010391]
	Learning Rate: 0.00103912
	LOSS [training: 0.0013473329279271745 | validation: 0.0032680165295396442]
	TIME [epoch: 69.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002177971559030344		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.002177971559030344 | validation: 0.0020600542608668775]
	TIME [epoch: 69.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024289399541370374		[learning rate: 0.0010342]
	Learning Rate: 0.00103423
	LOSS [training: 0.0024289399541370374 | validation: 0.0025970529506600215]
	TIME [epoch: 69.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020074938712614137		[learning rate: 0.0010318]
	Learning Rate: 0.00103179
	LOSS [training: 0.0020074938712614137 | validation: 0.002118593977572675]
	TIME [epoch: 69.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00149651047497783		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.00149651047497783 | validation: 0.002330012762713399]
	TIME [epoch: 70 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014969935662946222		[learning rate: 0.0010269]
	Learning Rate: 0.00102692
	LOSS [training: 0.0014969935662946222 | validation: 0.0030064686486798308]
	TIME [epoch: 69.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024718647903382235		[learning rate: 0.0010245]
	Learning Rate: 0.0010245
	LOSS [training: 0.0024718647903382235 | validation: 0.0018030282164218337]
	TIME [epoch: 69.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001397102593099338		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.001397102593099338 | validation: 0.004659348079931774]
	TIME [epoch: 69.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001973725181934734		[learning rate: 0.0010197]
	Learning Rate: 0.00101967
	LOSS [training: 0.001973725181934734 | validation: 0.002761183022375052]
	TIME [epoch: 69.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024303193139304574		[learning rate: 0.0010173]
	Learning Rate: 0.00101727
	LOSS [training: 0.0024303193139304574 | validation: 0.004302701670518726]
	TIME [epoch: 69.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001528356361662682		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.001528356361662682 | validation: 0.0026929471850179326]
	TIME [epoch: 69.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015542062590065296		[learning rate: 0.0010125]
	Learning Rate: 0.00101248
	LOSS [training: 0.0015542062590065296 | validation: 0.0017220696561586432]
	TIME [epoch: 69.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001507147393428161		[learning rate: 0.0010101]
	Learning Rate: 0.00101009
	LOSS [training: 0.001507147393428161 | validation: 0.002340968569467917]
	TIME [epoch: 69.4 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017322771775064609		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.0017322771775064609 | validation: 0.004343157859640065]
	TIME [epoch: 69.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022887453761222167		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.0022887453761222167 | validation: 0.0013546265912364693]
	TIME [epoch: 69.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1023.pth
	Model improved!!!
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018416121455980977		[learning rate: 0.001003]
	Learning Rate: 0.00100296
	LOSS [training: 0.0018416121455980977 | validation: 0.0016811831281424636]
	TIME [epoch: 69.2 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014820097047235365		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.0014820097047235365 | validation: 0.0021347665707795675]
	TIME [epoch: 69.1 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012508869069740485		[learning rate: 0.00099823]
	Learning Rate: 0.000998231
	LOSS [training: 0.0012508869069740485 | validation: 0.0029179142494436894]
	TIME [epoch: 69.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021027479536828183		[learning rate: 0.00099588]
	Learning Rate: 0.000995876
	LOSS [training: 0.0021027479536828183 | validation: 0.004564684702209847]
	TIME [epoch: 69.2 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00226022801958672		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.00226022801958672 | validation: 0.002250125105613338]
	TIME [epoch: 69.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018561570751091205		[learning rate: 0.00099118]
	Learning Rate: 0.000991183
	LOSS [training: 0.0018561570751091205 | validation: 0.0026034352434432407]
	TIME [epoch: 69.2 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016130929586352233		[learning rate: 0.00098885]
	Learning Rate: 0.000988845
	LOSS [training: 0.0016130929586352233 | validation: 0.0031285208464838796]
	TIME [epoch: 69.2 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016013415926670192		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.0016013415926670192 | validation: 0.0019817283945772054]
	TIME [epoch: 69.4 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013573169278147722		[learning rate: 0.00098419]
	Learning Rate: 0.000984185
	LOSS [training: 0.0013573169278147722 | validation: 0.002753111759753854]
	TIME [epoch: 69 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002731126532056157		[learning rate: 0.00098186]
	Learning Rate: 0.000981864
	LOSS [training: 0.002731126532056157 | validation: 0.0027575582791269752]
	TIME [epoch: 69 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018001354089897275		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.0018001354089897275 | validation: 0.001766904441743498]
	TIME [epoch: 69.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010572154733443926		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.0010572154733443926 | validation: 0.0018427229976825492]
	TIME [epoch: 69.1 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011631087157776515		[learning rate: 0.00097493]
	Learning Rate: 0.000974932
	LOSS [training: 0.0011631087157776515 | validation: 0.0023968445909665847]
	TIME [epoch: 69.2 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028743308999126613		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.0028743308999126613 | validation: 0.002000256476233975]
	TIME [epoch: 69.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021152427944826414		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.0021152427944826414 | validation: 0.003358684023606109]
	TIME [epoch: 69.1 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015213168237480038		[learning rate: 0.00096805]
	Learning Rate: 0.000968049
	LOSS [training: 0.0015213168237480038 | validation: 0.0015206811108281917]
	TIME [epoch: 69.2 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001331522014661856		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.001331522014661856 | validation: 0.002209998525033547]
	TIME [epoch: 69.2 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017608184438478948		[learning rate: 0.00096349]
	Learning Rate: 0.000963488
	LOSS [training: 0.0017608184438478948 | validation: 0.001693322919747061]
	TIME [epoch: 69.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010166535357800555		[learning rate: 0.00096121]
	Learning Rate: 0.000961215
	LOSS [training: 0.0010166535357800555 | validation: 0.0018122011389412344]
	TIME [epoch: 69.2 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023841517278277843		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.0023841517278277843 | validation: 0.0021045083430498187]
	TIME [epoch: 69.2 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019389373568938517		[learning rate: 0.00095669]
	Learning Rate: 0.000956686
	LOSS [training: 0.0019389373568938517 | validation: 0.0020010645044034655]
	TIME [epoch: 69.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013269459364529702		[learning rate: 0.00095443]
	Learning Rate: 0.000954429
	LOSS [training: 0.0013269459364529702 | validation: 0.0016364604681804787]
	TIME [epoch: 69.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012040620588849142		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.0012040620588849142 | validation: 0.001475353571154968]
	TIME [epoch: 69.1 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031961667865760537		[learning rate: 0.00094993]
	Learning Rate: 0.000949932
	LOSS [training: 0.0031961667865760537 | validation: 0.0045658111507664995]
	TIME [epoch: 69.4 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027301396361864953		[learning rate: 0.00094769]
	Learning Rate: 0.000947691
	LOSS [training: 0.0027301396361864953 | validation: 0.003127434145051814]
	TIME [epoch: 69.4 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016224309056735494		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.0016224309056735494 | validation: 0.002018075489174742]
	TIME [epoch: 69.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001282722429330833		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.001282722429330833 | validation: 0.002109643364137871]
	TIME [epoch: 69.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015284939971421966		[learning rate: 0.000941]
	Learning Rate: 0.000941
	LOSS [training: 0.0015284939971421966 | validation: 0.0030645594982017664]
	TIME [epoch: 69.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024833785525112677		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.0024833785525112677 | validation: 0.001786435727128602]
	TIME [epoch: 69.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012374502547787222		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.0012374502547787222 | validation: 0.003483858873462911]
	TIME [epoch: 69.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017060968688819781		[learning rate: 0.00093436]
	Learning Rate: 0.000934357
	LOSS [training: 0.0017060968688819781 | validation: 0.002239636614670004]
	TIME [epoch: 69.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015602106178640059		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.0015602106178640059 | validation: 0.0015920719232543192]
	TIME [epoch: 69.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015473233528154977		[learning rate: 0.00092995]
	Learning Rate: 0.000929954
	LOSS [training: 0.0015473233528154977 | validation: 0.0019348405750967493]
	TIME [epoch: 69.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002368891231969924		[learning rate: 0.00092776]
	Learning Rate: 0.000927761
	LOSS [training: 0.002368891231969924 | validation: 0.0025680282128831334]
	TIME [epoch: 70 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012059392957195858		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.0012059392957195858 | validation: 0.0014930463098899295]
	TIME [epoch: 69.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014309552509044977		[learning rate: 0.00092339]
	Learning Rate: 0.000923389
	LOSS [training: 0.0014309552509044977 | validation: 0.001853754150023275]
	TIME [epoch: 69.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020302939228923796		[learning rate: 0.00092121]
	Learning Rate: 0.000921211
	LOSS [training: 0.0020302939228923796 | validation: 0.0016979926202473844]
	TIME [epoch: 69.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016989039189069474		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.0016989039189069474 | validation: 0.003442711604417573]
	TIME [epoch: 69.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015474605529630975		[learning rate: 0.00091687]
	Learning Rate: 0.00091687
	LOSS [training: 0.0015474605529630975 | validation: 0.0015136397780355724]
	TIME [epoch: 69.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001108329918562289		[learning rate: 0.00091471]
	Learning Rate: 0.000914707
	LOSS [training: 0.001108329918562289 | validation: 0.0025549563064726035]
	TIME [epoch: 69.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016571728120202854		[learning rate: 0.00091255]
	Learning Rate: 0.00091255
	LOSS [training: 0.0016571728120202854 | validation: 0.0023330466404180663]
	TIME [epoch: 69.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012119680676111418		[learning rate: 0.0009104]
	Learning Rate: 0.000910397
	LOSS [training: 0.0012119680676111418 | validation: 0.0026132916128158126]
	TIME [epoch: 69.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019983077658119325		[learning rate: 0.00090825]
	Learning Rate: 0.00090825
	LOSS [training: 0.0019983077658119325 | validation: 0.002649992405243622]
	TIME [epoch: 69.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014388576477445134		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.0014388576477445134 | validation: 0.0017520842397410678]
	TIME [epoch: 69.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017016141303052429		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.0017016141303052429 | validation: 0.002127144927570181]
	TIME [epoch: 69.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012956109945895648		[learning rate: 0.00090184]
	Learning Rate: 0.000901837
	LOSS [training: 0.0012956109945895648 | validation: 0.0014833732674300792]
	TIME [epoch: 69.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011181339640831552		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.0011181339640831552 | validation: 0.003065169624716397]
	TIME [epoch: 69.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019225133976774472		[learning rate: 0.00089759]
	Learning Rate: 0.000897588
	LOSS [training: 0.0019225133976774472 | validation: 0.0028730108007043167]
	TIME [epoch: 69.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001953773480057651		[learning rate: 0.00089547]
	Learning Rate: 0.00089547
	LOSS [training: 0.001953773480057651 | validation: 0.002042210018309702]
	TIME [epoch: 69.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015939234401382248		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.0015939234401382248 | validation: 0.002603924094768316]
	TIME [epoch: 69.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017750646114712651		[learning rate: 0.00089125]
	Learning Rate: 0.000891251
	LOSS [training: 0.0017750646114712651 | validation: 0.001513022617946599]
	TIME [epoch: 69.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010856169787474496		[learning rate: 0.00088915]
	Learning Rate: 0.000889149
	LOSS [training: 0.0010856169787474496 | validation: 0.002550889056909038]
	TIME [epoch: 69.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013658193408827282		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.0013658193408827282 | validation: 0.002962179250479168]
	TIME [epoch: 69.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015716153983432795		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.0015716153983432795 | validation: 0.002586706722633307]
	TIME [epoch: 69.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016508713380109204		[learning rate: 0.00088287]
	Learning Rate: 0.000882871
	LOSS [training: 0.0016508713380109204 | validation: 0.0019115522955951134]
	TIME [epoch: 69.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015386414023674361		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.0015386414023674361 | validation: 0.0019781810107210936]
	TIME [epoch: 69.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015022969439627799		[learning rate: 0.00087871]
	Learning Rate: 0.000878711
	LOSS [training: 0.0015022969439627799 | validation: 0.002372278033595487]
	TIME [epoch: 69.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014159902421980993		[learning rate: 0.00087664]
	Learning Rate: 0.000876639
	LOSS [training: 0.0014159902421980993 | validation: 0.002039748323553737]
	TIME [epoch: 69.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017136852286372955		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.0017136852286372955 | validation: 0.0027703123290148297]
	TIME [epoch: 69.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011675311584829478		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.0011675311584829478 | validation: 0.0019292433526950977]
	TIME [epoch: 69.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001277334356759888		[learning rate: 0.00087045]
	Learning Rate: 0.00087045
	LOSS [training: 0.001277334356759888 | validation: 0.0014147541055672024]
	TIME [epoch: 69.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010856756122174223		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.0010856756122174223 | validation: 0.001942598352752106]
	TIME [epoch: 69.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017658575860148617		[learning rate: 0.00086635]
	Learning Rate: 0.000866348
	LOSS [training: 0.0017658575860148617 | validation: 0.0013102464963517554]
	TIME [epoch: 69.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1086.pth
	Model improved!!!
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010562307159965392		[learning rate: 0.0008643]
	Learning Rate: 0.000864304
	LOSS [training: 0.0010562307159965392 | validation: 0.0033435068252894804]
	TIME [epoch: 69.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018268748167062743		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.0018268748167062743 | validation: 0.002918131088021938]
	TIME [epoch: 69.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014884340340481877		[learning rate: 0.00086023]
	Learning Rate: 0.000860232
	LOSS [training: 0.0014884340340481877 | validation: 0.0020294954139095083]
	TIME [epoch: 69.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016861485951477455		[learning rate: 0.0008582]
	Learning Rate: 0.000858202
	LOSS [training: 0.0016861485951477455 | validation: 0.003130412334085013]
	TIME [epoch: 69.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013981315753059387		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.0013981315753059387 | validation: 0.0014938090939165944]
	TIME [epoch: 69.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011683702640759874		[learning rate: 0.00085416]
	Learning Rate: 0.000854159
	LOSS [training: 0.0011683702640759874 | validation: 0.0031903762356584133]
	TIME [epoch: 69.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002435092417153416		[learning rate: 0.00085214]
	Learning Rate: 0.000852144
	LOSS [training: 0.002435092417153416 | validation: 0.0013436133322023637]
	TIME [epoch: 69.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014112885376356718		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.0014112885376356718 | validation: 0.0017257542827860436]
	TIME [epoch: 69.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014361748934911829		[learning rate: 0.00084813]
	Learning Rate: 0.000848128
	LOSS [training: 0.0014361748934911829 | validation: 0.0022627911610705446]
	TIME [epoch: 69.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012637313790151473		[learning rate: 0.00084613]
	Learning Rate: 0.000846128
	LOSS [training: 0.0012637313790151473 | validation: 0.0026326075674412584]
	TIME [epoch: 69.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001854734115010413		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.001854734115010413 | validation: 0.001545599398139032]
	TIME [epoch: 69.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011185961305472368		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.0011185961305472368 | validation: 0.0014668964998226573]
	TIME [epoch: 69.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009913078232550328		[learning rate: 0.00084015]
	Learning Rate: 0.000840154
	LOSS [training: 0.0009913078232550328 | validation: 0.0022685738014021233]
	TIME [epoch: 69.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020516355975261007		[learning rate: 0.00083817]
	Learning Rate: 0.000838173
	LOSS [training: 0.0020516355975261007 | validation: 0.0019927328835457887]
	TIME [epoch: 69.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016993667003217365		[learning rate: 0.0008362]
	Learning Rate: 0.000836195
	LOSS [training: 0.0016993667003217365 | validation: 0.001771104319389405]
	TIME [epoch: 69.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012180319070570795		[learning rate: 0.00083422]
	Learning Rate: 0.000834223
	LOSS [training: 0.0012180319070570795 | validation: 0.0015365800723095627]
	TIME [epoch: 69.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000977732398752187		[learning rate: 0.00083226]
	Learning Rate: 0.000832255
	LOSS [training: 0.000977732398752187 | validation: 0.0022185309798835075]
	TIME [epoch: 69.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012391975714894934		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.0012391975714894934 | validation: 0.00405244957286333]
	TIME [epoch: 69.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019478495187016099		[learning rate: 0.00082833]
	Learning Rate: 0.000828333
	LOSS [training: 0.0019478495187016099 | validation: 0.002985734954418167]
	TIME [epoch: 69.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013387887520370794		[learning rate: 0.00082638]
	Learning Rate: 0.00082638
	LOSS [training: 0.0013387887520370794 | validation: 0.0019177027673750483]
	TIME [epoch: 69.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001532363471487934		[learning rate: 0.00082443]
	Learning Rate: 0.00082443
	LOSS [training: 0.001532363471487934 | validation: 0.002074037880691951]
	TIME [epoch: 69.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001121837018196764		[learning rate: 0.00082249]
	Learning Rate: 0.000822485
	LOSS [training: 0.001121837018196764 | validation: 0.0018091131495744134]
	TIME [epoch: 69.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008614008343384794		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.0008614008343384794 | validation: 0.0023176024013632696]
	TIME [epoch: 69.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014728520413357991		[learning rate: 0.00081861]
	Learning Rate: 0.00081861
	LOSS [training: 0.0014728520413357991 | validation: 0.002201736787671673]
	TIME [epoch: 69.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013350697651684771		[learning rate: 0.00081668]
	Learning Rate: 0.000816679
	LOSS [training: 0.0013350697651684771 | validation: 0.003156397283620794]
	TIME [epoch: 69.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015185593255915566		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.0015185593255915566 | validation: 0.0019055678344666828]
	TIME [epoch: 69.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011572413432030066		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.0011572413432030066 | validation: 0.002219382338325925]
	TIME [epoch: 69.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012786884653964306		[learning rate: 0.00081091]
	Learning Rate: 0.000810913
	LOSS [training: 0.0012786884653964306 | validation: 0.0013988063209662317]
	TIME [epoch: 69.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009759274812568968		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.0009759274812568968 | validation: 0.0024738146348151488]
	TIME [epoch: 69.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013049494920261034		[learning rate: 0.00080709]
	Learning Rate: 0.000807092
	LOSS [training: 0.0013049494920261034 | validation: 0.002615243398812199]
	TIME [epoch: 69.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013682200483759119		[learning rate: 0.00080519]
	Learning Rate: 0.000805188
	LOSS [training: 0.0013682200483759119 | validation: 0.0025509087657601963]
	TIME [epoch: 69.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012893960697465798		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.0012893960697465798 | validation: 0.0014388253534642567]
	TIME [epoch: 69.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010871323152252096		[learning rate: 0.00080139]
	Learning Rate: 0.000801394
	LOSS [training: 0.0010871323152252096 | validation: 0.002153909853721338]
	TIME [epoch: 69.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013129639430499835		[learning rate: 0.0007995]
	Learning Rate: 0.000799504
	LOSS [training: 0.0013129639430499835 | validation: 0.0013274740669218543]
	TIME [epoch: 69.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007612212537348396		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.0007612212537348396 | validation: 0.0017447050325727648]
	TIME [epoch: 69.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016221975632282537		[learning rate: 0.00079574]
	Learning Rate: 0.000795736
	LOSS [training: 0.0016221975632282537 | validation: 0.00171942301150977]
	TIME [epoch: 69.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010437548314846858		[learning rate: 0.00079386]
	Learning Rate: 0.000793859
	LOSS [training: 0.0010437548314846858 | validation: 0.0010163786206079032]
	TIME [epoch: 69.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1123.pth
	Model improved!!!
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013994128284858776		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.0013994128284858776 | validation: 0.0018954524991018752]
	TIME [epoch: 69.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011909472231022827		[learning rate: 0.00079012]
	Learning Rate: 0.000790119
	LOSS [training: 0.0011909472231022827 | validation: 0.0014725835055216044]
	TIME [epoch: 69.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015454141716336506		[learning rate: 0.00078826]
	Learning Rate: 0.000788255
	LOSS [training: 0.0015454141716336506 | validation: 0.0017316250434878766]
	TIME [epoch: 69.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001429189442352		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.001429189442352 | validation: 0.0031366298402593787]
	TIME [epoch: 69.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012415273711766		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.0012415273711766 | validation: 0.001302108799597022]
	TIME [epoch: 69.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008454386140614188		[learning rate: 0.00078269]
	Learning Rate: 0.00078269
	LOSS [training: 0.0008454386140614188 | validation: 0.0014658080851729957]
	TIME [epoch: 69.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001352719012473167		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.001352719012473167 | validation: 0.0015875729292004195]
	TIME [epoch: 69.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010194061080870899		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.0010194061080870899 | validation: 0.0022125106804160737]
	TIME [epoch: 69.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013105692717234772		[learning rate: 0.00077716]
	Learning Rate: 0.000777164
	LOSS [training: 0.0013105692717234772 | validation: 0.002334258042109056]
	TIME [epoch: 69.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016226750126353646		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.0016226750126353646 | validation: 0.002046965452120687]
	TIME [epoch: 69.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001241674043741229		[learning rate: 0.0007735]
	Learning Rate: 0.000773502
	LOSS [training: 0.001241674043741229 | validation: 0.0017336546660720272]
	TIME [epoch: 69.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009391918561972132		[learning rate: 0.00077168]
	Learning Rate: 0.000771678
	LOSS [training: 0.0009391918561972132 | validation: 0.0021993786102823504]
	TIME [epoch: 69.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014321257587893575		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.0014321257587893575 | validation: 0.0017655901649096936]
	TIME [epoch: 69.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011919501370316816		[learning rate: 0.00076804]
	Learning Rate: 0.000768041
	LOSS [training: 0.0011919501370316816 | validation: 0.002644976745856124]
	TIME [epoch: 69.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014277719814175947		[learning rate: 0.00076623]
	Learning Rate: 0.00076623
	LOSS [training: 0.0014277719814175947 | validation: 0.0015969075591102833]
	TIME [epoch: 69.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010713070191490902		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.0010713070191490902 | validation: 0.0027535646478214037]
	TIME [epoch: 69.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015897299153916147		[learning rate: 0.00076262]
	Learning Rate: 0.000762619
	LOSS [training: 0.0015897299153916147 | validation: 0.0018442912387586113]
	TIME [epoch: 69.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009706358435881948		[learning rate: 0.00076082]
	Learning Rate: 0.00076082
	LOSS [training: 0.0009706358435881948 | validation: 0.0029431182778064864]
	TIME [epoch: 69.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010812741365888053		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.0010812741365888053 | validation: 0.0013213965888252003]
	TIME [epoch: 69.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009107454735027632		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.0009107454735027632 | validation: 0.002335242700304759]
	TIME [epoch: 69.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013836114563136356		[learning rate: 0.00075545]
	Learning Rate: 0.000755449
	LOSS [training: 0.0013836114563136356 | validation: 0.0017457387353150143]
	TIME [epoch: 69.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010206008019818516		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.0010206008019818516 | validation: 0.0020549648722345574]
	TIME [epoch: 69.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013700289143614521		[learning rate: 0.00075189]
	Learning Rate: 0.000751889
	LOSS [training: 0.0013700289143614521 | validation: 0.0015255833300509762]
	TIME [epoch: 69.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001066826536355605		[learning rate: 0.00075012]
	Learning Rate: 0.000750116
	LOSS [training: 0.001066826536355605 | validation: 0.0013581229664888683]
	TIME [epoch: 69.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014647497026922989		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.0014647497026922989 | validation: 0.0011685269889447865]
	TIME [epoch: 69.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009625647527567991		[learning rate: 0.00074658]
	Learning Rate: 0.000746581
	LOSS [training: 0.0009625647527567991 | validation: 0.0032393345935908275]
	TIME [epoch: 69.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00129679199139488		[learning rate: 0.00074482]
	Learning Rate: 0.00074482
	LOSS [training: 0.00129679199139488 | validation: 0.001926771440806163]
	TIME [epoch: 69.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001423790544318387		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.001423790544318387 | validation: 0.0009793347243088313]
	TIME [epoch: 69.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1151.pth
	Model improved!!!
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012659247448814775		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.0012659247448814775 | validation: 0.0018211696389062225]
	TIME [epoch: 70 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012889931673904548		[learning rate: 0.00073956]
	Learning Rate: 0.000739562
	LOSS [training: 0.0012889931673904548 | validation: 0.0013925848446064838]
	TIME [epoch: 69.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018133836523613169		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.0018133836523613169 | validation: 0.0018765571286874288]
	TIME [epoch: 69.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00118536074990039		[learning rate: 0.00073608]
	Learning Rate: 0.000736077
	LOSS [training: 0.00118536074990039 | validation: 0.002019072561941311]
	TIME [epoch: 69.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013364629946289437		[learning rate: 0.00073434]
	Learning Rate: 0.000734341
	LOSS [training: 0.0013364629946289437 | validation: 0.002672722625964983]
	TIME [epoch: 69.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015548361173293764		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.0015548361173293764 | validation: 0.0019371721082026864]
	TIME [epoch: 69.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009902556959762853		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.0009902556959762853 | validation: 0.0012588698177928963]
	TIME [epoch: 69.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008325921877428621		[learning rate: 0.00072916]
	Learning Rate: 0.000729156
	LOSS [training: 0.0008325921877428621 | validation: 0.0019231802760168737]
	TIME [epoch: 69.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007117436086468139		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.0007117436086468139 | validation: 0.0019254808497341412]
	TIME [epoch: 69.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016718504279933967		[learning rate: 0.00072572]
	Learning Rate: 0.00072572
	LOSS [training: 0.0016718504279933967 | validation: 0.002100824939707014]
	TIME [epoch: 69.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013995962745197994		[learning rate: 0.00072401]
	Learning Rate: 0.000724008
	LOSS [training: 0.0013995962745197994 | validation: 0.002148084703411788]
	TIME [epoch: 69.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008548869849408568		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.0008548869849408568 | validation: 0.001512639128173194]
	TIME [epoch: 69.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014096853509008849		[learning rate: 0.0007206]
	Learning Rate: 0.000720597
	LOSS [training: 0.0014096853509008849 | validation: 0.0021487513519110575]
	TIME [epoch: 69.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010620663484822615		[learning rate: 0.0007189]
	Learning Rate: 0.000718897
	LOSS [training: 0.0010620663484822615 | validation: 0.0021169927778352643]
	TIME [epoch: 69.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012261936775435716		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.0012261936775435716 | validation: 0.002298683802114456]
	TIME [epoch: 69.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013210287823319361		[learning rate: 0.00071551]
	Learning Rate: 0.00071551
	LOSS [training: 0.0013210287823319361 | validation: 0.0012829739978475407]
	TIME [epoch: 69.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006237613575658432		[learning rate: 0.00071382]
	Learning Rate: 0.000713822
	LOSS [training: 0.0006237613575658432 | validation: 0.0017536571263229738]
	TIME [epoch: 69.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010814034790682559		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.0010814034790682559 | validation: 0.001303588598115522]
	TIME [epoch: 69.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011201893922704877		[learning rate: 0.00071046]
	Learning Rate: 0.000710458
	LOSS [training: 0.0011201893922704877 | validation: 0.0028261093064711356]
	TIME [epoch: 69.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015595066314173906		[learning rate: 0.00070878]
	Learning Rate: 0.000708782
	LOSS [training: 0.0015595066314173906 | validation: 0.0012172814881003832]
	TIME [epoch: 70 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008615730225434346		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.0008615730225434346 | validation: 0.001260837093125643]
	TIME [epoch: 70 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011714943353760333		[learning rate: 0.00070544]
	Learning Rate: 0.000705443
	LOSS [training: 0.0011714943353760333 | validation: 0.001587447741488319]
	TIME [epoch: 69.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012655482303338941		[learning rate: 0.00070378]
	Learning Rate: 0.000703778
	LOSS [training: 0.0012655482303338941 | validation: 0.0016567853815570848]
	TIME [epoch: 70 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009854599685380802		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.0009854599685380802 | validation: 0.0015050785898189894]
	TIME [epoch: 69.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012529355908708281		[learning rate: 0.00070046]
	Learning Rate: 0.000700462
	LOSS [training: 0.0012529355908708281 | validation: 0.0018240373690411884]
	TIME [epoch: 69.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008492536261256246		[learning rate: 0.00069881]
	Learning Rate: 0.00069881
	LOSS [training: 0.0008492536261256246 | validation: 0.001349300939425433]
	TIME [epoch: 69.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010854659577306228		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.0010854659577306228 | validation: 0.0024230352749881443]
	TIME [epoch: 69.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001731886788446054		[learning rate: 0.00069552]
	Learning Rate: 0.000695517
	LOSS [training: 0.001731886788446054 | validation: 0.0017519364514955943]
	TIME [epoch: 69.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009025306429684903		[learning rate: 0.00069388]
	Learning Rate: 0.000693876
	LOSS [training: 0.0009025306429684903 | validation: 0.0018467169024797485]
	TIME [epoch: 69.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001330635457967437		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.001330635457967437 | validation: 0.001482753511564355]
	TIME [epoch: 69.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000842010376593702		[learning rate: 0.00069061]
	Learning Rate: 0.000690607
	LOSS [training: 0.000842010376593702 | validation: 0.0016398161110646788]
	TIME [epoch: 69.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001184571550281691		[learning rate: 0.00068898]
	Learning Rate: 0.000688978
	LOSS [training: 0.001184571550281691 | validation: 0.0012096559034600212]
	TIME [epoch: 69.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007647619137177038		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.0007647619137177038 | validation: 0.0015185925814054002]
	TIME [epoch: 69.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009806491356569816		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.0009806491356569816 | validation: 0.0018127797958761623]
	TIME [epoch: 69.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008798257628278661		[learning rate: 0.00068411]
	Learning Rate: 0.000684114
	LOSS [training: 0.0008798257628278661 | validation: 0.0021774895157041724]
	TIME [epoch: 69.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009210559076389469		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.0009210559076389469 | validation: 0.0019105535241152021]
	TIME [epoch: 70 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015445640865477742		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.0015445640865477742 | validation: 0.001462189662875601]
	TIME [epoch: 69.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011449617121163584		[learning rate: 0.00067928]
	Learning Rate: 0.000679284
	LOSS [training: 0.0011449617121163584 | validation: 0.0014678114273155903]
	TIME [epoch: 69.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010596290049882675		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.0010596290049882675 | validation: 0.001663961526614239]
	TIME [epoch: 69.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009758038080591818		[learning rate: 0.00067608]
	Learning Rate: 0.000676083
	LOSS [training: 0.0009758038080591818 | validation: 0.0015533952242343867]
	TIME [epoch: 70.1 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008691840258559761		[learning rate: 0.00067449]
	Learning Rate: 0.000674488
	LOSS [training: 0.0008691840258559761 | validation: 0.002858251848932151]
	TIME [epoch: 69.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001318820653127903		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.001318820653127903 | validation: 0.0015350404444754151]
	TIME [epoch: 70 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014601931872340436		[learning rate: 0.00067131]
	Learning Rate: 0.00067131
	LOSS [training: 0.0014601931872340436 | validation: 0.0011271496113800456]
	TIME [epoch: 69.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006844053972733237		[learning rate: 0.00066973]
	Learning Rate: 0.000669726
	LOSS [training: 0.0006844053972733237 | validation: 0.0017401225158201541]
	TIME [epoch: 69.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008059510294844529		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.0008059510294844529 | validation: 0.0010235027435550573]
	TIME [epoch: 70.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012807756788345294		[learning rate: 0.00066657]
	Learning Rate: 0.000666571
	LOSS [training: 0.0012807756788345294 | validation: 0.002780190505981505]
	TIME [epoch: 69.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001458823851841557		[learning rate: 0.000665]
	Learning Rate: 0.000664998
	LOSS [training: 0.001458823851841557 | validation: 0.001337286821234562]
	TIME [epoch: 69.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006569956521721801		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.0006569956521721801 | validation: 0.0012195410143702272]
	TIME [epoch: 69.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001042840179322168		[learning rate: 0.00066186]
	Learning Rate: 0.000661865
	LOSS [training: 0.001042840179322168 | validation: 0.0008863471388403728]
	TIME [epoch: 70 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1200.pth
	Model improved!!!
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009518106071849928		[learning rate: 0.0006603]
	Learning Rate: 0.000660304
	LOSS [training: 0.0009518106071849928 | validation: 0.0010893468802432328]
	TIME [epoch: 69.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012223247658794969		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.0012223247658794969 | validation: 0.002100878346235361]
	TIME [epoch: 69.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011113178223943504		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.0011113178223943504 | validation: 0.0019741556720034243]
	TIME [epoch: 70 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001054448789688306		[learning rate: 0.00065564]
	Learning Rate: 0.000655642
	LOSS [training: 0.001054448789688306 | validation: 0.0016204814945478515]
	TIME [epoch: 69.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012668519776377883		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.0012668519776377883 | validation: 0.0016725915646068614]
	TIME [epoch: 69.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010319962188141598		[learning rate: 0.00065255]
	Learning Rate: 0.000652552
	LOSS [training: 0.0010319962188141598 | validation: 0.002133792147322352]
	TIME [epoch: 70 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010360270936730122		[learning rate: 0.00065101]
	Learning Rate: 0.000651013
	LOSS [training: 0.0010360270936730122 | validation: 0.0015801502100314996]
	TIME [epoch: 69.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008321550828399177		[learning rate: 0.00064948]
	Learning Rate: 0.000649478
	LOSS [training: 0.0008321550828399177 | validation: 0.0011630445889706839]
	TIME [epoch: 69.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000900555918589873		[learning rate: 0.00064795]
	Learning Rate: 0.000647945
	LOSS [training: 0.000900555918589873 | validation: 0.001461291804073184]
	TIME [epoch: 70 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012726077284056932		[learning rate: 0.00064642]
	Learning Rate: 0.000646417
	LOSS [training: 0.0012726077284056932 | validation: 0.001528905222408806]
	TIME [epoch: 69.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000955723711032558		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.000955723711032558 | validation: 0.0016486426566248555]
	TIME [epoch: 70 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010180450160554497		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.0010180450160554497 | validation: 0.0020357774034371347]
	TIME [epoch: 70 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012960097728080971		[learning rate: 0.00064185]
	Learning Rate: 0.000641854
	LOSS [training: 0.0012960097728080971 | validation: 0.0015035518772687714]
	TIME [epoch: 69.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008516784530970145		[learning rate: 0.00064034]
	Learning Rate: 0.00064034
	LOSS [training: 0.0008516784530970145 | validation: 0.0014165864356253791]
	TIME [epoch: 70 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011651847522255402		[learning rate: 0.00063883]
	Learning Rate: 0.000638829
	LOSS [training: 0.0011651847522255402 | validation: 0.0017360299926435178]
	TIME [epoch: 70 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010744761969848904		[learning rate: 0.00063732]
	Learning Rate: 0.000637322
	LOSS [training: 0.0010744761969848904 | validation: 0.0014719719027104354]
	TIME [epoch: 69.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008051682669366432		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: 0.0008051682669366432 | validation: 0.0009612753122387918]
	TIME [epoch: 70 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00100269462764411		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.00100269462764411 | validation: 0.0017269741929156527]
	TIME [epoch: 69.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008044027343948468		[learning rate: 0.00063282]
	Learning Rate: 0.000632823
	LOSS [training: 0.0008044027343948468 | validation: 0.0015151477215858398]
	TIME [epoch: 69.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001073871349417359		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: 0.001073871349417359 | validation: 0.0017785070144785262]
	TIME [epoch: 69.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001081349797915932		[learning rate: 0.00062984]
	Learning Rate: 0.000629841
	LOSS [training: 0.001081349797915932 | validation: 0.0016924027283866233]
	TIME [epoch: 69.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001057042452970513		[learning rate: 0.00062836]
	Learning Rate: 0.000628355
	LOSS [training: 0.001057042452970513 | validation: 0.0014007788240235604]
	TIME [epoch: 69.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009325032513693892		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.0009325032513693892 | validation: 0.0015489965014464637]
	TIME [epoch: 69.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008698847793620444		[learning rate: 0.00062539]
	Learning Rate: 0.000625394
	LOSS [training: 0.0008698847793620444 | validation: 0.002428916112546359]
	TIME [epoch: 69.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012484259898023		[learning rate: 0.00062392]
	Learning Rate: 0.000623919
	LOSS [training: 0.0012484259898023 | validation: 0.0018298550932429212]
	TIME [epoch: 69.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009539871912648192		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.0009539871912648192 | validation: 0.0020991229121675448]
	TIME [epoch: 70 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011806060255166871		[learning rate: 0.00062098]
	Learning Rate: 0.000620979
	LOSS [training: 0.0011806060255166871 | validation: 0.001695111984295891]
	TIME [epoch: 69.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007740855374566274		[learning rate: 0.00061951]
	Learning Rate: 0.000619514
	LOSS [training: 0.0007740855374566274 | validation: 0.0021627748279298338]
	TIME [epoch: 69.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008629104575158677		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 0.0008629104575158677 | validation: 0.0011942337624769345]
	TIME [epoch: 70 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011879212128016728		[learning rate: 0.0006166]
	Learning Rate: 0.000616595
	LOSS [training: 0.0011879212128016728 | validation: 0.001313062749112727]
	TIME [epoch: 69.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001192186513466745		[learning rate: 0.00061514]
	Learning Rate: 0.000615141
	LOSS [training: 0.001192186513466745 | validation: 0.0018225560400723841]
	TIME [epoch: 69.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009928509162594674		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.0009928509162594674 | validation: 0.0014270261366395795]
	TIME [epoch: 69.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007319782825631806		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.0007319782825631806 | validation: 0.001291067652911857]
	TIME [epoch: 69.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012756022236743748		[learning rate: 0.0006108]
	Learning Rate: 0.000610798
	LOSS [training: 0.0012756022236743748 | validation: 0.002007879493798341]
	TIME [epoch: 69.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010244746346968238		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.0010244746346968238 | validation: 0.0016970102522118724]
	TIME [epoch: 69.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000883615486139237		[learning rate: 0.00060792]
	Learning Rate: 0.00060792
	LOSS [training: 0.000883615486139237 | validation: 0.0015974745152342767]
	TIME [epoch: 70.1 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008670591752722818		[learning rate: 0.00060649]
	Learning Rate: 0.000606486
	LOSS [training: 0.0008670591752722818 | validation: 0.0011031524574943994]
	TIME [epoch: 70.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008147831450748395		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.0008147831450748395 | validation: 0.0016820875949539254]
	TIME [epoch: 69.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010629176771279566		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.0010629176771279566 | validation: 0.0012218684035422696]
	TIME [epoch: 69.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009294768894533865		[learning rate: 0.0006022]
	Learning Rate: 0.000602204
	LOSS [training: 0.0009294768894533865 | validation: 0.0012392881358665856]
	TIME [epoch: 69.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012190215843216722		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.0012190215843216722 | validation: 0.0011738945912496757]
	TIME [epoch: 69.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010568083006362561		[learning rate: 0.00059937]
	Learning Rate: 0.000599366
	LOSS [training: 0.0010568083006362561 | validation: 0.0014901949249894937]
	TIME [epoch: 69.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011746216212351857		[learning rate: 0.00059795]
	Learning Rate: 0.000597953
	LOSS [training: 0.0011746216212351857 | validation: 0.0015229032916412484]
	TIME [epoch: 69.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007537302598305919		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.0007537302598305919 | validation: 0.0011774297732794663]
	TIME [epoch: 69.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011612659390941062		[learning rate: 0.00059513]
	Learning Rate: 0.000595135
	LOSS [training: 0.0011612659390941062 | validation: 0.0015779681523508948]
	TIME [epoch: 69.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008918689048831559		[learning rate: 0.00059373]
	Learning Rate: 0.000593731
	LOSS [training: 0.0008918689048831559 | validation: 0.0013195877544329973]
	TIME [epoch: 69.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000727522289159249		[learning rate: 0.00059233]
	Learning Rate: 0.000592331
	LOSS [training: 0.000727522289159249 | validation: 0.0010355142455806456]
	TIME [epoch: 69.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001112571633897416		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.001112571633897416 | validation: 0.0014105071068640208]
	TIME [epoch: 69.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008698810327228327		[learning rate: 0.00058954]
	Learning Rate: 0.000589539
	LOSS [training: 0.0008698810327228327 | validation: 0.0014247269531319571]
	TIME [epoch: 69.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008729340110549366		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.0008729340110549366 | validation: 0.0012986169487764442]
	TIME [epoch: 69.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013345878692405072		[learning rate: 0.00058676]
	Learning Rate: 0.000586761
	LOSS [training: 0.0013345878692405072 | validation: 0.002091566009089706]
	TIME [epoch: 69.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010544451788821183		[learning rate: 0.00058538]
	Learning Rate: 0.000585377
	LOSS [training: 0.0010544451788821183 | validation: 0.0008308402783443168]
	TIME [epoch: 69.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011490675100351087		[learning rate: 0.000584]
	Learning Rate: 0.000583997
	LOSS [training: 0.0011490675100351087 | validation: 0.002217902079201081]
	TIME [epoch: 70 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007192929275139164		[learning rate: 0.00058262]
	Learning Rate: 0.000582619
	LOSS [training: 0.0007192929275139164 | validation: 0.00123193683112053]
	TIME [epoch: 69.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00100446363645538		[learning rate: 0.00058124]
	Learning Rate: 0.000581245
	LOSS [training: 0.00100446363645538 | validation: 0.001266423137355389]
	TIME [epoch: 69.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000660276440181643		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.000660276440181643 | validation: 0.001204717080148564]
	TIME [epoch: 69.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008738830664323281		[learning rate: 0.00057851]
	Learning Rate: 0.000578506
	LOSS [training: 0.0008738830664323281 | validation: 0.0012299772748641002]
	TIME [epoch: 69.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010526947567416445		[learning rate: 0.00057714]
	Learning Rate: 0.000577141
	LOSS [training: 0.0010526947567416445 | validation: 0.0013728425891847476]
	TIME [epoch: 69.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000634430536333162		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 0.000634430536333162 | validation: 0.0017284436606681438]
	TIME [epoch: 69.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010027048073613701		[learning rate: 0.00057442]
	Learning Rate: 0.000574422
	LOSS [training: 0.0010027048073613701 | validation: 0.0008140308222651429]
	TIME [epoch: 69.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd2_20240704_134547/states/model_phi1_1a_v_mmd2_1260.pth
	Model improved!!!
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000915752030980846		[learning rate: 0.00057307]
	Learning Rate: 0.000573067
	LOSS [training: 0.000915752030980846 | validation: 0.0011690054409297863]
	TIME [epoch: 69.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009474488147828442		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 0.0009474488147828442 | validation: 0.0013067163703851686]
	TIME [epoch: 69.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008760374307547689		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.0008760374307547689 | validation: 0.001294648983787612]
	TIME [epoch: 69.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006542552781269423		[learning rate: 0.00056902]
	Learning Rate: 0.000569021
	LOSS [training: 0.0006542552781269423 | validation: 0.001384439249451903]
	TIME [epoch: 69.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009615647118867032		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.0009615647118867032 | validation: 0.0011404600867582948]
	TIME [epoch: 69.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010615074260729475		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.0010615074260729475 | validation: 0.0011604156604446852]
	TIME [epoch: 69.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008059816513245175		[learning rate: 0.000565]
	Learning Rate: 0.000565004
	LOSS [training: 0.0008059816513245175 | validation: 0.0014109721146817167]
	TIME [epoch: 69.8 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005797349114974349		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.0005797349114974349 | validation: 0.0014943288116382946]
	TIME [epoch: 69.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006570185478373074		[learning rate: 0.00056234]
	Learning Rate: 0.000562341
	LOSS [training: 0.0006570185478373074 | validation: 0.001531500617611088]
	TIME [epoch: 69.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008176753737254166		[learning rate: 0.00056101]
	Learning Rate: 0.000561015
	LOSS [training: 0.0008176753737254166 | validation: 0.0017201984518174626]
	TIME [epoch: 69.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009890733617679522		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.0009890733617679522 | validation: 0.0014657575834835788]
	TIME [epoch: 69.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008580208058753551		[learning rate: 0.00055837]
	Learning Rate: 0.000558371
	LOSS [training: 0.0008580208058753551 | validation: 0.0011654771698412533]
	TIME [epoch: 69.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007925308782705092		[learning rate: 0.00055705]
	Learning Rate: 0.000557054
	LOSS [training: 0.0007925308782705092 | validation: 0.0020640198376524017]
	TIME [epoch: 69.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010809343914707527		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.0010809343914707527 | validation: 0.001052189344588955]
	TIME [epoch: 69.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006706541886622321		[learning rate: 0.00055443]
	Learning Rate: 0.000554429
	LOSS [training: 0.0006706541886622321 | validation: 0.0013146429330201724]
	TIME [epoch: 69.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007333806017332155		[learning rate: 0.00055312]
	Learning Rate: 0.000553121
	LOSS [training: 0.0007333806017332155 | validation: 0.0011913242745488725]
	TIME [epoch: 69.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000849227856160685		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.000849227856160685 | validation: 0.001093025007784145]
	TIME [epoch: 69.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009027174689630282		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.0009027174689630282 | validation: 0.0014818816416403103]
	TIME [epoch: 69.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011309889647043124		[learning rate: 0.00054922]
	Learning Rate: 0.000549216
	LOSS [training: 0.0011309889647043124 | validation: 0.0013820338111089506]
	TIME [epoch: 69.4 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007746745335275073		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.0007746745335275073 | validation: 0.0011169887766608194]
	TIME [epoch: 69.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006277991286493354		[learning rate: 0.00054663]
	Learning Rate: 0.000546629
	LOSS [training: 0.0006277991286493354 | validation: 0.0013555443552636115]
	TIME [epoch: 69.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009266271461421414		[learning rate: 0.00054534]
	Learning Rate: 0.000545339
	LOSS [training: 0.0009266271461421414 | validation: 0.0012066695447916294]
	TIME [epoch: 69.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001298027391779429		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.001298027391779429 | validation: 0.0015988934026826005]
	TIME [epoch: 69.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008378306689098278		[learning rate: 0.00054277]
	Learning Rate: 0.000542769
	LOSS [training: 0.0008378306689098278 | validation: 0.0018278852052694729]
	TIME [epoch: 69.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009780788668694728		[learning rate: 0.00054149]
	Learning Rate: 0.000541489
	LOSS [training: 0.0009780788668694728 | validation: 0.0016104153804288863]
	TIME [epoch: 69.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007046713755651077		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: 0.0007046713755651077 | validation: 0.0013143989366134435]
	TIME [epoch: 69.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000926748621050589		[learning rate: 0.00053894]
	Learning Rate: 0.000538938
	LOSS [training: 0.000926748621050589 | validation: 0.0013886272505731023]
	TIME [epoch: 69.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006399933589836137		[learning rate: 0.00053767]
	Learning Rate: 0.000537666
	LOSS [training: 0.0006399933589836137 | validation: 0.001663446520632669]
	TIME [epoch: 69.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010949017668932064		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.0010949017668932064 | validation: 0.002219086264377152]
	TIME [epoch: 69.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001396238054395838		[learning rate: 0.00053513]
	Learning Rate: 0.000535133
	LOSS [training: 0.001396238054395838 | validation: 0.0013815533767109471]
	TIME [epoch: 69.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005279993332118575		[learning rate: 0.00053387]
	Learning Rate: 0.00053387
	LOSS [training: 0.0005279993332118575 | validation: 0.0013106613886203426]
	TIME [epoch: 69.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007029938597567471		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.0007029938597567471 | validation: 0.0014479571759876428]
	TIME [epoch: 69.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010712279255962094		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.0010712279255962094 | validation: 0.0017784223509873342]
	TIME [epoch: 69.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008065408710569147		[learning rate: 0.0005301]
	Learning Rate: 0.000530101
	LOSS [training: 0.0008065408710569147 | validation: 0.0011832588748120214]
	TIME [epoch: 69.8 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011643499144042557		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: 0.0011643499144042557 | validation: 0.0010851663104325445]
	TIME [epoch: 70 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008646670879047776		[learning rate: 0.0005276]
	Learning Rate: 0.000527603
	LOSS [training: 0.0008646670879047776 | validation: 0.0013947907459210614]
	TIME [epoch: 69.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006681654447647527		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.0006681654447647527 | validation: 0.0015848998538636313]
	TIME [epoch: 69.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007900834046831074		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: 0.0007900834046831074 | validation: 0.0013443761024975194]
	TIME [epoch: 69.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006530946602653727		[learning rate: 0.00052388]
	Learning Rate: 0.000523879
	LOSS [training: 0.0006530946602653727 | validation: 0.0009303768220575064]
	TIME [epoch: 69.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010407000321018957		[learning rate: 0.00052264]
	Learning Rate: 0.000522643
	LOSS [training: 0.0010407000321018957 | validation: 0.001668803891570689]
	TIME [epoch: 69.7 sec]
EPOCH 1301/2000:
	Training over batches...
