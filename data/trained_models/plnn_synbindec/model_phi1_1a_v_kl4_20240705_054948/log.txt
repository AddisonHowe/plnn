Args:
Namespace(name='model_phi1_1a_v_kl4', outdir='out/model_training/model_phi1_1a_v_kl4', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3671676135

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.682474908518401		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 11.682474908518401 | validation: 10.380818748759957]
	TIME [epoch: 99.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.873154853680838		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 10.873154853680838 | validation: 10.287145854748651]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.818791264197136		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 10.818791264197136 | validation: 10.198162242230893]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.478138971637467		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 10.478138971637467 | validation: 10.468946488810598]
	TIME [epoch: 8.02 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.421608075176415		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 10.421608075176415 | validation: 9.365912654338263]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.835032510507286		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 9.835032510507286 | validation: 9.217208280499303]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.199281231778947		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 10.199281231778947 | validation: 8.324546242028887]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.342061278614185		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 9.342061278614185 | validation: 8.789193301174272]
	TIME [epoch: 8.04 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.194956174246775		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 9.194956174246775 | validation: 7.625209445371157]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.933367023337764		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 8.933367023337764 | validation: 9.246294857232247]
	TIME [epoch: 8.03 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.883658569448581		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 8.883658569448581 | validation: 7.749774151531261]
	TIME [epoch: 8.03 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.72722327078348		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 8.72722327078348 | validation: 6.8298943790346875]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.610365233917452		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 8.610365233917452 | validation: 7.781957018979178]
	TIME [epoch: 8.04 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.374374018714366		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 8.374374018714366 | validation: 7.6738687556793455]
	TIME [epoch: 8.04 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.550606985779808		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 8.550606985779808 | validation: 6.347228871955929]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.990302234397947		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 7.990302234397947 | validation: 6.885291054169727]
	TIME [epoch: 8.02 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.574644072093701		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 8.574644072093701 | validation: 7.296620173228151]
	TIME [epoch: 8.04 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.121657827883658		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 8.121657827883658 | validation: 6.595560423661153]
	TIME [epoch: 8.06 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.074596498658533		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 8.074596498658533 | validation: 6.252557082652574]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.532151001532674		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 7.532151001532674 | validation: 6.143525008562741]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.01312563237715		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 8.01312563237715 | validation: 6.753152790553862]
	TIME [epoch: 8.01 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.5831055153600735		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 7.5831055153600735 | validation: 6.087631254001714]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.765705751468717		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 7.765705751468717 | validation: 6.356781773816485]
	TIME [epoch: 8.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.502484623574867		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 7.502484623574867 | validation: 5.87547804899141]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.129753572654892		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 7.129753572654892 | validation: 6.027907302564702]
	TIME [epoch: 8.03 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.369110223813182		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 7.369110223813182 | validation: 6.079062338418406]
	TIME [epoch: 8.02 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.170372659348701		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 7.170372659348701 | validation: 5.925863768685568]
	TIME [epoch: 8.02 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.898883007249305		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 6.898883007249305 | validation: 5.961553105816423]
	TIME [epoch: 8.03 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.73983453080083		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 6.73983453080083 | validation: 6.679005818459679]
	TIME [epoch: 8.07 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.266745711215405		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 7.266745711215405 | validation: 5.394806558852577]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5112412799171615		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 6.5112412799171615 | validation: 5.692401955052951]
	TIME [epoch: 8.03 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831549162846445		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 6.831549162846445 | validation: 5.2930687698299534]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.448004650090214		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 6.448004650090214 | validation: 6.064815359440532]
	TIME [epoch: 8.05 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5746878504885835		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 6.5746878504885835 | validation: 5.3367547434782345]
	TIME [epoch: 8.08 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.546059627450187		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 6.546059627450187 | validation: 5.532063995426993]
	TIME [epoch: 8.04 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.341293250580618		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 6.341293250580618 | validation: 5.121947702093877]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.419923837665528		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 6.419923837665528 | validation: 5.027039230938198]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1812530686371		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 6.1812530686371 | validation: 5.485820750050392]
	TIME [epoch: 8.02 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.15366801900928		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 6.15366801900928 | validation: 4.966466040464201]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.320552854076343		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 6.320552854076343 | validation: 5.109846916444722]
	TIME [epoch: 8.02 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.901409650143669		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 5.901409650143669 | validation: 4.734038464061598]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.999020843312454		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 5.999020843312454 | validation: 5.018683761077073]
	TIME [epoch: 8.03 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.77931358673159		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 5.77931358673159 | validation: 4.906789151277357]
	TIME [epoch: 8.03 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.678926387481546		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 5.678926387481546 | validation: 4.55466152727287]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0710810742209524		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 6.0710810742209524 | validation: 4.657575117688285]
	TIME [epoch: 8.04 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.561164375764692		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 5.561164375764692 | validation: 4.860281918507448]
	TIME [epoch: 8.02 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.560114031911922		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 5.560114031911922 | validation: 5.088031443146718]
	TIME [epoch: 8.02 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.761207263675946		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 5.761207263675946 | validation: 4.430891899611645]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.320537760915406		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 5.320537760915406 | validation: 4.338593406911761]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7071102900478		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 5.7071102900478 | validation: 4.377720240510253]
	TIME [epoch: 8.04 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3079949049782975		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.3079949049782975 | validation: 4.203704215318138]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.62119320539359		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.62119320539359 | validation: 4.372711304095485]
	TIME [epoch: 8.02 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9568738111302695		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 5.9568738111302695 | validation: 4.392076733055568]
	TIME [epoch: 8.03 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4679288325442466		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 5.4679288325442466 | validation: 4.0951823508634355]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.086196470958155		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 5.086196470958155 | validation: 4.088541210895897]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.606420304412265		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 5.606420304412265 | validation: 4.028560008864212]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.076837081188933		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 5.076837081188933 | validation: 3.8743355088569906]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.068134881879832		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 5.068134881879832 | validation: 3.9991013875800085]
	TIME [epoch: 8.04 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.593285148180438		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 5.593285148180438 | validation: 4.259620581854727]
	TIME [epoch: 8.05 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.08923455393138		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 5.08923455393138 | validation: 4.082372208961928]
	TIME [epoch: 8.06 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.040450568785222		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 5.040450568785222 | validation: 3.930063187944392]
	TIME [epoch: 8.03 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.196370245015888		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 5.196370245015888 | validation: 4.175574857047846]
	TIME [epoch: 8.03 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.028014023678365		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 5.028014023678365 | validation: 3.693063241854686]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.044183998441722		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 5.044183998441722 | validation: 3.731095300029558]
	TIME [epoch: 8.04 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.857215914174644		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 4.857215914174644 | validation: 3.574900528673566]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.922919045173157		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 4.922919045173157 | validation: 4.069270025921892]
	TIME [epoch: 8.02 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.986795460886758		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 4.986795460886758 | validation: 3.4594848586349563]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015860568111173		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 5.015860568111173 | validation: 4.349301275015714]
	TIME [epoch: 8.03 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950453403971356		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 4.950453403971356 | validation: 3.748565208679088]
	TIME [epoch: 8.02 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.998549389316696		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 4.998549389316696 | validation: 3.5159656241409296]
	TIME [epoch: 8.09 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.841332217718452		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 4.841332217718452 | validation: 4.591527079621941]
	TIME [epoch: 8.04 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.842809275776745		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 4.842809275776745 | validation: 3.520558315463474]
	TIME [epoch: 8.03 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.707751459679769		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 4.707751459679769 | validation: 4.120952234816919]
	TIME [epoch: 8.03 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.823752248114093		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 4.823752248114093 | validation: 3.7224218667673457]
	TIME [epoch: 8.04 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.739431409005028		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 4.739431409005028 | validation: 3.659991926468854]
	TIME [epoch: 8.07 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.672351740803368		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 4.672351740803368 | validation: 3.7545079732919895]
	TIME [epoch: 8.05 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.039104081814114		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 5.039104081814114 | validation: 3.4069539902171018]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.268522837972451		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 5.268522837972451 | validation: 8.465243378783317]
	TIME [epoch: 8.03 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6594508278523055		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 6.6594508278523055 | validation: 3.7653625901544117]
	TIME [epoch: 8.02 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.922599844211217		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 4.922599844211217 | validation: 3.639475138175368]
	TIME [epoch: 8.04 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.665577441356466		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 4.665577441356466 | validation: 3.2743401158623593]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498770123537599		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 4.498770123537599 | validation: 3.3446712902268017]
	TIME [epoch: 8.02 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.800310676763979		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 4.800310676763979 | validation: 3.8593232055565254]
	TIME [epoch: 8.02 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.853561396248143		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 4.853561396248143 | validation: 3.4115220993129345]
	TIME [epoch: 8.03 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365581223241401		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 4.365581223241401 | validation: 3.2638586295588796]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.195133171174131		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 4.195133171174131 | validation: 3.3341448008810706]
	TIME [epoch: 8.07 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.862331010152548		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 3.862331010152548 | validation: 3.0699170399164055]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2164551714128375		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 3.2164551714128375 | validation: 2.8848317431968304]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1082115842886466		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 3.1082115842886466 | validation: 2.459242491652879]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257076583432531		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 2.257076583432531 | validation: 2.436323678875781]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7839963968403003		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 2.7839963968403003 | validation: 2.3899818034352327]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357581477701125		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 2.357581477701125 | validation: 2.1771920753200185]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3947487381094175		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 2.3947487381094175 | validation: 2.222983468291855]
	TIME [epoch: 8.03 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1249548298926606		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 2.1249548298926606 | validation: 3.277400576176926]
	TIME [epoch: 8.02 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432677532261784		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 2.432677532261784 | validation: 2.6457431235749533]
	TIME [epoch: 8.02 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.565056195631309		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 2.565056195631309 | validation: 2.401337297367517]
	TIME [epoch: 8.07 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1077153746810446		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 2.1077153746810446 | validation: 2.187102712204042]
	TIME [epoch: 8.02 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4468689839898983		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 2.4468689839898983 | validation: 2.2166867139962245]
	TIME [epoch: 8.02 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10147505256652		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 2.10147505256652 | validation: 2.1996027299545027]
	TIME [epoch: 8.03 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2807515477275917		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 2.2807515477275917 | validation: 2.2063964668490943]
	TIME [epoch: 8.03 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9842845536991305		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 1.9842845536991305 | validation: 2.679849014689587]
	TIME [epoch: 8.07 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2549489057154304		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 2.2549489057154304 | validation: 3.144963195584583]
	TIME [epoch: 8.03 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.518724626061061		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 2.518724626061061 | validation: 1.8005139532278474]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7566852935557147		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 1.7566852935557147 | validation: 1.5697360920379608]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8419908854942881		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 1.8419908854942881 | validation: 1.9390441253496284]
	TIME [epoch: 8.03 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2901650936237794		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 2.2901650936237794 | validation: 2.29135676394137]
	TIME [epoch: 8.06 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.976706951404692		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 1.976706951404692 | validation: 1.8444252630409332]
	TIME [epoch: 8.04 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9746608652123618		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 1.9746608652123618 | validation: 1.8697304689294354]
	TIME [epoch: 8.03 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9096198276301117		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 1.9096198276301117 | validation: 1.8824817052645568]
	TIME [epoch: 8.03 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780500063071492		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 1.7780500063071492 | validation: 1.8094662535992083]
	TIME [epoch: 8.03 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750757330162791		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 1.750757330162791 | validation: 3.0151351250440794]
	TIME [epoch: 8.05 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093817179881543		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 2.093817179881543 | validation: 1.4319565941943462]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.815346672139819		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 1.815346672139819 | validation: 1.945076783381483]
	TIME [epoch: 8.03 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7529937992542628		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 1.7529937992542628 | validation: 1.5579741514764662]
	TIME [epoch: 8.02 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7311412431071178		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 1.7311412431071178 | validation: 1.718901732971535]
	TIME [epoch: 8.02 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6317401443817803		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 1.6317401443817803 | validation: 1.755887202163253]
	TIME [epoch: 8.04 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6045708955224063		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 1.6045708955224063 | validation: 1.9748163983983447]
	TIME [epoch: 8.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7753689167586257		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 1.7753689167586257 | validation: 1.2970543063805777]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8882359916960327		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 1.8882359916960327 | validation: 1.8534411388314278]
	TIME [epoch: 8.03 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7439130020975495		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 1.7439130020975495 | validation: 1.6344949844449796]
	TIME [epoch: 8.03 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2747759981159015		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 2.2747759981159015 | validation: 1.522328968921003]
	TIME [epoch: 8.03 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.559508032432772		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 1.559508032432772 | validation: 1.3236648481825708]
	TIME [epoch: 8.08 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8301317886831057		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 1.8301317886831057 | validation: 1.7395605948470578]
	TIME [epoch: 8.04 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5170697166922626		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 1.5170697166922626 | validation: 1.6395484002146654]
	TIME [epoch: 8.02 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5726488473290985		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 1.5726488473290985 | validation: 1.3094369227076457]
	TIME [epoch: 8.02 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7319651459298468		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 1.7319651459298468 | validation: 1.4078590750648556]
	TIME [epoch: 8.04 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483514330000296		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 1.483514330000296 | validation: 1.5274921524508325]
	TIME [epoch: 8.05 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7248968910068352		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 1.7248968910068352 | validation: 1.4574625220637076]
	TIME [epoch: 8.05 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3792155220234257		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 1.3792155220234257 | validation: 1.3034861179863477]
	TIME [epoch: 8.02 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5682045107915852		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 1.5682045107915852 | validation: 1.4229293518743504]
	TIME [epoch: 8.02 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6318533283191703		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 1.6318533283191703 | validation: 1.4165137459125816]
	TIME [epoch: 8.02 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4160183826215837		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 1.4160183826215837 | validation: 2.557061039659612]
	TIME [epoch: 8.03 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7849513909406085		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 1.7849513909406085 | validation: 1.2017333060464557]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3787697593177923		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 1.3787697593177923 | validation: 1.832828095691798]
	TIME [epoch: 8.02 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5575770822373953		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 1.5575770822373953 | validation: 1.1979992436893174]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3759494681296915		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 1.3759494681296915 | validation: 1.6635353321041277]
	TIME [epoch: 8.02 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5496888696146347		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 1.5496888696146347 | validation: 1.2304592791451956]
	TIME [epoch: 8.02 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341479887430578		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 1.341479887430578 | validation: 1.3849587322723838]
	TIME [epoch: 8.08 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.310052910276685		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 1.310052910276685 | validation: 1.6085832577123078]
	TIME [epoch: 8.03 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4713480048236713		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 1.4713480048236713 | validation: 1.3909051820056106]
	TIME [epoch: 8.02 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4305959808608784		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 1.4305959808608784 | validation: 1.2405207435335084]
	TIME [epoch: 8.02 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2167384762471882		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 1.2167384762471882 | validation: 1.8733102857153825]
	TIME [epoch: 8.03 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.599424119852463		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 1.599424119852463 | validation: 1.940525199945063]
	TIME [epoch: 8.06 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3974818511726452		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 1.3974818511726452 | validation: 1.0891417026392562]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4175507369966955		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 1.4175507369966955 | validation: 1.565720308360377]
	TIME [epoch: 8.03 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423360651248838		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 1.423360651248838 | validation: 1.280255960281519]
	TIME [epoch: 8.02 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.444765612860242		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 1.444765612860242 | validation: 1.4346998466053975]
	TIME [epoch: 8.03 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.38971751991136		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 1.38971751991136 | validation: 1.1885768074361365]
	TIME [epoch: 8.05 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1930312133269085		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 1.1930312133269085 | validation: 1.0528601478172575]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6383457015976741		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 1.6383457015976741 | validation: 1.538509387563006]
	TIME [epoch: 8.02 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.461261272890534		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 1.461261272890534 | validation: 1.7707230313321518]
	TIME [epoch: 8.03 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9343769141546014		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 1.9343769141546014 | validation: 1.4723736588491967]
	TIME [epoch: 8.02 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688441700350568		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 1.2688441700350568 | validation: 1.2057525964829936]
	TIME [epoch: 8.02 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5714541538441724		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 1.5714541538441724 | validation: 1.2302307631168028]
	TIME [epoch: 8.06 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257409806379835		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 1.257409806379835 | validation: 1.2586192011595778]
	TIME [epoch: 8.02 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3103196884866533		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 1.3103196884866533 | validation: 1.4579346450283959]
	TIME [epoch: 8.02 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3383508926041605		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 1.3383508926041605 | validation: 1.217265971374085]
	TIME [epoch: 8.02 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1887209265917924		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 1.1887209265917924 | validation: 1.3616471369783407]
	TIME [epoch: 8.02 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2931039868329357		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 1.2931039868329357 | validation: 1.3303814891952446]
	TIME [epoch: 8.07 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4246711693373983		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 1.4246711693373983 | validation: 1.1692437656279964]
	TIME [epoch: 8.03 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4901325654922484		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 1.4901325654922484 | validation: 1.112738363578593]
	TIME [epoch: 8.02 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.317903603400637		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 1.317903603400637 | validation: 1.330941887917362]
	TIME [epoch: 8.01 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3443761877715148		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 1.3443761877715148 | validation: 1.289903143820795]
	TIME [epoch: 8.02 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1880186564252342		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 1.1880186564252342 | validation: 1.1990970906772556]
	TIME [epoch: 8.35 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1469626109414253		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 1.1469626109414253 | validation: 1.3768576272586706]
	TIME [epoch: 8.05 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4025235512539986		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 1.4025235512539986 | validation: 1.3708366848781712]
	TIME [epoch: 8.02 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6399283490021836		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 1.6399283490021836 | validation: 1.1959343810880427]
	TIME [epoch: 8.02 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3476520667967737		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 1.3476520667967737 | validation: 1.2222134589051343]
	TIME [epoch: 8.02 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3244513332002399		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 1.3244513332002399 | validation: 1.2524589112143274]
	TIME [epoch: 8.03 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3905993705902806		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 1.3905993705902806 | validation: 1.5125986902958433]
	TIME [epoch: 8.06 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2749721327388865		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 1.2749721327388865 | validation: 1.0838690489818137]
	TIME [epoch: 8.03 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4341142172515138		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 1.4341142172515138 | validation: 1.753852626773476]
	TIME [epoch: 8.02 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3510573470826683		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 1.3510573470826683 | validation: 1.155780097344905]
	TIME [epoch: 8.02 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1128434119477437		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 1.1128434119477437 | validation: 1.3515661205388079]
	TIME [epoch: 8.02 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343468920489092		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 1.343468920489092 | validation: 1.294525425696798]
	TIME [epoch: 8.06 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3598721905910582		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 1.3598721905910582 | validation: 1.1614724762973125]
	TIME [epoch: 8.03 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1654679274663555		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 1.1654679274663555 | validation: 1.3814226435385608]
	TIME [epoch: 8.02 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0789450761525208		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 1.0789450761525208 | validation: 1.5943102276764956]
	TIME [epoch: 8.02 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5807027147478154		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 1.5807027147478154 | validation: 1.0125335544769054]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397084818331145		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 1.1397084818331145 | validation: 1.334165486294393]
	TIME [epoch: 8.07 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2766196903293956		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 1.2766196903293956 | validation: 1.3486214657082711]
	TIME [epoch: 8.05 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2104832778493373		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 1.2104832778493373 | validation: 1.3614871015475571]
	TIME [epoch: 8.02 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1708484137080986		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 1.1708484137080986 | validation: 1.3874314710439064]
	TIME [epoch: 8.03 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2127380162061838		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 1.2127380162061838 | validation: 0.9662222509798414]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5121878473001644		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 1.5121878473001644 | validation: 0.9852364120664381]
	TIME [epoch: 8.05 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.340204414760675		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 1.340204414760675 | validation: 1.089727546862215]
	TIME [epoch: 8.05 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1854670722691818		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 1.1854670722691818 | validation: 1.2005049495591744]
	TIME [epoch: 8.03 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148563013112257		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 1.0148563013112257 | validation: 1.2026071608416298]
	TIME [epoch: 8.01 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3765183722757404		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 1.3765183722757404 | validation: 1.1583800423754549]
	TIME [epoch: 8.03 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2046589642298642		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 1.2046589642298642 | validation: 1.1994846360824138]
	TIME [epoch: 8.03 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4798464691220914		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 1.4798464691220914 | validation: 1.027316191103334]
	TIME [epoch: 8.09 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9423098482722166		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.9423098482722166 | validation: 1.3818633323675793]
	TIME [epoch: 8.08 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3512245546564212		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 1.3512245546564212 | validation: 1.509801514157416]
	TIME [epoch: 8.08 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1928207046497508		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 1.1928207046497508 | validation: 1.1156164028058955]
	TIME [epoch: 8.06 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159824319644091		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 1.159824319644091 | validation: 1.3281610638693442]
	TIME [epoch: 8.05 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1662483043312823		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 1.1662483043312823 | validation: 1.0914670791314376]
	TIME [epoch: 8.08 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1505438159422607		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 1.1505438159422607 | validation: 1.4775701994069297]
	TIME [epoch: 8.04 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3189865906291902		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 1.3189865906291902 | validation: 1.017551101212632]
	TIME [epoch: 8.03 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2289409395957351		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 1.2289409395957351 | validation: 1.327601181396859]
	TIME [epoch: 8.03 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2096345443712053		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 1.2096345443712053 | validation: 0.9318412590554034]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9017666534608861		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.9017666534608861 | validation: 0.9819536371526729]
	TIME [epoch: 108 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4336372372966393		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 1.4336372372966393 | validation: 1.0952386935332048]
	TIME [epoch: 15.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2148230340877555		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 1.2148230340877555 | validation: 0.8742496295582014]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4179403641278596		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 1.4179403641278596 | validation: 1.0970761090944356]
	TIME [epoch: 15.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2058841900874644		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 1.2058841900874644 | validation: 1.4090081896477578]
	TIME [epoch: 15.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1690015418471775		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 1.1690015418471775 | validation: 1.443499425682421]
	TIME [epoch: 15.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1288176652593966		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 1.1288176652593966 | validation: 1.1259370647511457]
	TIME [epoch: 15.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1670984617939077		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 1.1670984617939077 | validation: 0.8638680140192712]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1902474143463515		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 1.1902474143463515 | validation: 1.3891433050492312]
	TIME [epoch: 15.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3220585874320356		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 1.3220585874320356 | validation: 0.9927469618689988]
	TIME [epoch: 15.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9165143792962089		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.9165143792962089 | validation: 0.8196069585386055]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2357468456010996		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 1.2357468456010996 | validation: 0.8733641818472264]
	TIME [epoch: 15.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363170159447912		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 1.363170159447912 | validation: 1.115277502413209]
	TIME [epoch: 15.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120608537243763		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 1.120608537243763 | validation: 0.7876971008528031]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1995196632070972		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 1.1995196632070972 | validation: 0.8665492460434354]
	TIME [epoch: 15.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625445175842518		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 1.0625445175842518 | validation: 1.0942177448318056]
	TIME [epoch: 15.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2164726562974864		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 1.2164726562974864 | validation: 0.9557151272395559]
	TIME [epoch: 15.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0194459525494513		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 1.0194459525494513 | validation: 0.8757466474269022]
	TIME [epoch: 15.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1621659317872606		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 1.1621659317872606 | validation: 0.8857534061700123]
	TIME [epoch: 15.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1634738368990691		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 1.1634738368990691 | validation: 1.1009840633168233]
	TIME [epoch: 15.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0657741321730898		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 1.0657741321730898 | validation: 1.0438920140472443]
	TIME [epoch: 15.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9970521279783529		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.9970521279783529 | validation: 0.9011059208922747]
	TIME [epoch: 15.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3418585889433405		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 1.3418585889433405 | validation: 2.2546500536362153]
	TIME [epoch: 15.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9141384886617636		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 1.9141384886617636 | validation: 1.1650406518895262]
	TIME [epoch: 15.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2666927716364071		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 1.2666927716364071 | validation: 0.96155134485109]
	TIME [epoch: 15.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0161612111669405		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 1.0161612111669405 | validation: 0.8724583542076352]
	TIME [epoch: 15.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1334560209106275		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 1.1334560209106275 | validation: 1.010072964062522]
	TIME [epoch: 15.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0448366920835537		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 1.0448366920835537 | validation: 0.790661887761233]
	TIME [epoch: 15.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0282813240786108		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 1.0282813240786108 | validation: 0.8333977212707357]
	TIME [epoch: 15.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9330578003741047		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.9330578003741047 | validation: 0.8161199480678233]
	TIME [epoch: 15.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0500786023408222		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 1.0500786023408222 | validation: 1.028201697065013]
	TIME [epoch: 15.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1422627002236494		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 1.1422627002236494 | validation: 0.8938454592415368]
	TIME [epoch: 15.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0551184475159139		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 1.0551184475159139 | validation: 0.9813799204286212]
	TIME [epoch: 15.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1126472837877697		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 1.1126472837877697 | validation: 1.2610010603867863]
	TIME [epoch: 15.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1204504650393734		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 1.1204504650393734 | validation: 1.4060142318656386]
	TIME [epoch: 15.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1467791135612375		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 1.1467791135612375 | validation: 0.9593735162815705]
	TIME [epoch: 15.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0709022021844983		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 1.0709022021844983 | validation: 0.748522903586464]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6885768073203513		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 1.6885768073203513 | validation: 0.9229354221947792]
	TIME [epoch: 15.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1213821186873805		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 1.1213821186873805 | validation: 1.1998236426826918]
	TIME [epoch: 15.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891774152645898		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.9891774152645898 | validation: 0.9439033521788138]
	TIME [epoch: 15.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501271476265845		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 1.0501271476265845 | validation: 0.862840379496332]
	TIME [epoch: 15.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9720883394382112		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.9720883394382112 | validation: 1.0617888502257253]
	TIME [epoch: 15.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166071420866915		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 1.166071420866915 | validation: 1.1748318121486259]
	TIME [epoch: 15.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2026497088872146		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 1.2026497088872146 | validation: 0.7454759035006409]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9028365659418393		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.9028365659418393 | validation: 1.3521784496469054]
	TIME [epoch: 15.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1589554021888733		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 1.1589554021888733 | validation: 1.0105270679029261]
	TIME [epoch: 15.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1624305497992857		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 1.1624305497992857 | validation: 0.8477429250547361]
	TIME [epoch: 15.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9949331529059895		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.9949331529059895 | validation: 1.211447775358983]
	TIME [epoch: 15.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.46308786175085		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 1.46308786175085 | validation: 0.7596123146307112]
	TIME [epoch: 15.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8798737850679513		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.8798737850679513 | validation: 0.9065347612069332]
	TIME [epoch: 15.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323680764359845		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 1.1323680764359845 | validation: 0.9487020610696215]
	TIME [epoch: 15.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2870798784035449		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 1.2870798784035449 | validation: 1.1457873120257462]
	TIME [epoch: 15.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9989069416925129		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.9989069416925129 | validation: 0.8439410324738316]
	TIME [epoch: 15.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9126775522369217		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.9126775522369217 | validation: 1.0409181307395778]
	TIME [epoch: 15.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403788757106963		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 1.1403788757106963 | validation: 0.9682943903845262]
	TIME [epoch: 15.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0376630079414486		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 1.0376630079414486 | validation: 0.7570268998795564]
	TIME [epoch: 15.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437842296380269		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.9437842296380269 | validation: 1.2081109636632106]
	TIME [epoch: 15.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1199650552728224		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.1199650552728224 | validation: 0.9671464048595183]
	TIME [epoch: 15.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1200428355585534		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 1.1200428355585534 | validation: 0.914529913855744]
	TIME [epoch: 15.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.977708330040405		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.977708330040405 | validation: 0.821850469323206]
	TIME [epoch: 15.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013997360291527		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 1.013997360291527 | validation: 1.1232903652434647]
	TIME [epoch: 15.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092749355793346		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 1.092749355793346 | validation: 1.0366835700370607]
	TIME [epoch: 15.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0407711847054069		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 1.0407711847054069 | validation: 0.9170520610385109]
	TIME [epoch: 15.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0468902412612306		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 1.0468902412612306 | validation: 0.9373489911621611]
	TIME [epoch: 15.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079073602899348		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 1.079073602899348 | validation: 0.989780047235485]
	TIME [epoch: 15.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1740058360517815		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 1.1740058360517815 | validation: 0.7613310910219031]
	TIME [epoch: 15.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419347934119672		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.8419347934119672 | validation: 0.9885683598757695]
	TIME [epoch: 15.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4777395614718398		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 1.4777395614718398 | validation: 1.066300446339143]
	TIME [epoch: 15.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347277505397492		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 1.0347277505397492 | validation: 0.9883197510729083]
	TIME [epoch: 15.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1192554618160107		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 1.1192554618160107 | validation: 0.8746433045310509]
	TIME [epoch: 15.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9698093591818615		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.9698093591818615 | validation: 1.281064194558619]
	TIME [epoch: 15.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1816992515572564		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 1.1816992515572564 | validation: 0.9146955343559302]
	TIME [epoch: 15.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.908573046246586		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.908573046246586 | validation: 0.8419733220310957]
	TIME [epoch: 15.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0055644617730277		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 1.0055644617730277 | validation: 0.9513570776555165]
	TIME [epoch: 15.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9811599570744759		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.9811599570744759 | validation: 0.9157651516822236]
	TIME [epoch: 15.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0972229214884748		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 1.0972229214884748 | validation: 0.7555718664638928]
	TIME [epoch: 15.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045838535429742		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 1.045838535429742 | validation: 0.6868839311789696]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0470116225123933		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 1.0470116225123933 | validation: 1.5029421302618307]
	TIME [epoch: 15.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.200298546212568		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 1.200298546212568 | validation: 0.8822927911154249]
	TIME [epoch: 15.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9563327090500624		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.9563327090500624 | validation: 1.0459187189918608]
	TIME [epoch: 15.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9854570338683165		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.9854570338683165 | validation: 0.864482479054566]
	TIME [epoch: 15.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604884872693967		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 1.0604884872693967 | validation: 0.9005932020932605]
	TIME [epoch: 15.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0107755072872209		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 1.0107755072872209 | validation: 0.8837783334408817]
	TIME [epoch: 15.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1316890907808759		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 1.1316890907808759 | validation: 0.8209366748381327]
	TIME [epoch: 15.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.959955262050402		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.959955262050402 | validation: 0.8253569750037089]
	TIME [epoch: 15.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060290283343857		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 1.060290283343857 | validation: 1.017246234076406]
	TIME [epoch: 15.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9278519543753074		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.9278519543753074 | validation: 0.9015992901592265]
	TIME [epoch: 15.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9902093228962026		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.9902093228962026 | validation: 0.8079875591162871]
	TIME [epoch: 15.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9414891375021659		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.9414891375021659 | validation: 1.3824367041979826]
	TIME [epoch: 15.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0518178575654054		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 1.0518178575654054 | validation: 0.9032552665051179]
	TIME [epoch: 15.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9007221988405381		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.9007221988405381 | validation: 0.7769444232786349]
	TIME [epoch: 15.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979294209525673		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.979294209525673 | validation: 1.5242745560709623]
	TIME [epoch: 15.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.960291611313713		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.960291611313713 | validation: 1.0245346264797401]
	TIME [epoch: 15.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8770955857104652		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.8770955857104652 | validation: 1.203710294068654]
	TIME [epoch: 15.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9941932889858761		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.9941932889858761 | validation: 1.366723293511306]
	TIME [epoch: 15.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1695950771220371		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 1.1695950771220371 | validation: 0.7962786625860439]
	TIME [epoch: 15.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826209205596968		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.7826209205596968 | validation: 1.098740547281521]
	TIME [epoch: 15.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0477628693932006		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 1.0477628693932006 | validation: 0.7310226331541513]
	TIME [epoch: 15.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782561907999342		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.8782561907999342 | validation: 1.0753408744181303]
	TIME [epoch: 15.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1070498538523017		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 1.1070498538523017 | validation: 1.1209175981680906]
	TIME [epoch: 15.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9285010006633648		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.9285010006633648 | validation: 0.6857307315618912]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9654563755109482		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 1.9654563755109482 | validation: 2.3911107913158895]
	TIME [epoch: 15.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9206722736513702		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 1.9206722736513702 | validation: 1.5456383873504431]
	TIME [epoch: 15.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4664780166907274		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 1.4664780166907274 | validation: 1.2608595372616394]
	TIME [epoch: 15.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.281412668075566		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 1.281412668075566 | validation: 1.0854213719940726]
	TIME [epoch: 15.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2542315661577315		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 1.2542315661577315 | validation: 0.7899339402578802]
	TIME [epoch: 15.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217769104338883		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 1.2217769104338883 | validation: 0.6977430896594586]
	TIME [epoch: 15.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018473837069137		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 1.018473837069137 | validation: 0.9016469036927385]
	TIME [epoch: 15.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8853579072465245		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.8853579072465245 | validation: 0.8535852123292967]
	TIME [epoch: 15.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9357649385697264		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.9357649385697264 | validation: 0.8982338692159276]
	TIME [epoch: 15.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008144646024926		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.9008144646024926 | validation: 0.6624264366249968]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9247245159249338		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.9247245159249338 | validation: 0.9122394755176477]
	TIME [epoch: 15.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9929758837472098		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.9929758837472098 | validation: 0.7618541516390686]
	TIME [epoch: 15.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8905560903302219		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.8905560903302219 | validation: 1.3635519134335223]
	TIME [epoch: 15.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556276793135543		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 1.1556276793135543 | validation: 0.9570051967555464]
	TIME [epoch: 15.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.988354850019041		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.988354850019041 | validation: 0.9663315467594795]
	TIME [epoch: 15.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598082753746718		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 1.0598082753746718 | validation: 0.8339999005333788]
	TIME [epoch: 15.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8930250070665153		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.8930250070665153 | validation: 1.127257213201113]
	TIME [epoch: 15.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000071855121969		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 1.000071855121969 | validation: 0.9114636328836192]
	TIME [epoch: 15.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8519762641707598		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.8519762641707598 | validation: 1.0161097669857444]
	TIME [epoch: 15.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0845918076078809		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 1.0845918076078809 | validation: 0.8285499402109182]
	TIME [epoch: 15.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0139995663377273		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 1.0139995663377273 | validation: 1.256810797431676]
	TIME [epoch: 15.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261945486884936		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 1.0261945486884936 | validation: 0.9957603029167348]
	TIME [epoch: 15.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9851664102799704		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.9851664102799704 | validation: 1.2548833908877266]
	TIME [epoch: 15.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0550838566272311		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 1.0550838566272311 | validation: 0.8591237921391701]
	TIME [epoch: 15.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8725122504716303		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.8725122504716303 | validation: 0.9596294132536054]
	TIME [epoch: 15.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0675740222458818		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 1.0675740222458818 | validation: 0.7165269466432089]
	TIME [epoch: 15.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9919239204340411		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.9919239204340411 | validation: 0.7739094355262154]
	TIME [epoch: 15.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181578867618047		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.8181578867618047 | validation: 0.9011503407221354]
	TIME [epoch: 15.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9146992629733811		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.9146992629733811 | validation: 0.9118356815896123]
	TIME [epoch: 15.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9227203872200138		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.9227203872200138 | validation: 0.9240646358828248]
	TIME [epoch: 15.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010291962601448		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 1.010291962601448 | validation: 0.646578163757535]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9382327840257727		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.9382327840257727 | validation: 0.9691271200302077]
	TIME [epoch: 15.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9311245927254395		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.9311245927254395 | validation: 0.9976625720756984]
	TIME [epoch: 15.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8725712573303503		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.8725712573303503 | validation: 1.18124168356744]
	TIME [epoch: 15.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0081940006939418		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 1.0081940006939418 | validation: 0.7138544773161539]
	TIME [epoch: 15.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9161911654392417		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.9161911654392417 | validation: 1.1145817446100792]
	TIME [epoch: 15.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0330220944570472		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 1.0330220944570472 | validation: 0.8564589803585295]
	TIME [epoch: 15.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941255296201085		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.941255296201085 | validation: 0.7962523973362077]
	TIME [epoch: 15.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8588027806212621		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.8588027806212621 | validation: 0.8704590845006098]
	TIME [epoch: 15.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9726679067818089		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.9726679067818089 | validation: 0.8854146643327542]
	TIME [epoch: 15.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1778063075225327		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 1.1778063075225327 | validation: 1.1186237274423854]
	TIME [epoch: 15.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735278423610737		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 1.0735278423610737 | validation: 0.9865114582842407]
	TIME [epoch: 15.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8905563101118815		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.8905563101118815 | validation: 0.8833655965883751]
	TIME [epoch: 15.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9746511511037356		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.9746511511037356 | validation: 0.9769345473837452]
	TIME [epoch: 15.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9249146140973681		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.9249146140973681 | validation: 0.7775970335550075]
	TIME [epoch: 15.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285302134613256		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.8285302134613256 | validation: 0.9039174422625526]
	TIME [epoch: 15.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.015200446232796		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 1.015200446232796 | validation: 0.9601281720860192]
	TIME [epoch: 15.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2478261462177385		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 1.2478261462177385 | validation: 1.2615032300777298]
	TIME [epoch: 15.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0257320373899645		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 1.0257320373899645 | validation: 0.6640436630018176]
	TIME [epoch: 15.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189619299214382		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.9189619299214382 | validation: 0.7007033859004086]
	TIME [epoch: 15.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938832672263403		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.8938832672263403 | validation: 0.6562480931957803]
	TIME [epoch: 15.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9920334046131778		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.9920334046131778 | validation: 0.6717662048480368]
	TIME [epoch: 15.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8225191088273912		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.8225191088273912 | validation: 1.1412774499244929]
	TIME [epoch: 15.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9105644637200995		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.9105644637200995 | validation: 0.9794531270945281]
	TIME [epoch: 15.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0677205256652573		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 1.0677205256652573 | validation: 0.8887215648743547]
	TIME [epoch: 15.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9099680593814267		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.9099680593814267 | validation: 1.0312868429138664]
	TIME [epoch: 15.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253208502302694		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.8253208502302694 | validation: 0.7286605796403873]
	TIME [epoch: 15.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077087590031736		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 1.077087590031736 | validation: 0.7044464918667555]
	TIME [epoch: 15.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8669166629175085		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.8669166629175085 | validation: 0.8975039504281555]
	TIME [epoch: 15.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.99647511257248		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.99647511257248 | validation: 0.8541576588627506]
	TIME [epoch: 15.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432041258877487		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.8432041258877487 | validation: 0.8903359104327815]
	TIME [epoch: 15.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253682826654228		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.9253682826654228 | validation: 0.9887930797911529]
	TIME [epoch: 15.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0334516104577018		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 1.0334516104577018 | validation: 0.725558443341014]
	TIME [epoch: 15.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8840836034745035		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.8840836034745035 | validation: 0.7672326451755309]
	TIME [epoch: 15.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405028107958397		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.8405028107958397 | validation: 1.7366699613886818]
	TIME [epoch: 15.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148563021669301		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 1.0148563021669301 | validation: 1.1937013352334653]
	TIME [epoch: 15.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9376721131690499		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.9376721131690499 | validation: 0.7247113662886954]
	TIME [epoch: 15.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025338494380198		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 1.025338494380198 | validation: 0.7739659998322972]
	TIME [epoch: 15.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8444584670599637		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.8444584670599637 | validation: 0.6749720847475812]
	TIME [epoch: 15.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9686160144680405		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.9686160144680405 | validation: 0.7636916198043868]
	TIME [epoch: 15.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889524182172617		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.8889524182172617 | validation: 0.7290396023016756]
	TIME [epoch: 15.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9027608858108276		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.9027608858108276 | validation: 0.7067534992843841]
	TIME [epoch: 15.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9797776724838464		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.9797776724838464 | validation: 0.8489109089894311]
	TIME [epoch: 15.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8561186356967058		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.8561186356967058 | validation: 0.796553087013939]
	TIME [epoch: 15.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582364964660875		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.8582364964660875 | validation: 0.6948650187109099]
	TIME [epoch: 15.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8261002771987508		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.8261002771987508 | validation: 0.990362511041523]
	TIME [epoch: 15.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9322728848047669		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.9322728848047669 | validation: 0.6868805866877145]
	TIME [epoch: 15.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254800812423973		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.7254800812423973 | validation: 0.9516191197752177]
	TIME [epoch: 15.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9851976901186423		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.9851976901186423 | validation: 0.8234446573657312]
	TIME [epoch: 15.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8115265589386482		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.8115265589386482 | validation: 0.5884348956741414]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295322476568936		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.8295322476568936 | validation: 0.8590650399112985]
	TIME [epoch: 15.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9230887522691031		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.9230887522691031 | validation: 0.6452751461593853]
	TIME [epoch: 15.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8069160312915999		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.8069160312915999 | validation: 0.963056581022486]
	TIME [epoch: 15.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021900397821005		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 1.021900397821005 | validation: 0.8175468500645509]
	TIME [epoch: 15.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683877608625199		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.8683877608625199 | validation: 0.629759174574449]
	TIME [epoch: 15.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412410054729532		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.7412410054729532 | validation: 0.8439902500282142]
	TIME [epoch: 15.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784260394518022		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 1.0784260394518022 | validation: 0.6725066686282133]
	TIME [epoch: 15.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8634102344667639		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.8634102344667639 | validation: 1.3245213087628733]
	TIME [epoch: 15.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9747598819333315		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.9747598819333315 | validation: 0.7833971817934666]
	TIME [epoch: 15.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365004242149702		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.9365004242149702 | validation: 0.8745333117977769]
	TIME [epoch: 15.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174411563373864		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.7174411563373864 | validation: 3.2032372115486814]
	TIME [epoch: 15.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8565558818857608		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 1.8565558818857608 | validation: 1.5936944771661103]
	TIME [epoch: 15.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244837523058903		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 1.0244837523058903 | validation: 3.0027554394843587]
	TIME [epoch: 15.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.209426070378594		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 2.209426070378594 | validation: 1.7704349129491854]
	TIME [epoch: 15.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241275478535926		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 1.241275478535926 | validation: 1.173175910295325]
	TIME [epoch: 15.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0391361188768657		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 1.0391361188768657 | validation: 0.6229081909289993]
	TIME [epoch: 15.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9059715609310254		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.9059715609310254 | validation: 0.7170910781616252]
	TIME [epoch: 15.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8872908872333085		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.8872908872333085 | validation: 0.8150350492320453]
	TIME [epoch: 15.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570451283614786		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 1.0570451283614786 | validation: 0.9910366322709265]
	TIME [epoch: 15.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9092517822447233		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.9092517822447233 | validation: 1.2001403357496367]
	TIME [epoch: 15.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1725444918736976		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.1725444918736976 | validation: 0.7687997730738028]
	TIME [epoch: 15.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412597137961658		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.8412597137961658 | validation: 0.8544664842766372]
	TIME [epoch: 15.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9410469256041771		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.9410469256041771 | validation: 1.0409728365029367]
	TIME [epoch: 15.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761051269572957		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.8761051269572957 | validation: 1.0059721062303162]
	TIME [epoch: 15.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047091904155675		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.8047091904155675 | validation: 0.6880720721510307]
	TIME [epoch: 15.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8602474056406316		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.8602474056406316 | validation: 1.4114347572608812]
	TIME [epoch: 15.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9450869393015447		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.9450869393015447 | validation: 1.2692774205763842]
	TIME [epoch: 15.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9929729946804041		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.9929729946804041 | validation: 1.0707108915354793]
	TIME [epoch: 15.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1373345462394584		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 1.1373345462394584 | validation: 1.036554607671413]
	TIME [epoch: 15.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1417287209731029		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 1.1417287209731029 | validation: 0.8740323487992492]
	TIME [epoch: 15.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.889836310020083		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.889836310020083 | validation: 0.7214241972846157]
	TIME [epoch: 15.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959737180849382		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.7959737180849382 | validation: 0.5858985590073642]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9601577085520179		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.9601577085520179 | validation: 1.0354160484975874]
	TIME [epoch: 15.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8241111011687526		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.8241111011687526 | validation: 0.9141510627593918]
	TIME [epoch: 15.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.887773036699345		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.887773036699345 | validation: 0.6167047526036449]
	TIME [epoch: 15.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7636563759692128		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.7636563759692128 | validation: 1.3105385316433547]
	TIME [epoch: 15.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1821716194828766		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 1.1821716194828766 | validation: 0.7699310054908843]
	TIME [epoch: 15.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0427116132409273		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 1.0427116132409273 | validation: 1.0673249867864216]
	TIME [epoch: 15.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9145450697299058		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.9145450697299058 | validation: 0.8587416293155139]
	TIME [epoch: 15.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1661158000253948		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 1.1661158000253948 | validation: 0.6403638969977166]
	TIME [epoch: 15.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090142019897433		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.8090142019897433 | validation: 0.7366129948725297]
	TIME [epoch: 15.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8566900943041907		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.8566900943041907 | validation: 0.7059671096195457]
	TIME [epoch: 15.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8380615628603572		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.8380615628603572 | validation: 0.9944060723348837]
	TIME [epoch: 15.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0880037424905555		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 1.0880037424905555 | validation: 0.5389637059005272]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.890965465915866		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.890965465915866 | validation: 1.1545706057243372]
	TIME [epoch: 15.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794991078726453		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.9794991078726453 | validation: 0.7241943253866328]
	TIME [epoch: 15.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8415523344814166		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.8415523344814166 | validation: 0.6760823952833743]
	TIME [epoch: 15.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153939101033606		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.9153939101033606 | validation: 0.8140007397843295]
	TIME [epoch: 15.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953739668845333		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.8953739668845333 | validation: 0.8152931319674268]
	TIME [epoch: 15.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8398956312934395		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.8398956312934395 | validation: 0.9783870751545916]
	TIME [epoch: 15.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9505560736252893		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.9505560736252893 | validation: 0.745825287946501]
	TIME [epoch: 15.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8068407941135559		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.8068407941135559 | validation: 0.8732806050130428]
	TIME [epoch: 15.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779935075932457		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.7779935075932457 | validation: 0.4423480513161111]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544512691186259		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.7544512691186259 | validation: 0.8647121264998856]
	TIME [epoch: 15.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1152078372814762		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 1.1152078372814762 | validation: 0.7101609438641177]
	TIME [epoch: 15.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1261281468556168		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 1.1261281468556168 | validation: 1.0290052113028243]
	TIME [epoch: 15.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9315654569985506		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.9315654569985506 | validation: 0.7859756869786111]
	TIME [epoch: 15.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8255410923459711		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.8255410923459711 | validation: 0.7332371863555947]
	TIME [epoch: 15.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8444801304014968		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.8444801304014968 | validation: 0.7861058259501248]
	TIME [epoch: 15.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572628229609691		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.7572628229609691 | validation: 0.8462982715361593]
	TIME [epoch: 15.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8338153804850459		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.8338153804850459 | validation: 0.792415323075909]
	TIME [epoch: 15.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8172744239136804		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.8172744239136804 | validation: 0.9919379177859762]
	TIME [epoch: 15.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8449201153109389		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.8449201153109389 | validation: 0.5733220169283914]
	TIME [epoch: 15.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437507530023569		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.8437507530023569 | validation: 0.6104416163088977]
	TIME [epoch: 15.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9015081969047692		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.9015081969047692 | validation: 0.9521777178316131]
	TIME [epoch: 15.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500898010727992		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.7500898010727992 | validation: 0.8340774182017741]
	TIME [epoch: 15.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684348398152534		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.7684348398152534 | validation: 0.754125207755281]
	TIME [epoch: 15.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8923625331014771		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.8923625331014771 | validation: 0.5709322106325121]
	TIME [epoch: 15.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9158641321188956		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.9158641321188956 | validation: 0.6507677488979147]
	TIME [epoch: 15.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791659376709571		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.791659376709571 | validation: 1.176195120635935]
	TIME [epoch: 15.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9695878530726754		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.9695878530726754 | validation: 0.82928506662126]
	TIME [epoch: 15.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094874601047305		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.7094874601047305 | validation: 0.6885596249164423]
	TIME [epoch: 15.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9293662163214987		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.9293662163214987 | validation: 1.1097219642932532]
	TIME [epoch: 15.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789176623189999		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.789176623189999 | validation: 0.558398008252659]
	TIME [epoch: 15.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062733513601978		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.8062733513601978 | validation: 0.6631699673208066]
	TIME [epoch: 15.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303445289789545		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.8303445289789545 | validation: 0.873801704184142]
	TIME [epoch: 15.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9388301068552497		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.9388301068552497 | validation: 0.7736908448385671]
	TIME [epoch: 15.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757258073132899		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.7757258073132899 | validation: 0.6216395895108009]
	TIME [epoch: 15.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855609096879922		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.855609096879922 | validation: 0.6757450432819531]
	TIME [epoch: 15.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547615438258487		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.8547615438258487 | validation: 0.805268439033755]
	TIME [epoch: 15.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184014155777237		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.7184014155777237 | validation: 0.6796641963310901]
	TIME [epoch: 15.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8887032698737283		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.8887032698737283 | validation: 1.2728558189939259]
	TIME [epoch: 15.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9522703911173078		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.9522703911173078 | validation: 0.6009359124665348]
	TIME [epoch: 15.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.845867398085093		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.845867398085093 | validation: 0.7123603231666173]
	TIME [epoch: 15.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787462764196965		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.7787462764196965 | validation: 0.8556959219766472]
	TIME [epoch: 15.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9052550512822639		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.9052550512822639 | validation: 0.7042386692157357]
	TIME [epoch: 15.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8633593318392138		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.8633593318392138 | validation: 0.7586737636754597]
	TIME [epoch: 15.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707941693009146		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.707941693009146 | validation: 0.4562023693325028]
	TIME [epoch: 15.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8748152654124409		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.8748152654124409 | validation: 0.856847135935064]
	TIME [epoch: 15.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8947402408886594		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.8947402408886594 | validation: 0.6600046128936157]
	TIME [epoch: 15.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9736889405175733		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.9736889405175733 | validation: 0.7130039925740299]
	TIME [epoch: 15.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7868995539916183		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.7868995539916183 | validation: 0.726325797663764]
	TIME [epoch: 15.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367093485853216		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.7367093485853216 | validation: 0.7078884806082182]
	TIME [epoch: 15.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466575056652723		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.7466575056652723 | validation: 0.7607208361974915]
	TIME [epoch: 15.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8145516177734495		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.8145516177734495 | validation: 0.8503332044575949]
	TIME [epoch: 15.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9441175599018392		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.9441175599018392 | validation: 0.7162921726652811]
	TIME [epoch: 15.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7991188073786866		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.7991188073786866 | validation: 0.7175058581805366]
	TIME [epoch: 15.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.836906251550257		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.836906251550257 | validation: 0.734202777128633]
	TIME [epoch: 15.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9012478549408234		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.9012478549408234 | validation: 0.8847246626949674]
	TIME [epoch: 15.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274803513248972		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.7274803513248972 | validation: 0.9630024888880693]
	TIME [epoch: 15.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884162975683913		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.884162975683913 | validation: 0.7053202449687823]
	TIME [epoch: 15.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7971776855598585		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.7971776855598585 | validation: 0.5211472910293884]
	TIME [epoch: 15.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8238008244501713		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.8238008244501713 | validation: 0.9686915012659523]
	TIME [epoch: 15.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968133303714294		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.9968133303714294 | validation: 1.0122867250813248]
	TIME [epoch: 15.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301781376073171		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.8301781376073171 | validation: 0.8508733991709994]
	TIME [epoch: 15.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7747299926684916		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.7747299926684916 | validation: 0.5317195694837897]
	TIME [epoch: 15.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7740042675852309		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.7740042675852309 | validation: 1.0686741676994387]
	TIME [epoch: 15.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8686227430724065		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.8686227430724065 | validation: 0.8707454137860156]
	TIME [epoch: 15.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8318712570438347		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.8318712570438347 | validation: 0.702549030410354]
	TIME [epoch: 15.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613076592398986		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.7613076592398986 | validation: 0.774447766522145]
	TIME [epoch: 15.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048684061089267		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.8048684061089267 | validation: 0.9002955352911546]
	TIME [epoch: 15.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8597136373534366		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.8597136373534366 | validation: 0.7086591602356425]
	TIME [epoch: 15.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9216575893810508		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.9216575893810508 | validation: 0.7752567099961076]
	TIME [epoch: 15.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842458435794681		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.7842458435794681 | validation: 0.9295366726499502]
	TIME [epoch: 15.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789013547543465		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.789013547543465 | validation: 1.0380940949153845]
	TIME [epoch: 15.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475675340913934		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.8475675340913934 | validation: 0.6544219647483698]
	TIME [epoch: 15.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.957308393004598		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.957308393004598 | validation: 0.8542662199351168]
	TIME [epoch: 15.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393899066605631		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.7393899066605631 | validation: 0.5084032561317646]
	TIME [epoch: 15.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585494198294827		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.7585494198294827 | validation: 0.6154785852047392]
	TIME [epoch: 15.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8161667898917733		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.8161667898917733 | validation: 0.7788639573733318]
	TIME [epoch: 126 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707215716948764		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.7707215716948764 | validation: 0.6604372948439197]
	TIME [epoch: 34.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409829910515713		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.8409829910515713 | validation: 0.5999395584287293]
	TIME [epoch: 34.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8429508751094907		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.8429508751094907 | validation: 0.6912739340945167]
	TIME [epoch: 34.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956236120801397		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.7956236120801397 | validation: 0.699631815525273]
	TIME [epoch: 34.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187112975441363		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.8187112975441363 | validation: 0.8090963824595829]
	TIME [epoch: 34.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8029575398188491		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.8029575398188491 | validation: 0.7064135223304207]
	TIME [epoch: 34.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565681996351066		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.7565681996351066 | validation: 0.7137448622036265]
	TIME [epoch: 34.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746491226897845		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.7746491226897845 | validation: 0.7353440207049556]
	TIME [epoch: 34.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689043020818757		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.6689043020818757 | validation: 0.7272910370881807]
	TIME [epoch: 34.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755069084749169		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.8755069084749169 | validation: 0.589750311030595]
	TIME [epoch: 34.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7442651419032613		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.7442651419032613 | validation: 0.621718693448392]
	TIME [epoch: 34.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8638113270723993		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.8638113270723993 | validation: 0.8477939736129259]
	TIME [epoch: 34.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501033805885244		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.7501033805885244 | validation: 0.8559750008968068]
	TIME [epoch: 34.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8788293250841621		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.8788293250841621 | validation: 0.6221582775518116]
	TIME [epoch: 34.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6621683752939551		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.6621683752939551 | validation: 0.6442074910763518]
	TIME [epoch: 34.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6375481250398531		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.6375481250398531 | validation: 1.003809938611004]
	TIME [epoch: 34.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605380624967649		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.8605380624967649 | validation: 0.6758247917222088]
	TIME [epoch: 34.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7893509110263444		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.7893509110263444 | validation: 0.912294872500589]
	TIME [epoch: 34.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8010211663711895		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.8010211663711895 | validation: 0.5830372717576233]
	TIME [epoch: 34.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074056468274722		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.8074056468274722 | validation: 0.8527119918269908]
	TIME [epoch: 34.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8473367590476816		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.8473367590476816 | validation: 0.6299510609070572]
	TIME [epoch: 34.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8026672110554895		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.8026672110554895 | validation: 0.4937589657536898]
	TIME [epoch: 34.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.841400526250687		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.841400526250687 | validation: 0.5553559699292042]
	TIME [epoch: 34.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632647199127603		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.7632647199127603 | validation: 0.4795721195475482]
	TIME [epoch: 34.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113293413920764		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.8113293413920764 | validation: 0.5495826737580292]
	TIME [epoch: 34.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113638500874478		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.8113638500874478 | validation: 0.487939182990176]
	TIME [epoch: 34.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8430809591617989		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.8430809591617989 | validation: 0.8229694191552007]
	TIME [epoch: 34.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057899607266294		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.7057899607266294 | validation: 0.8999735240701376]
	TIME [epoch: 34.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486576924605979		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.8486576924605979 | validation: 0.7176735035947357]
	TIME [epoch: 34.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447079787254907		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.7447079787254907 | validation: 0.5463207337869409]
	TIME [epoch: 34.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.800211679338475		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.800211679338475 | validation: 0.6754211098110996]
	TIME [epoch: 34.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884516761902181		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.884516761902181 | validation: 0.7273614161864659]
	TIME [epoch: 34.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615893050073838		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.6615893050073838 | validation: 0.8013708060811136]
	TIME [epoch: 34.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8549886905816587		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.8549886905816587 | validation: 0.5547838733187973]
	TIME [epoch: 34.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707818399515395		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.7707818399515395 | validation: 0.653206223622054]
	TIME [epoch: 34.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911912811194939		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.7911912811194939 | validation: 0.5910068541346154]
	TIME [epoch: 34.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664924110162906		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.6664924110162906 | validation: 0.682269246220625]
	TIME [epoch: 34.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7604531483046915		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.7604531483046915 | validation: 0.9971532747274139]
	TIME [epoch: 34.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8561781454946001		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.8561781454946001 | validation: 0.8112935498966123]
	TIME [epoch: 34.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195976886991187		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.7195976886991187 | validation: 0.6460700787949167]
	TIME [epoch: 34.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272159858365606		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.8272159858365606 | validation: 0.7737476511039594]
	TIME [epoch: 34.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7878808428064794		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.7878808428064794 | validation: 0.7210016058124152]
	TIME [epoch: 34.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8232705150063443		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.8232705150063443 | validation: 0.8548213914341323]
	TIME [epoch: 34.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483459129929434		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.7483459129929434 | validation: 0.7840629660950413]
	TIME [epoch: 34.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732522133457301		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.7732522133457301 | validation: 0.9085632958513307]
	TIME [epoch: 34.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803123950532538		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.8803123950532538 | validation: 0.4187845039311346]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_547.pth
	Model improved!!!
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651277879987768		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.7651277879987768 | validation: 0.9039619692409762]
	TIME [epoch: 34.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1732267876530735		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 1.1732267876530735 | validation: 0.7753885335163268]
	TIME [epoch: 34.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380473236975066		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.7380473236975066 | validation: 0.7066828911903854]
	TIME [epoch: 34.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393549739479215		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.7393549739479215 | validation: 0.7302698542390609]
	TIME [epoch: 34.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381921503505287		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.7381921503505287 | validation: 1.1289267083697632]
	TIME [epoch: 34.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240702295357156		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.8240702295357156 | validation: 0.47740129034899803]
	TIME [epoch: 34.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773314112524489		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.5773314112524489 | validation: 0.7734627958993987]
	TIME [epoch: 34.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8135851316710411		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.8135851316710411 | validation: 0.6308423977708143]
	TIME [epoch: 34.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963212041296448		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.7963212041296448 | validation: 0.626868730042189]
	TIME [epoch: 34.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8018530148496822		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.8018530148496822 | validation: 0.8052395027134549]
	TIME [epoch: 34.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055860510105638		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.7055860510105638 | validation: 0.6743721820427001]
	TIME [epoch: 34.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7405132419003931		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.7405132419003931 | validation: 0.5633875498943806]
	TIME [epoch: 34.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7910036823648187		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.7910036823648187 | validation: 0.9023228911437858]
	TIME [epoch: 34.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8315432893692514		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.8315432893692514 | validation: 0.99620391487403]
	TIME [epoch: 34.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922450163523708		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.7922450163523708 | validation: 0.753330670103552]
	TIME [epoch: 34.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982867619920226		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.6982867619920226 | validation: 0.6127537103283704]
	TIME [epoch: 34.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218322755087533		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.7218322755087533 | validation: 0.6454217223253398]
	TIME [epoch: 34.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428542087005249		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.7428542087005249 | validation: 0.7913584399802733]
	TIME [epoch: 34.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8657955689483299		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.8657955689483299 | validation: 0.5204533522279404]
	TIME [epoch: 34.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575752754348156		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.6575752754348156 | validation: 0.6324869905458532]
	TIME [epoch: 34.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.784935823119145		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.784935823119145 | validation: 0.7690455280971727]
	TIME [epoch: 34.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895278531878707		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.7895278531878707 | validation: 0.45940465112334317]
	TIME [epoch: 34.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8259456639224837		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.8259456639224837 | validation: 0.8693894465380159]
	TIME [epoch: 34.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496431516497613		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.7496431516497613 | validation: 0.6278237350727895]
	TIME [epoch: 34.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438455159157771		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.7438455159157771 | validation: 1.317414991270038]
	TIME [epoch: 34.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9428543751981022		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.9428543751981022 | validation: 0.7693659298949056]
	TIME [epoch: 34.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8061767107851521		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.8061767107851521 | validation: 0.6132915292029988]
	TIME [epoch: 34.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425628435010596		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.7425628435010596 | validation: 0.5745376883246144]
	TIME [epoch: 34.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584573350121053		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.7584573350121053 | validation: 0.7708121334196676]
	TIME [epoch: 34.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8278801027484539		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.8278801027484539 | validation: 0.5893496288591462]
	TIME [epoch: 34.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785093065447807		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.6785093065447807 | validation: 0.7807643257264273]
	TIME [epoch: 34.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8731675695507892		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.8731675695507892 | validation: 0.5703361134087358]
	TIME [epoch: 34.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6702727015533392		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.6702727015533392 | validation: 0.6508528887059477]
	TIME [epoch: 34.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8631488600478583		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.8631488600478583 | validation: 0.8521081737365006]
	TIME [epoch: 34.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6350899480761824		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.6350899480761824 | validation: 0.9978848386192547]
	TIME [epoch: 34.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7450774213054479		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.7450774213054479 | validation: 0.6532812159616352]
	TIME [epoch: 34.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.842245841457952		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.842245841457952 | validation: 0.6851228855879097]
	TIME [epoch: 34.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059864397245375		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.7059864397245375 | validation: 0.6119273715322049]
	TIME [epoch: 34.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683351173334631		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.6683351173334631 | validation: 0.9289499320576355]
	TIME [epoch: 34.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8126700098676475		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.8126700098676475 | validation: 0.8091687013380068]
	TIME [epoch: 34.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71588063581132		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.71588063581132 | validation: 0.7723360730502242]
	TIME [epoch: 34.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7720658313321314		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.7720658313321314 | validation: 0.49816654218568546]
	TIME [epoch: 34.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7667656860087357		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.7667656860087357 | validation: 0.6965068869551714]
	TIME [epoch: 34.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655019161829184		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.7655019161829184 | validation: 1.0029171129591443]
	TIME [epoch: 34.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700389767124105		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.7700389767124105 | validation: 0.664672198396544]
	TIME [epoch: 34.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314232612319093		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.7314232612319093 | validation: 0.721283627272011]
	TIME [epoch: 34.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386485732685981		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.7386485732685981 | validation: 0.6669755817421841]
	TIME [epoch: 34.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603257506843362		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.603257506843362 | validation: 0.617528472820351]
	TIME [epoch: 34.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687608661784364		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.7687608661784364 | validation: 0.7857367667876621]
	TIME [epoch: 34.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8306657139438872		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.8306657139438872 | validation: 0.502445267410916]
	TIME [epoch: 34.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378891381477464		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.7378891381477464 | validation: 0.6458293754755146]
	TIME [epoch: 34.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908974285170145		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.5908974285170145 | validation: 0.861851724292563]
	TIME [epoch: 34.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467899007155646		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.8467899007155646 | validation: 0.7737322818375291]
	TIME [epoch: 34.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700808701580207		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.7700808701580207 | validation: 0.5554912751335072]
	TIME [epoch: 34.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469053582064948		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.6469053582064948 | validation: 0.46482997640460216]
	TIME [epoch: 34.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034282472295056		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.7034282472295056 | validation: 0.8165015405326215]
	TIME [epoch: 34.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8535936674642841		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.8535936674642841 | validation: 0.9230150837856583]
	TIME [epoch: 34.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588596941258254		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.7588596941258254 | validation: 0.5829460514606752]
	TIME [epoch: 34.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642232649524087		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.6642232649524087 | validation: 0.6285721138899946]
	TIME [epoch: 34.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461124179424742		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.6461124179424742 | validation: 0.6935619421842252]
	TIME [epoch: 34.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856944876709575		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.6856944876709575 | validation: 0.7195631784674923]
	TIME [epoch: 34.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8441259792442479		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.8441259792442479 | validation: 0.7613676905605296]
	TIME [epoch: 34.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520249740851914		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.7520249740851914 | validation: 0.6535844103490612]
	TIME [epoch: 34.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822431291012783		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.6822431291012783 | validation: 0.6396018452794701]
	TIME [epoch: 34.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8019638322267607		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.8019638322267607 | validation: 0.7251089399282737]
	TIME [epoch: 34.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114455648473555		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.8114455648473555 | validation: 0.8396906793735721]
	TIME [epoch: 34.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215787504160679		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.7215787504160679 | validation: 0.7074119586483996]
	TIME [epoch: 34.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625637961347631		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.7625637961347631 | validation: 0.8303092824208014]
	TIME [epoch: 34.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253675598679238		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.8253675598679238 | validation: 1.3630133302666017]
	TIME [epoch: 34.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9839589489250009		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.9839589489250009 | validation: 0.6493962352461264]
	TIME [epoch: 34.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227500230337349		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.7227500230337349 | validation: 0.5361626962514707]
	TIME [epoch: 34.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738077612613771		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.6738077612613771 | validation: 0.8517184849353451]
	TIME [epoch: 34.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8383206584791825		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.8383206584791825 | validation: 0.6245116442804637]
	TIME [epoch: 34.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789245077138337		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.8789245077138337 | validation: 1.4385856185196206]
	TIME [epoch: 34.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1218520833055374		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 1.1218520833055374 | validation: 0.6712546098822351]
	TIME [epoch: 34.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977123449277958		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.6977123449277958 | validation: 0.987159924370431]
	TIME [epoch: 34.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9652997900192134		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.9652997900192134 | validation: 0.7363377028463147]
	TIME [epoch: 34.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373441934254622		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.7373441934254622 | validation: 0.5906025728960718]
	TIME [epoch: 34.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9395316463890855		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 1.9395316463890855 | validation: 1.6389678367281522]
	TIME [epoch: 34.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9612985503424514		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 1.9612985503424514 | validation: 0.5230939987118696]
	TIME [epoch: 34.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089307921893245		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.8089307921893245 | validation: 0.5693869787716681]
	TIME [epoch: 34.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741202731139041		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.741202731139041 | validation: 0.664487062160964]
	TIME [epoch: 34.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397479938702901		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 1.1397479938702901 | validation: 1.0476945131184188]
	TIME [epoch: 34.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9272536866991055		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.9272536866991055 | validation: 0.5914084897380627]
	TIME [epoch: 34.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6160480827222639		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.6160480827222639 | validation: 0.4956207395898009]
	TIME [epoch: 34.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091519987570723		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.6091519987570723 | validation: 0.6279207391564012]
	TIME [epoch: 34.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0379908528515198		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 1.0379908528515198 | validation: 0.7214779389595509]
	TIME [epoch: 34.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029239459371122		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 1.029239459371122 | validation: 0.619549229383672]
	TIME [epoch: 34.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232436016368476		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.7232436016368476 | validation: 0.8073843635695582]
	TIME [epoch: 34.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8004146881852945		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.8004146881852945 | validation: 0.868225732319495]
	TIME [epoch: 34.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370835509026246		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.7370835509026246 | validation: 0.6497040325433581]
	TIME [epoch: 34.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691038662361948		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.6691038662361948 | validation: 0.551297276199437]
	TIME [epoch: 34.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153388564712583		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.6153388564712583 | validation: 0.4730168027805207]
	TIME [epoch: 34.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954924769740707		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.6954924769740707 | validation: 0.6223844880259155]
	TIME [epoch: 34.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231466993572653		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.7231466993572653 | validation: 0.7117602586338426]
	TIME [epoch: 34.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275232822031138		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.8275232822031138 | validation: 0.6999593347765087]
	TIME [epoch: 34.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890400552670946		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.6890400552670946 | validation: 0.818745888788166]
	TIME [epoch: 34.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251695114051135		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.6251695114051135 | validation: 0.5051098128329018]
	TIME [epoch: 34.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6095203179957134		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.6095203179957134 | validation: 1.2854156777428278]
	TIME [epoch: 34.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530238614685		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.7530238614685 | validation: 0.5355480766536053]
	TIME [epoch: 34.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236767606292146		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.7236767606292146 | validation: 0.546578448632471]
	TIME [epoch: 34.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831940046540906		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.6831940046540906 | validation: 0.5921133577337312]
	TIME [epoch: 34.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393068610055894		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.7393068610055894 | validation: 0.5704215830093762]
	TIME [epoch: 34.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771816088660367		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.7771816088660367 | validation: 0.6240466080105003]
	TIME [epoch: 34.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259829644531105		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.7259829644531105 | validation: 0.5984603902690413]
	TIME [epoch: 34.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191465158193597		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.7191465158193597 | validation: 0.794458505021179]
	TIME [epoch: 34.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406998574132317		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.7406998574132317 | validation: 0.6397551937444714]
	TIME [epoch: 34.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6695135434397601		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.6695135434397601 | validation: 0.5077304551269972]
	TIME [epoch: 34.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564716887981661		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.7564716887981661 | validation: 0.7127421363614862]
	TIME [epoch: 34.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444800260660075		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.7444800260660075 | validation: 1.3717988794949068]
	TIME [epoch: 34.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.886181138819575		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.886181138819575 | validation: 0.503483844361664]
	TIME [epoch: 34.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6350005794472745		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.6350005794472745 | validation: 0.5382290516681403]
	TIME [epoch: 34.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6164399501331843		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.6164399501331843 | validation: 0.6071807796663207]
	TIME [epoch: 34.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7167817042228161		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.7167817042228161 | validation: 0.6247919411850316]
	TIME [epoch: 34.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359808847290932		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.7359808847290932 | validation: 0.6779250517103543]
	TIME [epoch: 34.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218952004061729		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.7218952004061729 | validation: 0.887689269241131]
	TIME [epoch: 34.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952409126652828		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.6952409126652828 | validation: 0.6116203039886603]
	TIME [epoch: 34.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955137948288336		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.6955137948288336 | validation: 0.68917104787498]
	TIME [epoch: 34.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5920190000462784		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.5920190000462784 | validation: 0.5891927665222332]
	TIME [epoch: 34.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304430239626035		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.7304430239626035 | validation: 0.6149657956249246]
	TIME [epoch: 34.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661880850782196		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.6661880850782196 | validation: 0.6358279725287022]
	TIME [epoch: 34.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310792401867274		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.7310792401867274 | validation: 0.7997530312683425]
	TIME [epoch: 34.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793671236962784		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.6793671236962784 | validation: 0.8897210105039329]
	TIME [epoch: 34.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406092575254101		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.7406092575254101 | validation: 0.7363529220786533]
	TIME [epoch: 34.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714044899926314		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.7714044899926314 | validation: 0.6752076897280149]
	TIME [epoch: 34.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312027200760288		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.6312027200760288 | validation: 0.7264755002044532]
	TIME [epoch: 34.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047450333235628		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.7047450333235628 | validation: 0.6209489030200256]
	TIME [epoch: 34.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396745977919823		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.6396745977919823 | validation: 0.6578648780776168]
	TIME [epoch: 34.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6434504345311214		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.6434504345311214 | validation: 0.640534648360662]
	TIME [epoch: 34.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8297521374565473		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.8297521374565473 | validation: 0.5010812259474529]
	TIME [epoch: 34.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6292504339106467		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.6292504339106467 | validation: 0.586940512356221]
	TIME [epoch: 34.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6595519385537066		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.6595519385537066 | validation: 1.1640585777923866]
	TIME [epoch: 34.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684147535345724		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.9684147535345724 | validation: 0.5263188461950266]
	TIME [epoch: 34.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7939943161276901		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.7939943161276901 | validation: 0.7010583128635111]
	TIME [epoch: 34.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358178093179881		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.7358178093179881 | validation: 0.5467255785757507]
	TIME [epoch: 34.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575039788966626		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.6575039788966626 | validation: 0.6532985201792312]
	TIME [epoch: 34.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580563273762253		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.7580563273762253 | validation: 0.4573092753975927]
	TIME [epoch: 34.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47194140577288957		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.47194140577288957 | validation: 0.849090310696796]
	TIME [epoch: 34.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818540903220954		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.6818540903220954 | validation: 0.8045515839589312]
	TIME [epoch: 34.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339749251685731		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.7339749251685731 | validation: 0.871953547789078]
	TIME [epoch: 34.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047943826857879		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.7047943826857879 | validation: 1.0744778373266355]
	TIME [epoch: 34.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7603216196708924		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.7603216196708924 | validation: 0.7756803408220223]
	TIME [epoch: 34.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217043424027624		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.8217043424027624 | validation: 0.7682458632856939]
	TIME [epoch: 34.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215186612825321		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.7215186612825321 | validation: 0.6621005337299981]
	TIME [epoch: 34.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1346947122406974		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 1.1346947122406974 | validation: 0.7083689973969249]
	TIME [epoch: 34.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805015290498835		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.6805015290498835 | validation: 0.6540430267310647]
	TIME [epoch: 34.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.877656753115356		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.877656753115356 | validation: 0.5817480270324749]
	TIME [epoch: 34.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621082750295328		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.621082750295328 | validation: 0.6637328577063144]
	TIME [epoch: 34.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861060014602209		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.6861060014602209 | validation: 0.5393499715557589]
	TIME [epoch: 34.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241905469068704		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.5241905469068704 | validation: 0.6627272381300544]
	TIME [epoch: 34.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006931885065928		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 1.006931885065928 | validation: 0.4981421858787588]
	TIME [epoch: 34.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542752807716464		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.7542752807716464 | validation: 0.5374862263636432]
	TIME [epoch: 34.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471676736229226		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.5471676736229226 | validation: 0.5413700357292148]
	TIME [epoch: 34.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604004600137541		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.604004600137541 | validation: 0.9444348834597094]
	TIME [epoch: 34.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140098641561754		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.7140098641561754 | validation: 0.4998138190740625]
	TIME [epoch: 34.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054538786261723		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.6054538786261723 | validation: 0.5043745544870126]
	TIME [epoch: 34.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784476091762983		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.6784476091762983 | validation: 0.6371112811276143]
	TIME [epoch: 34.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5902278536803628		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.5902278536803628 | validation: 0.565076575838001]
	TIME [epoch: 34.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693874576221349		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.693874576221349 | validation: 0.5559300689762783]
	TIME [epoch: 34.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887648696289002		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.5887648696289002 | validation: 0.4220445627145931]
	TIME [epoch: 34.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905340348920449		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.5905340348920449 | validation: 0.6008456546595099]
	TIME [epoch: 34.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723436179662777		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.6723436179662777 | validation: 0.6552633763152982]
	TIME [epoch: 34.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021069947182319		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.6021069947182319 | validation: 0.7421944259157007]
	TIME [epoch: 34.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6362255626067965		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.6362255626067965 | validation: 0.4893803176896707]
	TIME [epoch: 34.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061217416545541		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.6061217416545541 | validation: 0.6634327629610994]
	TIME [epoch: 34.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529040177074082		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.6529040177074082 | validation: 0.544373388838364]
	TIME [epoch: 34.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365573499323202		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.6365573499323202 | validation: 0.47818060702828974]
	TIME [epoch: 34.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259966778263522		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.6259966778263522 | validation: 0.4146724404868448]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000200090189998		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.6000200090189998 | validation: 1.2058322854205712]
	TIME [epoch: 34.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.780599791598455		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.780599791598455 | validation: 0.5880848311884994]
	TIME [epoch: 34.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5849670004707881		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.5849670004707881 | validation: 0.8602039949773688]
	TIME [epoch: 34.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965590792257489		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.5965590792257489 | validation: 0.7913187816531952]
	TIME [epoch: 34.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076970806151277		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.7076970806151277 | validation: 1.203837376487979]
	TIME [epoch: 34.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734224281735746		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.734224281735746 | validation: 0.5431184250745515]
	TIME [epoch: 34.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244770265108654		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.5244770265108654 | validation: 0.6278084484044179]
	TIME [epoch: 34.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994072353666757		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.5994072353666757 | validation: 0.522304685733783]
	TIME [epoch: 34.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5996846862279135		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.5996846862279135 | validation: 0.7836753457642784]
	TIME [epoch: 34.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865744398406308		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.6865744398406308 | validation: 0.5433216342711125]
	TIME [epoch: 34.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575018279851216		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.6575018279851216 | validation: 0.458079957584986]
	TIME [epoch: 34.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876539984388715		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.6876539984388715 | validation: 0.4879724392454907]
	TIME [epoch: 34.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757060091581102		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.5757060091581102 | validation: 0.46655514927051983]
	TIME [epoch: 34.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357252555021439		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.5357252555021439 | validation: 0.6765286206182584]
	TIME [epoch: 34.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285625481254883		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.7285625481254883 | validation: 0.7529001489903948]
	TIME [epoch: 34.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688328159057747		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.6688328159057747 | validation: 0.582916719167181]
	TIME [epoch: 34.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5985335825085386		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.5985335825085386 | validation: 0.6679092163782319]
	TIME [epoch: 34.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463557171905665		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.5463557171905665 | validation: 0.9482533673298176]
	TIME [epoch: 34.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648257770038975		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.7648257770038975 | validation: 0.5079894285533986]
	TIME [epoch: 34.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7462137195601144		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.7462137195601144 | validation: 0.7145528970821233]
	TIME [epoch: 34.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126362922149811		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.6126362922149811 | validation: 0.454233274044755]
	TIME [epoch: 34.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188147001137647		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.6188147001137647 | validation: 0.5500567959299776]
	TIME [epoch: 34.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264398568415867		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.5264398568415867 | validation: 0.7081451145389898]
	TIME [epoch: 34.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411089003177374		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.6411089003177374 | validation: 0.657527033344522]
	TIME [epoch: 34.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6339273969836879		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.6339273969836879 | validation: 0.6375259342723871]
	TIME [epoch: 34.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915761773026434		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.5915761773026434 | validation: 0.5873966707217604]
	TIME [epoch: 34.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769477192443457		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.5769477192443457 | validation: 0.5081554058054447]
	TIME [epoch: 34.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42621540597682284		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.42621540597682284 | validation: 0.7019813549975433]
	TIME [epoch: 34.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653759441028813		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.653759441028813 | validation: 0.6735861515225068]
	TIME [epoch: 34.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147631733877913		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.7147631733877913 | validation: 0.5025557011603508]
	TIME [epoch: 34.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710305627763255		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.5710305627763255 | validation: 0.7161792538061895]
	TIME [epoch: 34.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770272267425126		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.5770272267425126 | validation: 0.4557971980566278]
	TIME [epoch: 34.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8153458365559765		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.8153458365559765 | validation: 1.2440507153828946]
	TIME [epoch: 34.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8650360967958359		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.8650360967958359 | validation: 0.6213381646919094]
	TIME [epoch: 34.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6522345652831305		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.6522345652831305 | validation: 0.4417101516505745]
	TIME [epoch: 34.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306928967154014		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.6306928967154014 | validation: 0.36404458982261484]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112411913062907		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.6112411913062907 | validation: 0.6368140381358732]
	TIME [epoch: 34.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268850295127647		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.9268850295127647 | validation: 0.5174182556076843]
	TIME [epoch: 34.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574486334630892		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.6574486334630892 | validation: 0.7514254341144749]
	TIME [epoch: 34.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528893013743152		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.7528893013743152 | validation: 0.6604763550618877]
	TIME [epoch: 34.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900944617959087		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.5900944617959087 | validation: 0.5547936905332702]
	TIME [epoch: 34.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821512126743901		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.5821512126743901 | validation: 0.7360392954666325]
	TIME [epoch: 34.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564878018269243		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.7564878018269243 | validation: 0.7858850924879472]
	TIME [epoch: 34.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70552106098489		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.70552106098489 | validation: 0.6477336697146716]
	TIME [epoch: 34.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086473330709181		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.6086473330709181 | validation: 0.7848315825987273]
	TIME [epoch: 34.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5880588600759489		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.5880588600759489 | validation: 0.4998931170637553]
	TIME [epoch: 34.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49269794300722347		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.49269794300722347 | validation: 0.5212159595627557]
	TIME [epoch: 34.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876549495059201		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.6876549495059201 | validation: 0.8669167002832869]
	TIME [epoch: 34.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7855284250737677		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.7855284250737677 | validation: 0.5108150673505466]
	TIME [epoch: 34.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446163527324782		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.5446163527324782 | validation: 0.7168449992257302]
	TIME [epoch: 34.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118840603602684		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.6118840603602684 | validation: 0.5218029708897318]
	TIME [epoch: 34.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6686245321050022		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.6686245321050022 | validation: 0.6127540060987311]
	TIME [epoch: 34.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6928335206144067		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.6928335206144067 | validation: 0.6446308257992173]
	TIME [epoch: 34.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6193210189321403		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.6193210189321403 | validation: 0.8580921012421021]
	TIME [epoch: 34.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824675826790157		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.7824675826790157 | validation: 0.6552383898331684]
	TIME [epoch: 34.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517890486186868		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.6517890486186868 | validation: 0.7320270799571462]
	TIME [epoch: 34.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647391465799029		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.6647391465799029 | validation: 0.6119988155502107]
	TIME [epoch: 34.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792882633064998		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.792882633064998 | validation: 0.5486242153438997]
	TIME [epoch: 34.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7814237803272996		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.7814237803272996 | validation: 0.5800110139668726]
	TIME [epoch: 34.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815890321833962		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.6815890321833962 | validation: 0.7135244411184667]
	TIME [epoch: 34.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212773610466209		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.8212773610466209 | validation: 0.8917832853800509]
	TIME [epoch: 34.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3100855239542342		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 1.3100855239542342 | validation: 0.6824628176129629]
	TIME [epoch: 34.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.867287934975127		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.867287934975127 | validation: 0.5255871437361346]
	TIME [epoch: 34.3 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909110962872611		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.6909110962872611 | validation: 0.504389745181083]
	TIME [epoch: 34.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9158897938797073		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.9158897938797073 | validation: 0.5547437555797033]
	TIME [epoch: 34.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840653053093429		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.5840653053093429 | validation: 0.405270540631273]
	TIME [epoch: 34.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755958837267524		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.6755958837267524 | validation: 0.47162527823178313]
	TIME [epoch: 34.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697856415488008		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.6697856415488008 | validation: 0.54263689477127]
	TIME [epoch: 34.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119621999151315		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.7119621999151315 | validation: 0.4205233105553378]
	TIME [epoch: 34.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191581089020683		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.5191581089020683 | validation: 0.5930201536900745]
	TIME [epoch: 34.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6447959210285912		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.6447959210285912 | validation: 0.5129634657555202]
	TIME [epoch: 34.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.617571494455427		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.617571494455427 | validation: 0.512100679898981]
	TIME [epoch: 34.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555143800567251		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.555143800567251 | validation: 0.8480274177154337]
	TIME [epoch: 34.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071086637545635		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.7071086637545635 | validation: 0.82098024269134]
	TIME [epoch: 34.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817605085482246		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.6817605085482246 | validation: 0.4349036990421101]
	TIME [epoch: 34.3 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290222381786382		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.5290222381786382 | validation: 0.3613161067357743]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365976243246748		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.6365976243246748 | validation: 0.7553062543001625]
	TIME [epoch: 34.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405539791750007		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.8405539791750007 | validation: 0.36526340540519486]
	TIME [epoch: 34.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292044997927684		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.9292044997927684 | validation: 0.6976286332581731]
	TIME [epoch: 34.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6747883692007262		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.6747883692007262 | validation: 0.6004012659440179]
	TIME [epoch: 34.3 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348869779592722		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.6348869779592722 | validation: 0.5474378433171476]
	TIME [epoch: 34.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955192688282984		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.5955192688282984 | validation: 0.3913769447749323]
	TIME [epoch: 34.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222654342715792		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.5222654342715792 | validation: 0.49268427318206454]
	TIME [epoch: 34.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488648810188125		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.5488648810188125 | validation: 0.9031985521603898]
	TIME [epoch: 34.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347172135263338		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.6347172135263338 | validation: 0.9212592599881964]
	TIME [epoch: 34.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467755940981158		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.6467755940981158 | validation: 0.8475855926681197]
	TIME [epoch: 34.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8103327724104892		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.8103327724104892 | validation: 0.7406985950960661]
	TIME [epoch: 34.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478678667012837		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.5478678667012837 | validation: 0.6512939846407158]
	TIME [epoch: 34.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366515604796102		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.6366515604796102 | validation: 0.6804149136737869]
	TIME [epoch: 34.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979459113348673		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.6979459113348673 | validation: 0.4330773735194311]
	TIME [epoch: 34.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6169131883431951		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.6169131883431951 | validation: 0.556375647790502]
	TIME [epoch: 34.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5097694228315711		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.5097694228315711 | validation: 0.6079070773304023]
	TIME [epoch: 34.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013726494719642		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.6013726494719642 | validation: 0.5211001864630771]
	TIME [epoch: 34.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512068193499998		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.5512068193499998 | validation: 0.5645695048448913]
	TIME [epoch: 34.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992163899043241		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.5992163899043241 | validation: 0.5872558324357295]
	TIME [epoch: 34.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6036501759607553		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.6036501759607553 | validation: 0.43862955672347326]
	TIME [epoch: 34.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263935432957347		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.6263935432957347 | validation: 0.4567658744404573]
	TIME [epoch: 34.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574059103746638		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.5574059103746638 | validation: 0.8121766517250826]
	TIME [epoch: 34.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174382477107164		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.6174382477107164 | validation: 0.5852211828529662]
	TIME [epoch: 34.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.918660907417945		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.918660907417945 | validation: 0.9109642544348185]
	TIME [epoch: 34.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174909152125686		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.7174909152125686 | validation: 0.4939472115712959]
	TIME [epoch: 34.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065659140938297		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.5065659140938297 | validation: 0.4409992096541985]
	TIME [epoch: 34.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106202115796548		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.5106202115796548 | validation: 0.47347897088807867]
	TIME [epoch: 34.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056575191738334		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.6056575191738334 | validation: 0.44516888033289315]
	TIME [epoch: 34.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753019950760279		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.5753019950760279 | validation: 0.4210580159078702]
	TIME [epoch: 34.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135601407485667		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.5135601407485667 | validation: 0.660463376500104]
	TIME [epoch: 34.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184339284297516		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.5184339284297516 | validation: 0.6703270560756182]
	TIME [epoch: 34.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219708763464784		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.6219708763464784 | validation: 0.6700182354290647]
	TIME [epoch: 34.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259420848014474		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.6259420848014474 | validation: 0.4449439509826478]
	TIME [epoch: 34.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213967751244194		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.6213967751244194 | validation: 0.49961673695232045]
	TIME [epoch: 34.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553419091818526		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.553419091818526 | validation: 0.3882854909416723]
	TIME [epoch: 34.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271033524287088		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.5271033524287088 | validation: 0.5764111550095807]
	TIME [epoch: 34.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104133079572599		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.5104133079572599 | validation: 0.7040885179604633]
	TIME [epoch: 34.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154791891532173		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.6154791891532173 | validation: 0.7018398498587408]
	TIME [epoch: 34.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293553875552323		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.5293553875552323 | validation: 0.6047882713016046]
	TIME [epoch: 34.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983683428832667		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.5983683428832667 | validation: 0.5270635214752356]
	TIME [epoch: 34.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839055022395204		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.5839055022395204 | validation: 0.4750974177409411]
	TIME [epoch: 34.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140447999414014		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.6140447999414014 | validation: 0.5349096633473431]
	TIME [epoch: 34.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384205954738074		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.5384205954738074 | validation: 0.399692414267411]
	TIME [epoch: 34.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43119426314709053		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.43119426314709053 | validation: 0.6052430806249228]
	TIME [epoch: 34.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850901330958712		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.5850901330958712 | validation: 0.4568675675789452]
	TIME [epoch: 34.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6668008606274393		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.6668008606274393 | validation: 0.3007947515958562]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42751916582512595		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.42751916582512595 | validation: 0.4541725886204471]
	TIME [epoch: 34.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5275476876544125		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.5275476876544125 | validation: 0.7574571982103699]
	TIME [epoch: 34.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651407014311856		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.5651407014311856 | validation: 0.49849523489705816]
	TIME [epoch: 34.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529614318499156		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.5529614318499156 | validation: 0.33395332189717564]
	TIME [epoch: 34.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434092086298749		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.5434092086298749 | validation: 0.5864862174732841]
	TIME [epoch: 34.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48442330375882603		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.48442330375882603 | validation: 1.3034677239398351]
	TIME [epoch: 34.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048007677144288		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.6048007677144288 | validation: 0.6824901044038025]
	TIME [epoch: 34.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516939979389816		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.516939979389816 | validation: 0.496665225880106]
	TIME [epoch: 34.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330277036467062		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.5330277036467062 | validation: 0.38671452869326206]
	TIME [epoch: 34.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43508251963466593		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.43508251963466593 | validation: 0.6057095949380653]
	TIME [epoch: 34.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6036730042065648		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.6036730042065648 | validation: 0.695083287622859]
	TIME [epoch: 34.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470894066106611		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.5470894066106611 | validation: 0.7097259958826534]
	TIME [epoch: 34.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563685919482423		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.563685919482423 | validation: 0.4084526561084742]
	TIME [epoch: 34.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523020199062965		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.523020199062965 | validation: 0.4547224044026197]
	TIME [epoch: 34.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850870179340929		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.5850870179340929 | validation: 0.5504086845911214]
	TIME [epoch: 34.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45947661672252776		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.45947661672252776 | validation: 0.26999298920093195]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067261404056723		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.5067261404056723 | validation: 0.5241839476273276]
	TIME [epoch: 34.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231063397344324		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.6231063397344324 | validation: 0.371119969317175]
	TIME [epoch: 34.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48311135570851915		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.48311135570851915 | validation: 0.6052648184173046]
	TIME [epoch: 34.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5352310739384416		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.5352310739384416 | validation: 0.6404385335778554]
	TIME [epoch: 34.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301439124259331		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.5301439124259331 | validation: 0.36937047870406403]
	TIME [epoch: 34.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5728813160557674		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.5728813160557674 | validation: 0.5787091942851028]
	TIME [epoch: 34.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49309809357734047		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.49309809357734047 | validation: 0.5258519218571382]
	TIME [epoch: 34.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357241553091784		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.5357241553091784 | validation: 1.5759686679365972]
	TIME [epoch: 34.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8339729529457702		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.8339729529457702 | validation: 0.3437573707868372]
	TIME [epoch: 34.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267607979971929		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.4267607979971929 | validation: 0.42951809191224866]
	TIME [epoch: 34.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49550177763101116		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.49550177763101116 | validation: 0.46434225169040905]
	TIME [epoch: 34.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303271098883193		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.5303271098883193 | validation: 0.3211403669001821]
	TIME [epoch: 34.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48342093854674534		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.48342093854674534 | validation: 0.4090153380427544]
	TIME [epoch: 34.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163359455918148		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.5163359455918148 | validation: 0.4303036977047781]
	TIME [epoch: 34.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268957612429354		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.4268957612429354 | validation: 0.3498003901109059]
	TIME [epoch: 34.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331480506243472		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.5331480506243472 | validation: 0.44312105085949016]
	TIME [epoch: 34.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021351022917592		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.4021351022917592 | validation: 0.3346128522819384]
	TIME [epoch: 34.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758484897641525		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.5758484897641525 | validation: 0.48417518822135874]
	TIME [epoch: 34.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900602002172612		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.5900602002172612 | validation: 0.6903309276062048]
	TIME [epoch: 34.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4725787644300615		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.4725787644300615 | validation: 0.3437841181750039]
	TIME [epoch: 34.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42871197190074883		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.42871197190074883 | validation: 0.4629922129120919]
	TIME [epoch: 34.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48405749795380354		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.48405749795380354 | validation: 0.3771635363425242]
	TIME [epoch: 34.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5283183946293345		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.5283183946293345 | validation: 0.4670696807165896]
	TIME [epoch: 34.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48500379829551477		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.48500379829551477 | validation: 0.5975596347424947]
	TIME [epoch: 34.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49243141080796016		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.49243141080796016 | validation: 0.5676525641691945]
	TIME [epoch: 34.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38283160785226045		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.38283160785226045 | validation: 0.9267062644934922]
	TIME [epoch: 34.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7642721204817989		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.7642721204817989 | validation: 0.7655341473163916]
	TIME [epoch: 34.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818608531360295		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.5818608531360295 | validation: 0.33305753920288006]
	TIME [epoch: 34.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46864733889205695		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.46864733889205695 | validation: 0.48902047479507105]
	TIME [epoch: 34.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44951583249143634		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.44951583249143634 | validation: 0.666788107683839]
	TIME [epoch: 34.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849377701552735		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.4849377701552735 | validation: 0.5500539616487061]
	TIME [epoch: 34.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559908820218448		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.559908820218448 | validation: 0.345651887651023]
	TIME [epoch: 34.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42822610129446		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.42822610129446 | validation: 0.5927487116844108]
	TIME [epoch: 34.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061193622200418		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.6061193622200418 | validation: 0.30275454136786384]
	TIME [epoch: 34.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35207356763078157		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.35207356763078157 | validation: 0.421782503809735]
	TIME [epoch: 34.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905654002267784		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.4905654002267784 | validation: 0.34786966604671676]
	TIME [epoch: 34.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43601678230261876		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.43601678230261876 | validation: 0.5816126938444323]
	TIME [epoch: 34.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580511931633085		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.4580511931633085 | validation: 0.4184623268177029]
	TIME [epoch: 34.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4439562266151535		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.4439562266151535 | validation: 0.46471655164172115]
	TIME [epoch: 34.3 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44496052596082936		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.44496052596082936 | validation: 0.6180971733513021]
	TIME [epoch: 34.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220577201979164		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.5220577201979164 | validation: 0.3813823195200482]
	TIME [epoch: 34.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49507939721078875		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.49507939721078875 | validation: 0.35544134255381166]
	TIME [epoch: 34.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40567080979960757		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.40567080979960757 | validation: 0.4898402214096088]
	TIME [epoch: 34.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741246495431802		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.3741246495431802 | validation: 1.4536273583531476]
	TIME [epoch: 34.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629325855877396		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.629325855877396 | validation: 0.3025885629704098]
	TIME [epoch: 34.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4233158117994678		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.4233158117994678 | validation: 0.33485996044369293]
	TIME [epoch: 34.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4046527668400234		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.4046527668400234 | validation: 0.3275036598307923]
	TIME [epoch: 34.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686306160785998		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.3686306160785998 | validation: 0.5060902284049458]
	TIME [epoch: 34.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458964862285981		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.458964862285981 | validation: 0.3728839588295496]
	TIME [epoch: 34.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165914287557794		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.6165914287557794 | validation: 0.45616074058236933]
	TIME [epoch: 34.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4931478243023413		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.4931478243023413 | validation: 0.4305837514551786]
	TIME [epoch: 34.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314199671557241		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.4314199671557241 | validation: 0.4093689589025953]
	TIME [epoch: 34.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896137155590607		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.6896137155590607 | validation: 0.3884061754785314]
	TIME [epoch: 34.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29349104493063033		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.29349104493063033 | validation: 0.8142648516398454]
	TIME [epoch: 34.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606210678746903		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.5606210678746903 | validation: 0.4897636479530829]
	TIME [epoch: 34.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746415558952389		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.5746415558952389 | validation: 0.305108592295636]
	TIME [epoch: 34.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39454917973395853		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.39454917973395853 | validation: 0.27066783979015285]
	TIME [epoch: 34.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4242300372179485		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.4242300372179485 | validation: 0.37736413845326744]
	TIME [epoch: 34.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687209602041461		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.4687209602041461 | validation: 0.3635054433613742]
	TIME [epoch: 34.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026392506637718		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.5026392506637718 | validation: 0.33386286055041814]
	TIME [epoch: 34.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4197477622107784		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.4197477622107784 | validation: 0.3994819192885437]
	TIME [epoch: 34.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44277535652326094		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.44277535652326094 | validation: 0.4203129401299357]
	TIME [epoch: 34.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3865853710005135		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.3865853710005135 | validation: 0.47645245768757305]
	TIME [epoch: 34.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908758810779304		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.4908758810779304 | validation: 0.32213131668530937]
	TIME [epoch: 34.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44234531404387745		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.44234531404387745 | validation: 0.4978597642838426]
	TIME [epoch: 37.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42070872413244254		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.42070872413244254 | validation: 0.33738705149700376]
	TIME [epoch: 34.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484623696093867		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.484623696093867 | validation: 0.3154752218070367]
	TIME [epoch: 34.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213866241335796		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.4213866241335796 | validation: 0.38945066371837095]
	TIME [epoch: 34.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40014856580145347		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.40014856580145347 | validation: 0.39736476761437645]
	TIME [epoch: 34.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39368055737113505		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.39368055737113505 | validation: 0.42073918180712455]
	TIME [epoch: 34.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4160975284685267		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.4160975284685267 | validation: 0.3173953713019372]
	TIME [epoch: 34.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202917472901425		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.4202917472901425 | validation: 0.311415196236576]
	TIME [epoch: 34.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36521274967132056		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.36521274967132056 | validation: 0.3401640947139882]
	TIME [epoch: 34.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468564343279624		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.4468564343279624 | validation: 0.44147154820602375]
	TIME [epoch: 34.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36087469795696364		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.36087469795696364 | validation: 0.38979510771988846]
	TIME [epoch: 34.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45346135806091215		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.45346135806091215 | validation: 0.4494832172789967]
	TIME [epoch: 34.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533175559014641		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.4533175559014641 | validation: 0.4742797564249774]
	TIME [epoch: 34.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568488256394341		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.4568488256394341 | validation: 0.423330661393526]
	TIME [epoch: 34.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127125564183264		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.5127125564183264 | validation: 0.4928381659869842]
	TIME [epoch: 34.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617637248984801		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.5617637248984801 | validation: 0.43796090110782326]
	TIME [epoch: 34.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37430712142043326		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.37430712142043326 | validation: 0.45244860206895976]
	TIME [epoch: 34.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4682537239326383		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.4682537239326383 | validation: 0.3502621195193155]
	TIME [epoch: 34.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40865738230383225		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.40865738230383225 | validation: 0.4866930556167883]
	TIME [epoch: 34.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4655795598586387		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.4655795598586387 | validation: 0.33714246718392815]
	TIME [epoch: 34.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36825738400718705		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.36825738400718705 | validation: 1.0105928136891653]
	TIME [epoch: 34.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404073382911619		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.6404073382911619 | validation: 0.5863878124257328]
	TIME [epoch: 34.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634680715427827		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.4634680715427827 | validation: 0.38278038476622006]
	TIME [epoch: 34.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4810202845858174		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.4810202845858174 | validation: 0.26296109446051147]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_941.pth
	Model improved!!!
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911055797673914		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.3911055797673914 | validation: 0.40812255579873347]
	TIME [epoch: 34.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007244357624129		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.5007244357624129 | validation: 0.3675201110041858]
	TIME [epoch: 34.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4101870044725724		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.4101870044725724 | validation: 0.3358777422920963]
	TIME [epoch: 34.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45414221635239604		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.45414221635239604 | validation: 0.3790077804351707]
	TIME [epoch: 34.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41855843512970675		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.41855843512970675 | validation: 0.6431029639309427]
	TIME [epoch: 34.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41178743088115555		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.41178743088115555 | validation: 0.6949297629126296]
	TIME [epoch: 34.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404354436685819		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.4404354436685819 | validation: 0.7501069278976913]
	TIME [epoch: 34.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44446266087322694		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.44446266087322694 | validation: 0.3919900440066241]
	TIME [epoch: 34.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4406745737098612		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.4406745737098612 | validation: 0.3484404000542668]
	TIME [epoch: 34.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49746252396682844		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.49746252396682844 | validation: 0.31917049464191616]
	TIME [epoch: 34.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4799909912604664		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.4799909912604664 | validation: 0.35040120063067115]
	TIME [epoch: 34.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535377146917509		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.3535377146917509 | validation: 0.2538566384728931]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_953.pth
	Model improved!!!
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480203816858094		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.4480203816858094 | validation: 0.2217328598891653]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_954.pth
	Model improved!!!
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196823675338402		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.4196823675338402 | validation: 0.5007952427294545]
	TIME [epoch: 34.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326536753642161		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.4326536753642161 | validation: 0.44142627977274773]
	TIME [epoch: 34.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40446072613314843		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.40446072613314843 | validation: 0.27581613427737933]
	TIME [epoch: 34.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23197636068039498		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.23197636068039498 | validation: 0.39896516816788713]
	TIME [epoch: 34.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573944718190252		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.4573944718190252 | validation: 0.3076861579729663]
	TIME [epoch: 34.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624563057230222		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.3624563057230222 | validation: 0.2644345045044234]
	TIME [epoch: 34.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3099347039640912		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.3099347039640912 | validation: 0.4488249852432853]
	TIME [epoch: 34.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42514294632950356		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.42514294632950356 | validation: 0.3734892839893341]
	TIME [epoch: 34.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48811940058132586		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.48811940058132586 | validation: 0.3557688003265125]
	TIME [epoch: 34.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41210195678759665		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.41210195678759665 | validation: 0.36783551847544427]
	TIME [epoch: 34.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224554033049201		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.4224554033049201 | validation: 0.25197179036367146]
	TIME [epoch: 34.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4606653818670321		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.4606653818670321 | validation: 0.3937147567757515]
	TIME [epoch: 34.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229639426604648		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.3229639426604648 | validation: 0.3590895328456931]
	TIME [epoch: 34.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3965189105777229		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.3965189105777229 | validation: 0.3295124504054366]
	TIME [epoch: 34.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930742558257408		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.3930742558257408 | validation: 0.2855215786594853]
	TIME [epoch: 34.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33819972234805584		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.33819972234805584 | validation: 0.524905426482823]
	TIME [epoch: 34.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38808300723352074		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.38808300723352074 | validation: 0.28192124180920547]
	TIME [epoch: 34.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418420174112851		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.418420174112851 | validation: 0.4514948936402928]
	TIME [epoch: 34.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38658071864245247		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.38658071864245247 | validation: 0.32636635457162977]
	TIME [epoch: 34.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40446318700582473		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.40446318700582473 | validation: 0.3846916960625216]
	TIME [epoch: 34.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41447799701760835		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.41447799701760835 | validation: 0.2884536742531893]
	TIME [epoch: 34.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568969683137098		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.3568969683137098 | validation: 0.2839558318416606]
	TIME [epoch: 34.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435339178823096		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.3435339178823096 | validation: 0.4539801046967893]
	TIME [epoch: 34.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134738078909023		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.4134738078909023 | validation: 0.31484063949791796]
	TIME [epoch: 34.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435017778869893		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.4435017778869893 | validation: 0.376608619657973]
	TIME [epoch: 34.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40994653310179163		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.40994653310179163 | validation: 0.27050957337509013]
	TIME [epoch: 34.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36531961905579313		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.36531961905579313 | validation: 0.24613372993671578]
	TIME [epoch: 34.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35420684434944905		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.35420684434944905 | validation: 0.2508425937421199]
	TIME [epoch: 34.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30756410702434966		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.30756410702434966 | validation: 0.2946338094938633]
	TIME [epoch: 36.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121704307601223		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.4121704307601223 | validation: 0.43033975368654614]
	TIME [epoch: 35 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37694468243136703		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.37694468243136703 | validation: 0.42316798438631664]
	TIME [epoch: 34.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556328074037237		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.4556328074037237 | validation: 0.36842400656274066]
	TIME [epoch: 34.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34771379843134254		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.34771379843134254 | validation: 0.45587772349542544]
	TIME [epoch: 34.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45119538040097007		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.45119538040097007 | validation: 0.39171279836196576]
	TIME [epoch: 34.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36940693884403675		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.36940693884403675 | validation: 0.47335003162641975]
	TIME [epoch: 34.3 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34874091034320076		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.34874091034320076 | validation: 0.2683621132427656]
	TIME [epoch: 34.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397063033854872		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.3397063033854872 | validation: 0.2471463646471615]
	TIME [epoch: 34.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36283840416644064		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.36283840416644064 | validation: 0.37861569896875297]
	TIME [epoch: 34.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848611318062004		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.3848611318062004 | validation: 0.5454959091849544]
	TIME [epoch: 34.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300110775385051		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.4300110775385051 | validation: 0.27165212662792104]
	TIME [epoch: 34.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25358886800578917		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.25358886800578917 | validation: 0.49357730642135966]
	TIME [epoch: 34.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44119664508348116		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.44119664508348116 | validation: 0.38036099239376314]
	TIME [epoch: 34.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47434920496614297		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.47434920496614297 | validation: 0.33295836225153086]
	TIME [epoch: 34.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430468150855663		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.3430468150855663 | validation: 0.5769684540223147]
	TIME [epoch: 34.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955376989496727		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.3955376989496727 | validation: 0.1589648900491269]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32783898907159836		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.32783898907159836 | validation: 0.32855941031063574]
	TIME [epoch: 34.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38991952153642184		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.38991952153642184 | validation: 0.6310045337503413]
	TIME [epoch: 166 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4505258747781676		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.4505258747781676 | validation: 0.44796860518732917]
	TIME [epoch: 73.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202796907638779		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.4202796907638779 | validation: 0.6582020570323659]
	TIME [epoch: 73.4 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41242032402214995		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.41242032402214995 | validation: 0.20538739564069053]
	TIME [epoch: 73.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31717325227148996		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.31717325227148996 | validation: 0.190318377041028]
	TIME [epoch: 73.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35005410738016013		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.35005410738016013 | validation: 0.7001818294933517]
	TIME [epoch: 73.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44835545371697844		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.44835545371697844 | validation: 0.3206265767060694]
	TIME [epoch: 73.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26516110494609024		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.26516110494609024 | validation: 0.2985943091383776]
	TIME [epoch: 73.4 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33043758002722357		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.33043758002722357 | validation: 0.5212444310511495]
	TIME [epoch: 73.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484878082570912		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.5484878082570912 | validation: 0.3038521070875071]
	TIME [epoch: 73.4 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31376324884505136		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.31376324884505136 | validation: 0.42067355362421627]
	TIME [epoch: 73.4 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37164639931400106		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.37164639931400106 | validation: 0.2875050639527592]
	TIME [epoch: 73.4 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39753358585147075		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.39753358585147075 | validation: 0.435138250185766]
	TIME [epoch: 73.4 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38704765455809476		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.38704765455809476 | validation: 0.17777472064798358]
	TIME [epoch: 73.4 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933442968618566		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.3933442968618566 | validation: 0.36841301846049834]
	TIME [epoch: 73.4 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43378265933336013		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.43378265933336013 | validation: 0.27644764541786604]
	TIME [epoch: 73.4 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273117637365299		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.3273117637365299 | validation: 0.2666548244150467]
	TIME [epoch: 73.4 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303915100020933		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.3303915100020933 | validation: 0.32906060831649186]
	TIME [epoch: 73.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33823258072498574		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.33823258072498574 | validation: 0.22563256608542848]
	TIME [epoch: 73.4 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174912985153652		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.3174912985153652 | validation: 0.3492525015442134]
	TIME [epoch: 73.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3304759096417882		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.3304759096417882 | validation: 0.4068668209333489]
	TIME [epoch: 73.4 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263686143972909		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.4263686143972909 | validation: 0.23989546952639396]
	TIME [epoch: 73.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915583927759822		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.2915583927759822 | validation: 0.2866892153554188]
	TIME [epoch: 73.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39222848244579867		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.39222848244579867 | validation: 0.20673123073598523]
	TIME [epoch: 73.4 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24007177401970417		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.24007177401970417 | validation: 0.888761315294412]
	TIME [epoch: 73.4 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5092531088706029		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.5092531088706029 | validation: 0.30961928698833563]
	TIME [epoch: 73.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171903695440455		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.3171903695440455 | validation: 0.38606163528343773]
	TIME [epoch: 73.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3231407019636729		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.3231407019636729 | validation: 0.27554879042114033]
	TIME [epoch: 73.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34176779074309765		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.34176779074309765 | validation: 0.42292897961896236]
	TIME [epoch: 73.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994741694025412		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.2994741694025412 | validation: 0.3107606504575031]
	TIME [epoch: 73.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41788801130536496		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.41788801130536496 | validation: 0.36445585071512954]
	TIME [epoch: 73.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39238911876412996		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.39238911876412996 | validation: 0.33618701963905523]
	TIME [epoch: 73.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625932854448848		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.3625932854448848 | validation: 0.3983012189657549]
	TIME [epoch: 73.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4723708369930364		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.4723708369930364 | validation: 0.39279773005669477]
	TIME [epoch: 73.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36735617743358856		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.36735617743358856 | validation: 0.37742329237570094]
	TIME [epoch: 73.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3251993283338613		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.3251993283338613 | validation: 0.15629281798054187]
	TIME [epoch: 73.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28280532212869686		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.28280532212869686 | validation: 0.29891080439944306]
	TIME [epoch: 73.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333034924175567		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.333034924175567 | validation: 0.4589754487101094]
	TIME [epoch: 73.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958169983353956		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.3958169983353956 | validation: 0.2640242681638027]
	TIME [epoch: 73.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497624362125429		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.3497624362125429 | validation: 0.7260270839471299]
	TIME [epoch: 73.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37872530469603094		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.37872530469603094 | validation: 0.28604896600892493]
	TIME [epoch: 73.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424859383642449		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.3424859383642449 | validation: 0.30416427857304046]
	TIME [epoch: 73.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4280986723587962		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.4280986723587962 | validation: 0.2567585291308223]
	TIME [epoch: 73.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536500291493097		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.2536500291493097 | validation: 0.36848577728212417]
	TIME [epoch: 73.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976802266699083		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.3976802266699083 | validation: 0.3015324509002801]
	TIME [epoch: 73.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38883566210563647		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.38883566210563647 | validation: 0.2510382368886833]
	TIME [epoch: 73.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27980961391432646		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.27980961391432646 | validation: 0.5518733391881857]
	TIME [epoch: 73.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4233911787400495		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.4233911787400495 | validation: 0.4481489998574368]
	TIME [epoch: 73.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756642017042767		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.3756642017042767 | validation: 0.42440141078576576]
	TIME [epoch: 73.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42262587168848265		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.42262587168848265 | validation: 0.223319229239356]
	TIME [epoch: 73.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23368122210853692		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.23368122210853692 | validation: 0.2822693011360884]
	TIME [epoch: 73.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31659099743905017		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.31659099743905017 | validation: 0.23648170480897815]
	TIME [epoch: 73.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35226969195618896		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.35226969195618896 | validation: 0.29882611768660144]
	TIME [epoch: 73.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3608174650661589		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.3608174650661589 | validation: 0.2852145930544638]
	TIME [epoch: 73.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511696552618774		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.3511696552618774 | validation: 0.37078864734852346]
	TIME [epoch: 73.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889362850001851		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.2889362850001851 | validation: 0.19305770112358456]
	TIME [epoch: 73.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30597345282028243		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.30597345282028243 | validation: 0.2786743089127772]
	TIME [epoch: 73.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36002207449130974		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.36002207449130974 | validation: 0.3326615268631068]
	TIME [epoch: 73.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051280259878453		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.3051280259878453 | validation: 0.3523148902402772]
	TIME [epoch: 73.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28155951825892656		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.28155951825892656 | validation: 0.25052862513993623]
	TIME [epoch: 73.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35362861497310016		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.35362861497310016 | validation: 0.2414086143355565]
	TIME [epoch: 73.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34378566245569125		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.34378566245569125 | validation: 0.3159565914779153]
	TIME [epoch: 73.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460846449676528		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.3460846449676528 | validation: 0.30037588373300705]
	TIME [epoch: 73.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22623201377366953		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.22623201377366953 | validation: 0.44182740161867007]
	TIME [epoch: 73.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34094089189727295		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.34094089189727295 | validation: 0.630673383016812]
	TIME [epoch: 73.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47462968758541046		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.47462968758541046 | validation: 0.26892002853658137]
	TIME [epoch: 73.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23367893412852983		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.23367893412852983 | validation: 0.33205239042242385]
	TIME [epoch: 73.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35671726916277235		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.35671726916277235 | validation: 0.4177597228715555]
	TIME [epoch: 73.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32823730914593274		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.32823730914593274 | validation: 0.5496987472634631]
	TIME [epoch: 73.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229049041408569		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.3229049041408569 | validation: 0.21263624175519846]
	TIME [epoch: 73.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342620188935225		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.2342620188935225 | validation: 0.3058782744667393]
	TIME [epoch: 73.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31521697324708486		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.31521697324708486 | validation: 0.3106288687196364]
	TIME [epoch: 73.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30445135658411804		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.30445135658411804 | validation: 0.4191266305291147]
	TIME [epoch: 73.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973013587514598		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.3973013587514598 | validation: 0.292914419834383]
	TIME [epoch: 73.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667069155600155		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.4667069155600155 | validation: 0.3505637946507532]
	TIME [epoch: 73.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33119059093138903		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.33119059093138903 | validation: 0.463286248370619]
	TIME [epoch: 73.4 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2717725569858698		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.2717725569858698 | validation: 0.1963734504588908]
	TIME [epoch: 73.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32280290995784466		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.32280290995784466 | validation: 0.2777799574754318]
	TIME [epoch: 73.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38593148959123535		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.38593148959123535 | validation: 0.3026155301749064]
	TIME [epoch: 73.4 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3111187190986505		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.3111187190986505 | validation: 0.3697907981814266]
	TIME [epoch: 73.4 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650891252028793		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.3650891252028793 | validation: 0.38525208329792715]
	TIME [epoch: 73.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804509665280147		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.3804509665280147 | validation: 0.2271740377072719]
	TIME [epoch: 73.4 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662802667839484		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.3662802667839484 | validation: 0.15437553991512087]
	TIME [epoch: 73.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1083.pth
	Model improved!!!
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28554116576231703		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.28554116576231703 | validation: 0.21877607104890276]
	TIME [epoch: 73.4 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27025574182459017		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.27025574182459017 | validation: 0.18754990854522138]
	TIME [epoch: 73.4 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202110444539134		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.3202110444539134 | validation: 0.2847971489488351]
	TIME [epoch: 73.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282004153004254		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.3282004153004254 | validation: 0.3213672729871364]
	TIME [epoch: 73.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43438570145403343		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.43438570145403343 | validation: 0.1888535052600696]
	TIME [epoch: 73.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651380422737873		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.2651380422737873 | validation: 0.15606591701810496]
	TIME [epoch: 73.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30517811885555457		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.30517811885555457 | validation: 0.2265779565853826]
	TIME [epoch: 73.4 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379270592895897		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.3379270592895897 | validation: 0.45234007628333567]
	TIME [epoch: 73.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31043028649683		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.31043028649683 | validation: 0.3979845146054833]
	TIME [epoch: 73.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44807251088334255		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.44807251088334255 | validation: 0.38050797593710217]
	TIME [epoch: 73.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708901631691478		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.3708901631691478 | validation: 0.3476494082775309]
	TIME [epoch: 73.4 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3248330052460521		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.3248330052460521 | validation: 0.2292257789463611]
	TIME [epoch: 73.4 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29683060040852804		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.29683060040852804 | validation: 0.32763272704219093]
	TIME [epoch: 73.4 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133917525657057		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.3133917525657057 | validation: 0.2808317752417645]
	TIME [epoch: 73.4 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29285559269126304		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.29285559269126304 | validation: 0.3163869795444699]
	TIME [epoch: 73.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396315430139317		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.3396315430139317 | validation: 0.21856883984527514]
	TIME [epoch: 73.4 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371237225391879		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.371237225391879 | validation: 0.2730500600465049]
	TIME [epoch: 73.4 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28852326395425526		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.28852326395425526 | validation: 0.22258963458672026]
	TIME [epoch: 73.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27464580096245367		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.27464580096245367 | validation: 0.3476594843860016]
	TIME [epoch: 73.4 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685795600151023		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.3685795600151023 | validation: 0.21278745499400428]
	TIME [epoch: 73.4 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25263413011422753		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.25263413011422753 | validation: 0.33169213308695317]
	TIME [epoch: 73.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612719270802311		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.3612719270802311 | validation: 0.18214255743008367]
	TIME [epoch: 73.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25556326452150474		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.25556326452150474 | validation: 0.2538188755077391]
	TIME [epoch: 73.4 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392524934959147		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.2392524934959147 | validation: 0.38033152799270653]
	TIME [epoch: 73.4 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902947220987843		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.2902947220987843 | validation: 0.5087631157098089]
	TIME [epoch: 73.4 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33177774183693903		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.33177774183693903 | validation: 0.17593500004361715]
	TIME [epoch: 73.4 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2654718927867268		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.2654718927867268 | validation: 0.31624288705406667]
	TIME [epoch: 73.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253645052377932		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.3253645052377932 | validation: 0.22649968476588866]
	TIME [epoch: 73.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24256923024701965		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.24256923024701965 | validation: 0.38992004815063974]
	TIME [epoch: 73.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3216907086374432		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.3216907086374432 | validation: 0.2023985129809207]
	TIME [epoch: 73.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639694720220308		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.2639694720220308 | validation: 0.22832696563087695]
	TIME [epoch: 73.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918884870222088		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.2918884870222088 | validation: 0.18197449167975654]
	TIME [epoch: 73.4 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23474436954702876		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.23474436954702876 | validation: 0.24099435068536476]
	TIME [epoch: 73.4 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577368009087383		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.2577368009087383 | validation: 0.24133371954808136]
	TIME [epoch: 73.4 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875936085028301		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.2875936085028301 | validation: 0.19509455935123818]
	TIME [epoch: 73.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908098302504101		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.1908098302504101 | validation: 0.5690109233208114]
	TIME [epoch: 73.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23334227909956506		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.23334227909956506 | validation: 0.3833280735049645]
	TIME [epoch: 73.4 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840614665440055		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.3840614665440055 | validation: 0.35567618397029277]
	TIME [epoch: 73.4 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45921206423349303		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.45921206423349303 | validation: 0.44604918052021053]
	TIME [epoch: 73.4 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3268403932065354		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.3268403932065354 | validation: 0.3565518005062053]
	TIME [epoch: 73.4 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650053374183638		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.2650053374183638 | validation: 0.4160992997275187]
	TIME [epoch: 73.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30809992584513657		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.30809992584513657 | validation: 0.24842539635354352]
	TIME [epoch: 73.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33744213517739624		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.33744213517739624 | validation: 0.2977871429584621]
	TIME [epoch: 73.4 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037608796448403		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.3037608796448403 | validation: 0.2888995863133661]
	TIME [epoch: 73.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24825953301822978		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.24825953301822978 | validation: 0.24904946281068746]
	TIME [epoch: 73.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828226067794281		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.2828226067794281 | validation: 0.34152851837009707]
	TIME [epoch: 73.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006874209342332		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.3006874209342332 | validation: 0.189236757508225]
	TIME [epoch: 73.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393878376942218		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.2393878376942218 | validation: 0.2846743115644685]
	TIME [epoch: 73.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071199941246141		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.3071199941246141 | validation: 0.25371130551059184]
	TIME [epoch: 73.4 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596730279228476		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.2596730279228476 | validation: 0.18710276792683053]
	TIME [epoch: 73.4 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22333384181595217		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.22333384181595217 | validation: 0.2508274601534891]
	TIME [epoch: 73.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795207400682444		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.2795207400682444 | validation: 0.17562650729570117]
	TIME [epoch: 73.4 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20694805275423203		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.20694805275423203 | validation: 0.19749765202876973]
	TIME [epoch: 73.4 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351553387603351		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.351553387603351 | validation: 0.2880177451033856]
	TIME [epoch: 73.4 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27855010423321314		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.27855010423321314 | validation: 0.18666872699395895]
	TIME [epoch: 73.4 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26536167168006014		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.26536167168006014 | validation: 0.19615529452011976]
	TIME [epoch: 73.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20174643477304194		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.20174643477304194 | validation: 0.3851854993331348]
	TIME [epoch: 73.4 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28497616162596995		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.28497616162596995 | validation: 0.19301893181678886]
	TIME [epoch: 73.4 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467013872279255		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.2467013872279255 | validation: 0.297271790755923]
	TIME [epoch: 73.4 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2991429461831243		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.2991429461831243 | validation: 0.27087343750238935]
	TIME [epoch: 73.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23590478295061973		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.23590478295061973 | validation: 0.309330592301884]
	TIME [epoch: 73.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27761051074722043		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.27761051074722043 | validation: 0.277817754776515]
	TIME [epoch: 73.4 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26796328232417804		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.26796328232417804 | validation: 0.20800014417515308]
	TIME [epoch: 73.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3154165972233809		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.3154165972233809 | validation: 0.1858227268751352]
	TIME [epoch: 73.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018549768157134		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.23018549768157134 | validation: 0.14610370609554735]
	TIME [epoch: 73.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1148.pth
	Model improved!!!
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26616129211370826		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.26616129211370826 | validation: 0.17943548936246562]
	TIME [epoch: 73.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16200452051819358		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.16200452051819358 | validation: 0.26033480470827475]
	TIME [epoch: 73.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25170836442337247		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.25170836442337247 | validation: 0.22300995970176557]
	TIME [epoch: 73.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539976976270573		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.2539976976270573 | validation: 0.24247439256357167]
	TIME [epoch: 73.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2445841947711787		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.2445841947711787 | validation: 0.36733917638217084]
	TIME [epoch: 73.4 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22157580249877365		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.22157580249877365 | validation: 0.10609635324230968]
	TIME [epoch: 73.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1154.pth
	Model improved!!!
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1877503557457802		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.1877503557457802 | validation: 0.1746591497632141]
	TIME [epoch: 73.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529450856869335		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.2529450856869335 | validation: 0.1709890096986007]
	TIME [epoch: 73.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2489539351036978		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.2489539351036978 | validation: 0.2484158505755425]
	TIME [epoch: 73.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23718003761377154		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.23718003761377154 | validation: 0.17558553941184463]
	TIME [epoch: 73.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.232754615136324		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.232754615136324 | validation: 0.2668603320323793]
	TIME [epoch: 73.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27688121355019635		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.27688121355019635 | validation: 0.23371924030943597]
	TIME [epoch: 73.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27022210724364765		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.27022210724364765 | validation: 0.23550411442073987]
	TIME [epoch: 73.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21676030626726797		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.21676030626726797 | validation: 0.4954298553501427]
	TIME [epoch: 73.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337843018142118		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.3337843018142118 | validation: 0.17800731273637793]
	TIME [epoch: 73.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503992015233676		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.2503992015233676 | validation: 0.31291599998863184]
	TIME [epoch: 73.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651452204153465		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.2651452204153465 | validation: 0.1765131056924148]
	TIME [epoch: 73.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19839671723634666		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.19839671723634666 | validation: 0.5021011744351225]
	TIME [epoch: 73.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30330975173775554		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.30330975173775554 | validation: 0.14514893063075246]
	TIME [epoch: 73.4 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24196628526315436		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.24196628526315436 | validation: 0.17028974763370539]
	TIME [epoch: 73.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21860785907152944		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.21860785907152944 | validation: 0.2901720792755026]
	TIME [epoch: 73.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982358290010659		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.2982358290010659 | validation: 0.44970234174572987]
	TIME [epoch: 73.3 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533672661870909		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.2533672661870909 | validation: 0.4553867925265289]
	TIME [epoch: 73.3 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29769594923650555		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.29769594923650555 | validation: 0.24636689092252909]
	TIME [epoch: 73.3 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24985553995071313		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.24985553995071313 | validation: 0.15527101646272623]
	TIME [epoch: 73.3 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26881768915310356		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.26881768915310356 | validation: 0.2491429363736654]
	TIME [epoch: 73.3 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593014318638744		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.20593014318638744 | validation: 0.16651015395562271]
	TIME [epoch: 73.4 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20014818396778655		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.20014818396778655 | validation: 0.20272382891609322]
	TIME [epoch: 73.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15150558321926083		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.15150558321926083 | validation: 0.16522644215985502]
	TIME [epoch: 73.4 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776291497311837		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.2776291497311837 | validation: 0.19392730064637909]
	TIME [epoch: 73.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17975006251094827		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.17975006251094827 | validation: 0.3749799485201537]
	TIME [epoch: 73.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098910642725775		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.3098910642725775 | validation: 0.2462739200998325]
	TIME [epoch: 73.4 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22868833372180628		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.22868833372180628 | validation: 0.2388803075711845]
	TIME [epoch: 73.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227430722507107		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.2227430722507107 | validation: 0.17807348819607624]
	TIME [epoch: 73.4 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2276799523493443		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.2276799523493443 | validation: 0.26861675302607463]
	TIME [epoch: 73.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22411778210666913		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.22411778210666913 | validation: 0.3460524743909051]
	TIME [epoch: 73.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191080798024565		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.191080798024565 | validation: 0.1963496680882387]
	TIME [epoch: 73.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321617874292197		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.2321617874292197 | validation: 0.2168108130526485]
	TIME [epoch: 73.4 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22968774724676472		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.22968774724676472 | validation: 0.15792560080286566]
	TIME [epoch: 73.4 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843512380026652		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.1843512380026652 | validation: 0.13936312183061145]
	TIME [epoch: 73.4 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15680490324454704		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.15680490324454704 | validation: 0.39459362288403466]
	TIME [epoch: 73.4 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272079131957129		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.272079131957129 | validation: 0.28180816011445764]
	TIME [epoch: 73.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2014015714797366		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.2014015714797366 | validation: 0.25723182806422223]
	TIME [epoch: 73.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19622280021078253		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.19622280021078253 | validation: 0.3968381350766439]
	TIME [epoch: 73.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861212048111239		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.2861212048111239 | validation: 0.28708355395784]
	TIME [epoch: 73.4 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24735915519380908		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.24735915519380908 | validation: 0.23733628988985123]
	TIME [epoch: 73.4 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28598448605608606		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.28598448605608606 | validation: 0.17903393153816738]
	TIME [epoch: 73.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19004240914147047		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.19004240914147047 | validation: 0.21119040168451525]
	TIME [epoch: 73.4 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2495178238497647		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.2495178238497647 | validation: 0.15142415248654198]
	TIME [epoch: 73.4 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21717536110151073		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.21717536110151073 | validation: 0.16865139545391716]
	TIME [epoch: 73.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19965696559961404		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.19965696559961404 | validation: 0.21469592407037358]
	TIME [epoch: 73.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1533376313381446		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.1533376313381446 | validation: 0.5081406260936443]
	TIME [epoch: 73.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28956109404929475		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.28956109404929475 | validation: 0.261719589983388]
	TIME [epoch: 73.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21842315950111785		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.21842315950111785 | validation: 0.26069805609206853]
	TIME [epoch: 73.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16382956257410364		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.16382956257410364 | validation: 0.16791435392593274]
	TIME [epoch: 73.4 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2341951061138784		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.2341951061138784 | validation: 0.18563954660745954]
	TIME [epoch: 73.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24053210541928072		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.24053210541928072 | validation: 0.14020217452172248]
	TIME [epoch: 73.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278196765242996		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.15278196765242996 | validation: 0.34027352013376533]
	TIME [epoch: 73.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2715109449067139		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.2715109449067139 | validation: 0.23995680729387608]
	TIME [epoch: 73.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2299131630612691		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.2299131630612691 | validation: 0.12509778603540636]
	TIME [epoch: 73.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19145561267811495		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.19145561267811495 | validation: 0.22773837800621577]
	TIME [epoch: 73.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24001563571735146		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.24001563571735146 | validation: 0.26580531460071904]
	TIME [epoch: 73.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16966704446568856		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.16966704446568856 | validation: 0.2201457217877763]
	TIME [epoch: 73.4 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381985268678749		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.2381985268678749 | validation: 0.2071066469492599]
	TIME [epoch: 73.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23751394834912226		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.23751394834912226 | validation: 0.2335858664009952]
	TIME [epoch: 73.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23568202679187777		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.23568202679187777 | validation: 0.11064780156838647]
	TIME [epoch: 73.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758150618192859		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.1758150618192859 | validation: 0.13837317486706688]
	TIME [epoch: 73.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600688269396965		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.19600688269396965 | validation: 0.13165592313843974]
	TIME [epoch: 73.4 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18708857887678934		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.18708857887678934 | validation: 0.15989827509973792]
	TIME [epoch: 73.4 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689373451651459		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.2689373451651459 | validation: 0.19440414592325295]
	TIME [epoch: 73.4 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21521537865198367		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.21521537865198367 | validation: 0.18484406391857022]
	TIME [epoch: 73.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103716519921517		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.2103716519921517 | validation: 0.3424320827668065]
	TIME [epoch: 73.4 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22717655342963478		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.22717655342963478 | validation: 0.17751460974251143]
	TIME [epoch: 73.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509903423647941		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.2509903423647941 | validation: 0.14548886712753814]
	TIME [epoch: 73.4 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23127047377599985		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.23127047377599985 | validation: 0.1418134886009704]
	TIME [epoch: 73.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2081859282537744		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.2081859282537744 | validation: 0.20088249500393277]
	TIME [epoch: 73.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743826126283511		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.1743826126283511 | validation: 0.21173719624546014]
	TIME [epoch: 73.3 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26879377728796106		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.26879377728796106 | validation: 0.26700190010393254]
	TIME [epoch: 73.4 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20143653123529442		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.20143653123529442 | validation: 0.22407311629354004]
	TIME [epoch: 73.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690795538541703		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.2690795538541703 | validation: 0.14751003853221184]
	TIME [epoch: 73.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15824910801554173		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.15824910801554173 | validation: 0.19791636408773278]
	TIME [epoch: 73.4 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16606598656246604		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.16606598656246604 | validation: 0.14072002935964167]
	TIME [epoch: 73.3 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631945999213097		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.1631945999213097 | validation: 0.3823012826153921]
	TIME [epoch: 73.4 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23113642607777624		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.23113642607777624 | validation: 0.15223365260253513]
	TIME [epoch: 73.2 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271662861677144		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.16271662861677144 | validation: 0.22322305716631163]
	TIME [epoch: 72.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17622794346664		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.17622794346664 | validation: 0.15142134868696025]
	TIME [epoch: 73 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17305090444123095		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.17305090444123095 | validation: 0.1592218980080139]
	TIME [epoch: 73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583726574513815		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.2583726574513815 | validation: 0.1885011761971042]
	TIME [epoch: 72.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17691298538323225		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.17691298538323225 | validation: 0.14723786165757788]
	TIME [epoch: 73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22196344483619085		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.22196344483619085 | validation: 0.0958363928113012]
	TIME [epoch: 73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl4_20240705_054948/states/model_phi1_1a_v_kl4_1238.pth
	Model improved!!!
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18736323601627197		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.18736323601627197 | validation: 0.14230480197437195]
	TIME [epoch: 72.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16485638086750332		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.16485638086750332 | validation: 0.25567123820811777]
	TIME [epoch: 72.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20932239303369243		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.20932239303369243 | validation: 0.19547926054443912]
	TIME [epoch: 72.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16181247362458806		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.16181247362458806 | validation: 0.17536803562543768]
	TIME [epoch: 72.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216787169084862		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.216787169084862 | validation: 0.3366344652013202]
	TIME [epoch: 72.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20218449664105614		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.20218449664105614 | validation: 0.2738341279100618]
	TIME [epoch: 72.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19906171740318468		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.19906171740318468 | validation: 0.2567351091683123]
	TIME [epoch: 72.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17594215780966546		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.17594215780966546 | validation: 0.17947913925931303]
	TIME [epoch: 72.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20899940025293096		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.20899940025293096 | validation: 0.2184356873091234]
	TIME [epoch: 72.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1656312296698453		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.1656312296698453 | validation: 0.1933582429765963]
	TIME [epoch: 72.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2034771184323138		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.2034771184323138 | validation: 0.16681792220973635]
	TIME [epoch: 72.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19546931543946755		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.19546931543946755 | validation: 0.19071833336199007]
	TIME [epoch: 72.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18987925984338674		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.18987925984338674 | validation: 0.13512039411803653]
	TIME [epoch: 72.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13513256344893998		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.13513256344893998 | validation: 0.15212566057036586]
	TIME [epoch: 72.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18250126923967913		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.18250126923967913 | validation: 0.3105293714685436]
	TIME [epoch: 72.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19972614560589758		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.19972614560589758 | validation: 0.14223292603935955]
	TIME [epoch: 72.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16351393517189683		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.16351393517189683 | validation: 0.19983978134962263]
	TIME [epoch: 72.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16012239711524856		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.16012239711524856 | validation: 0.23141156885833603]
	TIME [epoch: 73 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22161818105553946		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.22161818105553946 | validation: 0.21637126280193192]
	TIME [epoch: 72.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191376037652955		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.191376037652955 | validation: 0.18634026799914072]
	TIME [epoch: 73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15277158165977447		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.15277158165977447 | validation: 0.18197898181007185]
	TIME [epoch: 72.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15926759577775537		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.15926759577775537 | validation: 0.37460762789023483]
	TIME [epoch: 72.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23921345464758784		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.23921345464758784 | validation: 0.21985111316526068]
	TIME [epoch: 72.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036070678678432		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.15036070678678432 | validation: 0.2645263200256819]
	TIME [epoch: 72.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18833581377864406		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.18833581377864406 | validation: 0.12437537298956991]
	TIME [epoch: 72.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15373872264783295		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.15373872264783295 | validation: 0.1396830669806915]
	TIME [epoch: 73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279554937128204		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.16279554937128204 | validation: 0.21834643261981446]
	TIME [epoch: 72.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22044300208019302		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.22044300208019302 | validation: 0.14539222702955978]
	TIME [epoch: 72.9 sec]
EPOCH 1267/2000:
	Training over batches...
