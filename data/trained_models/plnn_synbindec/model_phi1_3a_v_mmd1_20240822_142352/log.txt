Args:
Namespace(name='model_phi1_3a_v_mmd1', outdir='out/model_training/model_phi1_3a_v_mmd1', training_data='data/training_data/data_phi1_3a/training', validation_data='data/training_data/data_phi1_3a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3201148004

Training model...

Saving initial model state to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.227394932152313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.227394932152313 | validation: 3.969283543147565]
	TIME [epoch: 28.3 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.93920126743676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.93920126743676 | validation: 3.7452149424016214]
	TIME [epoch: 0.88 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.76375463785614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.76375463785614 | validation: 3.6884710648054053]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.780419725917508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.780419725917508 | validation: 4.296824496645075]
	TIME [epoch: 0.873 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.365768702549342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.365768702549342 | validation: 3.545970225038209]
	TIME [epoch: 0.868 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.747190580257029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.747190580257029 | validation: 3.229061530508025]
	TIME [epoch: 0.872 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.328422064410562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.328422064410562 | validation: 3.228200697837842]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.290017670512164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.290017670512164 | validation: 2.9122966459906054]
	TIME [epoch: 0.873 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.0351203977419186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0351203977419186 | validation: 2.560076791452729]
	TIME [epoch: 0.872 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.567869118273725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.567869118273725 | validation: 3.36231431861563]
	TIME [epoch: 0.87 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9794811173255096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9794811173255096 | validation: 2.7534904445146284]
	TIME [epoch: 0.869 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.308420152620755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.308420152620755 | validation: 2.3211332617879115]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.350173610276413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.350173610276413 | validation: 2.0106123355397223]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.416371358957871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.416371358957871 | validation: 2.1550711385593244]
	TIME [epoch: 2.11 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2211149455027455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2211149455027455 | validation: 1.9197881413656583]
	TIME [epoch: 0.868 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.049833634905842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.049833634905842 | validation: 2.3529853603721214]
	TIME [epoch: 0.87 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0773267081348847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0773267081348847 | validation: 1.7403358638212283]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3203700488653816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3203700488653816 | validation: 2.0821232692696308]
	TIME [epoch: 0.871 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9558808839335426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9558808839335426 | validation: 1.6250355991009524]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.744001356572519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.744001356572519 | validation: 1.4872156122804068]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6485824138965262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6485824138965262 | validation: 1.3617343277839424]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5919299569586747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5919299569586747 | validation: 1.4670981337579476]
	TIME [epoch: 0.871 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5206183077002977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5206183077002977 | validation: 1.3448269433280589]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4535487401354212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4535487401354212 | validation: 1.6369097052576838]
	TIME [epoch: 0.87 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3794090964749506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3794090964749506 | validation: 1.1605625505214812]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5416687258774115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5416687258774115 | validation: 2.4614362550924107]
	TIME [epoch: 0.873 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0206524127649224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0206524127649224 | validation: 1.2684963659727522]
	TIME [epoch: 0.868 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5510633140805135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5510633140805135 | validation: 1.310048647905934]
	TIME [epoch: 0.876 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2260695930545802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2260695930545802 | validation: 1.7012634542353133]
	TIME [epoch: 0.884 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.45730900695771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.45730900695771 | validation: 1.108304052464164]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.318410684773451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.318410684773451 | validation: 1.308653080296823]
	TIME [epoch: 0.874 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1536813443197926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1536813443197926 | validation: 1.5252723498469525]
	TIME [epoch: 0.87 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2121451215206234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2121451215206234 | validation: 1.2234626837313247]
	TIME [epoch: 0.87 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1091879813331633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1091879813331633 | validation: 1.3087959423393654]
	TIME [epoch: 0.869 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0521940187836754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0521940187836754 | validation: 1.27008142619368]
	TIME [epoch: 0.87 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.040359595091568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.040359595091568 | validation: 1.2385430765003371]
	TIME [epoch: 0.869 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0418444927648434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0418444927648434 | validation: 1.2714422255753501]
	TIME [epoch: 0.869 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0696143125497277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0696143125497277 | validation: 1.188600635924486]
	TIME [epoch: 0.87 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0953422229241172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0953422229241172 | validation: 1.2546514960952708]
	TIME [epoch: 0.87 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0711876216288976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0711876216288976 | validation: 1.1959637090764819]
	TIME [epoch: 0.871 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.025854742277999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.025854742277999 | validation: 1.2000685883398727]
	TIME [epoch: 0.869 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9898658397072865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9898658397072865 | validation: 1.15860873033512]
	TIME [epoch: 0.87 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9855243355167395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9855243355167395 | validation: 1.174660002889518]
	TIME [epoch: 0.869 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9926664831749173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9926664831749173 | validation: 1.1396687170695692]
	TIME [epoch: 0.871 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0243781322761507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0243781322761507 | validation: 1.2237145590620537]
	TIME [epoch: 0.87 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0845772345138551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0845772345138551 | validation: 1.1993769236340899]
	TIME [epoch: 0.872 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1312849463083428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1312849463083428 | validation: 1.1995946564084927]
	TIME [epoch: 0.87 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0283076089575298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0283076089575298 | validation: 1.146734187055447]
	TIME [epoch: 0.871 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0162270658084598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0162270658084598 | validation: 1.1127036116174638]
	TIME [epoch: 0.872 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9750905908063314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9750905908063314 | validation: 1.0845359388936753]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9364237697791075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9364237697791075 | validation: 1.0806810885176086]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9198023949537995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9198023949537995 | validation: 1.0605120901808165]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9096493135462305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9096493135462305 | validation: 1.056345570491194]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9116663380585172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9116663380585172 | validation: 1.0236420421776158]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8999973283454592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8999973283454592 | validation: 1.041182139350634]
	TIME [epoch: 0.87 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8916665626867751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8916665626867751 | validation: 1.0095230096508703]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8909863231361219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8909863231361219 | validation: 1.0081329710502644]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9056471900503948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9056471900503948 | validation: 1.0906847904423913]
	TIME [epoch: 0.872 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0261245841630389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0261245841630389 | validation: 1.2228942802200486]
	TIME [epoch: 0.871 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1216337772221303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1216337772221303 | validation: 1.0985625008158841]
	TIME [epoch: 0.871 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0197408589731338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0197408589731338 | validation: 0.9972277706630788]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8770554015751776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8770554015751776 | validation: 0.979549121596686]
	TIME [epoch: 0.89 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9475907067330585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9475907067330585 | validation: 1.0372688250464766]
	TIME [epoch: 0.872 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9581050524712198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9581050524712198 | validation: 1.049269764692739]
	TIME [epoch: 0.874 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9386998440456171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9386998440456171 | validation: 1.1138252605084134]
	TIME [epoch: 0.87 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0220751274910302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0220751274910302 | validation: 1.0179744079725432]
	TIME [epoch: 0.871 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.922947993804168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.922947993804168 | validation: 0.9881406075651255]
	TIME [epoch: 0.87 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8812369117202721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8812369117202721 | validation: 0.9519264834499035]
	TIME [epoch: 0.872 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8718364908271139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8718364908271139 | validation: 0.9498591478878033]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8674001653775314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8674001653775314 | validation: 0.9752365518674009]
	TIME [epoch: 0.87 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8603178428640214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8603178428640214 | validation: 0.9395830600006948]
	TIME [epoch: 0.868 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8701960630639949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8701960630639949 | validation: 0.9622599827734437]
	TIME [epoch: 0.87 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8841768750509715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8841768750509715 | validation: 1.003820744898162]
	TIME [epoch: 0.868 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9647624387667275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9647624387667275 | validation: 1.1958771139389925]
	TIME [epoch: 0.868 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0828236842766152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0828236842766152 | validation: 0.9801058488529695]
	TIME [epoch: 0.868 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.886269455577696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.886269455577696 | validation: 0.9359857480728782]
	TIME [epoch: 0.868 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8587722763237358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8587722763237358 | validation: 0.9655741907697468]
	TIME [epoch: 0.87 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8856009564137322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8856009564137322 | validation: 0.9360057683998303]
	TIME [epoch: 0.87 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.872253664930162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.872253664930162 | validation: 0.9542847534029488]
	TIME [epoch: 0.871 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8619446029492801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8619446029492801 | validation: 0.9222958669217329]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8523580893146445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8523580893146445 | validation: 0.9299050706242291]
	TIME [epoch: 0.872 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8615676644299225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8615676644299225 | validation: 0.9554837237251373]
	TIME [epoch: 0.871 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8877588065983941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8877588065983941 | validation: 0.9920559311412372]
	TIME [epoch: 0.871 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9350317329930903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9350317329930903 | validation: 0.9477514389069676]
	TIME [epoch: 0.87 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9436334963996091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9436334963996091 | validation: 0.9548731140327075]
	TIME [epoch: 0.87 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8755354350690676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8755354350690676 | validation: 0.9251838000657678]
	TIME [epoch: 0.87 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8687571746767653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8687571746767653 | validation: 1.0129279429828564]
	TIME [epoch: 0.869 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9360670613900187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9360670613900187 | validation: 1.0117507951975078]
	TIME [epoch: 0.87 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9954266707104046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9954266707104046 | validation: 1.0438150449302572]
	TIME [epoch: 0.87 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9332002498910452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9332002498910452 | validation: 0.9105043865075635]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8504830353258374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8504830353258374 | validation: 0.9018163483083708]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8697027559438749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8697027559438749 | validation: 0.9392479083341789]
	TIME [epoch: 0.87 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8650686274208502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8650686274208502 | validation: 0.9182957742190825]
	TIME [epoch: 0.869 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8543060721717192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8543060721717192 | validation: 0.9194676392977794]
	TIME [epoch: 0.87 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.849765866332507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.849765866332507 | validation: 0.898148176105417]
	TIME [epoch: 0.89 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8436964019814029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8436964019814029 | validation: 0.896727970236341]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8424678562992708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8424678562992708 | validation: 0.9097362097855612]
	TIME [epoch: 0.872 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8659296653500131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8659296653500131 | validation: 1.069735252117812]
	TIME [epoch: 0.869 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.989501978871271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.989501978871271 | validation: 1.0768604338901828]
	TIME [epoch: 0.869 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0726431572192872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0726431572192872 | validation: 1.077321687877409]
	TIME [epoch: 0.869 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9597314738499501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9597314738499501 | validation: 0.925567557503743]
	TIME [epoch: 0.871 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8969794680054668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8969794680054668 | validation: 0.8733239822796272]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8588061279358218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8588061279358218 | validation: 0.8837625880140343]
	TIME [epoch: 0.871 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8445242713424618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8445242713424618 | validation: 0.8941835419372306]
	TIME [epoch: 0.869 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8486933723752443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8486933723752443 | validation: 0.8837187824643582]
	TIME [epoch: 0.87 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8322504529053133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8322504529053133 | validation: 0.8636378513932176]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8297211691711334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8297211691711334 | validation: 0.8771522464429868]
	TIME [epoch: 0.87 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8160455253479366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8160455253479366 | validation: 0.8583438474343446]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.844514032236508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.844514032236508 | validation: 2.133038527175703]
	TIME [epoch: 0.871 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2270679453327022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2270679453327022 | validation: 0.862288828313184]
	TIME [epoch: 0.869 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8223022689913964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8223022689913964 | validation: 0.8811765621624108]
	TIME [epoch: 0.871 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8302095559289149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8302095559289149 | validation: 0.9374595153669614]
	TIME [epoch: 0.869 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8533338323703475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8533338323703475 | validation: 0.8688241368596693]
	TIME [epoch: 0.87 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8295010900909746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8295010900909746 | validation: 0.8854799185947222]
	TIME [epoch: 0.869 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8359077357095871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8359077357095871 | validation: 0.8761287073057201]
	TIME [epoch: 0.871 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8241748720906378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8241748720906378 | validation: 0.8627843792394283]
	TIME [epoch: 0.871 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8139618688851361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8139618688851361 | validation: 0.8603023670198211]
	TIME [epoch: 0.869 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7983555025131577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7983555025131577 | validation: 0.8217582655345501]
	TIME [epoch: 0.869 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7746895104028919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7746895104028919 | validation: 0.7967633545023821]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7501221847980454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7501221847980454 | validation: 0.8799927191533515]
	TIME [epoch: 0.87 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8698684250734567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8698684250734567 | validation: 1.9376988751787927]
	TIME [epoch: 0.872 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8828858743796333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8828858743796333 | validation: 0.9005970969474639]
	TIME [epoch: 0.87 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.858821722297041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.858821722297041 | validation: 0.9226423931648473]
	TIME [epoch: 0.869 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9091768655336064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9091768655336064 | validation: 0.8964013155715247]
	TIME [epoch: 0.87 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8399160867364056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8399160867364056 | validation: 0.9052070646575618]
	TIME [epoch: 0.87 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.844575844538048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.844575844538048 | validation: 0.8580579442812013]
	TIME [epoch: 0.87 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8289245966522181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8289245966522181 | validation: 0.8507775319414276]
	TIME [epoch: 0.869 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8039455567413274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8039455567413274 | validation: 0.8606765095242346]
	TIME [epoch: 0.876 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7909669179963851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7909669179963851 | validation: 0.7898932786164501]
	TIME [epoch: 0.885 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7720349756783716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7720349756783716 | validation: 0.7746872274789767]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7517660080035691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7517660080035691 | validation: 0.7303934266681237]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.735255639206922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.735255639206922 | validation: 0.8316839691023863]
	TIME [epoch: 0.871 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8018565361627731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8018565361627731 | validation: 1.1478719119886232]
	TIME [epoch: 0.872 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2063580214413898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2063580214413898 | validation: 0.7963991483100812]
	TIME [epoch: 0.871 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7868412637188154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7868412637188154 | validation: 0.8262561631417882]
	TIME [epoch: 0.871 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7886365520576152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7886365520576152 | validation: 0.8171862568099126]
	TIME [epoch: 0.872 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8115969247171738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8115969247171738 | validation: 0.8127031529927233]
	TIME [epoch: 0.871 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7710419784382943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7710419784382943 | validation: 0.7368754242966965]
	TIME [epoch: 0.871 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7626022082360411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7626022082360411 | validation: 0.7909299602600816]
	TIME [epoch: 0.873 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.800558563224791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.800558563224791 | validation: 0.8771878858283677]
	TIME [epoch: 0.872 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8915440588276171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8915440588276171 | validation: 0.7843830205981986]
	TIME [epoch: 0.872 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7637770876501069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7637770876501069 | validation: 0.7547227932189365]
	TIME [epoch: 0.872 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7426875980861894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7426875980861894 | validation: 0.750372940564353]
	TIME [epoch: 0.873 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7565013060936352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7565013060936352 | validation: 0.8306676178240227]
	TIME [epoch: 0.871 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8546667648153163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8546667648153163 | validation: 0.9208604506261813]
	TIME [epoch: 0.872 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9511406930488451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9511406930488451 | validation: 0.8101883383710009]
	TIME [epoch: 0.871 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7900614577204595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7900614577204595 | validation: 0.8348503887536053]
	TIME [epoch: 0.871 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.804895456957397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.804895456957397 | validation: 0.776327258297098]
	TIME [epoch: 0.871 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7617639159300663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7617639159300663 | validation: 0.7265471478137444]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7155626318011182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7155626318011182 | validation: 0.6787398267231061]
	TIME [epoch: 0.873 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7310094136077189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7310094136077189 | validation: 0.723448781185682]
	TIME [epoch: 0.872 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7570431549951014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7570431549951014 | validation: 0.9148955898690364]
	TIME [epoch: 0.871 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9217398728544233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9217398728544233 | validation: 0.9063296499527616]
	TIME [epoch: 0.872 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9186384747758929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9186384747758929 | validation: 0.8447422298943664]
	TIME [epoch: 0.87 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8068112776097435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8068112776097435 | validation: 0.8651771932835235]
	TIME [epoch: 0.872 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8176405051840046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8176405051840046 | validation: 0.8394693918108924]
	TIME [epoch: 0.871 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.792580714912378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.792580714912378 | validation: 0.8160210061647425]
	TIME [epoch: 0.872 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.772762586528423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.772762586528423 | validation: 0.7372659649167878]
	TIME [epoch: 0.87 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7324516018836001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7324516018836001 | validation: 0.6721966923000824]
	TIME [epoch: 0.872 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7045928893023573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7045928893023573 | validation: 0.6998436202582557]
	TIME [epoch: 0.871 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7301959808456158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7301959808456158 | validation: 0.8323363579119548]
	TIME [epoch: 0.872 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8397863517077855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8397863517077855 | validation: 0.9431984145459332]
	TIME [epoch: 0.871 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9476051479815485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9476051479815485 | validation: 0.7912336919606859]
	TIME [epoch: 0.878 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8065401112198451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8065401112198451 | validation: 0.8042401362973669]
	TIME [epoch: 0.886 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7593986377460908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7593986377460908 | validation: 0.7727605839136396]
	TIME [epoch: 0.872 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7540851649005069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7540851649005069 | validation: 0.6867529236170814]
	TIME [epoch: 0.87 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7039570287203839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7039570287203839 | validation: 0.7004942752024388]
	TIME [epoch: 0.876 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7509279102200246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7509279102200246 | validation: 0.8015145961571456]
	TIME [epoch: 0.871 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8474899067067881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8474899067067881 | validation: 0.8147425061121267]
	TIME [epoch: 0.872 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8122892696422034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8122892696422034 | validation: 0.7244708128423151]
	TIME [epoch: 0.871 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7327120133023763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7327120133023763 | validation: 0.6730862472787638]
	TIME [epoch: 0.872 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6917034102486871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6917034102486871 | validation: 0.6430399746041318]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7026555097310913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7026555097310913 | validation: 0.6792690343762959]
	TIME [epoch: 0.874 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7426364111245088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7426364111245088 | validation: 0.755108262265916]
	TIME [epoch: 0.87 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.79928006511961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.79928006511961 | validation: 0.8119309694397862]
	TIME [epoch: 0.872 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8215862495628603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8215862495628603 | validation: 0.7299327581119487]
	TIME [epoch: 0.871 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7101227459567973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7101227459567973 | validation: 0.6536783500009739]
	TIME [epoch: 0.872 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6901562330145892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6901562330145892 | validation: 0.6833350758456701]
	TIME [epoch: 0.87 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7343049121069314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7343049121069314 | validation: 0.7384917304948171]
	TIME [epoch: 0.871 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7846195736301346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7846195736301346 | validation: 0.7678075311280594]
	TIME [epoch: 0.871 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.790191229852881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.790191229852881 | validation: 0.7054360900068275]
	TIME [epoch: 0.871 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7153167263072224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7153167263072224 | validation: 0.6441353809885837]
	TIME [epoch: 0.871 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6820472900637204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6820472900637204 | validation: 0.6611605873613441]
	TIME [epoch: 0.872 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7325095362057406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7325095362057406 | validation: 0.6919953059499678]
	TIME [epoch: 0.872 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7510273433519191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7510273433519191 | validation: 0.7330920743108515]
	TIME [epoch: 0.872 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7593826408528601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7593826408528601 | validation: 0.6753102966584952]
	TIME [epoch: 0.87 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6918183343056361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6918183343056361 | validation: 0.6202495269290988]
	TIME [epoch: 0.873 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7009859662365452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7009859662365452 | validation: 0.7062196691373681]
	TIME [epoch: 0.869 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.749318987925435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.749318987925435 | validation: 0.7067111685479494]
	TIME [epoch: 0.87 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7303448223592343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7303448223592343 | validation: 0.6337269440874046]
	TIME [epoch: 0.87 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6866228246917144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6866228246917144 | validation: 0.6186969311977116]
	TIME [epoch: 0.87 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6809040369117255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6809040369117255 | validation: 0.6643539043932387]
	TIME [epoch: 0.871 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6960107730304163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6960107730304163 | validation: 0.6237858543871218]
	TIME [epoch: 0.871 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6828814136749531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6828814136749531 | validation: 0.6180889999503693]
	TIME [epoch: 0.871 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6852502083997348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6852502083997348 | validation: 0.648681096587234]
	TIME [epoch: 0.873 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7014626858182716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7014626858182716 | validation: 0.7136795634395636]
	TIME [epoch: 0.872 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7573898729530433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7573898729530433 | validation: 0.6495243338044625]
	TIME [epoch: 0.872 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6789945425081072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6789945425081072 | validation: 0.5648867541833177]
	TIME [epoch: 0.872 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6570074084646879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6570074084646879 | validation: 0.6211319580152717]
	TIME [epoch: 0.879 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6528483755242995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6528483755242995 | validation: 0.5853618548615102]
	TIME [epoch: 0.886 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6427970257544284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6427970257544284 | validation: 0.6144263367039786]
	TIME [epoch: 27.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6739749729092697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6739749729092697 | validation: 0.7699463642030813]
	TIME [epoch: 1.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7915740077063026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7915740077063026 | validation: 0.8200446495733573]
	TIME [epoch: 1.71 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8547335700220137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8547335700220137 | validation: 0.7859590974308741]
	TIME [epoch: 1.71 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7827860664050726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7827860664050726 | validation: 0.7370697509872179]
	TIME [epoch: 1.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7269042120927806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7269042120927806 | validation: 0.5444523183106788]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6650717177500977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6650717177500977 | validation: 0.5611351138075497]
	TIME [epoch: 1.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6270727491431205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6270727491431205 | validation: 0.5825161210670268]
	TIME [epoch: 1.72 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6178865425451194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6178865425451194 | validation: 0.5577848025958394]
	TIME [epoch: 1.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6183685396846983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6183685396846983 | validation: 0.5754026784982419]
	TIME [epoch: 1.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6225788711159261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6225788711159261 | validation: 0.6340767107471557]
	TIME [epoch: 1.71 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6825768754938478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6825768754938478 | validation: 0.7370521910808109]
	TIME [epoch: 1.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7864908776458189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7864908776458189 | validation: 0.6928475313601737]
	TIME [epoch: 1.71 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7223435625481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7223435625481 | validation: 0.5915695300263978]
	TIME [epoch: 1.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6294969884731563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6294969884731563 | validation: 0.5726529409160018]
	TIME [epoch: 1.71 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6995747295778386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6995747295778386 | validation: 0.6009239557638371]
	TIME [epoch: 1.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6147457258517403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6147457258517403 | validation: 0.5346631431121831]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5841866813110009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5841866813110009 | validation: 0.5490040655210987]
	TIME [epoch: 1.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5991933945124811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5991933945124811 | validation: 0.5637872079239821]
	TIME [epoch: 1.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6031707915849926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6031707915849926 | validation: 0.5415480079279774]
	TIME [epoch: 1.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5861947588190612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5861947588190612 | validation: 0.5433283757445955]
	TIME [epoch: 1.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.581376644658298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.581376644658298 | validation: 0.5101426404549722]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5676570480410736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5676570480410736 | validation: 0.5583899096342207]
	TIME [epoch: 1.71 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5756649328362393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5756649328362393 | validation: 0.5339471158913545]
	TIME [epoch: 1.71 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5885300051393142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5885300051393142 | validation: 0.6353174078661585]
	TIME [epoch: 1.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6259580338993116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6259580338993116 | validation: 0.5221267394498871]
	TIME [epoch: 1.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5441691241850767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5441691241850767 | validation: 0.5299667935005109]
	TIME [epoch: 1.71 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5521410787097447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5521410787097447 | validation: 0.5662682140610917]
	TIME [epoch: 1.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5723272304373134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5723272304373134 | validation: 0.5059451426099574]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5501775355218861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5501775355218861 | validation: 0.55898094272167]
	TIME [epoch: 1.72 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.553770540871427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.553770540871427 | validation: 0.5135021124086564]
	TIME [epoch: 1.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5606280366829628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606280366829628 | validation: 0.6121640147359187]
	TIME [epoch: 1.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5955201090394091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5955201090394091 | validation: 0.4908209201775206]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5170987305633533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5170987305633533 | validation: 0.4894627254250954]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49703626829102826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49703626829102826 | validation: 0.48250706138216065]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4807321062667699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4807321062667699 | validation: 0.46297229184572486]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47879036857799134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47879036857799134 | validation: 0.5313411752064465]
	TIME [epoch: 1.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5011080286757216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5011080286757216 | validation: 0.528767861763286]
	TIME [epoch: 1.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6133344402006292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6133344402006292 | validation: 0.6538480680128984]
	TIME [epoch: 1.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5940757183861479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5940757183861479 | validation: 0.4736321870004215]
	TIME [epoch: 1.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46915897833491604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46915897833491604 | validation: 0.4881470770376045]
	TIME [epoch: 1.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5040093137092005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5040093137092005 | validation: 0.5782955935713694]
	TIME [epoch: 1.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5561873855217385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5561873855217385 | validation: 0.47985933491849403]
	TIME [epoch: 1.71 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4907218844070137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4907218844070137 | validation: 0.4781457120469586]
	TIME [epoch: 1.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4455747304801221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4455747304801221 | validation: 0.4528100404099015]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4401352671075651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4401352671075651 | validation: 0.45584688076136015]
	TIME [epoch: 1.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.431844624514293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.431844624514293 | validation: 0.4648046943520407]
	TIME [epoch: 1.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45098348681908806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45098348681908806 | validation: 0.5498825488342421]
	TIME [epoch: 1.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49734834999110833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49734834999110833 | validation: 0.5079737294307228]
	TIME [epoch: 1.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5438326776328306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5438326776328306 | validation: 0.7097596563164654]
	TIME [epoch: 1.71 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6470744660667487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6470744660667487 | validation: 0.43646422988695033]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.414804952257799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.414804952257799 | validation: 0.45716954034909874]
	TIME [epoch: 1.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4463150862979071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4463150862979071 | validation: 0.5589357290213648]
	TIME [epoch: 1.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5112604361578664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5112604361578664 | validation: 0.4559620193226301]
	TIME [epoch: 1.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45965107008544237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45965107008544237 | validation: 0.46236366309996335]
	TIME [epoch: 1.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4230478637617729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4230478637617729 | validation: 0.45881273248276716]
	TIME [epoch: 1.71 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42104261555044015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42104261555044015 | validation: 0.4566571822538566]
	TIME [epoch: 1.71 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41912118273787885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41912118273787885 | validation: 0.48093766303265284]
	TIME [epoch: 1.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44107636863603233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44107636863603233 | validation: 0.5390217142108839]
	TIME [epoch: 1.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4697944783484067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4697944783484067 | validation: 0.43397125412614346]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4200127078332466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4200127078332466 | validation: 0.507948015083758]
	TIME [epoch: 1.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4366419844992289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4366419844992289 | validation: 0.45453232960254497]
	TIME [epoch: 1.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4384097812311441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4384097812311441 | validation: 0.6323135607959226]
	TIME [epoch: 1.71 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5434113078054393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5434113078054393 | validation: 0.46893638268526683]
	TIME [epoch: 1.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4071563018368596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4071563018368596 | validation: 0.5050888660849061]
	TIME [epoch: 1.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4779985693942513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4779985693942513 | validation: 0.5212012687345111]
	TIME [epoch: 1.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4827436041852293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4827436041852293 | validation: 0.4633249566941996]
	TIME [epoch: 1.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4170853394684387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4170853394684387 | validation: 0.44333751644050967]
	TIME [epoch: 1.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40314965724313667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40314965724313667 | validation: 0.524456351949622]
	TIME [epoch: 1.72 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4527291616253713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4527291616253713 | validation: 0.4114568091233146]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4286641005814882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4286641005814882 | validation: 0.4959188256381582]
	TIME [epoch: 1.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4129490011869985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4129490011869985 | validation: 0.4291710826570701]
	TIME [epoch: 1.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37584392782837384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37584392782837384 | validation: 0.4276770904798639]
	TIME [epoch: 1.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3601114704165632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3601114704165632 | validation: 0.43909259990113514]
	TIME [epoch: 1.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3494764457125045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3494764457125045 | validation: 0.42413109009875116]
	TIME [epoch: 1.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3711415746194988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3711415746194988 | validation: 0.5801667577531495]
	TIME [epoch: 1.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49847439518053693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49847439518053693 | validation: 0.4865037475436224]
	TIME [epoch: 1.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46086551155198224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46086551155198224 | validation: 0.44992874414579503]
	TIME [epoch: 1.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35951314419446917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35951314419446917 | validation: 0.4193489094988927]
	TIME [epoch: 1.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34927274471430386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34927274471430386 | validation: 0.41735407300542793]
	TIME [epoch: 1.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37001037797213854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37001037797213854 | validation: 0.476729452353358]
	TIME [epoch: 1.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39168616363664954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39168616363664954 | validation: 0.4244177649363272]
	TIME [epoch: 1.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3641575577361615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3641575577361615 | validation: 0.477248301208248]
	TIME [epoch: 1.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36529913746012477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36529913746012477 | validation: 0.4338998443417018]
	TIME [epoch: 1.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3675904059105314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3675904059105314 | validation: 0.47032009227075894]
	TIME [epoch: 1.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35004305096139626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35004305096139626 | validation: 0.38371831725957106]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33972171249115624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33972171249115624 | validation: 0.49126675397777086]
	TIME [epoch: 1.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.383590939889842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.383590939889842 | validation: 0.4973706818310027]
	TIME [epoch: 1.71 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48157911758039895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48157911758039895 | validation: 0.4965216626145157]
	TIME [epoch: 1.71 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.418687381290877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.418687381290877 | validation: 0.4333520740882266]
	TIME [epoch: 1.72 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3384334670262172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3384334670262172 | validation: 0.3937235686664551]
	TIME [epoch: 1.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32772060006152737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32772060006152737 | validation: 0.39851028005608224]
	TIME [epoch: 1.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32301552044131226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32301552044131226 | validation: 0.3799702883618483]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3219371351617227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219371351617227 | validation: 0.37666862502927456]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3080134568770551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3080134568770551 | validation: 0.3793777286684392]
	TIME [epoch: 1.71 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32210094309786463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32210094309786463 | validation: 0.48566442234935114]
	TIME [epoch: 1.71 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4282103189837648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4282103189837648 | validation: 0.45795081235237467]
	TIME [epoch: 1.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4243015289248356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4243015289248356 | validation: 0.4707207839577732]
	TIME [epoch: 1.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3567485252654609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3567485252654609 | validation: 0.4229662224274348]
	TIME [epoch: 1.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3718823817375572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3718823817375572 | validation: 0.4385021178934668]
	TIME [epoch: 1.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32813268157149195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32813268157149195 | validation: 0.3417740468466324]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2795937478265409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2795937478265409 | validation: 0.362435472478418]
	TIME [epoch: 1.71 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28333388332781395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28333388332781395 | validation: 0.34037813761434776]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29250281549812834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29250281549812834 | validation: 0.43204113460657967]
	TIME [epoch: 1.71 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3492446490303558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3492446490303558 | validation: 0.4763980737932615]
	TIME [epoch: 1.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.50573294408892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.50573294408892 | validation: 0.473236379263207]
	TIME [epoch: 1.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3630160604280079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3630160604280079 | validation: 0.4130306716463865]
	TIME [epoch: 1.71 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35780774192694464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35780774192694464 | validation: 0.3897701526833709]
	TIME [epoch: 1.71 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31232011210605704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31232011210605704 | validation: 0.36333130325717544]
	TIME [epoch: 1.71 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27549537605126256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27549537605126256 | validation: 0.321683899605379]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2730151577761245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2730151577761245 | validation: 0.41463818597678276]
	TIME [epoch: 1.71 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33602774386469203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33602774386469203 | validation: 0.345722437179959]
	TIME [epoch: 1.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37194029495346437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37194029495346437 | validation: 0.49560463867561105]
	TIME [epoch: 1.71 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42211231736742677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42211231736742677 | validation: 0.46394578576245477]
	TIME [epoch: 1.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42618185864230274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42618185864230274 | validation: 0.33873478221396697]
	TIME [epoch: 1.71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28083397554822365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28083397554822365 | validation: 0.5658106439053446]
	TIME [epoch: 1.71 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4663742817100554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4663742817100554 | validation: 0.30881768784472724]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30247669917515047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30247669917515047 | validation: 0.3636696349014487]
	TIME [epoch: 1.71 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3091608499333791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3091608499333791 | validation: 0.3122562510992595]
	TIME [epoch: 1.71 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2579096691166027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2579096691166027 | validation: 0.3129131428369878]
	TIME [epoch: 1.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25565083159828933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25565083159828933 | validation: 0.2795297720519158]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25648487199973696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25648487199973696 | validation: 0.30142073270236724]
	TIME [epoch: 1.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23044657757824305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23044657757824305 | validation: 0.2558822382971528]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2590203915174836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2590203915174836 | validation: 0.5229817864980756]
	TIME [epoch: 1.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3997384296254328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3997384296254328 | validation: 0.5275698117890673]
	TIME [epoch: 1.71 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6178279522220872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6178279522220872 | validation: 0.24920602225187005]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23930582147801205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23930582147801205 | validation: 0.4392294090756439]
	TIME [epoch: 1.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3416624479040623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3416624479040623 | validation: 0.2951025052156528]
	TIME [epoch: 1.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30739492687896786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30739492687896786 | validation: 0.2597118412274364]
	TIME [epoch: 1.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22432588950483554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22432588950483554 | validation: 0.34644859219609714]
	TIME [epoch: 1.71 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.259665285566691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.259665285566691 | validation: 0.24784061561300819]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23580439054325059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23580439054325059 | validation: 0.2750338925463362]
	TIME [epoch: 1.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21293524749304518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21293524749304518 | validation: 0.2785758640696944]
	TIME [epoch: 1.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24227255070632686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24227255070632686 | validation: 0.4259050386002754]
	TIME [epoch: 1.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3807154698482114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3807154698482114 | validation: 0.32098186827387387]
	TIME [epoch: 1.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36134745605477037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36134745605477037 | validation: 0.24491466434924514]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18714514788304867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18714514788304867 | validation: 0.2640030494355424]
	TIME [epoch: 1.71 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23390237713448225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23390237713448225 | validation: 0.254840366004001]
	TIME [epoch: 1.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22218553188649515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22218553188649515 | validation: 0.19323061291400656]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17873433511521605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17873433511521605 | validation: 0.2537627619504866]
	TIME [epoch: 1.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19199982020450365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19199982020450365 | validation: 0.22348367089247034]
	TIME [epoch: 1.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32266099564737516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32266099564737516 | validation: 0.6519549475118449]
	TIME [epoch: 1.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.594274675590781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.594274675590781 | validation: 0.35854470241371605]
	TIME [epoch: 1.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5022263693974397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5022263693974397 | validation: 0.20080590416251254]
	TIME [epoch: 1.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22003299899808337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22003299899808337 | validation: 0.38032039283484037]
	TIME [epoch: 1.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2979466718066665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2979466718066665 | validation: 0.22952862350551528]
	TIME [epoch: 1.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20164886180237748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20164886180237748 | validation: 0.1882095959241514]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18223887243632253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18223887243632253 | validation: 0.23292321267756178]
	TIME [epoch: 1.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1789613920796217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1789613920796217 | validation: 0.18044018485134708]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15828113403336447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15828113403336447 | validation: 0.20481823798888166]
	TIME [epoch: 1.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15660389910592307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15660389910592307 | validation: 0.1816309927281821]
	TIME [epoch: 1.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1657217419102877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1657217419102877 | validation: 0.21890480745981572]
	TIME [epoch: 1.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16699846120805625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16699846120805625 | validation: 0.1536001018734763]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15385001441679996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15385001441679996 | validation: 0.22048653358198284]
	TIME [epoch: 1.71 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1539205629129689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1539205629129689 | validation: 0.18907083438844133]
	TIME [epoch: 1.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.270178052551396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.270178052551396 | validation: 0.5766878513832431]
	TIME [epoch: 1.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.539571797102718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.539571797102718 | validation: 0.28211064272014713]
	TIME [epoch: 1.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38610310786472996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38610310786472996 | validation: 0.202695938786322]
	TIME [epoch: 1.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17724387996878968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17724387996878968 | validation: 0.28195653889174893]
	TIME [epoch: 1.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2179129983430431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2179129983430431 | validation: 0.15848552945867592]
	TIME [epoch: 1.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16454848591624324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16454848591624324 | validation: 0.15942125740719662]
	TIME [epoch: 1.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1337204193092851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1337204193092851 | validation: 0.15250621173850853]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12562424733978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12562424733978 | validation: 0.12871477905658066]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12851090975029827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12851090975029827 | validation: 0.17344093133893548]
	TIME [epoch: 1.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15329322750076735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15329322750076735 | validation: 0.2602299727553208]
	TIME [epoch: 1.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3262507683154747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3262507683154747 | validation: 0.28654102634559314]
	TIME [epoch: 1.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22436042620757987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22436042620757987 | validation: 0.25171362068704967]
	TIME [epoch: 1.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2963622128298031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2963622128298031 | validation: 0.3021660232896268]
	TIME [epoch: 1.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21257109464848345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21257109464848345 | validation: 0.11526949089432025]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12057760442809005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12057760442809005 | validation: 0.12229688411667805]
	TIME [epoch: 1.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1162741778756601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1162741778756601 | validation: 0.13170223162547587]
	TIME [epoch: 1.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11169731503358186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11169731503358186 | validation: 0.11700143998867873]
	TIME [epoch: 1.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11547177828382861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11547177828382861 | validation: 0.1727626297924236]
	TIME [epoch: 1.71 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13335584149259627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13335584149259627 | validation: 0.2062044026565154]
	TIME [epoch: 1.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26102242510876805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26102242510876805 | validation: 0.49023668932253905]
	TIME [epoch: 1.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42348599418035043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42348599418035043 | validation: 0.3314109082540246]
	TIME [epoch: 1.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4341625346999458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4341625346999458 | validation: 0.16535388935493162]
	TIME [epoch: 1.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14251288396803577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14251288396803577 | validation: 0.28674401778401143]
	TIME [epoch: 1.71 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22425600479893398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22425600479893398 | validation: 0.13397958657537226]
	TIME [epoch: 1.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17153179880218325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17153179880218325 | validation: 0.15522062785505006]
	TIME [epoch: 1.71 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11981008253506228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11981008253506228 | validation: 0.14025857651354362]
	TIME [epoch: 1.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11479548611784303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11479548611784303 | validation: 0.09640148393664397]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10649276748636309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10649276748636309 | validation: 0.11950962269726682]
	TIME [epoch: 1.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09486368998272411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09486368998272411 | validation: 0.0835644745379005]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0975679932001879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0975679932001879 | validation: 0.22177962136530738]
	TIME [epoch: 1.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18415094954774916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18415094954774916 | validation: 0.28109044823395785]
	TIME [epoch: 1.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3506406626764947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3506406626764947 | validation: 0.26555375759858063]
	TIME [epoch: 1.72 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20181051530053395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20181051530053395 | validation: 0.16728281453277224]
	TIME [epoch: 1.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2146097460908219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2146097460908219 | validation: 0.1876794037083313]
	TIME [epoch: 1.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1555961056730709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1555961056730709 | validation: 0.10922219790565518]
	TIME [epoch: 1.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1040350067344499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1040350067344499 | validation: 0.08128342926216978]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08105573726615681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08105573726615681 | validation: 0.09821201432180728]
	TIME [epoch: 1.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07956800378789344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07956800378789344 | validation: 0.08663288351207474]
	TIME [epoch: 1.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10213168638528075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10213168638528075 | validation: 0.24535736056980195]
	TIME [epoch: 1.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20384693426818917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20384693426818917 | validation: 0.38700595697916323]
	TIME [epoch: 1.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46929375343177254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46929375343177254 | validation: 0.20895883405005372]
	TIME [epoch: 1.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15416339504827123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15416339504827123 | validation: 0.13166775163726982]
	TIME [epoch: 1.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12372262134745221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12372262134745221 | validation: 0.09323008389423243]
	TIME [epoch: 1.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11049806860571675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11049806860571675 | validation: 0.10828566661248012]
	TIME [epoch: 1.71 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09499275832600237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09499275832600237 | validation: 0.08133887272655269]
	TIME [epoch: 1.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08345728741411183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08345728741411183 | validation: 0.10863343981570679]
	TIME [epoch: 1.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08971364669716433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08971364669716433 | validation: 0.1160776727013847]
	TIME [epoch: 1.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11296290672021941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11296290672021941 | validation: 0.21937942506608904]
	TIME [epoch: 1.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16712049958608152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16712049958608152 | validation: 0.2996981439713248]
	TIME [epoch: 1.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3592451104267556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3592451104267556 | validation: 0.27866589574696915]
	TIME [epoch: 1.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22390906414536246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22390906414536246 | validation: 0.09369954611664949]
	TIME [epoch: 1.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13622970139931923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13622970139931923 | validation: 0.10366581496152028]
	TIME [epoch: 1.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08466999495990293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08466999495990293 | validation: 0.10123627641422835]
	TIME [epoch: 1.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08296707883349537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08296707883349537 | validation: 0.0629093998721559]
	TIME [epoch: 1.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08658840876908876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08658840876908876 | validation: 0.14172826888468693]
	TIME [epoch: 1.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10359709999725837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10359709999725837 | validation: 0.11867040007147922]
	TIME [epoch: 1.71 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15465002400030708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15465002400030708 | validation: 0.30466600184864]
	TIME [epoch: 1.71 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24079245169157829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24079245169157829 | validation: 0.33645413410334324]
	TIME [epoch: 1.71 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3744674728161992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3744674728161992 | validation: 0.13807412786144685]
	TIME [epoch: 1.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10333502621951293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10333502621951293 | validation: 0.1425695427817611]
	TIME [epoch: 1.71 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12280958072888665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12280958072888665 | validation: 0.09230719178205488]
	TIME [epoch: 1.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10624008468838814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10624008468838814 | validation: 0.1254538735309673]
	TIME [epoch: 1.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09666655933901279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09666655933901279 | validation: 0.10530512584428031]
	TIME [epoch: 1.71 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0895476636247526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0895476636247526 | validation: 0.1119417199646946]
	TIME [epoch: 1.71 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10025604904569844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10025604904569844 | validation: 0.10808856315631798]
	TIME [epoch: 1.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0897399773803778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0897399773803778 | validation: 0.08331509966754902]
	TIME [epoch: 1.71 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07389820687671497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07389820687671497 | validation: 0.08966113199630285]
	TIME [epoch: 1.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09622920772142107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09622920772142107 | validation: 0.2563759324446206]
	TIME [epoch: 1.71 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23006671388977856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23006671388977856 | validation: 0.3463730362166232]
	TIME [epoch: 1.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43335715347046816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43335715347046816 | validation: 0.18901062065634533]
	TIME [epoch: 1.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14396049103727382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14396049103727382 | validation: 0.11024095717324034]
	TIME [epoch: 1.71 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12412335980460239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12412335980460239 | validation: 0.0965424172084941]
	TIME [epoch: 1.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09465287130169299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09465287130169299 | validation: 0.11420629599357551]
	TIME [epoch: 1.71 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08470748907330876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08470748907330876 | validation: 0.07216762883256123]
	TIME [epoch: 1.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07395240447517094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07395240447517094 | validation: 0.07807209283040734]
	TIME [epoch: 1.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06954540931469476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06954540931469476 | validation: 0.06416013404890297]
	TIME [epoch: 1.71 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06852260982792605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06852260982792605 | validation: 0.12491323562402004]
	TIME [epoch: 1.71 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10852924569363806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10852924569363806 | validation: 0.2015801195911139]
	TIME [epoch: 1.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2589570183271993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2589570183271993 | validation: 0.3353285703480333]
	TIME [epoch: 1.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3105632317873058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3105632317873058 | validation: 0.18278523218172538]
	TIME [epoch: 1.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22973993503163545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22973993503163545 | validation: 0.11939458233432697]
	TIME [epoch: 1.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10745044879910726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10745044879910726 | validation: 0.14259833822319723]
	TIME [epoch: 1.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10383077416487706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10383077416487706 | validation: 0.07278623014945805]
	TIME [epoch: 1.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09940600500100345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09940600500100345 | validation: 0.09128957774583685]
	TIME [epoch: 1.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06894640171212227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06894640171212227 | validation: 0.0777939248465491]
	TIME [epoch: 1.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06312725795614124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06312725795614124 | validation: 0.07823214883135549]
	TIME [epoch: 1.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07158019564516149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07158019564516149 | validation: 0.07739977950412842]
	TIME [epoch: 1.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07047174523316278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07047174523316278 | validation: 0.1090544423616367]
	TIME [epoch: 1.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0889903813951911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0889903813951911 | validation: 0.16695343854355515]
	TIME [epoch: 1.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.183033528852354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.183033528852354 | validation: 0.35683671369202374]
	TIME [epoch: 1.71 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3364473167912992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3364473167912992 | validation: 0.31362934676155746]
	TIME [epoch: 1.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32749679352661903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32749679352661903 | validation: 0.12589033627067067]
	TIME [epoch: 1.71 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09371978207802904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09371978207802904 | validation: 0.13296159885245284]
	TIME [epoch: 1.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12890727532103405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12890727532103405 | validation: 0.09373094181746557]
	TIME [epoch: 1.72 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09058305144357143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09058305144357143 | validation: 0.10661009068769774]
	TIME [epoch: 1.71 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07667419160165462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07667419160165462 | validation: 0.06867198661240462]
	TIME [epoch: 1.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06378736309594321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06378736309594321 | validation: 0.06815472139242598]
	TIME [epoch: 1.71 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06035535831365859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06035535831365859 | validation: 0.05888648614708794]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06351422536388235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06351422536388235 | validation: 0.10868092485735209]
	TIME [epoch: 1.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09261437254915703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09261437254915703 | validation: 0.10788497061540932]
	TIME [epoch: 1.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14981864561338873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14981864561338873 | validation: 0.22329818144140134]
	TIME [epoch: 1.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19801141894351673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19801141894351673 | validation: 0.22399750755433534]
	TIME [epoch: 1.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2364050177538771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2364050177538771 | validation: 0.15854081314743504]
	TIME [epoch: 1.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14933419241803683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14933419241803683 | validation: 0.0990153258104749]
	TIME [epoch: 1.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10766269237771184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10766269237771184 | validation: 0.08111683700615678]
	TIME [epoch: 1.71 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07299592746085991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07299592746085991 | validation: 0.07721272667215445]
	TIME [epoch: 1.71 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05627714445533316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05627714445533316 | validation: 0.04864942714864171]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05070826480708543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05070826480708543 | validation: 0.055738192134990094]
	TIME [epoch: 1.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04936590069296361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04936590069296361 | validation: 0.05606675599707056]
	TIME [epoch: 1.71 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05195313058138385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05195313058138385 | validation: 0.13121716836859734]
	TIME [epoch: 1.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10670684779559278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10670684779559278 | validation: 0.26562693502903406]
	TIME [epoch: 1.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3173208477263061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3173208477263061 | validation: 0.31718534630652795]
	TIME [epoch: 1.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2761457614543165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2761457614543165 | validation: 0.10920823591674483]
	TIME [epoch: 1.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13772806484152278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13772806484152278 | validation: 0.10198578881763609]
	TIME [epoch: 1.72 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07147155762658103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07147155762658103 | validation: 0.08175474430014906]
	TIME [epoch: 1.71 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06698540106250904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06698540106250904 | validation: 0.058344670977550986]
	TIME [epoch: 1.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06256759684999377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06256759684999377 | validation: 0.06961773725283496]
	TIME [epoch: 1.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05672839394481605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05672839394481605 | validation: 0.06232128591987565]
	TIME [epoch: 1.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06468425174345618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06468425174345618 | validation: 0.1061001622626797]
	TIME [epoch: 1.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08382956068188492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08382956068188492 | validation: 0.10112447362346799]
	TIME [epoch: 1.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10523725893793427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10523725893793427 | validation: 0.16508697097282132]
	TIME [epoch: 1.71 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14691662835154184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14691662835154184 | validation: 0.18767435184606485]
	TIME [epoch: 1.71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24901241654878412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24901241654878412 | validation: 0.21552981722624298]
	TIME [epoch: 1.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18722023914396346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18722023914396346 | validation: 0.06177244144598394]
	TIME [epoch: 1.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08085904986525985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08085904986525985 | validation: 0.07334758350097322]
	TIME [epoch: 1.71 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05576780306659277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05576780306659277 | validation: 0.06254842828000085]
	TIME [epoch: 1.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056595964805876184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056595964805876184 | validation: 0.05272856977880627]
	TIME [epoch: 1.71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060138697276190936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060138697276190936 | validation: 0.08958772227325466]
	TIME [epoch: 1.71 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07640738102983063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07640738102983063 | validation: 0.08173513710594628]
	TIME [epoch: 1.71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10629753336403512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10629753336403512 | validation: 0.18014294702898698]
	TIME [epoch: 1.71 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1768000439282143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1768000439282143 | validation: 0.2553482700312532]
	TIME [epoch: 1.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2593329325061729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2593329325061729 | validation: 0.11356411023631462]
	TIME [epoch: 1.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10261380622290105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10261380622290105 | validation: 0.05958521586049335]
	TIME [epoch: 1.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06957888133780168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06957888133780168 | validation: 0.10453972080518062]
	TIME [epoch: 1.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07613268805007158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07613268805007158 | validation: 0.05885598833404679]
	TIME [epoch: 1.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06454679172567021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06454679172567021 | validation: 0.08426532201077912]
	TIME [epoch: 1.71 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07455162798707782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07455162798707782 | validation: 0.08128378872860811]
	TIME [epoch: 1.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09491380986937543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09491380986937543 | validation: 0.1452841268212532]
	TIME [epoch: 1.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12178710301125775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12178710301125775 | validation: 0.09743097122544638]
	TIME [epoch: 1.71 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12797773423091194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12797773423091194 | validation: 0.1431825120551116]
	TIME [epoch: 1.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.125992444188749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.125992444188749 | validation: 0.15245969124119088]
	TIME [epoch: 1.71 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15999384795165283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15999384795165283 | validation: 0.14398558998309802]
	TIME [epoch: 1.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1264210275205685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1264210275205685 | validation: 0.08580641290529907]
	TIME [epoch: 1.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08980876018227893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08980876018227893 | validation: 0.0661388386935615]
	TIME [epoch: 1.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0524137115910284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0524137115910284 | validation: 0.048294207478803544]
	TIME [epoch: 1.71 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043762018216057755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043762018216057755 | validation: 0.04442296522427335]
	TIME [epoch: 29 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04345306892652141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04345306892652141 | validation: 0.05423496901627359]
	TIME [epoch: 3.39 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04514930691783592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04514930691783592 | validation: 0.05320435028995635]
	TIME [epoch: 3.38 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07019409211126344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07019409211126344 | validation: 0.23223304436465733]
	TIME [epoch: 3.38 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20546975954850905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20546975954850905 | validation: 0.31569330486358727]
	TIME [epoch: 3.38 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3580834800219016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3580834800219016 | validation: 0.10925745501699563]
	TIME [epoch: 3.38 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0946192385505287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0946192385505287 | validation: 0.07311673082330697]
	TIME [epoch: 3.38 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0626643463928966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0626643463928966 | validation: 0.0722948413811498]
	TIME [epoch: 3.38 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061355717356376634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061355717356376634 | validation: 0.08237637717273859]
	TIME [epoch: 3.38 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06131240694281793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06131240694281793 | validation: 0.0455149747825618]
	TIME [epoch: 3.39 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05477840741475121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05477840741475121 | validation: 0.05968187972136705]
	TIME [epoch: 3.38 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04928351042464302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04928351042464302 | validation: 0.05461228374875282]
	TIME [epoch: 3.38 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05922797662126275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05922797662126275 | validation: 0.10705107066877398]
	TIME [epoch: 3.38 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08883920022464575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08883920022464575 | validation: 0.10512718472531796]
	TIME [epoch: 3.38 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14528455035894966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14528455035894966 | validation: 0.1732952136030688]
	TIME [epoch: 3.37 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1644194334095878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1644194334095878 | validation: 0.13516877440381755]
	TIME [epoch: 3.38 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1405540035017284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1405540035017284 | validation: 0.1745794991825802]
	TIME [epoch: 3.38 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14726284691752592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14726284691752592 | validation: 0.11831436535259782]
	TIME [epoch: 3.38 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11159241927086207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11159241927086207 | validation: 0.08111037048185861]
	TIME [epoch: 3.38 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1069768103537978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1069768103537978 | validation: 0.08461671428445604]
	TIME [epoch: 3.38 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0780066697336642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0780066697336642 | validation: 0.04932752858490304]
	TIME [epoch: 3.39 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0463485321548683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0463485321548683 | validation: 0.03758204269326169]
	TIME [epoch: 3.38 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03745798603902139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03745798603902139 | validation: 0.040494666688274186]
	TIME [epoch: 3.37 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03407371328790775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03407371328790775 | validation: 0.031146276546553293]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03409634769284851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03409634769284851 | validation: 0.07329002778322286]
	TIME [epoch: 3.37 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06368289888324316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06368289888324316 | validation: 0.2363241956295875]
	TIME [epoch: 3.37 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2991292130504449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2991292130504449 | validation: 0.3777412218145989]
	TIME [epoch: 3.37 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36780915262205854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36780915262205854 | validation: 0.14539367275333634]
	TIME [epoch: 3.37 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21836220145691188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21836220145691188 | validation: 0.07636201546536339]
	TIME [epoch: 3.37 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07600885880215345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07600885880215345 | validation: 0.14410810095083626]
	TIME [epoch: 3.37 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10919154626584206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10919154626584206 | validation: 0.06811278351694021]
	TIME [epoch: 3.38 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07110809254677516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07110809254677516 | validation: 0.06257465205692461]
	TIME [epoch: 3.38 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0523636603479968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0523636603479968 | validation: 0.06160483362501299]
	TIME [epoch: 3.36 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04671621214907867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04671621214907867 | validation: 0.041842992351232434]
	TIME [epoch: 3.37 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0440511150879569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0440511150879569 | validation: 0.05783286292750455]
	TIME [epoch: 3.37 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04709775212233156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04709775212233156 | validation: 0.053196182240511994]
	TIME [epoch: 3.37 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0577366561949218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0577366561949218 | validation: 0.08920817522961284]
	TIME [epoch: 3.37 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07721209104963801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07721209104963801 | validation: 0.08051466898016231]
	TIME [epoch: 3.37 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09123275175488878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09123275175488878 | validation: 0.1023498794058751]
	TIME [epoch: 3.37 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08731645451269174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08731645451269174 | validation: 0.10360178978951895]
	TIME [epoch: 3.37 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09553596375614654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09553596375614654 | validation: 0.19013481080359007]
	TIME [epoch: 3.37 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2280255855438464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2280255855438464 | validation: 0.26130856617551385]
	TIME [epoch: 3.38 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25818228146323824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25818228146323824 | validation: 0.08637668535666462]
	TIME [epoch: 3.39 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1219116196573279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1219116196573279 | validation: 0.08254610888899734]
	TIME [epoch: 3.37 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05498156471672968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05498156471672968 | validation: 0.07666631341746122]
	TIME [epoch: 3.37 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054351115047674946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054351115047674946 | validation: 0.051760689027939524]
	TIME [epoch: 3.37 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05417260824203037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05417260824203037 | validation: 0.05615615254484452]
	TIME [epoch: 3.37 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046163844479242586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046163844479242586 | validation: 0.04865061702645046]
	TIME [epoch: 3.37 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04533777894899616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04533777894899616 | validation: 0.060939460167560355]
	TIME [epoch: 3.37 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05021034094076609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05021034094076609 | validation: 0.060715266831522036]
	TIME [epoch: 3.37 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06167260362354115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06167260362354115 | validation: 0.09828470471055634]
	TIME [epoch: 3.37 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08479232267428286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08479232267428286 | validation: 0.12197138561990002]
	TIME [epoch: 3.37 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16029058065605856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16029058065605856 | validation: 0.2229479731043064]
	TIME [epoch: 3.37 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23873006446336395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23873006446336395 | validation: 0.11860252182190877]
	TIME [epoch: 3.39 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1464946883738255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1464946883738255 | validation: 0.08624300593552299]
	TIME [epoch: 3.37 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0881833138801208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0881833138801208 | validation: 0.10877587309839205]
	TIME [epoch: 3.38 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07752745568717943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07752745568717943 | validation: 0.06321264383144802]
	TIME [epoch: 3.38 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06505873372359605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06505873372359605 | validation: 0.0508242630626652]
	TIME [epoch: 3.37 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04277528692031215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04277528692031215 | validation: 0.04381862871539638]
	TIME [epoch: 3.38 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04235926355067845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04235926355067845 | validation: 0.040404151466972744]
	TIME [epoch: 3.37 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04298274198334511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04298274198334511 | validation: 0.05564198661160407]
	TIME [epoch: 3.37 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05132532429537953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05132532429537953 | validation: 0.13091915128561823]
	TIME [epoch: 3.37 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1229867397588833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1229867397588833 | validation: 0.2698040998613715]
	TIME [epoch: 3.37 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31568932964917246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31568932964917246 | validation: 0.1609028948990463]
	TIME [epoch: 3.39 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13505665433143615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13505665433143615 | validation: 0.08361953651568133]
	TIME [epoch: 3.39 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07917020789820689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07917020789820689 | validation: 0.09661715239211305]
	TIME [epoch: 3.37 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07210355061976927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07210355061976927 | validation: 0.0570232246569832]
	TIME [epoch: 3.37 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04949381871061074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04949381871061074 | validation: 0.06457092716812218]
	TIME [epoch: 3.37 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045380690300219635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045380690300219635 | validation: 0.047896578762768385]
	TIME [epoch: 3.37 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05204853803017315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05204853803017315 | validation: 0.07807943602105039]
	TIME [epoch: 3.37 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06330056712638381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06330056712638381 | validation: 0.059166740049801825]
	TIME [epoch: 3.37 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08810705208033699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08810705208033699 | validation: 0.11450501476353328]
	TIME [epoch: 3.37 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11274270107927374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11274270107927374 | validation: 0.1094083585546723]
	TIME [epoch: 3.37 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12766680288068924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12766680288068924 | validation: 0.16744759348010854]
	TIME [epoch: 3.37 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15514338808636638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15514338808636638 | validation: 0.16472932907024207]
	TIME [epoch: 3.37 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17338090208513407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17338090208513407 | validation: 0.08159801682313313]
	TIME [epoch: 3.39 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08750251450659782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08750251450659782 | validation: 0.05703074719971832]
	TIME [epoch: 3.37 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044054694512306175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044054694512306175 | validation: 0.042783447445856285]
	TIME [epoch: 3.37 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046625494486023766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046625494486023766 | validation: 0.05752882002434043]
	TIME [epoch: 3.37 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04813784889136354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04813784889136354 | validation: 0.06581730889427699]
	TIME [epoch: 3.37 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05897170157867643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05897170157867643 | validation: 0.09984233789222027]
	TIME [epoch: 3.37 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08846004725821961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08846004725821961 | validation: 0.13633804005091282]
	TIME [epoch: 3.37 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13511901319067193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13511901319067193 | validation: 0.13933982087227506]
	TIME [epoch: 3.37 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1340799414616161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1340799414616161 | validation: 0.07733118254348248]
	TIME [epoch: 3.37 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.091589342141387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.091589342141387 | validation: 0.06934405989506374]
	TIME [epoch: 3.37 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05661428522793363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05661428522793363 | validation: 0.037629577498277805]
	TIME [epoch: 3.38 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04347400495019988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04347400495019988 | validation: 0.06137406696316708]
	TIME [epoch: 3.38 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05172944877320921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05172944877320921 | validation: 0.06171236330226751]
	TIME [epoch: 3.37 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07539744339025255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07539744339025255 | validation: 0.10081935477170577]
	TIME [epoch: 3.37 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09724912304826713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09724912304826713 | validation: 0.06944722005675355]
	TIME [epoch: 3.37 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08458155406648037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08458155406648037 | validation: 0.06464034000517281]
	TIME [epoch: 3.37 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052222410043584036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052222410043584036 | validation: 0.07570345114106955]
	TIME [epoch: 3.37 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06461013984177166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06461013984177166 | validation: 0.17232822030681533]
	TIME [epoch: 3.39 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18901133161458003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18901133161458003 | validation: 0.24507665532750292]
	TIME [epoch: 3.37 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2462163458505782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2462163458505782 | validation: 0.09503519481330652]
	TIME [epoch: 3.37 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13162633569409857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13162633569409857 | validation: 0.08006567652693115]
	TIME [epoch: 3.37 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05964364422941247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05964364422941247 | validation: 0.08025720814843013]
	TIME [epoch: 3.37 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057397813801751275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057397813801751275 | validation: 0.04704507760755506]
	TIME [epoch: 3.39 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049634607220670035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049634607220670035 | validation: 0.0493749382463709]
	TIME [epoch: 3.37 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0393185911579662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0393185911579662 | validation: 0.04559099685343061]
	TIME [epoch: 3.37 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03939877504665819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03939877504665819 | validation: 0.051585255836017266]
	TIME [epoch: 3.37 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047507129133541194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047507129133541194 | validation: 0.05920701467134307]
	TIME [epoch: 3.37 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055798907605149835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055798907605149835 | validation: 0.06935214280171209]
	TIME [epoch: 3.37 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058042471950958005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058042471950958005 | validation: 0.04884401135679222]
	TIME [epoch: 3.38 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06253045861294412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06253045861294412 | validation: 0.0984181798173153]
	TIME [epoch: 3.36 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08535345902762184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08535345902762184 | validation: 0.12610962606510823]
	TIME [epoch: 3.36 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20876207317295148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20876207317295148 | validation: 0.2675800813106391]
	TIME [epoch: 3.37 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27266465345320456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27266465345320456 | validation: 0.17320567543637277]
	TIME [epoch: 3.39 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22403425862232187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22403425862232187 | validation: 0.10133278081884996]
	TIME [epoch: 3.37 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0966149504023749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0966149504023749 | validation: 0.09292957768172688]
	TIME [epoch: 3.42 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07313488709745851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07313488709745851 | validation: 0.053367992299572856]
	TIME [epoch: 3.37 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05562945758882952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05562945758882952 | validation: 0.05807546829041184]
	TIME [epoch: 3.37 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05824113346075271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05824113346075271 | validation: 0.058715945830187]
	TIME [epoch: 3.37 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046904054366766514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046904054366766514 | validation: 0.04252382493320326]
	TIME [epoch: 3.36 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0420554600492504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0420554600492504 | validation: 0.04351230331276227]
	TIME [epoch: 3.36 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03636702374016894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03636702374016894 | validation: 0.04307214195851593]
	TIME [epoch: 3.36 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036286891618099094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036286891618099094 | validation: 0.05257978628078408]
	TIME [epoch: 3.36 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052065523831747895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052065523831747895 | validation: 0.12296480993099171]
	TIME [epoch: 3.37 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1288320312759357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1288320312759357 | validation: 0.23467232326006682]
	TIME [epoch: 3.38 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23381395738083405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23381395738083405 | validation: 0.13026849631880594]
	TIME [epoch: 3.39 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1197314535149869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1197314535149869 | validation: 0.06349649221113854]
	TIME [epoch: 3.38 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07076780857743338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07076780857743338 | validation: 0.09314078066034215]
	TIME [epoch: 3.37 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0770472443049402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0770472443049402 | validation: 0.046581348929448235]
	TIME [epoch: 3.37 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061999204764519346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061999204764519346 | validation: 0.06147633486584844]
	TIME [epoch: 3.37 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047572808201423275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047572808201423275 | validation: 0.038035025077707646]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_142352/states/model_phi1_3a_v_mmd1_625.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1269.729 seconds.
