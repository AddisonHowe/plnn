Args:
Namespace(name='model_phi1_1a_v_kl1', outdir='out/model_training/model_phi1_1a_v_kl1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3297588454

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.593566878759136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.593566878759136 | validation: 11.448501466860575]
	TIME [epoch: 108 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.806463875082956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.806463875082956 | validation: 12.275586737311013]
	TIME [epoch: 8.39 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.841714288249896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.841714288249896 | validation: 11.694931020064313]
	TIME [epoch: 8.4 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.249470202625107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.249470202625107 | validation: 11.264345018672365]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.828083025468132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.828083025468132 | validation: 10.906850113327547]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.345657880646097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.345657880646097 | validation: 11.012538334358208]
	TIME [epoch: 8.41 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.58922770384637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.58922770384637 | validation: 10.718525392373044]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.251729549831165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.251729549831165 | validation: 10.616125629922246]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.971991291792271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.971991291792271 | validation: 10.555119617643795]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.909323139457845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.909323139457845 | validation: 10.464147011308398]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.948797645827192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.948797645827192 | validation: 10.44515144291063]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.859600161874557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.859600161874557 | validation: 10.23157008008442]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.485441136432673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.485441136432673 | validation: 9.216296851388542]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.659733660811098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.659733660811098 | validation: 8.455630349325208]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.851807836636907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.851807836636907 | validation: 8.577230564702262]
	TIME [epoch: 8.33 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.465747929375743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.465747929375743 | validation: 8.004936585777045]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.291533126721415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.291533126721415 | validation: 7.62627467772824]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.593773022872383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.593773022872383 | validation: 7.365220201310274]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.405627820030122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.405627820030122 | validation: 7.8748380512855665]
	TIME [epoch: 8.29 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.769176558331985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.769176558331985 | validation: 7.612715067435008]
	TIME [epoch: 8.33 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.317296457629375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.317296457629375 | validation: 7.162195812435844]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9841248920757035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9841248920757035 | validation: 6.7957954565809695]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.001922647849266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.001922647849266 | validation: 6.68789773158209]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.857265283670424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.857265283670424 | validation: 6.613210862162736]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921096771237849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.921096771237849 | validation: 6.613210062614899]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.526295567697758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.526295567697758 | validation: 6.3116642570812065]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.630334069549682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.630334069549682 | validation: 6.380488488110169]
	TIME [epoch: 8.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0974271448587825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0974271448587825 | validation: 6.910777974016041]
	TIME [epoch: 8.28 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6270913324448255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6270913324448255 | validation: 5.843078356289742]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.330577797181533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.330577797181533 | validation: 5.696559958815454]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.238515647705318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.238515647705318 | validation: 6.111250808792971]
	TIME [epoch: 8.29 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.703140911999697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703140911999697 | validation: 5.558299083068576]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.041385385166629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.041385385166629 | validation: 4.8837250238328345]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8688921726690255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8688921726690255 | validation: 5.355787381568073]
	TIME [epoch: 8.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.858280960500095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.858280960500095 | validation: 5.009857654609254]
	TIME [epoch: 8.32 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.206626662361755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.206626662361755 | validation: 6.1781869706518755]
	TIME [epoch: 8.29 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0408527057669605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0408527057669605 | validation: 4.696453666562968]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.781439591382166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.781439591382166 | validation: 4.6115518380911595]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.919381481084624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.919381481084624 | validation: 4.770402579926624]
	TIME [epoch: 8.31 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.823592690558055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.823592690558055 | validation: 4.702880077979534]
	TIME [epoch: 8.33 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.706927005351278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.706927005351278 | validation: 4.571868777197623]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531467820978843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.531467820978843 | validation: 4.374907674413638]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544749926058643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.544749926058643 | validation: 4.240257133382131]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6462469868208025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6462469868208025 | validation: 4.294954813014632]
	TIME [epoch: 8.31 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.425183472617731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.425183472617731 | validation: 4.3796235066842435]
	TIME [epoch: 8.39 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.374502580829737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.374502580829737 | validation: 4.63964284269859]
	TIME [epoch: 8.38 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.418343019785803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.418343019785803 | validation: 4.176051297465708]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.321670675088804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.321670675088804 | validation: 4.494099921971257]
	TIME [epoch: 8.39 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164955382194554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164955382194554 | validation: 3.7827700107511255]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.189176778357233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.189176778357233 | validation: 3.904195311729388]
	TIME [epoch: 8.43 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.288077005854624		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.288077005854624 | validation: 3.682351642710226]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7463368073666645		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.7463368073666645 | validation: 3.803189995165055]
	TIME [epoch: 8.37 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.016808578697532		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.016808578697532 | validation: 3.524579968049732]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5265781625884647		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.5265781625884647 | validation: 5.648514168190259]
	TIME [epoch: 8.38 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811495780276838		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.811495780276838 | validation: 3.7863761076753795]
	TIME [epoch: 8.46 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6448924881935834		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.6448924881935834 | validation: 3.6469209661420265]
	TIME [epoch: 8.43 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377688032131983		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.377688032131983 | validation: 3.245764856197842]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1968983459638913		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.1968983459638913 | validation: 3.042019291438704]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0464137841499754		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.0464137841499754 | validation: 3.1760016000511975]
	TIME [epoch: 8.42 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9888088785062257		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.9888088785062257 | validation: 2.9605105282107935]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.844305231391001		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.844305231391001 | validation: 2.6765190050858614]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.653164811847569		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.653164811847569 | validation: 2.6252942003570254]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.689091796776473		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.689091796776473 | validation: 2.993815912481434]
	TIME [epoch: 8.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5655940126751733		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.5655940126751733 | validation: 2.9532233336844773]
	TIME [epoch: 8.42 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876795440839733		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.876795440839733 | validation: 2.5818695100238416]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.401140124236182		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.401140124236182 | validation: 2.553609634427623]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2501916345271127		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.2501916345271127 | validation: 2.1497868268699563]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272636643646113		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.272636643646113 | validation: 2.3098637739449854]
	TIME [epoch: 8.42 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329709530675652		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.329709530675652 | validation: 2.3254276371062526]
	TIME [epoch: 8.42 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3219709176997028		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.3219709176997028 | validation: 2.1545161357229654]
	TIME [epoch: 8.47 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1427159149772255		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.1427159149772255 | validation: 2.215014875454473]
	TIME [epoch: 8.41 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377300713918772		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.377300713918772 | validation: 2.6481877505792393]
	TIME [epoch: 8.38 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.495375223749679		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.495375223749679 | validation: 1.92497437528153]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1307104033667246		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.1307104033667246 | validation: 1.9281080480297026]
	TIME [epoch: 8.41 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1542734195574544		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.1542734195574544 | validation: 2.232178094462803]
	TIME [epoch: 8.39 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0480504839191864		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.0480504839191864 | validation: 2.178123985919269]
	TIME [epoch: 8.39 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.855592425035196		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.855592425035196 | validation: 2.12262988513132]
	TIME [epoch: 8.37 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1422519673306395		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.1422519673306395 | validation: 2.9101962878616074]
	TIME [epoch: 8.35 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.214092897180637		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.214092897180637 | validation: 2.303323291928076]
	TIME [epoch: 8.38 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.981693594706982		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.981693594706982 | validation: 1.8991233166059396]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.913470787221193		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.913470787221193 | validation: 2.4420174510425827]
	TIME [epoch: 8.38 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1553206003991217		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.1553206003991217 | validation: 2.7889619380634416]
	TIME [epoch: 8.39 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1550496813469495		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.1550496813469495 | validation: 1.9314888652776716]
	TIME [epoch: 8.37 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9717123664397862		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9717123664397862 | validation: 2.0121820550467047]
	TIME [epoch: 8.37 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.103410594728212		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.103410594728212 | validation: 2.065230270957438]
	TIME [epoch: 8.39 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7569806545504651		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.7569806545504651 | validation: 2.3119371925953205]
	TIME [epoch: 8.33 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8676700699280142		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.8676700699280142 | validation: 4.220942874652605]
	TIME [epoch: 8.36 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8808337950414713		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.8808337950414713 | validation: 2.037892995410295]
	TIME [epoch: 8.35 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9259755624311352		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.9259755624311352 | validation: 1.7091365339256064]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.725265286026726		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.725265286026726 | validation: 5.295194160582366]
	TIME [epoch: 8.32 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.860766263913377		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.860766263913377 | validation: 2.274848685910289]
	TIME [epoch: 8.36 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0071077268554802		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.0071077268554802 | validation: 1.9539909067586942]
	TIME [epoch: 8.35 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7471463076820268		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7471463076820268 | validation: 1.7561357670950204]
	TIME [epoch: 8.32 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6228677196794412		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6228677196794412 | validation: 1.5246677970084375]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6851652657695122		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.6851652657695122 | validation: 1.502282661002]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.806574811984532		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.806574811984532 | validation: 2.194746526910124]
	TIME [epoch: 8.34 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8143292624911123		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.8143292624911123 | validation: 1.9262029123208237]
	TIME [epoch: 8.29 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8026119981902449		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8026119981902449 | validation: 2.2115373514748544]
	TIME [epoch: 8.28 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9966018001063501		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.9966018001063501 | validation: 2.0290749133877704]
	TIME [epoch: 8.28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008644770344768		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.008644770344768 | validation: 1.73066445328432]
	TIME [epoch: 8.29 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6695922936336833		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.6695922936336833 | validation: 2.5303254607222216]
	TIME [epoch: 8.33 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0385412627024255		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.0385412627024255 | validation: 1.9644584155805789]
	TIME [epoch: 8.29 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8624447682439285		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.8624447682439285 | validation: 1.8192990907208606]
	TIME [epoch: 8.28 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7708893875392324		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.7708893875392324 | validation: 1.6195857975316756]
	TIME [epoch: 8.28 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.71579748485079		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.71579748485079 | validation: 1.478200895958295]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4946480385694882		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.4946480385694882 | validation: 4.420965337191806]
	TIME [epoch: 8.33 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8641070906588446		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.8641070906588446 | validation: 1.585102271509257]
	TIME [epoch: 8.28 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7230450472002061		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.7230450472002061 | validation: 1.7769112889878835]
	TIME [epoch: 8.28 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.671492594562332		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.671492594562332 | validation: 1.6905155638692486]
	TIME [epoch: 8.28 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5718039496611138		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.5718039496611138 | validation: 1.8188879598958554]
	TIME [epoch: 8.28 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5166510542922433		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5166510542922433 | validation: 1.667980932490984]
	TIME [epoch: 8.33 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.589262455818143		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.589262455818143 | validation: 2.06997295575902]
	TIME [epoch: 8.28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087422121483509		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.087422121483509 | validation: 1.7790042418600573]
	TIME [epoch: 8.28 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343322475849024		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.343322475849024 | validation: 2.5966171280307204]
	TIME [epoch: 8.28 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2394598959617884		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.2394598959617884 | validation: 2.0230021547879953]
	TIME [epoch: 8.28 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8902460307756355		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.8902460307756355 | validation: 1.6277254254171232]
	TIME [epoch: 8.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7386136627015876		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.7386136627015876 | validation: 1.723457236973763]
	TIME [epoch: 8.32 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6904504403459282		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.6904504403459282 | validation: 1.6599208714041898]
	TIME [epoch: 8.28 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5397008544048552		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.5397008544048552 | validation: 1.6844194706900781]
	TIME [epoch: 8.28 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6259767362105542		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.6259767362105542 | validation: 2.1075207024473412]
	TIME [epoch: 8.28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8728388042118693		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.8728388042118693 | validation: 1.6945257758247378]
	TIME [epoch: 8.28 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307920689201992		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.307920689201992 | validation: 2.202736833171865]
	TIME [epoch: 8.32 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3315960279694745		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.3315960279694745 | validation: 1.8269058248486596]
	TIME [epoch: 8.29 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.569768049151128		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.569768049151128 | validation: 1.9289697242749924]
	TIME [epoch: 8.32 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.602749258228376		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.602749258228376 | validation: 1.5238950198161803]
	TIME [epoch: 8.37 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6556613385181607		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.6556613385181607 | validation: 1.8696810578996064]
	TIME [epoch: 8.38 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5747067324957245		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.5747067324957245 | validation: 1.397763649799745]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.628769629403371		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.628769629403371 | validation: 1.258891723935216]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.499743167994247		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.499743167994247 | validation: 1.343335708195843]
	TIME [epoch: 8.38 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2190015840874782		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.2190015840874782 | validation: 1.500957438511492]
	TIME [epoch: 8.38 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5955142236587543		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.5955142236587543 | validation: 1.2792767587002558]
	TIME [epoch: 8.39 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3025973081094113		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.3025973081094113 | validation: 1.0917226519926313]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273753358675957		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.273753358675957 | validation: 1.4994060832434337]
	TIME [epoch: 8.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.287269998143743		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.287269998143743 | validation: 1.4508191092906526]
	TIME [epoch: 8.37 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6491292653914777		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6491292653914777 | validation: 1.0177660796654493]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.468671401650175		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.468671401650175 | validation: 1.3189704296739815]
	TIME [epoch: 8.43 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526605715433541		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.526605715433541 | validation: 1.4665239037637894]
	TIME [epoch: 8.41 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5587335329022594		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.5587335329022594 | validation: 1.063395392311143]
	TIME [epoch: 8.44 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4578126885524285		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.4578126885524285 | validation: 1.1615629664942413]
	TIME [epoch: 8.41 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4259181026072616		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4259181026072616 | validation: 1.8484479932484006]
	TIME [epoch: 8.41 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4253370814671429		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.4253370814671429 | validation: 1.1322308562016863]
	TIME [epoch: 8.42 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4157476935361994		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4157476935361994 | validation: 1.1748620670281589]
	TIME [epoch: 8.41 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4250016096953828		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.4250016096953828 | validation: 1.9475624898954842]
	TIME [epoch: 8.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3813128323763921		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.3813128323763921 | validation: 1.6558313287105597]
	TIME [epoch: 8.42 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4965201994525683		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.4965201994525683 | validation: 1.6209310503142138]
	TIME [epoch: 8.41 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5114823475610728		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.5114823475610728 | validation: 1.095281220920756]
	TIME [epoch: 8.41 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2516616589006209		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.2516616589006209 | validation: 1.0534491654677556]
	TIME [epoch: 8.41 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2153700948005317		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.2153700948005317 | validation: 1.2775982976260323]
	TIME [epoch: 8.42 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6038194367058667		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6038194367058667 | validation: 1.14082881438602]
	TIME [epoch: 8.44 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1904932596933275		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1904932596933275 | validation: 1.1404686168338911]
	TIME [epoch: 8.41 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111780044331716		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.111780044331716 | validation: 1.1251788632216901]
	TIME [epoch: 8.41 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888531405829864		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.2888531405829864 | validation: 1.0127268779569405]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5498230578942902		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.5498230578942902 | validation: 2.175658298393577]
	TIME [epoch: 8.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5532573022221206		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.5532573022221206 | validation: 1.5601958561178413]
	TIME [epoch: 8.46 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6131007670910378		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.6131007670910378 | validation: 1.268254893714539]
	TIME [epoch: 8.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137315137619866		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.137315137619866 | validation: 1.495802170682321]
	TIME [epoch: 8.39 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099810033753145		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.099810033753145 | validation: 1.2924243031014113]
	TIME [epoch: 8.41 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4015630326104989		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.4015630326104989 | validation: 1.423968135384174]
	TIME [epoch: 8.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2010238827226407		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.2010238827226407 | validation: 0.975612855198818]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1006197006111844		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.1006197006111844 | validation: 0.9450332740007508]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636748358048205		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0636748358048205 | validation: 1.794609263643363]
	TIME [epoch: 8.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5669926997567858		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.5669926997567858 | validation: 1.5293275886960118]
	TIME [epoch: 8.41 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3893245093985986		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.3893245093985986 | validation: 1.2334843883967972]
	TIME [epoch: 8.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3063622204532852		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.3063622204532852 | validation: 0.8715345243772028]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009835257606077		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.009835257606077 | validation: 1.3364379576670566]
	TIME [epoch: 8.34 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238693381203952		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.238693381203952 | validation: 2.6731637269385957]
	TIME [epoch: 8.32 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1151991384869944		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.1151991384869944 | validation: 2.1961274412489447]
	TIME [epoch: 8.31 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7847892708651367		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.7847892708651367 | validation: 2.242771774567232]
	TIME [epoch: 8.31 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.553907927358648		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.553907927358648 | validation: 2.239414889655511]
	TIME [epoch: 8.33 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7704363637640983		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.7704363637640983 | validation: 1.734070131834462]
	TIME [epoch: 8.31 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9523634821318834		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.9523634821318834 | validation: 1.7027577047562827]
	TIME [epoch: 8.31 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4586417381534384		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.4586417381534384 | validation: 1.2813640744020345]
	TIME [epoch: 8.31 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193837595870393		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.193837595870393 | validation: 1.2185297487651088]
	TIME [epoch: 8.28 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302385629139674		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.2302385629139674 | validation: 0.8649695018019667]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016633997924237		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.1016633997924237 | validation: 1.2554788948121884]
	TIME [epoch: 8.34 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877183343234038		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.0877183343234038 | validation: 0.9952569984959723]
	TIME [epoch: 8.29 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1704574779748904		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1704574779748904 | validation: 0.922135132554923]
	TIME [epoch: 8.29 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3624910195748077		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.3624910195748077 | validation: 2.2907760228216807]
	TIME [epoch: 8.29 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359678032288859		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.7359678032288859 | validation: 1.4613985129475409]
	TIME [epoch: 8.29 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1427442124209062		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.1427442124209062 | validation: 0.8226583463597883]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1102908144048083		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.1102908144048083 | validation: 1.2916981158119514]
	TIME [epoch: 8.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1033197447182133		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1033197447182133 | validation: 1.0420604582590574]
	TIME [epoch: 8.29 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9882450553489501		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.9882450553489501 | validation: 0.8642928000366705]
	TIME [epoch: 8.29 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1117317362812447		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.1117317362812447 | validation: 1.494282137560464]
	TIME [epoch: 8.28 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784485455356458		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0784485455356458 | validation: 1.142243964435147]
	TIME [epoch: 8.33 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8804395495107906		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8804395495107906 | validation: 1.3949060235718873]
	TIME [epoch: 8.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1106966378818866		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.1106966378818866 | validation: 2.0544930377485056]
	TIME [epoch: 8.29 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2008996935747873		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2008996935747873 | validation: 1.0033640983337833]
	TIME [epoch: 8.29 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9831380528170601		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.9831380528170601 | validation: 0.9780573682110814]
	TIME [epoch: 8.29 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837082587811583		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.1837082587811583 | validation: 0.8563440289322997]
	TIME [epoch: 8.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1114546349737306		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.1114546349737306 | validation: 1.0812877941221686]
	TIME [epoch: 8.33 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9879220537913934		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9879220537913934 | validation: 0.7765255923171459]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9111036044465395		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9111036044465395 | validation: 1.5309108995981542]
	TIME [epoch: 8.29 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9797666027407888		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.9797666027407888 | validation: 1.0042239872530963]
	TIME [epoch: 8.28 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9780279838960284		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9780279838960284 | validation: 1.0695716495228489]
	TIME [epoch: 8.28 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822641805536516		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9822641805536516 | validation: 1.389928354572308]
	TIME [epoch: 8.32 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0141189991283333		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.0141189991283333 | validation: 0.7765610817960313]
	TIME [epoch: 8.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1235286486822322		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.1235286486822322 | validation: 1.068678216069728]
	TIME [epoch: 8.28 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1141091305347643		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.1141091305347643 | validation: 1.5236146626151275]
	TIME [epoch: 8.29 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1676002067250684		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1676002067250684 | validation: 0.8681598311335623]
	TIME [epoch: 8.29 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8237732581221017		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8237732581221017 | validation: 1.34782094591981]
	TIME [epoch: 8.33 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5235761311504272		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.5235761311504272 | validation: 1.976380815062154]
	TIME [epoch: 8.31 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343093976171875		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.343093976171875 | validation: 0.8134835765682392]
	TIME [epoch: 8.29 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8519449956837433		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8519449956837433 | validation: 0.8287152599032245]
	TIME [epoch: 8.29 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8528834768378597		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8528834768378597 | validation: 1.1569910445410474]
	TIME [epoch: 8.29 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0838672051005303		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0838672051005303 | validation: 1.0455399753245869]
	TIME [epoch: 8.38 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3123015743892101		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.3123015743892101 | validation: 0.7898011749869829]
	TIME [epoch: 8.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2725820083727715		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2725820083727715 | validation: 1.358849223672801]
	TIME [epoch: 8.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2622746196194201		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.2622746196194201 | validation: 1.2775416568187508]
	TIME [epoch: 8.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2388661461549006		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.2388661461549006 | validation: 1.022855437623317]
	TIME [epoch: 8.39 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010344089516865		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.010344089516865 | validation: 1.1739150702797836]
	TIME [epoch: 8.41 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8823301425220244		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8823301425220244 | validation: 0.8630796635922464]
	TIME [epoch: 8.43 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8344996822314753		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8344996822314753 | validation: 2.9044055364096004]
	TIME [epoch: 8.39 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9681894338175678		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.9681894338175678 | validation: 1.461478456484251]
	TIME [epoch: 8.38 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4128295315370734		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.4128295315370734 | validation: 1.4014715012031673]
	TIME [epoch: 8.38 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2940774593590387		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.2940774593590387 | validation: 0.8968517677421929]
	TIME [epoch: 8.39 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605134485828332		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.1605134485828332 | validation: 1.0221668541691282]
	TIME [epoch: 8.44 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143351618724266		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8143351618724266 | validation: 0.6084522824619532]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8767893908545307		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8767893908545307 | validation: 1.535907185959806]
	TIME [epoch: 8.42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9417871721769278		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9417871721769278 | validation: 2.5361912630366312]
	TIME [epoch: 8.41 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7970439739345423		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.7970439739345423 | validation: 1.728194793169677]
	TIME [epoch: 8.42 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3775575226111951		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.3775575226111951 | validation: 1.3320288958156357]
	TIME [epoch: 8.41 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364341059753023		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1364341059753023 | validation: 1.248708890101752]
	TIME [epoch: 8.46 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0844465065893203		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0844465065893203 | validation: 0.8812154668541754]
	TIME [epoch: 8.41 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217473145748696		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7217473145748696 | validation: 0.8119511961376331]
	TIME [epoch: 8.41 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9128507582482145		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.9128507582482145 | validation: 0.8581289209066996]
	TIME [epoch: 8.41 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732110719906785		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7732110719906785 | validation: 0.5867841477456681]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400441335675977		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.8400441335675977 | validation: 0.9347232828765726]
	TIME [epoch: 8.47 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1576735620912062		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.1576735620912062 | validation: 1.100258071488824]
	TIME [epoch: 8.42 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9456478491231173		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9456478491231173 | validation: 1.3525690185017332]
	TIME [epoch: 8.41 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043063312544989		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.0043063312544989 | validation: 0.8454478539059842]
	TIME [epoch: 8.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333606879290806		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8333606879290806 | validation: 0.8435531640943164]
	TIME [epoch: 8.41 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7560077417960697		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7560077417960697 | validation: 2.410651999803297]
	TIME [epoch: 8.45 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5547023367796187		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.5547023367796187 | validation: 1.2130653281493464]
	TIME [epoch: 8.41 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899947656234233		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.899947656234233 | validation: 0.9317979266227496]
	TIME [epoch: 8.41 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8493222368665212		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8493222368665212 | validation: 0.7714187285618387]
	TIME [epoch: 8.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532086383216764		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7532086383216764 | validation: 0.7304272912273919]
	TIME [epoch: 8.39 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8218138269477399		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8218138269477399 | validation: 1.500227623929348]
	TIME [epoch: 8.41 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1557956907696938		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.1557956907696938 | validation: 1.3430230676584234]
	TIME [epoch: 8.44 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8537771505890679		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8537771505890679 | validation: 0.8938202666019723]
	TIME [epoch: 8.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8864675906111065		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8864675906111065 | validation: 0.9016398219032771]
	TIME [epoch: 8.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732686666156823		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.0732686666156823 | validation: 0.684830790647259]
	TIME [epoch: 8.43 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7440489309028135		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7440489309028135 | validation: 0.8573160972563008]
	TIME [epoch: 8.42 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7628668520403087		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7628668520403087 | validation: 0.5331537354774977]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432286295363622		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8432286295363622 | validation: 0.5954350702665202]
	TIME [epoch: 8.31 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9135563206764417		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.9135563206764417 | validation: 0.8755190871953051]
	TIME [epoch: 8.32 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9977473515920734		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.9977473515920734 | validation: 0.7350405466482488]
	TIME [epoch: 8.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2276612037334795		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.2276612037334795 | validation: 0.8737089936139621]
	TIME [epoch: 8.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708726268530183		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7708726268530183 | validation: 0.5870177675092476]
	TIME [epoch: 8.36 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809877587993922		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7809877587993922 | validation: 0.7722186312293953]
	TIME [epoch: 8.31 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8231631444044536		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8231631444044536 | validation: 1.1409965048552446]
	TIME [epoch: 8.29 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9264093134899518		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.9264093134899518 | validation: 0.9651321845895976]
	TIME [epoch: 8.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704267673390942		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7704267673390942 | validation: 0.8370698705413111]
	TIME [epoch: 8.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755112389264245		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7755112389264245 | validation: 0.7134397382397758]
	TIME [epoch: 8.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7716167769915807		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7716167769915807 | validation: 0.6987608640207151]
	TIME [epoch: 8.32 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333843429034729		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7333843429034729 | validation: 0.6289551308616016]
	TIME [epoch: 8.28 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744766463890742		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.744766463890742 | validation: 0.5718545663858268]
	TIME [epoch: 8.28 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476535534412154		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8476535534412154 | validation: 2.1908636026439003]
	TIME [epoch: 8.28 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5384633324365318		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.5384633324365318 | validation: 1.37129145332282]
	TIME [epoch: 8.27 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.247239361254176		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.247239361254176 | validation: 0.917083107393675]
	TIME [epoch: 8.33 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0123227403642079		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0123227403642079 | validation: 1.6435066203128723]
	TIME [epoch: 8.29 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046046474981061		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.046046474981061 | validation: 0.5525402943485327]
	TIME [epoch: 8.28 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617904268510305		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7617904268510305 | validation: 0.7336947257248967]
	TIME [epoch: 8.28 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7454518865308186		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7454518865308186 | validation: 0.8119919835301512]
	TIME [epoch: 8.28 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471259638423693		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7471259638423693 | validation: 1.1849294562068151]
	TIME [epoch: 8.28 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7503860334229894		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7503860334229894 | validation: 0.7635448163096211]
	TIME [epoch: 8.32 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425615425562762		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.8425615425562762 | validation: 0.4739232117074488]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1020465508199366		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.1020465508199366 | validation: 1.19452587492245]
	TIME [epoch: 8.29 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8365844410876231		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.8365844410876231 | validation: 0.8284988214529506]
	TIME [epoch: 8.29 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432052322393315		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8432052322393315 | validation: 1.170634759378582]
	TIME [epoch: 8.29 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181322204577968		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8181322204577968 | validation: 0.6074265850372923]
	TIME [epoch: 8.32 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6725988192740323		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.6725988192740323 | validation: 0.8119190854352785]
	TIME [epoch: 8.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6546618486571926		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6546618486571926 | validation: 0.9059027553153811]
	TIME [epoch: 8.29 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808860526955049		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7808860526955049 | validation: 0.5223017467751626]
	TIME [epoch: 8.29 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734160209211606		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.734160209211606 | validation: 1.9712400331084545]
	TIME [epoch: 8.29 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1075315336044471		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.1075315336044471 | validation: 0.6951261050035014]
	TIME [epoch: 8.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8709454894777438		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.8709454894777438 | validation: 0.7902015783250836]
	TIME [epoch: 8.33 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015612877600981		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7015612877600981 | validation: 0.46915807460777337]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5715211095534224		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.5715211095534224 | validation: 1.1390608523913572]
	TIME [epoch: 8.29 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644732253165608		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7644732253165608 | validation: 1.2155865645914976]
	TIME [epoch: 8.29 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9543866130812189		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.9543866130812189 | validation: 0.8928912181616436]
	TIME [epoch: 8.29 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314517928370599		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7314517928370599 | validation: 0.5684704480016347]
	TIME [epoch: 8.32 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.896951288424204		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.896951288424204 | validation: 0.6205828533704558]
	TIME [epoch: 8.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034951677870278		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7034951677870278 | validation: 0.5696544863369708]
	TIME [epoch: 8.29 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320302093708875		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7320302093708875 | validation: 1.4433852612139189]
	TIME [epoch: 8.35 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9832796148077397		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9832796148077397 | validation: 0.5138821941683335]
	TIME [epoch: 8.38 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252658926286803		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6252658926286803 | validation: 0.46848592000106415]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7937620776243035		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7937620776243035 | validation: 1.9488115174468705]
	TIME [epoch: 8.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0963932014409188		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.0963932014409188 | validation: 0.6272877768836433]
	TIME [epoch: 8.38 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6720573472264981		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6720573472264981 | validation: 0.6417353988496521]
	TIME [epoch: 8.38 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183766311298039		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.6183766311298039 | validation: 0.5901120938796784]
	TIME [epoch: 8.38 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409738210524372		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5409738210524372 | validation: 0.5689344250384157]
	TIME [epoch: 8.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579709761604946		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.6579709761604946 | validation: 0.5868429558373338]
	TIME [epoch: 8.41 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8665457980440657		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8665457980440657 | validation: 0.7457334240779275]
	TIME [epoch: 8.37 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059997769281067		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7059997769281067 | validation: 0.8682046802128807]
	TIME [epoch: 8.41 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9262328194008311		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.9262328194008311 | validation: 0.9078616864580522]
	TIME [epoch: 8.39 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8003264797697672		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.8003264797697672 | validation: 0.4793207573187276]
	TIME [epoch: 8.41 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251357808682039		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5251357808682039 | validation: 0.4828147453954796]
	TIME [epoch: 8.45 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764997141600095		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.764997141600095 | validation: 0.6004559508511855]
	TIME [epoch: 8.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821953718150132		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6821953718150132 | validation: 0.4422968213421413]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806856920751369		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5806856920751369 | validation: 1.8103018972192015]
	TIME [epoch: 8.42 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2635168003056494		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.2635168003056494 | validation: 0.7030194080277208]
	TIME [epoch: 8.41 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9769232501627213		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.9769232501627213 | validation: 0.748531891508369]
	TIME [epoch: 8.45 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9046619552570164		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9046619552570164 | validation: 0.7248049240531362]
	TIME [epoch: 8.43 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576410093367408		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7576410093367408 | validation: 0.5255112142618497]
	TIME [epoch: 8.43 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6330149288960012		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6330149288960012 | validation: 0.7274315947346615]
	TIME [epoch: 8.42 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865595040836034		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6865595040836034 | validation: 0.5341623025614921]
	TIME [epoch: 8.43 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061304471852997		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6061304471852997 | validation: 0.7366263857273059]
	TIME [epoch: 8.44 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084434996294038		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7084434996294038 | validation: 0.5541240913378519]
	TIME [epoch: 8.42 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871069441246463		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5871069441246463 | validation: 0.49293981214405447]
	TIME [epoch: 8.38 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127596213539302		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5127596213539302 | validation: 0.3473474402123814]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107584385554396		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5107584385554396 | validation: 0.4220133809158161]
	TIME [epoch: 8.38 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.461246733489487		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.461246733489487 | validation: 0.5117560628453439]
	TIME [epoch: 8.35 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7610592418476451		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7610592418476451 | validation: 0.36335431362166387]
	TIME [epoch: 8.39 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341223979965886		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5341223979965886 | validation: 0.3954004539728503]
	TIME [epoch: 8.41 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7978824360459034		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7978824360459034 | validation: 1.1007180804928858]
	TIME [epoch: 8.41 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205921639477705		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7205921639477705 | validation: 0.6630560100408127]
	TIME [epoch: 8.41 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49589387876931723		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.49589387876931723 | validation: 0.6788101432637733]
	TIME [epoch: 8.41 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974711287125668		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5974711287125668 | validation: 0.6669488117243568]
	TIME [epoch: 8.46 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736923529221031		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.736923529221031 | validation: 0.9432582887115246]
	TIME [epoch: 8.42 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409382501542402		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7409382501542402 | validation: 0.3461516189128828]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.547467432565503		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.547467432565503 | validation: 0.27311781240499355]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47040928084063494		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.47040928084063494 | validation: 0.39654564142705384]
	TIME [epoch: 8.29 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518219383156551		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.518219383156551 | validation: 0.4299321222224711]
	TIME [epoch: 8.32 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4197396477714681		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.4197396477714681 | validation: 0.7752781084856464]
	TIME [epoch: 8.33 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780992714579039		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5780992714579039 | validation: 0.7411923052545876]
	TIME [epoch: 8.31 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187267664343348		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7187267664343348 | validation: 1.8292252529173125]
	TIME [epoch: 8.34 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9772356385287831		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9772356385287831 | validation: 1.0187197531824528]
	TIME [epoch: 8.33 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9296154827489854		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.9296154827489854 | validation: 0.8997225772782396]
	TIME [epoch: 8.34 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265605447184187		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6265605447184187 | validation: 1.4435107722990446]
	TIME [epoch: 8.33 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1228790544870562		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.1228790544870562 | validation: 0.5637701971082856]
	TIME [epoch: 8.29 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8757351182622887		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8757351182622887 | validation: 0.9010951143039787]
	TIME [epoch: 8.29 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681413576184129		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6681413576184129 | validation: 0.4943681881299911]
	TIME [epoch: 8.29 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8493576291618662		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8493576291618662 | validation: 1.0437160119248772]
	TIME [epoch: 8.28 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0185275799574864		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.0185275799574864 | validation: 0.8864585971026617]
	TIME [epoch: 8.32 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247707261590908		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.0247707261590908 | validation: 1.1183112602526954]
	TIME [epoch: 8.29 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526893258302334		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7526893258302334 | validation: 0.8944622145524853]
	TIME [epoch: 8.28 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6274784124629265		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6274784124629265 | validation: 1.2639785282696048]
	TIME [epoch: 8.28 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9242288880435219		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9242288880435219 | validation: 1.8280549393031125]
	TIME [epoch: 8.28 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268858288530565		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.0268858288530565 | validation: 0.8684852626783829]
	TIME [epoch: 8.28 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179841887428892		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7179841887428892 | validation: 0.7907535546943663]
	TIME [epoch: 8.32 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351240754614418		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6351240754614418 | validation: 0.55564462896419]
	TIME [epoch: 8.28 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5407823295437506		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5407823295437506 | validation: 0.5202808909006336]
	TIME [epoch: 8.28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4778001848331335		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.4778001848331335 | validation: 0.3575192367494005]
	TIME [epoch: 8.28 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206104660636694		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6206104660636694 | validation: 0.4815752308719527]
	TIME [epoch: 8.28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023349085693662		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6023349085693662 | validation: 0.6519875091682376]
	TIME [epoch: 8.32 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539596875046914		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.539596875046914 | validation: 2.0679282517719897]
	TIME [epoch: 8.29 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1244865638977315		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.1244865638977315 | validation: 0.4700971175993356]
	TIME [epoch: 8.28 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686805994540579		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5686805994540579 | validation: 1.1470163955454273]
	TIME [epoch: 8.28 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.617605392979075		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.617605392979075 | validation: 0.3515541952492405]
	TIME [epoch: 8.28 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45557951115373096		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.45557951115373096 | validation: 0.4864318676930843]
	TIME [epoch: 8.29 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416374861420874		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5416374861420874 | validation: 0.4589273597998374]
	TIME [epoch: 8.33 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580120495756444		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5580120495756444 | validation: 0.43061984365857764]
	TIME [epoch: 8.29 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688285113575309		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.688285113575309 | validation: 0.5530145921593239]
	TIME [epoch: 8.28 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409579031838049		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5409579031838049 | validation: 0.4952426662459386]
	TIME [epoch: 8.28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865416277662106		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.4865416277662106 | validation: 0.4788836941775526]
	TIME [epoch: 8.28 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438571703092985		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5438571703092985 | validation: 0.7992133635953789]
	TIME [epoch: 8.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7637703019675623		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.7637703019675623 | validation: 0.4661047003047317]
	TIME [epoch: 8.31 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434356118028406		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5434356118028406 | validation: 0.43200106101895985]
	TIME [epoch: 8.28 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453296059047484		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4453296059047484 | validation: 0.454215985492162]
	TIME [epoch: 8.28 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633792274396826		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.633792274396826 | validation: 0.3427476988123422]
	TIME [epoch: 8.28 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766823779557353		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4766823779557353 | validation: 0.7067524096432228]
	TIME [epoch: 8.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672038011734171		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.4672038011734171 | validation: 0.41560824181795086]
	TIME [epoch: 8.33 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147081951535975		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4147081951535975 | validation: 0.4985761944179383]
	TIME [epoch: 8.32 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353435868879083		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6353435868879083 | validation: 0.5869935162233043]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923186866451782		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5923186866451782 | validation: 0.8666876231286935]
	TIME [epoch: 8.35 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48688974171087585		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.48688974171087585 | validation: 0.4742199274463503]
	TIME [epoch: 8.31 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.600947243944791		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.600947243944791 | validation: 0.7380369242115412]
	TIME [epoch: 8.33 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49778013963647805		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.49778013963647805 | validation: 0.4039545660335282]
	TIME [epoch: 8.34 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389118555654247		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7389118555654247 | validation: 0.47879979569239184]
	TIME [epoch: 8.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.579461794534482		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.579461794534482 | validation: 0.6271008399350364]
	TIME [epoch: 8.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683337832992447		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.4683337832992447 | validation: 0.6481769774119416]
	TIME [epoch: 8.31 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385775300615147		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5385775300615147 | validation: 1.0801607025834503]
	TIME [epoch: 8.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454246423123512		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6454246423123512 | validation: 0.3976458698786167]
	TIME [epoch: 8.35 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49827462784319154		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.49827462784319154 | validation: 0.4560385188536014]
	TIME [epoch: 8.31 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376196579665331		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.4376196579665331 | validation: 0.7411078350807772]
	TIME [epoch: 8.32 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49053258019693746		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.49053258019693746 | validation: 0.47444803288388215]
	TIME [epoch: 8.33 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891615354600999		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.4891615354600999 | validation: 0.30791374043707875]
	TIME [epoch: 8.31 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513960931402111		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4513960931402111 | validation: 0.3631519891447717]
	TIME [epoch: 8.32 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4244711139494399		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4244711139494399 | validation: 0.4157071091405976]
	TIME [epoch: 8.35 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4923780935593862		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.4923780935593862 | validation: 0.38839769788849154]
	TIME [epoch: 8.32 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945831577725399		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.4945831577725399 | validation: 0.39743962658986676]
	TIME [epoch: 8.33 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4436645486239079		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4436645486239079 | validation: 0.3576743241287753]
	TIME [epoch: 8.31 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46228691915547465		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.46228691915547465 | validation: 0.5812147689470821]
	TIME [epoch: 8.31 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511611930856657		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.511611930856657 | validation: 0.4091298323677316]
	TIME [epoch: 8.36 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4450924607721752		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4450924607721752 | validation: 0.5900365055303844]
	TIME [epoch: 8.35 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641850505160329		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4641850505160329 | validation: 0.33803561431668544]
	TIME [epoch: 8.32 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47085018171608606		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.47085018171608606 | validation: 0.38101704782629253]
	TIME [epoch: 8.32 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4644448980993335		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.4644448980993335 | validation: 0.3845143001981871]
	TIME [epoch: 8.31 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48822116469620513		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.48822116469620513 | validation: 0.3334569066526546]
	TIME [epoch: 8.31 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024916947795792		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4024916947795792 | validation: 0.44327287850227914]
	TIME [epoch: 8.35 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4889106122390395		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.4889106122390395 | validation: 0.31140226809641314]
	TIME [epoch: 8.32 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120113219679318		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7120113219679318 | validation: 1.176567494128491]
	TIME [epoch: 8.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7935458814697395		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7935458814697395 | validation: 0.4054450619049863]
	TIME [epoch: 8.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025932591150038		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6025932591150038 | validation: 0.6348326446454592]
	TIME [epoch: 8.31 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499563672207697		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5499563672207697 | validation: 0.4636914673137513]
	TIME [epoch: 8.36 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119320490500896		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5119320490500896 | validation: 0.9944222415847566]
	TIME [epoch: 8.33 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000327170831201		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6000327170831201 | validation: 0.2817894138799877]
	TIME [epoch: 8.31 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39650624053702066		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.39650624053702066 | validation: 0.5526832776917743]
	TIME [epoch: 8.31 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626365229890178		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5626365229890178 | validation: 0.26429068200193806]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562205962504237		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3562205962504237 | validation: 0.39428798049179914]
	TIME [epoch: 8.34 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365681546488985		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.365681546488985 | validation: 0.7449565177049916]
	TIME [epoch: 8.37 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067453404029153		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5067453404029153 | validation: 0.9210312256625081]
	TIME [epoch: 8.34 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650163750220551		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.4650163750220551 | validation: 0.9286303326021667]
	TIME [epoch: 8.37 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2234079168883136		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.2234079168883136 | validation: 1.0464121779999136]
	TIME [epoch: 8.36 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211775284278363		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.9211775284278363 | validation: 0.3781366336745209]
	TIME [epoch: 8.34 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44077028890620407		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.44077028890620407 | validation: 0.29019113431949756]
	TIME [epoch: 8.36 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38031644181140023		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.38031644181140023 | validation: 0.6334984578568894]
	TIME [epoch: 8.33 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761976534971222		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5761976534971222 | validation: 0.7233221724256971]
	TIME [epoch: 8.32 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4965879715941273		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.4965879715941273 | validation: 0.44405020385317806]
	TIME [epoch: 8.32 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283490383880759		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.4283490383880759 | validation: 1.0465365524411383]
	TIME [epoch: 8.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165943239857893		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.8165943239857893 | validation: 0.5630176267127773]
	TIME [epoch: 8.33 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39395737570578426		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.39395737570578426 | validation: 0.328008053979344]
	TIME [epoch: 8.38 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35714327888236397		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.35714327888236397 | validation: 0.44897060548248957]
	TIME [epoch: 8.32 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946937929427028		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3946937929427028 | validation: 0.42086373818319267]
	TIME [epoch: 8.32 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41592370842637394		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.41592370842637394 | validation: 0.31925690942999907]
	TIME [epoch: 8.32 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29140571282342453		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.29140571282342453 | validation: 0.3916745706655722]
	TIME [epoch: 8.34 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36697305726523544		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.36697305726523544 | validation: 0.41974703635971666]
	TIME [epoch: 8.39 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776982622837251		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4776982622837251 | validation: 0.4065346611520411]
	TIME [epoch: 8.36 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523216212410675		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4523216212410675 | validation: 0.22746155089472486]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300176175967248		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7300176175967248 | validation: 0.8170607611475404]
	TIME [epoch: 8.31 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46195723237885294		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.46195723237885294 | validation: 0.30716247257496465]
	TIME [epoch: 8.32 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316515641372642		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3316515641372642 | validation: 0.4392126909402833]
	TIME [epoch: 8.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43313965898278		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.43313965898278 | validation: 0.42772129593032754]
	TIME [epoch: 8.34 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.413056661562306		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.413056661562306 | validation: 0.5157122896897501]
	TIME [epoch: 8.33 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426201083635978		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.426201083635978 | validation: 0.4659736495301094]
	TIME [epoch: 8.32 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550570368003566		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4550570368003566 | validation: 0.4120295115219507]
	TIME [epoch: 8.31 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4368924087761951		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4368924087761951 | validation: 0.7159766210368721]
	TIME [epoch: 8.33 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48135518094466256		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.48135518094466256 | validation: 0.5933398743292071]
	TIME [epoch: 8.36 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5417051873912421		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5417051873912421 | validation: 0.5141062658373898]
	TIME [epoch: 8.36 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553139119895584		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.4553139119895584 | validation: 0.3334890223551813]
	TIME [epoch: 8.33 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3829442679992757		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3829442679992757 | validation: 0.24220701796248972]
	TIME [epoch: 8.32 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352495623871673		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.352495623871673 | validation: 0.5134401581493429]
	TIME [epoch: 8.31 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571070990060991		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7571070990060991 | validation: 1.1963491949563607]
	TIME [epoch: 8.33 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.580656247446831		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.580656247446831 | validation: 0.7087084172779983]
	TIME [epoch: 8.33 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4564756734797337		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.4564756734797337 | validation: 0.3427125195483519]
	TIME [epoch: 8.31 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377622387285385		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3377622387285385 | validation: 0.9284884970664875]
	TIME [epoch: 8.33 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49009622838797284		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.49009622838797284 | validation: 0.29679324045034483]
	TIME [epoch: 8.32 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480034431627541		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3480034431627541 | validation: 0.2704439189326805]
	TIME [epoch: 8.33 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391469449434763		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3391469449434763 | validation: 0.3633137111278211]
	TIME [epoch: 8.36 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088012776653881		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3088012776653881 | validation: 0.45574221732941667]
	TIME [epoch: 8.33 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216169470688988		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.6216169470688988 | validation: 0.496573346178176]
	TIME [epoch: 8.36 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683442076969001		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4683442076969001 | validation: 0.6798297871308654]
	TIME [epoch: 8.33 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36403745771524876		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.36403745771524876 | validation: 0.4735860084736395]
	TIME [epoch: 8.31 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4803778631239019		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.4803778631239019 | validation: 0.6774307905632126]
	TIME [epoch: 8.31 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840713391436744		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5840713391436744 | validation: 0.44663932677264484]
	TIME [epoch: 8.36 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186183657313998		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.3186183657313998 | validation: 0.33367774135560563]
	TIME [epoch: 8.31 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568060313217768		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3568060313217768 | validation: 0.33097538358339096]
	TIME [epoch: 8.32 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31046521260015636		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.31046521260015636 | validation: 0.5120857174037513]
	TIME [epoch: 8.35 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4366287484087601		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4366287484087601 | validation: 0.31197760868532254]
	TIME [epoch: 8.32 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817371709512669		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3817371709512669 | validation: 0.34229378095628815]
	TIME [epoch: 8.33 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609489613606866		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3609489613606866 | validation: 0.43917319022010665]
	TIME [epoch: 8.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941382082077417		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3941382082077417 | validation: 0.5813872971759984]
	TIME [epoch: 8.28 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36419951965918473		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.36419951965918473 | validation: 0.4267782530067453]
	TIME [epoch: 8.28 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722200420953327		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5722200420953327 | validation: 0.9204116926142549]
	TIME [epoch: 8.28 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121635043831075		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5121635043831075 | validation: 0.23493399926615138]
	TIME [epoch: 8.32 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897557663317791		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2897557663317791 | validation: 0.4160707587073009]
	TIME [epoch: 8.41 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936469443327171		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3936469443327171 | validation: 0.4619794774926651]
	TIME [epoch: 8.36 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118756343110358		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3118756343110358 | validation: 0.3088857215435781]
	TIME [epoch: 8.31 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601317155975532		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3601317155975532 | validation: 0.5065657144855267]
	TIME [epoch: 8.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3770103905613769		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3770103905613769 | validation: 0.4096057230290464]
	TIME [epoch: 8.31 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329207979638964		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.3329207979638964 | validation: 0.30735905358691634]
	TIME [epoch: 8.35 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3613391146328724		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3613391146328724 | validation: 0.2603721431237329]
	TIME [epoch: 8.35 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552811048092218		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.3552811048092218 | validation: 0.34345759127494213]
	TIME [epoch: 8.34 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29831616905801756		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.29831616905801756 | validation: 0.2417491219465017]
	TIME [epoch: 8.35 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947388128307028		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2947388128307028 | validation: 0.2829685931679302]
	TIME [epoch: 8.33 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26051962977538873		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.26051962977538873 | validation: 0.6500081303988869]
	TIME [epoch: 8.32 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5901583393029757		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5901583393029757 | validation: 0.5037830962414139]
	TIME [epoch: 8.38 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677651850074709		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3677651850074709 | validation: 0.35072236901148957]
	TIME [epoch: 8.34 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3493490326452198		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3493490326452198 | validation: 0.3503455176147779]
	TIME [epoch: 8.32 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070372582506216		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.5070372582506216 | validation: 0.4336036936536104]
	TIME [epoch: 8.32 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35914667281454876		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.35914667281454876 | validation: 0.2495903213802173]
	TIME [epoch: 8.36 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37826689637311406		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.37826689637311406 | validation: 0.3275721979406298]
	TIME [epoch: 8.37 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998090057472032		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2998090057472032 | validation: 0.6179297777753581]
	TIME [epoch: 8.37 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089803087697001		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5089803087697001 | validation: 0.9009287088526696]
	TIME [epoch: 8.32 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513534070030555		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5513534070030555 | validation: 0.39329294671607173]
	TIME [epoch: 8.31 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868641413281645		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4868641413281645 | validation: 0.5377344273224206]
	TIME [epoch: 8.31 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38489908686321067		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.38489908686321067 | validation: 0.3012086828661406]
	TIME [epoch: 8.33 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27258017858471145		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.27258017858471145 | validation: 0.31229061760952825]
	TIME [epoch: 8.35 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29800965227958925		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.29800965227958925 | validation: 0.29188911775533644]
	TIME [epoch: 8.32 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512818144335214		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2512818144335214 | validation: 0.2015120459868659]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35772334261765604		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.35772334261765604 | validation: 0.3587526973551958]
	TIME [epoch: 8.33 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992049659280452		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5992049659280452 | validation: 1.019251669090261]
	TIME [epoch: 8.31 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5661412201465993		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5661412201465993 | validation: 0.37243638399949536]
	TIME [epoch: 8.33 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733752173641806		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2733752173641806 | validation: 0.25903180629451505]
	TIME [epoch: 8.34 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3262836267425423		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.3262836267425423 | validation: 0.35850705180556597]
	TIME [epoch: 8.31 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30189193871696035		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.30189193871696035 | validation: 0.315261575002418]
	TIME [epoch: 8.31 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31257777195402564		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.31257777195402564 | validation: 0.4035649491792561]
	TIME [epoch: 8.31 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36087931111984795		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.36087931111984795 | validation: 0.30156350873787646]
	TIME [epoch: 8.32 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528913062304496		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3528913062304496 | validation: 0.5842125387545093]
	TIME [epoch: 8.39 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32584154176992985		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.32584154176992985 | validation: 0.31771316183512444]
	TIME [epoch: 8.33 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218597974380071		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6218597974380071 | validation: 0.5625168337939406]
	TIME [epoch: 8.32 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729309344910511		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3729309344910511 | validation: 0.24271566311405932]
	TIME [epoch: 8.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29581651384735236		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.29581651384735236 | validation: 0.4018444771919299]
	TIME [epoch: 8.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314335545484448		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4314335545484448 | validation: 0.3027728593787976]
	TIME [epoch: 8.35 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29003614105548847		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.29003614105548847 | validation: 0.2559801467320957]
	TIME [epoch: 8.31 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776117423621284		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2776117423621284 | validation: 0.25992510216755704]
	TIME [epoch: 8.31 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.381689440230066		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.381689440230066 | validation: 0.5954956336168488]
	TIME [epoch: 8.33 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4783455650350681		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4783455650350681 | validation: 0.4269842761864937]
	TIME [epoch: 8.31 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417353608427044		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.4417353608427044 | validation: 0.2972086476512493]
	TIME [epoch: 8.33 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4158621114379961		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.4158621114379961 | validation: 0.3909659814742054]
	TIME [epoch: 8.36 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976541529969353		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.3976541529969353 | validation: 0.3484868225156922]
	TIME [epoch: 8.32 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38066098851998054		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.38066098851998054 | validation: 0.2657692462752092]
	TIME [epoch: 8.35 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889466923921613		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.2889466923921613 | validation: 0.3172047890285139]
	TIME [epoch: 8.34 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30149567340280137		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.30149567340280137 | validation: 0.5609092082545457]
	TIME [epoch: 8.32 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916509867347414		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3916509867347414 | validation: 0.46018945332365124]
	TIME [epoch: 8.35 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40453222597584376		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.40453222597584376 | validation: 0.22046559635528348]
	TIME [epoch: 8.32 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708478625342616		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2708478625342616 | validation: 0.5055180478703906]
	TIME [epoch: 8.31 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4867648999955785		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.4867648999955785 | validation: 0.36945700237946877]
	TIME [epoch: 8.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28361290146998663		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.28361290146998663 | validation: 0.17406876866679105]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23963872999043526		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.23963872999043526 | validation: 0.3760789316779187]
	TIME [epoch: 8.35 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519891320877676		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.3519891320877676 | validation: 0.1884898796940785]
	TIME [epoch: 8.32 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19609486986020733		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.19609486986020733 | validation: 0.257620799883194]
	TIME [epoch: 8.31 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274450953827853		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.274450953827853 | validation: 0.4119447595432185]
	TIME [epoch: 8.31 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36051380079166345		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.36051380079166345 | validation: 0.3738615051078096]
	TIME [epoch: 8.34 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38842157476736405		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.38842157476736405 | validation: 0.25607536425932526]
	TIME [epoch: 8.37 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35962235492377714		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.35962235492377714 | validation: 0.27878588622756356]
	TIME [epoch: 8.32 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38317811196543766		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.38317811196543766 | validation: 0.3181203161888476]
	TIME [epoch: 8.31 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25882468237771605		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.25882468237771605 | validation: 0.2287130558561379]
	TIME [epoch: 8.31 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413878275097326		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.2413878275097326 | validation: 0.23768109418366634]
	TIME [epoch: 8.29 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32394897927384075		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.32394897927384075 | validation: 0.40134596520024696]
	TIME [epoch: 8.31 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356326678009447		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.3356326678009447 | validation: 0.3045173838181163]
	TIME [epoch: 8.37 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648053528495889		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3648053528495889 | validation: 0.41164180046515914]
	TIME [epoch: 8.31 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41611231996244524		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.41611231996244524 | validation: 0.26881800776221565]
	TIME [epoch: 8.31 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26540797354484597		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.26540797354484597 | validation: 0.34313494555827595]
	TIME [epoch: 8.31 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30381799633563034		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.30381799633563034 | validation: 0.2753389174592923]
	TIME [epoch: 8.31 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24197234105807877		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.24197234105807877 | validation: 0.3192668837594932]
	TIME [epoch: 8.37 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28901491693529985		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.28901491693529985 | validation: 0.29685858949215493]
	TIME [epoch: 8.35 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39457436915036936		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.39457436915036936 | validation: 0.39346901994486716]
	TIME [epoch: 8.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335270187742283		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.335270187742283 | validation: 0.30280850490416156]
	TIME [epoch: 8.31 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2673517702565117		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2673517702565117 | validation: 0.3142854177315865]
	TIME [epoch: 8.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4691823497141343		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4691823497141343 | validation: 0.5512082129815097]
	TIME [epoch: 8.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106541569837936		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.5106541569837936 | validation: 0.3320035194224693]
	TIME [epoch: 8.36 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540897477387532		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.4540897477387532 | validation: 0.43960983086714]
	TIME [epoch: 8.34 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660561767645334		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3660561767645334 | validation: 0.2214890732814479]
	TIME [epoch: 8.33 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546792437521875		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2546792437521875 | validation: 0.18570428476712314]
	TIME [epoch: 8.28 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29055647308750465		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.29055647308750465 | validation: 0.6236940128839101]
	TIME [epoch: 8.28 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46447259184407974		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.46447259184407974 | validation: 0.48851090950062304]
	TIME [epoch: 8.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233236932569472		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3233236932569472 | validation: 0.3224451731829492]
	TIME [epoch: 8.32 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159435224045047		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3159435224045047 | validation: 0.31674220562591676]
	TIME [epoch: 8.28 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29410200801467223		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.29410200801467223 | validation: 0.21690640319322696]
	TIME [epoch: 8.28 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581179971473706		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.2581179971473706 | validation: 0.227870444579416]
	TIME [epoch: 8.28 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21002913470257165		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.21002913470257165 | validation: 0.6219653059861834]
	TIME [epoch: 8.28 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3517672703833468		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3517672703833468 | validation: 0.2051913751314775]
	TIME [epoch: 8.32 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21931167101251592		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.21931167101251592 | validation: 0.4010820201318145]
	TIME [epoch: 8.29 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135138785890708		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3135138785890708 | validation: 0.30081997819516115]
	TIME [epoch: 8.28 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884815786572823		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2884815786572823 | validation: 0.2865990503887105]
	TIME [epoch: 8.28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26681889009082016		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.26681889009082016 | validation: 0.37837630637759023]
	TIME [epoch: 8.28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35332631262871045		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.35332631262871045 | validation: 0.5019621189322133]
	TIME [epoch: 8.29 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35206459881148394		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.35206459881148394 | validation: 0.44712454164340576]
	TIME [epoch: 8.32 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320390694046898		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.320390694046898 | validation: 0.7942110549517661]
	TIME [epoch: 8.29 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39941148566037726		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.39941148566037726 | validation: 0.4348772203105049]
	TIME [epoch: 8.28 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743479519406401		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.2743479519406401 | validation: 0.2839925710776049]
	TIME [epoch: 8.28 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691636190139647		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3691636190139647 | validation: 0.44629280648934744]
	TIME [epoch: 8.29 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860339383975427		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3860339383975427 | validation: 0.20991997408390084]
	TIME [epoch: 8.32 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26459006463107554		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.26459006463107554 | validation: 0.20714691105130079]
	TIME [epoch: 8.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699358679467098		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2699358679467098 | validation: 0.3173758284155995]
	TIME [epoch: 8.28 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848542134024066		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2848542134024066 | validation: 0.24369392487455638]
	TIME [epoch: 8.28 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26080274978376444		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.26080274978376444 | validation: 0.3053360171969355]
	TIME [epoch: 8.28 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22318891154292259		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.22318891154292259 | validation: 0.18048277335070584]
	TIME [epoch: 8.29 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22055042649409956		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.22055042649409956 | validation: 0.39128044423764685]
	TIME [epoch: 8.33 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26119656240662187		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.26119656240662187 | validation: 0.197571786896444]
	TIME [epoch: 8.29 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21267668066087883		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.21267668066087883 | validation: 0.23265768331637757]
	TIME [epoch: 8.28 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684529057654234		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.21684529057654234 | validation: 0.494098035610114]
	TIME [epoch: 8.28 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27377750993465794		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.27377750993465794 | validation: 0.25486524313346937]
	TIME [epoch: 8.28 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22692784930496024		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.22692784930496024 | validation: 0.22243924238559848]
	TIME [epoch: 8.31 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21002460793717984		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.21002460793717984 | validation: 0.18856600396736228]
	TIME [epoch: 8.31 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21641894473559894		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.21641894473559894 | validation: 0.2609549323195543]
	TIME [epoch: 8.28 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22715306606970867		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.22715306606970867 | validation: 0.2865092635999421]
	TIME [epoch: 8.28 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23628532210101272		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.23628532210101272 | validation: 0.23487537377995282]
	TIME [epoch: 8.28 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992772666123663		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1992772666123663 | validation: 0.2636540689096583]
	TIME [epoch: 8.28 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27492472294590187		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.27492472294590187 | validation: 0.14985943357003623]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22269581949522296		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.22269581949522296 | validation: 0.20500273552194787]
	TIME [epoch: 8.29 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28973971466856346		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.28973971466856346 | validation: 0.5445776090586156]
	TIME [epoch: 8.28 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518370746949969		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3518370746949969 | validation: 0.1989415496704963]
	TIME [epoch: 8.28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19461602205567327		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.19461602205567327 | validation: 0.2869722839117761]
	TIME [epoch: 8.28 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26551100262964555		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.26551100262964555 | validation: 0.2329560955010115]
	TIME [epoch: 8.32 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720771741300161		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.2720771741300161 | validation: 0.2873196798562472]
	TIME [epoch: 8.29 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33507468208260255		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.33507468208260255 | validation: 0.161625227134776]
	TIME [epoch: 8.28 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33783020029479643		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.33783020029479643 | validation: 0.373395462360958]
	TIME [epoch: 8.28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38865134814054936		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.38865134814054936 | validation: 0.2551894074528987]
	TIME [epoch: 8.28 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25000290261851466		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.25000290261851466 | validation: 0.1479264597452313]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19708323472066272		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.19708323472066272 | validation: 0.19205619689740172]
	TIME [epoch: 8.32 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037601341634776		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2037601341634776 | validation: 0.14607903381220091]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28574298900366546		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.28574298900366546 | validation: 0.17647940667841636]
	TIME [epoch: 8.29 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22443262250751211		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.22443262250751211 | validation: 0.16760136092123662]
	TIME [epoch: 8.28 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22273242099131058		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.22273242099131058 | validation: 0.186459370957691]
	TIME [epoch: 8.29 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113501530655485		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2113501530655485 | validation: 0.3234535037472378]
	TIME [epoch: 8.33 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22556752912995415		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.22556752912995415 | validation: 0.21574624455319255]
	TIME [epoch: 8.28 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21219029257918487		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.21219029257918487 | validation: 0.17216873946883332]
	TIME [epoch: 8.29 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437729674172032		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3437729674172032 | validation: 0.2908246200336463]
	TIME [epoch: 8.29 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26032760528382637		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.26032760528382637 | validation: 0.30645106145633116]
	TIME [epoch: 8.28 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35356410491212326		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.35356410491212326 | validation: 0.20475138799413262]
	TIME [epoch: 8.33 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075763004849569		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2075763004849569 | validation: 0.2356319911234941]
	TIME [epoch: 8.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22919702340906517		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.22919702340906517 | validation: 0.23804921679384922]
	TIME [epoch: 8.29 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22937917745907355		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.22937917745907355 | validation: 0.17974001689566463]
	TIME [epoch: 8.29 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616057617550786		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2616057617550786 | validation: 0.3439986691571391]
	TIME [epoch: 8.29 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840206800799433		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.2840206800799433 | validation: 0.3101476373544537]
	TIME [epoch: 8.29 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674255248359664		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.2674255248359664 | validation: 0.20177793597345267]
	TIME [epoch: 8.33 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251763375675314		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2251763375675314 | validation: 0.2217087336298525]
	TIME [epoch: 8.29 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24287138282164866		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.24287138282164866 | validation: 0.2859557565969624]
	TIME [epoch: 8.29 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968693366396628		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2968693366396628 | validation: 0.21723490282737984]
	TIME [epoch: 8.28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20374561150854162		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.20374561150854162 | validation: 0.23380916046480832]
	TIME [epoch: 8.29 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410269218883935		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.2410269218883935 | validation: 0.21271463194897808]
	TIME [epoch: 8.32 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20998929400501398		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.20998929400501398 | validation: 0.42556870072192327]
	TIME [epoch: 8.31 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23945074532713134		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.23945074532713134 | validation: 0.31758945290497065]
	TIME [epoch: 8.29 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21538398045849733		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.21538398045849733 | validation: 0.1596146961692745]
	TIME [epoch: 8.29 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18547523016499917		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.18547523016499917 | validation: 0.28064180251466286]
	TIME [epoch: 8.28 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970280078961502		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.1970280078961502 | validation: 0.18135779889851597]
	TIME [epoch: 8.31 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205347522870448		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.2205347522870448 | validation: 0.26427399641711324]
	TIME [epoch: 8.31 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22265509868363037		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.22265509868363037 | validation: 0.35810870339363143]
	TIME [epoch: 8.29 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680052018820984		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.2680052018820984 | validation: 0.19463192844742577]
	TIME [epoch: 8.28 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21336869904491007		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.21336869904491007 | validation: 0.21528584859121108]
	TIME [epoch: 8.28 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19252958091256256		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.19252958091256256 | validation: 0.2510255813061816]
	TIME [epoch: 8.28 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21934920480401351		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.21934920480401351 | validation: 0.27420027654942336]
	TIME [epoch: 8.33 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27045187983727703		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.27045187983727703 | validation: 0.16559646531684225]
	TIME [epoch: 8.29 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24699594993205942		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.24699594993205942 | validation: 0.29851595225941707]
	TIME [epoch: 8.29 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20472785190154608		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.20472785190154608 | validation: 0.24538920387556074]
	TIME [epoch: 8.92 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22178664357095462		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.22178664357095462 | validation: 0.16703310168003815]
	TIME [epoch: 8.29 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1776672641396077		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1776672641396077 | validation: 0.15115646526402154]
	TIME [epoch: 8.31 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19034424393463237		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.19034424393463237 | validation: 0.2552921478826382]
	TIME [epoch: 8.32 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17651700647783336		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.17651700647783336 | validation: 0.2738313484516919]
	TIME [epoch: 8.29 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327156790045399		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.4327156790045399 | validation: 0.35678467705547035]
	TIME [epoch: 8.29 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37919652729324405		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.37919652729324405 | validation: 0.31420506159302275]
	TIME [epoch: 8.29 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498091345204811		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3498091345204811 | validation: 0.18275648562199492]
	TIME [epoch: 8.29 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23421615673263182		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.23421615673263182 | validation: 0.19935168126407482]
	TIME [epoch: 8.33 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1897813566403488		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1897813566403488 | validation: 0.23148572014241844]
	TIME [epoch: 8.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26169242749461735		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.26169242749461735 | validation: 0.35589110647042255]
	TIME [epoch: 8.29 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31522205146509386		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.31522205146509386 | validation: 0.28278394436760956]
	TIME [epoch: 8.29 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26571675001464684		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.26571675001464684 | validation: 0.19372396655989965]
	TIME [epoch: 8.29 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17156815532585318		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.17156815532585318 | validation: 0.3208318811147205]
	TIME [epoch: 8.29 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24362624232874786		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.24362624232874786 | validation: 0.16031386382601687]
	TIME [epoch: 8.33 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20429038249742484		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.20429038249742484 | validation: 0.20546171569766586]
	TIME [epoch: 8.29 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146213262008973		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.2146213262008973 | validation: 0.17847327602484186]
	TIME [epoch: 8.29 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28630950022064483		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.28630950022064483 | validation: 0.2775152249567039]
	TIME [epoch: 8.29 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21912950709481754		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.21912950709481754 | validation: 0.1892912394527411]
	TIME [epoch: 8.29 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19204124898819078		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.19204124898819078 | validation: 0.19231710741713243]
	TIME [epoch: 8.32 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19589448285816688		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.19589448285816688 | validation: 0.2809489410801206]
	TIME [epoch: 8.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698265865603866		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2698265865603866 | validation: 0.27566793519503197]
	TIME [epoch: 8.29 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18855594408806042		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.18855594408806042 | validation: 0.19601983373883186]
	TIME [epoch: 8.29 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15648048809021411		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.15648048809021411 | validation: 0.1693657089425834]
	TIME [epoch: 8.29 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692293964038494		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.1692293964038494 | validation: 0.18399846719845103]
	TIME [epoch: 8.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869423908505365		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.1869423908505365 | validation: 0.18957031663756857]
	TIME [epoch: 8.33 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23625797164177406		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.23625797164177406 | validation: 0.13061662726746592]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1722808876207377		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1722808876207377 | validation: 0.22935877076850758]
	TIME [epoch: 8.29 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857920349791188		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.2857920349791188 | validation: 0.36405518885742605]
	TIME [epoch: 8.28 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2400027047335463		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2400027047335463 | validation: 0.21688441554709287]
	TIME [epoch: 8.29 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17953435538508505		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.17953435538508505 | validation: 0.1723022341948949]
	TIME [epoch: 8.32 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18877715340522824		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.18877715340522824 | validation: 0.16349971517633557]
	TIME [epoch: 8.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20521161036564375		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.20521161036564375 | validation: 0.2777303645286458]
	TIME [epoch: 8.28 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23621060969797517		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.23621060969797517 | validation: 0.2699225548639188]
	TIME [epoch: 8.28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21725548060739427		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.21725548060739427 | validation: 0.1782285260199316]
	TIME [epoch: 8.28 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17112958780760804		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.17112958780760804 | validation: 0.14418704945774694]
	TIME [epoch: 8.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19428554698733264		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.19428554698733264 | validation: 0.29565420843070567]
	TIME [epoch: 8.31 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2683595026037711		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.2683595026037711 | validation: 0.2835141929290927]
	TIME [epoch: 8.28 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300473911019184		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2300473911019184 | validation: 0.17175212854683303]
	TIME [epoch: 8.29 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17382753950217605		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.17382753950217605 | validation: 0.161343039021548]
	TIME [epoch: 8.28 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24609508215321177		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.24609508215321177 | validation: 0.3338291048519396]
	TIME [epoch: 8.28 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32269653516144725		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.32269653516144725 | validation: 0.19447752259807166]
	TIME [epoch: 8.33 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24316030485747908		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.24316030485747908 | validation: 0.3449746895211604]
	TIME [epoch: 8.29 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672818566655236		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2672818566655236 | validation: 0.19003729200746472]
	TIME [epoch: 8.29 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22764507914865584		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.22764507914865584 | validation: 0.2355337681752187]
	TIME [epoch: 8.29 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266849789662486		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.2266849789662486 | validation: 0.22199348633141847]
	TIME [epoch: 8.28 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22072289224614738		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.22072289224614738 | validation: 0.17269752831737406]
	TIME [epoch: 8.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23526408872959986		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.23526408872959986 | validation: 0.18560472776773795]
	TIME [epoch: 8.32 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20268252332368558		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.20268252332368558 | validation: 0.18069178078218615]
	TIME [epoch: 8.29 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15820323049995846		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.15820323049995846 | validation: 0.24781618538047526]
	TIME [epoch: 8.28 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790167001743958		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1790167001743958 | validation: 0.12854455793807365]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16523614316002624		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.16523614316002624 | validation: 0.1727225302952692]
	TIME [epoch: 8.29 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857360980718416		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1857360980718416 | validation: 0.28763511906958655]
	TIME [epoch: 8.33 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814175679545448		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2814175679545448 | validation: 0.19771005230143138]
	TIME [epoch: 8.29 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17309883702406983		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.17309883702406983 | validation: 0.24211762520362032]
	TIME [epoch: 8.28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24558351752274268		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.24558351752274268 | validation: 0.21936955701048227]
	TIME [epoch: 8.28 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16635611279766407		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.16635611279766407 | validation: 0.24191648161111645]
	TIME [epoch: 8.29 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18618315304074165		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.18618315304074165 | validation: 0.21468919917283927]
	TIME [epoch: 8.32 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20574287667030836		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.20574287667030836 | validation: 0.23616673846676062]
	TIME [epoch: 8.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779168446313126		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.2779168446313126 | validation: 0.2619093937582041]
	TIME [epoch: 8.28 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20940885927086672		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.20940885927086672 | validation: 0.17758938399745344]
	TIME [epoch: 8.28 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655735311994736		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1655735311994736 | validation: 0.19364733485023405]
	TIME [epoch: 8.28 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16912120077530837		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.16912120077530837 | validation: 0.16950870008152358]
	TIME [epoch: 8.29 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728629862805996		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.1728629862805996 | validation: 0.19943785370993677]
	TIME [epoch: 8.32 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20510724893538546		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.20510724893538546 | validation: 0.27410978714579737]
	TIME [epoch: 8.29 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367085022200387		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2367085022200387 | validation: 0.2004283582503699]
	TIME [epoch: 8.28 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22006975816891083		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.22006975816891083 | validation: 0.22590063871603894]
	TIME [epoch: 8.28 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547935398254429		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2547935398254429 | validation: 0.18578687068524818]
	TIME [epoch: 8.28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585528358048076		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1585528358048076 | validation: 0.18862264824469105]
	TIME [epoch: 8.32 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17040117130560328		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.17040117130560328 | validation: 0.20297894634644006]
	TIME [epoch: 8.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17577855619142904		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.17577855619142904 | validation: 0.23106854359586515]
	TIME [epoch: 8.29 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875742819745081		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.1875742819745081 | validation: 0.2500217515755164]
	TIME [epoch: 8.28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23239528800639433		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.23239528800639433 | validation: 0.20189129901231795]
	TIME [epoch: 8.29 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24651240661226909		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.24651240661226909 | validation: 0.2643394596805439]
	TIME [epoch: 8.29 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2609607398998168		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2609607398998168 | validation: 0.16516656226456794]
	TIME [epoch: 8.34 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15586254352999987		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.15586254352999987 | validation: 0.1840595688165722]
	TIME [epoch: 8.29 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011742231971196		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.16011742231971196 | validation: 0.21998799552286488]
	TIME [epoch: 8.28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773658393260127		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.19773658393260127 | validation: 0.1807116215320263]
	TIME [epoch: 8.28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19985968572305035		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19985968572305035 | validation: 0.21280135967138417]
	TIME [epoch: 8.28 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20541965659492759		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.20541965659492759 | validation: 0.4183315240979353]
	TIME [epoch: 8.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2924921511429453		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2924921511429453 | validation: 0.21059881231831842]
	TIME [epoch: 8.31 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18172596222783527		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.18172596222783527 | validation: 0.22139943390001296]
	TIME [epoch: 8.28 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155443518821565		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.2155443518821565 | validation: 0.21406385368366265]
	TIME [epoch: 8.28 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826481642979577		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.16826481642979577 | validation: 0.27287079918002644]
	TIME [epoch: 8.29 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1835253427912109		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1835253427912109 | validation: 0.2935279142873565]
	TIME [epoch: 8.28 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19768083427753785		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.19768083427753785 | validation: 0.18872477838955246]
	TIME [epoch: 8.33 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17676175109438746		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.17676175109438746 | validation: 0.13252392732757154]
	TIME [epoch: 8.28 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18829444207747176		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.18829444207747176 | validation: 0.17933066448679982]
	TIME [epoch: 8.28 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628446583035346		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1628446583035346 | validation: 0.22523412019720787]
	TIME [epoch: 8.28 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16946608664899884		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.16946608664899884 | validation: 0.16354225658621463]
	TIME [epoch: 8.28 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15919983177274097		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.15919983177274097 | validation: 0.16136314280076264]
	TIME [epoch: 8.32 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14878610489545332		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.14878610489545332 | validation: 0.11562514507400312]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15294006460572662		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15294006460572662 | validation: 0.1879926252574664]
	TIME [epoch: 8.29 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18224611917922548		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.18224611917922548 | validation: 0.17422638504433424]
	TIME [epoch: 8.28 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28245031664370523		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.28245031664370523 | validation: 0.1726591257907104]
	TIME [epoch: 8.28 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20949086576541148		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.20949086576541148 | validation: 0.15577590493866883]
	TIME [epoch: 8.28 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13832645881660705		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.13832645881660705 | validation: 0.24767711899354644]
	TIME [epoch: 8.32 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18262528805049136		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.18262528805049136 | validation: 0.15248301902455638]
	TIME [epoch: 8.28 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15136751199676418		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.15136751199676418 | validation: 0.21257622486431002]
	TIME [epoch: 8.28 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19737276594504838		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.19737276594504838 | validation: 0.1743662661809136]
	TIME [epoch: 8.28 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16955504986417885		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.16955504986417885 | validation: 0.1852939447003238]
	TIME [epoch: 8.29 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189538929413099		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.189538929413099 | validation: 0.3326497873584088]
	TIME [epoch: 8.32 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651574341730161		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2651574341730161 | validation: 0.2731897910107593]
	TIME [epoch: 8.28 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20445463391110735		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.20445463391110735 | validation: 0.18968648836075883]
	TIME [epoch: 8.28 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695341110412097		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1695341110412097 | validation: 0.15264576682417874]
	TIME [epoch: 8.28 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14977346962253293		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.14977346962253293 | validation: 0.1660121648175295]
	TIME [epoch: 8.28 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166254641578619		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.166254641578619 | validation: 0.14613530693848992]
	TIME [epoch: 8.32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446439947253469		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1446439947253469 | validation: 0.1896932541608764]
	TIME [epoch: 8.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19746460992297576		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.19746460992297576 | validation: 0.23558575903596618]
	TIME [epoch: 8.29 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22763275789727824		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.22763275789727824 | validation: 0.18380243635361443]
	TIME [epoch: 8.28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16539184278522603		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.16539184278522603 | validation: 0.17477754353797148]
	TIME [epoch: 8.28 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026062261998185		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.14026062261998185 | validation: 0.18088493691815494]
	TIME [epoch: 8.28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19881969909407868		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.19881969909407868 | validation: 0.2561620972274147]
	TIME [epoch: 8.33 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092864059783271		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2092864059783271 | validation: 0.13942222015594927]
	TIME [epoch: 8.29 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13878494463173532		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.13878494463173532 | validation: 0.2708876674357553]
	TIME [epoch: 8.29 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18506939394934374		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.18506939394934374 | validation: 0.2192033123883795]
	TIME [epoch: 8.29 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820355130711168		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1820355130711168 | validation: 0.13555093885360053]
	TIME [epoch: 8.29 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132364889873794		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14132364889873794 | validation: 0.22015501573782192]
	TIME [epoch: 8.31 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19392575235481863		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.19392575235481863 | validation: 0.19624663081734584]
	TIME [epoch: 8.32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19326095904969637		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.19326095904969637 | validation: 0.17726179102630793]
	TIME [epoch: 8.28 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166969170362907		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.166969170362907 | validation: 0.13530129612369096]
	TIME [epoch: 8.29 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14053834713477198		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.14053834713477198 | validation: 0.15639841651819825]
	TIME [epoch: 8.29 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1737784564240185		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1737784564240185 | validation: 0.18725714056415485]
	TIME [epoch: 8.29 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15911746815567948		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.15911746815567948 | validation: 0.13246936066706944]
	TIME [epoch: 8.33 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575713834564831		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.13575713834564831 | validation: 0.18565844415042482]
	TIME [epoch: 8.29 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1779492904388148		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1779492904388148 | validation: 0.17197859450173408]
	TIME [epoch: 8.29 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15888693838706575		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15888693838706575 | validation: 0.19048378043033865]
	TIME [epoch: 8.28 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21840422307350668		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.21840422307350668 | validation: 0.2946870009585754]
	TIME [epoch: 8.28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16925859974151342		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.16925859974151342 | validation: 0.20735855562503486]
	TIME [epoch: 8.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17049230747910551		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.17049230747910551 | validation: 0.14645445483106118]
	TIME [epoch: 8.32 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14504902380766377		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.14504902380766377 | validation: 0.1290201495493718]
	TIME [epoch: 8.29 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508591141448315		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.1508591141448315 | validation: 0.13826479752763537]
	TIME [epoch: 8.28 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14103379688349182		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14103379688349182 | validation: 0.14887176663766966]
	TIME [epoch: 8.28 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13684051203351982		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.13684051203351982 | validation: 0.14112617567500052]
	TIME [epoch: 8.28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14322000944899632		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.14322000944899632 | validation: 0.14343248650573165]
	TIME [epoch: 8.32 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20376602548084768		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.20376602548084768 | validation: 0.23664731956045054]
	TIME [epoch: 8.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20101919225753842		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.20101919225753842 | validation: 0.15974729602962529]
	TIME [epoch: 8.28 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175322906346267		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15175322906346267 | validation: 0.2370749332608863]
	TIME [epoch: 8.28 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509196997520068		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.2509196997520068 | validation: 0.16239332619092012]
	TIME [epoch: 8.28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19948744546119648		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.19948744546119648 | validation: 0.16495664577276187]
	TIME [epoch: 8.29 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234345827449425		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.2234345827449425 | validation: 0.24342865744630304]
	TIME [epoch: 8.32 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16225682189734325		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.16225682189734325 | validation: 0.23077794458832443]
	TIME [epoch: 8.28 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939418524156201		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1939418524156201 | validation: 0.12339804244649197]
	TIME [epoch: 8.28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958817935068601		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1958817935068601 | validation: 0.15852591509344754]
	TIME [epoch: 8.28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16275285156490582		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.16275285156490582 | validation: 0.2943023030907251]
	TIME [epoch: 8.28 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29120043278196844		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.29120043278196844 | validation: 0.21259477652900033]
	TIME [epoch: 8.32 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22495900195442972		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.22495900195442972 | validation: 0.17891696376353428]
	TIME [epoch: 8.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16153003990684844		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.16153003990684844 | validation: 0.13175324643992453]
	TIME [epoch: 8.28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14168464277175624		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.14168464277175624 | validation: 0.16190483572406494]
	TIME [epoch: 8.28 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801689146333095		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.12801689146333095 | validation: 0.29657598135599783]
	TIME [epoch: 8.28 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25762872845810053		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.25762872845810053 | validation: 0.3585816025475642]
	TIME [epoch: 8.28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19155141531255288		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.19155141531255288 | validation: 0.4357786528074481]
	TIME [epoch: 8.33 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24484254739007624		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.24484254739007624 | validation: 0.2668330656431314]
	TIME [epoch: 8.28 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17851547600027748		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.17851547600027748 | validation: 0.18406588499461127]
	TIME [epoch: 8.28 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19837646386063643		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.19837646386063643 | validation: 0.2548751984553507]
	TIME [epoch: 8.28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18031503163895157		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.18031503163895157 | validation: 0.1791002401137173]
	TIME [epoch: 8.28 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21599681075718163		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.21599681075718163 | validation: 0.19597893212054973]
	TIME [epoch: 8.31 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608494474803383		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1608494474803383 | validation: 0.2042974236956336]
	TIME [epoch: 8.31 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14226103907386667		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.14226103907386667 | validation: 0.26629675656902324]
	TIME [epoch: 8.28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18030426018532886		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.18030426018532886 | validation: 0.1446509921765731]
	TIME [epoch: 8.28 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14260604157264645		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.14260604157264645 | validation: 0.12062090090815461]
	TIME [epoch: 8.28 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15426233033875164		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.15426233033875164 | validation: 0.15919401488581186]
	TIME [epoch: 8.28 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22785768791639519		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.22785768791639519 | validation: 0.30358701554814416]
	TIME [epoch: 8.32 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23969559679772462		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.23969559679772462 | validation: 0.19409513017808083]
	TIME [epoch: 8.29 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663362113973772		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.1663362113973772 | validation: 0.13775111158029096]
	TIME [epoch: 8.28 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925314697844434		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.12925314697844434 | validation: 0.14238136193324397]
	TIME [epoch: 8.28 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15601253408408078		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.15601253408408078 | validation: 0.17162731661845304]
	TIME [epoch: 8.28 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17302289675342108		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.17302289675342108 | validation: 0.18348407364951658]
	TIME [epoch: 8.29 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14560435289586382		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.14560435289586382 | validation: 0.19583487098680724]
	TIME [epoch: 8.32 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044032087325955		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.16044032087325955 | validation: 0.15030630367067963]
	TIME [epoch: 8.28 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411868566153094		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1411868566153094 | validation: 0.16353158121591665]
	TIME [epoch: 8.28 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20022484568245158		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.20022484568245158 | validation: 0.1984649162534638]
	TIME [epoch: 8.28 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22221054644337562		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.22221054644337562 | validation: 0.2660366123195359]
	TIME [epoch: 8.28 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15519484613941242		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.15519484613941242 | validation: 0.13051027180688618]
	TIME [epoch: 8.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14074245644994748		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.14074245644994748 | validation: 0.16179665344468833]
	TIME [epoch: 8.29 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685778579570603		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.1685778579570603 | validation: 0.12683037428222316]
	TIME [epoch: 8.28 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518051753456552		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1518051753456552 | validation: 0.18872001702989835]
	TIME [epoch: 8.28 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16480137006513232		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.16480137006513232 | validation: 0.15607428224835096]
	TIME [epoch: 8.28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15762301406413334		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.15762301406413334 | validation: 0.16390475145042938]
	TIME [epoch: 8.28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22876846579002968		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.22876846579002968 | validation: 0.11435797202954913]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_797.pth
	Model improved!!!
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11871070624856062		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.11871070624856062 | validation: 0.16110205283304746]
	TIME [epoch: 8.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614491559843771		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1614491559843771 | validation: 0.14907141887484288]
	TIME [epoch: 8.29 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12553909127643392		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.12553909127643392 | validation: 0.14326351759469289]
	TIME [epoch: 8.28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564772158865257		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.13564772158865257 | validation: 0.14614330719572724]
	TIME [epoch: 8.29 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15048757756477749		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.15048757756477749 | validation: 0.17707412209078977]
	TIME [epoch: 8.33 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870681921000158		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1870681921000158 | validation: 0.23581176129628495]
	TIME [epoch: 8.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576636047010674		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.2576636047010674 | validation: 0.41615167286751054]
	TIME [epoch: 8.29 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658882592799907		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2658882592799907 | validation: 0.21718797202976384]
	TIME [epoch: 8.29 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23804291437044262		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.23804291437044262 | validation: 0.317660950185705]
	TIME [epoch: 8.29 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527852177562572		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2527852177562572 | validation: 0.2398677639647489]
	TIME [epoch: 8.32 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18628170343825312		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.18628170343825312 | validation: 0.13697683829697463]
	TIME [epoch: 8.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727852453025803		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1727852453025803 | validation: 0.19451809279787552]
	TIME [epoch: 8.29 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17159499302473719		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.17159499302473719 | validation: 0.15768160028112466]
	TIME [epoch: 8.29 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16007275979100344		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.16007275979100344 | validation: 0.13387391502797844]
	TIME [epoch: 8.29 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19018850130984902		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.19018850130984902 | validation: 0.3042251381918112]
	TIME [epoch: 8.29 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35350943740005225		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.35350943740005225 | validation: 0.38718213154982517]
	TIME [epoch: 8.33 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2905567604625596		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.2905567604625596 | validation: 0.2716658476525074]
	TIME [epoch: 8.29 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19663663485669813		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.19663663485669813 | validation: 0.1626467084232538]
	TIME [epoch: 8.29 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417183347326967		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.1417183347326967 | validation: 0.16595762549649884]
	TIME [epoch: 8.29 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15816767752126493		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.15816767752126493 | validation: 0.14207467398538676]
	TIME [epoch: 8.29 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017755279947913		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.14017755279947913 | validation: 0.15464786330796576]
	TIME [epoch: 8.32 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15211178135096226		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.15211178135096226 | validation: 0.16660377329017617]
	TIME [epoch: 8.31 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16000882241348158		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.16000882241348158 | validation: 0.15641528432249835]
	TIME [epoch: 8.29 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459290994422568		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1459290994422568 | validation: 0.12809161629200944]
	TIME [epoch: 8.29 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879838838023538		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.12879838838023538 | validation: 0.22607374596694102]
	TIME [epoch: 8.29 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212320100916692		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.2212320100916692 | validation: 0.26396390077965015]
	TIME [epoch: 8.29 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20679370884111922		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.20679370884111922 | validation: 0.23486549061622003]
	TIME [epoch: 8.33 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16561325190275766		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.16561325190275766 | validation: 0.1605094056054277]
	TIME [epoch: 8.29 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18899239986605332		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.18899239986605332 | validation: 0.29346366614300057]
	TIME [epoch: 8.29 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992955738885111		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1992955738885111 | validation: 0.19468291653978587]
	TIME [epoch: 8.29 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17213372312297576		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.17213372312297576 | validation: 0.21329781145297544]
	TIME [epoch: 8.29 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130978352634822		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.15130978352634822 | validation: 0.1987997749006639]
	TIME [epoch: 8.31 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14484210851059914		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14484210851059914 | validation: 0.14642131826398114]
	TIME [epoch: 8.32 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323404201281352		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.1323404201281352 | validation: 0.12155211942574017]
	TIME [epoch: 8.29 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11742213716933657		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.11742213716933657 | validation: 0.13306693338487996]
	TIME [epoch: 8.29 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363772490218807		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.14363772490218807 | validation: 0.1552026583371448]
	TIME [epoch: 8.29 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323590175207488		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1323590175207488 | validation: 0.1343384574540515]
	TIME [epoch: 8.29 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12673286481144364		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.12673286481144364 | validation: 0.1484318270251614]
	TIME [epoch: 8.33 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006611227998305		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.13006611227998305 | validation: 0.14243046060009312]
	TIME [epoch: 8.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391069571007508		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.1391069571007508 | validation: 0.12227827994803095]
	TIME [epoch: 8.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14811891140398062		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.14811891140398062 | validation: 0.16371293947164403]
	TIME [epoch: 8.29 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478175952033769		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.1478175952033769 | validation: 0.15812300232679674]
	TIME [epoch: 8.29 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14121462876070895		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.14121462876070895 | validation: 0.19907193488601543]
	TIME [epoch: 8.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14127347812193702		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.14127347812193702 | validation: 0.14769199803478109]
	TIME [epoch: 8.33 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436138160564695		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.13436138160564695 | validation: 0.1595286689957901]
	TIME [epoch: 8.29 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401380068952917		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.13401380068952917 | validation: 0.1607888987082778]
	TIME [epoch: 8.29 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242143799079023		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.13242143799079023 | validation: 0.13470075418738192]
	TIME [epoch: 8.29 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294434559886165		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1294434559886165 | validation: 0.13422568262972795]
	TIME [epoch: 8.29 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13017312221605637		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.13017312221605637 | validation: 0.12478313801984112]
	TIME [epoch: 8.33 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12519173558013574		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.12519173558013574 | validation: 0.18640927079871095]
	TIME [epoch: 8.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262920983888122		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.14262920983888122 | validation: 0.16186460881763487]
	TIME [epoch: 8.29 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12615375936476783		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12615375936476783 | validation: 0.18156776950566877]
	TIME [epoch: 8.29 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12830983458206516		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.12830983458206516 | validation: 0.16974380649822277]
	TIME [epoch: 8.28 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13746432186302823		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13746432186302823 | validation: 0.11832718898706963]
	TIME [epoch: 8.29 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114485057275775		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1114485057275775 | validation: 0.1394782931886381]
	TIME [epoch: 8.33 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15877887536365262		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.15877887536365262 | validation: 0.13883591790555183]
	TIME [epoch: 8.29 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304329872436703		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1304329872436703 | validation: 0.1976990832656486]
	TIME [epoch: 8.29 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596639034782601		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1596639034782601 | validation: 0.1457270416401123]
	TIME [epoch: 8.28 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16093137610819597		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.16093137610819597 | validation: 0.1325586758879209]
	TIME [epoch: 8.28 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197243105056313		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.15197243105056313 | validation: 0.17628888116318955]
	TIME [epoch: 8.32 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340518616609376		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.16340518616609376 | validation: 0.1963386640068287]
	TIME [epoch: 8.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16934588200772138		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.16934588200772138 | validation: 0.19883768191258683]
	TIME [epoch: 8.29 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18956302783476994		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.18956302783476994 | validation: 0.18066650082670876]
	TIME [epoch: 8.29 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14071874365319603		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.14071874365319603 | validation: 0.15086514767055284]
	TIME [epoch: 8.29 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395093679938868		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.15395093679938868 | validation: 0.12798772418572216]
	TIME [epoch: 8.29 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090142916147682		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13090142916147682 | validation: 0.15445731491772174]
	TIME [epoch: 8.34 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12732492638850446		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.12732492638850446 | validation: 0.1369580955053326]
	TIME [epoch: 8.29 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992908704718276		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.12992908704718276 | validation: 0.15519171161995385]
	TIME [epoch: 8.29 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854857185013336		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.13854857185013336 | validation: 0.15001997737703165]
	TIME [epoch: 8.29 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13595200245697092		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.13595200245697092 | validation: 0.15722576813699007]
	TIME [epoch: 8.28 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047952958702361		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.12047952958702361 | validation: 0.1562207584421093]
	TIME [epoch: 8.31 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14400947973390543		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.14400947973390543 | validation: 0.16387335329584557]
	TIME [epoch: 8.32 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790630087074902		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.14790630087074902 | validation: 0.21955612544635933]
	TIME [epoch: 8.28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638028377559515		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.1638028377559515 | validation: 0.14605486612343596]
	TIME [epoch: 8.28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16143140131204364		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.16143140131204364 | validation: 0.13240777934279235]
	TIME [epoch: 8.29 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13028913380812823		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.13028913380812823 | validation: 0.17453982031591583]
	TIME [epoch: 8.33 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563093669533194		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.13563093669533194 | validation: 0.15364685935691857]
	TIME [epoch: 8.33 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14150981032953794		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.14150981032953794 | validation: 0.1610115207514881]
	TIME [epoch: 8.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18139468638548478		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.18139468638548478 | validation: 0.22861180328433955]
	TIME [epoch: 8.29 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22806620029714095		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.22806620029714095 | validation: 0.19543659258854496]
	TIME [epoch: 8.29 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21646538310827318		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.21646538310827318 | validation: 0.2310325947591496]
	TIME [epoch: 8.28 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22769980913334453		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.22769980913334453 | validation: 0.20234344135610288]
	TIME [epoch: 8.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17971050211156786		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.17971050211156786 | validation: 0.1906296045929508]
	TIME [epoch: 8.33 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17198193724470545		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.17198193724470545 | validation: 0.1415270890163448]
	TIME [epoch: 8.28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14213851325475843		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.14213851325475843 | validation: 0.1535951637306413]
	TIME [epoch: 8.29 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14082480056254984		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.14082480056254984 | validation: 0.17602201329042533]
	TIME [epoch: 8.29 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13163250215975253		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.13163250215975253 | validation: 0.20548531635314965]
	TIME [epoch: 8.28 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15419917749199227		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.15419917749199227 | validation: 0.1337353554318541]
	TIME [epoch: 8.33 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12271302581194113		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.12271302581194113 | validation: 0.1839953206820846]
	TIME [epoch: 8.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16608476130797697		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.16608476130797697 | validation: 0.1660215463726446]
	TIME [epoch: 8.29 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13985396923474977		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.13985396923474977 | validation: 0.12830223592722473]
	TIME [epoch: 8.29 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534379557028164		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.1534379557028164 | validation: 0.12335176513727798]
	TIME [epoch: 8.28 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13020166194955948		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13020166194955948 | validation: 0.1537900189024966]
	TIME [epoch: 8.29 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13876112390733272		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.13876112390733272 | validation: 0.13296639804835564]
	TIME [epoch: 8.33 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016071789632893		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.12016071789632893 | validation: 0.1376508341473711]
	TIME [epoch: 8.29 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226094060161405		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.12226094060161405 | validation: 0.13736407160372427]
	TIME [epoch: 8.29 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286500209306677		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1286500209306677 | validation: 0.15457421494809875]
	TIME [epoch: 8.29 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532090456236716		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.1532090456236716 | validation: 0.24142757940252327]
	TIME [epoch: 8.29 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2000619913528464		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.2000619913528464 | validation: 0.20088517242372528]
	TIME [epoch: 8.32 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20345946269457013		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.20345946269457013 | validation: 0.19716112759487475]
	TIME [epoch: 8.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17749784375046712		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.17749784375046712 | validation: 0.12664491259747845]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240702_111150/states/model_phi1_1a_v_kl1_898.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 7655.718 seconds.
