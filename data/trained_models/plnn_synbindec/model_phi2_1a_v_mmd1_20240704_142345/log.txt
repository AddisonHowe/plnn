Args:
Namespace(name='model_phi2_1a_v_mmd1', outdir='out/model_training/model_phi2_1a_v_mmd1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3119600136

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.938871668336586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.938871668336586 | validation: 4.152544347181655]
	TIME [epoch: 122 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7096241002221526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7096241002221526 | validation: 3.080123612387583]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.685169703778219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.685169703778219 | validation: 2.6618528926092555]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200917761287167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.200917761287167 | validation: 2.1427361266928315]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7585419679483452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7585419679483452 | validation: 1.5558164889389983]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6443512422591597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6443512422591597 | validation: 0.9459076407734162]
	TIME [epoch: 7.48 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3030237181371571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3030237181371571 | validation: 0.9702606764290751]
	TIME [epoch: 7.45 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1141107198068605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1141107198068605 | validation: 0.9205308162829329]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655425893186785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0655425893186785 | validation: 0.996096624439208]
	TIME [epoch: 7.44 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0096193468244339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0096193468244339 | validation: 0.8316688283474203]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9308285342833734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9308285342833734 | validation: 0.6740093213390544]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526492825079308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7526492825079308 | validation: 0.8872242058736618]
	TIME [epoch: 7.44 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9285127629020836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9285127629020836 | validation: 0.6771310957122454]
	TIME [epoch: 7.43 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074122193969417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8074122193969417 | validation: 0.6221436487282583]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858548364840409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6858548364840409 | validation: 0.7332998775149527]
	TIME [epoch: 7.44 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301121436255416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7301121436255416 | validation: 0.8525708802862538]
	TIME [epoch: 7.52 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7957542234142554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7957542234142554 | validation: 0.47774523066342706]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894049900654445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6894049900654445 | validation: 0.5999921102506804]
	TIME [epoch: 7.44 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138011202981451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7138011202981451 | validation: 0.5861213689941489]
	TIME [epoch: 7.43 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057414051418603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7057414051418603 | validation: 0.4321144106299049]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674086464694357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.674086464694357 | validation: 0.7838917915647707]
	TIME [epoch: 7.49 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7395265048572961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7395265048572961 | validation: 0.5403077236617184]
	TIME [epoch: 7.44 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861641901131185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6861641901131185 | validation: 0.4536389788546718]
	TIME [epoch: 7.43 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683693568133986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.683693568133986 | validation: 0.48575971525238787]
	TIME [epoch: 7.43 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650927102186656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.650927102186656 | validation: 0.5790316260578616]
	TIME [epoch: 7.45 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276190341444276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7276190341444276 | validation: 0.5516690498804824]
	TIME [epoch: 7.48 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6637764136047335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6637764136047335 | validation: 0.422604056277791]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684672297249199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6684672297249199 | validation: 0.4392962600846504]
	TIME [epoch: 7.45 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217790766126879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6217790766126879 | validation: 0.5345178970013895]
	TIME [epoch: 7.44 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615841728827786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6615841728827786 | validation: 0.38754633448808407]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373988074862444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6373988074862444 | validation: 0.5196283802899588]
	TIME [epoch: 7.48 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6425331953799546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6425331953799546 | validation: 0.5254179516541013]
	TIME [epoch: 7.44 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231010118893152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6231010118893152 | validation: 0.48562479109717477]
	TIME [epoch: 7.45 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024785277477827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7024785277477827 | validation: 0.4450943097040798]
	TIME [epoch: 7.44 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6051089366342339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6051089366342339 | validation: 0.4728701826687114]
	TIME [epoch: 7.46 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157539254280833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6157539254280833 | validation: 0.46353065927032616]
	TIME [epoch: 7.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6602943476761357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6602943476761357 | validation: 0.4273243545943276]
	TIME [epoch: 7.44 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.675603910671602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.675603910671602 | validation: 0.4568697425361351]
	TIME [epoch: 7.43 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052852369754612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6052852369754612 | validation: 0.534994061504592]
	TIME [epoch: 7.44 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466990002036144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6466990002036144 | validation: 0.3970501300150993]
	TIME [epoch: 7.46 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423165007661892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6423165007661892 | validation: 0.3977112387045637]
	TIME [epoch: 7.47 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485127218854697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6485127218854697 | validation: 0.520136139895939]
	TIME [epoch: 7.43 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115510604192846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6115510604192846 | validation: 0.5775950467945243]
	TIME [epoch: 7.44 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157136172453692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6157136172453692 | validation: 0.37528666553021944]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5798611759400579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5798611759400579 | validation: 0.6927005455559498]
	TIME [epoch: 7.46 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443109841672468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7443109841672468 | validation: 0.4622569257505563]
	TIME [epoch: 7.49 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248915334142854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6248915334142854 | validation: 0.6458163771089986]
	TIME [epoch: 7.43 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.647485050867125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.647485050867125 | validation: 0.45067087815808377]
	TIME [epoch: 7.43 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014196689739081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6014196689739081 | validation: 0.46283626124933436]
	TIME [epoch: 7.44 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618876313553918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5618876313553918 | validation: 0.4783184147401087]
	TIME [epoch: 7.45 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912952103780474		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.5912952103780474 | validation: 0.5706699412761688]
	TIME [epoch: 7.48 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516003504091228		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.5516003504091228 | validation: 0.56904633234085]
	TIME [epoch: 7.43 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817092717530041		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.6817092717530041 | validation: 0.46276582150141776]
	TIME [epoch: 7.43 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790602238519418		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.5790602238519418 | validation: 0.46023377562459267]
	TIME [epoch: 7.43 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853567751243913		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.5853567751243913 | validation: 0.4990802515406989]
	TIME [epoch: 7.45 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620693824892402		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.620693824892402 | validation: 0.596471793117646]
	TIME [epoch: 7.47 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5963577722918104		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5963577722918104 | validation: 0.45840776466397776]
	TIME [epoch: 7.46 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261561802160923		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.5261561802160923 | validation: 0.6202426176460984]
	TIME [epoch: 7.44 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253131955883322		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6253131955883322 | validation: 0.4006703974369929]
	TIME [epoch: 7.42 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4968281093126844		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.4968281093126844 | validation: 0.46598137543333107]
	TIME [epoch: 7.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359559699419066		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.6359559699419066 | validation: 0.5093205887169485]
	TIME [epoch: 7.49 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697917905490621		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5697917905490621 | validation: 0.41358871759740123]
	TIME [epoch: 7.44 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605079874800175		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5605079874800175 | validation: 0.5609896376084832]
	TIME [epoch: 7.43 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785779982809217		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5785779982809217 | validation: 0.46403338652319903]
	TIME [epoch: 7.43 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323412345652621		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5323412345652621 | validation: 0.5625849444658044]
	TIME [epoch: 7.42 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203112051586114		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5203112051586114 | validation: 0.32806292068315696]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473654367454348		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5473654367454348 | validation: 0.42095945394006884]
	TIME [epoch: 7.44 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469199419655797		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5469199419655797 | validation: 0.34417265598740865]
	TIME [epoch: 7.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809466318765489		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.4809466318765489 | validation: 0.45576979483760344]
	TIME [epoch: 7.45 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605035881372193		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.5605035881372193 | validation: 0.3258199612304272]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936273349161441		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.4936273349161441 | validation: 0.44866923055523233]
	TIME [epoch: 7.49 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5282036204571375		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5282036204571375 | validation: 0.37534024238224034]
	TIME [epoch: 7.44 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711461183953203		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.4711461183953203 | validation: 0.41024049252800565]
	TIME [epoch: 7.46 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098762957164312		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5098762957164312 | validation: 0.48252869523245645]
	TIME [epoch: 7.45 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48955163690231007		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.48955163690231007 | validation: 0.3348409572577116]
	TIME [epoch: 7.47 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839295110352916		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5839295110352916 | validation: 0.34826213536690787]
	TIME [epoch: 7.48 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44763778090937256		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.44763778090937256 | validation: 0.4167418156502275]
	TIME [epoch: 7.46 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709407474247548		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.4709407474247548 | validation: 0.3384832767868555]
	TIME [epoch: 7.45 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48445392494546463		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.48445392494546463 | validation: 0.34743812943926944]
	TIME [epoch: 7.45 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44311141186325376		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.44311141186325376 | validation: 0.4176482695149127]
	TIME [epoch: 7.49 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4933034498615934		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.4933034498615934 | validation: 0.28566147413060894]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45806276455757206		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.45806276455757206 | validation: 0.33795486353928467]
	TIME [epoch: 7.43 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4304629678764834		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.4304629678764834 | validation: 0.2948042753320862]
	TIME [epoch: 7.43 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935096238403225		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.4935096238403225 | validation: 0.30518380026342523]
	TIME [epoch: 7.43 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297089436543288		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.4297089436543288 | validation: 0.3027497384491022]
	TIME [epoch: 7.45 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41011233563662003		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.41011233563662003 | validation: 0.25780606278415374]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42261774039136263		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.42261774039136263 | validation: 0.2911766745059424]
	TIME [epoch: 7.43 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4477695356414323		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.4477695356414323 | validation: 0.2711258691534059]
	TIME [epoch: 7.43 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39292627028538873		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.39292627028538873 | validation: 0.2973901389579793]
	TIME [epoch: 7.43 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409564106582897		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.409564106582897 | validation: 0.30881749432097416]
	TIME [epoch: 7.45 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364445854867099		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4364445854867099 | validation: 0.2823589039538259]
	TIME [epoch: 7.49 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3870349959021929		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.3870349959021929 | validation: 0.29660949540914383]
	TIME [epoch: 7.45 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41071204906354003		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.41071204906354003 | validation: 0.2355210862953937]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37602892492213924		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.37602892492213924 | validation: 0.28383966684800244]
	TIME [epoch: 7.44 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36722128282097416		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.36722128282097416 | validation: 0.22472937727524772]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44116110617924487		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.44116110617924487 | validation: 0.26818695639669965]
	TIME [epoch: 7.48 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896234040435873		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.3896234040435873 | validation: 0.25422500514688584]
	TIME [epoch: 7.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639705210764193		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3639705210764193 | validation: 0.2366342809332049]
	TIME [epoch: 7.46 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716988800334833		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.3716988800334833 | validation: 0.25409374311820326]
	TIME [epoch: 7.44 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35873065970730933		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.35873065970730933 | validation: 0.22365623923947042]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662076581355567		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.3662076581355567 | validation: 0.2222873367062148]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34679437861319456		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.34679437861319456 | validation: 0.2624387607149292]
	TIME [epoch: 7.46 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662997330557131		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.3662997330557131 | validation: 0.2109897207730182]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278851606412676		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.3278851606412676 | validation: 0.24438787152385882]
	TIME [epoch: 7.47 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645432600933681		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.3645432600933681 | validation: 0.20176116165711624]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484335575875459		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.3484335575875459 | validation: 0.21551284087369066]
	TIME [epoch: 7.47 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32475462224905555		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.32475462224905555 | validation: 0.19696593134065746]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437322087931353		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.3437322087931353 | validation: 0.19242549403680873]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31751954078715533		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.31751954078715533 | validation: 0.19402220261156636]
	TIME [epoch: 7.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514936056395336		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3514936056395336 | validation: 0.1957416802674907]
	TIME [epoch: 7.48 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3213496188249577		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.3213496188249577 | validation: 0.21095833798103053]
	TIME [epoch: 7.43 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239211966202936		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.3239211966202936 | validation: 0.2244847082124436]
	TIME [epoch: 7.43 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33985365814753266		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.33985365814753266 | validation: 0.20608501589713363]
	TIME [epoch: 7.43 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310711446544748		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.310711446544748 | validation: 0.18443836303332545]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33212643638363776		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.33212643638363776 | validation: 0.21096625161086963]
	TIME [epoch: 7.52 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31890485963972665		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.31890485963972665 | validation: 0.19224730659480843]
	TIME [epoch: 7.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144542351836703		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.3144542351836703 | validation: 0.1997243036431722]
	TIME [epoch: 7.44 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116923564968964		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.3116923564968964 | validation: 0.19047683065287618]
	TIME [epoch: 7.44 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30482690970045206		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.30482690970045206 | validation: 0.1919907795255995]
	TIME [epoch: 7.43 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261501577249949		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.3261501577249949 | validation: 0.18497274503713138]
	TIME [epoch: 7.49 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041760803541044		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3041760803541044 | validation: 0.1920843843126331]
	TIME [epoch: 7.45 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299718786873167		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3299718786873167 | validation: 0.2475664860468965]
	TIME [epoch: 7.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32272676744046386		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.32272676744046386 | validation: 0.1798024401376711]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30924259424457173		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.30924259424457173 | validation: 0.20931052381734466]
	TIME [epoch: 7.43 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106013346445207		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3106013346445207 | validation: 0.18912467370815]
	TIME [epoch: 7.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31869253675069587		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.31869253675069587 | validation: 0.19779328449263295]
	TIME [epoch: 7.46 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070316962690512		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3070316962690512 | validation: 0.18024988521450283]
	TIME [epoch: 7.45 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332194909543129		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3332194909543129 | validation: 0.18660173555445056]
	TIME [epoch: 7.44 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30960130419971665		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.30960130419971665 | validation: 0.20982026205406445]
	TIME [epoch: 7.43 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085736875240752		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.3085736875240752 | validation: 0.19717387207684497]
	TIME [epoch: 7.49 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30331482029953266		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.30331482029953266 | validation: 0.17920210203047499]
	TIME [epoch: 7.44 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29847615294071117		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.29847615294071117 | validation: 0.18356504024943487]
	TIME [epoch: 7.46 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085278608663901		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3085278608663901 | validation: 0.17566477291088248]
	TIME [epoch: 7.48 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29553943711587694		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.29553943711587694 | validation: 0.29162216862112145]
	TIME [epoch: 7.46 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264453772357523		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.3264453772357523 | validation: 0.18569008694936312]
	TIME [epoch: 7.52 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047803401112329		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3047803401112329 | validation: 0.17768119339125987]
	TIME [epoch: 7.46 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115843834071321		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.3115843834071321 | validation: 0.17317056022343627]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30517837631690675		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.30517837631690675 | validation: 0.20606905741742226]
	TIME [epoch: 7.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30639787542953245		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.30639787542953245 | validation: 0.25276696583363495]
	TIME [epoch: 7.48 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33009112577870814		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.33009112577870814 | validation: 0.18257797400362805]
	TIME [epoch: 7.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172323738370292		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3172323738370292 | validation: 0.1798854618440598]
	TIME [epoch: 7.46 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952380073337133		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.2952380073337133 | validation: 0.18749030977843306]
	TIME [epoch: 7.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055714033333834		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3055714033333834 | validation: 0.1750963769276207]
	TIME [epoch: 7.46 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29815028707409613		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.29815028707409613 | validation: 0.1780511802725695]
	TIME [epoch: 7.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033326345143167		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3033326345143167 | validation: 0.20152749716419865]
	TIME [epoch: 7.52 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125652521144089		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3125652521144089 | validation: 0.173639485322758]
	TIME [epoch: 7.47 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29725921376458836		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.29725921376458836 | validation: 0.2194726401201889]
	TIME [epoch: 7.48 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310770911767511		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.310770911767511 | validation: 0.17240412490061732]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898365171414769		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.2898365171414769 | validation: 0.17225500959116616]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884304101788925		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2884304101788925 | validation: 0.17012144266479232]
	TIME [epoch: 7.48 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098739334458822		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.3098739334458822 | validation: 0.19002283297921085]
	TIME [epoch: 7.43 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29533907154960326		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.29533907154960326 | validation: 0.16995782825229494]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28888996483424867		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.28888996483424867 | validation: 0.16130892125537521]
	TIME [epoch: 7.43 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992990616758597		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.2992990616758597 | validation: 0.1867959528783337]
	TIME [epoch: 7.48 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355612630675933		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.3355612630675933 | validation: 0.3838488331238957]
	TIME [epoch: 7.46 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3148689783891873		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.3148689783891873 | validation: 0.36361251713983556]
	TIME [epoch: 7.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3027446885855885		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3027446885855885 | validation: 0.3696785745246952]
	TIME [epoch: 7.44 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31265544888566427		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.31265544888566427 | validation: 0.3630606453946338]
	TIME [epoch: 7.44 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3034914684442215		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3034914684442215 | validation: 0.38024493452806774]
	TIME [epoch: 7.49 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077082450236222		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3077082450236222 | validation: 0.3588780847200974]
	TIME [epoch: 7.48 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039195500053757		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3039195500053757 | validation: 0.36796921134504545]
	TIME [epoch: 7.47 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941132878346466		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.29941132878346466 | validation: 0.36167782369393586]
	TIME [epoch: 7.47 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30609432467450515		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.30609432467450515 | validation: 0.37631556363688046]
	TIME [epoch: 7.45 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30557815045893305		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.30557815045893305 | validation: 0.36037768157555705]
	TIME [epoch: 7.48 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29737197661707915		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.29737197661707915 | validation: 0.3514308406644423]
	TIME [epoch: 7.48 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30907317981824967		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.30907317981824967 | validation: 0.3558911101485923]
	TIME [epoch: 7.45 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29561748239690694		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.29561748239690694 | validation: 0.35896235484159633]
	TIME [epoch: 7.47 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961461404924394		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.2961461404924394 | validation: 0.36056894528515593]
	TIME [epoch: 7.46 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30694461507963133		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.30694461507963133 | validation: 0.36973994252156767]
	TIME [epoch: 7.48 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30020165756693235		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.30020165756693235 | validation: 0.3549628498067564]
	TIME [epoch: 7.48 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29579086378772457		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.29579086378772457 | validation: 0.372427798911109]
	TIME [epoch: 7.45 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29801741676353		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.29801741676353 | validation: 0.35531953773735436]
	TIME [epoch: 7.46 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29114320538773003		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.29114320538773003 | validation: 0.3548877892319645]
	TIME [epoch: 7.47 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28945328313047336		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.28945328313047336 | validation: 0.3583257040364204]
	TIME [epoch: 7.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30136647345084344		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.30136647345084344 | validation: 0.35296002997992315]
	TIME [epoch: 7.48 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29012591853442454		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.29012591853442454 | validation: 0.35979968537367424]
	TIME [epoch: 7.46 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881182561982504		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.2881182561982504 | validation: 0.34362400813215577]
	TIME [epoch: 7.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29614211772440124		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.29614211772440124 | validation: 0.3485253109856024]
	TIME [epoch: 7.46 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2896823455495819		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2896823455495819 | validation: 0.35689504544475703]
	TIME [epoch: 7.51 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29662023757051675		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.29662023757051675 | validation: 0.3478195073574878]
	TIME [epoch: 7.49 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28975065997762683		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.28975065997762683 | validation: 0.34525054773120295]
	TIME [epoch: 7.47 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28028146989456393		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.28028146989456393 | validation: 0.32763995816778213]
	TIME [epoch: 7.46 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28262667320538676		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.28262667320538676 | validation: 0.29231424293956143]
	TIME [epoch: 7.46 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2407076349954293		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.2407076349954293 | validation: 0.16995878600261047]
	TIME [epoch: 7.49 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30577405634906213		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.30577405634906213 | validation: 0.15631839117125346]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23177903864850205		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.23177903864850205 | validation: 0.14870330698705175]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19928013548365336		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.19928013548365336 | validation: 0.13005845835938212]
	TIME [epoch: 7.46 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19313584841744005		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.19313584841744005 | validation: 0.16288339044232147]
	TIME [epoch: 7.46 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17522532659492043		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.17522532659492043 | validation: 0.14305715009627448]
	TIME [epoch: 7.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371434654317248		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.15371434654317248 | validation: 0.11837066281556002]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171254595863626		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.171254595863626 | validation: 0.17368240792749307]
	TIME [epoch: 7.46 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990815380929237		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.1990815380929237 | validation: 0.19630403651990883]
	TIME [epoch: 7.43 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16681483179671552		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.16681483179671552 | validation: 0.12256622856109543]
	TIME [epoch: 7.43 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18835642511050127		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.18835642511050127 | validation: 0.11560282855478404]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572214254051139		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.1572214254051139 | validation: 0.17417289664769095]
	TIME [epoch: 7.44 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14487821687392305		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.14487821687392305 | validation: 0.11990513389976075]
	TIME [epoch: 7.44 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19801210780817377		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.19801210780817377 | validation: 0.13919776729967573]
	TIME [epoch: 7.44 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19314114468687188		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.19314114468687188 | validation: 0.1719539956971199]
	TIME [epoch: 7.44 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157909539635135		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.157909539635135 | validation: 0.17613750111290555]
	TIME [epoch: 7.49 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15157502803432854		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.15157502803432854 | validation: 0.15974695553116514]
	TIME [epoch: 7.44 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15792577982456774		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.15792577982456774 | validation: 0.16706813386719088]
	TIME [epoch: 129 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549564187009758		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.1549564187009758 | validation: 0.16477316723875024]
	TIME [epoch: 14.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828233328023536		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.12828233328023536 | validation: 0.1314965683454781]
	TIME [epoch: 14.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13151322450023867		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.13151322450023867 | validation: 0.21753135535285967]
	TIME [epoch: 14.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16283020319667837		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.16283020319667837 | validation: 0.19485198297070025]
	TIME [epoch: 14.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415842716343622		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1415842716343622 | validation: 0.10382147137115844]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435043648372403		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.11435043648372403 | validation: 0.10671032561167229]
	TIME [epoch: 14.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12227893103528972		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.12227893103528972 | validation: 0.1090792640808558]
	TIME [epoch: 14.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12168506772995237		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.12168506772995237 | validation: 0.08958963974757855]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12924873669174586		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.12924873669174586 | validation: 0.11384148981467611]
	TIME [epoch: 14.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312072995458977		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.1312072995458977 | validation: 0.09200360336593401]
	TIME [epoch: 14.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850827407688658		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.11850827407688658 | validation: 0.11880525799548977]
	TIME [epoch: 14.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685418550509942		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.10685418550509942 | validation: 0.08552430024753048]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10988800275635137		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.10988800275635137 | validation: 0.1886956543623181]
	TIME [epoch: 14.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11420953850457649		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11420953850457649 | validation: 0.11906701044391618]
	TIME [epoch: 14.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643868330485408		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.09643868330485408 | validation: 0.06324439055694515]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08549583819562555		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.08549583819562555 | validation: 0.05854057405541096]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11579737276806193		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.11579737276806193 | validation: 0.12080114720599515]
	TIME [epoch: 14.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20248774761265195		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.20248774761265195 | validation: 0.1572045812520854]
	TIME [epoch: 14.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178659642733714		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.10178659642733714 | validation: 0.08354001383918007]
	TIME [epoch: 14.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147759620404261		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.09147759620404261 | validation: 0.07185808571211494]
	TIME [epoch: 14.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902735665420894		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.0902735665420894 | validation: 0.04628902037571796]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08325689251333113		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.08325689251333113 | validation: 0.14137178165767508]
	TIME [epoch: 14.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2470265676469226		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2470265676469226 | validation: 0.15832334625748]
	TIME [epoch: 14.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485735749191017		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.11485735749191017 | validation: 0.06972519717391748]
	TIME [epoch: 14.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414174410850086		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.10414174410850086 | validation: 0.05064427066071818]
	TIME [epoch: 14.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08503815751351514		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.08503815751351514 | validation: 0.21491914177238142]
	TIME [epoch: 14.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454844999638373		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.1454844999638373 | validation: 0.0638905743961104]
	TIME [epoch: 14.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795228912194879		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.1795228912194879 | validation: 0.28724827682266346]
	TIME [epoch: 14.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3347359297371786		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.3347359297371786 | validation: 0.1494151167736311]
	TIME [epoch: 14.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741299068461224		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.2741299068461224 | validation: 0.149234480323859]
	TIME [epoch: 14.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27266205156255735		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.27266205156255735 | validation: 0.15141656988414]
	TIME [epoch: 14.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27648119537894056		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.27648119537894056 | validation: 0.1520644190237725]
	TIME [epoch: 14.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27485436048171513		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.27485436048171513 | validation: 0.15177442161096122]
	TIME [epoch: 14.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27620889791740333		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.27620889791740333 | validation: 0.15252669775583455]
	TIME [epoch: 14.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761541928054575		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.2761541928054575 | validation: 0.1552408400792043]
	TIME [epoch: 14.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782037433939091		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2782037433939091 | validation: 0.1533929370845592]
	TIME [epoch: 14.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781313221088503		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.2781313221088503 | validation: 0.16876037396921723]
	TIME [epoch: 14.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27983037457504384		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.27983037457504384 | validation: 0.1712209369583723]
	TIME [epoch: 14.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28695738038108565		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.28695738038108565 | validation: 0.21475266083231523]
	TIME [epoch: 14.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29331222893257647		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.29331222893257647 | validation: 0.1601413446094393]
	TIME [epoch: 14.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28034976617886087		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.28034976617886087 | validation: 0.16748730163078926]
	TIME [epoch: 14.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18926274965154327		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.18926274965154327 | validation: 0.1287597604004092]
	TIME [epoch: 14.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2370834504912509		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2370834504912509 | validation: 0.18613448229550433]
	TIME [epoch: 14.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11323355145400434		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.11323355145400434 | validation: 0.060105501383027365]
	TIME [epoch: 14.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064162831830088		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.08064162831830088 | validation: 0.05364985082955627]
	TIME [epoch: 14.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06477507490679435		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.06477507490679435 | validation: 0.03921655897970012]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828445267674697		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.0828445267674697 | validation: 0.04645226015063143]
	TIME [epoch: 14.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793542421140694		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.06793542421140694 | validation: 0.036007093117139795]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07624059543876702		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.07624059543876702 | validation: 0.04256901374578902]
	TIME [epoch: 14.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05996046858013972		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.05996046858013972 | validation: 0.04204265100507851]
	TIME [epoch: 14.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058967644094223955		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.058967644094223955 | validation: 0.04965566313371378]
	TIME [epoch: 14.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128128868460574		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.06128128868460574 | validation: 0.09900663623941992]
	TIME [epoch: 14.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116993167773915		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.12116993167773915 | validation: 0.0611885121662183]
	TIME [epoch: 14.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05938415555785992		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.05938415555785992 | validation: 0.03263883915380632]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23225504940514094		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.23225504940514094 | validation: 0.266929754384746]
	TIME [epoch: 14.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13466423179091794		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.13466423179091794 | validation: 0.04298296634826658]
	TIME [epoch: 14.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569747896502954		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.05569747896502954 | validation: 0.03782352245756739]
	TIME [epoch: 14.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05218718455389616		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.05218718455389616 | validation: 0.03511720243307655]
	TIME [epoch: 14.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087123616089623		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.05087123616089623 | validation: 0.03995821038330456]
	TIME [epoch: 14.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574202266416717		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.07574202266416717 | validation: 0.036399499300582]
	TIME [epoch: 14.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046173399987547686		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.046173399987547686 | validation: 0.033988552544505564]
	TIME [epoch: 14.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451921686759845		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.0451921686759845 | validation: 0.034159633612495605]
	TIME [epoch: 14.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039187405561231105		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.039187405561231105 | validation: 0.02967151176594431]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05128429826975923		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.05128429826975923 | validation: 0.02694459074620453]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773358182488817		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.04773358182488817 | validation: 0.1581970061398783]
	TIME [epoch: 14.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13614740009981272		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.13614740009981272 | validation: 0.03808271438786737]
	TIME [epoch: 14.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125227620002747		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.05125227620002747 | validation: 0.026839365578895335]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04909402063503459		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.04909402063503459 | validation: 0.029712574036964354]
	TIME [epoch: 14.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046218392678066475		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.046218392678066475 | validation: 0.02700553488522939]
	TIME [epoch: 14.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0709173805654878		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.0709173805654878 | validation: 0.033619578506316604]
	TIME [epoch: 14.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04964980233767081		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.04964980233767081 | validation: 0.021902734847102624]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410145255862298		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.0410145255862298 | validation: 0.043587151547419156]
	TIME [epoch: 14.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588472361077258		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.08588472361077258 | validation: 0.023228834339184216]
	TIME [epoch: 14.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04490089534562386		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.04490089534562386 | validation: 0.040594190958521105]
	TIME [epoch: 14.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06070907051159933		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.06070907051159933 | validation: 0.03660087611920919]
	TIME [epoch: 14.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545080113259058		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.05545080113259058 | validation: 0.03344423996703183]
	TIME [epoch: 14.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069801158806877		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.04069801158806877 | validation: 0.09582596704863]
	TIME [epoch: 14.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791040474385729		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.0791040474385729 | validation: 0.03759103047551758]
	TIME [epoch: 14.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750806314753442		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.03750806314753442 | validation: 0.019419373200373683]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031201761191787723		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.031201761191787723 | validation: 0.03454873301744675]
	TIME [epoch: 14.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04700570985689116		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.04700570985689116 | validation: 0.05540128141232655]
	TIME [epoch: 14.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261720060606853		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.03261720060606853 | validation: 0.01774477702176316]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530396447870678		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.04530396447870678 | validation: 0.024528280600404326]
	TIME [epoch: 14.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930318423664356		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.03930318423664356 | validation: 0.03167323326420822]
	TIME [epoch: 14.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026735690766837024		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.026735690766837024 | validation: 0.027682407941133292]
	TIME [epoch: 14.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714214991287271		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.05714214991287271 | validation: 0.029556148168503927]
	TIME [epoch: 14.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332455633548021		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.0332455633548021 | validation: 0.09750694262708778]
	TIME [epoch: 14.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10689673325963989		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.10689673325963989 | validation: 0.040451679380452]
	TIME [epoch: 14.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04920441654875921		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.04920441654875921 | validation: 0.029326668593558508]
	TIME [epoch: 14.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443535212539038		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.03443535212539038 | validation: 0.02659128461493315]
	TIME [epoch: 14.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786317754592943		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.05786317754592943 | validation: 0.054181730673791915]
	TIME [epoch: 14.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988329595505201		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.03988329595505201 | validation: 0.02770132063728359]
	TIME [epoch: 14.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03121130582572973		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.03121130582572973 | validation: 0.04081843756125377]
	TIME [epoch: 14.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026565896029408897		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.026565896029408897 | validation: 0.02522017507048173]
	TIME [epoch: 14.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489456084170859		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.03489456084170859 | validation: 0.02823197026476173]
	TIME [epoch: 14.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0312974507432244		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.0312974507432244 | validation: 0.019317088600618745]
	TIME [epoch: 14.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022762889093045968		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.022762889093045968 | validation: 0.02198697384906112]
	TIME [epoch: 14.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046197927547458474		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.046197927547458474 | validation: 0.04622590762196055]
	TIME [epoch: 14.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053227278793842814		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.053227278793842814 | validation: 0.02515769050371889]
	TIME [epoch: 14.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031882400454166224		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.031882400454166224 | validation: 0.02565809472978712]
	TIME [epoch: 14.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054252880800102876		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.054252880800102876 | validation: 0.023204812783586173]
	TIME [epoch: 14.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726988053110446		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.06726988053110446 | validation: 0.02984678576362522]
	TIME [epoch: 14.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0310381845250815		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.0310381845250815 | validation: 0.025531491429766545]
	TIME [epoch: 14.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028361947843016974		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.028361947843016974 | validation: 0.020020542074139752]
	TIME [epoch: 14.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030199044343333255		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.030199044343333255 | validation: 0.12513253705042213]
	TIME [epoch: 14.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897936551929021		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.0897936551929021 | validation: 0.06250905135226788]
	TIME [epoch: 14.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045894976799933096		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.045894976799933096 | validation: 0.03803998896725935]
	TIME [epoch: 14.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036065552914091		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.036065552914091 | validation: 0.023441557760262164]
	TIME [epoch: 14.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236604944812709		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.03236604944812709 | validation: 0.02138819695458649]
	TIME [epoch: 14.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026337841021408428		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.026337841021408428 | validation: 0.019189378924851504]
	TIME [epoch: 14.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08502657384533452		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.08502657384533452 | validation: 0.02273402311768852]
	TIME [epoch: 14.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029924591349826224		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.029924591349826224 | validation: 0.023947348918980673]
	TIME [epoch: 14.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028715667405602927		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.028715667405602927 | validation: 0.015568389811455911]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024066804087755272		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.024066804087755272 | validation: 0.030630074699571394]
	TIME [epoch: 14.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025418739613626763		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.025418739613626763 | validation: 0.01595061491754602]
	TIME [epoch: 14.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029163445521245043		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.029163445521245043 | validation: 0.062065210590652425]
	TIME [epoch: 14.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04602260994346087		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.04602260994346087 | validation: 0.3173965578247122]
	TIME [epoch: 14.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949550545803591		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.1949550545803591 | validation: 0.07180131518568995]
	TIME [epoch: 14.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06653714105631553		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.06653714105631553 | validation: 0.024911876029185438]
	TIME [epoch: 14.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026144945096487286		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.026144945096487286 | validation: 0.0442500506797963]
	TIME [epoch: 14.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259820933168186		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.07259820933168186 | validation: 0.020474067202353653]
	TIME [epoch: 14.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032323235358625496		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.032323235358625496 | validation: 0.024242066270194693]
	TIME [epoch: 14.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02694809232504227		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.02694809232504227 | validation: 0.01688686814163578]
	TIME [epoch: 14.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02185868458811642		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.02185868458811642 | validation: 0.08232047640075618]
	TIME [epoch: 14.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04834589592517628		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.04834589592517628 | validation: 0.025556292262126724]
	TIME [epoch: 14.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305869826661348		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.03305869826661348 | validation: 0.01760521750673598]
	TIME [epoch: 14.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03646403836482049		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.03646403836482049 | validation: 0.026753123401216408]
	TIME [epoch: 14.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021253802643714004		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.021253802643714004 | validation: 0.018126550792493215]
	TIME [epoch: 14.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04305122270628657		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.04305122270628657 | validation: 0.021948825326148655]
	TIME [epoch: 14.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02616236165016892		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.02616236165016892 | validation: 0.018275370101568725]
	TIME [epoch: 14.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016985092672092052		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.016985092672092052 | validation: 0.025010875459912034]
	TIME [epoch: 14.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02975763461705431		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.02975763461705431 | validation: 0.02297458293644935]
	TIME [epoch: 14.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966762942700617		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.03966762942700617 | validation: 0.018657452657338917]
	TIME [epoch: 14.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03103671444240197		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.03103671444240197 | validation: 0.01951214528249974]
	TIME [epoch: 14.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028695030323356		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.04028695030323356 | validation: 0.01486716481321208]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02180325196660643		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.02180325196660643 | validation: 0.01909966531059923]
	TIME [epoch: 14.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02168527413079277		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.02168527413079277 | validation: 0.015615892977907532]
	TIME [epoch: 14.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029263959434994838		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.029263959434994838 | validation: 0.06399145153336694]
	TIME [epoch: 14.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049987098842836794		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.049987098842836794 | validation: 0.0180445675857683]
	TIME [epoch: 14.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02136907994165125		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.02136907994165125 | validation: 0.014809529431120636]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020587294985596673		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.020587294985596673 | validation: 0.020741205042027266]
	TIME [epoch: 14.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222691302842819		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.02222691302842819 | validation: 0.012566280201963717]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016579988402025164		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.016579988402025164 | validation: 0.021703411783919078]
	TIME [epoch: 14.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02105677851086996		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.02105677851086996 | validation: 0.018744488198038083]
	TIME [epoch: 14.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04845652276083909		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.04845652276083909 | validation: 0.042572303858289084]
	TIME [epoch: 14.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03247150182956328		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.03247150182956328 | validation: 0.019402791397640194]
	TIME [epoch: 14.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0294627387418371		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.0294627387418371 | validation: 0.02093911613330446]
	TIME [epoch: 14.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024207820659737707		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.024207820659737707 | validation: 0.026732373718259688]
	TIME [epoch: 14.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022879847903275637		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.022879847903275637 | validation: 0.011955750238589292]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018035439812478606		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.018035439812478606 | validation: 0.015186939842088312]
	TIME [epoch: 14.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029061858157567618		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.029061858157567618 | validation: 0.01846799073419959]
	TIME [epoch: 14.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020841805501997105		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.020841805501997105 | validation: 0.03469880115457088]
	TIME [epoch: 14.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236954655907709		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.03236954655907709 | validation: 0.04510122060986566]
	TIME [epoch: 14.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330739946042084		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.0330739946042084 | validation: 0.03228596802721524]
	TIME [epoch: 14.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021494299737949467		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.021494299737949467 | validation: 0.043607690233939025]
	TIME [epoch: 14.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030637873849253837		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.030637873849253837 | validation: 0.01449797408284625]
	TIME [epoch: 14.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02417371295427398		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.02417371295427398 | validation: 0.023990020752743167]
	TIME [epoch: 14.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020111182710281297		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.020111182710281297 | validation: 0.01771198894629631]
	TIME [epoch: 14.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022000850410364634		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.022000850410364634 | validation: 0.011529901154320371]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018851990584530385		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.018851990584530385 | validation: 0.028856607263966803]
	TIME [epoch: 14.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025229608325600773		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.025229608325600773 | validation: 0.016154476755761222]
	TIME [epoch: 14.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0218186608069576		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.0218186608069576 | validation: 0.020839722660143823]
	TIME [epoch: 14.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473017949465597		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.02473017949465597 | validation: 0.01868076489739831]
	TIME [epoch: 14.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018322668384222352		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.018322668384222352 | validation: 0.022076969641814548]
	TIME [epoch: 14.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025070190089935343		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.025070190089935343 | validation: 0.011530161048260667]
	TIME [epoch: 14.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028600787262859792		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.028600787262859792 | validation: 0.0266381510628275]
	TIME [epoch: 14.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031768459237212235		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.031768459237212235 | validation: 0.014762089225930952]
	TIME [epoch: 14.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020673253334082407		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.020673253334082407 | validation: 0.015322557465146623]
	TIME [epoch: 14.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022036910770459786		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.022036910770459786 | validation: 0.017174457092801076]
	TIME [epoch: 14.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026102542365336663		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.026102542365336663 | validation: 0.014322713666995328]
	TIME [epoch: 14.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030130931812294096		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.030130931812294096 | validation: 0.019815934355804435]
	TIME [epoch: 14.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896572139979643		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.04896572139979643 | validation: 0.0631956728302384]
	TIME [epoch: 14.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05608304013382077		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.05608304013382077 | validation: 0.01520842279960773]
	TIME [epoch: 14.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960812000810679		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.01960812000810679 | validation: 0.013559137072225603]
	TIME [epoch: 14.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016926973547847102		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.016926973547847102 | validation: 0.01466947103523752]
	TIME [epoch: 14.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017689693469489502		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.017689693469489502 | validation: 0.014652704514790438]
	TIME [epoch: 14.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025132360092356833		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.025132360092356833 | validation: 0.018526286186647575]
	TIME [epoch: 14.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026187043158966188		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.026187043158966188 | validation: 0.013373305598035302]
	TIME [epoch: 14.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0439817943321814		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.0439817943321814 | validation: 0.01617399036670393]
	TIME [epoch: 14.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020580241375215594		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.020580241375215594 | validation: 0.018369772467098037]
	TIME [epoch: 14.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019652536244719025		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.019652536244719025 | validation: 0.014953492099851863]
	TIME [epoch: 14.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706083741831263		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.01706083741831263 | validation: 0.01573479533473726]
	TIME [epoch: 14.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019645706540229867		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.019645706540229867 | validation: 0.04769272632305038]
	TIME [epoch: 14.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037843813166306854		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.037843813166306854 | validation: 0.01571317808888662]
	TIME [epoch: 14.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021040336731478402		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.021040336731478402 | validation: 0.0191280554330009]
	TIME [epoch: 14.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018839821151865596		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.018839821151865596 | validation: 0.016080189398167022]
	TIME [epoch: 14.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383375879740002		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.0383375879740002 | validation: 0.023639983493642]
	TIME [epoch: 14.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0286052305846291		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.0286052305846291 | validation: 0.013342079533712985]
	TIME [epoch: 14.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0270379660267826		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.0270379660267826 | validation: 0.023872838856465708]
	TIME [epoch: 14.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032399213039568636		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.032399213039568636 | validation: 0.018867550615085365]
	TIME [epoch: 14.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021029874695028615		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.021029874695028615 | validation: 0.011064661691100522]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017160503552895952		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.017160503552895952 | validation: 0.01884973055025038]
	TIME [epoch: 14.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023938443112723785		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.023938443112723785 | validation: 0.016129365451905044]
	TIME [epoch: 14.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017677744013170085		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.017677744013170085 | validation: 0.015558710129460633]
	TIME [epoch: 14.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017732956585397294		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.017732956585397294 | validation: 0.09173198764793963]
	TIME [epoch: 14.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912476542269933		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.10912476542269933 | validation: 0.036006265848153224]
	TIME [epoch: 14.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021892313759868616		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.021892313759868616 | validation: 0.018834090378130653]
	TIME [epoch: 14.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027088392055146227		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.027088392055146227 | validation: 0.017106777677996093]
	TIME [epoch: 14.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018472773461332623		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.018472773461332623 | validation: 0.015579838209682544]
	TIME [epoch: 14.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018056631346526065		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.018056631346526065 | validation: 0.015520548239669116]
	TIME [epoch: 14.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014274171782619815		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.014274171782619815 | validation: 0.014375233009413353]
	TIME [epoch: 14.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018272625588865866		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.018272625588865866 | validation: 0.015150143080472777]
	TIME [epoch: 14.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015222557581891142		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.015222557581891142 | validation: 0.016869232326089827]
	TIME [epoch: 14.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168669319376377		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.03168669319376377 | validation: 0.015459202921322291]
	TIME [epoch: 14.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590549683894714		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.02590549683894714 | validation: 0.01625081279645825]
	TIME [epoch: 14.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473474229178517		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.02473474229178517 | validation: 0.015226729204361692]
	TIME [epoch: 14.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023835207840149704		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.023835207840149704 | validation: 0.012618254653731254]
	TIME [epoch: 14.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01862528910614871		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.01862528910614871 | validation: 0.024022365940995376]
	TIME [epoch: 14.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02429671364949554		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.02429671364949554 | validation: 0.013448316552934707]
	TIME [epoch: 14.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317341734299955		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.0317341734299955 | validation: 0.014176404336825679]
	TIME [epoch: 14.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026282582433474682		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.026282582433474682 | validation: 0.011750813921669913]
	TIME [epoch: 14.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015418458715747438		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.015418458715747438 | validation: 0.01870170808301396]
	TIME [epoch: 14.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016167779352836097		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.016167779352836097 | validation: 0.01248414295869876]
	TIME [epoch: 14.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014642954358914316		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.014642954358914316 | validation: 0.015700088757693267]
	TIME [epoch: 14.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018603589950053043		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.018603589950053043 | validation: 0.01348306323964758]
	TIME [epoch: 14.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02112181445902345		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.02112181445902345 | validation: 0.01766004960350597]
	TIME [epoch: 14.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052510619910063304		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.052510619910063304 | validation: 0.032330672789287876]
	TIME [epoch: 14.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403632514098055		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.02403632514098055 | validation: 0.011254565975860796]
	TIME [epoch: 14.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026876966912296553		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.026876966912296553 | validation: 0.019108929510095136]
	TIME [epoch: 14.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019123937499943833		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.019123937499943833 | validation: 0.013834433485216959]
	TIME [epoch: 14.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01564001377009447		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.01564001377009447 | validation: 0.012029845085270031]
	TIME [epoch: 14.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375743350530913		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.03375743350530913 | validation: 0.02261580453016051]
	TIME [epoch: 14.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01647605289195285		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.01647605289195285 | validation: 0.07129204876159473]
	TIME [epoch: 14.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930645271194927		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.03930645271194927 | validation: 0.014318852080687512]
	TIME [epoch: 14.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014747079031158844		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.014747079031158844 | validation: 0.011762754025526147]
	TIME [epoch: 14.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015028919778108465		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.015028919778108465 | validation: 0.016303319331511815]
	TIME [epoch: 14.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018637268879668593		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.018637268879668593 | validation: 0.02961433951862311]
	TIME [epoch: 14.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02400171136556005		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.02400171136556005 | validation: 0.01650828944927947]
	TIME [epoch: 14.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025988719153865053		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.025988719153865053 | validation: 0.01901248756624286]
	TIME [epoch: 14.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02006205669713935		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.02006205669713935 | validation: 0.027760868631521433]
	TIME [epoch: 14.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028437961563371965		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.028437961563371965 | validation: 0.024494037618262222]
	TIME [epoch: 14.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021832773439980597		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.021832773439980597 | validation: 0.019890702326633862]
	TIME [epoch: 14.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017989407166219544		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.017989407166219544 | validation: 0.014125426044805727]
	TIME [epoch: 14.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04409322774442693		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.04409322774442693 | validation: 0.037161445978904056]
	TIME [epoch: 14.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030615066198649905		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.030615066198649905 | validation: 0.015161428392421404]
	TIME [epoch: 14.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369001289617058		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.02369001289617058 | validation: 0.018141756480904266]
	TIME [epoch: 14.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021972595329599193		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.021972595329599193 | validation: 0.08052130323880408]
	TIME [epoch: 14.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843272711206924		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.05843272711206924 | validation: 0.012316107764571607]
	TIME [epoch: 14.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018150962473041512		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.018150962473041512 | validation: 0.01659743469732907]
	TIME [epoch: 14.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018026050365133328		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.018026050365133328 | validation: 0.011945583266369188]
	TIME [epoch: 14.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014911633924189805		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.014911633924189805 | validation: 0.013976595598005067]
	TIME [epoch: 14.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016956826234631694		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.016956826234631694 | validation: 0.013683602830497917]
	TIME [epoch: 14.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016766060407554507		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.016766060407554507 | validation: 0.010372939553414718]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017209687265908526		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.017209687265908526 | validation: 0.01568994909119747]
	TIME [epoch: 14.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018711632124032183		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.018711632124032183 | validation: 0.01871547655069964]
	TIME [epoch: 14.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014867566819617649		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.014867566819617649 | validation: 0.019360076909978607]
	TIME [epoch: 14.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850081045424202		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.01850081045424202 | validation: 0.012035253218317431]
	TIME [epoch: 14.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664203798542977		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.03664203798542977 | validation: 0.012663287504186289]
	TIME [epoch: 14.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01676703340130347		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.01676703340130347 | validation: 0.010318572175130537]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013721157784675395		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.013721157784675395 | validation: 0.011336326497568897]
	TIME [epoch: 14.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016435542110748394		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.016435542110748394 | validation: 0.014179677703619003]
	TIME [epoch: 14.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018166831415823412		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.018166831415823412 | validation: 0.011682030629959223]
	TIME [epoch: 14.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015367418081093327		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.015367418081093327 | validation: 0.015389563328634172]
	TIME [epoch: 14.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019946939660381666		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.019946939660381666 | validation: 0.01482588295177862]
	TIME [epoch: 14.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017678581974819894		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.017678581974819894 | validation: 0.0121186180370076]
	TIME [epoch: 14.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014583677817796781		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.014583677817796781 | validation: 0.015031390619598104]
	TIME [epoch: 14.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976737334950756		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.03976737334950756 | validation: 0.0697174166768109]
	TIME [epoch: 14.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530972887415815		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.07530972887415815 | validation: 0.029746667401337915]
	TIME [epoch: 14.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408074041384757		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.02408074041384757 | validation: 0.010658810789279233]
	TIME [epoch: 14.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013342261573981861		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.013342261573981861 | validation: 0.012795635145427968]
	TIME [epoch: 14.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075570692242025		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.07075570692242025 | validation: 0.01487199707299668]
	TIME [epoch: 14.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017051844454418277		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.017051844454418277 | validation: 0.01279965053230193]
	TIME [epoch: 14.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012169713703670974		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.012169713703670974 | validation: 0.012355857484435713]
	TIME [epoch: 14.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013253604665994002		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.013253604665994002 | validation: 0.013062079135133353]
	TIME [epoch: 14.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013169799073027087		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.013169799073027087 | validation: 0.014180831647120574]
	TIME [epoch: 14.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015137973856575039		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.015137973856575039 | validation: 0.011109273786733898]
	TIME [epoch: 14.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059455522956010726		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.059455522956010726 | validation: 0.0257765467810817]
	TIME [epoch: 14.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02139191719525437		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.02139191719525437 | validation: 0.027687998147591313]
	TIME [epoch: 14.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0189807094456777		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.0189807094456777 | validation: 0.021312277800485977]
	TIME [epoch: 14.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0161920052467774		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.0161920052467774 | validation: 0.012364848580800253]
	TIME [epoch: 14.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013134755032718525		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.013134755032718525 | validation: 0.014806583514096569]
	TIME [epoch: 14.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014848055850296651		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.014848055850296651 | validation: 0.01748250871055754]
	TIME [epoch: 14.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015399506354896711		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.015399506354896711 | validation: 0.012036085142774421]
	TIME [epoch: 14.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01358646992463184		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.01358646992463184 | validation: 0.011605803246514921]
	TIME [epoch: 14.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015469955213856195		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.015469955213856195 | validation: 0.01177292982652806]
	TIME [epoch: 14.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014347431949930647		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.014347431949930647 | validation: 0.03052171342732172]
	TIME [epoch: 14.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020728039828389003		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.020728039828389003 | validation: 0.012356728970140231]
	TIME [epoch: 14.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017160634288390802		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.017160634288390802 | validation: 0.0120872476852685]
	TIME [epoch: 14.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013731761878542558		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.013731761878542558 | validation: 0.04876754947400917]
	TIME [epoch: 14.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030058297488470616		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.030058297488470616 | validation: 0.012048102662792376]
	TIME [epoch: 14.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927998504417892		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.01927998504417892 | validation: 0.016049154221497094]
	TIME [epoch: 14.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592482323403121		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.01592482323403121 | validation: 0.01172829439568366]
	TIME [epoch: 14.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01524047641165802		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.01524047641165802 | validation: 0.017884725387912657]
	TIME [epoch: 14.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015491911360690593		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.015491911360690593 | validation: 0.022586000899771662]
	TIME [epoch: 14.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016897793381541574		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.016897793381541574 | validation: 0.011055847875623664]
	TIME [epoch: 14.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014186654900195883		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.014186654900195883 | validation: 0.018265765744608437]
	TIME [epoch: 14.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01436794641606567		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.01436794641606567 | validation: 0.013065686824740214]
	TIME [epoch: 14.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534397372310598		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.02534397372310598 | validation: 0.012004314291911984]
	TIME [epoch: 14.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012272527190538066		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.012272527190538066 | validation: 0.011686406019930602]
	TIME [epoch: 14.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013005496883233178		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.013005496883233178 | validation: 0.03622362571682177]
	TIME [epoch: 14.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028508787228462475		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.028508787228462475 | validation: 0.01914542352446651]
	TIME [epoch: 14.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01690785517996518		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.01690785517996518 | validation: 0.011348121694068593]
	TIME [epoch: 14.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02951352228016662		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.02951352228016662 | validation: 0.021758655624547877]
	TIME [epoch: 14.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03350546139470733		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.03350546139470733 | validation: 0.029071376515013295]
	TIME [epoch: 14.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022281285260349778		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.022281285260349778 | validation: 0.012890288895615986]
	TIME [epoch: 14.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027956911600255333		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.027956911600255333 | validation: 0.013977388070364456]
	TIME [epoch: 14.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014476381940203427		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.014476381940203427 | validation: 0.011697858911564123]
	TIME [epoch: 14.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013127170762770651		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.013127170762770651 | validation: 0.01142106232487667]
	TIME [epoch: 14.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014290170056136114		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.014290170056136114 | validation: 0.01261922016696246]
	TIME [epoch: 14.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031124803560208518		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.031124803560208518 | validation: 0.0197123450099848]
	TIME [epoch: 147 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015187283535229669		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.015187283535229669 | validation: 0.027261763575644055]
	TIME [epoch: 31.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020468412485003168		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.020468412485003168 | validation: 0.012022130584637932]
	TIME [epoch: 31.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013043595749855322		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.013043595749855322 | validation: 0.011364481898367071]
	TIME [epoch: 31.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017409393808328066		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.017409393808328066 | validation: 0.015501164490994625]
	TIME [epoch: 31.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04391455272168483		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.04391455272168483 | validation: 0.0129640663175218]
	TIME [epoch: 31.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014898468455050785		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.014898468455050785 | validation: 0.009173133876199358]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_507.pth
	Model improved!!!
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011405642497249008		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.011405642497249008 | validation: 0.016248169560437835]
	TIME [epoch: 31.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01402103595935157		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.01402103595935157 | validation: 0.01135857653024527]
	TIME [epoch: 31.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013930619761161799		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.013930619761161799 | validation: 0.0136044162567744]
	TIME [epoch: 31.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014693689510507955		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.014693689510507955 | validation: 0.01359858324989631]
	TIME [epoch: 31.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0121780306942606		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.0121780306942606 | validation: 0.0263129264666878]
	TIME [epoch: 31.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016157282803477842		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.016157282803477842 | validation: 0.02772256511540948]
	TIME [epoch: 31.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018605285446054193		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.018605285446054193 | validation: 0.013061139145543943]
	TIME [epoch: 31.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024550268577439378		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.024550268577439378 | validation: 0.012097807284097376]
	TIME [epoch: 31.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014924218876697398		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.014924218876697398 | validation: 0.011729595243095773]
	TIME [epoch: 31.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0191449072487093		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.0191449072487093 | validation: 0.013008521807423195]
	TIME [epoch: 31.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014279071853961475		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.014279071853961475 | validation: 0.011151651191757934]
	TIME [epoch: 31.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027014229330600038		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.027014229330600038 | validation: 0.015135532869981198]
	TIME [epoch: 31.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014652299534856984		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.014652299534856984 | validation: 0.013038681196339186]
	TIME [epoch: 31.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012093569147769209		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.012093569147769209 | validation: 0.009679513918305143]
	TIME [epoch: 31.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01471445006620398		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.01471445006620398 | validation: 0.013339629011547153]
	TIME [epoch: 31.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01317625246754947		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.01317625246754947 | validation: 0.020931720307007726]
	TIME [epoch: 31.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0160457214615858		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.0160457214615858 | validation: 0.011052490635038301]
	TIME [epoch: 31.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014375740358466508		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.014375740358466508 | validation: 0.01221707553855264]
	TIME [epoch: 31.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015533370883538351		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.015533370883538351 | validation: 0.012002614679460998]
	TIME [epoch: 31.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018196610852645137		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.018196610852645137 | validation: 0.014178723819969189]
	TIME [epoch: 31.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030656198979781935		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.030656198979781935 | validation: 0.0401924165266733]
	TIME [epoch: 31.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033232207046720384		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.033232207046720384 | validation: 0.01210952881314427]
	TIME [epoch: 31.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015207705664216455		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.015207705664216455 | validation: 0.01234873963066848]
	TIME [epoch: 31.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01374596019530317		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.01374596019530317 | validation: 0.012949638666939427]
	TIME [epoch: 31.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013980722570575864		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.013980722570575864 | validation: 0.010993144676552435]
	TIME [epoch: 31.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014610485437139362		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.014610485437139362 | validation: 0.015948123676816646]
	TIME [epoch: 31.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0216508966630431		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.0216508966630431 | validation: 0.014711408881720957]
	TIME [epoch: 31.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014791327114592911		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.014791327114592911 | validation: 0.013189964997612923]
	TIME [epoch: 31.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014509878286860083		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.014509878286860083 | validation: 0.014210006200757064]
	TIME [epoch: 31.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014517753019105588		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.014517753019105588 | validation: 0.010356046677277776]
	TIME [epoch: 31.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01171374042533426		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.01171374042533426 | validation: 0.012035547889259429]
	TIME [epoch: 31.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014011990410054503		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.014011990410054503 | validation: 0.011955638127477325]
	TIME [epoch: 31.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014407229651952947		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.014407229651952947 | validation: 0.013216167955352803]
	TIME [epoch: 31.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014375101113371893		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.014375101113371893 | validation: 0.03131049539381277]
	TIME [epoch: 31.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02006476980841213		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.02006476980841213 | validation: 0.020836221187137807]
	TIME [epoch: 31.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01889922109482206		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.01889922109482206 | validation: 0.017287675692873265]
	TIME [epoch: 31.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030835712531537295		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.030835712531537295 | validation: 0.018137897591789673]
	TIME [epoch: 31.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014820486259989848		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.014820486259989848 | validation: 0.014426989224264535]
	TIME [epoch: 31.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014267201230749772		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.014267201230749772 | validation: 0.01246769016310265]
	TIME [epoch: 31.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015581011704041366		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.015581011704041366 | validation: 0.011674861208312019]
	TIME [epoch: 31.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01353116051505508		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.01353116051505508 | validation: 0.012038125012773635]
	TIME [epoch: 31.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012930480104867016		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.012930480104867016 | validation: 0.011559162112777813]
	TIME [epoch: 31.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023247175745690483		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.023247175745690483 | validation: 0.010824154276590342]
	TIME [epoch: 31.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043795542593736705		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.043795542593736705 | validation: 0.04953080648821993]
	TIME [epoch: 31.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320155307328077		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.03320155307328077 | validation: 0.013210922340873796]
	TIME [epoch: 31.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014374603565839549		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.014374603565839549 | validation: 0.014219317160888676]
	TIME [epoch: 31.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01374018965090935		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.01374018965090935 | validation: 0.012300662929374963]
	TIME [epoch: 31.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0130989143135056		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0130989143135056 | validation: 0.011711734894136891]
	TIME [epoch: 31.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011985147795883243		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.011985147795883243 | validation: 0.012166380867020474]
	TIME [epoch: 31.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021946518451793948		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.021946518451793948 | validation: 0.012700350235804805]
	TIME [epoch: 31.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014682198060089401		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.014682198060089401 | validation: 0.010050048725886619]
	TIME [epoch: 31.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013559294499291085		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.013559294499291085 | validation: 0.012112100829882688]
	TIME [epoch: 31.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01384943071142311		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.01384943071142311 | validation: 0.009629599804257807]
	TIME [epoch: 31.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012201718437185462		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.012201718437185462 | validation: 0.009981527340924072]
	TIME [epoch: 31.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013290826240157882		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.013290826240157882 | validation: 0.010941012518982343]
	TIME [epoch: 31.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012744124441570647		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.012744124441570647 | validation: 0.010669071858045793]
	TIME [epoch: 31.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013547132115279189		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.013547132115279189 | validation: 0.010565137380145476]
	TIME [epoch: 31.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011945554884533261		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.011945554884533261 | validation: 0.012054805224707822]
	TIME [epoch: 31.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013798953500019783		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.013798953500019783 | validation: 0.014629615515930616]
	TIME [epoch: 31.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015342904952734498		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.015342904952734498 | validation: 0.012928457599083294]
	TIME [epoch: 31.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016452132065218127		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.016452132065218127 | validation: 0.010478754940745223]
	TIME [epoch: 31.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012241187344848213		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.012241187344848213 | validation: 0.016254928718850852]
	TIME [epoch: 31.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013829086613477447		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.013829086613477447 | validation: 0.01123403602080709]
	TIME [epoch: 31.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012406494484969431		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.012406494484969431 | validation: 0.015167502989433809]
	TIME [epoch: 31.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014058063311850668		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.014058063311850668 | validation: 0.012344235329202322]
	TIME [epoch: 31.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014356369031648112		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.014356369031648112 | validation: 0.018506280036605954]
	TIME [epoch: 31.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016758868360704938		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.016758868360704938 | validation: 0.011172558283656655]
	TIME [epoch: 31.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012686518297450388		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.012686518297450388 | validation: 0.013459061964317533]
	TIME [epoch: 31.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019769850802380647		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.019769850802380647 | validation: 0.01337114124709315]
	TIME [epoch: 31.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013303852084760594		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.013303852084760594 | validation: 0.011302986411912118]
	TIME [epoch: 31.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012375307890814008		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.012375307890814008 | validation: 0.011186886977403408]
	TIME [epoch: 31.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012652048026705656		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.012652048026705656 | validation: 0.010985735977731902]
	TIME [epoch: 31.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013579116297541657		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.013579116297541657 | validation: 0.009803376769500058]
	TIME [epoch: 31.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011517989189271844		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.011517989189271844 | validation: 0.010805125371727998]
	TIME [epoch: 31.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012458349840757967		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.012458349840757967 | validation: 0.00990730286094976]
	TIME [epoch: 31.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011034437360869996		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.011034437360869996 | validation: 0.00970020913432725]
	TIME [epoch: 31.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012252397932158777		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.012252397932158777 | validation: 0.01085358725143453]
	TIME [epoch: 31.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013026399820802122		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.013026399820802122 | validation: 0.015805193840648112]
	TIME [epoch: 31.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014058452190099015		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.014058452190099015 | validation: 0.010595695351249539]
	TIME [epoch: 31.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256330640224279		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.03256330640224279 | validation: 0.019803612761653447]
	TIME [epoch: 31.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018316457850805812		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.018316457850805812 | validation: 0.012572500298397295]
	TIME [epoch: 31.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021382632191195964		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.021382632191195964 | validation: 0.017814191797075517]
	TIME [epoch: 31.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016211063694253246		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.016211063694253246 | validation: 0.012160293686333432]
	TIME [epoch: 31.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013096745938771468		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.013096745938771468 | validation: 0.011039888055728697]
	TIME [epoch: 31.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012679282156118925		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.012679282156118925 | validation: 0.009684253770073856]
	TIME [epoch: 31.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012640073384834902		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.012640073384834902 | validation: 0.010222289264227205]
	TIME [epoch: 31.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014286815525553238		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.014286815525553238 | validation: 0.010513329646570617]
	TIME [epoch: 31.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01239480548774452		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.01239480548774452 | validation: 0.013230479315229804]
	TIME [epoch: 31.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012420590616167569		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.012420590616167569 | validation: 0.013226308846552138]
	TIME [epoch: 31.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023133177016187674		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.023133177016187674 | validation: 0.01438440536681356]
	TIME [epoch: 31.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013284788765554669		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.013284788765554669 | validation: 0.011157048346193056]
	TIME [epoch: 31.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013086704603434918		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.013086704603434918 | validation: 0.016686131124970874]
	TIME [epoch: 31.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01327570622916844		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.01327570622916844 | validation: 0.018390340824335445]
	TIME [epoch: 31.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016020288840600874		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.016020288840600874 | validation: 0.010889499037904227]
	TIME [epoch: 31.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013906848574994201		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.013906848574994201 | validation: 0.010182568868679602]
	TIME [epoch: 31.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012905162192831892		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.012905162192831892 | validation: 0.010934655759006595]
	TIME [epoch: 31.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013923559281550443		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.013923559281550443 | validation: 0.010605795492108312]
	TIME [epoch: 31.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019926139493513025		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.019926139493513025 | validation: 0.022509635566608933]
	TIME [epoch: 31.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01594947148813345		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.01594947148813345 | validation: 0.012928433925624887]
	TIME [epoch: 31.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01355685809981509		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.01355685809981509 | validation: 0.013374444298873016]
	TIME [epoch: 31.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550370511044825		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.03550370511044825 | validation: 0.01113310617898536]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240704_142345/states/model_phi2_1a_v_mmd1_608.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 9761.936 seconds.
