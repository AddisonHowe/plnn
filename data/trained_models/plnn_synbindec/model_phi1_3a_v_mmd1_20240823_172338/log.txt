Args:
Namespace(name='model_phi1_3a_v_mmd1', outdir='out/model_training/model_phi1_3a_v_mmd1', training_data='data/training_data/data_phi1_3a/training', validation_data='data/training_data/data_phi1_3a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2335607701

Training model...

Saving initial model state to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.894472239593968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.894472239593968 | validation: 4.331807985998013]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.649605276506483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.649605276506483 | validation: 4.288417027915166]
	TIME [epoch: 0.971 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4833060097265007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4833060097265007 | validation: 2.819420628250984]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9168768063219863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9168768063219863 | validation: 3.793122743222195]
	TIME [epoch: 0.923 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4031188136444745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4031188136444745 | validation: 2.966984338588937]
	TIME [epoch: 0.921 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.481015354934457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.481015354934457 | validation: 2.299422364894685]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9115197910099346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9115197910099346 | validation: 2.0829567355519427]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9624382739652413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9624382739652413 | validation: 1.8819061957405445]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6396842283559772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6396842283559772 | validation: 1.7803374677555632]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4606356882183005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4606356882183005 | validation: 1.751973377278845]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4176328137019334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4176328137019334 | validation: 1.700684177328584]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.38743268908304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.38743268908304 | validation: 1.7310655196821447]
	TIME [epoch: 0.917 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4131555200617345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4131555200617345 | validation: 1.6665344345606332]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3967552704256962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3967552704256962 | validation: 1.6331262905762083]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.28092358259296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.28092358259296 | validation: 1.5874403295948798]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2249796770948198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2249796770948198 | validation: 1.5458088232106568]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.186599276010673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.186599276010673 | validation: 1.52827473954855]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1824151720662999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1824151720662999 | validation: 1.5375785208840482]
	TIME [epoch: 0.919 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1837653363941443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1837653363941443 | validation: 1.5436506799414162]
	TIME [epoch: 0.927 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1834666783032266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1834666783032266 | validation: 1.5079290811501211]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1635397295768721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1635397295768721 | validation: 1.5013562082460494]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1485594161676986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1485594161676986 | validation: 1.4763758828605908]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1333171645255977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1333171645255977 | validation: 1.485478864768042]
	TIME [epoch: 0.918 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1301117208746871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1301117208746871 | validation: 1.4644112037311925]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.123038887435042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.123038887435042 | validation: 1.4672802032527603]
	TIME [epoch: 0.917 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1248557590042583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1248557590042583 | validation: 1.4428693250745284]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1186185665259034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1186185665259034 | validation: 1.4567197371973266]
	TIME [epoch: 0.917 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1064099219079193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1064099219079193 | validation: 1.4082129344072576]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0985632812312247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0985632812312247 | validation: 1.4233178639784694]
	TIME [epoch: 0.915 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.088307265526973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.088307265526973 | validation: 1.3839073416595076]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.071842386948619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.071842386948619 | validation: 1.384112063389872]
	TIME [epoch: 0.917 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0688531709563631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0688531709563631 | validation: 1.3631452362046041]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.063003400835799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.063003400835799 | validation: 1.3703775960767277]
	TIME [epoch: 0.921 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0579734586673974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0579734586673974 | validation: 1.3408829513434135]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0424178487871163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0424178487871163 | validation: 1.3375688206663052]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0404923901135645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0404923901135645 | validation: 1.3092639206553316]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.027150531936847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.027150531936847 | validation: 1.3213137525059455]
	TIME [epoch: 0.919 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0202942436344662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0202942436344662 | validation: 1.2795217245524613]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0074634507410831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0074634507410831 | validation: 1.2800294285805172]
	TIME [epoch: 0.916 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0019585753907019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0019585753907019 | validation: 1.243594316420056]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.989328539543197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.989328539543197 | validation: 1.2643983365643798]
	TIME [epoch: 0.918 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9870798995952876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9870798995952876 | validation: 1.2258293060921894]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9847612177781531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9847612177781531 | validation: 1.2451474509206635]
	TIME [epoch: 0.917 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9864903546845163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9864903546845163 | validation: 1.2221570803797341]
	TIME [epoch: 0.912 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9767048761149982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9767048761149982 | validation: 1.2235433450313358]
	TIME [epoch: 0.919 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9757568997154846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9757568997154846 | validation: 1.2175591989472059]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9552142628211746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9552142628211746 | validation: 1.183358689095322]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9575133638398384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9575133638398384 | validation: 1.1739654140993523]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9359113800491556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9359113800491556 | validation: 1.1426225977983073]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9262181594171724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9262181594171724 | validation: 1.1277039092759107]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9188144090503392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9188144090503392 | validation: 1.185900038054913]
	TIME [epoch: 0.914 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9600912769042266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9600912769042266 | validation: 1.1346397637572647]
	TIME [epoch: 0.916 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9932976877103219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9932976877103219 | validation: 1.2372495075810825]
	TIME [epoch: 0.926 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9892980186836877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9892980186836877 | validation: 1.0836649144563377]
	TIME [epoch: 0.911 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8894289792086665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8894289792086665 | validation: 1.084248758174425]
	TIME [epoch: 0.917 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8854826378273005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8854826378273005 | validation: 1.105700724283975]
	TIME [epoch: 0.922 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8963892421302014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8963892421302014 | validation: 1.0396102584597176]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8904655095402637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8904655095402637 | validation: 1.0728392063329117]
	TIME [epoch: 0.917 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.878322484362445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.878322484362445 | validation: 1.0393904810792935]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8854894213896453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8854894213896453 | validation: 1.086867299242306]
	TIME [epoch: 0.919 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9157031885242068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9157031885242068 | validation: 1.20540670318441]
	TIME [epoch: 0.916 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0265788929936863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0265788929936863 | validation: 1.099554567236554]
	TIME [epoch: 0.915 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9304430055773151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9304430055773151 | validation: 1.0995902564984998]
	TIME [epoch: 0.916 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9158370554863531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9158370554863531 | validation: 1.004422907895333]
	TIME [epoch: 0.914 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8931271212196251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8931271212196251 | validation: 1.043945924299925]
	TIME [epoch: 0.914 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8867419778689358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8867419778689358 | validation: 1.012821286859538]
	TIME [epoch: 0.916 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8643767298290151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8643767298290151 | validation: 1.0047885272658112]
	TIME [epoch: 0.918 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8598394973353033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8598394973353033 | validation: 1.0056701306551534]
	TIME [epoch: 0.915 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8513678457205386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8513678457205386 | validation: 0.980530275436469]
	TIME [epoch: 0.915 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8577098779291734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8577098779291734 | validation: 0.9976234003405203]
	TIME [epoch: 0.916 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8623135306898516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8623135306898516 | validation: 1.043515814364676]
	TIME [epoch: 0.916 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8898839081609858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8898839081609858 | validation: 1.0657653277353987]
	TIME [epoch: 0.919 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9586609683016019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9586609683016019 | validation: 1.2054473614126224]
	TIME [epoch: 1.17 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0415549561561934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0415549561561934 | validation: 1.0207736313659348]
	TIME [epoch: 0.917 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9130790844443655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9130790844443655 | validation: 1.0707928957111044]
	TIME [epoch: 0.909 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9547647835221134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9547647835221134 | validation: 0.9659173962664961]
	TIME [epoch: 0.91 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8492044088254147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8492044088254147 | validation: 0.9748673478152942]
	TIME [epoch: 0.91 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8674411017640836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8674411017640836 | validation: 1.0158587709844051]
	TIME [epoch: 0.912 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8711415174995117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8711415174995117 | validation: 0.9900680069373586]
	TIME [epoch: 0.913 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8809671283621787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8809671283621787 | validation: 1.0634530219764755]
	TIME [epoch: 0.911 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.926290491674941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.926290491674941 | validation: 0.9970641270582283]
	TIME [epoch: 0.908 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9155555339795298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9155555339795298 | validation: 1.0414598987468877]
	TIME [epoch: 0.911 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9068203779064541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9068203779064541 | validation: 0.9728439278553092]
	TIME [epoch: 0.91 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8610161332480393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8610161332480393 | validation: 0.9804973747031568]
	TIME [epoch: 0.91 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8460849870508491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8460849870508491 | validation: 0.970431997913832]
	TIME [epoch: 0.908 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8498855731911217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8498855731911217 | validation: 0.9498586751066553]
	TIME [epoch: 0.91 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8462175179585918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8462175179585918 | validation: 0.9689663585060995]
	TIME [epoch: 0.912 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8593652831539084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8593652831539084 | validation: 0.9748270848904398]
	TIME [epoch: 0.91 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8798939945415745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8798939945415745 | validation: 1.0692256187617375]
	TIME [epoch: 0.911 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9461557717088327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9461557717088327 | validation: 1.0432612961976153]
	TIME [epoch: 0.911 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9586944429135632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9586944429135632 | validation: 1.0568761694303113]
	TIME [epoch: 0.913 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9339268573586251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9339268573586251 | validation: 0.9671316613284621]
	TIME [epoch: 0.91 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.854468858970531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.854468858970531 | validation: 0.9396631323787124]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8559549403251977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8559549403251977 | validation: 0.9668747654138308]
	TIME [epoch: 0.918 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8756449271960746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8756449271960746 | validation: 0.9767923337958776]
	TIME [epoch: 0.919 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8810679341579544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8810679341579544 | validation: 1.0064962690914008]
	TIME [epoch: 0.932 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9028491911665363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9028491911665363 | validation: 0.9703056637332077]
	TIME [epoch: 0.917 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8678621176871631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8678621176871631 | validation: 0.9467491864989651]
	TIME [epoch: 0.92 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8616438664822232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8616438664822232 | validation: 1.0019613425973428]
	TIME [epoch: 0.917 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9055354684057285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9055354684057285 | validation: 0.9678379717229433]
	TIME [epoch: 0.922 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9181156039619758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9181156039619758 | validation: 1.0514468237138328]
	TIME [epoch: 0.92 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9292479779015628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9292479779015628 | validation: 0.9479231569241968]
	TIME [epoch: 0.915 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.86594615384692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.86594615384692 | validation: 0.956826499459233]
	TIME [epoch: 0.916 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8504505320269001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8504505320269001 | validation: 0.9283929523588101]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8494771477391114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8494771477391114 | validation: 0.9484174313050865]
	TIME [epoch: 0.914 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8544875070419753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8544875070419753 | validation: 0.9538383560130601]
	TIME [epoch: 0.913 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8479203175731863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8479203175731863 | validation: 0.987344452076589]
	TIME [epoch: 0.914 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8629365423934552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8629365423934552 | validation: 0.983623868951619]
	TIME [epoch: 0.913 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8791970928586784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8791970928586784 | validation: 1.062183636123598]
	TIME [epoch: 0.913 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.942269266989154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.942269266989154 | validation: 0.9669115191846386]
	TIME [epoch: 0.91 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9000461350137587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9000461350137587 | validation: 1.024603793768177]
	TIME [epoch: 0.916 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9415660612900982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9415660612900982 | validation: 0.934180272628983]
	TIME [epoch: 0.914 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8534062188285577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8534062188285577 | validation: 0.9571717157842269]
	TIME [epoch: 0.917 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8448406849322833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8448406849322833 | validation: 0.9338679223971227]
	TIME [epoch: 0.915 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8448025115529397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8448025115529397 | validation: 0.969711262145045]
	TIME [epoch: 0.915 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8576314704508365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8576314704508365 | validation: 0.9427061256781081]
	TIME [epoch: 0.912 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469453246238555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469453246238555 | validation: 0.9653737211360021]
	TIME [epoch: 0.911 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8668179701191158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8668179701191158 | validation: 0.9570098119481554]
	TIME [epoch: 0.913 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8862731992324977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8862731992324977 | validation: 1.0928188915228951]
	TIME [epoch: 0.914 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9766801344657613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9766801344657613 | validation: 0.9582035571286959]
	TIME [epoch: 0.913 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8891828439132553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8891828439132553 | validation: 0.9541975467453465]
	TIME [epoch: 0.914 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8585785076225284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8585785076225284 | validation: 0.9130691976844741]
	TIME [epoch: 0.913 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.841495891712037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.841495891712037 | validation: 0.9344210201615823]
	TIME [epoch: 0.92 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8327006485476872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8327006485476872 | validation: 0.9332885317805787]
	TIME [epoch: 0.916 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8292085715561325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8292085715561325 | validation: 0.9130130378813425]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8335659914396695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8335659914396695 | validation: 0.9142041785070925]
	TIME [epoch: 0.917 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8322305741666085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8322305741666085 | validation: 0.9306546939551602]
	TIME [epoch: 0.974 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8278681541657532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8278681541657532 | validation: 1.0249886964687287]
	TIME [epoch: 0.917 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9034366826355167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9034366826355167 | validation: 1.099473422252238]
	TIME [epoch: 0.915 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0718682920988654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0718682920988654 | validation: 1.1144333082144924]
	TIME [epoch: 0.915 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9941762352628266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9941762352628266 | validation: 0.94603408811806]
	TIME [epoch: 0.913 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8451941617169585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8451941617169585 | validation: 0.9662966816797935]
	TIME [epoch: 0.915 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9224816929742712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9224816929742712 | validation: 0.9778280615352826]
	TIME [epoch: 0.912 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8847046774653279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8847046774653279 | validation: 0.9290379993769492]
	TIME [epoch: 0.913 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8323787505886787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8323787505886787 | validation: 0.9259737441857102]
	TIME [epoch: 0.913 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8612269950897217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8612269950897217 | validation: 0.9397734483817914]
	TIME [epoch: 0.912 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8459710957943973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8459710957943973 | validation: 0.9182427746045202]
	TIME [epoch: 0.915 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8285230353922746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8285230353922746 | validation: 0.9175950334495483]
	TIME [epoch: 0.914 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8297981941430861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8297981941430861 | validation: 0.9527182998572119]
	TIME [epoch: 0.915 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8612270901742878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8612270901742878 | validation: 0.967279108865029]
	TIME [epoch: 0.914 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9508039951079158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9508039951079158 | validation: 1.0729684163963307]
	TIME [epoch: 0.916 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0171439011863312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0171439011863312 | validation: 0.9221540862518787]
	TIME [epoch: 0.923 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8294047950539216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8294047950539216 | validation: 0.9358799643158234]
	TIME [epoch: 0.912 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8909621856427802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8909621856427802 | validation: 0.9440226226370033]
	TIME [epoch: 0.914 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8749475498395513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8749475498395513 | validation: 0.9025105814255299]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8341586449351516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8341586449351516 | validation: 0.9188970853813597]
	TIME [epoch: 0.924 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.849825137038337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.849825137038337 | validation: 0.907833450699016]
	TIME [epoch: 0.916 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8300988548975187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8300988548975187 | validation: 0.9022725472098557]
	TIME [epoch: 0.916 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8252517823974135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8252517823974135 | validation: 0.8920773231808283]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8271925168569544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8271925168569544 | validation: 0.9217695805280576]
	TIME [epoch: 0.92 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8416066791792031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8416066791792031 | validation: 0.9577323746939144]
	TIME [epoch: 0.923 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9188574962143631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9188574962143631 | validation: 1.1873163276575636]
	TIME [epoch: 0.918 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0425721857720842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0425721857720842 | validation: 0.9101657379960706]
	TIME [epoch: 0.919 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8251587467121614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8251587467121614 | validation: 0.9177437815045405]
	TIME [epoch: 0.916 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8695026328115631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8695026328115631 | validation: 1.003046790590173]
	TIME [epoch: 0.92 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9045402148491654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9045402148491654 | validation: 0.8869890077975854]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8316281323276854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8316281323276854 | validation: 0.8961175808799293]
	TIME [epoch: 0.916 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8388455013757868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8388455013757868 | validation: 0.9142982008407547]
	TIME [epoch: 0.91 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8291141116839631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8291141116839631 | validation: 0.8998093382247181]
	TIME [epoch: 0.916 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8192389936334828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8192389936334828 | validation: 0.8928741786104291]
	TIME [epoch: 0.915 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8240873325176955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8240873325176955 | validation: 0.8900042868322671]
	TIME [epoch: 0.912 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8193612558295851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8193612558295851 | validation: 0.9072966700253137]
	TIME [epoch: 0.912 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8309375832395253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8309375832395253 | validation: 0.953996204368194]
	TIME [epoch: 0.913 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8963975250119978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8963975250119978 | validation: 0.9888322097567177]
	TIME [epoch: 0.91 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9643900859923398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9643900859923398 | validation: 1.1351433419246681]
	TIME [epoch: 0.914 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.025903236840421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.025903236840421 | validation: 0.8994494467542737]
	TIME [epoch: 0.919 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8240038940088859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8240038940088859 | validation: 0.9032448542229261]
	TIME [epoch: 0.916 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8602079708244031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8602079708244031 | validation: 0.9780576007631728]
	TIME [epoch: 0.921 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.904321369977116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.904321369977116 | validation: 0.9081892735020412]
	TIME [epoch: 0.921 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8350566301800727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8350566301800727 | validation: 0.8965401710395862]
	TIME [epoch: 0.918 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8146122861509625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8146122861509625 | validation: 0.8817600203272085]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8179099278655915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8179099278655915 | validation: 0.8851271232365839]
	TIME [epoch: 0.912 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8227732338535892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8227732338535892 | validation: 0.9144684595063108]
	TIME [epoch: 0.913 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8258942056994681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8258942056994681 | validation: 0.900053335817129]
	TIME [epoch: 0.912 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8482243655934388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8482243655934388 | validation: 1.0179770813037057]
	TIME [epoch: 0.911 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9292728400764912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9292728400764912 | validation: 0.9394860610490694]
	TIME [epoch: 0.912 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.889315534424034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.889315534424034 | validation: 0.9726736430308454]
	TIME [epoch: 0.913 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8813207229353301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8813207229353301 | validation: 0.8982316604424005]
	TIME [epoch: 0.914 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8305801533838526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8305801533838526 | validation: 0.8858997257051119]
	TIME [epoch: 0.915 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8347545906247982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8347545906247982 | validation: 0.8943025180900279]
	TIME [epoch: 0.912 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8255375324514068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8255375324514068 | validation: 0.8971155267275613]
	TIME [epoch: 0.915 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8341406514694716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8341406514694716 | validation: 0.9388352276933954]
	TIME [epoch: 0.912 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8507057762655886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8507057762655886 | validation: 0.8614510299300688]
	TIME [epoch: 0.911 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8446629905502953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8446629905502953 | validation: 0.9240671959264066]
	TIME [epoch: 0.919 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8470700110174931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8470700110174931 | validation: 0.9146732578275039]
	TIME [epoch: 0.916 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8649816477787112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8649816477787112 | validation: 1.0261216762462244]
	TIME [epoch: 0.928 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9601383451251433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9601383451251433 | validation: 0.8991310713485561]
	TIME [epoch: 0.916 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.850602931430539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.850602931430539 | validation: 0.8798286817467645]
	TIME [epoch: 0.913 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8202399399910317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8202399399910317 | validation: 0.8598681604532694]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.808398506216067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.808398506216067 | validation: 0.876491564568866]
	TIME [epoch: 0.923 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8084318380061635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8084318380061635 | validation: 0.8720877495373398]
	TIME [epoch: 0.917 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8255052099704696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8255052099704696 | validation: 0.8977571603333605]
	TIME [epoch: 0.914 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8303394797367344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8303394797367344 | validation: 0.8912090340994642]
	TIME [epoch: 0.917 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8355204857357491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8355204857357491 | validation: 0.9596772963330804]
	TIME [epoch: 0.909 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8779296986778178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8779296986778178 | validation: 0.9408765248334339]
	TIME [epoch: 0.911 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.934550197989648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.934550197989648 | validation: 1.0550288757702706]
	TIME [epoch: 0.911 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0191790347716818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0191790347716818 | validation: 0.8832284815142103]
	TIME [epoch: 0.912 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8134969685521436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8134969685521436 | validation: 0.8886587508755458]
	TIME [epoch: 0.91 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8453155239304769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8453155239304769 | validation: 0.9228684979906554]
	TIME [epoch: 0.912 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8731477965778066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8731477965778066 | validation: 0.873215119719101]
	TIME [epoch: 0.908 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8397016117994051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8397016117994051 | validation: 0.9433767675333107]
	TIME [epoch: 23.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8525014471848547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8525014471848547 | validation: 0.8755327780038403]
	TIME [epoch: 1.81 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8228734122709017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8228734122709017 | validation: 0.8492428459116893]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8032149030958013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8032149030958013 | validation: 0.8586228117170919]
	TIME [epoch: 1.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8017685800357743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8017685800357743 | validation: 0.8521002227549129]
	TIME [epoch: 1.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7909367618460499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7909367618460499 | validation: 0.8379863191172066]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7972878099646463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7972878099646463 | validation: 0.8584286581965058]
	TIME [epoch: 1.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7998931388862588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7998931388862588 | validation: 0.8753476761117387]
	TIME [epoch: 1.81 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8309580825975698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8309580825975698 | validation: 1.11677578336187]
	TIME [epoch: 1.79 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.017822464044213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.017822464044213 | validation: 0.9785875145671309]
	TIME [epoch: 1.79 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0103491828641544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0103491828641544 | validation: 0.9521776356337274]
	TIME [epoch: 1.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9414675760466982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9414675760466982 | validation: 0.8524627910424183]
	TIME [epoch: 1.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8093471826420258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8093471826420258 | validation: 0.8921725878741746]
	TIME [epoch: 1.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8805149279651612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8805149279651612 | validation: 0.884240362369021]
	TIME [epoch: 1.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8413672552798878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8413672552798878 | validation: 0.8330257527954384]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8209976494948569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8209976494948569 | validation: 0.9013943675280521]
	TIME [epoch: 1.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8382030869780728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8382030869780728 | validation: 0.845731880663859]
	TIME [epoch: 1.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8039305690614676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8039305690614676 | validation: 0.8347268373999381]
	TIME [epoch: 1.79 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7973067905815296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7973067905815296 | validation: 0.8460079497666868]
	TIME [epoch: 1.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7925931767678364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7925931767678364 | validation: 0.8373602592222762]
	TIME [epoch: 1.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7906398027665489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7906398027665489 | validation: 0.8101540819400667]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7956193731732889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7956193731732889 | validation: 0.9305002998426254]
	TIME [epoch: 1.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8599932167128106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8599932167128106 | validation: 0.9907824574370316]
	TIME [epoch: 1.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9992877597759184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9992877597759184 | validation: 1.0736661493565947]
	TIME [epoch: 1.81 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0043060338720298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0043060338720298 | validation: 0.8595405499985042]
	TIME [epoch: 1.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7972826450083662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7972826450083662 | validation: 0.8856013781292061]
	TIME [epoch: 1.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8705284954054652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8705284954054652 | validation: 0.9788985530351924]
	TIME [epoch: 1.81 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9000884828317481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9000884828317481 | validation: 0.8643856368609045]
	TIME [epoch: 1.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.800212714635658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.800212714635658 | validation: 0.8309980604324502]
	TIME [epoch: 1.81 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8040263535272741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8040263535272741 | validation: 0.8627618772291051]
	TIME [epoch: 1.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8034076761659565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8034076761659565 | validation: 0.8274129604570561]
	TIME [epoch: 1.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8016712395144897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8016712395144897 | validation: 0.8578996940516362]
	TIME [epoch: 1.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8212333274992366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8212333274992366 | validation: 0.8427169123581097]
	TIME [epoch: 1.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8306759898284538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8306759898284538 | validation: 0.9004692282833807]
	TIME [epoch: 1.81 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8626544865673168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8626544865673168 | validation: 0.853903999523287]
	TIME [epoch: 1.82 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.827537006251053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.827537006251053 | validation: 0.8778154176593592]
	TIME [epoch: 1.81 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8255676653133418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8255676653133418 | validation: 0.8251811615405158]
	TIME [epoch: 1.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8230090467630672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8230090467630672 | validation: 0.8819182078198016]
	TIME [epoch: 1.81 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8215212509885932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8215212509885932 | validation: 0.8323805854278856]
	TIME [epoch: 1.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.808156392953943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.808156392953943 | validation: 0.8721715777109937]
	TIME [epoch: 1.81 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8293675059574506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8293675059574506 | validation: 0.8301915075840474]
	TIME [epoch: 1.81 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.841386115894715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.841386115894715 | validation: 0.921828004249078]
	TIME [epoch: 1.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.879837438381357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.879837438381357 | validation: 0.8491363544621957]
	TIME [epoch: 1.81 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8217279352702641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8217279352702641 | validation: 0.8728826245231064]
	TIME [epoch: 1.81 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8126973081603762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8126973081603762 | validation: 0.8041062579398688]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7979887874291598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7979887874291598 | validation: 0.8348712451664675]
	TIME [epoch: 1.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7957696981975548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7957696981975548 | validation: 0.805609391569885]
	TIME [epoch: 1.81 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7814165053491937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7814165053491937 | validation: 0.8441833297127839]
	TIME [epoch: 1.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7928218789594789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7928218789594789 | validation: 0.8287435956838625]
	TIME [epoch: 1.81 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8232519012922268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8232519012922268 | validation: 0.9925796464303046]
	TIME [epoch: 1.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9481351526481165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9481351526481165 | validation: 0.8708794064834472]
	TIME [epoch: 1.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8911727156783852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8911727156783852 | validation: 0.8928872137181257]
	TIME [epoch: 1.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8486446504447978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8486446504447978 | validation: 0.8166476898296378]
	TIME [epoch: 1.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7748847110749781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7748847110749781 | validation: 0.8239023773927792]
	TIME [epoch: 1.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7803485367232307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7803485367232307 | validation: 0.8294196923048862]
	TIME [epoch: 1.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.801622745031201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.801622745031201 | validation: 0.8014161588229994]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7807270424859514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7807270424859514 | validation: 0.7933084946031528]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7776718689233367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7776718689233367 | validation: 0.7877018940884544]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7705002730556365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7705002730556365 | validation: 0.7864499925690449]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7738901031739859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7738901031739859 | validation: 0.8775509278495234]
	TIME [epoch: 1.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8383443266773005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8383443266773005 | validation: 1.0762922738275316]
	TIME [epoch: 1.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1072427307303643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1072427307303643 | validation: 1.0553594084267133]
	TIME [epoch: 1.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0277181410071383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0277181410071383 | validation: 0.8308155200504598]
	TIME [epoch: 1.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7786206381016518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7786206381016518 | validation: 0.8785336486108957]
	TIME [epoch: 1.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8981413593042818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8981413593042818 | validation: 0.9158917548022967]
	TIME [epoch: 1.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8814239517391796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8814239517391796 | validation: 0.7869906887376905]
	TIME [epoch: 1.79 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7685226300452673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7685226300452673 | validation: 0.7972246610705608]
	TIME [epoch: 1.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7886435260665522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7886435260665522 | validation: 0.8399709933393749]
	TIME [epoch: 1.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8104242735973596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8104242735973596 | validation: 0.7903451128905701]
	TIME [epoch: 1.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7796489351351948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7796489351351948 | validation: 0.799864242117284]
	TIME [epoch: 1.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7716881599334566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7716881599334566 | validation: 0.7756941895327574]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7689994967905746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7689994967905746 | validation: 0.8124338066213176]
	TIME [epoch: 1.81 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7735353633743017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7735353633743017 | validation: 0.778052995010442]
	TIME [epoch: 1.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7853977927694215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7853977927694215 | validation: 0.8872804781083176]
	TIME [epoch: 1.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8398189729015604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8398189729015604 | validation: 0.8717200192692008]
	TIME [epoch: 1.81 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8939837742592843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8939837742592843 | validation: 0.9362532079133278]
	TIME [epoch: 1.81 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9296100094702203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9296100094702203 | validation: 0.7840006804026189]
	TIME [epoch: 1.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7642935457973559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7642935457973559 | validation: 0.7714689930920446]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7693339130923557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7693339130923557 | validation: 0.8144396143782283]
	TIME [epoch: 1.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7981025942375877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7981025942375877 | validation: 0.8188885072697055]
	TIME [epoch: 1.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8069756257456656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8069756257456656 | validation: 0.8987592883068034]
	TIME [epoch: 1.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.847539223425815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.847539223425815 | validation: 0.7813099182793226]
	TIME [epoch: 1.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7904593643786579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7904593643786579 | validation: 0.7903988048909962]
	TIME [epoch: 1.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7734412527228527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7734412527228527 | validation: 0.7912078288818429]
	TIME [epoch: 1.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7743538497269075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7743538497269075 | validation: 0.8348424527847211]
	TIME [epoch: 1.82 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8301800621019197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8301800621019197 | validation: 0.821969764223879]
	TIME [epoch: 1.81 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8489173625718838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8489173625718838 | validation: 0.8756579179441915]
	TIME [epoch: 1.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8698685840717606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8698685840717606 | validation: 0.7877190417471088]
	TIME [epoch: 1.81 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.788706428408459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.788706428408459 | validation: 0.843403243318117]
	TIME [epoch: 1.79 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7954222174292193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7954222174292193 | validation: 0.7725249268001799]
	TIME [epoch: 1.81 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7741669772023628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7741669772023628 | validation: 0.7868322815882223]
	TIME [epoch: 1.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.767239269400322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.767239269400322 | validation: 0.7362610562149827]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7668619561337279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7668619561337279 | validation: 0.8177676074741177]
	TIME [epoch: 1.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8060379917832131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8060379917832131 | validation: 0.8590138427164601]
	TIME [epoch: 1.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8799392934378546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8799392934378546 | validation: 0.9311288168398939]
	TIME [epoch: 1.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9461670865089706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9461670865089706 | validation: 0.7483630316457686]
	TIME [epoch: 1.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7645447496161797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7645447496161797 | validation: 0.7581387192415849]
	TIME [epoch: 1.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7577284950520577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7577284950520577 | validation: 0.7681908825936135]
	TIME [epoch: 1.81 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.785511092160761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.785511092160761 | validation: 0.774123486289526]
	TIME [epoch: 1.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.783544255733095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.783544255733095 | validation: 0.797238109923627]
	TIME [epoch: 1.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7880842684684011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7880842684684011 | validation: 0.7943990511773626]
	TIME [epoch: 1.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8016659727062367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8016659727062367 | validation: 0.8819849226785215]
	TIME [epoch: 1.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8471120579752085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8471120579752085 | validation: 0.7921671501051514]
	TIME [epoch: 1.81 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7831645945063701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7831645945063701 | validation: 0.7738689763929806]
	TIME [epoch: 1.81 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7770851604485456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7770851604485456 | validation: 0.7560888718450403]
	TIME [epoch: 1.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7674643804723891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7674643804723891 | validation: 0.7776171648898075]
	TIME [epoch: 1.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7822386327398532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7822386327398532 | validation: 0.7537522322706579]
	TIME [epoch: 1.81 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7853745008010183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7853745008010183 | validation: 0.8537649684580093]
	TIME [epoch: 1.81 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8359485262441502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8359485262441502 | validation: 0.7710736604127706]
	TIME [epoch: 1.82 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7866556521232133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7866556521232133 | validation: 0.8173876820407022]
	TIME [epoch: 1.81 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7908039377350644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7908039377350644 | validation: 0.75601060946162]
	TIME [epoch: 1.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7688990518394405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7688990518394405 | validation: 0.7526586240727513]
	TIME [epoch: 1.81 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7703989090043026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7703989090043026 | validation: 0.7659407942975349]
	TIME [epoch: 1.81 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7609215650901864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7609215650901864 | validation: 0.7569159215196535]
	TIME [epoch: 1.81 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7766833784156757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7766833784156757 | validation: 0.7442493760403286]
	TIME [epoch: 1.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7524204821517911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7524204821517911 | validation: 0.7513607300515743]
	TIME [epoch: 1.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7643497967677542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7643497967677542 | validation: 0.7401442616921434]
	TIME [epoch: 1.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7686310875680594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7686310875680594 | validation: 0.954774740819162]
	TIME [epoch: 1.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8792235764357167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8792235764357167 | validation: 0.800595635985851]
	TIME [epoch: 1.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8666176569754188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8666176569754188 | validation: 0.8271349810000906]
	TIME [epoch: 1.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7881654362603857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7881654362603857 | validation: 0.7039547433849266]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7191471856525559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7191471856525559 | validation: 0.7068021301622409]
	TIME [epoch: 1.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7514963197106173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7514963197106173 | validation: 0.7524229527263855]
	TIME [epoch: 1.81 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7521742326415258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7521742326415258 | validation: 0.7436526502612135]
	TIME [epoch: 1.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.758887915431654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.758887915431654 | validation: 0.760212892787196]
	TIME [epoch: 1.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7850220047493051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7850220047493051 | validation: 0.9117511184662179]
	TIME [epoch: 1.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8728089685564808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8728089685564808 | validation: 0.7408130717238324]
	TIME [epoch: 1.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.749279594664676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.749279594664676 | validation: 0.7198870049010937]
	TIME [epoch: 1.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7266243771323215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7266243771323215 | validation: 0.6762616963049459]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7205647122621457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7205647122621457 | validation: 0.7027259542607527]
	TIME [epoch: 1.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7247507885674841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7247507885674841 | validation: 0.7265416131959057]
	TIME [epoch: 1.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7395652281732459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7395652281732459 | validation: 0.7771169423595209]
	TIME [epoch: 1.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8084241540861433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8084241540861433 | validation: 0.7730777287091147]
	TIME [epoch: 1.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7821708435922031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7821708435922031 | validation: 0.7236539085749848]
	TIME [epoch: 1.81 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7417060906797928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7417060906797928 | validation: 0.6522804895150687]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6869528883323475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6869528883323475 | validation: 0.757958913240938]
	TIME [epoch: 1.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7263644120000308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7263644120000308 | validation: 0.7798589560139164]
	TIME [epoch: 1.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8772844381440973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8772844381440973 | validation: 0.8679903416892671]
	TIME [epoch: 1.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7970703879916825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7970703879916825 | validation: 0.6436800649935281]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6705238014110697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6705238014110697 | validation: 0.6503249243989391]
	TIME [epoch: 1.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7097165268821255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7097165268821255 | validation: 0.6849541902534028]
	TIME [epoch: 1.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6898947689694092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6898947689694092 | validation: 0.6163556288788563]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6677734032124616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6677734032124616 | validation: 0.6320978206673669]
	TIME [epoch: 1.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6605307964403936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6605307964403936 | validation: 0.6900213709940091]
	TIME [epoch: 1.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7122241197788682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7122241197788682 | validation: 0.811297830987376]
	TIME [epoch: 1.81 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8674491284724469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8674491284724469 | validation: 0.866406383462401]
	TIME [epoch: 1.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8671070006020241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8671070006020241 | validation: 0.6143316458508536]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6463067276099086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6463067276099086 | validation: 0.6089365246048507]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6449244316350559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6449244316350559 | validation: 0.611534326241431]
	TIME [epoch: 1.79 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6769719999239661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6769719999239661 | validation: 0.7345386447092311]
	TIME [epoch: 1.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7192826660820931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7192826660820931 | validation: 0.6304491262591594]
	TIME [epoch: 1.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7016622880340878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7016622880340878 | validation: 0.6686564939560544]
	TIME [epoch: 1.81 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6594300447299277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6594300447299277 | validation: 0.5857476592419667]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6675417034601511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6675417034601511 | validation: 0.7692722059896173]
	TIME [epoch: 1.81 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7053193139031068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7053193139031068 | validation: 0.6579578115804452]
	TIME [epoch: 1.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7320949697292359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7320949697292359 | validation: 0.7866085206204044]
	TIME [epoch: 1.82 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7236989098488213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7236989098488213 | validation: 0.578163624468272]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6154312573749596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6154312573749596 | validation: 0.5456689840373264]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5964002031347443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5964002031347443 | validation: 0.5984447591051082]
	TIME [epoch: 1.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5999318606128076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5999318606128076 | validation: 0.5379049098176371]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6095674885072342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6095674885072342 | validation: 0.6323421539071105]
	TIME [epoch: 1.81 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6157465046180268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6157465046180268 | validation: 0.5638490586680377]
	TIME [epoch: 1.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6441653268107039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6441653268107039 | validation: 0.6585518909467615]
	TIME [epoch: 1.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6308917320742483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6308917320742483 | validation: 0.5584840106438567]
	TIME [epoch: 1.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6217654284133266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6217654284133266 | validation: 0.5780349473078673]
	TIME [epoch: 1.81 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5706041122353424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5706041122353424 | validation: 0.60892084341197]
	TIME [epoch: 1.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6000235935603258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6000235935603258 | validation: 0.7773443258185974]
	TIME [epoch: 1.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8045330008048618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8045330008048618 | validation: 0.9165598765488863]
	TIME [epoch: 1.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8103028295451992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8103028295451992 | validation: 0.5022189729598021]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5548900058150137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5548900058150137 | validation: 0.5241860965511954]
	TIME [epoch: 1.82 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5495218142388213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5495218142388213 | validation: 0.5815273046379069]
	TIME [epoch: 1.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5926238274130564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5926238274130564 | validation: 0.6421684594374677]
	TIME [epoch: 1.81 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6223336613284517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6223336613284517 | validation: 0.5888072177774596]
	TIME [epoch: 1.81 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5936386950253179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5936386950253179 | validation: 0.6056557055918624]
	TIME [epoch: 1.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5918533619399058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5918533619399058 | validation: 0.5584626056766447]
	TIME [epoch: 1.81 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6120041147237736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6120041147237736 | validation: 0.6452373289998303]
	TIME [epoch: 1.81 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5832320256257508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5832320256257508 | validation: 0.5080841860772933]
	TIME [epoch: 1.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5625274611888625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5625274611888625 | validation: 0.6487864625662505]
	TIME [epoch: 1.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.573274937457007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.573274937457007 | validation: 0.5520517390580505]
	TIME [epoch: 1.81 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.598523493798389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.598523493798389 | validation: 0.686657909657906]
	TIME [epoch: 1.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6065460033401397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6065460033401397 | validation: 0.5094585150753198]
	TIME [epoch: 1.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5265340849113023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5265340849113023 | validation: 0.5178134348575112]
	TIME [epoch: 1.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49203037540206723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49203037540206723 | validation: 0.512928847163037]
	TIME [epoch: 1.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4903114196406683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4903114196406683 | validation: 0.5538013946682508]
	TIME [epoch: 1.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5571041620475186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5571041620475186 | validation: 0.8882653432578902]
	TIME [epoch: 1.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7946511739529538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7946511739529538 | validation: 0.5504320944426802]
	TIME [epoch: 1.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5885777858231941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5885777858231941 | validation: 0.48858749481071195]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4887206493545018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4887206493545018 | validation: 0.535485982366268]
	TIME [epoch: 1.81 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5506401179992143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5506401179992143 | validation: 0.6359675640006373]
	TIME [epoch: 1.81 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5814465101179961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5814465101179961 | validation: 0.5939554287928938]
	TIME [epoch: 1.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5535823302566302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5535823302566302 | validation: 0.5155178878815255]
	TIME [epoch: 1.81 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47140668318835355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47140668318835355 | validation: 0.46260722308454433]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46616924096454415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46616924096454415 | validation: 0.6140417210929909]
	TIME [epoch: 1.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5353219131325732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5353219131325732 | validation: 0.5873462054209391]
	TIME [epoch: 1.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6141025544291757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6141025544291757 | validation: 0.6771326248309409]
	TIME [epoch: 1.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5579383347034375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5579383347034375 | validation: 0.4813505317565843]
	TIME [epoch: 1.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48294743040491694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48294743040491694 | validation: 0.5737466578086297]
	TIME [epoch: 1.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5001410478165894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5001410478165894 | validation: 0.5793668366312463]
	TIME [epoch: 1.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5421079549314378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5421079549314378 | validation: 0.5667099004315647]
	TIME [epoch: 1.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49779814156328345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49779814156328345 | validation: 0.5085584935900993]
	TIME [epoch: 1.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4671520872691581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4671520872691581 | validation: 0.4836251043324758]
	TIME [epoch: 1.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4467981307308376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4467981307308376 | validation: 0.5393652988950809]
	TIME [epoch: 1.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46758466908600427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46758466908600427 | validation: 0.5608527392998127]
	TIME [epoch: 1.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5288204219634588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5288204219634588 | validation: 0.685894309187969]
	TIME [epoch: 1.81 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5732027710234885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5732027710234885 | validation: 0.47641613920021514]
	TIME [epoch: 1.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47030161722867336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47030161722867336 | validation: 0.4701178114969382]
	TIME [epoch: 1.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41653909350171103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41653909350171103 | validation: 0.4418340209706563]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41654010260731594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41654010260731594 | validation: 0.526036121376795]
	TIME [epoch: 1.79 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4352075661444457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4352075661444457 | validation: 0.5692058938091437]
	TIME [epoch: 1.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5409300397423915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5409300397423915 | validation: 0.7054856341630509]
	TIME [epoch: 1.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5689924155562837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5689924155562837 | validation: 0.5090200043098153]
	TIME [epoch: 1.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4860775392267216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4860775392267216 | validation: 0.4502773873137098]
	TIME [epoch: 1.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39892580345051615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39892580345051615 | validation: 0.45101568407122694]
	TIME [epoch: 1.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3887055629475455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3887055629475455 | validation: 0.4240033176658969]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40354945905673345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40354945905673345 | validation: 0.6722656947597451]
	TIME [epoch: 1.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5388490577513473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5388490577513473 | validation: 0.6695583444942249]
	TIME [epoch: 1.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7836292855169006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7836292855169006 | validation: 0.4792436805072409]
	TIME [epoch: 1.79 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4070977404932381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4070977404932381 | validation: 0.5409617869874285]
	TIME [epoch: 1.79 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4562278993227067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4562278993227067 | validation: 0.5657362457041523]
	TIME [epoch: 1.79 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5189832046089975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5189832046089975 | validation: 0.5201255456075882]
	TIME [epoch: 1.79 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.488226164764681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.488226164764681 | validation: 0.5113934292702976]
	TIME [epoch: 1.79 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42287029310708785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42287029310708785 | validation: 0.4357116163136476]
	TIME [epoch: 1.79 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3900429449251082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3900429449251082 | validation: 0.4248949040604453]
	TIME [epoch: 1.79 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37069771985353583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37069771985353583 | validation: 0.4163682980675673]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3597297382798792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3597297382798792 | validation: 0.4286563244686348]
	TIME [epoch: 1.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3578005422396862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3578005422396862 | validation: 0.48081459711019436]
	TIME [epoch: 1.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39269054823566296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39269054823566296 | validation: 0.7301969782553215]
	TIME [epoch: 1.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6144576157647051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6144576157647051 | validation: 0.7042847000678013]
	TIME [epoch: 1.81 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7481360772101817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7481360772101817 | validation: 0.4080751821151566]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3899837886004875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3899837886004875 | validation: 0.6281979669726367]
	TIME [epoch: 1.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5046193952919593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5046193952919593 | validation: 0.5014010679672326]
	TIME [epoch: 1.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4322421892922007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4322421892922007 | validation: 0.4025423560091301]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38876774313973095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38876774313973095 | validation: 0.5191770351298802]
	TIME [epoch: 1.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40618112153637626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40618112153637626 | validation: 0.3815784727609234]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36783461915603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36783461915603 | validation: 0.46342929562439183]
	TIME [epoch: 1.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34992442986242484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34992442986242484 | validation: 0.3756710031606167]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3362226120636319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3362226120636319 | validation: 0.4364280023632474]
	TIME [epoch: 1.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3368010562911432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3368010562911432 | validation: 0.41848474868538243]
	TIME [epoch: 1.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38521749914109316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38521749914109316 | validation: 0.5960172308975356]
	TIME [epoch: 1.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5240939286592393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5240939286592393 | validation: 0.7059452001488976]
	TIME [epoch: 1.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5711702863112917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5711702863112917 | validation: 0.43868968243627615]
	TIME [epoch: 1.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45544043403069423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45544043403069423 | validation: 0.48520846480266777]
	TIME [epoch: 1.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3749086147413819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3749086147413819 | validation: 0.4285931685429262]
	TIME [epoch: 1.79 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38505663008986135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38505663008986135 | validation: 0.41478566290675745]
	TIME [epoch: 1.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3708343493529688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3708343493529688 | validation: 0.42672165008261276]
	TIME [epoch: 1.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34986420628598836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34986420628598836 | validation: 0.3601141826769999]
	TIME [epoch: 1.79 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3533799150162464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3533799150162464 | validation: 0.5377516849988061]
	TIME [epoch: 1.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38420748045051434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38420748045051434 | validation: 0.4170701472230793]
	TIME [epoch: 1.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3939644537264544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3939644537264544 | validation: 0.4775277174027598]
	TIME [epoch: 1.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.370704282493014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.370704282493014 | validation: 0.38453230415344053]
	TIME [epoch: 1.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3416030850477098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3416030850477098 | validation: 0.3700722640600387]
	TIME [epoch: 1.81 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3093543637154138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3093543637154138 | validation: 0.3792151099015025]
	TIME [epoch: 1.81 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3046580506708428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3046580506708428 | validation: 0.3413691572056573]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3168045054466894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3168045054466894 | validation: 0.5435593534636413]
	TIME [epoch: 1.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4027885031182364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4027885031182364 | validation: 0.40980875224112606]
	TIME [epoch: 1.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4153694876586736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4153694876586736 | validation: 0.4031878379866906]
	TIME [epoch: 1.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3143654422110017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3143654422110017 | validation: 0.4116966122885094]
	TIME [epoch: 1.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40023221425991806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40023221425991806 | validation: 0.8157898405921682]
	TIME [epoch: 1.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6487247597353374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6487247597353374 | validation: 0.4524042684378376]
	TIME [epoch: 1.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3975937406989294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3975937406989294 | validation: 0.31982464534692984]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30374303659012775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30374303659012775 | validation: 0.4441789031439233]
	TIME [epoch: 1.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3539875622055773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3539875622055773 | validation: 0.34868029460372174]
	TIME [epoch: 1.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3084054120172206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3084054120172206 | validation: 0.3175896830533927]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26521893617861003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26521893617861003 | validation: 0.31827075804314875]
	TIME [epoch: 1.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2637424691346614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2637424691346614 | validation: 0.3227673393721231]
	TIME [epoch: 1.79 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2779367481921649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2779367481921649 | validation: 0.4412913076624017]
	TIME [epoch: 1.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3253474593728455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3253474593728455 | validation: 0.477366877062839]
	TIME [epoch: 1.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5047491651089807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5047491651089807 | validation: 0.602319355417449]
	TIME [epoch: 1.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46639053468447417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46639053468447417 | validation: 0.351132994892238]
	TIME [epoch: 1.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2862632151325962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2862632151325962 | validation: 0.3159278448974348]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3379106437850822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3379106437850822 | validation: 0.37403606159464364]
	TIME [epoch: 1.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29781794546439516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29781794546439516 | validation: 0.29078515418361967]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26551724414797234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26551724414797234 | validation: 0.303038318712326]
	TIME [epoch: 1.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2792866288351402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2792866288351402 | validation: 0.3621153820779279]
	TIME [epoch: 1.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28341175341098007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28341175341098007 | validation: 0.3257472050157241]
	TIME [epoch: 1.81 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29599567193082577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29599567193082577 | validation: 0.39327304769934446]
	TIME [epoch: 1.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29870713802215537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29870713802215537 | validation: 0.3534572916300727]
	TIME [epoch: 1.81 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3382076060696744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3382076060696744 | validation: 0.3462903130959796]
	TIME [epoch: 1.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.271956105497748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.271956105497748 | validation: 0.25149531052707463]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24407955007242998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24407955007242998 | validation: 0.3499176741250476]
	TIME [epoch: 1.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2580161270640249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2580161270640249 | validation: 0.28508158712304715]
	TIME [epoch: 1.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30690543979596374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30690543979596374 | validation: 0.4209632579657001]
	TIME [epoch: 1.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3188469277540141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3188469277540141 | validation: 0.22525951483493728]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23059265332984802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23059265332984802 | validation: 0.2607792632373001]
	TIME [epoch: 1.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1991334421386447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1991334421386447 | validation: 0.21789412704802347]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18705226552373128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18705226552373128 | validation: 0.2566781588193205]
	TIME [epoch: 1.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19581771454941824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19581771454941824 | validation: 0.48354241149237015]
	TIME [epoch: 1.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5354203754623129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5354203754623129 | validation: 0.8671798154614575]
	TIME [epoch: 1.82 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7660270912419259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7660270912419259 | validation: 0.5964484912727993]
	TIME [epoch: 1.79 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49268708849040255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49268708849040255 | validation: 0.31457221313688494]
	TIME [epoch: 1.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2770044760152574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2770044760152574 | validation: 0.25181778156881857]
	TIME [epoch: 1.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2617714316331041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2617714316331041 | validation: 0.26488237353288563]
	TIME [epoch: 1.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26336781611301724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26336781611301724 | validation: 0.2257441476830616]
	TIME [epoch: 1.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20357438391842855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20357438391842855 | validation: 0.20966087582957627]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19848422171096833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19848422171096833 | validation: 0.2664246935158314]
	TIME [epoch: 1.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19050229777513103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19050229777513103 | validation: 0.19963018137434488]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17895681494108065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17895681494108065 | validation: 0.26825576260312073]
	TIME [epoch: 1.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2135379937310186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2135379937310186 | validation: 0.4893996009608921]
	TIME [epoch: 1.81 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47009579599559914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47009579599559914 | validation: 0.6216126025925536]
	TIME [epoch: 1.81 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49267864338202594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49267864338202594 | validation: 0.4036634840429127]
	TIME [epoch: 1.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34098902581531076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34098902581531076 | validation: 0.28479003333923214]
	TIME [epoch: 25.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2728334597461081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2728334597461081 | validation: 0.25175417911351233]
	TIME [epoch: 3.58 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22158801259461233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22158801259461233 | validation: 0.22689576425784097]
	TIME [epoch: 3.57 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1902866118572527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1902866118572527 | validation: 0.21251781075309095]
	TIME [epoch: 3.57 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18754349411718693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18754349411718693 | validation: 0.23783930909306147]
	TIME [epoch: 3.61 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17861682356289799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17861682356289799 | validation: 0.18839678727329112]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15979662772788303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15979662772788303 | validation: 0.22583867699956586]
	TIME [epoch: 3.58 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1668988066030565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1668988066030565 | validation: 0.256775313521302]
	TIME [epoch: 3.55 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24148558385639432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24148558385639432 | validation: 0.5994584118667339]
	TIME [epoch: 3.57 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48594346492575385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48594346492575385 | validation: 0.36603967370805307]
	TIME [epoch: 3.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26407704925463615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26407704925463615 | validation: 0.27835097389305563]
	TIME [epoch: 3.55 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32316158061976086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32316158061976086 | validation: 0.2815152231820381]
	TIME [epoch: 3.57 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26090984641475656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26090984641475656 | validation: 0.25665309684089394]
	TIME [epoch: 3.56 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21196298792507443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21196298792507443 | validation: 0.220655200965434]
	TIME [epoch: 3.55 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19887846088628525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19887846088628525 | validation: 0.20778943880739043]
	TIME [epoch: 3.55 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15475800080334773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15475800080334773 | validation: 0.1954229742085113]
	TIME [epoch: 3.55 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1503488564954318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1503488564954318 | validation: 0.21322387601128545]
	TIME [epoch: 3.54 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17465628326249052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17465628326249052 | validation: 0.29485752328963594]
	TIME [epoch: 3.54 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2774775307150916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2774775307150916 | validation: 0.4950396774687038]
	TIME [epoch: 3.55 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3941053054413975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3941053054413975 | validation: 0.2720776533335271]
	TIME [epoch: 3.59 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20671208483938996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20671208483938996 | validation: 0.2443787119537702]
	TIME [epoch: 3.58 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26580706071280685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26580706071280685 | validation: 0.3302293774849554]
	TIME [epoch: 3.59 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28934113090119107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28934113090119107 | validation: 0.1916985877879801]
	TIME [epoch: 3.57 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15839681051762752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15839681051762752 | validation: 0.20206707590703005]
	TIME [epoch: 3.55 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1848110796453352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1848110796453352 | validation: 0.2661848172449334]
	TIME [epoch: 3.57 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20568266519974537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20568266519974537 | validation: 0.19589839500325645]
	TIME [epoch: 3.55 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15051763818217384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15051763818217384 | validation: 0.1699271790555218]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14761157133198294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14761157133198294 | validation: 0.17986355562209894]
	TIME [epoch: 3.55 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1353640352388463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1353640352388463 | validation: 0.13295709028192434]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11774782856396662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11774782856396662 | validation: 0.17202238658115696]
	TIME [epoch: 3.57 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11401574475756715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11401574475756715 | validation: 0.14869506504634403]
	TIME [epoch: 3.57 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13666266124084958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13666266124084958 | validation: 0.28477707672898694]
	TIME [epoch: 3.57 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2576520178509132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2576520178509132 | validation: 0.35752140328043963]
	TIME [epoch: 3.56 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3063436456561649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3063436456561649 | validation: 0.38667316551091757]
	TIME [epoch: 3.58 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34364572984352443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34364572984352443 | validation: 0.45043582128469045]
	TIME [epoch: 3.58 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.392031898738903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.392031898738903 | validation: 0.27696501361105547]
	TIME [epoch: 3.56 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21617397629665486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21617397629665486 | validation: 0.25878530942809247]
	TIME [epoch: 3.57 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24120304391636954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24120304391636954 | validation: 0.17364493813228488]
	TIME [epoch: 3.57 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1494980068531626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1494980068531626 | validation: 0.15381776093570465]
	TIME [epoch: 3.55 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11836773588040199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11836773588040199 | validation: 0.15342769399262154]
	TIME [epoch: 3.57 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1314448025710974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1314448025710974 | validation: 0.17110243099282926]
	TIME [epoch: 3.57 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11750177836075505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11750177836075505 | validation: 0.12620246793652265]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09851555730126263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09851555730126263 | validation: 0.15125718714741485]
	TIME [epoch: 3.58 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09822015859555482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09822015859555482 | validation: 0.15561384044659357]
	TIME [epoch: 3.58 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11962969227716747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11962969227716747 | validation: 0.30452007721592306]
	TIME [epoch: 3.57 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22995331318718923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22995331318718923 | validation: 0.24278393779877555]
	TIME [epoch: 3.57 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19744404866492435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19744404866492435 | validation: 0.19894366651375395]
	TIME [epoch: 3.57 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15009209906688495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15009209906688495 | validation: 0.14879490808235493]
	TIME [epoch: 3.54 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11971639425592617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11971639425592617 | validation: 0.1380764349501379]
	TIME [epoch: 3.57 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10741561569823502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10741561569823502 | validation: 0.1386936281871285]
	TIME [epoch: 3.54 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14103574743738115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14103574743738115 | validation: 0.18852784392497948]
	TIME [epoch: 3.54 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.166484537085122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.166484537085122 | validation: 0.11915639536246025]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10508459103862418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10508459103862418 | validation: 0.1108880082082465]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07715269997021731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07715269997021731 | validation: 0.11031272944557857]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09524678038828235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09524678038828235 | validation: 0.22620018099990025]
	TIME [epoch: 3.57 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20945155818869182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20945155818869182 | validation: 0.23613807419420374]
	TIME [epoch: 3.57 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21449128312934396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21449128312934396 | validation: 0.41798040734159275]
	TIME [epoch: 3.56 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3296750010812184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3296750010812184 | validation: 0.23948200414249798]
	TIME [epoch: 3.57 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22881039437027004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22881039437027004 | validation: 0.19903312258451883]
	TIME [epoch: 3.58 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18611433535545152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18611433535545152 | validation: 0.18635695115807768]
	TIME [epoch: 3.56 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1650958990666964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1650958990666964 | validation: 0.16768448311893336]
	TIME [epoch: 3.55 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16117235858815923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16117235858815923 | validation: 0.10768699779886015]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07492144580744985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07492144580744985 | validation: 0.10917090577131383]
	TIME [epoch: 3.57 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07688544924849779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07688544924849779 | validation: 0.10816576364499791]
	TIME [epoch: 3.55 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0789081948295823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0789081948295823 | validation: 0.09465670498219517]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06921495802582009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06921495802582009 | validation: 0.09711985903515626]
	TIME [epoch: 3.56 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06787834435940235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06787834435940235 | validation: 0.11501973142457622]
	TIME [epoch: 3.54 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09490320708697979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09490320708697979 | validation: 0.18013488530000635]
	TIME [epoch: 3.56 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1528226070313455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1528226070313455 | validation: 0.34186849313929335]
	TIME [epoch: 3.56 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30560998778827675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30560998778827675 | validation: 0.12823394850791597]
	TIME [epoch: 3.57 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11532874212441879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11532874212441879 | validation: 0.16219404136265872]
	TIME [epoch: 3.57 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1611498751481794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1611498751481794 | validation: 0.25595015425715645]
	TIME [epoch: 3.57 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21647051658401353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21647051658401353 | validation: 0.09215262109138421]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07207404359061245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07207404359061245 | validation: 0.14288609967273302]
	TIME [epoch: 3.56 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12694778345059113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12694778345059113 | validation: 0.14869570079484648]
	TIME [epoch: 3.56 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11203012912135667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11203012912135667 | validation: 0.07134621733919058]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057219081488468514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057219081488468514 | validation: 0.08872342231518315]
	TIME [epoch: 3.56 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07085161887044424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07085161887044424 | validation: 0.09436761983861092]
	TIME [epoch: 3.57 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08188957859631557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08188957859631557 | validation: 0.10235233544842065]
	TIME [epoch: 3.56 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09514031035956032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09514031035956032 | validation: 0.14746149292242908]
	TIME [epoch: 3.56 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13788400236228196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13788400236228196 | validation: 0.16745174195107437]
	TIME [epoch: 3.56 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1422528763555564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1422528763555564 | validation: 0.165599061687695]
	TIME [epoch: 3.58 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11767634118279827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11767634118279827 | validation: 0.18954304582797385]
	TIME [epoch: 3.57 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14393363615592342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14393363615592342 | validation: 0.10247636218680506]
	TIME [epoch: 3.57 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0935209871384525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0935209871384525 | validation: 0.09886776998081537]
	TIME [epoch: 3.57 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08490243003230759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08490243003230759 | validation: 0.06378275583360667]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07082899801725218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07082899801725218 | validation: 0.07745686240494581]
	TIME [epoch: 3.57 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05708952830896129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05708952830896129 | validation: 0.07865616396061943]
	TIME [epoch: 3.57 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07265811036127466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07265811036127466 | validation: 0.13975233570473278]
	TIME [epoch: 3.58 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1117870652314319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1117870652314319 | validation: 0.17117084362554472]
	TIME [epoch: 3.59 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15252135795427557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15252135795427557 | validation: 0.10896383763440123]
	TIME [epoch: 3.57 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0870459348365979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0870459348365979 | validation: 0.0998240102539783]
	TIME [epoch: 3.57 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07214502619146833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07214502619146833 | validation: 0.12762642681256364]
	TIME [epoch: 3.58 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13358444184228263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13358444184228263 | validation: 0.15095131455997343]
	TIME [epoch: 3.57 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13898921203576559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13898921203576559 | validation: 0.19957329115427755]
	TIME [epoch: 3.58 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15639500155903227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15639500155903227 | validation: 0.08612849379364021]
	TIME [epoch: 3.58 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07608109276178407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07608109276178407 | validation: 0.09711989739384408]
	TIME [epoch: 3.59 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07842781996006598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07842781996006598 | validation: 0.056700578498644405]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0684159663700293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0684159663700293 | validation: 0.06655050767905615]
	TIME [epoch: 3.56 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05151998268570296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05151998268570296 | validation: 0.08246777678476845]
	TIME [epoch: 3.57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.064510076648845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.064510076648845 | validation: 0.12778938973712367]
	TIME [epoch: 3.56 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09363076510668482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09363076510668482 | validation: 0.19440895536491415]
	TIME [epoch: 3.56 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13969080900427883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13969080900427883 | validation: 0.11859135944559332]
	TIME [epoch: 3.55 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08870878157912297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08870878157912297 | validation: 0.06391677532719518]
	TIME [epoch: 3.56 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058700653941007826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058700653941007826 | validation: 0.061269201053267365]
	TIME [epoch: 3.56 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056221173983035756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056221173983035756 | validation: 0.06602797330701274]
	TIME [epoch: 3.56 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0660201286494699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0660201286494699 | validation: 0.09041932029487956]
	TIME [epoch: 3.55 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08711350294535446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08711350294535446 | validation: 0.11597516350371789]
	TIME [epoch: 3.57 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12053606475236579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12053606475236579 | validation: 0.11864274624881316]
	TIME [epoch: 3.56 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11711198220513415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11711198220513415 | validation: 0.19350359846185783]
	TIME [epoch: 3.58 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18507948499087262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18507948499087262 | validation: 0.09487503404681108]
	TIME [epoch: 3.55 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09989914699431811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09989914699431811 | validation: 0.07218041373928215]
	TIME [epoch: 3.56 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053979488288923995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053979488288923995 | validation: 0.08045835020538133]
	TIME [epoch: 3.56 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06035722272158942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06035722272158942 | validation: 0.07563812032809879]
	TIME [epoch: 3.56 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07132398211664352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07132398211664352 | validation: 0.08653251553474235]
	TIME [epoch: 3.56 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0752563304469116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0752563304469116 | validation: 0.07235112696342157]
	TIME [epoch: 3.57 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06301249355366725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06301249355366725 | validation: 0.09031686386454243]
	TIME [epoch: 3.56 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06679945820275338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06679945820275338 | validation: 0.12054380116402359]
	TIME [epoch: 3.58 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0942347605891968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0942347605891968 | validation: 0.12301873831050376]
	TIME [epoch: 3.57 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10054555758219237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10054555758219237 | validation: 0.1458264210722703]
	TIME [epoch: 3.58 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.132509825732838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.132509825732838 | validation: 0.06649066632592551]
	TIME [epoch: 3.56 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06933748597790836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06933748597790836 | validation: 0.05957245007144366]
	TIME [epoch: 3.59 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05914919512014805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05914919512014805 | validation: 0.06375210466296531]
	TIME [epoch: 3.58 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06411587047131263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06411587047131263 | validation: 0.06707189747876255]
	TIME [epoch: 3.58 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06770773468965478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06770773468965478 | validation: 0.05911517111229179]
	TIME [epoch: 3.57 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058874923070548243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058874923070548243 | validation: 0.0727274183349013]
	TIME [epoch: 3.57 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06563504866013982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06563504866013982 | validation: 0.09701042379969822]
	TIME [epoch: 3.56 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07586731532229843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07586731532229843 | validation: 0.08801557208351021]
	TIME [epoch: 3.57 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07507494475624918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07507494475624918 | validation: 0.059187387596702126]
	TIME [epoch: 3.57 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05454902222399061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05454902222399061 | validation: 0.044985982978717386]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042934761174550626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042934761174550626 | validation: 0.06396371618104449]
	TIME [epoch: 3.59 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053638129203527535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053638129203527535 | validation: 0.054107797087499125]
	TIME [epoch: 3.57 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07790130757740737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07790130757740737 | validation: 0.09470971666498867]
	TIME [epoch: 3.57 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08902985471932535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08902985471932535 | validation: 0.058445085042362614]
	TIME [epoch: 3.58 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055595002623261766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055595002623261766 | validation: 0.09638586664956544]
	TIME [epoch: 3.58 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06985541984605202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06985541984605202 | validation: 0.23587131282965645]
	TIME [epoch: 3.58 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18870971174803935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18870971174803935 | validation: 0.24267955198344687]
	TIME [epoch: 3.57 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21171897132249812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21171897132249812 | validation: 0.20691567341587255]
	TIME [epoch: 3.57 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21807511766714094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21807511766714094 | validation: 0.06361811663740845]
	TIME [epoch: 3.57 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06622132803320412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06622132803320412 | validation: 0.11200889444489998]
	TIME [epoch: 3.56 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0974780699939099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0974780699939099 | validation: 0.09456157058105275]
	TIME [epoch: 3.57 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07800277265867969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07800277265867969 | validation: 0.040847386929204754]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027919222314815143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027919222314815143 | validation: 0.03969251598933786]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031802355181191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031802355181191 | validation: 0.04617205893370689]
	TIME [epoch: 3.56 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0334520957126927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0334520957126927 | validation: 0.041190587502088025]
	TIME [epoch: 3.57 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03143411422543139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03143411422543139 | validation: 0.046079259300911966]
	TIME [epoch: 3.57 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03333041226409098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03333041226409098 | validation: 0.06461351411565851]
	TIME [epoch: 3.57 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04438399092682345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04438399092682345 | validation: 0.08703429214524894]
	TIME [epoch: 3.57 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08183149040036294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08183149040036294 | validation: 0.15947116310055465]
	TIME [epoch: 3.56 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18713371393928324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18713371393928324 | validation: 0.07954346848143487]
	TIME [epoch: 3.56 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08960070346775201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08960070346775201 | validation: 0.04808490473878374]
	TIME [epoch: 3.55 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032578615966137286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032578615966137286 | validation: 0.06807718015931584]
	TIME [epoch: 3.57 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04450574150312351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04450574150312351 | validation: 0.10743483578868229]
	TIME [epoch: 3.57 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09060594818991319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09060594818991319 | validation: 0.1506162167753973]
	TIME [epoch: 3.58 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1187402722627428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1187402722627428 | validation: 0.16144651129982693]
	TIME [epoch: 3.58 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15654979082743278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15654979082743278 | validation: 0.04504407754425095]
	TIME [epoch: 3.58 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04843475429920036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04843475429920036 | validation: 0.05613593533239563]
	TIME [epoch: 3.57 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03713538041508776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03713538041508776 | validation: 0.06305680064861964]
	TIME [epoch: 3.57 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05285640680615546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05285640680615546 | validation: 0.057945881038072036]
	TIME [epoch: 3.58 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042561670383485205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042561670383485205 | validation: 0.05082973539369329]
	TIME [epoch: 3.61 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048153408922309196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048153408922309196 | validation: 0.05440872588129214]
	TIME [epoch: 3.59 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05222885184471843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05222885184471843 | validation: 0.059331493190412525]
	TIME [epoch: 3.58 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06948350740269836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06948350740269836 | validation: 0.07289493499049259]
	TIME [epoch: 3.58 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07146805127475352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07146805127475352 | validation: 0.042302875560550436]
	TIME [epoch: 3.56 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050981404782985136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050981404782985136 | validation: 0.05059475903587372]
	TIME [epoch: 3.58 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053230663064641304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053230663064641304 | validation: 0.1160647329947995]
	TIME [epoch: 3.57 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11560114432364114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11560114432364114 | validation: 0.15098166580237968]
	TIME [epoch: 3.57 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15209721560424144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15209721560424144 | validation: 0.0758761271332415]
	TIME [epoch: 3.57 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05890484238252174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05890484238252174 | validation: 0.07295497997738785]
	TIME [epoch: 3.57 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04237851798893547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04237851798893547 | validation: 0.10912992367540222]
	TIME [epoch: 3.57 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08356457705237169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08356457705237169 | validation: 0.14188481214101095]
	TIME [epoch: 3.56 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10987434931990327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10987434931990327 | validation: 0.103583392938657]
	TIME [epoch: 3.57 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07535553740832932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07535553740832932 | validation: 0.06417072626228586]
	TIME [epoch: 3.57 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05108921393732322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05108921393732322 | validation: 0.05825497368171632]
	TIME [epoch: 3.58 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05678539656967116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05678539656967116 | validation: 0.05199795263777172]
	TIME [epoch: 3.57 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05511270493106135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05511270493106135 | validation: 0.061669045473483224]
	TIME [epoch: 3.58 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059586276666436754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059586276666436754 | validation: 0.07455974362641112]
	TIME [epoch: 3.56 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07782621113013759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07782621113013759 | validation: 0.06255107422484278]
	TIME [epoch: 3.57 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06969044649185964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06969044649185964 | validation: 0.061292624580811195]
	TIME [epoch: 3.57 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05336324973647447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05336324973647447 | validation: 0.05171184113000041]
	TIME [epoch: 3.58 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03893920516912569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03893920516912569 | validation: 0.06370206771529115]
	TIME [epoch: 3.56 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04852032420014295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04852032420014295 | validation: 0.1116596279972625]
	TIME [epoch: 3.58 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07954298913530218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07954298913530218 | validation: 0.15338236228271862]
	TIME [epoch: 3.56 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12445130601117586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12445130601117586 | validation: 0.11284915627105828]
	TIME [epoch: 3.56 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08607030031796294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08607030031796294 | validation: 0.047615097912901805]
	TIME [epoch: 3.57 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04714399496129293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04714399496129293 | validation: 0.04671923581690953]
	TIME [epoch: 3.58 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04358902818706427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04358902818706427 | validation: 0.047156029420069585]
	TIME [epoch: 3.57 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052458412719657885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052458412719657885 | validation: 0.06839419122464392]
	TIME [epoch: 3.58 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061684436719904125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061684436719904125 | validation: 0.04621593431861443]
	TIME [epoch: 3.56 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04756042822509354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04756042822509354 | validation: 0.04875578542607886]
	TIME [epoch: 3.56 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03688069342097025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03688069342097025 | validation: 0.055892213021388006]
	TIME [epoch: 3.55 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044250630684728655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044250630684728655 | validation: 0.09097361678015711]
	TIME [epoch: 3.55 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10690354285031167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10690354285031167 | validation: 0.20161298461064128]
	TIME [epoch: 3.57 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19653716804631174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19653716804631174 | validation: 0.09160364936289998]
	TIME [epoch: 3.57 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07308513515396632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07308513515396632 | validation: 0.07374062688952612]
	TIME [epoch: 3.56 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05798820356289639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05798820356289639 | validation: 0.10467148296815153]
	TIME [epoch: 3.58 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07770631422346069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07770631422346069 | validation: 0.07069727220949855]
	TIME [epoch: 3.57 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058353945241127934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058353945241127934 | validation: 0.05839925862873396]
	TIME [epoch: 3.58 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03766644041207475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03766644041207475 | validation: 0.04028563497923449]
	TIME [epoch: 3.57 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033002911256309816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033002911256309816 | validation: 0.043597188512105034]
	TIME [epoch: 3.59 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03313520951342905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03313520951342905 | validation: 0.04823206047779552]
	TIME [epoch: 3.57 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0460462236973636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0460462236973636 | validation: 0.08655125254374312]
	TIME [epoch: 3.56 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07567655949654259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07567655949654259 | validation: 0.13184154273825974]
	TIME [epoch: 3.55 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10989309942806717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10989309942806717 | validation: 0.07142302877984266]
	TIME [epoch: 3.58 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060912227533325945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060912227533325945 | validation: 0.060819405293001144]
	TIME [epoch: 3.57 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04419466884513509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04419466884513509 | validation: 0.049316533245265]
	TIME [epoch: 3.58 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05728729532563791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05728729532563791 | validation: 0.06396827112871435]
	TIME [epoch: 3.58 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06806682917449278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06806682917449278 | validation: 0.04530286627527653]
	TIME [epoch: 3.58 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06459049111822453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06459049111822453 | validation: 0.06460378533784614]
	TIME [epoch: 3.56 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0620058919956494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0620058919956494 | validation: 0.07911567992683599]
	TIME [epoch: 3.58 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06772819170247062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06772819170247062 | validation: 0.08448148804276157]
	TIME [epoch: 3.58 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07906643637065519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07906643637065519 | validation: 0.11021024836906135]
	TIME [epoch: 3.57 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09241542733306318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09241542733306318 | validation: 0.06437778557167362]
	TIME [epoch: 3.57 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05720381499681119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05720381499681119 | validation: 0.08104359952127596]
	TIME [epoch: 3.57 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06388255649786852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06388255649786852 | validation: 0.12983742526888667]
	TIME [epoch: 3.56 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09851893779422807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09851893779422807 | validation: 0.09189946072430376]
	TIME [epoch: 3.56 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08487230780099618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08487230780099618 | validation: 0.05508986320650397]
	TIME [epoch: 3.57 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047643038842171304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047643038842171304 | validation: 0.03843868172530899]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024946248311165292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024946248311165292 | validation: 0.034380095053992664]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019580007641905327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019580007641905327 | validation: 0.03766618469968516]
	TIME [epoch: 3.57 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025217802751031606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025217802751031606 | validation: 0.04233600146667843]
	TIME [epoch: 3.56 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0353253170325558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0353253170325558 | validation: 0.07204639263025628]
	TIME [epoch: 3.56 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06609161239351122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06609161239351122 | validation: 0.09621156421690583]
	TIME [epoch: 3.58 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10671888392031466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10671888392031466 | validation: 0.10544692356347665]
	TIME [epoch: 3.57 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1026547075332847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1026547075332847 | validation: 0.04081408846419679]
	TIME [epoch: 3.58 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02939816861360428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02939816861360428 | validation: 0.027426776524670918]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01865874136023812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01865874136023812 | validation: 0.032747187923750164]
	TIME [epoch: 3.57 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023608723867938074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023608723867938074 | validation: 0.047251414592214214]
	TIME [epoch: 3.56 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0376831668131883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0376831668131883 | validation: 0.12807892198614257]
	TIME [epoch: 3.57 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12624029756658808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12624029756658808 | validation: 0.2484832593652119]
	TIME [epoch: 3.57 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22218876297290038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22218876297290038 | validation: 0.21303050507135612]
	TIME [epoch: 3.59 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16711142671604876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16711142671604876 | validation: 0.06548676615400802]
	TIME [epoch: 3.55 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0558903614829176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0558903614829176 | validation: 0.08238692463271453]
	TIME [epoch: 3.57 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08238211477428237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08238211477428237 | validation: 0.04626670446170547]
	TIME [epoch: 3.56 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03826063274321679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03826063274321679 | validation: 0.051817958085034005]
	TIME [epoch: 3.58 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041480742087981394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041480742087981394 | validation: 0.038310840584163314]
	TIME [epoch: 3.58 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038523768623407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038523768623407 | validation: 0.03608934104660614]
	TIME [epoch: 3.59 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033906664526816094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033906664526816094 | validation: 0.044951298881897535]
	TIME [epoch: 3.57 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05027170726378746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05027170726378746 | validation: 0.06113958277732942]
	TIME [epoch: 3.57 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05879604052278817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05879604052278817 | validation: 0.04405601992371359]
	TIME [epoch: 3.56 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04578057593720663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04578057593720663 | validation: 0.035757022595101794]
	TIME [epoch: 3.58 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026640642559993225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026640642559993225 | validation: 0.026288027768130225]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020195613206288487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020195613206288487 | validation: 0.03391312697977982]
	TIME [epoch: 3.57 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02250853217636278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02250853217636278 | validation: 0.06380004155242583]
	TIME [epoch: 3.57 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04913486366167911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04913486366167911 | validation: 0.1316977919675055]
	TIME [epoch: 3.56 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1125214479216195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1125214479216195 | validation: 0.16176223494209396]
	TIME [epoch: 3.55 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12598410777447805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12598410777447805 | validation: 0.05992915440088269]
	TIME [epoch: 3.57 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06233056997861951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06233056997861951 | validation: 0.04355453492363562]
	TIME [epoch: 3.57 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04518132640611269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04518132640611269 | validation: 0.04568723809045465]
	TIME [epoch: 3.57 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04531899799270219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04531899799270219 | validation: 0.0424888613611696]
	TIME [epoch: 3.57 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04566269318901993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04566269318901993 | validation: 0.05738096571769927]
	TIME [epoch: 3.57 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054120234812823735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054120234812823735 | validation: 0.09267633686733877]
	TIME [epoch: 3.56 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0875529850313755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0875529850313755 | validation: 0.13913858154621284]
	TIME [epoch: 3.57 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12294083361701982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12294083361701982 | validation: 0.07532372698298856]
	TIME [epoch: 3.58 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0670337655538636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0670337655538636 | validation: 0.040617349829798234]
	TIME [epoch: 3.56 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030237911302427766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030237911302427766 | validation: 0.038372690329618014]
	TIME [epoch: 3.56 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021224106395431853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021224106395431853 | validation: 0.025166063244140554]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024084668591428306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024084668591428306 | validation: 0.03957276330904849]
	TIME [epoch: 3.57 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030481764120514322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030481764120514322 | validation: 0.04199522414801661]
	TIME [epoch: 3.58 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04071136241084121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04071136241084121 | validation: 0.08330567987363822]
	TIME [epoch: 3.59 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06402003561893499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06402003561893499 | validation: 0.09387298023098962]
	TIME [epoch: 3.58 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08224556929188045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08224556929188045 | validation: 0.11025517469633389]
	TIME [epoch: 3.59 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07909070226662268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07909070226662268 | validation: 0.09607952278602866]
	TIME [epoch: 3.59 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0860340833201214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0860340833201214 | validation: 0.0895362089532217]
	TIME [epoch: 3.57 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10149505502123903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10149505502123903 | validation: 0.06945264299784562]
	TIME [epoch: 3.58 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07344855927010033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07344855927010033 | validation: 0.04812328388485508]
	TIME [epoch: 3.56 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039824727461700134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039824727461700134 | validation: 0.033969999079335976]
	TIME [epoch: 3.58 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02500989810559462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02500989810559462 | validation: 0.02810887924734185]
	TIME [epoch: 3.57 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028753996050980314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028753996050980314 | validation: 0.03920084622965081]
	TIME [epoch: 3.57 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03334044864103704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03334044864103704 | validation: 0.03664276298619573]
	TIME [epoch: 3.56 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0379733240814187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0379733240814187 | validation: 0.042533668380387586]
	TIME [epoch: 3.57 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04456338897087465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04456338897087465 | validation: 0.03714783116708144]
	TIME [epoch: 3.58 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037725353134473186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037725353134473186 | validation: 0.03960581122300962]
	TIME [epoch: 3.58 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034466240729555495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034466240729555495 | validation: 0.04934345482465331]
	TIME [epoch: 3.57 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042146540095139635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042146540095139635 | validation: 0.10882248006266637]
	TIME [epoch: 3.58 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08045920592926678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08045920592926678 | validation: 0.1809574505042141]
	TIME [epoch: 3.58 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16871776917242112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16871776917242112 | validation: 0.20867310942362233]
	TIME [epoch: 3.57 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21169412134196353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21169412134196353 | validation: 0.030114025301334377]
	TIME [epoch: 3.57 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03582087928541112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03582087928541112 | validation: 0.0780950411202805]
	TIME [epoch: 3.57 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05800180277429101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05800180277429101 | validation: 0.08509149562170137]
	TIME [epoch: 3.57 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06824453384062966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06824453384062966 | validation: 0.04093222855054628]
	TIME [epoch: 3.56 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025945334208004784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025945334208004784 | validation: 0.02463378008493164]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016297829154868958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016297829154868958 | validation: 0.026971220550098207]
	TIME [epoch: 3.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020204136122995733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020204136122995733 | validation: 0.026988203391585655]
	TIME [epoch: 3.56 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025619520054042316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025619520054042316 | validation: 0.04079727879854364]
	TIME [epoch: 3.57 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03984229360428805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03984229360428805 | validation: 0.0559706543391173]
	TIME [epoch: 3.57 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07007776877621284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07007776877621284 | validation: 0.11672318906743016]
	TIME [epoch: 3.57 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10508649423785194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10508649423785194 | validation: 0.09832188492743317]
	TIME [epoch: 3.58 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08089202340840725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08089202340840725 | validation: 0.08097512889967601]
	TIME [epoch: 3.56 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057561285306816784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057561285306816784 | validation: 0.06755587378911891]
	TIME [epoch: 3.57 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061081226774200525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061081226774200525 | validation: 0.06756199088757797]
	TIME [epoch: 3.56 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06825829502933727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06825829502933727 | validation: 0.05504676799785603]
	TIME [epoch: 3.57 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048258909885279574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048258909885279574 | validation: 0.039403138375208376]
	TIME [epoch: 3.55 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028644996197545926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028644996197545926 | validation: 0.02272219382102715]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018191895917982096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.018191895917982096 | validation: 0.021757949345983255]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01892031633688881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01892031633688881 | validation: 0.02560680273105938]
	TIME [epoch: 3.57 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0289901278997054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0289901278997054 | validation: 0.04917801559405856]
	TIME [epoch: 3.56 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04613783465047975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04613783465047975 | validation: 0.05226996702542916]
	TIME [epoch: 3.57 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06505670320375478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06505670320375478 | validation: 0.11128767614631901]
	TIME [epoch: 3.57 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08014139220371977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08014139220371977 | validation: 0.14072227504216353]
	TIME [epoch: 3.63 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10973779731201828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10973779731201828 | validation: 0.12462291082179258]
	TIME [epoch: 3.59 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08395322852332675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08395322852332675 | validation: 0.05976464024839641]
	TIME [epoch: 3.57 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057132633553220326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057132633553220326 | validation: 0.0552300467103583]
	TIME [epoch: 3.57 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059098687849850125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059098687849850125 | validation: 0.05486347194180657]
	TIME [epoch: 3.57 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05605873080616936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05605873080616936 | validation: 0.0434928553160769]
	TIME [epoch: 3.56 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04443578398338589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04443578398338589 | validation: 0.028747348440664178]
	TIME [epoch: 3.56 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021387068305645986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021387068305645986 | validation: 0.027317940775695316]
	TIME [epoch: 3.58 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015688030587408915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015688030587408915 | validation: 0.021056825582564248]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_808.pth
	Model improved!!!
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013697493621291044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013697493621291044 | validation: 0.031596995653683235]
	TIME [epoch: 3.57 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022210354093071438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022210354093071438 | validation: 0.06252408620283668]
	TIME [epoch: 3.58 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047354360018342576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047354360018342576 | validation: 0.15994011379436546]
	TIME [epoch: 3.57 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1270190672421249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1270190672421249 | validation: 0.14404085946362316]
	TIME [epoch: 3.58 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12829938428337515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12829938428337515 | validation: 0.09070141493331606]
	TIME [epoch: 3.57 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07733588506409679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07733588506409679 | validation: 0.031258186297653236]
	TIME [epoch: 3.57 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02860745753395391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02860745753395391 | validation: 0.04328710563548227]
	TIME [epoch: 3.56 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0339978746623721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0339978746623721 | validation: 0.04022436755361691]
	TIME [epoch: 3.56 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03697536601009426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03697536601009426 | validation: 0.03768960311046276]
	TIME [epoch: 3.56 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03169457906641652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03169457906641652 | validation: 0.019789249442092535]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019930193218376923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019930193218376923 | validation: 0.02246054541680892]
	TIME [epoch: 3.57 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015132525889827173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015132525889827173 | validation: 0.018329801367636605]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_820.pth
	Model improved!!!
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016421099729894077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016421099729894077 | validation: 0.03654965680144997]
	TIME [epoch: 3.57 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028768370107078063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028768370107078063 | validation: 0.1178988203214717]
	TIME [epoch: 3.57 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10361169135654538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10361169135654538 | validation: 0.2508180375906674]
	TIME [epoch: 3.57 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23386349968029685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23386349968029685 | validation: 0.05694006239933387]
	TIME [epoch: 3.57 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05078531959584041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05078531959584041 | validation: 0.031113525121091515]
	TIME [epoch: 3.57 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03517271372196518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03517271372196518 | validation: 0.05146832935722293]
	TIME [epoch: 3.59 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04900787679960161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04900787679960161 | validation: 0.04575551719454855]
	TIME [epoch: 3.57 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03936591035222962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03936591035222962 | validation: 0.050105484761203425]
	TIME [epoch: 3.56 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039563362286280074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039563362286280074 | validation: 0.05767758928442787]
	TIME [epoch: 3.58 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04665696631968622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04665696631968622 | validation: 0.06407991095051616]
	TIME [epoch: 3.58 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050476118821337436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050476118821337436 | validation: 0.05562493404219085]
	TIME [epoch: 3.57 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045135082226526964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045135082226526964 | validation: 0.05086464764019053]
	TIME [epoch: 3.57 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04491039515472541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04491039515472541 | validation: 0.0484071784079056]
	TIME [epoch: 3.57 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051708837121107465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051708837121107465 | validation: 0.05579011925649407]
	TIME [epoch: 3.58 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05860217839142883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05860217839142883 | validation: 0.04146100097420854]
	TIME [epoch: 3.57 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04373472868685902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04373472868685902 | validation: 0.02950668320065732]
	TIME [epoch: 3.57 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029850752119323386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029850752119323386 | validation: 0.029698847670401415]
	TIME [epoch: 3.58 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02464492141539197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02464492141539197 | validation: 0.03878714651575563]
	TIME [epoch: 3.59 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036467545160717034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036467545160717034 | validation: 0.04848025061595601]
	TIME [epoch: 3.58 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0497334514614427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0497334514614427 | validation: 0.06879174295932165]
	TIME [epoch: 3.57 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07231264400032755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07231264400032755 | validation: 0.08447191323690528]
	TIME [epoch: 3.56 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07916995827199878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07916995827199878 | validation: 0.08915116540575192]
	TIME [epoch: 3.58 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07730796238446189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07730796238446189 | validation: 0.11197282253558281]
	TIME [epoch: 3.57 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08588618642225072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08588618642225072 | validation: 0.08182548313159202]
	TIME [epoch: 3.57 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05575874378674816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05575874378674816 | validation: 0.038647430595800635]
	TIME [epoch: 3.58 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030423524400679892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030423524400679892 | validation: 0.03236286646558747]
	TIME [epoch: 3.58 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026493790104045303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026493790104045303 | validation: 0.0278077992810363]
	TIME [epoch: 3.57 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02955396558296373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02955396558296373 | validation: 0.04156229465164873]
	TIME [epoch: 3.58 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03723981359436508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03723981359436508 | validation: 0.028131144654922877]
	TIME [epoch: 3.58 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03574662665462491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03574662665462491 | validation: 0.03503464052844073]
	TIME [epoch: 3.57 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03092574761392065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03092574761392065 | validation: 0.02224636487978209]
	TIME [epoch: 3.58 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02577850081687794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02577850081687794 | validation: 0.03254297515542159]
	TIME [epoch: 3.58 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02807791260868762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02807791260868762 | validation: 0.03925045855378948]
	TIME [epoch: 3.58 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0483514615158661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0483514615158661 | validation: 0.08049620187198586]
	TIME [epoch: 3.58 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09211901424579058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09211901424579058 | validation: 0.08318696502158135]
	TIME [epoch: 3.57 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07940931567250316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07940931567250316 | validation: 0.08380997927542706]
	TIME [epoch: 3.58 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05690961598041014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05690961598041014 | validation: 0.14285837767081513]
	TIME [epoch: 3.57 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10172010060475946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10172010060475946 | validation: 0.09983386518992471]
	TIME [epoch: 3.56 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07640504661574457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07640504661574457 | validation: 0.036603334674723195]
	TIME [epoch: 3.58 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027597375647282447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027597375647282447 | validation: 0.02341080376967787]
	TIME [epoch: 3.57 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013971271175738851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013971271175738851 | validation: 0.01597973298168845]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01036260720415243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01036260720415243 | validation: 0.015518015265646556]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_862.pth
	Model improved!!!
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.011656996945429739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011656996945429739 | validation: 0.027694935136572008]
	TIME [epoch: 3.58 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019402078410251523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019402078410251523 | validation: 0.048302698554204264]
	TIME [epoch: 3.58 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057214106924322695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057214106924322695 | validation: 0.1306778142941573]
	TIME [epoch: 3.57 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16273294045400008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16273294045400008 | validation: 0.12892919637972564]
	TIME [epoch: 3.56 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12636866112600062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12636866112600062 | validation: 0.021688377870821327]
	TIME [epoch: 3.56 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020123843400021553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020123843400021553 | validation: 0.030384474367233114]
	TIME [epoch: 3.55 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033307798099499596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033307798099499596 | validation: 0.052368841976812956]
	TIME [epoch: 3.58 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032004722582593015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032004722582593015 | validation: 0.019678173659530673]
	TIME [epoch: 3.57 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.012373786799213155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012373786799213155 | validation: 0.0160952551211308]
	TIME [epoch: 3.56 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.011816896009770183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011816896009770183 | validation: 0.02010023530259423]
	TIME [epoch: 3.55 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013075933045744788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013075933045744788 | validation: 0.023103480982261827]
	TIME [epoch: 3.56 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019075981397314482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019075981397314482 | validation: 0.05930406816550191]
	TIME [epoch: 3.56 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0512844807536297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0512844807536297 | validation: 0.27530338377583335]
	TIME [epoch: 3.56 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20974025041654223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20974025041654223 | validation: 0.22879414717262822]
	TIME [epoch: 3.56 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20851998265264526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20851998265264526 | validation: 0.04715220428702157]
	TIME [epoch: 3.58 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04767020760138282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04767020760138282 | validation: 0.11146599869157257]
	TIME [epoch: 3.56 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09533133630724365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09533133630724365 | validation: 0.0511410324100585]
	TIME [epoch: 3.57 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03799667061500726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03799667061500726 | validation: 0.02307882191317003]
	TIME [epoch: 3.55 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021012769397730936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021012769397730936 | validation: 0.04034178851046848]
	TIME [epoch: 3.56 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030995944441080735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030995944441080735 | validation: 0.02679745298095452]
	TIME [epoch: 3.56 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019979502560447865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019979502560447865 | validation: 0.024877098144955756]
	TIME [epoch: 3.56 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020666909018285506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020666909018285506 | validation: 0.02740431281606964]
	TIME [epoch: 3.55 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039315806211128825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039315806211128825 | validation: 0.06527942092695498]
	TIME [epoch: 3.56 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06588355867708368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06588355867708368 | validation: 0.05040907517173709]
	TIME [epoch: 3.57 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06901412914159906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06901412914159906 | validation: 0.05714199953212882]
	TIME [epoch: 3.54 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04319241534698457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04319241534698457 | validation: 0.025837461019910735]
	TIME [epoch: 3.56 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01883483901335276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01883483901335276 | validation: 0.020553364433539535]
	TIME [epoch: 3.56 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019958261876828136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019958261876828136 | validation: 0.038745275177539396]
	TIME [epoch: 3.57 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0283923205905576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0283923205905576 | validation: 0.04753567415703583]
	TIME [epoch: 3.57 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04011015516967304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04011015516967304 | validation: 0.07106188817809747]
	TIME [epoch: 3.56 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06049708055886065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06049708055886065 | validation: 0.10447229234461386]
	TIME [epoch: 3.57 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07531684022098689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07531684022098689 | validation: 0.12872975988598276]
	TIME [epoch: 3.57 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09795040674624472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09795040674624472 | validation: 0.06660377221907586]
	TIME [epoch: 3.57 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051547594244351166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051547594244351166 | validation: 0.0261941728944121]
	TIME [epoch: 3.56 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03293886891011952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03293886891011952 | validation: 0.03744215381342274]
	TIME [epoch: 3.57 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03758684486886869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03758684486886869 | validation: 0.033390823099114474]
	TIME [epoch: 3.55 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03725743538447858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03725743538447858 | validation: 0.04135635302414628]
	TIME [epoch: 3.56 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033894481746238374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033894481746238374 | validation: 0.03971393497696865]
	TIME [epoch: 3.56 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03104046574902414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03104046574902414 | validation: 0.04452424731282235]
	TIME [epoch: 3.57 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03403071473265629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03403071473265629 | validation: 0.04924196832265989]
	TIME [epoch: 3.57 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04273575832035057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04273575832035057 | validation: 0.057892525880317416]
	TIME [epoch: 3.58 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049487522134516695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049487522134516695 | validation: 0.062069956003598874]
	TIME [epoch: 3.58 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054955640599210986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054955640599210986 | validation: 0.04497258695040459]
	TIME [epoch: 3.57 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04411385784943954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04411385784943954 | validation: 0.04883667315598889]
	TIME [epoch: 3.57 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04159670559084499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04159670559084499 | validation: 0.04100952515056256]
	TIME [epoch: 3.56 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050689951731944766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050689951731944766 | validation: 0.0788794276563189]
	TIME [epoch: 3.57 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0768212091712844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0768212091712844 | validation: 0.05987009038870222]
	TIME [epoch: 3.57 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06266615967283548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06266615967283548 | validation: 0.045174757459162045]
	TIME [epoch: 3.56 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03308301644096118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03308301644096118 | validation: 0.03600314960582743]
	TIME [epoch: 3.58 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02141326264576126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02141326264576126 | validation: 0.02337514853354491]
	TIME [epoch: 3.58 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022841045629858146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022841045629858146 | validation: 0.038043209930038846]
	TIME [epoch: 3.58 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03052272219916585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03052272219916585 | validation: 0.06036944096808488]
	TIME [epoch: 3.58 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05461142893234705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05461142893234705 | validation: 0.11425870033530015]
	TIME [epoch: 3.58 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10399962288384998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10399962288384998 | validation: 0.08480282039445684]
	TIME [epoch: 3.58 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07530541521758213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07530541521758213 | validation: 0.048964459246766706]
	TIME [epoch: 3.57 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03754948901020699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03754948901020699 | validation: 0.025392350637916613]
	TIME [epoch: 3.57 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01973790181194649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01973790181194649 | validation: 0.021945024634258042]
	TIME [epoch: 3.57 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01963226911207151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01963226911207151 | validation: 0.039648098637825]
	TIME [epoch: 3.58 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028066168149546284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028066168149546284 | validation: 0.03787206736748202]
	TIME [epoch: 3.57 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05315487737190006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05315487737190006 | validation: 0.07396880289245764]
	TIME [epoch: 3.57 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06581908302157474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06581908302157474 | validation: 0.040990059955911665]
	TIME [epoch: 3.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04325504357685366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04325504357685366 | validation: 0.0312465725202]
	TIME [epoch: 3.56 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02384462773977835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02384462773977835 | validation: 0.028140133393164426]
	TIME [epoch: 3.56 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024615252993935594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024615252993935594 | validation: 0.03474240658083399]
	TIME [epoch: 3.57 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04220707394381606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04220707394381606 | validation: 0.06601131511541795]
	TIME [epoch: 3.58 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0713199523705024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0713199523705024 | validation: 0.07952019165340003]
	TIME [epoch: 3.58 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07660284451340157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07660284451340157 | validation: 0.07995862117317326]
	TIME [epoch: 3.57 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0678051630112486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0678051630112486 | validation: 0.1026996297755523]
	TIME [epoch: 3.57 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06991733408080592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06991733408080592 | validation: 0.0635038320248962]
	TIME [epoch: 3.57 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049098135577834115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049098135577834115 | validation: 0.02346551657404662]
	TIME [epoch: 3.57 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022014155923303164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022014155923303164 | validation: 0.03123910121214521]
	TIME [epoch: 3.57 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02797817546668384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02797817546668384 | validation: 0.03958941241632769]
	TIME [epoch: 3.57 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04363369556521076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04363369556521076 | validation: 0.056833144284677034]
	TIME [epoch: 3.57 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0534462162680535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0534462162680535 | validation: 0.025625752338726795]
	TIME [epoch: 3.56 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03448580519024668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03448580519024668 | validation: 0.03018653123263993]
	TIME [epoch: 3.57 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022123571517939845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022123571517939845 | validation: 0.016544246100312476]
	TIME [epoch: 3.56 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019795864299516172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019795864299516172 | validation: 0.0210155598025884]
	TIME [epoch: 3.57 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021993674484523006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021993674484523006 | validation: 0.040294214043232655]
	TIME [epoch: 3.59 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0410896637921958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0410896637921958 | validation: 0.06093699994205655]
	TIME [epoch: 3.58 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06307744585488405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06307744585488405 | validation: 0.09917604878688381]
	TIME [epoch: 3.58 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09127034869805412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09127034869805412 | validation: 0.1474609563944569]
	TIME [epoch: 3.58 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1172434053667946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1172434053667946 | validation: 0.05467549155984839]
	TIME [epoch: 3.59 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04874229973897849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04874229973897849 | validation: 0.03479636221548601]
	TIME [epoch: 3.57 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034783867680257104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034783867680257104 | validation: 0.0351008538329186]
	TIME [epoch: 3.56 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0425488163507211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0425488163507211 | validation: 0.04992950447736267]
	TIME [epoch: 3.57 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04651802600253936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04651802600253936 | validation: 0.03504449113263828]
	TIME [epoch: 3.56 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039293834520588544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039293834520588544 | validation: 0.03750594678542775]
	TIME [epoch: 3.57 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03127033681862559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03127033681862559 | validation: 0.023352323018536653]
	TIME [epoch: 3.56 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022727984131649004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022727984131649004 | validation: 0.021698790171702027]
	TIME [epoch: 3.58 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016068856535033687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016068856535033687 | validation: 0.025068833070403113]
	TIME [epoch: 3.55 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01583546781663899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01583546781663899 | validation: 0.02565012278671158]
	TIME [epoch: 3.57 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02363414118795892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02363414118795892 | validation: 0.07299999734866024]
	TIME [epoch: 3.57 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05191728681555022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05191728681555022 | validation: 0.143866234322726]
	TIME [epoch: 3.57 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11664449524380442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11664449524380442 | validation: 0.08956264706183098]
	TIME [epoch: 3.56 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09373218410868361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09373218410868361 | validation: 0.05143721275832589]
	TIME [epoch: 3.56 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055126009615314005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055126009615314005 | validation: 0.030397998314778074]
	TIME [epoch: 3.57 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03584555841377779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03584555841377779 | validation: 0.04316174794323103]
	TIME [epoch: 3.56 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03223758099251743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03223758099251743 | validation: 0.03855817094830616]
	TIME [epoch: 3.57 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03185856381096599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03185856381096599 | validation: 0.03001648375853267]
	TIME [epoch: 3.58 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024759892560151535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024759892560151535 | validation: 0.02549219926054191]
	TIME [epoch: 3.56 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020411239978230786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020411239978230786 | validation: 0.028702249170855062]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240823_172338/states/model_phi1_3a_v_mmd1_963.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 2549.072 seconds.
