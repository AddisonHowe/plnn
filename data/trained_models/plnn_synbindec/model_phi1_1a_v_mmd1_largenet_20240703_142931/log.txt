Args:
Namespace(name='model_phi1_1a_v_mmd1_largenet', outdir='out/model_training/model_phi1_1a_v_mmd1_largenet', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 201641609

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.231363964973547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.231363964973547 | validation: 5.313018358164545]
	TIME [epoch: 101 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.65284437763402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.65284437763402 | validation: 4.657773633788274]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.334234945803926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.334234945803926 | validation: 4.42742831442653]
	TIME [epoch: 9.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.152006467999539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.152006467999539 | validation: 4.460301985978488]
	TIME [epoch: 9.56 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014960165320877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.014960165320877 | validation: 4.237429978864624]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.893099208115791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.893099208115791 | validation: 3.893315461179487]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8317827412004926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8317827412004926 | validation: 3.9041118362938]
	TIME [epoch: 9.56 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4455880040922633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4455880040922633 | validation: 3.415523449456058]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1452783146131065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1452783146131065 | validation: 3.3982167801004097]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0787009915675183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0787009915675183 | validation: 3.075396511845362]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7141771472516334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7141771472516334 | validation: 2.783092697679688]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6703655997148146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6703655997148146 | validation: 2.8743156082141845]
	TIME [epoch: 9.56 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5601577229587122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5601577229587122 | validation: 2.6111201427416333]
	TIME [epoch: 9.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3536194354645503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3536194354645503 | validation: 2.051249302335109]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369407519514359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.369407519514359 | validation: 2.3700614468063446]
	TIME [epoch: 9.62 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7387455001873622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7387455001873622 | validation: 1.6214371881332648]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9578867534582813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9578867534582813 | validation: 2.1307838695599672]
	TIME [epoch: 9.66 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8533699773944043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8533699773944043 | validation: 1.2353108162771587]
	TIME [epoch: 9.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6820232802251853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6820232802251853 | validation: 1.1923105128869325]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.162220522782376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.162220522782376 | validation: 0.9413667746975689]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8562385768817207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8562385768817207 | validation: 0.8822740097180642]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483958375300804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.483958375300804 | validation: 1.3455699070154945]
	TIME [epoch: 9.65 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051094669622642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.051094669622642 | validation: 0.7834917101583333]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108668794626025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7108668794626025 | validation: 0.6212267452169067]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.649040043152947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.649040043152947 | validation: 1.062984165222388]
	TIME [epoch: 9.61 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3970984853721167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3970984853721167 | validation: 0.9791209358694436]
	TIME [epoch: 9.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9619871245998135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9619871245998135 | validation: 0.7399413090122358]
	TIME [epoch: 9.67 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976086973490754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6976086973490754 | validation: 0.5938778384352073]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5537908350329421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5537908350329421 | validation: 0.9010438547373478]
	TIME [epoch: 9.63 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8121511417041294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8121511417041294 | validation: 0.6889357179281829]
	TIME [epoch: 9.63 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709664061016113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6709664061016113 | validation: 0.49518425829316515]
	TIME [epoch: 9.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8989233091677212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8989233091677212 | validation: 0.7530272484318963]
	TIME [epoch: 9.61 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7365247914303318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7365247914303318 | validation: 0.6527424247478413]
	TIME [epoch: 9.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435710882333308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6435710882333308 | validation: 0.561350154656194]
	TIME [epoch: 9.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548206438432214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5548206438432214 | validation: 0.5086852371257076]
	TIME [epoch: 9.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130831921455969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7130831921455969 | validation: 0.6404260635327177]
	TIME [epoch: 9.65 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6249646042399394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6249646042399394 | validation: 0.5263054199083717]
	TIME [epoch: 9.61 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5092322502700086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5092322502700086 | validation: 0.46905590608648096]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5933077692785758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5933077692785758 | validation: 0.47919712687644195]
	TIME [epoch: 9.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8975334374780422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8975334374780422 | validation: 0.5692863526554693]
	TIME [epoch: 9.65 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108420526585704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6108420526585704 | validation: 0.5691204083494065]
	TIME [epoch: 9.61 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5904724493325356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5904724493325356 | validation: 0.572384614691537]
	TIME [epoch: 9.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812816313847333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5812816313847333 | validation: 0.5758243265605187]
	TIME [epoch: 9.59 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6465863962105547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6465863962105547 | validation: 0.5504954986037496]
	TIME [epoch: 9.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5863325888010275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5863325888010275 | validation: 0.8544787907503433]
	TIME [epoch: 9.64 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409320051974044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7409320051974044 | validation: 0.6328330234533315]
	TIME [epoch: 9.59 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6150554614958622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6150554614958622 | validation: 0.5733997607075585]
	TIME [epoch: 9.59 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840121392965459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5840121392965459 | validation: 0.7114484947443469]
	TIME [epoch: 9.59 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607284050171421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.607284050171421 | validation: 0.5504245161145688]
	TIME [epoch: 9.64 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764632759353786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5764632759353786 | validation: 0.5172975278046843]
	TIME [epoch: 9.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49177642371274993		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.49177642371274993 | validation: 1.4153438946228176]
	TIME [epoch: 9.59 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8308879764509335		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.8308879764509335 | validation: 0.577925388208478]
	TIME [epoch: 9.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592037669683453		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5592037669683453 | validation: 0.5145264965264494]
	TIME [epoch: 9.61 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789348373439551		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.4789348373439551 | validation: 0.6259773055330706]
	TIME [epoch: 9.63 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468900560202471		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.5468900560202471 | validation: 0.6691111717640637]
	TIME [epoch: 9.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208597516078748		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.5208597516078748 | validation: 0.4949398163409986]
	TIME [epoch: 9.59 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693875227741709		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.4693875227741709 | validation: 0.47398358569701415]
	TIME [epoch: 9.59 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299596082257296		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.4299596082257296 | validation: 0.438534978382737]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388790222277322		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.388790222277322 | validation: 0.44061398401772855]
	TIME [epoch: 9.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4856878705963145		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.4856878705963145 | validation: 0.5618701378088131]
	TIME [epoch: 9.59 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041626900028176		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.4041626900028176 | validation: 0.41400274111388335]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40884287403148667		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.40884287403148667 | validation: 0.520512705974904]
	TIME [epoch: 9.63 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472905987857776		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.4472905987857776 | validation: 0.5629742203930017]
	TIME [epoch: 9.62 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4445146132413606		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.4445146132413606 | validation: 0.44357697036685784]
	TIME [epoch: 9.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019853374303503		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.4019853374303503 | validation: 0.40018614629436877]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39743672601689184		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.39743672601689184 | validation: 0.3759053194834619]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38748859208085995		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.38748859208085995 | validation: 0.4035372350115669]
	TIME [epoch: 9.65 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.647509061390304		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.647509061390304 | validation: 0.6550941112370823]
	TIME [epoch: 9.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460013477433996		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.5460013477433996 | validation: 0.4489402227697254]
	TIME [epoch: 9.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39670587368892535		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.39670587368892535 | validation: 0.441659510567615]
	TIME [epoch: 9.61 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36155572482313175		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.36155572482313175 | validation: 0.5029741191090137]
	TIME [epoch: 9.66 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4170504268092038		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.4170504268092038 | validation: 0.43734920996999693]
	TIME [epoch: 9.62 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37787681842240417		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.37787681842240417 | validation: 0.3614415862309351]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334722561990195		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.3334722561990195 | validation: 0.3779309729743624]
	TIME [epoch: 9.62 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39034830192775394		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.39034830192775394 | validation: 0.3658119196274337]
	TIME [epoch: 9.64 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943830738621798		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.3943830738621798 | validation: 0.6814376608492096]
	TIME [epoch: 9.65 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44245496924278427		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.44245496924278427 | validation: 0.37353358225204014]
	TIME [epoch: 9.62 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135391696702029		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.3135391696702029 | validation: 0.36546910752589234]
	TIME [epoch: 9.62 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3707072583038663		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.3707072583038663 | validation: 0.43132374853586464]
	TIME [epoch: 9.62 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3322050603276464		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.3322050603276464 | validation: 0.27294127151159175]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28121578435660505		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.28121578435660505 | validation: 0.2437648542670083]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270620654495932		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.270620654495932 | validation: 0.34903297573544334]
	TIME [epoch: 9.61 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123806753086369		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.3123806753086369 | validation: 0.2511802964546004]
	TIME [epoch: 9.61 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725650414261157		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.2725650414261157 | validation: 0.4296630794188022]
	TIME [epoch: 9.62 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3877394155082173		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.3877394155082173 | validation: 0.3187655495725136]
	TIME [epoch: 9.66 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35483732764426146		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.35483732764426146 | validation: 0.3289807984826995]
	TIME [epoch: 9.61 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26213737408049337		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.26213737408049337 | validation: 0.24251358171619325]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145510135698929		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.3145510135698929 | validation: 0.3502928318116119]
	TIME [epoch: 9.61 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284178129677025		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3284178129677025 | validation: 0.47534477562989264]
	TIME [epoch: 9.66 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32810043043043347		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.32810043043043347 | validation: 0.24847953754603463]
	TIME [epoch: 9.61 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26301675775667865		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.26301675775667865 | validation: 0.36721645370381983]
	TIME [epoch: 9.61 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31024133540955195		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.31024133540955195 | validation: 0.3225745972064971]
	TIME [epoch: 9.61 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854037891220469		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.2854037891220469 | validation: 0.2360674718302632]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24066868572595665		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.24066868572595665 | validation: 0.24721955602554296]
	TIME [epoch: 9.64 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23859830679616834		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.23859830679616834 | validation: 0.3190469340630975]
	TIME [epoch: 9.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33993540847627335		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.33993540847627335 | validation: 0.3417473215671145]
	TIME [epoch: 9.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27795094646899654		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.27795094646899654 | validation: 0.2155684025888872]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2308634896855214		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.2308634896855214 | validation: 0.3069165117323257]
	TIME [epoch: 9.68 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669178821265562		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.2669178821265562 | validation: 0.23823226437240683]
	TIME [epoch: 9.63 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21998516461123988		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.21998516461123988 | validation: 0.21490641549558165]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22657918483570233		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.22657918483570233 | validation: 0.19125495993728742]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19206591637780054		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.19206591637780054 | validation: 0.2890521065542278]
	TIME [epoch: 9.68 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23699998594158914		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.23699998594158914 | validation: 0.26941357937260646]
	TIME [epoch: 9.63 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.307161327598469		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.307161327598469 | validation: 0.3041482416992016]
	TIME [epoch: 9.62 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539674914396547		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.2539674914396547 | validation: 0.18847726963250477]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19809970113505943		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.19809970113505943 | validation: 0.2101402359740261]
	TIME [epoch: 9.69 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198492716371966		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.198492716371966 | validation: 0.1913791174431243]
	TIME [epoch: 9.68 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720941983023553		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.2720941983023553 | validation: 0.3377171903467928]
	TIME [epoch: 9.61 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25945731884215906		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.25945731884215906 | validation: 0.25704077324810504]
	TIME [epoch: 9.62 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23141533367335582		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.23141533367335582 | validation: 0.21043824558671814]
	TIME [epoch: 9.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21526966667371775		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.21526966667371775 | validation: 0.198524674063788]
	TIME [epoch: 9.65 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2379770275152533		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.2379770275152533 | validation: 0.2206911933841073]
	TIME [epoch: 9.62 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22218867333537032		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.22218867333537032 | validation: 0.19277694267327194]
	TIME [epoch: 9.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20440490154262111		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.20440490154262111 | validation: 0.2532411575497769]
	TIME [epoch: 9.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24219355330775533		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.24219355330775533 | validation: 0.24002430408962339]
	TIME [epoch: 9.61 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724117125225734		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.2724117125225734 | validation: 0.27410228469602327]
	TIME [epoch: 9.65 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22631281051635238		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.22631281051635238 | validation: 0.19698274696179255]
	TIME [epoch: 9.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23902069784893468		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.23902069784893468 | validation: 0.18981792104497353]
	TIME [epoch: 9.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20148909852997499		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.20148909852997499 | validation: 0.1936460141520709]
	TIME [epoch: 9.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144284457412058		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.2144284457412058 | validation: 0.29355182221284704]
	TIME [epoch: 9.65 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525324899429234		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3525324899429234 | validation: 0.298529280700131]
	TIME [epoch: 9.61 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21114958576871523		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.21114958576871523 | validation: 0.21525610889856278]
	TIME [epoch: 9.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837344265930138		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.1837344265930138 | validation: 0.23448715306799456]
	TIME [epoch: 9.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17430127497030617		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.17430127497030617 | validation: 0.23097070883520182]
	TIME [epoch: 9.61 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21794756057479803		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.21794756057479803 | validation: 0.20258603324689783]
	TIME [epoch: 9.65 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1797936677307348		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.1797936677307348 | validation: 0.18870941554562387]
	TIME [epoch: 9.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19269248532110275		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.19269248532110275 | validation: 0.20347478296994875]
	TIME [epoch: 9.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19189368396934708		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.19189368396934708 | validation: 0.16421326044056356]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16853034992408567		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.16853034992408567 | validation: 0.16820909873213044]
	TIME [epoch: 9.65 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20006391202053045		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20006391202053045 | validation: 0.19360877513916552]
	TIME [epoch: 9.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17544066287307136		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.17544066287307136 | validation: 0.15569874098074454]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1923247874824498		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.1923247874824498 | validation: 0.17346126002094767]
	TIME [epoch: 9.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18189650078184666		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.18189650078184666 | validation: 0.1714887568130658]
	TIME [epoch: 9.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944823110745944		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.1944823110745944 | validation: 0.2914410842125057]
	TIME [epoch: 9.64 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22046449245397898		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.22046449245397898 | validation: 0.18806826281535377]
	TIME [epoch: 9.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18734837911538516		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.18734837911538516 | validation: 0.2020857521259977]
	TIME [epoch: 9.59 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17927471073492657		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.17927471073492657 | validation: 0.16003997835434375]
	TIME [epoch: 9.59 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652716150464699		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.1652716150464699 | validation: 0.14427910336753638]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17034453711827		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.17034453711827 | validation: 0.18999109930104285]
	TIME [epoch: 9.64 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19210630764322398		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.19210630764322398 | validation: 0.14160980913331273]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676810360095912		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.1676810360095912 | validation: 0.1586625111367875]
	TIME [epoch: 9.62 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666826516942382		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.1666826516942382 | validation: 0.1510284018096979]
	TIME [epoch: 9.61 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16337057356911378		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.16337057356911378 | validation: 0.19935220498912082]
	TIME [epoch: 9.64 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14603173875642722		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.14603173875642722 | validation: 0.15226252990429867]
	TIME [epoch: 9.63 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16254445545357651		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.16254445545357651 | validation: 0.24562315498649767]
	TIME [epoch: 9.61 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948415972415556		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.1948415972415556 | validation: 0.13319151235521945]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16062422811137708		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.16062422811137708 | validation: 0.23645994017377764]
	TIME [epoch: 9.61 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123921409883284		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.15123921409883284 | validation: 0.13732315628293915]
	TIME [epoch: 9.66 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12849846662502684		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.12849846662502684 | validation: 0.2471357354159744]
	TIME [epoch: 9.62 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16421811450805454		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.16421811450805454 | validation: 0.12221224086108495]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522866516249032		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.1522866516249032 | validation: 0.154491876283756]
	TIME [epoch: 9.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14608605962111235		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.14608605962111235 | validation: 0.1434519849606]
	TIME [epoch: 9.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12548210729603199		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.12548210729603199 | validation: 0.10914314759740762]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18204782821279133		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.18204782821279133 | validation: 0.16393807525602144]
	TIME [epoch: 9.62 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870758597069207		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.12870758597069207 | validation: 0.12185315648356224]
	TIME [epoch: 9.62 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645118229027407		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.11645118229027407 | validation: 0.17909487438320465]
	TIME [epoch: 9.62 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15410376797292982		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.15410376797292982 | validation: 0.12433399591461008]
	TIME [epoch: 9.64 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066954304146057		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.15066954304146057 | validation: 0.1463892842162894]
	TIME [epoch: 9.66 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14811602527914003		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.14811602527914003 | validation: 0.13808875364393158]
	TIME [epoch: 9.63 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14421755511989076		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.14421755511989076 | validation: 0.18070444989420476]
	TIME [epoch: 9.62 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15730286406066682		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.15730286406066682 | validation: 0.11848475026497828]
	TIME [epoch: 9.62 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570277008603878		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.15570277008603878 | validation: 0.10865465813622496]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315687392396957		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.1315687392396957 | validation: 0.1025900645294891]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218848143994682		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.09218848143994682 | validation: 0.15546657470304953]
	TIME [epoch: 9.62 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297703173699906		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.15297703173699906 | validation: 0.12461731150326574]
	TIME [epoch: 9.62 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612778983946477		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.09612778983946477 | validation: 0.10012916046924539]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727649382274598		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.13727649382274598 | validation: 0.14192655470313592]
	TIME [epoch: 9.67 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10664207072859139		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.10664207072859139 | validation: 0.12465919872071642]
	TIME [epoch: 9.62 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813285018367726		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.12813285018367726 | validation: 0.08643748453424092]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07482463615766231		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.07482463615766231 | validation: 0.07392679606624236]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062002174793201		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.1062002174793201 | validation: 0.1995069660739433]
	TIME [epoch: 9.61 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301722298584581		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.10301722298584581 | validation: 0.07231284944685895]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11964886938445701		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.11964886938445701 | validation: 0.1512124079530805]
	TIME [epoch: 9.59 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872370255784356		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.09872370255784356 | validation: 0.10145975122536917]
	TIME [epoch: 9.61 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11320608056190269		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.11320608056190269 | validation: 0.08881561585360476]
	TIME [epoch: 9.61 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09601856747745713		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.09601856747745713 | validation: 0.07494436388509756]
	TIME [epoch: 9.65 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06732358487460377		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.06732358487460377 | validation: 0.0733603368376801]
	TIME [epoch: 9.62 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987471908998822		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.0987471908998822 | validation: 0.2608775655875718]
	TIME [epoch: 9.59 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17842399478633483		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.17842399478633483 | validation: 0.11711720068202838]
	TIME [epoch: 9.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07655093444257223		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.07655093444257223 | validation: 0.07265327061653024]
	TIME [epoch: 9.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06697277933221739		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.06697277933221739 | validation: 0.09271321911470329]
	TIME [epoch: 9.64 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16174251496009587		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.16174251496009587 | validation: 0.10531214904619515]
	TIME [epoch: 9.62 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10282350102576443		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.10282350102576443 | validation: 0.09084262095543663]
	TIME [epoch: 9.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.082384375742424		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.082384375742424 | validation: 0.08724469431229193]
	TIME [epoch: 9.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07406275862843856		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.07406275862843856 | validation: 0.1436899857391702]
	TIME [epoch: 9.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10984506559813749		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.10984506559813749 | validation: 0.07382008288999328]
	TIME [epoch: 9.62 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08223101797282957		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.08223101797282957 | validation: 0.08421818690886292]
	TIME [epoch: 9.61 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920643153698389		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.09920643153698389 | validation: 0.10451215535744887]
	TIME [epoch: 9.63 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230437948681748		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.07230437948681748 | validation: 0.05397926051787423]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05840542797085595		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.05840542797085595 | validation: 0.11986660229729806]
	TIME [epoch: 9.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14660009514844344		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.14660009514844344 | validation: 0.1194948544503532]
	TIME [epoch: 9.64 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070892621300132		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.1070892621300132 | validation: 0.09761777820535111]
	TIME [epoch: 9.64 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577958796090637		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.08577958796090637 | validation: 0.10101981010682679]
	TIME [epoch: 9.64 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609910541382169		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.07609910541382169 | validation: 0.08007741435360985]
	TIME [epoch: 9.67 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868461155611496		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.0868461155611496 | validation: 0.11631589077454041]
	TIME [epoch: 9.69 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09581836279168769		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.09581836279168769 | validation: 0.10741482294569746]
	TIME [epoch: 9.64 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795839167024166		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.0795839167024166 | validation: 0.08698591917439548]
	TIME [epoch: 9.64 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09025476683666589		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.09025476683666589 | validation: 0.05925309898686151]
	TIME [epoch: 9.63 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05153849486268311		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.05153849486268311 | validation: 0.061675741320160196]
	TIME [epoch: 9.67 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924837111643913		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.0924837111643913 | validation: 0.05522648958878157]
	TIME [epoch: 9.65 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056761843788371964		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.056761843788371964 | validation: 0.06521251531604827]
	TIME [epoch: 9.63 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227568769154816		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.1227568769154816 | validation: 0.057272924425020286]
	TIME [epoch: 9.63 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276865786893612		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.07276865786893612 | validation: 0.05724839024374996]
	TIME [epoch: 9.64 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054690884389307366		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.054690884389307366 | validation: 0.06324417418663443]
	TIME [epoch: 9.69 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822964218792218		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.06822964218792218 | validation: 0.1479146485185131]
	TIME [epoch: 9.64 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09670101902502322		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.09670101902502322 | validation: 0.060166521033705]
	TIME [epoch: 9.64 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029202072368836		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.06029202072368836 | validation: 0.06042381865167934]
	TIME [epoch: 9.62 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08524674557577433		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.08524674557577433 | validation: 0.06801798714261785]
	TIME [epoch: 9.66 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142103252922576		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.05142103252922576 | validation: 0.05837179326923722]
	TIME [epoch: 9.66 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08375694955727048		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.08375694955727048 | validation: 0.17553999123060507]
	TIME [epoch: 9.63 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10187079362892264		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.10187079362892264 | validation: 0.053020909726097236]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056340932174219385		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.056340932174219385 | validation: 0.05481379537547294]
	TIME [epoch: 9.63 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07139075959140527		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.07139075959140527 | validation: 0.10407603471077179]
	TIME [epoch: 9.66 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374920968619735		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.06374920968619735 | validation: 0.051287971935888854]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060377946301445454		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.060377946301445454 | validation: 0.09869287650900385]
	TIME [epoch: 9.62 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028734443233427		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.07028734443233427 | validation: 0.045520986779886426]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599689146320075		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.0599689146320075 | validation: 0.07111635108628647]
	TIME [epoch: 9.63 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07706477232422371		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.07706477232422371 | validation: 0.05398228614810075]
	TIME [epoch: 9.65 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03775590581226916		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.03775590581226916 | validation: 0.037841670143296466]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09145210133917722		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.09145210133917722 | validation: 0.08912366947702957]
	TIME [epoch: 9.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422224415671752		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.05422224415671752 | validation: 0.08432924352555754]
	TIME [epoch: 9.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04674743033710973		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.04674743033710973 | validation: 0.07682526093184724]
	TIME [epoch: 9.62 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694153799587325		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.07694153799587325 | validation: 0.05362361715758492]
	TIME [epoch: 9.62 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06070146840607973		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.06070146840607973 | validation: 0.05296478711762462]
	TIME [epoch: 9.58 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438940304770592		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.0438940304770592 | validation: 0.03862561168407782]
	TIME [epoch: 9.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954738167202562		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.05954738167202562 | validation: 0.06955374376122714]
	TIME [epoch: 9.58 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127655279726493		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.07127655279726493 | validation: 0.050193502762507156]
	TIME [epoch: 9.65 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923752189502649		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.0923752189502649 | validation: 0.07982329413033576]
	TIME [epoch: 9.59 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370472158853793		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.06370472158853793 | validation: 0.08362179038064463]
	TIME [epoch: 9.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264432846910921		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.06264432846910921 | validation: 0.04390380170100519]
	TIME [epoch: 9.59 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600759727822861		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.03600759727822861 | validation: 0.04675839999156222]
	TIME [epoch: 9.62 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534118845598929		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.05534118845598929 | validation: 0.10798119178230237]
	TIME [epoch: 9.63 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07465998357891199		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.07465998357891199 | validation: 0.05374069047884321]
	TIME [epoch: 9.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040254075434604755		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.040254075434604755 | validation: 0.03479479147637164]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05147335753940828		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.05147335753940828 | validation: 0.09825833676107501]
	TIME [epoch: 9.62 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371378180446779		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.05371378180446779 | validation: 0.05497832100213991]
	TIME [epoch: 9.67 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04778900108923556		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.04778900108923556 | validation: 0.10236604012210555]
	TIME [epoch: 9.62 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07137201792780125		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.07137201792780125 | validation: 0.031359834361465534]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499317952029281		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.04499317952029281 | validation: 0.09746254564405188]
	TIME [epoch: 9.64 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517442664822581		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.0517442664822581 | validation: 0.03297560094780587]
	TIME [epoch: 9.64 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03102278672119188		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.03102278672119188 | validation: 0.06922856244603869]
	TIME [epoch: 9.68 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08682095103134324		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.08682095103134324 | validation: 0.03765719458436967]
	TIME [epoch: 9.63 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04129133895430869		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.04129133895430869 | validation: 0.03546460313634652]
	TIME [epoch: 9.63 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003089037382562		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.04003089037382562 | validation: 0.0714302521564602]
	TIME [epoch: 9.62 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042933065394353286		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.042933065394353286 | validation: 0.04060651173735705]
	TIME [epoch: 9.65 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06604629030644192		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.06604629030644192 | validation: 0.06875424363717644]
	TIME [epoch: 9.66 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044324059411804714		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.044324059411804714 | validation: 0.02901100367803698]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050583097387501		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.03050583097387501 | validation: 0.035684796329873834]
	TIME [epoch: 9.63 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06973967271638781		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.06973967271638781 | validation: 0.037727429397343956]
	TIME [epoch: 9.63 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605638214822224		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.03605638214822224 | validation: 0.06473728163181525]
	TIME [epoch: 9.68 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04963828953127977		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.04963828953127977 | validation: 0.05685382665682119]
	TIME [epoch: 9.63 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051059270732417374		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.051059270732417374 | validation: 0.03453829264787078]
	TIME [epoch: 9.62 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026903692302196542		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.026903692302196542 | validation: 0.030980031725851585]
	TIME [epoch: 9.62 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0400500444150056		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.0400500444150056 | validation: 0.09341430900389719]
	TIME [epoch: 9.63 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059691641336651405		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.059691641336651405 | validation: 0.03715066589696806]
	TIME [epoch: 9.67 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433911105763333		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.04433911105763333 | validation: 0.06491476902808473]
	TIME [epoch: 9.62 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046937355088389345		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.046937355088389345 | validation: 0.03226624376373322]
	TIME [epoch: 9.62 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04405935551451198		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.04405935551451198 | validation: 0.05046067258178921]
	TIME [epoch: 9.62 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043193847649812975		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.043193847649812975 | validation: 0.04298724813990428]
	TIME [epoch: 9.67 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04180301329172824		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.04180301329172824 | validation: 0.046301658704756006]
	TIME [epoch: 9.63 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037264685865319794		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.037264685865319794 | validation: 0.052603157361684305]
	TIME [epoch: 9.63 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738836947242291		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.03738836947242291 | validation: 0.04509832185018784]
	TIME [epoch: 9.63 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050858840145212594		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.050858840145212594 | validation: 0.04099042665394313]
	TIME [epoch: 9.65 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030786024241365194		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.030786024241365194 | validation: 0.027900987743991856]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288821621346835		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.04288821621346835 | validation: 0.08060368167948133]
	TIME [epoch: 9.62 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056108988175650854		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.056108988175650854 | validation: 0.16393630360257264]
	TIME [epoch: 9.61 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087416081705506		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.087416081705506 | validation: 0.04989107973095509]
	TIME [epoch: 9.61 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044823838200457294		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.044823838200457294 | validation: 0.03621674054427423]
	TIME [epoch: 9.67 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026632884098572007		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.026632884098572007 | validation: 0.027306040157284397]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029677148872182035		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.029677148872182035 | validation: 0.03971610608032641]
	TIME [epoch: 9.61 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748085442900748		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.04748085442900748 | validation: 0.07531292585208485]
	TIME [epoch: 9.61 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04514107671211198		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.04514107671211198 | validation: 0.03687964437412963]
	TIME [epoch: 9.62 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034639215575826596		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.034639215575826596 | validation: 0.03607823038014769]
	TIME [epoch: 9.66 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335235929556893		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.0335235929556893 | validation: 0.04763632491289757]
	TIME [epoch: 9.61 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04887684981817873		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.04887684981817873 | validation: 0.0283115912946322]
	TIME [epoch: 9.61 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031684430592817336		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.031684430592817336 | validation: 0.060349988515373654]
	TIME [epoch: 9.61 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703453233368359		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.03703453233368359 | validation: 0.03364189323986391]
	TIME [epoch: 9.63 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021217330865484163		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.021217330865484163 | validation: 0.034085030446154095]
	TIME [epoch: 9.64 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576479046121076		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.0576479046121076 | validation: 0.06329527400414268]
	TIME [epoch: 9.61 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049013332271263546		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.049013332271263546 | validation: 0.04635248775621218]
	TIME [epoch: 9.61 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028839508572283856		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.028839508572283856 | validation: 0.019490274507395086]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742447144677626		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.01742447144677626 | validation: 0.04559472437663242]
	TIME [epoch: 9.68 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718944584942538		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.05718944584942538 | validation: 0.02758043399755484]
	TIME [epoch: 9.62 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025911784335178576		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.025911784335178576 | validation: 0.027975404258871253]
	TIME [epoch: 9.62 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412161566639406		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.0412161566639406 | validation: 0.050588220213392536]
	TIME [epoch: 9.62 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04084598103095018		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.04084598103095018 | validation: 0.03320760813862241]
	TIME [epoch: 9.63 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030756893404242813		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.030756893404242813 | validation: 0.027132295425355724]
	TIME [epoch: 9.67 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02218973519450975		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.02218973519450975 | validation: 0.04843720697111455]
	TIME [epoch: 9.62 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05053900213978861		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.05053900213978861 | validation: 0.020657734034760677]
	TIME [epoch: 9.62 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02655737359166098		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.02655737359166098 | validation: 0.023009186608124593]
	TIME [epoch: 9.62 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020656856810573318		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.020656856810573318 | validation: 0.02125316975485913]
	TIME [epoch: 9.67 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047509660926850855		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.047509660926850855 | validation: 0.07578490526586465]
	TIME [epoch: 9.63 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03369269812875805		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.03369269812875805 | validation: 0.0304769858905704]
	TIME [epoch: 9.62 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529329988119894		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.03529329988119894 | validation: 0.029878808671744826]
	TIME [epoch: 9.62 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022523640295064207		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.022523640295064207 | validation: 0.03608184628874376]
	TIME [epoch: 9.64 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776522711063765		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.03776522711063765 | validation: 0.05481225575460236]
	TIME [epoch: 9.66 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544928354136044		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.03544928354136044 | validation: 0.024418465286291373]
	TIME [epoch: 9.62 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020183007540732753		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.020183007540732753 | validation: 0.03800160427247648]
	TIME [epoch: 9.62 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03874841169918374		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.03874841169918374 | validation: 0.02447983776118988]
	TIME [epoch: 9.62 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019605816078857044		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.019605816078857044 | validation: 0.021810074361642583]
	TIME [epoch: 9.68 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283682224685152		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.04283682224685152 | validation: 0.036599405159809355]
	TIME [epoch: 9.61 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022522227543631628		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.022522227543631628 | validation: 0.032257641064763726]
	TIME [epoch: 9.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926835353013711		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.03926835353013711 | validation: 0.03091465995355302]
	TIME [epoch: 9.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05094952314226818		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.05094952314226818 | validation: 0.02726602686940114]
	TIME [epoch: 9.61 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021400218110112487		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.021400218110112487 | validation: 0.0218870578162906]
	TIME [epoch: 9.65 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139141938953329		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.03139141938953329 | validation: 0.04109341511089813]
	TIME [epoch: 9.61 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026761365376359064		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.026761365376359064 | validation: 0.023035885400629365]
	TIME [epoch: 9.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026769935863557377		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.026769935863557377 | validation: 0.02741603036354137]
	TIME [epoch: 9.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940856173210469		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.03940856173210469 | validation: 0.02375907230073647]
	TIME [epoch: 9.66 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733662120832586		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.01733662120832586 | validation: 0.025704567373184356]
	TIME [epoch: 9.63 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030243355575661733		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.030243355575661733 | validation: 0.029436362659385373]
	TIME [epoch: 9.62 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026289748882962392		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.026289748882962392 | validation: 0.06191984508143568]
	TIME [epoch: 9.62 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573006575020861		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.03573006575020861 | validation: 0.0242074705497657]
	TIME [epoch: 9.63 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01714904369313381		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.01714904369313381 | validation: 0.02184621700460971]
	TIME [epoch: 9.67 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03205260664416587		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.03205260664416587 | validation: 0.042974013023922314]
	TIME [epoch: 9.62 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503484172958806		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.02503484172958806 | validation: 0.02888063185127058]
	TIME [epoch: 9.62 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02748975029796181		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.02748975029796181 | validation: 0.027661313133643967]
	TIME [epoch: 9.62 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024936279189927267		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.024936279189927267 | validation: 0.03692571031123136]
	TIME [epoch: 9.62 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033364562171232695		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.033364562171232695 | validation: 0.015590213586523316]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023457165091341093		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.023457165091341093 | validation: 0.01584229825147305]
	TIME [epoch: 9.62 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876827296609313		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.01876827296609313 | validation: 0.03833099550657809]
	TIME [epoch: 9.62 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02615550245084773		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.02615550245084773 | validation: 0.04477288384582742]
	TIME [epoch: 9.64 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838578153459167		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.03838578153459167 | validation: 0.015248173142595606]
	TIME [epoch: 9.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594230067940659		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.015594230067940659 | validation: 0.020284509896587925]
	TIME [epoch: 9.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308410807485249		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.02308410807485249 | validation: 0.04560162882787936]
	TIME [epoch: 9.96 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03446976230881628		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.03446976230881628 | validation: 0.03265714857044921]
	TIME [epoch: 9.64 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020608300128374585		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.020608300128374585 | validation: 0.027103311286086642]
	TIME [epoch: 9.67 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025100200597757		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.025100200597757 | validation: 0.033209878735474666]
	TIME [epoch: 9.63 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02859652362335608		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.02859652362335608 | validation: 0.01872580413285295]
	TIME [epoch: 9.63 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013117473398615642		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.013117473398615642 | validation: 0.018889698038001494]
	TIME [epoch: 9.61 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193692974533375		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.03193692974533375 | validation: 0.04286052121685133]
	TIME [epoch: 9.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022447613272700742		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.022447613272700742 | validation: 0.030265398865638025]
	TIME [epoch: 9.66 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031513765576503844		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.031513765576503844 | validation: 0.02174016592190762]
	TIME [epoch: 9.61 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020990673670096712		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.020990673670096712 | validation: 0.02895290793821485]
	TIME [epoch: 9.61 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017243980649258243		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.017243980649258243 | validation: 0.01636657375428986]
	TIME [epoch: 9.61 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019528304489768306		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.019528304489768306 | validation: 0.04832653789228149]
	TIME [epoch: 9.65 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424228578781388		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.03424228578781388 | validation: 0.03518190887676044]
	TIME [epoch: 9.63 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02597409514173885		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.02597409514173885 | validation: 0.023018090867306346]
	TIME [epoch: 9.61 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016060139899214794		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.016060139899214794 | validation: 0.02072722869781543]
	TIME [epoch: 9.61 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09731058563598238		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09731058563598238 | validation: 0.08128451540912845]
	TIME [epoch: 9.61 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640852128134617		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.06640852128134617 | validation: 0.03859065542104256]
	TIME [epoch: 9.66 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028498063888134126		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.028498063888134126 | validation: 0.025483580213349337]
	TIME [epoch: 9.61 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024908042703965398		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.024908042703965398 | validation: 0.01774265100835398]
	TIME [epoch: 9.61 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016348907612553844		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.016348907612553844 | validation: 0.024043905728456]
	TIME [epoch: 9.61 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02577260417469482		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.02577260417469482 | validation: 0.03983819037014204]
	TIME [epoch: 9.65 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022569082177306382		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.022569082177306382 | validation: 0.020653558598247065]
	TIME [epoch: 9.62 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020460699117864592		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.020460699117864592 | validation: 0.01965881625222291]
	TIME [epoch: 9.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013886418913033188		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.013886418913033188 | validation: 0.017022685655372082]
	TIME [epoch: 9.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0249373957805019		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.0249373957805019 | validation: 0.04438017858929687]
	TIME [epoch: 9.62 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021605242418447437		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.021605242418447437 | validation: 0.013806210965025167]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015812712288676013		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.015812712288676013 | validation: 0.027645738105384628]
	TIME [epoch: 9.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193028948546417		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.03193028948546417 | validation: 0.05019038442333115]
	TIME [epoch: 9.61 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020752783604287943		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.020752783604287943 | validation: 0.016101305104153304]
	TIME [epoch: 9.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014228310108815277		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.014228310108815277 | validation: 0.029280515074159123]
	TIME [epoch: 9.65 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277302280981838		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.03277302280981838 | validation: 0.023489168840639438]
	TIME [epoch: 9.61 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01346335724295484		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.01346335724295484 | validation: 0.015433504396713656]
	TIME [epoch: 9.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014781403526651157		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.014781403526651157 | validation: 0.0346835400326914]
	TIME [epoch: 9.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03615542371252075		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.03615542371252075 | validation: 0.017140064127749276]
	TIME [epoch: 9.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013588856409578066		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.013588856409578066 | validation: 0.012086847850326926]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014757886147245327		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.014757886147245327 | validation: 0.033214280812654554]
	TIME [epoch: 9.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026923663640538945		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.026923663640538945 | validation: 0.13120523915145055]
	TIME [epoch: 9.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069627728821091		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.06069627728821091 | validation: 0.026405097671882854]
	TIME [epoch: 9.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016052956407046532		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.016052956407046532 | validation: 0.013470120975654571]
	TIME [epoch: 9.61 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01112193943599626		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.01112193943599626 | validation: 0.012386026590381637]
	TIME [epoch: 9.65 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016047238602120074		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.016047238602120074 | validation: 0.046777607772048216]
	TIME [epoch: 9.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026778760011699976		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.026778760011699976 | validation: 0.012442971680734773]
	TIME [epoch: 9.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011627675162141398		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.011627675162141398 | validation: 0.017876666215886513]
	TIME [epoch: 9.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016105724314093024		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.016105724314093024 | validation: 0.031541357719599934]
	TIME [epoch: 9.64 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493096403591264		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.03493096403591264 | validation: 0.015304780521193218]
	TIME [epoch: 9.61 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01406861177039784		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.01406861177039784 | validation: 0.014445387919887163]
	TIME [epoch: 9.67 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019518354599411487		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.019518354599411487 | validation: 0.02168664341555679]
	TIME [epoch: 9.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018332323147329604		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.018332323147329604 | validation: 0.008651294783611797]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010275428296083326		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.010275428296083326 | validation: 0.01600067704004308]
	TIME [epoch: 9.64 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030799302230433416		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.030799302230433416 | validation: 0.014951087141969186]
	TIME [epoch: 9.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01627874527562055		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.01627874527562055 | validation: 0.012350527188661633]
	TIME [epoch: 9.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012742474212472104		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.012742474212472104 | validation: 0.016001827826591042]
	TIME [epoch: 9.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01804263876553212		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.01804263876553212 | validation: 0.016410818956033895]
	TIME [epoch: 9.63 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018297989280718383		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.018297989280718383 | validation: 0.028940809424555135]
	TIME [epoch: 9.61 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016109178221649263		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.016109178221649263 | validation: 0.015927283537455927]
	TIME [epoch: 9.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017216111910015215		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.017216111910015215 | validation: 0.03112841630812538]
	TIME [epoch: 9.59 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018254814809848346		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.018254814809848346 | validation: 0.015386294195166798]
	TIME [epoch: 9.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014936802154838552		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.014936802154838552 | validation: 0.026261387579790605]
	TIME [epoch: 9.65 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023553205821844364		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.023553205821844364 | validation: 0.020596435076848253]
	TIME [epoch: 9.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016424818569974374		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.016424818569974374 | validation: 0.013145774654772964]
	TIME [epoch: 9.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012505089901783242		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.012505089901783242 | validation: 0.049091158004731836]
	TIME [epoch: 9.59 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027978818960801136		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.027978818960801136 | validation: 0.018361855201098617]
	TIME [epoch: 9.63 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02744834973021125		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.02744834973021125 | validation: 0.037801037099581554]
	TIME [epoch: 9.61 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02786715112265077		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.02786715112265077 | validation: 0.028708546524257514]
	TIME [epoch: 9.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016501747916998315		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.016501747916998315 | validation: 0.011212514996035327]
	TIME [epoch: 9.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010333597929370447		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.010333597929370447 | validation: 0.015078066233012454]
	TIME [epoch: 9.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020057744984049202		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.020057744984049202 | validation: 0.016878544112753045]
	TIME [epoch: 9.65 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01316306323613117		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.01316306323613117 | validation: 0.013946450809595945]
	TIME [epoch: 9.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011043300863906091		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.011043300863906091 | validation: 0.011457472399044629]
	TIME [epoch: 9.59 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017453047676732086		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.017453047676732086 | validation: 0.050615137642035485]
	TIME [epoch: 9.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030823832943431453		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.030823832943431453 | validation: 0.016280791139989755]
	TIME [epoch: 9.62 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01062271523623966		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.01062271523623966 | validation: 0.010560794488548691]
	TIME [epoch: 9.63 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010224201885268399		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.010224201885268399 | validation: 0.018802943913737123]
	TIME [epoch: 9.62 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023272522029277258		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.023272522029277258 | validation: 0.024536486830914903]
	TIME [epoch: 9.62 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019693405849413835		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.019693405849413835 | validation: 0.02391586409173746]
	TIME [epoch: 9.62 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014273147858851427		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.014273147858851427 | validation: 0.012122655046391338]
	TIME [epoch: 9.66 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010842104195331463		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.010842104195331463 | validation: 0.020362208951917742]
	TIME [epoch: 9.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374219037193184		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.02374219037193184 | validation: 0.014322378572181849]
	TIME [epoch: 9.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015504254126969274		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.015504254126969274 | validation: 0.011407789912974963]
	TIME [epoch: 9.62 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01017952995497979		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.01017952995497979 | validation: 0.015043505622258285]
	TIME [epoch: 9.66 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012549448278784438		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.012549448278784438 | validation: 0.018559582493500214]
	TIME [epoch: 9.62 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018429279436358928		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.018429279436358928 | validation: 0.01210915030794645]
	TIME [epoch: 9.61 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015032005198958785		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.015032005198958785 | validation: 0.010696619301684711]
	TIME [epoch: 9.61 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01582402236218701		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.01582402236218701 | validation: 0.03454964607149964]
	TIME [epoch: 9.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016734946089886082		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.016734946089886082 | validation: 0.012606955666715774]
	TIME [epoch: 9.64 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009946382314123432		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.009946382314123432 | validation: 0.007660686837392051]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00992324227455787		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.00992324227455787 | validation: 0.024326034811061215]
	TIME [epoch: 9.59 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026098315543823483		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.026098315543823483 | validation: 0.011831136512331739]
	TIME [epoch: 9.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00894992133319682		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.00894992133319682 | validation: 0.014216808290185273]
	TIME [epoch: 9.64 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016148352063655363		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.016148352063655363 | validation: 0.022319792930149733]
	TIME [epoch: 9.61 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015221304635762852		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.015221304635762852 | validation: 0.010958656150503407]
	TIME [epoch: 9.59 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009126417994841474		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.009126417994841474 | validation: 0.01587453145085245]
	TIME [epoch: 9.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012717703664608976		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.012717703664608976 | validation: 0.011311164617472062]
	TIME [epoch: 9.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017991513640910294		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.017991513640910294 | validation: 0.032473453745049376]
	TIME [epoch: 9.65 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0167417441126242		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.0167417441126242 | validation: 0.012683880123913058]
	TIME [epoch: 9.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014508820025965638		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.014508820025965638 | validation: 0.013005398997111884]
	TIME [epoch: 9.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010939328650915176		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.010939328650915176 | validation: 0.018991166337949172]
	TIME [epoch: 9.59 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01524047679160505		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.01524047679160505 | validation: 0.01725512179427039]
	TIME [epoch: 9.62 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012467204281654704		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.012467204281654704 | validation: 0.017589848548140566]
	TIME [epoch: 9.63 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014496841390711768		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.014496841390711768 | validation: 0.021384813862784895]
	TIME [epoch: 9.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012028937393173008		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.012028937393173008 | validation: 0.012818455457782945]
	TIME [epoch: 9.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009211570575581952		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.009211570575581952 | validation: 0.018993386525951044]
	TIME [epoch: 9.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02054629569873562		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.02054629569873562 | validation: 0.011243066945791778]
	TIME [epoch: 9.65 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00869039499012037		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.00869039499012037 | validation: 0.007758723358840998]
	TIME [epoch: 9.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021474299467761703		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.021474299467761703 | validation: 0.010340172470186211]
	TIME [epoch: 9.59 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012002848535058189		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.012002848535058189 | validation: 0.010216052242802656]
	TIME [epoch: 9.59 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009677086703323089		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.009677086703323089 | validation: 0.016173677780557335]
	TIME [epoch: 9.64 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013535434488026623		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.013535434488026623 | validation: 0.02672573148012175]
	TIME [epoch: 9.61 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464200112442078		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.01464200112442078 | validation: 0.008861689085687074]
	TIME [epoch: 9.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008679963862411776		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.008679963862411776 | validation: 0.012766920058690092]
	TIME [epoch: 9.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016860339211681095		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.016860339211681095 | validation: 0.03389663768705495]
	TIME [epoch: 9.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016619961265370516		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.016619961265370516 | validation: 0.012919231203179036]
	TIME [epoch: 9.64 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009663992858157795		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.009663992858157795 | validation: 0.007591495623954328]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01169782826989092		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.01169782826989092 | validation: 0.013654011200523127]
	TIME [epoch: 9.62 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01595697540633339		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.01595697540633339 | validation: 0.01020486195661029]
	TIME [epoch: 9.62 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008979487387723592		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.008979487387723592 | validation: 0.00865782171100638]
	TIME [epoch: 9.66 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013275361930795555		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.013275361930795555 | validation: 0.010623051392276626]
	TIME [epoch: 9.64 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007665995849505206		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.007665995849505206 | validation: 0.01119634818336941]
	TIME [epoch: 9.59 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022795976436943997		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.022795976436943997 | validation: 0.009005814626989739]
	TIME [epoch: 9.59 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010927618801726527		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.010927618801726527 | validation: 0.009863398385299729]
	TIME [epoch: 9.61 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008592628936961956		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.008592628936961956 | validation: 0.012531509403650196]
	TIME [epoch: 9.66 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00982219281413781		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.00982219281413781 | validation: 0.009954218790210452]
	TIME [epoch: 9.62 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016799039187053465		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.016799039187053465 | validation: 0.019932216803391006]
	TIME [epoch: 9.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01775418902445218		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.01775418902445218 | validation: 0.009404964255188034]
	TIME [epoch: 9.61 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007931471148925727		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.007931471148925727 | validation: 0.009753887429478005]
	TIME [epoch: 9.63 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011651789381841117		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.011651789381841117 | validation: 0.01584813394701831]
	TIME [epoch: 9.64 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014078081832881771		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.014078081832881771 | validation: 0.013183932947155974]
	TIME [epoch: 9.61 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010323601573406772		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.010323601573406772 | validation: 0.008950642060495274]
	TIME [epoch: 9.61 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012606026980528831		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.012606026980528831 | validation: 0.01757249806402622]
	TIME [epoch: 9.61 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01159324242996509		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.01159324242996509 | validation: 0.012187456040379352]
	TIME [epoch: 9.67 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013309291427687492		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.013309291427687492 | validation: 0.017539671189137913]
	TIME [epoch: 9.61 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01023471465036849		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.01023471465036849 | validation: 0.018306849703185375]
	TIME [epoch: 9.62 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01425793451435622		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.01425793451435622 | validation: 0.011834470497901806]
	TIME [epoch: 9.61 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009698895352868919		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.009698895352868919 | validation: 0.010933302901918414]
	TIME [epoch: 9.65 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010755951642442835		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.010755951642442835 | validation: 0.010324283696998936]
	TIME [epoch: 9.62 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009164891767871533		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.009164891767871533 | validation: 0.017521841746554415]
	TIME [epoch: 9.61 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014950304888447064		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.014950304888447064 | validation: 0.007338280411171752]
	TIME [epoch: 9.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008032816550244615		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.008032816550244615 | validation: 0.0120434534649643]
	TIME [epoch: 9.61 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014913027775359054		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.014913027775359054 | validation: 0.014179648236971567]
	TIME [epoch: 9.65 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012116539472881556		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.012116539472881556 | validation: 0.010219951329489082]
	TIME [epoch: 9.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007870253425175241		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.007870253425175241 | validation: 0.00814995856381907]
	TIME [epoch: 9.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014229575340706443		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.014229575340706443 | validation: 0.018983713264235046]
	TIME [epoch: 9.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013816615281151788		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.013816615281151788 | validation: 0.014700191238866806]
	TIME [epoch: 9.61 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008595694728007882		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.008595694728007882 | validation: 0.008170137065602143]
	TIME [epoch: 9.64 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010344838694499228		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.010344838694499228 | validation: 0.012719467570787955]
	TIME [epoch: 9.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008801979836026813		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.008801979836026813 | validation: 0.011305649141994431]
	TIME [epoch: 9.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014586083596869602		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.014586083596869602 | validation: 0.01544152481483455]
	TIME [epoch: 9.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00961272220944818		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.00961272220944818 | validation: 0.006544644264660079]
	TIME [epoch: 9.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006378207744879183		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.006378207744879183 | validation: 0.01309355171279011]
	TIME [epoch: 9.64 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018693316534581006		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.018693316534581006 | validation: 0.015749101142222846]
	TIME [epoch: 9.63 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009318301015122958		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.009318301015122958 | validation: 0.008200237302749925]
	TIME [epoch: 9.63 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00900962711483369		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.00900962711483369 | validation: 0.019115067016525704]
	TIME [epoch: 9.63 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01098089930706288		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.01098089930706288 | validation: 0.008712410092905748]
	TIME [epoch: 9.68 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006457825717622527		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.006457825717622527 | validation: 0.007816697605534446]
	TIME [epoch: 9.63 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011837106746774293		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.011837106746774293 | validation: 0.012736083802062825]
	TIME [epoch: 9.63 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01051299577739312		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.01051299577739312 | validation: 0.015221497540705379]
	TIME [epoch: 9.63 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009170348905737378		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.009170348905737378 | validation: 0.009662451139727723]
	TIME [epoch: 9.67 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00875683570238731		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.00875683570238731 | validation: 0.03156889790796465]
	TIME [epoch: 9.63 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01563286403482212		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.01563286403482212 | validation: 0.00842206009507172]
	TIME [epoch: 9.62 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00735504110635459		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.00735504110635459 | validation: 0.007066726408245608]
	TIME [epoch: 10.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006691158341578882		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.006691158341578882 | validation: 0.012618151269460186]
	TIME [epoch: 9.63 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017871308199892456		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.017871308199892456 | validation: 0.009546287687131767]
	TIME [epoch: 9.67 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008666506184124609		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.008666506184124609 | validation: 0.00867112203229933]
	TIME [epoch: 9.62 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007429790352961561		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.007429790352961561 | validation: 0.006087840172203578]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039760689035823644		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.039760689035823644 | validation: 0.04575523122716524]
	TIME [epoch: 9.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033650610549673034		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.033650610549673034 | validation: 0.015565065210194361]
	TIME [epoch: 9.64 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012972678890333007		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.012972678890333007 | validation: 0.0075741270295751825]
	TIME [epoch: 9.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00684069257685163		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.00684069257685163 | validation: 0.007500407266162867]
	TIME [epoch: 9.59 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063503148422570785		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.0063503148422570785 | validation: 0.008871588158420079]
	TIME [epoch: 9.59 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009958903129514207		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.009958903129514207 | validation: 0.0175012703117983]
	TIME [epoch: 9.59 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010083200228004347		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.010083200228004347 | validation: 0.0068834535510975655]
	TIME [epoch: 9.64 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00822219074920251		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.00822219074920251 | validation: 0.008440138470385439]
	TIME [epoch: 9.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00745840419022006		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.00745840419022006 | validation: 0.008111985991082035]
	TIME [epoch: 9.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010529188224469521		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.010529188224469521 | validation: 0.009364043861742093]
	TIME [epoch: 9.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008394350882691961		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.008394350882691961 | validation: 0.00820047309714872]
	TIME [epoch: 9.63 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008228201486723733		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.008228201486723733 | validation: 0.011965622203875731]
	TIME [epoch: 9.61 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00804820612064091		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.00804820612064091 | validation: 0.010155005996008156]
	TIME [epoch: 9.61 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011195161603484096		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.011195161603484096 | validation: 0.006947065403492934]
	TIME [epoch: 9.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007777596903904297		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.007777596903904297 | validation: 0.01725022411886376]
	TIME [epoch: 9.62 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010338277835667766		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.010338277835667766 | validation: 0.006077203298592949]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00766082373032133		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.00766082373032133 | validation: 0.01639511724382557]
	TIME [epoch: 9.61 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011130302648899434		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.011130302648899434 | validation: 0.008986717544744588]
	TIME [epoch: 9.61 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009162129633803886		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.009162129633803886 | validation: 0.012040839340596615]
	TIME [epoch: 9.62 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008381201690679192		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.008381201690679192 | validation: 0.006671846246738086]
	TIME [epoch: 9.65 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007041839898040602		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.007041839898040602 | validation: 0.014400380542080203]
	TIME [epoch: 9.63 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011279999284319294		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.011279999284319294 | validation: 0.00812066520083232]
	TIME [epoch: 9.61 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058333430257555795		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.0058333430257555795 | validation: 0.0094219699890775]
	TIME [epoch: 9.61 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013970999804776596		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.013970999804776596 | validation: 0.009049268175176364]
	TIME [epoch: 9.61 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007489059513256507		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.007489059513256507 | validation: 0.007160118716208629]
	TIME [epoch: 9.65 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00769738329032627		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.00769738329032627 | validation: 0.012237543642890144]
	TIME [epoch: 9.63 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009097036083158528		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.009097036083158528 | validation: 0.006401192275022631]
	TIME [epoch: 9.61 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005927370097988545		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.005927370097988545 | validation: 0.010201141083062344]
	TIME [epoch: 9.61 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008237727457241455		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.008237727457241455 | validation: 0.008971408405184438]
	TIME [epoch: 9.61 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01439743815198656		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.01439743815198656 | validation: 0.007168812309788559]
	TIME [epoch: 9.66 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006689070127041471		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.006689070127041471 | validation: 0.007683403735098076]
	TIME [epoch: 9.61 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00967398272289232		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.00967398272289232 | validation: 0.007076347728805263]
	TIME [epoch: 9.61 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071958653211802275		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.0071958653211802275 | validation: 0.007194670762324113]
	TIME [epoch: 9.61 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00829258151807891		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.00829258151807891 | validation: 0.015615386407795875]
	TIME [epoch: 9.66 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009916011899629701		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.009916011899629701 | validation: 0.008125944548750742]
	TIME [epoch: 9.62 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00709917593865406		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.00709917593865406 | validation: 0.007069025626402251]
	TIME [epoch: 9.61 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006862436931254964		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.006862436931254964 | validation: 0.014108217010934716]
	TIME [epoch: 9.61 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009167759213046103		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.009167759213046103 | validation: 0.009835293281225647]
	TIME [epoch: 9.63 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006226782504775701		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.006226782504775701 | validation: 0.008419001524744407]
	TIME [epoch: 9.65 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011589461502774612		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.011589461502774612 | validation: 0.007748277392614604]
	TIME [epoch: 9.61 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006012433475938145		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.006012433475938145 | validation: 0.007078238997112912]
	TIME [epoch: 9.61 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007868062360714616		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.007868062360714616 | validation: 0.009934288449843533]
	TIME [epoch: 9.61 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010673076639789064		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.010673076639789064 | validation: 0.012355193654170281]
	TIME [epoch: 9.66 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006783283759010051		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.006783283759010051 | validation: 0.008421855441565717]
	TIME [epoch: 9.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015231320256257124		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.015231320256257124 | validation: 0.02064038806254166]
	TIME [epoch: 9.61 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014151086185797202		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.014151086185797202 | validation: 0.010012591460069735]
	TIME [epoch: 9.62 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006445935386052314		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.006445935386052314 | validation: 0.005843624102999923]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005374354100125952		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.005374354100125952 | validation: 0.007515416591310619]
	TIME [epoch: 9.63 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008458372343324406		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.008458372343324406 | validation: 0.0065964806105681]
	TIME [epoch: 9.59 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005684960623376991		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.005684960623376991 | validation: 0.010086486754647536]
	TIME [epoch: 9.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007322477075996705		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.007322477075996705 | validation: 0.009224383983546466]
	TIME [epoch: 9.59 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00902912905559685		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.00902912905559685 | validation: 0.0060689913279796505]
	TIME [epoch: 9.64 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005300291773956306		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.005300291773956306 | validation: 0.010574014559143684]
	TIME [epoch: 9.61 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00832746450119223		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.00832746450119223 | validation: 0.014331828320954358]
	TIME [epoch: 9.59 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00836439079233815		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.00836439079233815 | validation: 0.0063989162378566035]
	TIME [epoch: 9.59 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008468443793593856		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.008468443793593856 | validation: 0.0068286842258821565]
	TIME [epoch: 9.62 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00554483159770018		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.00554483159770018 | validation: 0.007136600818044749]
	TIME [epoch: 9.65 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009508522743587124		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.009508522743587124 | validation: 0.009187323016249832]
	TIME [epoch: 9.61 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006391853065017399		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.006391853065017399 | validation: 0.008512730311177547]
	TIME [epoch: 9.59 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005495057199447569		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.005495057199447569 | validation: 0.008327012323857571]
	TIME [epoch: 9.59 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008190082486239455		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.008190082486239455 | validation: 0.006894808479090686]
	TIME [epoch: 9.64 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007841057214305464		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.007841057214305464 | validation: 0.014657661871065066]
	TIME [epoch: 9.62 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007925913940932066		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.007925913940932066 | validation: 0.0069520664318936335]
	TIME [epoch: 9.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006400281203362521		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.006400281203362521 | validation: 0.007811609429501878]
	TIME [epoch: 9.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006607531237753483		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.006607531237753483 | validation: 0.008026307102662191]
	TIME [epoch: 9.62 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008946736911498642		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.008946736911498642 | validation: 0.008927817171555863]
	TIME [epoch: 9.65 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068093535020476575		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0068093535020476575 | validation: 0.013418536656553001]
	TIME [epoch: 9.61 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007322788034245957		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.007322788034245957 | validation: 0.006838428602875823]
	TIME [epoch: 9.59 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052428934737817085		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.0052428934737817085 | validation: 0.00738724394723503]
	TIME [epoch: 9.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011373361862940922		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.011373361862940922 | validation: 0.00930357693540434]
	TIME [epoch: 9.66 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006534760824654716		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.006534760824654716 | validation: 0.007812713224765639]
	TIME [epoch: 9.61 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055342250478652		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.0055342250478652 | validation: 0.006650160255586324]
	TIME [epoch: 9.58 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006153556709487846		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.006153556709487846 | validation: 0.009012696451713216]
	TIME [epoch: 9.59 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008991562581739785		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.008991562581739785 | validation: 0.006290690141779997]
	TIME [epoch: 9.65 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005711824375509261		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.005711824375509261 | validation: 0.007199600342367185]
	TIME [epoch: 9.62 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007383479986526954		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.007383479986526954 | validation: 0.009883155606684221]
	TIME [epoch: 9.59 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005956480747250903		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.005956480747250903 | validation: 0.0055010377330354]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006193164220223742		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.006193164220223742 | validation: 0.00745125280867631]
	TIME [epoch: 9.63 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008233441114442932		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.008233441114442932 | validation: 0.009604278835247438]
	TIME [epoch: 9.67 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005437143221625261		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.005437143221625261 | validation: 0.005664621075854241]
	TIME [epoch: 9.62 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077967785681026715		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.0077967785681026715 | validation: 0.014536913026320788]
	TIME [epoch: 9.62 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007704399026735295		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.007704399026735295 | validation: 0.005168454978008434]
	TIME [epoch: 9.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005232965508145103		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.005232965508145103 | validation: 0.006925305955993862]
	TIME [epoch: 9.63 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007238506548719818		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.007238506548719818 | validation: 0.011316354171073392]
	TIME [epoch: 9.66 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007820364503155425		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.007820364503155425 | validation: 0.005471165895900525]
	TIME [epoch: 9.62 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004939269477769602		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.004939269477769602 | validation: 0.006929236058451677]
	TIME [epoch: 9.63 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007716712631867581		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.007716712631867581 | validation: 0.008677685590189643]
	TIME [epoch: 9.62 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007288200533930065		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.007288200533930065 | validation: 0.0064371699264219855]
	TIME [epoch: 9.66 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075617462983206245		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0075617462983206245 | validation: 0.006686532381236023]
	TIME [epoch: 9.63 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004630672139544654		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.004630672139544654 | validation: 0.006374691752045648]
	TIME [epoch: 9.61 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006333553152207916		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.006333553152207916 | validation: 0.009493060109459502]
	TIME [epoch: 9.62 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007095756015813688		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.007095756015813688 | validation: 0.007395917579582342]
	TIME [epoch: 9.63 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006269094800106868		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.006269094800106868 | validation: 0.00723922647631336]
	TIME [epoch: 9.67 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006276546731724077		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.006276546731724077 | validation: 0.005770169317093319]
	TIME [epoch: 9.61 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00609027582501219		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.00609027582501219 | validation: 0.009447147575299538]
	TIME [epoch: 9.69 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007609497661552046		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.007609497661552046 | validation: 0.005780647975269932]
	TIME [epoch: 9.62 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005814204758598821		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.005814204758598821 | validation: 0.0076571727250121634]
	TIME [epoch: 9.67 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00714661765823955		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.00714661765823955 | validation: 0.0085303214868333]
	TIME [epoch: 9.63 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005676744566295607		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.005676744566295607 | validation: 0.007902507507750919]
	TIME [epoch: 9.62 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008762654114708947		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.008762654114708947 | validation: 0.0066015547459969985]
	TIME [epoch: 9.62 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006669509338523414		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.006669509338523414 | validation: 0.008688434215005241]
	TIME [epoch: 9.63 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005569860316589483		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.005569860316589483 | validation: 0.006327790659403834]
	TIME [epoch: 9.67 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00774874225518435		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.00774874225518435 | validation: 0.005421016131299019]
	TIME [epoch: 9.62 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005227997814779634		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.005227997814779634 | validation: 0.006247172651184489]
	TIME [epoch: 9.62 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005665235489183303		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.005665235489183303 | validation: 0.012093014944138142]
	TIME [epoch: 9.62 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007423103181414023		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.007423103181414023 | validation: 0.005919447554903188]
	TIME [epoch: 9.67 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005198042276489515		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.005198042276489515 | validation: 0.005712509471490171]
	TIME [epoch: 9.63 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005329047690988029		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.005329047690988029 | validation: 0.006417820506807148]
	TIME [epoch: 9.62 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063777413448336765		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.0063777413448336765 | validation: 0.015313027078143873]
	TIME [epoch: 9.62 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009507732451813663		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.009507732451813663 | validation: 0.010775875977003047]
	TIME [epoch: 9.64 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061226868387431604		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0061226868387431604 | validation: 0.004776338464341312]
	TIME [epoch: 9.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005160003007903621		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.005160003007903621 | validation: 0.006367774613077531]
	TIME [epoch: 9.61 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005713384676504178		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.005713384676504178 | validation: 0.00477944521233734]
	TIME [epoch: 9.61 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007538983520871223		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.007538983520871223 | validation: 0.0077357023688541604]
	TIME [epoch: 9.62 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005916800193994173		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.005916800193994173 | validation: 0.005372159143734193]
	TIME [epoch: 9.66 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005676398084781366		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.005676398084781366 | validation: 0.008441290010528549]
	TIME [epoch: 9.62 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006659510667731234		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.006659510667731234 | validation: 0.007621365674916206]
	TIME [epoch: 9.61 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006337784193937186		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.006337784193937186 | validation: 0.006040178242478848]
	TIME [epoch: 9.61 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00563346546575038		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.00563346546575038 | validation: 0.005154131025945191]
	TIME [epoch: 9.62 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004356349853380244		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.004356349853380244 | validation: 0.0050718340202839]
	TIME [epoch: 9.66 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005200544995311218		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.005200544995311218 | validation: 0.015697951122355516]
	TIME [epoch: 9.62 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075501788978422045		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0075501788978422045 | validation: 0.006608811724583101]
	TIME [epoch: 9.61 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058169082528114905		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.0058169082528114905 | validation: 0.006936107261305907]
	TIME [epoch: 9.61 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005475459833558641		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.005475459833558641 | validation: 0.005466104977844222]
	TIME [epoch: 9.66 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004971496925486095		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.004971496925486095 | validation: 0.005677984198762682]
	TIME [epoch: 9.62 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005744827895559911		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.005744827895559911 | validation: 0.0069240703690859]
	TIME [epoch: 9.61 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005841879434074033		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.005841879434074033 | validation: 0.008380854330805125]
	TIME [epoch: 9.58 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053928765988382945		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.0053928765988382945 | validation: 0.006540461802308892]
	TIME [epoch: 9.67 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00485671240990109		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.00485671240990109 | validation: 0.00963967818927142]
	TIME [epoch: 9.66 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008483858856467035		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.008483858856467035 | validation: 0.006537351333662456]
	TIME [epoch: 9.64 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004923850455487325		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.004923850455487325 | validation: 0.005025223433265271]
	TIME [epoch: 9.62 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004506682047704333		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.004506682047704333 | validation: 0.0052091076726939155]
	TIME [epoch: 9.62 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060161747184374025		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.0060161747184374025 | validation: 0.008443701371670921]
	TIME [epoch: 9.67 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052663545885549695		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.0052663545885549695 | validation: 0.007525951784222032]
	TIME [epoch: 9.63 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005580124473931219		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.005580124473931219 | validation: 0.0065490119265939496]
	TIME [epoch: 9.62 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004973677158514182		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.004973677158514182 | validation: 0.004847457001963167]
	TIME [epoch: 9.62 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004966002708128863		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.004966002708128863 | validation: 0.007839996625969098]
	TIME [epoch: 9.66 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006316099972085046		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.006316099972085046 | validation: 0.004457311274104939]
	TIME [epoch: 9.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061425877020493905		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.0061425877020493905 | validation: 0.005741796232012002]
	TIME [epoch: 9.61 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004414792151202811		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.004414792151202811 | validation: 0.005541430020394969]
	TIME [epoch: 9.61 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005396340193319811		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.005396340193319811 | validation: 0.006090975097108681]
	TIME [epoch: 9.62 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005832357604894533		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.005832357604894533 | validation: 0.005606402970657215]
	TIME [epoch: 9.65 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004765731318840729		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.004765731318840729 | validation: 0.006013213919849108]
	TIME [epoch: 9.61 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004778093370262778		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.004778093370262778 | validation: 0.005110107637428579]
	TIME [epoch: 9.61 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005683015747599784		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.005683015747599784 | validation: 0.006709521943883068]
	TIME [epoch: 9.61 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005516773027148399		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.005516773027148399 | validation: 0.005480241617698505]
	TIME [epoch: 9.62 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042628798644959		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0042628798644959 | validation: 0.004210305002523215]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005523302816158157		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.005523302816158157 | validation: 0.011681045306584113]
	TIME [epoch: 9.61 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006827281740875734		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.006827281740875734 | validation: 0.006027619386643108]
	TIME [epoch: 9.61 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005331766473961838		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.005331766473961838 | validation: 0.005572132326480537]
	TIME [epoch: 9.61 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004930703384367445		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.004930703384367445 | validation: 0.005076887627393532]
	TIME [epoch: 9.67 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005270527067134475		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.005270527067134475 | validation: 0.005490438308898473]
	TIME [epoch: 9.61 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004401591635110929		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.004401591635110929 | validation: 0.004986627963662319]
	TIME [epoch: 9.61 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007623684742121694		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.007623684742121694 | validation: 0.006415142882299634]
	TIME [epoch: 9.61 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004487847205017341		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.004487847205017341 | validation: 0.004428306835169947]
	TIME [epoch: 9.62 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005110065419161239		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.005110065419161239 | validation: 0.00401217182689466]
	TIME [epoch: 9.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004380167479492663		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.004380167479492663 | validation: 0.007518109213835769]
	TIME [epoch: 9.61 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005486361291458116		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.005486361291458116 | validation: 0.004546482826325356]
	TIME [epoch: 9.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037225440288509142		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.0037225440288509142 | validation: 0.005659306154535433]
	TIME [epoch: 9.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048129415203433945		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0048129415203433945 | validation: 0.008079075653126485]
	TIME [epoch: 9.65 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006119152089735114		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.006119152089735114 | validation: 0.004893075450121886]
	TIME [epoch: 9.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004577488114877343		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.004577488114877343 | validation: 0.0045279559590561385]
	TIME [epoch: 9.61 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004502551064356581		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.004502551064356581 | validation: 0.003906378363380396]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004044268170443795		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.004044268170443795 | validation: 0.0061616220360440265]
	TIME [epoch: 9.61 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006434147110605575		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.006434147110605575 | validation: 0.005561929885812113]
	TIME [epoch: 9.66 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004290323624277129		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.004290323624277129 | validation: 0.005068761884368398]
	TIME [epoch: 9.61 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00463067228605665		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.00463067228605665 | validation: 0.005440036900665454]
	TIME [epoch: 9.61 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004348689817739864		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.004348689817739864 | validation: 0.0061672042370028435]
	TIME [epoch: 9.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006250605454542689		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.006250605454542689 | validation: 0.005950395714128328]
	TIME [epoch: 9.61 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005672328062156902		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.005672328062156902 | validation: 0.005238634788392479]
	TIME [epoch: 9.65 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00426358098585971		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.00426358098585971 | validation: 0.007619152816395278]
	TIME [epoch: 9.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061065537718079125		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0061065537718079125 | validation: 0.005236682046930877]
	TIME [epoch: 9.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038960463620376735		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.0038960463620376735 | validation: 0.0053600334162671945]
	TIME [epoch: 9.61 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004230611311968905		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.004230611311968905 | validation: 0.004951380416000016]
	TIME [epoch: 9.65 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004585620742295648		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.004585620742295648 | validation: 0.005564312810153073]
	TIME [epoch: 9.61 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006291631464168137		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.006291631464168137 | validation: 0.004505183791158846]
	TIME [epoch: 9.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00488383781372741		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.00488383781372741 | validation: 0.004191729846350391]
	TIME [epoch: 9.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0040667806345181315		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.0040667806345181315 | validation: 0.0049355080920890256]
	TIME [epoch: 9.61 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050778756333580664		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.0050778756333580664 | validation: 0.004393563781834004]
	TIME [epoch: 9.65 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042385611372241835		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.0042385611372241835 | validation: 0.004587641999595447]
	TIME [epoch: 9.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004416866699259194		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.004416866699259194 | validation: 0.00549938073270256]
	TIME [epoch: 9.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005062806118400361		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.005062806118400361 | validation: 0.004512352119279579]
	TIME [epoch: 9.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004451726364508041		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.004451726364508041 | validation: 0.004202838678373444]
	TIME [epoch: 9.65 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050237553765896115		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.0050237553765896115 | validation: 0.007583114349894319]
	TIME [epoch: 9.61 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005621139049221296		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.005621139049221296 | validation: 0.0050500468881346915]
	TIME [epoch: 9.61 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039743093886748255		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.0039743093886748255 | validation: 0.0037347793965324264]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004120719341423555		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.004120719341423555 | validation: 0.004136997428012725]
	TIME [epoch: 9.64 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005290058786467319		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.005290058786467319 | validation: 0.00446879276461992]
	TIME [epoch: 9.62 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004295019655763212		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.004295019655763212 | validation: 0.004234776277704022]
	TIME [epoch: 9.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004158630432677452		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.004158630432677452 | validation: 0.006669194811162267]
	TIME [epoch: 9.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005188650855417825		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.005188650855417825 | validation: 0.0046136889990542]
	TIME [epoch: 9.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036221392487638493		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.0036221392487638493 | validation: 0.00395989894607213]
	TIME [epoch: 9.64 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005013321397887738		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.005013321397887738 | validation: 0.008461487519336456]
	TIME [epoch: 9.62 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004752097965699147		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.004752097965699147 | validation: 0.004474907316428815]
	TIME [epoch: 9.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004053567040000862		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.004053567040000862 | validation: 0.006306465273308517]
	TIME [epoch: 9.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003989325993129494		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.003989325993129494 | validation: 0.00415645438206871]
	TIME [epoch: 9.61 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055255649047925605		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.0055255649047925605 | validation: 0.012506270519485288]
	TIME [epoch: 9.65 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00799589427410582		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.00799589427410582 | validation: 0.004887344141923959]
	TIME [epoch: 9.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003797416563554228		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.003797416563554228 | validation: 0.003916095717227666]
	TIME [epoch: 9.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037396324394025297		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0037396324394025297 | validation: 0.0033295759009281034]
	TIME [epoch: 9.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00399813029917408		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.00399813029917408 | validation: 0.004721826311745937]
	TIME [epoch: 9.65 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003636998123072354		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.003636998123072354 | validation: 0.005041336026744134]
	TIME [epoch: 9.61 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00546037490661099		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.00546037490661099 | validation: 0.003919293689415405]
	TIME [epoch: 9.59 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00392929252452525		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.00392929252452525 | validation: 0.00406866989509704]
	TIME [epoch: 9.59 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004019798946237873		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.004019798946237873 | validation: 0.004775777969824637]
	TIME [epoch: 9.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039412174675633495		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0039412174675633495 | validation: 0.005568684966495385]
	TIME [epoch: 9.66 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004150010852114488		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.004150010852114488 | validation: 0.005803183144196696]
	TIME [epoch: 9.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00482208691917401		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.00482208691917401 | validation: 0.0049914106233315885]
	TIME [epoch: 9.59 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004300697101323687		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.004300697101323687 | validation: 0.004688642216711689]
	TIME [epoch: 9.59 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004969929145011003		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.004969929145011003 | validation: 0.004690711697302705]
	TIME [epoch: 9.64 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003528223985629719		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.003528223985629719 | validation: 0.0041373509230896565]
	TIME [epoch: 9.62 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005069976841337278		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.005069976841337278 | validation: 0.007081459263732157]
	TIME [epoch: 9.59 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004803253009351645		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.004803253009351645 | validation: 0.004412026510111132]
	TIME [epoch: 9.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004069120761868479		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.004069120761868479 | validation: 0.0037423372398948072]
	TIME [epoch: 9.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034897519434853473		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0034897519434853473 | validation: 0.004546203319634652]
	TIME [epoch: 9.67 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005439886553734311		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.005439886553734311 | validation: 0.004608987862459916]
	TIME [epoch: 9.59 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003908626981637775		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.003908626981637775 | validation: 0.005197775341697507]
	TIME [epoch: 9.61 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003531253733469694		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.003531253733469694 | validation: 0.005270700534689322]
	TIME [epoch: 9.61 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005097996222219518		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.005097996222219518 | validation: 0.0031454076173855197]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003469720528289677		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.003469720528289677 | validation: 0.0030732017726372487]
	TIME [epoch: 9.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030570130817095227		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.0030570130817095227 | validation: 0.005290495495687333]
	TIME [epoch: 9.61 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004854827055840127		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.004854827055840127 | validation: 0.007104955831771914]
	TIME [epoch: 9.61 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004346692753751523		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.004346692753751523 | validation: 0.004308316666632018]
	TIME [epoch: 9.61 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036234147215676283		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0036234147215676283 | validation: 0.0034669080950754105]
	TIME [epoch: 9.65 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037763960366006192		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0037763960366006192 | validation: 0.0033540259002573175]
	TIME [epoch: 9.62 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004868992046991059		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.004868992046991059 | validation: 0.004195201865642656]
	TIME [epoch: 9.61 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0040547079187144616		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0040547079187144616 | validation: 0.0043662603406747795]
	TIME [epoch: 9.61 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036488926321151197		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0036488926321151197 | validation: 0.005805304456632687]
	TIME [epoch: 9.61 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003791608006401222		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.003791608006401222 | validation: 0.00458276476022072]
	TIME [epoch: 9.65 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038590627505617064		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.0038590627505617064 | validation: 0.003917665809873943]
	TIME [epoch: 9.61 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004381258222475693		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.004381258222475693 | validation: 0.004869467122946039]
	TIME [epoch: 9.61 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00366622129314753		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.00366622129314753 | validation: 0.004361455580837293]
	TIME [epoch: 9.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003718847084686284		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.003718847084686284 | validation: 0.006978440332196676]
	TIME [epoch: 9.63 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004769742767063973		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.004769742767063973 | validation: 0.0031057257659724107]
	TIME [epoch: 9.64 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003488205000575674		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.003488205000575674 | validation: 0.004542771624033519]
	TIME [epoch: 9.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035467995990943312		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0035467995990943312 | validation: 0.004329474290489948]
	TIME [epoch: 9.61 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004413330735359303		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.004413330735359303 | validation: 0.0037023330682793504]
	TIME [epoch: 9.61 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034249688018605845		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.0034249688018605845 | validation: 0.004127191468791224]
	TIME [epoch: 9.66 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003771888533065684		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.003771888533065684 | validation: 0.006635789382428713]
	TIME [epoch: 9.61 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004219242702471333		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.004219242702471333 | validation: 0.0037139330707003223]
	TIME [epoch: 9.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00379499906947311		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.00379499906947311 | validation: 0.003927675377684228]
	TIME [epoch: 9.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004239692557007848		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.004239692557007848 | validation: 0.004358734482314318]
	TIME [epoch: 9.65 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003927219092105645		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.003927219092105645 | validation: 0.004993234155503547]
	TIME [epoch: 9.62 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038961606687239842		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0038961606687239842 | validation: 0.004129339720863089]
	TIME [epoch: 9.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004660400818905168		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.004660400818905168 | validation: 0.0034682767333289463]
	TIME [epoch: 9.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002985822890656536		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.002985822890656536 | validation: 0.0032052313960335968]
	TIME [epoch: 9.61 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037542370238865543		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.0037542370238865543 | validation: 0.005538681967269112]
	TIME [epoch: 9.65 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003988543105152623		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.003988543105152623 | validation: 0.003276381879130155]
	TIME [epoch: 9.61 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032907764278544633		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.0032907764278544633 | validation: 0.004670050814433801]
	TIME [epoch: 9.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004120786422028903		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.004120786422028903 | validation: 0.004689434660203386]
	TIME [epoch: 9.61 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041249735620752445		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0041249735620752445 | validation: 0.00405148750934837]
	TIME [epoch: 9.64 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003471321212280486		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.003471321212280486 | validation: 0.003776808894341338]
	TIME [epoch: 9.62 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004098298768911744		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.004098298768911744 | validation: 0.0034120021163897398]
	TIME [epoch: 9.59 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032996015608759604		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.0032996015608759604 | validation: 0.0032791011424863374]
	TIME [epoch: 9.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004000727051728467		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.004000727051728467 | validation: 0.004610950598075141]
	TIME [epoch: 9.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004336243748910074		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.004336243748910074 | validation: 0.004388552309682409]
	TIME [epoch: 9.64 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003532124774275532		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.003532124774275532 | validation: 0.003544657130231113]
	TIME [epoch: 9.53 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033728023172362367		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0033728023172362367 | validation: 0.004564665414671833]
	TIME [epoch: 9.56 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004043724082165498		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.004043724082165498 | validation: 0.004613820860179975]
	TIME [epoch: 9.67 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036182684926258247		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0036182684926258247 | validation: 0.004202602697596349]
	TIME [epoch: 9.62 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005774936388739606		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.005774936388739606 | validation: 0.004368964366509527]
	TIME [epoch: 9.57 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003627733406217333		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.003627733406217333 | validation: 0.003716538297587618]
	TIME [epoch: 9.56 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033521435202209056		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.0033521435202209056 | validation: 0.0051225667766699855]
	TIME [epoch: 9.56 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033422316938002605		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.0033422316938002605 | validation: 0.004829448152862162]
	TIME [epoch: 9.57 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036215299395657634		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.0036215299395657634 | validation: 0.003170100391366187]
	TIME [epoch: 9.61 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035872036447680295		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.0035872036447680295 | validation: 0.004284660492980836]
	TIME [epoch: 9.56 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035072279321095197		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0035072279321095197 | validation: 0.0057315459032140125]
	TIME [epoch: 9.56 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003708140014454292		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.003708140014454292 | validation: 0.005051895427744844]
	TIME [epoch: 9.56 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003675385034277182		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.003675385034277182 | validation: 0.004612051944028936]
	TIME [epoch: 9.61 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003980932291138488		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.003980932291138488 | validation: 0.0030759854604195313]
	TIME [epoch: 9.57 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030323476825213844		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0030323476825213844 | validation: 0.0034284362284860495]
	TIME [epoch: 9.55 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032865962729351555		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0032865962729351555 | validation: 0.004470352911412248]
	TIME [epoch: 9.56 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037824625655832715		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.0037824625655832715 | validation: 0.005713592339427387]
	TIME [epoch: 9.58 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004405964435577152		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.004405964435577152 | validation: 0.004124907802915179]
	TIME [epoch: 9.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031720379234816327		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0031720379234816327 | validation: 0.00358320241818852]
	TIME [epoch: 9.56 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035671579245034413		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0035671579245034413 | validation: 0.0035675109312255228]
	TIME [epoch: 9.56 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004308116488702404		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.004308116488702404 | validation: 0.004030753716999745]
	TIME [epoch: 9.55 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032371844108878742		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.0032371844108878742 | validation: 0.0038970525911112067]
	TIME [epoch: 9.62 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004258501000219281		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.004258501000219281 | validation: 0.003419893931102467]
	TIME [epoch: 9.56 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003517502556030975		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.003517502556030975 | validation: 0.0033700391091788075]
	TIME [epoch: 9.56 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033330960461928037		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.0033330960461928037 | validation: 0.005050619874568774]
	TIME [epoch: 9.56 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00354897971621835		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.00354897971621835 | validation: 0.0037945612198778634]
	TIME [epoch: 9.58 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003120897794428063		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.003120897794428063 | validation: 0.003804260596340039]
	TIME [epoch: 9.59 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003093830401982073		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.003093830401982073 | validation: 0.0030727016407812446]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00417567848486258		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.00417567848486258 | validation: 0.005601061789185535]
	TIME [epoch: 9.54 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003936536855837056		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.003936536855837056 | validation: 0.004027692186808447]
	TIME [epoch: 9.55 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035162858185785973		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.0035162858185785973 | validation: 0.0035024248202056617]
	TIME [epoch: 9.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002819028770337196		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.002819028770337196 | validation: 0.0026367928976367898]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029747511945929627		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.0029747511945929627 | validation: 0.0032610515934421887]
	TIME [epoch: 9.57 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003562550671295801		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.003562550671295801 | validation: 0.0029585894023573846]
	TIME [epoch: 9.57 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038171870440439635		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.0038171870440439635 | validation: 0.003469169221267351]
	TIME [epoch: 9.57 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002749861737057538		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.002749861737057538 | validation: 0.003376194621136577]
	TIME [epoch: 9.62 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003358846547789867		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.003358846547789867 | validation: 0.0053838638916636665]
	TIME [epoch: 9.57 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039022238188892292		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0039022238188892292 | validation: 0.0034942406807976587]
	TIME [epoch: 9.57 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031476950252018656		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0031476950252018656 | validation: 0.0031862147130576404]
	TIME [epoch: 9.57 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034693592737341525		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.0034693592737341525 | validation: 0.0031707849168837845]
	TIME [epoch: 9.59 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003250962944265753		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.003250962944265753 | validation: 0.003356606380852064]
	TIME [epoch: 9.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003059308863139801		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.003059308863139801 | validation: 0.00825317828096052]
	TIME [epoch: 9.57 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005603664331333243		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.005603664331333243 | validation: 0.004219674652095048]
	TIME [epoch: 9.57 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028936619581996273		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0028936619581996273 | validation: 0.004042785497071537]
	TIME [epoch: 9.57 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036106124211821213		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.0036106124211821213 | validation: 0.0035905227137087844]
	TIME [epoch: 9.61 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031459467882708654		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0031459467882708654 | validation: 0.0038712432849716035]
	TIME [epoch: 9.57 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003047255122302719		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.003047255122302719 | validation: 0.0043993596962614645]
	TIME [epoch: 9.57 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033104310948049087		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.0033104310948049087 | validation: 0.0034220987322026693]
	TIME [epoch: 9.56 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034025897857077945		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0034025897857077945 | validation: 0.004398163092917894]
	TIME [epoch: 9.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003739296127697588		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.003739296127697588 | validation: 0.002821263734295372]
	TIME [epoch: 9.58 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028809862227862633		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0028809862227862633 | validation: 0.003684264922430738]
	TIME [epoch: 9.57 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037807519253757575		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.0037807519253757575 | validation: 0.003071684157243517]
	TIME [epoch: 9.57 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029129986441663322		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0029129986441663322 | validation: 0.004315490697213846]
	TIME [epoch: 9.57 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029090952898982426		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0029090952898982426 | validation: 0.0038958758103732694]
	TIME [epoch: 9.62 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034874798189427677		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.0034874798189427677 | validation: 0.003384172465543127]
	TIME [epoch: 9.57 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036857679389807095		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0036857679389807095 | validation: 0.003316646327735021]
	TIME [epoch: 9.57 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029940477510809224		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0029940477510809224 | validation: 0.0025850559207268387]
	TIME [epoch: 9.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003188785509311333		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.003188785509311333 | validation: 0.003037601584490502]
	TIME [epoch: 9.61 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029675985403566107		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.0029675985403566107 | validation: 0.0038388909261042724]
	TIME [epoch: 9.58 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030726794120134004		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0030726794120134004 | validation: 0.0028099664843133105]
	TIME [epoch: 9.56 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029165337870328423		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.0029165337870328423 | validation: 0.0033007675273253236]
	TIME [epoch: 9.56 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003952454255313329		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.003952454255313329 | validation: 0.002640094363042267]
	TIME [epoch: 9.57 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035570221139187234		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0035570221139187234 | validation: 0.0037063054842798914]
	TIME [epoch: 9.61 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028036191873778817		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.0028036191873778817 | validation: 0.0034378119059304576]
	TIME [epoch: 9.57 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002960816369237597		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.002960816369237597 | validation: 0.002801665022429978]
	TIME [epoch: 9.56 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029051493019685917		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.0029051493019685917 | validation: 0.004962130813864998]
	TIME [epoch: 9.56 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003919906733336057		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.003919906733336057 | validation: 0.004481229856072752]
	TIME [epoch: 9.59 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003268142091201483		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.003268142091201483 | validation: 0.0034114790936050398]
	TIME [epoch: 9.59 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002727930882114029		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.002727930882114029 | validation: 0.0035237513716327336]
	TIME [epoch: 9.57 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003252691581897234		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.003252691581897234 | validation: 0.0033989872473275404]
	TIME [epoch: 9.57 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033194267020694415		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0033194267020694415 | validation: 0.003027463686280666]
	TIME [epoch: 9.56 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003126809239205372		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.003126809239205372 | validation: 0.0037485686442893518]
	TIME [epoch: 9.61 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030320725130108983		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.0030320725130108983 | validation: 0.0030506380963832734]
	TIME [epoch: 9.57 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003506920841488714		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.003506920841488714 | validation: 0.003231223809342304]
	TIME [epoch: 9.56 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030447613813326057		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0030447613813326057 | validation: 0.002917206526475958]
	TIME [epoch: 9.57 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032186511599012865		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.0032186511599012865 | validation: 0.003923967286234136]
	TIME [epoch: 9.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033294651599901207		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.0033294651599901207 | validation: 0.0025290202312545224]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_821.pth
	Model improved!!!
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027154785297497813		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.0027154785297497813 | validation: 0.0035402309591957273]
	TIME [epoch: 9.56 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003906264168739225		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.003906264168739225 | validation: 0.004054873066916226]
	TIME [epoch: 9.55 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029563723854864575		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0029563723854864575 | validation: 0.003730990364968208]
	TIME [epoch: 9.56 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029321114404736236		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0029321114404736236 | validation: 0.003124463633981221]
	TIME [epoch: 9.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038719568699358475		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0038719568699358475 | validation: 0.0036226222079870428]
	TIME [epoch: 9.56 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028618148671632486		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0028618148671632486 | validation: 0.0029773651084658123]
	TIME [epoch: 9.55 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002969814231979241		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.002969814231979241 | validation: 0.002884115994915842]
	TIME [epoch: 9.55 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002523982912036053		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.002523982912036053 | validation: 0.0037778947482970376]
	TIME [epoch: 9.56 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00383992880431169		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.00383992880431169 | validation: 0.003959258258861057]
	TIME [epoch: 9.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030058996224698606		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0030058996224698606 | validation: 0.004096909730581099]
	TIME [epoch: 9.55 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029378965959809033		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0029378965959809033 | validation: 0.002960691204398546]
	TIME [epoch: 9.55 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002859056206421763		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.002859056206421763 | validation: 0.00374403336829341]
	TIME [epoch: 9.55 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00338585719166432		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.00338585719166432 | validation: 0.00470817055552789]
	TIME [epoch: 9.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036542677098433687		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0036542677098433687 | validation: 0.0036302802312487836]
	TIME [epoch: 9.56 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026705992788051665		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.0026705992788051665 | validation: 0.002597126572246988]
	TIME [epoch: 9.55 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029593980543004754		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0029593980543004754 | validation: 0.004637161781801861]
	TIME [epoch: 9.55 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003689867543357669		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.003689867543357669 | validation: 0.0027261066713948168]
	TIME [epoch: 9.57 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028811223394251432		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0028811223394251432 | validation: 0.0035459153247313032]
	TIME [epoch: 9.59 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031828661891528266		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0031828661891528266 | validation: 0.0033580558217319307]
	TIME [epoch: 9.55 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031056116279485177		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0031056116279485177 | validation: 0.00350802026397021]
	TIME [epoch: 9.55 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028929459011667207		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0028929459011667207 | validation: 0.003672814661010478]
	TIME [epoch: 9.55 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033102057123412126		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0033102057123412126 | validation: 0.0032355431102356136]
	TIME [epoch: 9.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003043720943911043		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.003043720943911043 | validation: 0.002963010893076314]
	TIME [epoch: 9.56 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003339345340022256		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.003339345340022256 | validation: 0.0036762017890810024]
	TIME [epoch: 9.55 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00264470677759771		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.00264470677759771 | validation: 0.0034211205833201896]
	TIME [epoch: 9.56 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029599309317752953		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.0029599309317752953 | validation: 0.003578998595560285]
	TIME [epoch: 9.57 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028636996508307607		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0028636996508307607 | validation: 0.002404896166227301]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_848.pth
	Model improved!!!
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032940526274404117		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.0032940526274404117 | validation: 0.00322738107056378]
	TIME [epoch: 9.56 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002724423804306591		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.002724423804306591 | validation: 0.0031893388468540165]
	TIME [epoch: 9.55 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003038121454176216		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.003038121454176216 | validation: 0.002710927622732664]
	TIME [epoch: 9.55 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027558975074226106		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.0027558975074226106 | validation: 0.00400434433505355]
	TIME [epoch: 9.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029972111044944106		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.0029972111044944106 | validation: 0.0025243033572858245]
	TIME [epoch: 9.56 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025010380167001236		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0025010380167001236 | validation: 0.0037256182315482207]
	TIME [epoch: 9.55 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030715345364238046		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0030715345364238046 | validation: 0.004389414996777483]
	TIME [epoch: 9.55 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037687863838015995		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0037687863838015995 | validation: 0.007716287751241129]
	TIME [epoch: 9.56 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004524278154147162		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.004524278154147162 | validation: 0.0028000899407728723]
	TIME [epoch: 9.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002540414830906868		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.002540414830906868 | validation: 0.00331546984323161]
	TIME [epoch: 9.55 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024866924669132086		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.0024866924669132086 | validation: 0.0029887547896626536]
	TIME [epoch: 9.55 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026811162186877032		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0026811162186877032 | validation: 0.004228732565907901]
	TIME [epoch: 9.55 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00278259565318207		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.00278259565318207 | validation: 0.003582800861960024]
	TIME [epoch: 9.59 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003004455911996562		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.003004455911996562 | validation: 0.0036330558054934164]
	TIME [epoch: 9.56 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026736800095813577		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.0026736800095813577 | validation: 0.002867680079081846]
	TIME [epoch: 9.55 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002970956924287219		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.002970956924287219 | validation: 0.0029220115899363996]
	TIME [epoch: 9.55 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025883206058904176		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0025883206058904176 | validation: 0.0034757333146497697]
	TIME [epoch: 9.56 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028426132914576947		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.0028426132914576947 | validation: 0.003606423389350711]
	TIME [epoch: 9.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003113778904486941		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.003113778904486941 | validation: 0.0029558134276220444]
	TIME [epoch: 9.55 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002951855048994392		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.002951855048994392 | validation: 0.003725561163957332]
	TIME [epoch: 9.55 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023148340666682547		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0023148340666682547 | validation: 0.00275229250083527]
	TIME [epoch: 9.56 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031111454150620846		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0031111454150620846 | validation: 0.003851994298684612]
	TIME [epoch: 9.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030700250376507233		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0030700250376507233 | validation: 0.0029880521195093097]
	TIME [epoch: 9.57 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002768558029433232		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.002768558029433232 | validation: 0.003246647525370751]
	TIME [epoch: 9.55 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027909605212762434		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.0027909605212762434 | validation: 0.003133763355973864]
	TIME [epoch: 9.55 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022902449918268818		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0022902449918268818 | validation: 0.0034492436853052885]
	TIME [epoch: 9.56 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028763890947405323		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.0028763890947405323 | validation: 0.004332845751441904]
	TIME [epoch: 9.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028134763324473592		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0028134763324473592 | validation: 0.003097361236592107]
	TIME [epoch: 9.56 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025757374925145923		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.0025757374925145923 | validation: 0.002721858939905714]
	TIME [epoch: 9.55 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002739009856732251		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.002739009856732251 | validation: 0.0031351117038371295]
	TIME [epoch: 9.55 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026627655368930726		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0026627655368930726 | validation: 0.003852969861229628]
	TIME [epoch: 9.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002560932536051025		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.002560932536051025 | validation: 0.0029500489580916297]
	TIME [epoch: 9.56 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002864405707937866		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.002864405707937866 | validation: 0.002646503910334764]
	TIME [epoch: 9.55 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002705117898868493		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.002705117898868493 | validation: 0.0030951350808561015]
	TIME [epoch: 9.55 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002603332860598283		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.002603332860598283 | validation: 0.002314425586783167]
	TIME [epoch: 9.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026061362060761494		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0026061362060761494 | validation: 0.0027278007951362497]
	TIME [epoch: 9.58 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027721549431227606		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0027721549431227606 | validation: 0.002525822568803875]
	TIME [epoch: 9.54 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025416399723576116		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.0025416399723576116 | validation: 0.0029176522478139002]
	TIME [epoch: 9.54 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024801346967709592		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0024801346967709592 | validation: 0.0028028523585468847]
	TIME [epoch: 9.54 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023569677250770893		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0023569677250770893 | validation: 0.0038349919598066923]
	TIME [epoch: 9.57 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032760237107801334		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0032760237107801334 | validation: 0.0026218709578739664]
	TIME [epoch: 9.55 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039990946049816515		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.0039990946049816515 | validation: 0.003422686719255914]
	TIME [epoch: 9.55 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028748414052512353		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0028748414052512353 | validation: 0.00300824753326183]
	TIME [epoch: 9.54 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002613043057652065		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.002613043057652065 | validation: 0.002339725690282047]
	TIME [epoch: 9.54 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025310111996062375		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.0025310111996062375 | validation: 0.0034888038700228163]
	TIME [epoch: 9.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026367006008687363		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.0026367006008687363 | validation: 0.005170881591603165]
	TIME [epoch: 9.55 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029280022961227304		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0029280022961227304 | validation: 0.0031396739154742675]
	TIME [epoch: 9.55 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002632938436117541		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.002632938436117541 | validation: 0.002735778334825465]
	TIME [epoch: 9.54 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002662431012595065		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.002662431012595065 | validation: 0.002793948300154621]
	TIME [epoch: 9.59 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028520701511370143		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.0028520701511370143 | validation: 0.0034446812861650584]
	TIME [epoch: 9.57 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002763226632983722		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.002763226632983722 | validation: 0.0029230232843508695]
	TIME [epoch: 9.55 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028118691511665028		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0028118691511665028 | validation: 0.0035272678062359493]
	TIME [epoch: 9.55 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025262591683004342		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0025262591683004342 | validation: 0.0028254720742546015]
	TIME [epoch: 9.56 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026152401651855246		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.0026152401651855246 | validation: 0.003595458062153714]
	TIME [epoch: 9.62 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002520444755576757		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.002520444755576757 | validation: 0.0028179695390612566]
	TIME [epoch: 9.57 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024678316827219803		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0024678316827219803 | validation: 0.0041824994416449]
	TIME [epoch: 9.57 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026283734681677483		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.0026283734681677483 | validation: 0.0032847089481121854]
	TIME [epoch: 9.57 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027646537036116353		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.0027646537036116353 | validation: 0.002724657787688212]
	TIME [epoch: 9.59 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025128987194688044		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0025128987194688044 | validation: 0.002827584936108478]
	TIME [epoch: 9.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027741896589833295		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0027741896589833295 | validation: 0.004029909783462474]
	TIME [epoch: 9.57 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031676048722257613		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.0031676048722257613 | validation: 0.0027201571941198664]
	TIME [epoch: 9.57 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022996658038659298		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0022996658038659298 | validation: 0.0031117986600243544]
	TIME [epoch: 9.56 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002557670527233413		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.002557670527233413 | validation: 0.002431286733495141]
	TIME [epoch: 9.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002198318812832332		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.002198318812832332 | validation: 0.0033214100966209702]
	TIME [epoch: 9.56 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025538009361551414		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0025538009361551414 | validation: 0.0020653106245862897]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027233952774016364		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0027233952774016364 | validation: 0.0034811143691328246]
	TIME [epoch: 9.55 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027015418589504854		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.0027015418589504854 | validation: 0.0030946237472902886]
	TIME [epoch: 9.59 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002719497068116003		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.002719497068116003 | validation: 0.004061231718742623]
	TIME [epoch: 9.56 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024292695718395817		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.0024292695718395817 | validation: 0.0027607745457206706]
	TIME [epoch: 9.55 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002809581353727478		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.002809581353727478 | validation: 0.0025959568705357363]
	TIME [epoch: 9.55 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025259712257594182		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.0025259712257594182 | validation: 0.0025536163177728097]
	TIME [epoch: 9.55 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002406911080905808		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.002406911080905808 | validation: 0.0025501349226315683]
	TIME [epoch: 9.59 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023626417188605466		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0023626417188605466 | validation: 0.003995024652208611]
	TIME [epoch: 9.56 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025521989877400624		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0025521989877400624 | validation: 0.0028684048361364758]
	TIME [epoch: 9.55 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028352378269569816		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0028352378269569816 | validation: 0.0033148085406195646]
	TIME [epoch: 9.55 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023484424868602414		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.0023484424868602414 | validation: 0.0029405614862786627]
	TIME [epoch: 9.55 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025235668573365014		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0025235668573365014 | validation: 0.0028666201618755965]
	TIME [epoch: 9.59 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030115744285554693		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0030115744285554693 | validation: 0.00281098007781735]
	TIME [epoch: 9.55 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026187308733405176		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0026187308733405176 | validation: 0.0036137853300285986]
	TIME [epoch: 9.55 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025628360020387934		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.0025628360020387934 | validation: 0.003101582833860322]
	TIME [epoch: 9.55 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025232940729375663		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0025232940729375663 | validation: 0.002653715673206762]
	TIME [epoch: 9.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002560990232636641		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.002560990232636641 | validation: 0.0028969533416626217]
	TIME [epoch: 9.56 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022698682033523046		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0022698682033523046 | validation: 0.0029554670425745904]
	TIME [epoch: 9.56 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002975044757347452		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.002975044757347452 | validation: 0.0029808366188222276]
	TIME [epoch: 9.56 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025567066494384927		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.0025567066494384927 | validation: 0.0031979952934940194]
	TIME [epoch: 9.56 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025124532480205702		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0025124532480205702 | validation: 0.003448722925994245]
	TIME [epoch: 9.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002611940044908497		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.002611940044908497 | validation: 0.003237126098699295]
	TIME [epoch: 9.56 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002830195478192711		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.002830195478192711 | validation: 0.00329493979177519]
	TIME [epoch: 9.56 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002294276940008007		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.002294276940008007 | validation: 0.0029167246473838474]
	TIME [epoch: 9.56 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023558319642414155		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0023558319642414155 | validation: 0.002824367660591123]
	TIME [epoch: 9.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026449493935131415		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0026449493935131415 | validation: 0.0030851790760745112]
	TIME [epoch: 9.56 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002417433015536166		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.002417433015536166 | validation: 0.0027983729575187504]
	TIME [epoch: 9.56 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024914650871128868		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.0024914650871128868 | validation: 0.00307318941951526]
	TIME [epoch: 9.56 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002323369278045717		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.002323369278045717 | validation: 0.0030940257973521685]
	TIME [epoch: 9.57 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025640494779322212		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.0025640494779322212 | validation: 0.0026200178281476534]
	TIME [epoch: 9.59 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002684809099520249		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.002684809099520249 | validation: 0.0028609602449161937]
	TIME [epoch: 9.56 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002243683781891174		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.002243683781891174 | validation: 0.0027802779296293325]
	TIME [epoch: 9.56 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021583266545931227		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0021583266545931227 | validation: 0.0025288872427330408]
	TIME [epoch: 9.54 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023996047659593797		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0023996047659593797 | validation: 0.002684695801519991]
	TIME [epoch: 9.61 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002395925765254529		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.002395925765254529 | validation: 0.0027826762706991853]
	TIME [epoch: 9.55 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00235810348557359		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.00235810348557359 | validation: 0.0027432962835436]
	TIME [epoch: 9.56 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024359091369604373		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.0024359091369604373 | validation: 0.0037950698698538485]
	TIME [epoch: 9.54 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002488096001091511		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.002488096001091511 | validation: 0.003484636397818028]
	TIME [epoch: 9.58 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002511118898940945		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.002511118898940945 | validation: 0.0028543036710374993]
	TIME [epoch: 9.56 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002432678682018321		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.002432678682018321 | validation: 0.0024940686689293914]
	TIME [epoch: 9.55 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002325208162001592		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.002325208162001592 | validation: 0.0030867299933121295]
	TIME [epoch: 9.54 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00237174008241064		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.00237174008241064 | validation: 0.002776322700217021]
	TIME [epoch: 9.56 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023545183883664418		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.0023545183883664418 | validation: 0.002915343655920376]
	TIME [epoch: 9.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021988229893683308		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0021988229893683308 | validation: 0.002678860547124663]
	TIME [epoch: 9.55 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002422010914884726		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.002422010914884726 | validation: 0.0028722759149882194]
	TIME [epoch: 9.54 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002188742357557396		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.002188742357557396 | validation: 0.0026885794842396366]
	TIME [epoch: 9.53 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024629959797261188		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0024629959797261188 | validation: 0.0032015474059796907]
	TIME [epoch: 9.57 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002242404174295846		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.002242404174295846 | validation: 0.003321230513833944]
	TIME [epoch: 9.55 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002330021455650616		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.002330021455650616 | validation: 0.0029528709424380254]
	TIME [epoch: 9.54 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023133036096558307		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.0023133036096558307 | validation: 0.0027146474070624173]
	TIME [epoch: 9.53 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023329647327518513		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.0023329647327518513 | validation: 0.0033463018840943137]
	TIME [epoch: 9.53 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022542373237113		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0022542373237113 | validation: 0.003034313122822831]
	TIME [epoch: 9.57 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002340442098669902		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.002340442098669902 | validation: 0.0029156141665759193]
	TIME [epoch: 9.53 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025036520173356063		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0025036520173356063 | validation: 0.0030659322853920767]
	TIME [epoch: 9.52 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022345863715378814		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0022345863715378814 | validation: 0.002627556407302518]
	TIME [epoch: 9.53 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022710499444335494		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0022710499444335494 | validation: 0.0026633922997046817]
	TIME [epoch: 9.58 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002233347941385132		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.002233347941385132 | validation: 0.0032211995164407856]
	TIME [epoch: 9.54 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021182713047935174		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0021182713047935174 | validation: 0.0026729464646172165]
	TIME [epoch: 9.52 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002487722062949878		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.002487722062949878 | validation: 0.0023979812204172274]
	TIME [epoch: 9.52 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026111358037024836		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0026111358037024836 | validation: 0.0024993283374419493]
	TIME [epoch: 9.53 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023147507655646134		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0023147507655646134 | validation: 0.0022072573052607006]
	TIME [epoch: 9.59 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002313534796872144		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.002313534796872144 | validation: 0.002374979443906538]
	TIME [epoch: 9.54 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021538062699913534		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.0021538062699913534 | validation: 0.0024099613856372664]
	TIME [epoch: 9.55 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023161346843798914		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.0023161346843798914 | validation: 0.003063139754471874]
	TIME [epoch: 9.55 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022510241062026945		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0022510241062026945 | validation: 0.003397847743749277]
	TIME [epoch: 9.58 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023082445699784994		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0023082445699784994 | validation: 0.004072773048166167]
	TIME [epoch: 9.56 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002442659911998635		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.002442659911998635 | validation: 0.0026903183277973346]
	TIME [epoch: 9.54 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022594409893233803		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0022594409893233803 | validation: 0.0025829567982373867]
	TIME [epoch: 9.54 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022738072051384753		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0022738072051384753 | validation: 0.002640195085687535]
	TIME [epoch: 9.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021179359379246048		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0021179359379246048 | validation: 0.0032628764066070302]
	TIME [epoch: 9.58 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00246750460640084		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.00246750460640084 | validation: 0.002671536111333993]
	TIME [epoch: 9.54 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002249579212870212		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.002249579212870212 | validation: 0.002530716666867108]
	TIME [epoch: 9.54 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024703133976937556		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.0024703133976937556 | validation: 0.002984718641047431]
	TIME [epoch: 9.54 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00225967935801878		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.00225967935801878 | validation: 0.0027593583343180714]
	TIME [epoch: 9.58 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002293238989137207		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.002293238989137207 | validation: 0.0030234611653487614]
	TIME [epoch: 9.55 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002319613168264039		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.002319613168264039 | validation: 0.0030314399802354526]
	TIME [epoch: 9.54 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021823150034768995		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0021823150034768995 | validation: 0.002621534133660935]
	TIME [epoch: 9.54 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022469583526616346		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.0022469583526616346 | validation: 0.003166747722864481]
	TIME [epoch: 9.55 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021064217065403152		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0021064217065403152 | validation: 0.0036940781471048157]
	TIME [epoch: 9.58 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022274074335237033		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.0022274074335237033 | validation: 0.0025866929883430058]
	TIME [epoch: 9.54 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022783935244435703		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0022783935244435703 | validation: 0.0026943878087262643]
	TIME [epoch: 9.54 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002350618056335429		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.002350618056335429 | validation: 0.002698451180520289]
	TIME [epoch: 9.54 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002446555852017011		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.002446555852017011 | validation: 0.003977338184922967]
	TIME [epoch: 9.59 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002122220204350871		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.002122220204350871 | validation: 0.0030434651814002745]
	TIME [epoch: 9.55 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002166782821217708		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.002166782821217708 | validation: 0.0032533103218907898]
	TIME [epoch: 9.54 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023214836324943547		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0023214836324943547 | validation: 0.0024515533260597603]
	TIME [epoch: 9.54 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002263691071635184		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.002263691071635184 | validation: 0.002527425609074108]
	TIME [epoch: 9.54 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020739692771246988		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0020739692771246988 | validation: 0.0025092466822308254]
	TIME [epoch: 9.58 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002107326470090873		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.002107326470090873 | validation: 0.0032353676154707285]
	TIME [epoch: 9.52 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022663411052339837		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0022663411052339837 | validation: 0.0020376142863484984]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020622051948106287		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0020622051948106287 | validation: 0.003911878246923783]
	TIME [epoch: 9.53 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023497661950962435		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.0023497661950962435 | validation: 0.0021285196833821384]
	TIME [epoch: 9.58 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021566882285670758		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0021566882285670758 | validation: 0.0022608534177518927]
	TIME [epoch: 9.56 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026808234355375797		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0026808234355375797 | validation: 0.0031681254933905506]
	TIME [epoch: 9.54 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021647571285859464		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.0021647571285859464 | validation: 0.0024459313264349565]
	TIME [epoch: 9.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021107569190154203		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.0021107569190154203 | validation: 0.002435479993143222]
	TIME [epoch: 9.54 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002158513914710929		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.002158513914710929 | validation: 0.0023441548365987185]
	TIME [epoch: 9.58 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020642317223497227		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0020642317223497227 | validation: 0.0027903973555230962]
	TIME [epoch: 9.56 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00233867914482989		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.00233867914482989 | validation: 0.0023756035839295952]
	TIME [epoch: 9.53 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020364660068391857		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0020364660068391857 | validation: 0.0022207597463418235]
	TIME [epoch: 9.54 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020572359028022172		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0020572359028022172 | validation: 0.0028795846407221044]
	TIME [epoch: 9.55 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022601514906818044		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0022601514906818044 | validation: 0.002589145959755821]
	TIME [epoch: 9.59 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002343997454744518		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.002343997454744518 | validation: 0.0029396282860331413]
	TIME [epoch: 9.52 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002207726486007338		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.002207726486007338 | validation: 0.0026718309538069198]
	TIME [epoch: 9.54 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020794573940774827		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.0020794573940774827 | validation: 0.003206602633489064]
	TIME [epoch: 9.52 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024281583324010725		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0024281583324010725 | validation: 0.002843167266598533]
	TIME [epoch: 9.58 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002413836590049446		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.002413836590049446 | validation: 0.0026132955643251056]
	TIME [epoch: 9.54 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019724118938449103		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0019724118938449103 | validation: 0.0021618971556265176]
	TIME [epoch: 9.54 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022992762136352235		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0022992762136352235 | validation: 0.004399594248340369]
	TIME [epoch: 9.52 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002489050762673135		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.002489050762673135 | validation: 0.0024462436655546425]
	TIME [epoch: 9.54 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024858690909962972		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0024858690909962972 | validation: 0.002232543240642996]
	TIME [epoch: 9.57 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020181582006814393		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0020181582006814393 | validation: 0.0029989228152862988]
	TIME [epoch: 9.53 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00210039549161865		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.00210039549161865 | validation: 0.0025562350653382353]
	TIME [epoch: 9.52 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002004651067512348		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.002004651067512348 | validation: 0.002951132232052867]
	TIME [epoch: 9.52 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002214935633168192		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.002214935633168192 | validation: 0.0022993377016868747]
	TIME [epoch: 9.59 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022509593425434986		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0022509593425434986 | validation: 0.0025916501929022797]
	TIME [epoch: 9.55 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023018739800628888		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.0023018739800628888 | validation: 0.0022195104509702157]
	TIME [epoch: 9.53 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021393167925763		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0021393167925763 | validation: 0.0025921030461467593]
	TIME [epoch: 9.52 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002121381729879422		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.002121381729879422 | validation: 0.0024771932089007746]
	TIME [epoch: 9.53 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023278918749156234		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.0023278918749156234 | validation: 0.002389037480657474]
	TIME [epoch: 9.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024926355072624863		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.0024926355072624863 | validation: 0.0024809264766311855]
	TIME [epoch: 9.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002072954419771993		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.002072954419771993 | validation: 0.003158288752710903]
	TIME [epoch: 9.54 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021053758161805923		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.0021053758161805923 | validation: 0.0028213743123815488]
	TIME [epoch: 9.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001987226910709596		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.001987226910709596 | validation: 0.0022302688914026705]
	TIME [epoch: 9.59 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023963418008846418		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.0023963418008846418 | validation: 0.002965011245372942]
	TIME [epoch: 9.52 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020579530774470904		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0020579530774470904 | validation: 0.002024920087130071]
	TIME [epoch: 9.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1039.pth
	Model improved!!!
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001979115230893201		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.001979115230893201 | validation: 0.0025557505878963304]
	TIME [epoch: 9.53 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020798802842964467		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0020798802842964467 | validation: 0.0022023922666340426]
	TIME [epoch: 9.55 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002028787966025471		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.002028787966025471 | validation: 0.0023192071162273695]
	TIME [epoch: 9.57 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002209692743800076		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.002209692743800076 | validation: 0.003509274092529087]
	TIME [epoch: 9.53 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002170415943498032		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.002170415943498032 | validation: 0.0028569083210315364]
	TIME [epoch: 9.53 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002076340487836346		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.002076340487836346 | validation: 0.00254639135614502]
	TIME [epoch: 9.52 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002080574317726268		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.002080574317726268 | validation: 0.0019511390509017231]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1046.pth
	Model improved!!!
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020122007155214242		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.0020122007155214242 | validation: 0.0028511163773481153]
	TIME [epoch: 9.57 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002062198568961837		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.002062198568961837 | validation: 0.002427564989488081]
	TIME [epoch: 9.54 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002122706324169623		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.002122706324169623 | validation: 0.0022138606435307216]
	TIME [epoch: 9.54 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019539157790762892		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0019539157790762892 | validation: 0.0022810859957798574]
	TIME [epoch: 9.52 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021493032183461797		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0021493032183461797 | validation: 0.002803453216505737]
	TIME [epoch: 9.56 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002060322182320127		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.002060322182320127 | validation: 0.002536665913977205]
	TIME [epoch: 9.53 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020229347534985336		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.0020229347534985336 | validation: 0.002488571091995193]
	TIME [epoch: 9.52 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018961500526376686		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.0018961500526376686 | validation: 0.002482220251702989]
	TIME [epoch: 9.52 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021696027090917056		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.0021696027090917056 | validation: 0.0025566890237799403]
	TIME [epoch: 9.53 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018755893075588352		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.0018755893075588352 | validation: 0.002334120024554137]
	TIME [epoch: 9.57 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019347285757362912		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0019347285757362912 | validation: 0.00262304632821077]
	TIME [epoch: 9.52 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002007318973406516		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.002007318973406516 | validation: 0.002450898982404348]
	TIME [epoch: 9.52 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019265365926638951		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0019265365926638951 | validation: 0.00278444231526992]
	TIME [epoch: 9.52 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002076627590016424		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.002076627590016424 | validation: 0.0028381555785299316]
	TIME [epoch: 9.57 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002100664194483769		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.002100664194483769 | validation: 0.0026750192501296165]
	TIME [epoch: 9.53 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020881587202125516		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0020881587202125516 | validation: 0.002097520299232716]
	TIME [epoch: 9.53 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002131584290412862		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.002131584290412862 | validation: 0.0025766489471727144]
	TIME [epoch: 9.54 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002486344505474855		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.002486344505474855 | validation: 0.002999575552181864]
	TIME [epoch: 9.54 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002538472017774578		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.002538472017774578 | validation: 0.002581712441259829]
	TIME [epoch: 9.58 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020691775174289024		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0020691775174289024 | validation: 0.002358675441114082]
	TIME [epoch: 9.53 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001990488634173006		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.001990488634173006 | validation: 0.002740071896592384]
	TIME [epoch: 9.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020986578134459697		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.0020986578134459697 | validation: 0.0023810664027279875]
	TIME [epoch: 9.53 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001927442247999051		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.001927442247999051 | validation: 0.0021653957227971434]
	TIME [epoch: 9.57 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020960443498346413		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0020960443498346413 | validation: 0.002429962200806157]
	TIME [epoch: 9.53 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019360673845465024		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0019360673845465024 | validation: 0.002014719502324568]
	TIME [epoch: 9.52 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021726901306795697		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.0021726901306795697 | validation: 0.0024633031714336234]
	TIME [epoch: 9.52 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001873845101359481		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.001873845101359481 | validation: 0.002573228229168119]
	TIME [epoch: 9.54 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002005953075571531		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.002005953075571531 | validation: 0.0026080955799884925]
	TIME [epoch: 9.56 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021499128827616155		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.0021499128827616155 | validation: 0.002170877963429489]
	TIME [epoch: 9.52 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020385640411477754		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0020385640411477754 | validation: 0.0020255297264388725]
	TIME [epoch: 9.53 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002067835819986208		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.002067835819986208 | validation: 0.0023525084626363204]
	TIME [epoch: 9.53 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019490249428195101		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.0019490249428195101 | validation: 0.0031684138764768426]
	TIME [epoch: 9.59 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00218005893732943		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.00218005893732943 | validation: 0.002669733279499484]
	TIME [epoch: 9.52 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00211135218460451		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.00211135218460451 | validation: 0.002743389783486455]
	TIME [epoch: 9.55 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017919378127429812		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.0017919378127429812 | validation: 0.003114202759691955]
	TIME [epoch: 9.52 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002106987578862426		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.002106987578862426 | validation: 0.002300579877801992]
	TIME [epoch: 9.54 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019370499062277907		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.0019370499062277907 | validation: 0.0027628769062939735]
	TIME [epoch: 9.55 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001903572896326606		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.001903572896326606 | validation: 0.0026167510440523564]
	TIME [epoch: 9.52 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022163309927309156		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0022163309927309156 | validation: 0.0019159142629685214]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017001417731095912		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.0017001417731095912 | validation: 0.002173003538043284]
	TIME [epoch: 9.53 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001962945046778835		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.001962945046778835 | validation: 0.0026559293515273667]
	TIME [epoch: 9.57 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002019860243560259		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.002019860243560259 | validation: 0.002626709195385672]
	TIME [epoch: 9.52 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002168127866243697		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.002168127866243697 | validation: 0.0027234251464396146]
	TIME [epoch: 9.52 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020725749348799814		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0020725749348799814 | validation: 0.0023703582505184765]
	TIME [epoch: 9.52 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023113259704168813		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0023113259704168813 | validation: 0.002188959222573253]
	TIME [epoch: 9.53 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002275954914204517		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.002275954914204517 | validation: 0.002680884085126645]
	TIME [epoch: 9.86 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002040103181230899		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.002040103181230899 | validation: 0.0025558012800989604]
	TIME [epoch: 9.55 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019884822408166897		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0019884822408166897 | validation: 0.0020284624416099834]
	TIME [epoch: 9.55 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020780782607783127		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0020780782607783127 | validation: 0.002742597029347903]
	TIME [epoch: 9.55 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00201559101786804		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.00201559101786804 | validation: 0.0028898780292376473]
	TIME [epoch: 9.57 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001830504000994276		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.001830504000994276 | validation: 0.0030583151508303524]
	TIME [epoch: 9.58 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001836453524338489		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.001836453524338489 | validation: 0.002312588374295066]
	TIME [epoch: 9.55 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019926493773514123		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0019926493773514123 | validation: 0.002461577936405783]
	TIME [epoch: 9.55 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020766988409989962		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.0020766988409989962 | validation: 0.0029169475455593148]
	TIME [epoch: 9.55 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020044094520212186		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0020044094520212186 | validation: 0.002447033756090807]
	TIME [epoch: 9.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019349012015526827		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.0019349012015526827 | validation: 0.0027131853211177174]
	TIME [epoch: 9.55 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018596118149415608		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0018596118149415608 | validation: 0.002421167206162255]
	TIME [epoch: 9.55 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020040764075659944		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0020040764075659944 | validation: 0.0025150541903100933]
	TIME [epoch: 9.55 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020052916139642273		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0020052916139642273 | validation: 0.0024343130458012157]
	TIME [epoch: 9.55 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018965540455892888		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0018965540455892888 | validation: 0.0027859910814578602]
	TIME [epoch: 9.59 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017660174597134816		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.0017660174597134816 | validation: 0.0023508515288427735]
	TIME [epoch: 9.55 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019536837226275194		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.0019536837226275194 | validation: 0.0025771499283979305]
	TIME [epoch: 9.55 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019468440284788348		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0019468440284788348 | validation: 0.0026584978120179105]
	TIME [epoch: 9.55 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019498933030871893		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.0019498933030871893 | validation: 0.002409532250526624]
	TIME [epoch: 9.59 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00196302601496406		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.00196302601496406 | validation: 0.0030618846087938014]
	TIME [epoch: 9.56 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019058331592168788		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.0019058331592168788 | validation: 0.002963030830927438]
	TIME [epoch: 9.55 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020020896688460505		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0020020896688460505 | validation: 0.0023899933685599777]
	TIME [epoch: 9.55 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018276839222195417		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0018276839222195417 | validation: 0.002263147714591307]
	TIME [epoch: 9.55 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019892924570290293		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0019892924570290293 | validation: 0.0021430341142187653]
	TIME [epoch: 9.59 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001896707354909335		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.001896707354909335 | validation: 0.0028879075536334168]
	TIME [epoch: 9.55 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001802825654083223		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.001802825654083223 | validation: 0.0025809468097646]
	TIME [epoch: 9.55 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016735295916373214		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0016735295916373214 | validation: 0.0024355841097105655]
	TIME [epoch: 9.55 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017742615617966286		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.0017742615617966286 | validation: 0.0025970601108489992]
	TIME [epoch: 9.59 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019269894368574895		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0019269894368574895 | validation: 0.002649722516696957]
	TIME [epoch: 9.56 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018662687796519844		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0018662687796519844 | validation: 0.002706566843262542]
	TIME [epoch: 9.55 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020461807389774165		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0020461807389774165 | validation: 0.0024006771554660874]
	TIME [epoch: 9.55 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019284341776705488		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.0019284341776705488 | validation: 0.003103532175484686]
	TIME [epoch: 9.55 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017953105753420878		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0017953105753420878 | validation: 0.002155417258048865]
	TIME [epoch: 9.59 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002044901008759801		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.002044901008759801 | validation: 0.002719211736045013]
	TIME [epoch: 9.55 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018775464934601203		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0018775464934601203 | validation: 0.0025932271476971722]
	TIME [epoch: 9.55 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021469394095018765		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.0021469394095018765 | validation: 0.002278046476859816]
	TIME [epoch: 9.55 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019299158678377617		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0019299158678377617 | validation: 0.002195876732491152]
	TIME [epoch: 9.59 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002096491374520898		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.002096491374520898 | validation: 0.002212444674912753]
	TIME [epoch: 9.55 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020003720988095008		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0020003720988095008 | validation: 0.002169339854751237]
	TIME [epoch: 9.55 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001676693865697756		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.001676693865697756 | validation: 0.002084610066211543]
	TIME [epoch: 9.54 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019790246709127817		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.0019790246709127817 | validation: 0.0022883441832416878]
	TIME [epoch: 9.57 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019159191866803317		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.0019159191866803317 | validation: 0.0026146358325342487]
	TIME [epoch: 9.58 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002147321253267448		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.002147321253267448 | validation: 0.0019307803469083922]
	TIME [epoch: 9.55 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018713265201928198		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.0018713265201928198 | validation: 0.0029411148830619455]
	TIME [epoch: 9.54 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018574334365269198		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0018574334365269198 | validation: 0.0029495457672225707]
	TIME [epoch: 9.55 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018637855430651672		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.0018637855430651672 | validation: 0.00229262138931083]
	TIME [epoch: 9.59 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017934884207271907		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0017934884207271907 | validation: 0.002914790096046324]
	TIME [epoch: 9.55 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019923623521812483		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0019923623521812483 | validation: 0.0023477214869731993]
	TIME [epoch: 9.55 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001945710184230634		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.001945710184230634 | validation: 0.0020735996878537017]
	TIME [epoch: 9.55 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001918421748612624		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.001918421748612624 | validation: 0.002519697260301787]
	TIME [epoch: 9.57 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017052908645902403		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.0017052908645902403 | validation: 0.0023045121635407]
	TIME [epoch: 9.57 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017799029485609267		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.0017799029485609267 | validation: 0.0028402684028416324]
	TIME [epoch: 9.55 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002174600522617687		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.002174600522617687 | validation: 0.002727220145838831]
	TIME [epoch: 9.55 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001916134247452873		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.001916134247452873 | validation: 0.002154641985443531]
	TIME [epoch: 9.54 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018842031414258824		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0018842031414258824 | validation: 0.0029034839045950465]
	TIME [epoch: 9.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016676006364070026		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0016676006364070026 | validation: 0.0025658957771538633]
	TIME [epoch: 9.55 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001745952556290617		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.001745952556290617 | validation: 0.0023499296743969026]
	TIME [epoch: 9.55 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025918626834392625		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0025918626834392625 | validation: 0.00328443613822484]
	TIME [epoch: 9.55 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002587753737891923		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.002587753737891923 | validation: 0.0026357280584692546]
	TIME [epoch: 9.59 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002149598898671605		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.002149598898671605 | validation: 0.0024501227663938077]
	TIME [epoch: 9.56 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001821883910267961		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.001821883910267961 | validation: 0.0028494159266920236]
	TIME [epoch: 9.55 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019273480712019991		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.0019273480712019991 | validation: 0.0024569416586525047]
	TIME [epoch: 9.55 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016119059455659123		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.0016119059455659123 | validation: 0.0019490673739940884]
	TIME [epoch: 9.55 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017968562524677788		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.0017968562524677788 | validation: 0.0023959739328907057]
	TIME [epoch: 9.59 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017580329200641764		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0017580329200641764 | validation: 0.0026375003344221615]
	TIME [epoch: 9.55 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019567256749292348		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0019567256749292348 | validation: 0.0022345961489555156]
	TIME [epoch: 9.54 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018049973108659298		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0018049973108659298 | validation: 0.0027123720369181216]
	TIME [epoch: 9.55 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001762815264699566		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.001762815264699566 | validation: 0.0024873275577229747]
	TIME [epoch: 9.59 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002019884346502214		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.002019884346502214 | validation: 0.003064833088325905]
	TIME [epoch: 9.56 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017200860954692172		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0017200860954692172 | validation: 0.0024351041935872127]
	TIME [epoch: 9.55 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020751078778853504		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.0020751078778853504 | validation: 0.00246765584799942]
	TIME [epoch: 9.55 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017464493484698478		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0017464493484698478 | validation: 0.002636872331829412]
	TIME [epoch: 9.55 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001842207511107391		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.001842207511107391 | validation: 0.0024532257279757676]
	TIME [epoch: 9.59 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019236901392331671		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0019236901392331671 | validation: 0.0024355281640493914]
	TIME [epoch: 9.55 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019241961197636048		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.0019241961197636048 | validation: 0.0025209743457954258]
	TIME [epoch: 9.55 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020112773835599985		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0020112773835599985 | validation: 0.0020193015738298693]
	TIME [epoch: 9.55 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016802632589130546		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.0016802632589130546 | validation: 0.002324855718348082]
	TIME [epoch: 9.59 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00188279518870897		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.00188279518870897 | validation: 0.0026317057931870337]
	TIME [epoch: 9.56 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024560731583803002		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0024560731583803002 | validation: 0.002873309325376451]
	TIME [epoch: 9.55 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021124140651912456		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0021124140651912456 | validation: 0.0025367443460451505]
	TIME [epoch: 9.55 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022662199187987756		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.0022662199187987756 | validation: 0.00273014351561644]
	TIME [epoch: 9.55 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001974882335982595		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.001974882335982595 | validation: 0.0027560747392383505]
	TIME [epoch: 9.59 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002082877993338183		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.002082877993338183 | validation: 0.0027011912626563853]
	TIME [epoch: 9.55 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021367441490980736		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0021367441490980736 | validation: 0.002842455539627432]
	TIME [epoch: 9.55 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018453862391077666		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0018453862391077666 | validation: 0.0021674977930593153]
	TIME [epoch: 9.55 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020008260073284233		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0020008260073284233 | validation: 0.0022277590156852237]
	TIME [epoch: 9.59 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020098377517968483		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.0020098377517968483 | validation: 0.0021816441520942044]
	TIME [epoch: 9.55 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019421334045687199		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.0019421334045687199 | validation: 0.002255354302104445]
	TIME [epoch: 9.54 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018342131144657948		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0018342131144657948 | validation: 0.0025609690982163784]
	TIME [epoch: 9.55 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018262143999571091		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0018262143999571091 | validation: 0.0031201181240974344]
	TIME [epoch: 9.55 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018735635695109375		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0018735635695109375 | validation: 0.0019650497486912244]
	TIME [epoch: 9.59 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019000019747750113		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.0019000019747750113 | validation: 0.0025039002239307484]
	TIME [epoch: 9.55 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018357467292748836		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0018357467292748836 | validation: 0.0026325530829173485]
	TIME [epoch: 9.55 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001905380141526088		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.001905380141526088 | validation: 0.002282134921898744]
	TIME [epoch: 9.54 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018394586390542717		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.0018394586390542717 | validation: 0.0024127528167451917]
	TIME [epoch: 9.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_largenet_20240703_142931/states/model_phi1_1a_v_mmd1_largenet_1186.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 11580.278 seconds.
