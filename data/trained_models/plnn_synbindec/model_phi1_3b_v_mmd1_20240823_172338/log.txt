Args:
Namespace(name='model_phi1_3b_v_mmd1', outdir='out/model_training/model_phi1_3b_v_mmd1', training_data='data/training_data/data_phi1_3b/training', validation_data='data/training_data/data_phi1_3b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2985913335

Training model...

Saving initial model state to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.646625621535477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.646625621535477 | validation: 4.374250768811524]
	TIME [epoch: 27.6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6651366394150817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6651366394150817 | validation: 3.7341784543652645]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6051822403294613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6051822403294613 | validation: 2.838306009535021]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.033925235432664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.033925235432664 | validation: 3.1233158275654866]
	TIME [epoch: 1.89 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.903616032281915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.903616032281915 | validation: 2.490524116514516]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.497658101985437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.497658101985437 | validation: 2.5891064577642164]
	TIME [epoch: 1.89 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3272529470611376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3272529470611376 | validation: 2.2595340667489405]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1972657901907606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1972657901907606 | validation: 2.1837509377325484]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2354994062617912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2354994062617912 | validation: 2.2629590009077156]
	TIME [epoch: 1.87 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0248644574367365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0248644574367365 | validation: 1.9423485484003216]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.810499281584102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.810499281584102 | validation: 1.9968260740582737]
	TIME [epoch: 1.89 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7264541808273108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7264541808273108 | validation: 1.764815096107724]
	TIME [epoch: 1.9 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.672518420956228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.672518420956228 | validation: 1.8631929162631942]
	TIME [epoch: 1.88 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5990018984650085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5990018984650085 | validation: 1.6932873588532822]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.500660893895971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.500660893895971 | validation: 1.6698155797196343]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.442477861856185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.442477861856185 | validation: 1.544991209253346]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3985965576974795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3985965576974795 | validation: 1.6514067490732711]
	TIME [epoch: 1.88 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.395645220051494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.395645220051494 | validation: 1.446372674808911]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3252126404129883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3252126404129883 | validation: 1.5541518676330222]
	TIME [epoch: 1.88 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2983891367186218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2983891367186218 | validation: 1.4318471653343163]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2419849393869347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2419849393869347 | validation: 1.447865104298561]
	TIME [epoch: 1.88 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2416442317001863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2416442317001863 | validation: 1.4137846842210484]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1926419679705027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1926419679705027 | validation: 1.3780537973204072]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1460583975330954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1460583975330954 | validation: 1.2455039766840383]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0686114296246234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0686114296246234 | validation: 1.2208750638689194]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0190183959560253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0190183959560253 | validation: 1.200781518143109]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9935167468496036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9935167468496036 | validation: 1.1440698994030836]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9878985353815241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9878985353815241 | validation: 1.251483363471814]
	TIME [epoch: 1.88 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0483158823366956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0483158823366956 | validation: 1.2986436505933394]
	TIME [epoch: 1.88 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2659421132213908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2659421132213908 | validation: 1.0742272503118817]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9100347055606122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9100347055606122 | validation: 1.2021404529280453]
	TIME [epoch: 1.89 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.987488571254047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.987488571254047 | validation: 1.0721577262026096]
	TIME [epoch: 1.9 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9805931387040464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9805931387040464 | validation: 0.9987131816470873]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8880410304623023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8880410304623023 | validation: 1.0359327546831014]
	TIME [epoch: 1.89 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.883559753569462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.883559753569462 | validation: 0.9649120313542092]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8596846654465864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8596846654465864 | validation: 1.025045941573037]
	TIME [epoch: 1.89 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.884277196239616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.884277196239616 | validation: 1.0299880111982884]
	TIME [epoch: 1.88 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9359660654865198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9359660654865198 | validation: 1.0650308033745983]
	TIME [epoch: 1.88 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9267409385445009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9267409385445009 | validation: 0.9143274498243859]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.807068772557216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.807068772557216 | validation: 0.87454869186428]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.777650978478431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.777650978478431 | validation: 0.881275903277642]
	TIME [epoch: 1.87 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.780743035944802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.780743035944802 | validation: 0.8630460883990427]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.789290021840066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.789290021840066 | validation: 0.9116297389838874]
	TIME [epoch: 1.88 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8212900308343865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8212900308343865 | validation: 0.8881808968106644]
	TIME [epoch: 1.88 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8388494102476887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8388494102476887 | validation: 0.9964241685271376]
	TIME [epoch: 1.87 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8542308972845827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8542308972845827 | validation: 0.8501638048533607]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7979386219552659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7979386219552659 | validation: 0.8718139756146783]
	TIME [epoch: 1.88 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7924716758145337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7924716758145337 | validation: 0.940546555403077]
	TIME [epoch: 1.87 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8831449937027689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8831449937027689 | validation: 0.8352369476118814]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7702392499331663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7702392499331663 | validation: 0.862839258479363]
	TIME [epoch: 1.87 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.768516808339408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.768516808339408 | validation: 0.8391198506395174]
	TIME [epoch: 1.88 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7655555404815106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7655555404815106 | validation: 0.8378374914498377]
	TIME [epoch: 1.88 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7538769006465087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7538769006465087 | validation: 0.8302117148439845]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7564511009393948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7564511009393948 | validation: 0.8137978247904869]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7453884785677888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7453884785677888 | validation: 0.8491413588723875]
	TIME [epoch: 1.89 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.779234594793782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.779234594793782 | validation: 0.8563558754599271]
	TIME [epoch: 1.87 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7802134155649784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7802134155649784 | validation: 0.8861397752547934]
	TIME [epoch: 1.87 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8194255429072359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8194255429072359 | validation: 0.809241835643372]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7358131942282694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7358131942282694 | validation: 0.8841457265175467]
	TIME [epoch: 1.88 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7762573277851162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7762573277851162 | validation: 0.847795192818844]
	TIME [epoch: 1.88 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8640707232821359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8640707232821359 | validation: 0.92704883697551]
	TIME [epoch: 1.88 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8208224996301587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8208224996301587 | validation: 0.8606543702858561]
	TIME [epoch: 1.88 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7995949935956844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7995949935956844 | validation: 0.8250462512013841]
	TIME [epoch: 1.88 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.764206520518064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.764206520518064 | validation: 0.7821070176899289]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7236651069290442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7236651069290442 | validation: 0.8193004903344469]
	TIME [epoch: 1.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.738072655887937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.738072655887937 | validation: 0.8217876757396095]
	TIME [epoch: 1.88 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7639761349385279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7639761349385279 | validation: 0.7710268938931016]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7142617354584649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7142617354584649 | validation: 0.7935691200709826]
	TIME [epoch: 1.88 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7206123140672888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7206123140672888 | validation: 0.7614497640370579]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.724481187879382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.724481187879382 | validation: 0.8138680408801554]
	TIME [epoch: 1.88 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7340432096577844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7340432096577844 | validation: 0.7974684704875753]
	TIME [epoch: 1.88 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7736911644673515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7736911644673515 | validation: 0.9927031118584095]
	TIME [epoch: 1.88 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8574700337720006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8574700337720006 | validation: 0.7935948226467964]
	TIME [epoch: 1.88 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7552851459810319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7552851459810319 | validation: 0.8037998987882795]
	TIME [epoch: 1.88 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.736525811837687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.736525811837687 | validation: 0.7788811927344013]
	TIME [epoch: 1.88 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7183757130599068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7183757130599068 | validation: 0.7750514461101432]
	TIME [epoch: 1.88 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7102753659436837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7102753659436837 | validation: 0.7666001218560068]
	TIME [epoch: 1.88 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7056910879248883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7056910879248883 | validation: 0.7471100800427128]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7068541624390688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7068541624390688 | validation: 0.7822291397760724]
	TIME [epoch: 1.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7214904278026509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7214904278026509 | validation: 0.7981689945777832]
	TIME [epoch: 1.88 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.74808482434806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.74808482434806 | validation: 0.8676827166944874]
	TIME [epoch: 1.88 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8468523307047133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8468523307047133 | validation: 0.7742250703376645]
	TIME [epoch: 1.88 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7344814048370065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7344814048370065 | validation: 0.8259825274385353]
	TIME [epoch: 1.88 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7375992823895908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7375992823895908 | validation: 0.8264561439845967]
	TIME [epoch: 1.88 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469116542119903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469116542119903 | validation: 1.0665478879312758]
	TIME [epoch: 1.88 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9002462876603724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9002462876603724 | validation: 0.7632649065682141]
	TIME [epoch: 1.88 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7105640658881012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7105640658881012 | validation: 0.76860269333641]
	TIME [epoch: 1.88 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7552669468220781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7552669468220781 | validation: 0.8234190377278644]
	TIME [epoch: 1.88 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7401986388478937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7401986388478937 | validation: 0.7502570007511924]
	TIME [epoch: 1.88 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7073867792089976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7073867792089976 | validation: 0.7462737732658524]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7067730417395786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7067730417395786 | validation: 0.7725773860791718]
	TIME [epoch: 1.88 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7030034025339528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7030034025339528 | validation: 0.7405919150089972]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.706243206043549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.706243206043549 | validation: 0.7673660897601231]
	TIME [epoch: 1.88 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7234336665329266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7234336665329266 | validation: 0.8121061546056283]
	TIME [epoch: 1.88 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7681722641746436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7681722641746436 | validation: 0.8859624016251889]
	TIME [epoch: 1.88 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8449867550620329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8449867550620329 | validation: 0.7506109670406227]
	TIME [epoch: 1.88 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7549044083603746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7549044083603746 | validation: 0.940497818996901]
	TIME [epoch: 1.88 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8025677582710712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8025677582710712 | validation: 0.7380391133153859]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7115103403944876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7115103403944876 | validation: 0.7384968794868961]
	TIME [epoch: 1.88 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6966852859652045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6966852859652045 | validation: 0.757109297735036]
	TIME [epoch: 1.87 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6931551574703388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6931551574703388 | validation: 0.7266068075084381]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6988664906063713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6988664906063713 | validation: 0.7720976000900637]
	TIME [epoch: 1.88 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7019952330346538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7019952330346538 | validation: 0.7531753899849111]
	TIME [epoch: 1.89 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7345279668083232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7345279668083232 | validation: 1.0486183202315107]
	TIME [epoch: 1.88 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9304396717695167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9304396717695167 | validation: 0.7767599888562406]
	TIME [epoch: 1.88 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7706029343284346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7706029343284346 | validation: 0.7543880656850797]
	TIME [epoch: 1.88 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.713981221321347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.713981221321347 | validation: 0.7403448662984679]
	TIME [epoch: 1.88 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6907150676035237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6907150676035237 | validation: 0.7162998041319992]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6877651900342814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6877651900342814 | validation: 0.7335324020081098]
	TIME [epoch: 1.88 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.690230128490613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.690230128490613 | validation: 0.7279403338967415]
	TIME [epoch: 1.88 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6872325376708892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6872325376708892 | validation: 0.7374688558225261]
	TIME [epoch: 1.88 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6856512317550348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6856512317550348 | validation: 0.7132682984481973]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6849678897226512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6849678897226512 | validation: 0.7780640661030089]
	TIME [epoch: 1.88 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7074207127682789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7074207127682789 | validation: 0.8399818479153526]
	TIME [epoch: 1.88 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8741461204777287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8741461204777287 | validation: 1.1983099657930003]
	TIME [epoch: 1.88 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.040263590739218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.040263590739218 | validation: 0.7194316036356819]
	TIME [epoch: 1.87 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6817942471650504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6817942471650504 | validation: 0.7637136349177651]
	TIME [epoch: 1.87 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7969462109731401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7969462109731401 | validation: 0.7694706852439211]
	TIME [epoch: 1.87 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7315101386903778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7315101386903778 | validation: 0.7381616533554409]
	TIME [epoch: 1.88 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7010667028762351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7010667028762351 | validation: 0.7188922983439735]
	TIME [epoch: 1.88 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.703812298702909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.703812298702909 | validation: 0.7546856631108678]
	TIME [epoch: 1.88 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6969734493947035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6969734493947035 | validation: 0.7333630899921052]
	TIME [epoch: 1.87 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6986621693326066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6986621693326066 | validation: 0.718057667716173]
	TIME [epoch: 1.88 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.688252641785279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.688252641785279 | validation: 0.7230862790077272]
	TIME [epoch: 1.88 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6713167130011911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6713167130011911 | validation: 0.6944323585425414]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6613164037667341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6613164037667341 | validation: 0.7408666909211173]
	TIME [epoch: 1.88 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6696591169492286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6696591169492286 | validation: 0.7114370846229892]
	TIME [epoch: 1.88 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6944900021356596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6944900021356596 | validation: 1.1232100808206855]
	TIME [epoch: 1.89 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9434686176269722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9434686176269722 | validation: 0.83933143378934]
	TIME [epoch: 1.88 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9087367104088803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9087367104088803 | validation: 0.7170819496079227]
	TIME [epoch: 1.88 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7029675869424551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7029675869424551 | validation: 0.7460959454342637]
	TIME [epoch: 1.88 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7078854547124687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7078854547124687 | validation: 0.6913943704578214]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7027848151629877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7027848151629877 | validation: 0.709325419760857]
	TIME [epoch: 1.88 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6753515320689152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6753515320689152 | validation: 0.7151312828116663]
	TIME [epoch: 1.88 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6747672175376715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6747672175376715 | validation: 0.6934450107184627]
	TIME [epoch: 1.87 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.665222229075751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.665222229075751 | validation: 0.7216237376861614]
	TIME [epoch: 1.87 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6675449957054795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6675449957054795 | validation: 0.6885681345718665]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6613371699576311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6613371699576311 | validation: 0.7267195553141118]
	TIME [epoch: 1.88 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6607110564074031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6607110564074031 | validation: 0.6835035843377979]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6615735952832681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6615735952832681 | validation: 0.8838679984311398]
	TIME [epoch: 1.88 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7752655874876027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7752655874876027 | validation: 0.8692203102874498]
	TIME [epoch: 1.88 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9174836132300759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9174836132300759 | validation: 0.7539868919962099]
	TIME [epoch: 1.87 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7128088296430071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7128088296430071 | validation: 0.6771183943885468]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6438239845436526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6438239845436526 | validation: 0.6857242843011386]
	TIME [epoch: 1.88 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6746979425030667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6746979425030667 | validation: 0.7316462698022015]
	TIME [epoch: 1.88 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6653594322037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6653594322037 | validation: 0.647732651962015]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.630373828332465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.630373828332465 | validation: 0.7085656614934375]
	TIME [epoch: 1.88 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6309726785088791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6309726785088791 | validation: 0.7093398358498577]
	TIME [epoch: 1.88 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7261760022129281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7261760022129281 | validation: 1.1146888598100322]
	TIME [epoch: 1.88 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9249724831666469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9249724831666469 | validation: 0.6645973119676192]
	TIME [epoch: 1.87 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7313027326268855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7313027326268855 | validation: 0.6305142253104986]
	TIME [epoch: 1.89 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6676880210915077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6676880210915077 | validation: 0.6743051433470306]
	TIME [epoch: 1.89 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6702498621528542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6702498621528542 | validation: 0.6654872483890403]
	TIME [epoch: 1.87 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6582828618175074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6582828618175074 | validation: 0.6639415492664958]
	TIME [epoch: 1.88 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6520786175710506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6520786175710506 | validation: 0.6720795781687386]
	TIME [epoch: 1.88 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6363059450255606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6363059450255606 | validation: 0.6384707059666219]
	TIME [epoch: 1.88 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6218180231639481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6218180231639481 | validation: 0.6363061119239437]
	TIME [epoch: 1.87 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6024277781148488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6024277781148488 | validation: 0.6437872604701872]
	TIME [epoch: 1.87 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5798147671493944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5798147671493944 | validation: 0.6167523525310946]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5567626722297225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5567626722297225 | validation: 0.9082814186959575]
	TIME [epoch: 1.88 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7118834024414018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7118834024414018 | validation: 1.5066771365712786]
	TIME [epoch: 1.87 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3676551371641583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3676551371641583 | validation: 0.7052068763026867]
	TIME [epoch: 1.87 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.780051348151022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.780051348151022 | validation: 0.8734573054133019]
	TIME [epoch: 1.88 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8733080074942441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8733080074942441 | validation: 0.6421651024492179]
	TIME [epoch: 1.87 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6768409396141649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6768409396141649 | validation: 0.6580691987607259]
	TIME [epoch: 1.87 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7308494949505865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7308494949505865 | validation: 0.6342765245995701]
	TIME [epoch: 1.87 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.65030207715471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.65030207715471 | validation: 0.6713407267524449]
	TIME [epoch: 1.88 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6588274473605149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6588274473605149 | validation: 0.6223279446315085]
	TIME [epoch: 1.87 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.638190625439061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.638190625439061 | validation: 0.6325368140873179]
	TIME [epoch: 1.87 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6191474414925001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6191474414925001 | validation: 0.6322629644115272]
	TIME [epoch: 1.87 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6141770861265162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6141770861265162 | validation: 0.6225860849849899]
	TIME [epoch: 1.87 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5917661624673517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5917661624673517 | validation: 0.6322564985678152]
	TIME [epoch: 1.88 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5744510681518142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5744510681518142 | validation: 0.6002768086395953]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5676196738149439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5676196738149439 | validation: 0.6827849114035197]
	TIME [epoch: 1.87 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.588205833541689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.588205833541689 | validation: 0.9415892849136954]
	TIME [epoch: 1.87 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9760426576335344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9760426576335344 | validation: 0.9235585569274707]
	TIME [epoch: 1.88 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7973492498612871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7973492498612871 | validation: 0.5767116443141894]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6041052783976134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6041052783976134 | validation: 0.5684457252369103]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5860170326580633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5860170326580633 | validation: 0.5896663637235449]
	TIME [epoch: 1.88 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5853651453487311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5853651453487311 | validation: 0.5633006153791489]
	TIME [epoch: 1.88 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5510905661574118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5510905661574118 | validation: 0.6062170271933006]
	TIME [epoch: 1.88 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.537600906485448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.537600906485448 | validation: 0.5844536616375506]
	TIME [epoch: 1.88 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5590223038339179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5590223038339179 | validation: 1.1585449664590848]
	TIME [epoch: 1.88 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.891378575605425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.891378575605425 | validation: 0.7758269111161038]
	TIME [epoch: 1.88 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8646746183511992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8646746183511992 | validation: 0.5757027418792822]
	TIME [epoch: 1.88 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.648674295258945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.648674295258945 | validation: 0.7082853819486155]
	TIME [epoch: 1.87 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6886711650950997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6886711650950997 | validation: 0.5945423848788981]
	TIME [epoch: 1.87 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6314069065533171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6314069065533171 | validation: 0.5815620940894325]
	TIME [epoch: 1.88 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6187782562908409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6187782562908409 | validation: 0.581286711465617]
	TIME [epoch: 1.88 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6069857260916949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6069857260916949 | validation: 0.5694533094709643]
	TIME [epoch: 1.88 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5824647429232475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5824647429232475 | validation: 0.5768390981054108]
	TIME [epoch: 1.88 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5684108619308164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5684108619308164 | validation: 0.5723795270758403]
	TIME [epoch: 1.87 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5469734850903171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5469734850903171 | validation: 0.5434388607184479]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5381431374356658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5381431374356658 | validation: 0.6832346595682252]
	TIME [epoch: 1.88 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5891488172470315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5891488172470315 | validation: 0.7529200655081957]
	TIME [epoch: 1.88 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7955950427625222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7955950427625222 | validation: 0.7135133856857531]
	TIME [epoch: 1.88 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6217816544305383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6217816544305383 | validation: 0.5191023190356898]
	TIME [epoch: 1.87 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5386222194431375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5386222194431375 | validation: 0.5293507835950457]
	TIME [epoch: 1.88 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5156900908627411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5156900908627411 | validation: 0.5248795093634012]
	TIME [epoch: 1.88 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49544659716066086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49544659716066086 | validation: 0.5293437254783218]
	TIME [epoch: 1.88 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4876626319030079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4876626319030079 | validation: 0.506109380734396]
	TIME [epoch: 26.2 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49275628300557445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49275628300557445 | validation: 0.7102922616539624]
	TIME [epoch: 3.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5918093829995293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5918093829995293 | validation: 0.8504189116684602]
	TIME [epoch: 3.71 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8551878052324213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8551878052324213 | validation: 0.511314392684519]
	TIME [epoch: 3.72 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5777935989572588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5777935989572588 | validation: 0.5792060311326835]
	TIME [epoch: 3.72 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5918371682501975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5918371682501975 | validation: 0.49429359426986946]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5517553034376964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5517553034376964 | validation: 0.5409731803017719]
	TIME [epoch: 3.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5001411383968274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5001411383968274 | validation: 0.4751042576167002]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48580019343245656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48580019343245656 | validation: 0.6326011743251462]
	TIME [epoch: 3.74 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5274373668855692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5274373668855692 | validation: 0.6052722910385938]
	TIME [epoch: 3.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6843469130496006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6843469130496006 | validation: 0.5288952542978671]
	TIME [epoch: 3.72 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5514207970370913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5514207970370913 | validation: 0.46493511419449374]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4892850068803462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4892850068803462 | validation: 0.4504736690951859]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48888413790209345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48888413790209345 | validation: 0.6852080754566929]
	TIME [epoch: 3.72 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5651807706450864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5651807706450864 | validation: 0.7028634184839331]
	TIME [epoch: 3.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7143232709749597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7143232709749597 | validation: 0.49863934359164586]
	TIME [epoch: 3.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5357203006706555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5357203006706555 | validation: 0.5104104419490948]
	TIME [epoch: 3.71 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5171828457821576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5171828457821576 | validation: 0.4645524288832958]
	TIME [epoch: 3.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5049619963180748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049619963180748 | validation: 0.5958913015311772]
	TIME [epoch: 3.72 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5094595615491321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5094595615491321 | validation: 0.49897398934076964]
	TIME [epoch: 3.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5623807045796919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5623807045796919 | validation: 0.511854844734042]
	TIME [epoch: 3.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.489240302448259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.489240302448259 | validation: 0.4169968710129722]
	TIME [epoch: 3.73 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4429216498804003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4429216498804003 | validation: 0.4535233044213368]
	TIME [epoch: 3.72 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43277151715905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43277151715905 | validation: 0.43969581247914724]
	TIME [epoch: 3.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4253046108834325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4253046108834325 | validation: 0.43744453952205814]
	TIME [epoch: 3.72 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43178785547336923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43178785547336923 | validation: 0.40013441473097944]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.437842786060505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.437842786060505 | validation: 0.6415167675134691]
	TIME [epoch: 3.72 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5267334066174822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5267334066174822 | validation: 0.8111819987882485]
	TIME [epoch: 3.72 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7189143032843964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7189143032843964 | validation: 0.48681111301238345]
	TIME [epoch: 3.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.559678466896378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.559678466896378 | validation: 0.49658366084998545]
	TIME [epoch: 3.72 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5132918520141433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5132918520141433 | validation: 0.4125139981871903]
	TIME [epoch: 3.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4539670936556236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4539670936556236 | validation: 0.6266214255903663]
	TIME [epoch: 3.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5570859303579434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5570859303579434 | validation: 0.5456678278964456]
	TIME [epoch: 3.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5971165329021105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5971165329021105 | validation: 0.4813588911265632]
	TIME [epoch: 3.73 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5030678509980008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5030678509980008 | validation: 0.41205473055431335]
	TIME [epoch: 3.72 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4521565060429585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4521565060429585 | validation: 0.3965063250339497]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4477217327958576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4477217327958576 | validation: 0.5018343858514177]
	TIME [epoch: 3.73 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4488705802316258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4488705802316258 | validation: 0.43261204672291953]
	TIME [epoch: 3.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46899592132094287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46899592132094287 | validation: 0.5045996778314973]
	TIME [epoch: 3.72 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4484204360485731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4484204360485731 | validation: 0.3865145032339172]
	TIME [epoch: 3.73 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4357329277943214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4357329277943214 | validation: 0.4367524989737396]
	TIME [epoch: 3.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40946258552073433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40946258552073433 | validation: 0.3761012105924863]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3996222115566047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3996222115566047 | validation: 0.4327692916939643]
	TIME [epoch: 3.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41012347386302295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41012347386302295 | validation: 0.3755245107866494]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4342331737249046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4342331737249046 | validation: 0.5091382475757936]
	TIME [epoch: 3.73 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4504988057782162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4504988057782162 | validation: 0.4463423443202141]
	TIME [epoch: 3.72 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4788446178108618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4788446178108618 | validation: 0.4026138944642945]
	TIME [epoch: 3.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39322859944031846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39322859944031846 | validation: 0.3401378302199078]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3695726432553937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3695726432553937 | validation: 0.3361039541164115]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3555883112772078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3555883112772078 | validation: 0.3449586274877219]
	TIME [epoch: 3.72 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35860910283406683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35860910283406683 | validation: 0.32497883202991046]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35416708718260437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35416708718260437 | validation: 0.4196983946066368]
	TIME [epoch: 3.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37608015826710645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37608015826710645 | validation: 0.6338903019201225]
	TIME [epoch: 3.72 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5641683645390227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5641683645390227 | validation: 0.4371495264704983]
	TIME [epoch: 3.72 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4449570051170458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4449570051170458 | validation: 0.39433483126945257]
	TIME [epoch: 3.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39340263355551514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39340263355551514 | validation: 0.3580079306571782]
	TIME [epoch: 3.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3850147682690313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3850147682690313 | validation: 0.44607996227620045]
	TIME [epoch: 3.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4083596681237419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4083596681237419 | validation: 0.35468602692615736]
	TIME [epoch: 3.72 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3969918972164905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3969918972164905 | validation: 0.353664847171914]
	TIME [epoch: 3.72 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35091998138781094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35091998138781094 | validation: 0.30933463778869935]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3466557095000441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3466557095000441 | validation: 0.3584175265012419]
	TIME [epoch: 3.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3438184545893339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3438184545893339 | validation: 0.3224979100536158]
	TIME [epoch: 3.71 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3641750973902305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3641750973902305 | validation: 0.385357648546227]
	TIME [epoch: 3.72 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3530942100222329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3530942100222329 | validation: 0.35873163326010543]
	TIME [epoch: 3.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.388317426050776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.388317426050776 | validation: 0.4226808516324397]
	TIME [epoch: 3.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3620092098045242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3620092098045242 | validation: 0.34548551567357966]
	TIME [epoch: 3.72 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37147474468238384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37147474468238384 | validation: 0.35861355745496903]
	TIME [epoch: 3.72 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33314506702121777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33314506702121777 | validation: 0.2816234599681566]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31971990492519087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31971990492519087 | validation: 0.3050121772141071]
	TIME [epoch: 3.73 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30792280662549454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30792280662549454 | validation: 0.29220816656345877]
	TIME [epoch: 3.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3162876186806433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162876186806433 | validation: 0.3555102478483093]
	TIME [epoch: 3.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3329158169611341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3329158169611341 | validation: 0.3601852127167626]
	TIME [epoch: 3.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39310045425187395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39310045425187395 | validation: 0.42546355382911083]
	TIME [epoch: 3.71 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37425505158274985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37425505158274985 | validation: 0.339272778020136]
	TIME [epoch: 3.71 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3600264826070307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3600264826070307 | validation: 0.31810820256224726]
	TIME [epoch: 3.71 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30667227327875973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30667227327875973 | validation: 0.27268214195094304]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2919155323573976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2919155323573976 | validation: 0.3249407929355722]
	TIME [epoch: 3.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3085976904132924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3085976904132924 | validation: 0.32756321478324485]
	TIME [epoch: 3.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3580267469695943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3580267469695943 | validation: 0.37115951971254546]
	TIME [epoch: 3.72 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33452465926771874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33452465926771874 | validation: 0.3117005379228694]
	TIME [epoch: 3.72 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3200721363405134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3200721363405134 | validation: 0.34137262762016785]
	TIME [epoch: 3.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2973464993762775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2973464993762775 | validation: 0.3392693144791485]
	TIME [epoch: 3.71 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35111127564284944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35111127564284944 | validation: 0.323051315236631]
	TIME [epoch: 3.71 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28418793189975794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28418793189975794 | validation: 0.28551046020968845]
	TIME [epoch: 3.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2629019982134826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2629019982134826 | validation: 0.2845454518525498]
	TIME [epoch: 3.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25877655422638285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25877655422638285 | validation: 0.27433927374351186]
	TIME [epoch: 3.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24527938539418678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24527938539418678 | validation: 0.287365712845293]
	TIME [epoch: 3.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25053338089935084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25053338089935084 | validation: 0.3335237029925129]
	TIME [epoch: 3.71 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31471925374226045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31471925374226045 | validation: 1.1618538876480222]
	TIME [epoch: 3.71 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8027488804329065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8027488804329065 | validation: 0.4544999585654389]
	TIME [epoch: 3.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44053027905751974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44053027905751974 | validation: 0.49542401323767304]
	TIME [epoch: 3.72 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4595711273562072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4595711273562072 | validation: 0.38400331100947116]
	TIME [epoch: 3.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39411534003439386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39411534003439386 | validation: 0.28078574100007575]
	TIME [epoch: 3.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2668798006560345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2668798006560345 | validation: 0.33730882134979967]
	TIME [epoch: 3.72 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28775277279997513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28775277279997513 | validation: 0.28950544026935693]
	TIME [epoch: 3.71 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2643249383295377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2643249383295377 | validation: 0.2829374598157676]
	TIME [epoch: 3.71 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24812669004988158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24812669004988158 | validation: 0.28949255929730444]
	TIME [epoch: 3.71 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25026054748815574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25026054748815574 | validation: 0.26728972895134956]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23897717220022166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23897717220022166 | validation: 0.282074429461335]
	TIME [epoch: 3.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23510785892248745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23510785892248745 | validation: 0.26596496029232836]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22930299045424535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22930299045424535 | validation: 0.2880175390977121]
	TIME [epoch: 3.72 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2278877421716118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2278877421716118 | validation: 0.25934060988820423]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23383249404156417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23383249404156417 | validation: 0.3466167628258532]
	TIME [epoch: 3.71 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.257353048518544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.257353048518544 | validation: 0.33113651239206887]
	TIME [epoch: 3.72 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3126655090900838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3126655090900838 | validation: 0.4229729002353997]
	TIME [epoch: 3.73 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29765782294222676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29765782294222676 | validation: 0.3365731490550794]
	TIME [epoch: 3.71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32707240309052876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32707240309052876 | validation: 0.2958110923598472]
	TIME [epoch: 3.71 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2342416106922149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2342416106922149 | validation: 0.25849662492219355]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24224933269099425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24224933269099425 | validation: 0.30314612639726596]
	TIME [epoch: 3.71 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24488504755468563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24488504755468563 | validation: 0.2669157014552212]
	TIME [epoch: 3.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21070382138544724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21070382138544724 | validation: 0.25025303036781293]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21774622246556277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21774622246556277 | validation: 0.29043068973501673]
	TIME [epoch: 3.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20743893137169853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20743893137169853 | validation: 0.2548395175535541]
	TIME [epoch: 3.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2078574398325177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2078574398325177 | validation: 0.2951398465555852]
	TIME [epoch: 3.71 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20666600228304643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20666600228304643 | validation: 0.3142011141285507]
	TIME [epoch: 3.71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28524959662929533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28524959662929533 | validation: 0.4340644499128445]
	TIME [epoch: 3.72 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2834646158089026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2834646158089026 | validation: 0.40047617486088627]
	TIME [epoch: 3.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.364619340354502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.364619340354502 | validation: 0.2862677044515037]
	TIME [epoch: 3.71 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23885644089413638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23885644089413638 | validation: 0.31562948287530923]
	TIME [epoch: 3.72 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2603537122488023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2603537122488023 | validation: 0.28968021056276244]
	TIME [epoch: 3.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2612105650243595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2612105650243595 | validation: 0.25912157116148116]
	TIME [epoch: 3.71 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19494659594785696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19494659594785696 | validation: 0.28291623259135873]
	TIME [epoch: 3.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2133825865574432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2133825865574432 | validation: 0.2542425043486807]
	TIME [epoch: 3.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2204761026105672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2204761026105672 | validation: 0.26508571620711435]
	TIME [epoch: 3.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1921358288829039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1921358288829039 | validation: 0.29109609810860054]
	TIME [epoch: 3.71 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20305276965059374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20305276965059374 | validation: 0.27724796750375]
	TIME [epoch: 3.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20140040668411643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20140040668411643 | validation: 0.2542959348475266]
	TIME [epoch: 3.71 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19011026063369507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19011026063369507 | validation: 0.2637368967878443]
	TIME [epoch: 3.71 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19557537863755894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19557537863755894 | validation: 0.2645995176706764]
	TIME [epoch: 3.72 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2195635660161453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2195635660161453 | validation: 0.33874354201435253]
	TIME [epoch: 3.71 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26205296123923455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26205296123923455 | validation: 0.44832548161142366]
	TIME [epoch: 3.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3726318752684973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3726318752684973 | validation: 0.5816163936690438]
	TIME [epoch: 3.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4349103506269338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4349103506269338 | validation: 0.3196461540548084]
	TIME [epoch: 3.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2613545041797692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2613545041797692 | validation: 0.3560748471284331]
	TIME [epoch: 3.71 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3057024066261689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3057024066261689 | validation: 0.24513778103785527]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19470226813888508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19470226813888508 | validation: 0.2825705224469583]
	TIME [epoch: 3.72 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21213890967580284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21213890967580284 | validation: 0.24436375105113323]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19853753501145524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19853753501145524 | validation: 0.25161231826687763]
	TIME [epoch: 3.71 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1851298787123647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1851298787123647 | validation: 0.23876185424866603]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17787244789057874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17787244789057874 | validation: 0.24749982194116035]
	TIME [epoch: 3.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18587676018416094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18587676018416094 | validation: 0.2659636533953402]
	TIME [epoch: 3.72 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1919969699004774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1919969699004774 | validation: 0.24474433902920023]
	TIME [epoch: 3.72 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17698098957994435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17698098957994435 | validation: 0.2813535599137924]
	TIME [epoch: 3.72 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17910969993135564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17910969993135564 | validation: 0.2997019722086781]
	TIME [epoch: 3.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23537029633927473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23537029633927473 | validation: 0.2863968318809215]
	TIME [epoch: 3.72 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20033297859117633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20033297859117633 | validation: 0.28708464439102327]
	TIME [epoch: 3.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24965952201461158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24965952201461158 | validation: 0.2968051204068859]
	TIME [epoch: 3.72 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2147831841321253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2147831841321253 | validation: 0.27541267268263464]
	TIME [epoch: 3.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.200900717305464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.200900717305464 | validation: 0.298274844561812]
	TIME [epoch: 3.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22699297230236545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22699297230236545 | validation: 0.32107355211019556]
	TIME [epoch: 3.72 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2830417587880888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2830417587880888 | validation: 0.30235469239665]
	TIME [epoch: 3.72 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21964533478580348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21964533478580348 | validation: 0.24447848940887937]
	TIME [epoch: 3.72 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18311364446986503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18311364446986503 | validation: 0.23196389945447501]
	TIME [epoch: 3.73 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16354918495383078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16354918495383078 | validation: 0.24571234938115769]
	TIME [epoch: 3.72 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16772580280238525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16772580280238525 | validation: 0.2409677343746239]
	TIME [epoch: 3.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17005454775600523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17005454775600523 | validation: 0.2629564201948175]
	TIME [epoch: 3.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1574289219860618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1574289219860618 | validation: 0.2517258019075989]
	TIME [epoch: 3.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16491128819960307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16491128819960307 | validation: 0.42775404775160597]
	TIME [epoch: 3.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27195515392193675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27195515392193675 | validation: 0.35633136123149234]
	TIME [epoch: 3.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29151079887584364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29151079887584364 | validation: 0.2293787153283563]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17826241831518086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17826241831518086 | validation: 0.23556738788428655]
	TIME [epoch: 3.71 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24852290547401543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24852290547401543 | validation: 0.32024415950161195]
	TIME [epoch: 3.72 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.305567668013651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.305567668013651 | validation: 0.2638805742613498]
	TIME [epoch: 3.72 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2037412051142478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2037412051142478 | validation: 0.22274671208270727]
	TIME [epoch: 3.73 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18512017538052689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18512017538052689 | validation: 0.27033874546912023]
	TIME [epoch: 3.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2059138396681585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2059138396681585 | validation: 0.2570213954751701]
	TIME [epoch: 3.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19814390407124177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19814390407124177 | validation: 0.23287815128459055]
	TIME [epoch: 3.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1715877317145193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1715877317145193 | validation: 0.2967197598275827]
	TIME [epoch: 3.72 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21426780655463368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21426780655463368 | validation: 0.2601357415520829]
	TIME [epoch: 3.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21678351267924098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21678351267924098 | validation: 0.25423135696783783]
	TIME [epoch: 3.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18092779282541277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18092779282541277 | validation: 0.24706538464738426]
	TIME [epoch: 3.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1632011075243794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1632011075243794 | validation: 0.22784814777407997]
	TIME [epoch: 3.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15486886349398432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15486886349398432 | validation: 0.24468252641891317]
	TIME [epoch: 3.71 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16419036846703386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16419036846703386 | validation: 0.2494186650373038]
	TIME [epoch: 3.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16693931977738452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16693931977738452 | validation: 0.24254258596074318]
	TIME [epoch: 3.72 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1749478116449605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1749478116449605 | validation: 0.25710732606124237]
	TIME [epoch: 3.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17478609088202493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17478609088202493 | validation: 0.2501378156030289]
	TIME [epoch: 3.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17850900850219698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17850900850219698 | validation: 0.2787977693509575]
	TIME [epoch: 3.72 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1848249593149222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1848249593149222 | validation: 0.2711225729753432]
	TIME [epoch: 3.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1957759691675246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1957759691675246 | validation: 0.35987222137390346]
	TIME [epoch: 3.71 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24878710580922167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24878710580922167 | validation: 0.2616771939973922]
	TIME [epoch: 3.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24932542145870432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24932542145870432 | validation: 0.3425602900722014]
	TIME [epoch: 3.72 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3062120994659254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3062120994659254 | validation: 0.2572912142968619]
	TIME [epoch: 3.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20884143772425431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20884143772425431 | validation: 0.228959613421494]
	TIME [epoch: 3.72 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20058146729759518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20058146729759518 | validation: 0.2330427149429416]
	TIME [epoch: 3.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17013262819891067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17013262819891067 | validation: 0.2284924346873375]
	TIME [epoch: 3.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15607378734117572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15607378734117572 | validation: 0.2281636976465784]
	TIME [epoch: 3.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16393945489284792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16393945489284792 | validation: 0.2192391322753232]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15305477429671063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15305477429671063 | validation: 0.22846911737876072]
	TIME [epoch: 3.73 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15548038678579845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15548038678579845 | validation: 0.24158871006978988]
	TIME [epoch: 3.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1728879341649479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1728879341649479 | validation: 0.2532520075543702]
	TIME [epoch: 3.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18055174116984746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18055174116984746 | validation: 0.2894183958981369]
	TIME [epoch: 3.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23218516251846916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23218516251846916 | validation: 0.2148221496021333]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13786927133014848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13786927133014848 | validation: 0.23524171479487932]
	TIME [epoch: 3.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1567916990801338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1567916990801338 | validation: 0.2214378029519981]
	TIME [epoch: 3.71 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15431981843064904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15431981843064904 | validation: 0.23861821357382632]
	TIME [epoch: 3.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1864399803004416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1864399803004416 | validation: 0.2858948092984626]
	TIME [epoch: 3.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2363068357107117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2363068357107117 | validation: 0.239860882155594]
	TIME [epoch: 3.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15329621575067578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15329621575067578 | validation: 0.5508810262447192]
	TIME [epoch: 3.71 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36097417328188647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36097417328188647 | validation: 0.3760057258449905]
	TIME [epoch: 3.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3146416155150437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3146416155150437 | validation: 0.3283663756597445]
	TIME [epoch: 3.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26505749405634677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26505749405634677 | validation: 0.22189174477023244]
	TIME [epoch: 3.73 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1872767934690262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1872767934690262 | validation: 0.20356036842517586]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19984060772074677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19984060772074677 | validation: 0.22110374625330517]
	TIME [epoch: 3.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1816843019978052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1816843019978052 | validation: 0.24497853718485718]
	TIME [epoch: 3.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18720641429212265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18720641429212265 | validation: 0.22336002268571706]
	TIME [epoch: 3.71 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1784593529287057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1784593529287057 | validation: 0.19994306719253552]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14219807943974513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14219807943974513 | validation: 0.1941514668313774]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13610140382997798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13610140382997798 | validation: 0.189912518635892]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.133130813343982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.133130813343982 | validation: 0.19176820087502358]
	TIME [epoch: 3.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13146704318272887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13146704318272887 | validation: 0.19258748278609794]
	TIME [epoch: 3.72 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12696213420007013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12696213420007013 | validation: 0.1841300911445136]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11655401908204617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11655401908204617 | validation: 0.18865803727711125]
	TIME [epoch: 3.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12484704462942897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12484704462942897 | validation: 0.31207716668764107]
	TIME [epoch: 3.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27561094795574886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27561094795574886 | validation: 0.26770634905545787]
	TIME [epoch: 3.73 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21356832756520014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21356832756520014 | validation: 0.2641292179175667]
	TIME [epoch: 3.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21864279661271022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21864279661271022 | validation: 0.23001189210643608]
	TIME [epoch: 3.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14517501906396404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14517501906396404 | validation: 0.18025761138687568]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12496899351395023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12496899351395023 | validation: 0.21234026016562774]
	TIME [epoch: 3.71 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15372766033867835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15372766033867835 | validation: 0.24624420035629538]
	TIME [epoch: 3.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19596562495330155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19596562495330155 | validation: 0.37776975621908937]
	TIME [epoch: 3.72 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31203045991922745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31203045991922745 | validation: 0.2579763593656336]
	TIME [epoch: 3.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20377624659428933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20377624659428933 | validation: 0.4014958915180822]
	TIME [epoch: 3.72 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34650705967591294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34650705967591294 | validation: 0.20240518287534598]
	TIME [epoch: 3.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1441272871694341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1441272871694341 | validation: 0.24617861022605847]
	TIME [epoch: 3.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17241773582655423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17241773582655423 | validation: 0.2271880454182565]
	TIME [epoch: 3.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.152628712687726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.152628712687726 | validation: 0.19549704420268293]
	TIME [epoch: 3.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13897865976456772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13897865976456772 | validation: 0.2004636783367899]
	TIME [epoch: 3.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1404871662702972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1404871662702972 | validation: 0.1954365289028524]
	TIME [epoch: 3.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1384368042578192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1384368042578192 | validation: 0.2094783991529049]
	TIME [epoch: 3.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13805327904455467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13805327904455467 | validation: 0.21244396605365684]
	TIME [epoch: 3.71 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1596812879567176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1596812879567176 | validation: 0.23999453051117414]
	TIME [epoch: 3.71 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16252825843322183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16252825843322183 | validation: 0.2012907882106025]
	TIME [epoch: 3.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15002107797623687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15002107797623687 | validation: 0.18420648764854033]
	TIME [epoch: 3.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11616504256939475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11616504256939475 | validation: 0.19606113910128997]
	TIME [epoch: 3.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14609832450309188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14609832450309188 | validation: 0.2941462315056626]
	TIME [epoch: 3.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28714464693083586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28714464693083586 | validation: 0.2209184101559455]
	TIME [epoch: 3.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16674125134503612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16674125134503612 | validation: 0.2772781782076602]
	TIME [epoch: 3.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2530840943858075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2530840943858075 | validation: 0.3814263851418749]
	TIME [epoch: 3.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39758983606435094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39758983606435094 | validation: 0.4467558387133981]
	TIME [epoch: 3.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38816450660216445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38816450660216445 | validation: 0.7463324112134092]
	TIME [epoch: 3.72 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7332576819842995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7332576819842995 | validation: 0.4810678292672057]
	TIME [epoch: 3.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.651038280478993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.651038280478993 | validation: 0.4958712790491604]
	TIME [epoch: 3.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5854443613886636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5854443613886636 | validation: 0.3987704388281138]
	TIME [epoch: 3.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42927445795252994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42927445795252994 | validation: 0.35431953576927616]
	TIME [epoch: 3.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36722886427410517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36722886427410517 | validation: 0.2716294815624874]
	TIME [epoch: 3.72 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29467273921898113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29467273921898113 | validation: 0.27006357548232424]
	TIME [epoch: 3.71 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2821142797548121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2821142797548121 | validation: 0.2572391174319619]
	TIME [epoch: 3.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.252038717463586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.252038717463586 | validation: 0.23247940567607023]
	TIME [epoch: 3.71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22651832538614103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22651832538614103 | validation: 0.1674450363371178]
	TIME [epoch: 3.71 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20261424748417456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20261424748417456 | validation: 0.1491950271542016]
	TIME [epoch: 3.72 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19690368940577763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19690368940577763 | validation: 0.2226553245256768]
	TIME [epoch: 3.74 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19946160704966212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19946160704966212 | validation: 0.15987551119742904]
	TIME [epoch: 3.72 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17715132333207467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17715132333207467 | validation: 0.7334235277952551]
	TIME [epoch: 3.73 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6830953928931763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6830953928931763 | validation: 0.8291133672842608]
	TIME [epoch: 3.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6040484081518624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6040484081518624 | validation: 1.0683679663367807]
	TIME [epoch: 3.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.785733706445055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.785733706445055 | validation: 1.1108408332146205]
	TIME [epoch: 3.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8668328765085299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8668328765085299 | validation: 1.1282050274065079]
	TIME [epoch: 3.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8977971958000244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8977971958000244 | validation: 1.051519184343601]
	TIME [epoch: 3.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7710587085446354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7710587085446354 | validation: 0.8668742940953131]
	TIME [epoch: 3.71 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6084438308901661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6084438308901661 | validation: 0.5169268768619294]
	TIME [epoch: 3.71 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3842712866942586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3842712866942586 | validation: 0.24325220011250545]
	TIME [epoch: 3.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28363880575414047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28363880575414047 | validation: 0.23283522569640916]
	TIME [epoch: 3.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2716677297069378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2716677297069378 | validation: 0.1957873555881361]
	TIME [epoch: 3.71 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2106933236905272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2106933236905272 | validation: 0.1954739556513487]
	TIME [epoch: 3.72 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20153869334142915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20153869334142915 | validation: 0.19069764174397374]
	TIME [epoch: 3.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18075167515887366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18075167515887366 | validation: 0.19169583691317468]
	TIME [epoch: 3.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1687788351250196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1687788351250196 | validation: 0.18362996239914048]
	TIME [epoch: 3.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15464070413966763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15464070413966763 | validation: 0.1788355182479767]
	TIME [epoch: 3.71 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14572461923601973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14572461923601973 | validation: 0.17914168631245347]
	TIME [epoch: 3.71 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14196546922598127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14196546922598127 | validation: 0.17829147377405394]
	TIME [epoch: 3.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13853549217543923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13853549217543923 | validation: 0.17809594235755483]
	TIME [epoch: 3.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13679476865561033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13679476865561033 | validation: 0.16845244381482366]
	TIME [epoch: 3.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13067128934075817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13067128934075817 | validation: 0.18100967343673774]
	TIME [epoch: 3.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.129432074320632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.129432074320632 | validation: 0.18055395059503895]
	TIME [epoch: 3.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1208182219198371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1208182219198371 | validation: 0.17872240696363428]
	TIME [epoch: 3.71 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1195504833132382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1195504833132382 | validation: 0.18934452121096676]
	TIME [epoch: 3.71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12095527223809444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12095527223809444 | validation: 0.23035440410577462]
	TIME [epoch: 3.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.158845949099564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.158845949099564 | validation: 0.3151779723714126]
	TIME [epoch: 3.73 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29922378611176087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29922378611176087 | validation: 0.28113849851486744]
	TIME [epoch: 3.71 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22049280725289877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22049280725289877 | validation: 0.1999940229087136]
	TIME [epoch: 3.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14091193306846606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14091193306846606 | validation: 0.19649387537963492]
	TIME [epoch: 3.71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14938626975502756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14938626975502756 | validation: 0.21140720571940955]
	TIME [epoch: 3.71 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1391707901252919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1391707901252919 | validation: 0.16175213619148093]
	TIME [epoch: 3.71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12491732754357411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12491732754357411 | validation: 0.17208610546683722]
	TIME [epoch: 3.71 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12141442959285492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12141442959285492 | validation: 0.1600520353180963]
	TIME [epoch: 3.71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10999192413661706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10999192413661706 | validation: 0.16396120851323837]
	TIME [epoch: 3.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10568742893591938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10568742893591938 | validation: 0.16993597587459863]
	TIME [epoch: 3.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11047247962774912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11047247962774912 | validation: 0.19415546588339083]
	TIME [epoch: 3.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12272948907844398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12272948907844398 | validation: 0.1595999036358395]
	TIME [epoch: 3.71 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11692653007226107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11692653007226107 | validation: 0.18527162194085134]
	TIME [epoch: 3.72 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14472304163327507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14472304163327507 | validation: 0.18582129651641935]
	TIME [epoch: 3.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14766088771522254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14766088771522254 | validation: 0.23884909292363124]
	TIME [epoch: 3.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18376864374455745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18376864374455745 | validation: 0.24183512382362463]
	TIME [epoch: 3.72 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1805284976805656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1805284976805656 | validation: 0.19129664344004912]
	TIME [epoch: 3.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16281755760794753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16281755760794753 | validation: 0.23446675727624094]
	TIME [epoch: 3.71 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19068992771387502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19068992771387502 | validation: 0.17523208429588785]
	TIME [epoch: 3.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11380089963418524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11380089963418524 | validation: 0.16196093777272377]
	TIME [epoch: 3.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11574923037988817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11574923037988817 | validation: 0.15669557087442043]
	TIME [epoch: 3.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1027522153005863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1027522153005863 | validation: 0.15071285526391032]
	TIME [epoch: 3.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09236235359614493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09236235359614493 | validation: 0.15247902711295558]
	TIME [epoch: 30.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09053741178823568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09053741178823568 | validation: 0.150210210950389]
	TIME [epoch: 8.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09203235623231937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09203235623231937 | validation: 0.21065605405784488]
	TIME [epoch: 8.08 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14283819515268126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14283819515268126 | validation: 0.298357339129331]
	TIME [epoch: 8.08 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2643608560309106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2643608560309106 | validation: 0.27429789675254423]
	TIME [epoch: 8.07 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.212790027814901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.212790027814901 | validation: 0.25583776614696235]
	TIME [epoch: 8.11 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19658217168564107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19658217168564107 | validation: 0.18091927218373832]
	TIME [epoch: 8.07 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12657127328543588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12657127328543588 | validation: 0.17676762244428668]
	TIME [epoch: 8.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12678833381167512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12678833381167512 | validation: 0.19220061978543246]
	TIME [epoch: 8.07 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13486746736867983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13486746736867983 | validation: 0.16450194545117824]
	TIME [epoch: 8.09 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12457964164944357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12457964164944357 | validation: 0.1965018549671966]
	TIME [epoch: 8.09 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12678618208033243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12678618208033243 | validation: 0.1627136212367009]
	TIME [epoch: 8.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14701585511599388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14701585511599388 | validation: 0.2456281344746592]
	TIME [epoch: 8.08 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.189119301748772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.189119301748772 | validation: 0.1969997332990431]
	TIME [epoch: 8.09 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1422375582103207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1422375582103207 | validation: 0.18084634491600063]
	TIME [epoch: 8.08 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13653901118324885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13653901118324885 | validation: 0.15809315276310443]
	TIME [epoch: 8.09 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11751840430173857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11751840430173857 | validation: 0.15816310347217502]
	TIME [epoch: 8.09 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10632521480259233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10632521480259233 | validation: 0.14089408900871986]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10284237853044853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10284237853044853 | validation: 0.16367806753605058]
	TIME [epoch: 8.09 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10442954849536407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10442954849536407 | validation: 0.13783534539391895]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09765224217736464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09765224217736464 | validation: 0.21052921990452786]
	TIME [epoch: 8.08 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15974328695599735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15974328695599735 | validation: 0.18718534742316725]
	TIME [epoch: 8.09 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13897330009432649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13897330009432649 | validation: 0.2202505574914309]
	TIME [epoch: 8.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2220482076681006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2220482076681006 | validation: 0.20225500136679672]
	TIME [epoch: 8.08 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1499820229872247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1499820229872247 | validation: 0.1428816182327275]
	TIME [epoch: 8.08 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1012280024516672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1012280024516672 | validation: 0.16566760089414762]
	TIME [epoch: 8.08 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16291405425352318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16291405425352318 | validation: 0.5377043281050463]
	TIME [epoch: 8.09 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4423318952266746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4423318952266746 | validation: 0.6235564277787007]
	TIME [epoch: 8.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5033961813231425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5033961813231425 | validation: 0.3179172924229312]
	TIME [epoch: 8.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3073369821054536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3073369821054536 | validation: 0.2586291634488697]
	TIME [epoch: 8.09 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22613018026790968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22613018026790968 | validation: 0.2392080801014645]
	TIME [epoch: 8.09 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21009521020994307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21009521020994307 | validation: 0.2210181538486491]
	TIME [epoch: 8.09 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20099852624552342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20099852624552342 | validation: 0.2040564509134813]
	TIME [epoch: 8.09 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1495462711133901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1495462711133901 | validation: 0.209506514818332]
	TIME [epoch: 8.09 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15521278652487625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15521278652487625 | validation: 0.2593364039896891]
	TIME [epoch: 8.09 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18193353748141525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18193353748141525 | validation: 0.30163267359359386]
	TIME [epoch: 8.08 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25598590502744695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25598590502744695 | validation: 0.17641873434376099]
	TIME [epoch: 8.09 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14199094151108882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14199094151108882 | validation: 0.1860053718250202]
	TIME [epoch: 8.08 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13389669343083646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13389669343083646 | validation: 0.2058044453671248]
	TIME [epoch: 8.09 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14925986862581592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14925986862581592 | validation: 0.20741404098092203]
	TIME [epoch: 8.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15450312358956783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15450312358956783 | validation: 0.24073614042660918]
	TIME [epoch: 8.09 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19881072901873034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19881072901873034 | validation: 0.1696906025837535]
	TIME [epoch: 8.09 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11858262679177152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11858262679177152 | validation: 0.1806148884895422]
	TIME [epoch: 8.08 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12295425262699597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12295425262699597 | validation: 0.14333528447195537]
	TIME [epoch: 8.07 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09626285423913462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09626285423913462 | validation: 0.15204985814053815]
	TIME [epoch: 8.08 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10165344269222891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10165344269222891 | validation: 0.13791849892328037]
	TIME [epoch: 8.09 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10938536708250475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10938536708250475 | validation: 0.1641325146397794]
	TIME [epoch: 8.08 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10980809499700253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10980809499700253 | validation: 0.19763108686555825]
	TIME [epoch: 8.09 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13121419672424103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13121419672424103 | validation: 0.18925620976330332]
	TIME [epoch: 8.08 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12381701760872614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12381701760872614 | validation: 0.19020770808376286]
	TIME [epoch: 8.09 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13372993761789137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13372993761789137 | validation: 0.1569191994177885]
	TIME [epoch: 8.08 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10221801120870572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10221801120870572 | validation: 0.14855935120567673]
	TIME [epoch: 8.09 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12813376105871951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12813376105871951 | validation: 0.13485876308718575]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12683659490974633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12683659490974633 | validation: 0.2735230161207638]
	TIME [epoch: 8.07 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2184207647773043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2184207647773043 | validation: 0.2825429706158377]
	TIME [epoch: 8.08 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22751424920887148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22751424920887148 | validation: 0.33508412571815616]
	TIME [epoch: 8.08 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3430572871449024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3430572871449024 | validation: 0.15790690289488354]
	TIME [epoch: 8.09 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10421539783528816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10421539783528816 | validation: 0.24797562949240506]
	TIME [epoch: 8.08 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1770131281820034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1770131281820034 | validation: 0.18146722487201872]
	TIME [epoch: 8.08 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12913584305414058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12913584305414058 | validation: 0.12715037931492507]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12356491527130707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12356491527130707 | validation: 0.13919072937714497]
	TIME [epoch: 8.07 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11182514242213679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11182514242213679 | validation: 0.12631205166689263]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08966273243227324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08966273243227324 | validation: 0.13958982111111945]
	TIME [epoch: 8.09 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08894309963984229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08894309963984229 | validation: 0.11683481762703439]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07496688519419563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07496688519419563 | validation: 0.1208129380995223]
	TIME [epoch: 8.09 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07682550449650831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07682550449650831 | validation: 0.13035663136072148]
	TIME [epoch: 8.08 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08094044561882693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08094044561882693 | validation: 0.12285037941015148]
	TIME [epoch: 8.09 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1015525445432775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1015525445432775 | validation: 0.3266239983739845]
	TIME [epoch: 8.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29946677298727564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29946677298727564 | validation: 0.31526140627593735]
	TIME [epoch: 8.09 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33865543479414084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33865543479414084 | validation: 0.2391981696492921]
	TIME [epoch: 8.08 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.272761371258091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.272761371258091 | validation: 0.20061107371961404]
	TIME [epoch: 8.08 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16545338711698318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16545338711698318 | validation: 0.14802370788089073]
	TIME [epoch: 8.07 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10789786209630166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10789786209630166 | validation: 0.14305611813880592]
	TIME [epoch: 8.09 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0924784969394521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0924784969394521 | validation: 0.13536702558200178]
	TIME [epoch: 8.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0849341822127737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0849341822127737 | validation: 0.1343706326090773]
	TIME [epoch: 8.09 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07918406641580962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07918406641580962 | validation: 0.15420980525729708]
	TIME [epoch: 8.08 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07823615112344041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07823615112344041 | validation: 0.12713916853312127]
	TIME [epoch: 8.08 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08739755638957256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08739755638957256 | validation: 0.1853133094519674]
	TIME [epoch: 8.08 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11870698402780107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11870698402780107 | validation: 0.13414538293505093]
	TIME [epoch: 8.09 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08375247599430888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08375247599430888 | validation: 0.13115908349712643]
	TIME [epoch: 8.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08662641967841476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08662641967841476 | validation: 0.24790735549201204]
	TIME [epoch: 8.09 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20220473651679163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20220473651679163 | validation: 0.2768998380542866]
	TIME [epoch: 8.08 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20597908319363267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20597908319363267 | validation: 0.17637563601858242]
	TIME [epoch: 8.08 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.150995554918037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.150995554918037 | validation: 0.18801336090949167]
	TIME [epoch: 8.09 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13998723413507752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13998723413507752 | validation: 0.14052154718441043]
	TIME [epoch: 8.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09049339044572559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09049339044572559 | validation: 0.296668584285655]
	TIME [epoch: 8.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3203004956706912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3203004956706912 | validation: 0.1783490261878137]
	TIME [epoch: 8.08 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15465372149418088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15465372149418088 | validation: 0.18496760685205663]
	TIME [epoch: 8.1 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1297241374865013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1297241374865013 | validation: 0.17544388468435013]
	TIME [epoch: 8.08 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12018978221866558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12018978221866558 | validation: 0.16696137794387728]
	TIME [epoch: 8.09 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10956079687917233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10956079687917233 | validation: 0.1642294191364463]
	TIME [epoch: 8.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09413096330243144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09413096330243144 | validation: 0.14367451065199166]
	TIME [epoch: 8.09 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07259487681677411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07259487681677411 | validation: 0.1417333916323595]
	TIME [epoch: 8.09 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06929022479772345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06929022479772345 | validation: 0.151206715356191]
	TIME [epoch: 8.09 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07069690681371052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07069690681371052 | validation: 0.15129700261331114]
	TIME [epoch: 8.08 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08066677206029846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08066677206029846 | validation: 0.24817711064444953]
	TIME [epoch: 8.09 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18751947375049216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18751947375049216 | validation: 0.1822401136310993]
	TIME [epoch: 8.09 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14575834707278038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14575834707278038 | validation: 0.1733248092893063]
	TIME [epoch: 8.08 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12714959107253518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12714959107253518 | validation: 0.16644891930766864]
	TIME [epoch: 8.08 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09559323553015261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09559323553015261 | validation: 0.17243618952013107]
	TIME [epoch: 8.07 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10783398721724387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10783398721724387 | validation: 0.1708942953226549]
	TIME [epoch: 8.07 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14305485780385238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14305485780385238 | validation: 0.2192383885226434]
	TIME [epoch: 8.09 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15116034640995493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15116034640995493 | validation: 0.17951118596733284]
	TIME [epoch: 8.08 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1178227250590264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1178227250590264 | validation: 0.2138909406881222]
	TIME [epoch: 8.06 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23004455309009098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23004455309009098 | validation: 0.13580999340846053]
	TIME [epoch: 8.07 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10168089337533787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10168089337533787 | validation: 0.14568428591080043]
	TIME [epoch: 8.07 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11359166925976158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11359166925976158 | validation: 0.1666077959082066]
	TIME [epoch: 8.07 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10054228720450196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10054228720450196 | validation: 0.11703444889363311]
	TIME [epoch: 8.08 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0881736593772083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0881736593772083 | validation: 0.13659993595445083]
	TIME [epoch: 8.07 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08626165553801485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08626165553801485 | validation: 0.14374201347427867]
	TIME [epoch: 8.08 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09774599079814919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09774599079814919 | validation: 0.16007511280612913]
	TIME [epoch: 8.07 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13004481597537326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13004481597537326 | validation: 0.15917670579364832]
	TIME [epoch: 8.08 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11348034541790092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11348034541790092 | validation: 0.1139091963109344]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07103511440295161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07103511440295161 | validation: 0.11883011825271295]
	TIME [epoch: 8.07 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06398925048358166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06398925048358166 | validation: 0.1207626264228186]
	TIME [epoch: 8.12 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06332986719497334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06332986719497334 | validation: 0.12202061266743514]
	TIME [epoch: 8.06 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07871046024066827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07871046024066827 | validation: 0.24054710734553253]
	TIME [epoch: 8.05 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17071255354068027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17071255354068027 | validation: 0.23659964540081957]
	TIME [epoch: 8.04 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18634058396087716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18634058396087716 | validation: 0.17110544400773928]
	TIME [epoch: 8.05 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13523292225997133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13523292225997133 | validation: 0.11309015029640478]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08602218905494731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08602218905494731 | validation: 0.10314836130274818]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06384016760368319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06384016760368319 | validation: 0.09079545935324397]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06700655682189983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06700655682189983 | validation: 0.1299725522011023]
	TIME [epoch: 8.05 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0798352712760664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0798352712760664 | validation: 0.10631408579900029]
	TIME [epoch: 8.05 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08167075693769484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08167075693769484 | validation: 0.24828808783670456]
	TIME [epoch: 8.07 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16885086233697624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16885086233697624 | validation: 0.1978974508857831]
	TIME [epoch: 8.04 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12391843253582956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12391843253582956 | validation: 0.14597183051697904]
	TIME [epoch: 8.04 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12150188921865927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12150188921865927 | validation: 0.16492368804759272]
	TIME [epoch: 8.04 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12276749022843472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12276749022843472 | validation: 0.1373722577663839]
	TIME [epoch: 8.05 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1063743058624291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1063743058624291 | validation: 0.0875635252293178]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0705175800734535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0705175800734535 | validation: 0.11530479592395332]
	TIME [epoch: 8.09 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07837964699617751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07837964699617751 | validation: 0.08667349885550708]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054102837050290446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054102837050290446 | validation: 0.0881822755240248]
	TIME [epoch: 8.04 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04996831117841028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04996831117841028 | validation: 0.0970316644874758]
	TIME [epoch: 8.04 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05305344063818801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05305344063818801 | validation: 0.10897934392716452]
	TIME [epoch: 8.04 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06498792318286879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06498792318286879 | validation: 0.12348685185265165]
	TIME [epoch: 8.06 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10224918297984353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10224918297984353 | validation: 0.306655430041185]
	TIME [epoch: 8.06 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21725831923831046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21725831923831046 | validation: 0.21431710416216118]
	TIME [epoch: 8.04 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18864796540644624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18864796540644624 | validation: 0.18961601876135467]
	TIME [epoch: 8.04 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1826335605212048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1826335605212048 | validation: 0.179186371178601]
	TIME [epoch: 8.03 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16356581433576836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16356581433576836 | validation: 0.1422833844605574]
	TIME [epoch: 8.04 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10738826639770173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10738826639770173 | validation: 0.12172430839175614]
	TIME [epoch: 8.04 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08066711149427679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08066711149427679 | validation: 0.12856194854172046]
	TIME [epoch: 8.05 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08536100301990589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08536100301990589 | validation: 0.13075817262876616]
	TIME [epoch: 8.03 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08648816867224308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08648816867224308 | validation: 0.0998430346102712]
	TIME [epoch: 8.04 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06073003959866121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06073003959866121 | validation: 0.08053946828098633]
	TIME [epoch: 8.03 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_646.pth
	Model improved!!!
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05862314957180635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05862314957180635 | validation: 0.1450115267075027]
	TIME [epoch: 8.09 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0891983107823064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0891983107823064 | validation: 0.09329313859158064]
	TIME [epoch: 8.09 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0683607327479915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0683607327479915 | validation: 0.11133842298070462]
	TIME [epoch: 8.08 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06636462425877057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06636462425877057 | validation: 0.09023623586588207]
	TIME [epoch: 8.07 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057002771014288134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057002771014288134 | validation: 0.24523739749421805]
	TIME [epoch: 8.08 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2753698530436316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2753698530436316 | validation: 0.17260839719850424]
	TIME [epoch: 8.07 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15359999769789462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15359999769789462 | validation: 0.12259758904785951]
	TIME [epoch: 8.08 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09571071129006367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09571071129006367 | validation: 0.10029012271746628]
	TIME [epoch: 8.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09042845535096042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09042845535096042 | validation: 0.07405705065332084]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06270532845071926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06270532845071926 | validation: 0.0897057346505647]
	TIME [epoch: 8.06 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06130411815503797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06130411815503797 | validation: 0.06988482264933636]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_657.pth
	Model improved!!!
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05662642577515491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05662642577515491 | validation: 0.07547376821705827]
	TIME [epoch: 8.07 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04564462315105588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04564462315105588 | validation: 0.09318946696149166]
	TIME [epoch: 8.08 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056736971921041185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056736971921041185 | validation: 0.13705077217009173]
	TIME [epoch: 8.07 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10114396374638757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10114396374638757 | validation: 0.21148826044936084]
	TIME [epoch: 8.07 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18325295395084826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18325295395084826 | validation: 0.1465457708233731]
	TIME [epoch: 8.06 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12891454864283527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12891454864283527 | validation: 0.0847857444927936]
	TIME [epoch: 8.07 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06025491411625579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06025491411625579 | validation: 0.13243691583296485]
	TIME [epoch: 8.07 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10446553152353864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10446553152353864 | validation: 0.16692978527365768]
	TIME [epoch: 8.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1419205382335164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1419205382335164 | validation: 0.11061499901705552]
	TIME [epoch: 8.07 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0746473631253372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0746473631253372 | validation: 0.08621372188410108]
	TIME [epoch: 8.07 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057228130739610326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057228130739610326 | validation: 0.0725378363369563]
	TIME [epoch: 8.06 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05479614295064289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05479614295064289 | validation: 0.08241763006829748]
	TIME [epoch: 8.06 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06376088796060062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06376088796060062 | validation: 0.07290898397048101]
	TIME [epoch: 8.08 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05082801921239561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05082801921239561 | validation: 0.08139919619528092]
	TIME [epoch: 8.09 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055060489722147984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055060489722147984 | validation: 0.08432926659585023]
	TIME [epoch: 8.07 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06255230958594225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06255230958594225 | validation: 0.11553554743182226]
	TIME [epoch: 8.08 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08814383133082343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08814383133082343 | validation: 0.14091293564350102]
	TIME [epoch: 8.07 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11523938733207889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11523938733207889 | validation: 0.12569613113878517]
	TIME [epoch: 8.09 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1031560958835388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1031560958835388 | validation: 0.10386632611115867]
	TIME [epoch: 8.08 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08220257046942983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08220257046942983 | validation: 0.1075518077180418]
	TIME [epoch: 8.09 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1213726444835851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1213726444835851 | validation: 0.17349526113871205]
	TIME [epoch: 8.07 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11691444941335614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11691444941335614 | validation: 0.11561247252896703]
	TIME [epoch: 8.08 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.086269530024764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.086269530024764 | validation: 0.08071403803611127]
	TIME [epoch: 8.07 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0615507853970167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0615507853970167 | validation: 0.06270892573404124]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_681.pth
	Model improved!!!
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06816979519807205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06816979519807205 | validation: 0.062204471066219916]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054611889169093736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054611889169093736 | validation: 0.08500228019385576]
	TIME [epoch: 8.09 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09541687115314648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09541687115314648 | validation: 0.09718175524059368]
	TIME [epoch: 8.08 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06951943070783193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06951943070783193 | validation: 0.08165642841777815]
	TIME [epoch: 8.08 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06369059906904628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06369059906904628 | validation: 0.10474571288786061]
	TIME [epoch: 8.09 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08193470035372956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08193470035372956 | validation: 0.13166527584658577]
	TIME [epoch: 8.08 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12510298637208744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12510298637208744 | validation: 0.1412787161982631]
	TIME [epoch: 8.08 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12594058480229242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12594058480229242 | validation: 0.08493581763202632]
	TIME [epoch: 8.07 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0659422511010099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0659422511010099 | validation: 0.07167154950438108]
	TIME [epoch: 8.07 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049112148447988474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049112148447988474 | validation: 0.06747800696295833]
	TIME [epoch: 8.07 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07291897879195923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07291897879195923 | validation: 0.08946131986290673]
	TIME [epoch: 8.07 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07584012359446449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07584012359446449 | validation: 0.06826973120753795]
	TIME [epoch: 8.08 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046899452492852434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046899452492852434 | validation: 0.05296057592154057]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039669678407374696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039669678407374696 | validation: 0.07034673288820152]
	TIME [epoch: 8.07 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042297218997262055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042297218997262055 | validation: 0.07746473574490265]
	TIME [epoch: 8.08 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06249297030912639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06249297030912639 | validation: 0.13611559148175947]
	TIME [epoch: 8.08 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10328347974411269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10328347974411269 | validation: 0.12004746401997296]
	TIME [epoch: 8.08 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10891267262827597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10891267262827597 | validation: 0.17137784482763405]
	TIME [epoch: 8.09 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1664206435256063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1664206435256063 | validation: 0.07571508407782915]
	TIME [epoch: 8.08 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07762789765655237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07762789765655237 | validation: 0.063066075762974]
	TIME [epoch: 8.08 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04950301282083313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04950301282083313 | validation: 0.06704542919360057]
	TIME [epoch: 8.07 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0429942139716464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0429942139716464 | validation: 0.060573350490916084]
	TIME [epoch: 8.08 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05556646457275759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05556646457275759 | validation: 0.13534471877320972]
	TIME [epoch: 8.09 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09233232406326618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09233232406326618 | validation: 0.2558481822572336]
	TIME [epoch: 8.09 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15659049323588117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15659049323588117 | validation: 0.10286403254178987]
	TIME [epoch: 8.07 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07897443621463608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07897443621463608 | validation: 0.13177230937571882]
	TIME [epoch: 8.08 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09930209139123271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09930209139123271 | validation: 0.10788361915209087]
	TIME [epoch: 8.07 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07770876495487947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07770876495487947 | validation: 0.08909391316810139]
	TIME [epoch: 8.08 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07310273153809659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07310273153809659 | validation: 0.0905362420945161]
	TIME [epoch: 8.08 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06965521292085121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06965521292085121 | validation: 0.09369244960211821]
	TIME [epoch: 8.09 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08386887209598079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08386887209598079 | validation: 0.1013873536680954]
	TIME [epoch: 8.08 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07654963631726436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07654963631726436 | validation: 0.0989376511770951]
	TIME [epoch: 8.07 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07034093388191189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07034093388191189 | validation: 0.07870242383936059]
	TIME [epoch: 8.07 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04424275601325185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04424275601325185 | validation: 0.06911455684702839]
	TIME [epoch: 8.07 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037152736041305194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037152736041305194 | validation: 0.05920513172843757]
	TIME [epoch: 8.09 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05290993795300621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05290993795300621 | validation: 0.12272602302794106]
	TIME [epoch: 8.08 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09046019934443533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09046019934443533 | validation: 0.10184548885596839]
	TIME [epoch: 8.07 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08039300709895976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08039300709895976 | validation: 0.10194945498750158]
	TIME [epoch: 8.07 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06795544630284801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06795544630284801 | validation: 0.08560934861062487]
	TIME [epoch: 8.06 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0585025218686962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0585025218686962 | validation: 0.07825044863096686]
	TIME [epoch: 8.08 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07508396333622754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07508396333622754 | validation: 0.09296050476947747]
	TIME [epoch: 8.08 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09750163959771196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09750163959771196 | validation: 0.08346591938933916]
	TIME [epoch: 8.07 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07753442260381958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07753442260381958 | validation: 0.07904744474879181]
	TIME [epoch: 8.07 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0719717593000059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0719717593000059 | validation: 0.07996952022518672]
	TIME [epoch: 8.08 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06712040340571965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06712040340571965 | validation: 0.04847263123079576]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033461898234849956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033461898234849956 | validation: 0.057829490480667815]
	TIME [epoch: 8.09 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03842480787703643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03842480787703643 | validation: 0.06752599210085428]
	TIME [epoch: 8.08 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04800938452785299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04800938452785299 | validation: 0.16129140115613297]
	TIME [epoch: 8.07 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1408499517065499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1408499517065499 | validation: 0.15200012462513268]
	TIME [epoch: 8.07 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1458268501279761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1458268501279761 | validation: 0.09836907169930814]
	TIME [epoch: 8.08 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07930840957453049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07930840957453049 | validation: 0.04942302535846729]
	TIME [epoch: 8.08 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04054737302734443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04054737302734443 | validation: 0.04757327441440532]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041033618908308755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041033618908308755 | validation: 0.04760661593886922]
	TIME [epoch: 8.06 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030898237761483243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030898237761483243 | validation: 0.048033070044213255]
	TIME [epoch: 8.06 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03606433690432403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03606433690432403 | validation: 0.05328084959961328]
	TIME [epoch: 8.06 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03350546055873951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03350546055873951 | validation: 0.05524414401577139]
	TIME [epoch: 8.06 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043618812008021486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043618812008021486 | validation: 0.11428260512468631]
	TIME [epoch: 8.07 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09274300438307073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09274300438307073 | validation: 0.07556430460440909]
	TIME [epoch: 8.07 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07465010569943266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07465010569943266 | validation: 0.09127871525181426]
	TIME [epoch: 8.06 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07130575045164092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07130575045164092 | validation: 0.07794960576272693]
	TIME [epoch: 8.05 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07221720435281181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07221720435281181 | validation: 0.1064908139612031]
	TIME [epoch: 8.05 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09311234441297453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09311234441297453 | validation: 0.15414711413763044]
	TIME [epoch: 8.05 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15915253376298696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15915253376298696 | validation: 0.09417687343718315]
	TIME [epoch: 8.08 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08193156808110519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08193156808110519 | validation: 0.05911561218524254]
	TIME [epoch: 8.07 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060030168920516616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060030168920516616 | validation: 0.11140835069572481]
	TIME [epoch: 8.07 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09221303598202632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09221303598202632 | validation: 0.058246356718830807]
	TIME [epoch: 8.06 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0381220973016422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0381220973016422 | validation: 0.05023748818914845]
	TIME [epoch: 8.05 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04121865627039401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04121865627039401 | validation: 0.05972840409969976]
	TIME [epoch: 8.07 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043533593053698215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043533593053698215 | validation: 0.0535802600266196]
	TIME [epoch: 8.07 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05825127750131559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05825127750131559 | validation: 0.09587850718618507]
	TIME [epoch: 8.06 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0749905979131071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0749905979131071 | validation: 0.06514442258523956]
	TIME [epoch: 8.05 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0522156479486012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0522156479486012 | validation: 0.06500302455594392]
	TIME [epoch: 8.04 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052481174673220485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052481174673220485 | validation: 0.07192711396114622]
	TIME [epoch: 8.05 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07218868316875428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07218868316875428 | validation: 0.11840955219155087]
	TIME [epoch: 8.06 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1130352262267936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1130352262267936 | validation: 0.1305232746450737]
	TIME [epoch: 8.07 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11363336697250585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11363336697250585 | validation: 0.07092474607614131]
	TIME [epoch: 8.05 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048209096780383404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048209096780383404 | validation: 0.0508188464279683]
	TIME [epoch: 8.05 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05066504876791139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05066504876791139 | validation: 0.09124250795378402]
	TIME [epoch: 8.05 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08250015310841954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08250015310841954 | validation: 0.04752943960245112]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_760.pth
	Model improved!!!
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04464778713714322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04464778713714322 | validation: 0.06304581738523453]
	TIME [epoch: 8.07 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048945900354196346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048945900354196346 | validation: 0.051023756416515964]
	TIME [epoch: 8.06 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04873161228446543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04873161228446543 | validation: 0.05112400297724634]
	TIME [epoch: 8.06 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049117977440933165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049117977440933165 | validation: 0.05093649296757399]
	TIME [epoch: 8.07 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05112385897404938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05112385897404938 | validation: 0.06362183849479813]
	TIME [epoch: 8.05 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052430468834860994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052430468834860994 | validation: 0.10465874741431742]
	TIME [epoch: 8.07 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0925718044149317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0925718044149317 | validation: 0.17187393443411136]
	TIME [epoch: 8.07 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15796415053384188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15796415053384188 | validation: 0.10121999892929948]
	TIME [epoch: 8.07 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08549040556735323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08549040556735323 | validation: 0.043291701327486325]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03355198223394814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03355198223394814 | validation: 0.042942841444494]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02908131927310296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02908131927310296 | validation: 0.06449815244931717]
	TIME [epoch: 8.07 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04708101305525303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04708101305525303 | validation: 0.06399821495697122]
	TIME [epoch: 8.09 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05874455183018654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05874455183018654 | validation: 0.06744715990010851]
	TIME [epoch: 8.08 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06554132296524047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06554132296524047 | validation: 0.06323719743705941]
	TIME [epoch: 8.07 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05496591847446688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05496591847446688 | validation: 0.04502915574015709]
	TIME [epoch: 8.06 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03525835459308033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03525835459308033 | validation: 0.03584359916370724]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025705314463916423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025705314463916423 | validation: 0.05065937644661336]
	TIME [epoch: 8.05 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04018310196545551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04018310196545551 | validation: 0.09443578989362475]
	TIME [epoch: 8.08 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08524468469890728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08524468469890728 | validation: 0.09727215566285838]
	TIME [epoch: 8.07 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08195500505338739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08195500505338739 | validation: 0.10976046939047442]
	TIME [epoch: 8.07 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11334866707993854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11334866707993854 | validation: 0.1522092032060542]
	TIME [epoch: 8.06 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14363168763407033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14363168763407033 | validation: 0.12628526560291695]
	TIME [epoch: 8.05 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0975011437668286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0975011437668286 | validation: 0.09363195915267825]
	TIME [epoch: 8.07 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0612312814765029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0612312814765029 | validation: 0.04640663547446951]
	TIME [epoch: 8.08 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02890073089486216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02890073089486216 | validation: 0.04571381410326785]
	TIME [epoch: 8.07 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039334251471979526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039334251471979526 | validation: 0.07950863425437484]
	TIME [epoch: 8.05 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05236966102055665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05236966102055665 | validation: 0.0757193353550295]
	TIME [epoch: 8.06 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06046372954850912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06046372954850912 | validation: 0.08370159554167426]
	TIME [epoch: 8.06 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06274889423150015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06274889423150015 | validation: 0.06022413060684748]
	TIME [epoch: 8.08 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0450658655824833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0450658655824833 | validation: 0.06885178586157312]
	TIME [epoch: 8.07 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05377637666014138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05377637666014138 | validation: 0.08416742203291261]
	TIME [epoch: 8.06 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0794290523139335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0794290523139335 | validation: 0.09357990378654764]
	TIME [epoch: 8.06 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07285311955771288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07285311955771288 | validation: 0.06025967271017624]
	TIME [epoch: 8.06 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05082973991742511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05082973991742511 | validation: 0.05166310410121551]
	TIME [epoch: 8.06 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037334530971858494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037334530971858494 | validation: 0.04807049077171352]
	TIME [epoch: 8.08 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043083844108363786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043083844108363786 | validation: 0.064136619782048]
	TIME [epoch: 8.08 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05682954154065778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05682954154065778 | validation: 0.08874028548716335]
	TIME [epoch: 8.08 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07917966965623686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07917966965623686 | validation: 0.12207877482819873]
	TIME [epoch: 8.06 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11434845442757804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11434845442757804 | validation: 0.07403981355242939]
	TIME [epoch: 8.06 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06670973117966661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06670973117966661 | validation: 0.07504465501591318]
	TIME [epoch: 8.07 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051811189025224275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051811189025224275 | validation: 0.04086897727067951]
	TIME [epoch: 8.08 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03789221029210757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03789221029210757 | validation: 0.038600837590136695]
	TIME [epoch: 8.06 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03738408727571527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03738408727571527 | validation: 0.0675143523674623]
	TIME [epoch: 8.05 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05247103963133996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05247103963133996 | validation: 0.05005246808917091]
	TIME [epoch: 8.06 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04266491475570498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04266491475570498 | validation: 0.049309284247725384]
	TIME [epoch: 8.05 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039813125169230544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039813125169230544 | validation: 0.06593502471453545]
	TIME [epoch: 8.08 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054155249243086824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054155249243086824 | validation: 0.0843160460527999]
	TIME [epoch: 8.07 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08579908560269264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08579908560269264 | validation: 0.11014083199815888]
	TIME [epoch: 8.08 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09602500320957472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09602500320957472 | validation: 0.07064170150515668]
	TIME [epoch: 8.06 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0633990214757809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0633990214757809 | validation: 0.050922451606082844]
	TIME [epoch: 8.08 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03748337974580288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03748337974580288 | validation: 0.04691558281696974]
	TIME [epoch: 8.05 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033686647753101505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033686647753101505 | validation: 0.04751612887238227]
	TIME [epoch: 8.08 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04336365313604967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04336365313604967 | validation: 0.15019744782627406]
	TIME [epoch: 8.08 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1581171311587765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1581171311587765 | validation: 0.23529667245904942]
	TIME [epoch: 8.08 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2114007563246562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2114007563246562 | validation: 0.25876557053739496]
	TIME [epoch: 8.07 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15774572224552894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15774572224552894 | validation: 0.15999847525314573]
	TIME [epoch: 8.07 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09937441761213511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09937441761213511 | validation: 0.0923677422280626]
	TIME [epoch: 8.07 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06796882195833742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06796882195833742 | validation: 0.057407883984934495]
	TIME [epoch: 8.11 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05954385086478434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05954385086478434 | validation: 0.06175709049193069]
	TIME [epoch: 8.07 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0559582359726145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0559582359726145 | validation: 0.0607840938070349]
	TIME [epoch: 8.08 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05795216180734997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05795216180734997 | validation: 0.062268976916994845]
	TIME [epoch: 8.07 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059127094389537296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059127094389537296 | validation: 0.08470542215965239]
	TIME [epoch: 8.08 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08592488550333713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08592488550333713 | validation: 0.08498595965836492]
	TIME [epoch: 8.07 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07682000652183683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07682000652183683 | validation: 0.0678378253828028]
	TIME [epoch: 8.09 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05035964885476675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05035964885476675 | validation: 0.055252799766886365]
	TIME [epoch: 8.08 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038227758622001104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038227758622001104 | validation: 0.05787254696291604]
	TIME [epoch: 8.07 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046194857347312296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046194857347312296 | validation: 0.05581078374268172]
	TIME [epoch: 8.04 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04304982176404917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04304982176404917 | validation: 0.058499856967354984]
	TIME [epoch: 8.05 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039010106807158135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039010106807158135 | validation: 0.056745836097212524]
	TIME [epoch: 8.05 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033925569044791784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033925569044791784 | validation: 0.05492594242508408]
	TIME [epoch: 8.07 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04172808659645806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04172808659645806 | validation: 0.06642624872185098]
	TIME [epoch: 8.04 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06297661639363408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06297661639363408 | validation: 0.11268545077711177]
	TIME [epoch: 8.05 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09091256575661623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09091256575661623 | validation: 0.09140803650762293]
	TIME [epoch: 8.04 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07581859613122953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07581859613122953 | validation: 0.07143007957279816]
	TIME [epoch: 8.06 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04654149372525128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04654149372525128 | validation: 0.04804659730903398]
	TIME [epoch: 8.05 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02996362155546956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02996362155546956 | validation: 0.057491455200278443]
	TIME [epoch: 8.06 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033157035985164784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033157035985164784 | validation: 0.04582864357906852]
	TIME [epoch: 8.04 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03513845305163924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03513845305163924 | validation: 0.07332742297840344]
	TIME [epoch: 8.06 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06803091898002522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06803091898002522 | validation: 0.06730970285665248]
	TIME [epoch: 8.05 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05070014067495654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05070014067495654 | validation: 0.04611557658879722]
	TIME [epoch: 8.06 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036556126920272505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036556126920272505 | validation: 0.03624237278963205]
	TIME [epoch: 8.06 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027098447866624825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027098447866624825 | validation: 0.039359178172526516]
	TIME [epoch: 8.07 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030894005785629508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030894005785629508 | validation: 0.06535213353524126]
	TIME [epoch: 8.05 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04718611006254881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04718611006254881 | validation: 0.10181091970929297]
	TIME [epoch: 8.06 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08258723149717287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08258723149717287 | validation: 0.13886840030371336]
	TIME [epoch: 8.04 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12736053782091633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12736053782091633 | validation: 0.10395577472771694]
	TIME [epoch: 8.07 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12348904086463927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12348904086463927 | validation: 0.047181252414690594]
	TIME [epoch: 8.08 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04426438205681292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04426438205681292 | validation: 0.04991528530184896]
	TIME [epoch: 8.06 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07127724112552981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07127724112552981 | validation: 0.06236251272477821]
	TIME [epoch: 8.07 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06825741387934679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06825741387934679 | validation: 0.0765142069971301]
	TIME [epoch: 8.07 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06148630926350387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06148630926350387 | validation: 0.04548175636686032]
	TIME [epoch: 8.09 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04390363860067662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04390363860067662 | validation: 0.03864034425394694]
	TIME [epoch: 8.06 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03248358288926072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03248358288926072 | validation: 0.049627269456263404]
	TIME [epoch: 8.08 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04004696357762862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04004696357762862 | validation: 0.039450480309902884]
	TIME [epoch: 8.07 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037738838565567506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037738838565567506 | validation: 0.03702181437381154]
	TIME [epoch: 8.07 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0388910327055464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0388910327055464 | validation: 0.07400977836231179]
	TIME [epoch: 8.05 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05865709511287322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05865709511287322 | validation: 0.09167545885877883]
	TIME [epoch: 8.07 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07890845292148725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07890845292148725 | validation: 0.10068376751379593]
	TIME [epoch: 8.07 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07967279350251301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07967279350251301 | validation: 0.09517674346822443]
	TIME [epoch: 8.08 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0916634879871695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0916634879871695 | validation: 0.08049188426579909]
	TIME [epoch: 8.05 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08616963951755711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08616963951755711 | validation: 0.04885018020962095]
	TIME [epoch: 8.07 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0380694915038207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0380694915038207 | validation: 0.03756998106383032]
	TIME [epoch: 8.06 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030450589659197416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030450589659197416 | validation: 0.05898017538823726]
	TIME [epoch: 8.08 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05355374292445641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05355374292445641 | validation: 0.08003050149561441]
	TIME [epoch: 8.06 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07262978808803613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07262978808803613 | validation: 0.044840225107726395]
	TIME [epoch: 8.07 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.040401757808167585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.040401757808167585 | validation: 0.04346343957093366]
	TIME [epoch: 8.07 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03464591041099317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03464591041099317 | validation: 0.038002465670263566]
	TIME [epoch: 8.07 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03178699219633518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03178699219633518 | validation: 0.036902667079044195]
	TIME [epoch: 8.08 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026850623239711595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026850623239711595 | validation: 0.03929304472249302]
	TIME [epoch: 8.07 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025791756817935246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025791756817935246 | validation: 0.05518725835699091]
	TIME [epoch: 8.06 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04790048168623631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04790048168623631 | validation: 0.15161489018630167]
	TIME [epoch: 8.06 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1317261081475342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1317261081475342 | validation: 0.11289286410995364]
	TIME [epoch: 8.06 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11042616321461629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11042616321461629 | validation: 0.08313492406011458]
	TIME [epoch: 8.06 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06897573995546152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06897573995546152 | validation: 0.05015990805430305]
	TIME [epoch: 8.07 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0548856952391444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0548856952391444 | validation: 0.04433408098586487]
	TIME [epoch: 8.07 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04663655330351313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04663655330351313 | validation: 0.04184006122247528]
	TIME [epoch: 8.07 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04153750437383009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04153750437383009 | validation: 0.028904830534120143]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20240823_172338/states/model_phi1_3b_v_mmd1_877.pth
	Model improved!!!
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 4703.934 seconds.
