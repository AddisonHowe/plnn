Args:
Namespace(name='model_phi1_1b_v_mmd1', outdir='out/model_training/model_phi1_1b_v_mmd1', training_data='data/training_data/data_phi1_1b/training', validation_data='data/training_data/data_phi1_1b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1819533654

Training model...

Saving initial model state to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72326361780089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.72326361780089 | validation: 5.502198497569417]
	TIME [epoch: 136 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995213033035877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.995213033035877 | validation: 4.756779270279434]
	TIME [epoch: 46.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537771798672509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.537771798672509 | validation: 4.332363510321734]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.17500422308482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.17500422308482 | validation: 4.064364922737347]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.233584744436448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.233584744436448 | validation: 4.372569320109076]
	TIME [epoch: 46.1 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9996274847957585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9996274847957585 | validation: 3.8494520939023014]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.743980047784898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.743980047784898 | validation: 3.763222996595896]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.705541299278061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.705541299278061 | validation: 4.260843405727654]
	TIME [epoch: 46.1 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.788382838259083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.788382838259083 | validation: 3.5930683505098537]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.455966467885745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.455966467885745 | validation: 3.481950939878477]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4266778184447237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4266778184447237 | validation: 3.663616301776214]
	TIME [epoch: 46 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3631302335045876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3631302335045876 | validation: 3.4359772337798553]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2458626276981093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2458626276981093 | validation: 3.3158919720716575]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2142806288863044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2142806288863044 | validation: 3.249430097107357]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0916349487301082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0916349487301082 | validation: 3.2200031046406465]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0673256836166782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0673256836166782 | validation: 3.076783902577458]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9307356114082337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9307356114082337 | validation: 3.115251377758007]
	TIME [epoch: 46.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9222068967365917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9222068967365917 | validation: 3.0527442340458855]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7891715112514905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7891715112514905 | validation: 2.9894488888007276]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803522766870585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.803522766870585 | validation: 2.7624649303059563]
	TIME [epoch: 46.2 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.647768672662787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.647768672662787 | validation: 3.06827743888888]
	TIME [epoch: 46.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6425392220797774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6425392220797774 | validation: 2.6584261046301956]
	TIME [epoch: 46.5 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5535082428971845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5535082428971845 | validation: 2.757981915728708]
	TIME [epoch: 46.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5191411940459263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5191411940459263 | validation: 2.603498237522194]
	TIME [epoch: 46.5 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435545377978163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.435545377978163 | validation: 2.558574554013699]
	TIME [epoch: 46.6 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398650480069285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.398650480069285 | validation: 2.474116085033365]
	TIME [epoch: 46.6 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338378728376562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.338378728376562 | validation: 2.443217245581992]
	TIME [epoch: 46.6 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371876763934911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.371876763934911 | validation: 2.395431716300827]
	TIME [epoch: 46.6 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2762083386157888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2762083386157888 | validation: 2.1619236865636307]
	TIME [epoch: 46.5 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.168929978310805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.168929978310805 | validation: 2.086886178746248]
	TIME [epoch: 46.5 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.009611723287059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.009611723287059 | validation: 1.7346371686281588]
	TIME [epoch: 46.5 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9835899411240405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9835899411240405 | validation: 1.545053049107264]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.859819529956153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.859819529956153 | validation: 1.548994607537535]
	TIME [epoch: 46.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6167158896464233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6167158896464233 | validation: 1.3063235272785843]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7385734449672212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7385734449672212 | validation: 1.5267189577408344]
	TIME [epoch: 46.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.665958839567852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.665958839567852 | validation: 1.454191920910377]
	TIME [epoch: 46.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3865366780737158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3865366780737158 | validation: 2.3188949682964526]
	TIME [epoch: 46.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.801012605090968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.801012605090968 | validation: 1.6589388920054224]
	TIME [epoch: 46.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5238272018113244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5238272018113244 | validation: 1.6045652187964174]
	TIME [epoch: 46.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368931661241256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.368931661241256 | validation: 1.9141464490517768]
	TIME [epoch: 46.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5213399406923327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5213399406923327 | validation: 1.2985448906769745]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294226933172472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.294226933172472 | validation: 1.0531959676772282]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3024699221788911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3024699221788911 | validation: 1.0493915688026267]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2304375794138633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2304375794138633 | validation: 1.2112631737050366]
	TIME [epoch: 46.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.639748224556388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.639748224556388 | validation: 1.2826043506981883]
	TIME [epoch: 46.3 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3246444013512868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3246444013512868 | validation: 0.8707509663282939]
	TIME [epoch: 46.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.800446497335469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.800446497335469 | validation: 1.0265868844350623]
	TIME [epoch: 46.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2706533372907811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2706533372907811 | validation: 1.3599285714182088]
	TIME [epoch: 46.4 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1167472416123108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1167472416123108 | validation: 3.0315528566956793]
	TIME [epoch: 46.4 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091314022276959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.091314022276959 | validation: 0.9441955413815442]
	TIME [epoch: 46.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382503750387684		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.382503750387684 | validation: 3.0612908261771627]
	TIME [epoch: 46.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.871734512575161		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.871734512575161 | validation: 1.7735797117700907]
	TIME [epoch: 46.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6268257298136557		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.6268257298136557 | validation: 1.1534248221230485]
	TIME [epoch: 46.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.171894700509321		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.171894700509321 | validation: 0.9253330346752962]
	TIME [epoch: 46.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9643134901815049		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.9643134901815049 | validation: 1.8523306457214206]
	TIME [epoch: 46.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9586557999888745		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.9586557999888745 | validation: 1.8898816264875529]
	TIME [epoch: 46.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.839117335243382		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.839117335243382 | validation: 1.2346712919748133]
	TIME [epoch: 46.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.334363919353817		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.334363919353817 | validation: 0.8789886475390767]
	TIME [epoch: 46.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9599684117081055		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.9599684117081055 | validation: 0.8250481000399659]
	TIME [epoch: 46.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9376420080495824		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.9376420080495824 | validation: 1.194747232308831]
	TIME [epoch: 46.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5266166224647346		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.5266166224647346 | validation: 1.533095015884031]
	TIME [epoch: 46.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3065070250889845		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.3065070250889845 | validation: 0.958991687211928]
	TIME [epoch: 46.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9697029659709704		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9697029659709704 | validation: 1.6001126773400425]
	TIME [epoch: 46.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4325103452290915		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.4325103452290915 | validation: 0.8275215119883257]
	TIME [epoch: 46.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3768339817179898		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.3768339817179898 | validation: 1.7666308616861994]
	TIME [epoch: 46.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.657476258065103		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.657476258065103 | validation: 1.024697911301451]
	TIME [epoch: 46.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9789637481697532		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.9789637481697532 | validation: 0.7262362106900218]
	TIME [epoch: 46.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504316761464412		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6504316761464412 | validation: 0.4901597645715787]
	TIME [epoch: 46.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184894237852461		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.5184894237852461 | validation: 1.1136835882241605]
	TIME [epoch: 46.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044847591558969		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.044847591558969 | validation: 1.1951048873500842]
	TIME [epoch: 46.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8130131767100269		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.8130131767100269 | validation: 0.4773124821206437]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.544789433880656		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.544789433880656 | validation: 0.4599661510560946]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5448651293072959		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5448651293072959 | validation: 0.5372212927416479]
	TIME [epoch: 46.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9534512786955904		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.9534512786955904 | validation: 0.42811333734263457]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8127610504675251		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.8127610504675251 | validation: 0.41405361187105083]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679324449205069		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.4679324449205069 | validation: 0.36146319526918747]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9581427303021135		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.9581427303021135 | validation: 2.024747836997247]
	TIME [epoch: 46.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.882542634386386		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.882542634386386 | validation: 1.6585227843782921]
	TIME [epoch: 46.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5387760686249417		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.5387760686249417 | validation: 1.4882003876601053]
	TIME [epoch: 46 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4308384329979909		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.4308384329979909 | validation: 0.8282765774494134]
	TIME [epoch: 46.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265754553679973		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.6265754553679973 | validation: 0.36531312191050747]
	TIME [epoch: 46.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5421838620820593		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5421838620820593 | validation: 0.40119713524874645]
	TIME [epoch: 46 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42476727554399896		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.42476727554399896 | validation: 0.3890696174991448]
	TIME [epoch: 46.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412896465750261		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.3412896465750261 | validation: 0.3843559764386991]
	TIME [epoch: 46 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902438673294004		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6902438673294004 | validation: 1.0247772502059624]
	TIME [epoch: 46.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6288851007591673		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6288851007591673 | validation: 0.34625362518013314]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4366310647959251		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4366310647959251 | validation: 0.47873966997401374]
	TIME [epoch: 46 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38597951135034003		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.38597951135034003 | validation: 0.2958496439704927]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557653162755906		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.2557653162755906 | validation: 0.2384498511532809]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234838986627068		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4234838986627068 | validation: 0.4218698035511682]
	TIME [epoch: 46.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38779095729649066		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.38779095729649066 | validation: 0.3497462552945918]
	TIME [epoch: 46.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605619032717862		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.8605619032717862 | validation: 0.28172316384300206]
	TIME [epoch: 46.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9185220490812969		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.9185220490812969 | validation: 0.5100812652932948]
	TIME [epoch: 46.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1023891137881412		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.1023891137881412 | validation: 0.43082387753036205]
	TIME [epoch: 46.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128940180494424		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.4128940180494424 | validation: 0.37517779821731634]
	TIME [epoch: 46.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198194189625616		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.3198194189625616 | validation: 0.9473489323985549]
	TIME [epoch: 46.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899823545254621		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6899823545254621 | validation: 0.44938690118288294]
	TIME [epoch: 46.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38421002573136664		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.38421002573136664 | validation: 0.427926395597859]
	TIME [epoch: 46.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158252607641144		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.3158252607641144 | validation: 0.5289066046074086]
	TIME [epoch: 46.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575144715349892		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.3575144715349892 | validation: 1.5983542623721516]
	TIME [epoch: 46.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.567441161297002		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.567441161297002 | validation: 0.8012151239813656]
	TIME [epoch: 46.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396746319171183		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5396746319171183 | validation: 0.3828472824520992]
	TIME [epoch: 46.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591256101625543		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.3591256101625543 | validation: 0.336394480483539]
	TIME [epoch: 46.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4203813040373689		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.4203813040373689 | validation: 0.3646615268500143]
	TIME [epoch: 46.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178241492743437		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.3178241492743437 | validation: 0.2558088743966014]
	TIME [epoch: 46.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29936764493418627		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.29936764493418627 | validation: 0.2700272749970046]
	TIME [epoch: 46.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27883312778825664		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.27883312778825664 | validation: 0.18780543811480715]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33104254886772283		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.33104254886772283 | validation: 0.2763212153411707]
	TIME [epoch: 46.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523031360620128		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.4523031360620128 | validation: 0.38545202854950733]
	TIME [epoch: 46.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437786763338943		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.4437786763338943 | validation: 0.30256566477404345]
	TIME [epoch: 46.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20423211913712686		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.20423211913712686 | validation: 0.20944167971825667]
	TIME [epoch: 46.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22645496391489628		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.22645496391489628 | validation: 0.19492937888824002]
	TIME [epoch: 46 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34435644834834117		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.34435644834834117 | validation: 0.38463632062505326]
	TIME [epoch: 46.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542517529364512		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.6542517529364512 | validation: 1.6878675802418532]
	TIME [epoch: 46.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2560866864220808		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.2560866864220808 | validation: 0.3993715060390918]
	TIME [epoch: 46.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30934601682446117		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.30934601682446117 | validation: 0.2572333769216032]
	TIME [epoch: 46.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036781799125969		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.2036781799125969 | validation: 0.2020122189835385]
	TIME [epoch: 46 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751695172228955		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.1751695172228955 | validation: 1.265827967411415]
	TIME [epoch: 46.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1847602487401274		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.1847602487401274 | validation: 0.48096387136868696]
	TIME [epoch: 46 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652972874972553		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.3652972874972553 | validation: 0.263245575689177]
	TIME [epoch: 46 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21641529208474544		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.21641529208474544 | validation: 0.21528000427292784]
	TIME [epoch: 46.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18192056072996662		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.18192056072996662 | validation: 0.17767900111917906]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15703629696631183		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.15703629696631183 | validation: 0.2806112558735428]
	TIME [epoch: 46.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24130451160449493		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.24130451160449493 | validation: 0.1746843115279978]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21393487268088912		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.21393487268088912 | validation: 0.17248011863001705]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402866077732512		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.14402866077732512 | validation: 0.18733351105991997]
	TIME [epoch: 46.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9729742358733675		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.9729742358733675 | validation: 0.9682235662647342]
	TIME [epoch: 46 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582993424761783		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6582993424761783 | validation: 0.29796352159928574]
	TIME [epoch: 46 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840067583960189		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.2840067583960189 | validation: 0.2037939698396028]
	TIME [epoch: 46 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18098424015578285		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.18098424015578285 | validation: 0.1825668166018773]
	TIME [epoch: 46 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384423112406613		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.1384423112406613 | validation: 0.15288901551679046]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13449072415319444		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.13449072415319444 | validation: 0.18722900671233167]
	TIME [epoch: 46 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16823254417127784		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.16823254417127784 | validation: 0.1670621438921031]
	TIME [epoch: 46 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478047479009788		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.1478047479009788 | validation: 0.21183730635628323]
	TIME [epoch: 46.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44443529052672187		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.44443529052672187 | validation: 0.3289095071553542]
	TIME [epoch: 46 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23085294042251503		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.23085294042251503 | validation: 0.16917816664984997]
	TIME [epoch: 46 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328129873733156		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.17328129873733156 | validation: 0.21245671719525122]
	TIME [epoch: 46.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146053698853599		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.2146053698853599 | validation: 0.2619076189541648]
	TIME [epoch: 46 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15560297621736674		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.15560297621736674 | validation: 0.24675775684406942]
	TIME [epoch: 46 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041290767756647		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3041290767756647 | validation: 0.345722370810844]
	TIME [epoch: 46 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289578312689886		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.289578312689886 | validation: 0.3688284804677646]
	TIME [epoch: 46 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880387163683518		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.2880387163683518 | validation: 0.37036958967750244]
	TIME [epoch: 46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23785735289341076		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.23785735289341076 | validation: 0.1611159034379117]
	TIME [epoch: 46.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12631113934153887		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.12631113934153887 | validation: 0.20248566132877743]
	TIME [epoch: 46 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062926487708767		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.15062926487708767 | validation: 0.13588623935974584]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480563933527115		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.1480563933527115 | validation: 0.15039397831288054]
	TIME [epoch: 46.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34943858939567046		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.34943858939567046 | validation: 0.1803617471810818]
	TIME [epoch: 46.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14420952459204112		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.14420952459204112 | validation: 0.13467509405062697]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058779186328876		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.10058779186328876 | validation: 0.12536588577505509]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301356552884122		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.1301356552884122 | validation: 0.18982766332808237]
	TIME [epoch: 46.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875129351255325		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.2875129351255325 | validation: 0.6688963733959716]
	TIME [epoch: 46.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590934315476885		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.0590934315476885 | validation: 0.3700761894255923]
	TIME [epoch: 46 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433289324962938		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3433289324962938 | validation: 0.3357113114634612]
	TIME [epoch: 46.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2436993621533574		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.2436993621533574 | validation: 0.15067008102617985]
	TIME [epoch: 46 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09493044563851571		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.09493044563851571 | validation: 0.24516925334232734]
	TIME [epoch: 46.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21783758824229799		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.21783758824229799 | validation: 0.2780610869266632]
	TIME [epoch: 46 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17687238068669733		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.17687238068669733 | validation: 0.12493135482537379]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09582913563309296		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.09582913563309296 | validation: 0.1469952345179008]
	TIME [epoch: 46 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603544859956708		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.08603544859956708 | validation: 0.11010760799501156]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802644444078901		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.08802644444078901 | validation: 0.12228733202968832]
	TIME [epoch: 46.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08581411311819737		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.08581411311819737 | validation: 0.10936172496910426]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11839691655609119		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.11839691655609119 | validation: 0.18081348887019016]
	TIME [epoch: 46.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11845045163872892		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.11845045163872892 | validation: 0.22060809882892168]
	TIME [epoch: 46.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17559793257313738		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.17559793257313738 | validation: 0.15192520360348552]
	TIME [epoch: 46.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805413032526525		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.12805413032526525 | validation: 0.11750858194002647]
	TIME [epoch: 46.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678763805898302		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.07678763805898302 | validation: 0.09976977207608123]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07267280660524		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.07267280660524 | validation: 0.15410446062272484]
	TIME [epoch: 46.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13420431769734714		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.13420431769734714 | validation: 0.1504810056922245]
	TIME [epoch: 46.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125749568288805		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.11125749568288805 | validation: 0.14233355219564386]
	TIME [epoch: 46.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14622469840485203		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.14622469840485203 | validation: 0.22386959796128622]
	TIME [epoch: 46 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815824212155506		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.16815824212155506 | validation: 0.32051543211316513]
	TIME [epoch: 46 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20821417085714325		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.20821417085714325 | validation: 0.8879788159063551]
	TIME [epoch: 46.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9136607396152002		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.9136607396152002 | validation: 0.20439511522414608]
	TIME [epoch: 46.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14155303530796767		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.14155303530796767 | validation: 0.09732450970514248]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716895058728369		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.06716895058728369 | validation: 0.0879909422183717]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594854049164534		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.06594854049164534 | validation: 0.10811692158226044]
	TIME [epoch: 46.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148891563954428		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.09148891563954428 | validation: 0.10455548894669126]
	TIME [epoch: 46.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08778455906117769		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.08778455906117769 | validation: 0.147913696673242]
	TIME [epoch: 46.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17781594123553562		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.17781594123553562 | validation: 0.09349699542504877]
	TIME [epoch: 46.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832431101939537		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.0832431101939537 | validation: 0.11171268781509032]
	TIME [epoch: 46.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202475484436293		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.13202475484436293 | validation: 0.17721997908353976]
	TIME [epoch: 46.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12603272134484367		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.12603272134484367 | validation: 0.19811743174807228]
	TIME [epoch: 46.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194521601102491		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.194521601102491 | validation: 0.1659144907362099]
	TIME [epoch: 46.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272632402460317		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.4272632402460317 | validation: 1.4929558498520816]
	TIME [epoch: 46.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.474323344425579		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.474323344425579 | validation: 0.35329420775232767]
	TIME [epoch: 46.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113945252794366		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3113945252794366 | validation: 0.12303761001841154]
	TIME [epoch: 46.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628887973094682		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.10628887973094682 | validation: 0.07933216063991964]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008615838515603		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.07008615838515603 | validation: 0.08842657701359383]
	TIME [epoch: 46.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061520890407650325		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.061520890407650325 | validation: 0.08303812910343816]
	TIME [epoch: 46 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553575826644863		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.08553575826644863 | validation: 0.07548019612305135]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07503661581485421		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.07503661581485421 | validation: 0.26341237326555694]
	TIME [epoch: 46 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26538125033111176		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.26538125033111176 | validation: 0.17456680061070823]
	TIME [epoch: 46 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575291399538652		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.12575291399538652 | validation: 0.19438650766110185]
	TIME [epoch: 46.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705798766984525		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.1705798766984525 | validation: 0.10442789615955517]
	TIME [epoch: 46 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644849967220255		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.09644849967220255 | validation: 0.10410712108048786]
	TIME [epoch: 46 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09383131469879827		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.09383131469879827 | validation: 0.09947337560499706]
	TIME [epoch: 46 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920463039351757		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.06920463039351757 | validation: 0.06973731210511862]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763281782761071		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.0763281782761071 | validation: 0.17024545089066656]
	TIME [epoch: 46 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911279894374445		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.10911279894374445 | validation: 0.08195435796939665]
	TIME [epoch: 46 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06481324847408124		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.06481324847408124 | validation: 0.12127568761795066]
	TIME [epoch: 46.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568887515056179		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.09568887515056179 | validation: 0.06603507897371635]
	TIME [epoch: 186 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11174075421317312		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.11174075421317312 | validation: 0.13270646746172304]
	TIME [epoch: 97.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157838809427873		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.09157838809427873 | validation: 0.08005773103121099]
	TIME [epoch: 97.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561252436685382		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.04561252436685382 | validation: 0.05617837315627836]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.090243348013397		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.090243348013397 | validation: 0.1216023244465079]
	TIME [epoch: 97.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910847870132909		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1910847870132909 | validation: 0.08966147173061947]
	TIME [epoch: 97.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06596800183141645		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.06596800183141645 | validation: 0.05879075883416737]
	TIME [epoch: 97.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0590983967315941		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.0590983967315941 | validation: 0.07340462552268769]
	TIME [epoch: 97.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04716838427699874		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.04716838427699874 | validation: 0.0683629204458692]
	TIME [epoch: 97.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384723210308725		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.07384723210308725 | validation: 0.0627246568157383]
	TIME [epoch: 97.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06868775072899361		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.06868775072899361 | validation: 0.05711886574408724]
	TIME [epoch: 97.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762846028837484		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.14762846028837484 | validation: 0.18751193290444576]
	TIME [epoch: 97.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489197883071636		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.1489197883071636 | validation: 0.058132392716571515]
	TIME [epoch: 97.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486765056720504		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.07486765056720504 | validation: 0.05662359014515495]
	TIME [epoch: 97.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07894084881532042		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.07894084881532042 | validation: 0.07794894268326558]
	TIME [epoch: 97.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756322761800363		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.0756322761800363 | validation: 0.056923529957669354]
	TIME [epoch: 97.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824172827346622		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.4824172827346622 | validation: 0.3398463038853146]
	TIME [epoch: 97.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23548255335517967		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.23548255335517967 | validation: 0.18847672366480533]
	TIME [epoch: 97.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104672265095488		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.13104672265095488 | validation: 0.05762842006655526]
	TIME [epoch: 97.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045536758835309075		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.045536758835309075 | validation: 0.05401442253137123]
	TIME [epoch: 97.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540572570524567		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.05540572570524567 | validation: 0.06605583284308335]
	TIME [epoch: 97.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058110508333201624		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.058110508333201624 | validation: 0.10342185005954042]
	TIME [epoch: 97.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384397030040092		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.07384397030040092 | validation: 0.05590214081658694]
	TIME [epoch: 97.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131042231501501		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.05131042231501501 | validation: 0.09124381722420413]
	TIME [epoch: 97.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271949263223882		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09271949263223882 | validation: 0.20101331297845865]
	TIME [epoch: 97.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20421765739300096		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.20421765739300096 | validation: 0.07636440599474237]
	TIME [epoch: 97.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318204752510981		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.04318204752510981 | validation: 0.054555054586398005]
	TIME [epoch: 97.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035718416392785036		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.035718416392785036 | validation: 0.04428121102301695]
	TIME [epoch: 97.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364632413094742		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.10364632413094742 | validation: 0.07035513797702744]
	TIME [epoch: 97.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647164855861954		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.0647164855861954 | validation: 0.07771686628110652]
	TIME [epoch: 97.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164346130424433		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.05164346130424433 | validation: 0.0705347898905511]
	TIME [epoch: 97.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930012450692053		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.04930012450692053 | validation: 0.045062845814114676]
	TIME [epoch: 97.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0379454928117878		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.0379454928117878 | validation: 0.10839723733669618]
	TIME [epoch: 97.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672721793611399		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.0672721793611399 | validation: 0.060835460382945725]
	TIME [epoch: 97.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05872912038461098		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.05872912038461098 | validation: 0.15211462483251584]
	TIME [epoch: 97.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931869237667778		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.0931869237667778 | validation: 0.07485148066680017]
	TIME [epoch: 97.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04744786739873723		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.04744786739873723 | validation: 0.0803989489732515]
	TIME [epoch: 97.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047982798117141345		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.047982798117141345 | validation: 0.04569728846296997]
	TIME [epoch: 97.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527420171356625		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.0527420171356625 | validation: 0.08769752019095406]
	TIME [epoch: 97.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044753749797251836		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.044753749797251836 | validation: 0.04721748370709962]
	TIME [epoch: 97.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204756794656784		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.10204756794656784 | validation: 0.14903444373803065]
	TIME [epoch: 97.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31427910259948866		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.31427910259948866 | validation: 0.14792551757766131]
	TIME [epoch: 97.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10307409861235968		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.10307409861235968 | validation: 0.04878160374594831]
	TIME [epoch: 97.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032649267224448206		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.032649267224448206 | validation: 0.03714740371474914]
	TIME [epoch: 97.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04609415733265247		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.04609415733265247 | validation: 0.13115422697877704]
	TIME [epoch: 97.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15813006642987656		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.15813006642987656 | validation: 0.06889084023799419]
	TIME [epoch: 97.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480145811596286		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.05480145811596286 | validation: 0.06186657551310484]
	TIME [epoch: 97.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044270369313646085		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.044270369313646085 | validation: 0.04156649188077751]
	TIME [epoch: 97.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496673036854377		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.03496673036854377 | validation: 0.05278780392290973]
	TIME [epoch: 97.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045501297266397525		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.045501297266397525 | validation: 0.10932209754829937]
	TIME [epoch: 97.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09315766481929236		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.09315766481929236 | validation: 0.06966889312045746]
	TIME [epoch: 97.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047865520625285166		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.047865520625285166 | validation: 0.06976425813518836]
	TIME [epoch: 97.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777613058996602		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.06777613058996602 | validation: 0.05874216007607566]
	TIME [epoch: 97.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414471089009828		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.0414471089009828 | validation: 0.07931051043866252]
	TIME [epoch: 97.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04664677287472878		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.04664677287472878 | validation: 0.03638705601024666]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039899107693585616		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.039899107693585616 | validation: 0.05609223565631499]
	TIME [epoch: 97.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06251769890066042		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.06251769890066042 | validation: 0.11249016874091224]
	TIME [epoch: 97.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642168055148823		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.08642168055148823 | validation: 0.05509835140819072]
	TIME [epoch: 97.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067569699122524		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.07067569699122524 | validation: 0.0480340753913341]
	TIME [epoch: 97.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04953652763429216		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.04953652763429216 | validation: 0.05488051669938572]
	TIME [epoch: 97.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040186453691837966		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.040186453691837966 | validation: 0.08018819188785528]
	TIME [epoch: 97.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407284416136957		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.06407284416136957 | validation: 0.056645935439821646]
	TIME [epoch: 97.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046617363804540415		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.046617363804540415 | validation: 0.04817191982718322]
	TIME [epoch: 97.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0534581770672612		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.0534581770672612 | validation: 0.03866469624376983]
	TIME [epoch: 97.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04784377125419717		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.04784377125419717 | validation: 0.07034568604781165]
	TIME [epoch: 97.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047629610910956605		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.047629610910956605 | validation: 0.04567626971900686]
	TIME [epoch: 97.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042926568703578236		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.042926568703578236 | validation: 0.052249748183236314]
	TIME [epoch: 97.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052824191663898866		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.052824191663898866 | validation: 0.03630726148800267]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02506407169698263		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.02506407169698263 | validation: 0.037082972235368744]
	TIME [epoch: 97.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613763235124434		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1613763235124434 | validation: 0.07318292930053769]
	TIME [epoch: 97.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053822773761770894		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.053822773761770894 | validation: 0.05764765276708694]
	TIME [epoch: 97.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471036607775466		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.0471036607775466 | validation: 0.040813632295072635]
	TIME [epoch: 97.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032395482047935444		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.032395482047935444 | validation: 0.03468766954692765]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320292034332514		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.03320292034332514 | validation: 0.09943659466843208]
	TIME [epoch: 97.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858289016410466		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.04858289016410466 | validation: 0.21092417677407593]
	TIME [epoch: 97.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21361061283204702		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.21361061283204702 | validation: 0.07362238654464971]
	TIME [epoch: 97.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156370955199346		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.08156370955199346 | validation: 0.05477505285929782]
	TIME [epoch: 97.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045341175194925566		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.045341175194925566 | validation: 0.03429138613033997]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02806950546536619		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.02806950546536619 | validation: 0.058760443808969165]
	TIME [epoch: 97.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315698161377933		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.04315698161377933 | validation: 0.03958100451518097]
	TIME [epoch: 97.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040812530213552245		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.040812530213552245 | validation: 0.03351536002241062]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028872131564644493		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.028872131564644493 | validation: 0.03756993350621506]
	TIME [epoch: 97.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892809948640565		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.04892809948640565 | validation: 0.030894542755882104]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024623155066864036		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.024623155066864036 | validation: 0.030832258694545422]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263967091850524		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.03263967091850524 | validation: 0.03604232488649506]
	TIME [epoch: 97.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02243366862071184		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.02243366862071184 | validation: 0.031057490402941947]
	TIME [epoch: 97.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09560456958331826		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.09560456958331826 | validation: 0.06377631250682878]
	TIME [epoch: 97.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717554033792266		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.04717554033792266 | validation: 0.034102997870594835]
	TIME [epoch: 97.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14739513538752338		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.14739513538752338 | validation: 0.032876641072044334]
	TIME [epoch: 97.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372052653559347		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1372052653559347 | validation: 0.07669501215972566]
	TIME [epoch: 97.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044545964002297		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.044545964002297 | validation: 0.030085872362545604]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027534808785848207		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.027534808785848207 | validation: 0.029588289867431936]
	TIME [epoch: 97.2 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032057157714550734		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.032057157714550734 | validation: 0.029803400525608294]
	TIME [epoch: 97.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094433531052246		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.03094433531052246 | validation: 0.05776263773056863]
	TIME [epoch: 97.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068621892333152		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.06068621892333152 | validation: 0.061565457980735844]
	TIME [epoch: 97.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193530993067329		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.04193530993067329 | validation: 0.02638771264536534]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040308768277678306		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.040308768277678306 | validation: 0.03639421615014245]
	TIME [epoch: 97.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02495597839192671		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.02495597839192671 | validation: 0.03594447021295517]
	TIME [epoch: 97.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027343296534511313		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.027343296534511313 | validation: 0.033491702541551746]
	TIME [epoch: 97.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023760724782399566		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.023760724782399566 | validation: 0.32026084027791335]
	TIME [epoch: 97.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33153152311776934		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.33153152311776934 | validation: 0.1814041864830225]
	TIME [epoch: 97.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20847613609569451		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.20847613609569451 | validation: 0.12040614815154231]
	TIME [epoch: 97.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13537301327447512		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.13537301327447512 | validation: 0.0746396416748055]
	TIME [epoch: 97.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09226932663883114		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.09226932663883114 | validation: 0.05095037175633877]
	TIME [epoch: 97.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05849710094022336		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.05849710094022336 | validation: 0.037753986632449055]
	TIME [epoch: 97.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0334255210464091		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.0334255210464091 | validation: 0.03802822488278314]
	TIME [epoch: 97.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028993848087148923		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.028993848087148923 | validation: 0.026111947467302953]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027836932596834688		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.027836932596834688 | validation: 0.03217188744454667]
	TIME [epoch: 97.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299572025263622		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.0299572025263622 | validation: 0.038284357308540885]
	TIME [epoch: 97.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02423486790787414		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.02423486790787414 | validation: 0.026104360744206058]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074343262255194		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.074343262255194 | validation: 0.03659134820058984]
	TIME [epoch: 97.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04219541932277742		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.04219541932277742 | validation: 0.032389010746761246]
	TIME [epoch: 97.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023084817215919144		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.023084817215919144 | validation: 0.02358265301572684]
	TIME [epoch: 97.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018765289845518257		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.018765289845518257 | validation: 0.03163327219597981]
	TIME [epoch: 97.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070041394561099		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.070041394561099 | validation: 0.05637426687860487]
	TIME [epoch: 97.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888152628287137		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.02888152628287137 | validation: 0.02523457733156124]
	TIME [epoch: 97.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0227870067143612		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.0227870067143612 | validation: 0.029688893868041258]
	TIME [epoch: 97.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977643175859222		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.04977643175859222 | validation: 0.06075862399130805]
	TIME [epoch: 97.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046398967379905516		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.046398967379905516 | validation: 0.04985315301386614]
	TIME [epoch: 97.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04246171974136387		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.04246171974136387 | validation: 0.022632942715909543]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02132399776678471		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.02132399776678471 | validation: 0.02826510541888514]
	TIME [epoch: 97.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790554741116964		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.03790554741116964 | validation: 0.025540204015504928]
	TIME [epoch: 97.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02169497906213186		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.02169497906213186 | validation: 0.0233349382991927]
	TIME [epoch: 97.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02203511955090537		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.02203511955090537 | validation: 0.032065842092093455]
	TIME [epoch: 97.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327939100548695		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.03327939100548695 | validation: 0.03707258679676414]
	TIME [epoch: 97.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035891323764328326		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.035891323764328326 | validation: 0.04857389137959453]
	TIME [epoch: 97.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0276036138472002		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.0276036138472002 | validation: 0.03399029406187194]
	TIME [epoch: 97.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035216506621005755		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.035216506621005755 | validation: 0.028299349042943837]
	TIME [epoch: 97.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01964780338537308		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.01964780338537308 | validation: 0.020010683830199733]
	TIME [epoch: 97.2 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666521835079505		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.01666521835079505 | validation: 0.022312916730912707]
	TIME [epoch: 97.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02208972746131759		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.02208972746131759 | validation: 0.027293259324855434]
	TIME [epoch: 97.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047997646682145616		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.047997646682145616 | validation: 0.05627211023855802]
	TIME [epoch: 97.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047452757998654185		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.047452757998654185 | validation: 0.03865860162479217]
	TIME [epoch: 97.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020873233751177632		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.020873233751177632 | validation: 0.03911568272531617]
	TIME [epoch: 97.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027457215860773574		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.027457215860773574 | validation: 0.03849362091700556]
	TIME [epoch: 97.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027679142958710476		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.027679142958710476 | validation: 0.01667943586851945]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01727931086716139		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.01727931086716139 | validation: 0.02874056548517245]
	TIME [epoch: 97.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06357265933312682		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.06357265933312682 | validation: 0.04034213863943086]
	TIME [epoch: 97.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659054309736467		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.04659054309736467 | validation: 0.04106718282877982]
	TIME [epoch: 97.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02690497037172529		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.02690497037172529 | validation: 0.02541388253532546]
	TIME [epoch: 97.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04842761821926734		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.04842761821926734 | validation: 0.02480296810488338]
	TIME [epoch: 97.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028668507776978526		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.028668507776978526 | validation: 0.025495224888248617]
	TIME [epoch: 97.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020551633501096456		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.020551633501096456 | validation: 0.02361829941891128]
	TIME [epoch: 97.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06110897006551618		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.06110897006551618 | validation: 0.04020316046417467]
	TIME [epoch: 97.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025854257788721958		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.025854257788721958 | validation: 0.01798389038948993]
	TIME [epoch: 97.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022327304229406476		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.022327304229406476 | validation: 0.03317515646206152]
	TIME [epoch: 97.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017100631924629142		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.017100631924629142 | validation: 0.01676647068345185]
	TIME [epoch: 97.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02947505984182179		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.02947505984182179 | validation: 0.043804033206199196]
	TIME [epoch: 97.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032099441343504134		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.032099441343504134 | validation: 0.024785641725387657]
	TIME [epoch: 97.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01682575635851019		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.01682575635851019 | validation: 0.0208166885410782]
	TIME [epoch: 97.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020144715356202252		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.020144715356202252 | validation: 0.028475480933935114]
	TIME [epoch: 97.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01763580011324895		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.01763580011324895 | validation: 0.03621746320170147]
	TIME [epoch: 97.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05061504633407989		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.05061504633407989 | validation: 0.03487338660838432]
	TIME [epoch: 97.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023717602463724542		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.023717602463724542 | validation: 0.027565761145590693]
	TIME [epoch: 97.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01770798979524295		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.01770798979524295 | validation: 0.017096173371558734]
	TIME [epoch: 97.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02092935323467921		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.02092935323467921 | validation: 0.0655456595208207]
	TIME [epoch: 97.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659613405898604		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.03659613405898604 | validation: 0.015947264236259008]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04986837357120233		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.04986837357120233 | validation: 0.10197424047901739]
	TIME [epoch: 97.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559090845947308		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.08559090845947308 | validation: 0.05045082447103422]
	TIME [epoch: 97.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904089201422634		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.0904089201422634 | validation: 0.040743229906709276]
	TIME [epoch: 97.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276867391155049		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.04276867391155049 | validation: 0.019268631551170652]
	TIME [epoch: 97.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017501577999981716		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.017501577999981716 | validation: 0.013978644247146801]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013251857566289724		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.013251857566289724 | validation: 0.016024487704106267]
	TIME [epoch: 97.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06429027876010775		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.06429027876010775 | validation: 0.04444346419735526]
	TIME [epoch: 97.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04505571315515235		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.04505571315515235 | validation: 0.019515020536467347]
	TIME [epoch: 97.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05631563004136517		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.05631563004136517 | validation: 0.13228214016334325]
	TIME [epoch: 97.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197953493652433		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.1197953493652433 | validation: 0.054498321444838696]
	TIME [epoch: 97.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445301819530027		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.04445301819530027 | validation: 0.03485187626398816]
	TIME [epoch: 97.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029181218869400595		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.029181218869400595 | validation: 0.026103754390779166]
	TIME [epoch: 97.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021774544343330735		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.021774544343330735 | validation: 0.024208784193509053]
	TIME [epoch: 97.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023905699138608662		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.023905699138608662 | validation: 0.02637046101688219]
	TIME [epoch: 97.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027943567593789083		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.027943567593789083 | validation: 0.02243408089274291]
	TIME [epoch: 97.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02046248952097235		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.02046248952097235 | validation: 0.02149968116293544]
	TIME [epoch: 97.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017721674706965174		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.017721674706965174 | validation: 0.01897583566144498]
	TIME [epoch: 97.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02502310389816816		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.02502310389816816 | validation: 0.03831028312950567]
	TIME [epoch: 97.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703253249236004		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.03703253249236004 | validation: 0.019045125334876147]
	TIME [epoch: 97.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021287159364732855		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.021287159364732855 | validation: 0.0205698274948706]
	TIME [epoch: 97.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01976855724024142		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.01976855724024142 | validation: 0.027914902041203747]
	TIME [epoch: 97.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03031678262158368		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.03031678262158368 | validation: 0.0230593877147686]
	TIME [epoch: 97.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02085195007478135		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.02085195007478135 | validation: 0.019868542452471397]
	TIME [epoch: 97.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027070817124025353		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.027070817124025353 | validation: 0.05210141262792192]
	TIME [epoch: 97.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595578126663907		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.04595578126663907 | validation: 0.016525196639531156]
	TIME [epoch: 97.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025669158609440027		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.025669158609440027 | validation: 0.020367582880678404]
	TIME [epoch: 97.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017927392258417177		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.017927392258417177 | validation: 0.021492433459100665]
	TIME [epoch: 97.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016036870832714052		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.016036870832714052 | validation: 0.01599878460098201]
	TIME [epoch: 97.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024890678064538332		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.024890678064538332 | validation: 0.03664132957985327]
	TIME [epoch: 97.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02706661097347913		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.02706661097347913 | validation: 0.05667845675133071]
	TIME [epoch: 97.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565152147533395		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.03565152147533395 | validation: 0.02260192102312765]
	TIME [epoch: 97.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01889410295469983		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.01889410295469983 | validation: 0.0163461106648135]
	TIME [epoch: 97.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10569022235821185		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.10569022235821185 | validation: 0.05517262065936315]
	TIME [epoch: 97.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043463127295181134		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.043463127295181134 | validation: 0.022544419589468682]
	TIME [epoch: 97.4 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0257602364051328		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.0257602364051328 | validation: 0.03689512388675198]
	TIME [epoch: 97.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026788947909867196		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.026788947909867196 | validation: 0.02497468790941912]
	TIME [epoch: 97.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02172953998493355		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.02172953998493355 | validation: 0.015712969409582465]
	TIME [epoch: 97.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019811182134014175		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.019811182134014175 | validation: 0.018195459607738378]
	TIME [epoch: 97.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028201894520646496		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.028201894520646496 | validation: 0.01717509408203032]
	TIME [epoch: 97.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015470511616735506		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.015470511616735506 | validation: 0.016675571219199097]
	TIME [epoch: 97.4 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01821743609085618		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.01821743609085618 | validation: 0.018039067127753227]
	TIME [epoch: 97.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017736994541296198		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.017736994541296198 | validation: 0.0198894107596026]
	TIME [epoch: 97.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01458066396148526		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.01458066396148526 | validation: 0.021589000312491127]
	TIME [epoch: 97.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023319189281809437		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.023319189281809437 | validation: 0.09415833034334356]
	TIME [epoch: 97.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639894830621258		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.10639894830621258 | validation: 0.01738039864099313]
	TIME [epoch: 97.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021605679812753138		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.021605679812753138 | validation: 0.0180451066842384]
	TIME [epoch: 97.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05172638402581338		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.05172638402581338 | validation: 0.039978882242660316]
	TIME [epoch: 97.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07646465582322592		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.07646465582322592 | validation: 0.05515854644970455]
	TIME [epoch: 97.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657267421646638		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.05657267421646638 | validation: 0.029109925403052114]
	TIME [epoch: 97.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026008611940381315		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.026008611940381315 | validation: 0.030105319127188914]
	TIME [epoch: 97.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02918116249622839		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.02918116249622839 | validation: 0.014717216110787312]
	TIME [epoch: 97.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026374859298672764		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.026374859298672764 | validation: 0.021796887777644575]
	TIME [epoch: 97.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022912013244062703		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.022912013244062703 | validation: 0.017739295769265598]
	TIME [epoch: 97.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01929244951873838		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.01929244951873838 | validation: 0.015083381965832641]
	TIME [epoch: 97.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01691452749124002		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.01691452749124002 | validation: 0.013031207651124258]
	TIME [epoch: 97.2 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013558401186731276		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.013558401186731276 | validation: 0.022947827831352092]
	TIME [epoch: 97.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01904964721393821		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.01904964721393821 | validation: 0.018462135532551195]
	TIME [epoch: 97.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017434647014615036		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.017434647014615036 | validation: 0.045276262257961414]
	TIME [epoch: 97.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031316771346459646		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.031316771346459646 | validation: 0.01644466379405702]
	TIME [epoch: 97.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013665253466845594		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.013665253466845594 | validation: 0.02489549095504128]
	TIME [epoch: 97.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023444783991814634		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.023444783991814634 | validation: 0.02286032271016214]
	TIME [epoch: 97.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0166587715371454		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.0166587715371454 | validation: 0.014899288075057736]
	TIME [epoch: 97.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012998318802175463		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.012998318802175463 | validation: 0.02483656992144896]
	TIME [epoch: 97.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022808927086775017		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.022808927086775017 | validation: 0.02598999032306293]
	TIME [epoch: 97.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022146354366962464		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.022146354366962464 | validation: 0.03984056781801325]
	TIME [epoch: 97.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302984419512925		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.03302984419512925 | validation: 0.016748481431737555]
	TIME [epoch: 97.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015383956245105369		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.015383956245105369 | validation: 0.01531629114515784]
	TIME [epoch: 97.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017269175724311057		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.017269175724311057 | validation: 0.01813090129905557]
	TIME [epoch: 97.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306055211892833		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.1306055211892833 | validation: 0.09089029393246473]
	TIME [epoch: 97.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298587728466848		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.09298587728466848 | validation: 0.035768330336132706]
	TIME [epoch: 97.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026427663738198937		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.026427663738198937 | validation: 0.013465478532140937]
	TIME [epoch: 97.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014203442686028349		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.014203442686028349 | validation: 0.012860802206593988]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01286699171028791		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.01286699171028791 | validation: 0.01118330194329368]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_430.pth
	Model improved!!!
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013015724352380156		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.013015724352380156 | validation: 0.011668176585524033]
	TIME [epoch: 97.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01267163546165532		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.01267163546165532 | validation: 0.018266706435585076]
	TIME [epoch: 97.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019190495594566842		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.019190495594566842 | validation: 0.01207197936076403]
	TIME [epoch: 97.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02596016426821223		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.02596016426821223 | validation: 0.033716829779128994]
	TIME [epoch: 97.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374288405953737		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.03374288405953737 | validation: 0.012101202839213787]
	TIME [epoch: 97.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013979017661097956		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.013979017661097956 | validation: 0.05698818029412275]
	TIME [epoch: 97.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428016976770468		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.03428016976770468 | validation: 0.015231660618389858]
	TIME [epoch: 97.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499442821424185		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.04499442821424185 | validation: 0.019801920355525277]
	TIME [epoch: 97.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014650283158698627		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.014650283158698627 | validation: 0.011458701198593529]
	TIME [epoch: 97.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024856178117452703		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.024856178117452703 | validation: 0.023151682857436476]
	TIME [epoch: 97.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017535221757622156		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.017535221757622156 | validation: 0.013642584098555972]
	TIME [epoch: 97.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012768213841145544		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.012768213841145544 | validation: 0.01215408219831594]
	TIME [epoch: 97.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009776945858794678		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.009776945858794678 | validation: 0.013133031538077692]
	TIME [epoch: 97.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01314209571772725		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.01314209571772725 | validation: 0.014802310850675073]
	TIME [epoch: 97.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01946495519974967		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.01946495519974967 | validation: 0.012297024675076417]
	TIME [epoch: 97.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012479554307547967		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.012479554307547967 | validation: 0.059500015973609426]
	TIME [epoch: 97.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487233469771696		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.06487233469771696 | validation: 0.014467934235445316]
	TIME [epoch: 97.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035112346822689294		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.035112346822689294 | validation: 0.029006829705877174]
	TIME [epoch: 97.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01715276483040247		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.01715276483040247 | validation: 0.01133698108911019]
	TIME [epoch: 97.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020273437905383874		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.020273437905383874 | validation: 0.014805105003430916]
	TIME [epoch: 97.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013576872119443164		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.013576872119443164 | validation: 0.012338933857929531]
	TIME [epoch: 97.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01116195333250742		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.01116195333250742 | validation: 0.012350680190696312]
	TIME [epoch: 97.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016225385754617516		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.016225385754617516 | validation: 0.011190443768507325]
	TIME [epoch: 97.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013115813468733119		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.013115813468733119 | validation: 0.013876918271580229]
	TIME [epoch: 97.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011972555938422696		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.011972555938422696 | validation: 0.009345320786186044]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010787044516236948		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.010787044516236948 | validation: 0.02530902541972762]
	TIME [epoch: 97.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024595895344018823		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.024595895344018823 | validation: 0.012242978989945513]
	TIME [epoch: 97.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718118242866538		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.05718118242866538 | validation: 0.024889368783078368]
	TIME [epoch: 97.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01943033477951572		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.01943033477951572 | validation: 0.00868200805261013]
	TIME [epoch: 97.4 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009730996129876008		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.009730996129876008 | validation: 0.00950721623884812]
	TIME [epoch: 97.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008733788811094559		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.008733788811094559 | validation: 0.00982988956867355]
	TIME [epoch: 97.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009902290471893515		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.009902290471893515 | validation: 0.016685053143672662]
	TIME [epoch: 97.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013066154843069956		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.013066154843069956 | validation: 0.013840928504395866]
	TIME [epoch: 97.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010131884429130995		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.010131884429130995 | validation: 0.010126293195690087]
	TIME [epoch: 97.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010317949766978049		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.010317949766978049 | validation: 0.01225362377621024]
	TIME [epoch: 97.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023091893450680443		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.023091893450680443 | validation: 0.01347781866948102]
	TIME [epoch: 97.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016315004164005102		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.016315004164005102 | validation: 0.012719926881542266]
	TIME [epoch: 97.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01304629816875688		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.01304629816875688 | validation: 0.013457182896090988]
	TIME [epoch: 97.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012862030808779767		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.012862030808779767 | validation: 0.008436052129029478]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016700015376463866		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.016700015376463866 | validation: 0.014899083517160613]
	TIME [epoch: 97.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01294907905659502		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.01294907905659502 | validation: 0.014694907474728134]
	TIME [epoch: 97.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01030179250855209		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.01030179250855209 | validation: 0.008140422747621402]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011420909767430501		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.011420909767430501 | validation: 0.009523344697383182]
	TIME [epoch: 97.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010702280349471393		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.010702280349471393 | validation: 0.008163614636218796]
	TIME [epoch: 97.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00953301595721442		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.00953301595721442 | validation: 0.012178365630710862]
	TIME [epoch: 97.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01936316612448841		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.01936316612448841 | validation: 0.010185133303540806]
	TIME [epoch: 97.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011724706192806163		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.011724706192806163 | validation: 0.010646044971792883]
	TIME [epoch: 97.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015759615532547053		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.015759615532547053 | validation: 0.01606303076165612]
	TIME [epoch: 97.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012013056714277152		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.012013056714277152 | validation: 0.00941335653370131]
	TIME [epoch: 97.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010636618419745997		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.010636618419745997 | validation: 0.008709354076626367]
	TIME [epoch: 97.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011518447077166682		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.011518447077166682 | validation: 0.006839937258515134]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009638764643802498		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.009638764643802498 | validation: 0.010732033697099784]
	TIME [epoch: 97.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022735449552133274		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.022735449552133274 | validation: 0.015325729010711622]
	TIME [epoch: 97.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014629105323609023		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.014629105323609023 | validation: 0.00949649476500588]
	TIME [epoch: 97.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009867867320811794		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.009867867320811794 | validation: 0.01451336658377353]
	TIME [epoch: 97.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01502455527639589		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.01502455527639589 | validation: 0.006984853829350661]
	TIME [epoch: 97.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008053686658671854		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.008053686658671854 | validation: 0.007709262976890792]
	TIME [epoch: 97.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636034828852302		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.01636034828852302 | validation: 0.009762739228470874]
	TIME [epoch: 97.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010873298361959011		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.010873298361959011 | validation: 0.012998397226086249]
	TIME [epoch: 97.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012435288634357642		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.012435288634357642 | validation: 0.006784983813451027]
	TIME [epoch: 97.3 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008833147827630767		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.008833147827630767 | validation: 0.012147906096763323]
	TIME [epoch: 97.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00972014435571068		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.00972014435571068 | validation: 0.008179348426335109]
	TIME [epoch: 97.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008358646561057708		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.008358646561057708 | validation: 0.023312001712139627]
	TIME [epoch: 97.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01984295498032454		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.01984295498032454 | validation: 0.07569527746426372]
	TIME [epoch: 97.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05463958051997823		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.05463958051997823 | validation: 0.008909755068610943]
	TIME [epoch: 97.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010665697456476136		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.010665697456476136 | validation: 0.01013903962811993]
	TIME [epoch: 97.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010597238323142747		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.010597238323142747 | validation: 0.008070006079357483]
	TIME [epoch: 97.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00784417245093978		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.00784417245093978 | validation: 0.011030456070242072]
	TIME [epoch: 97.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010094454352403626		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.010094454352403626 | validation: 0.00898077127962283]
	TIME [epoch: 97.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00843986118889901		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.00843986118889901 | validation: 0.008192348130201425]
	TIME [epoch: 97.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007733401740116278		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.007733401740116278 | validation: 0.009510348272313968]
	TIME [epoch: 289 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200708007539577		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.0200708007539577 | validation: 0.023987355866037112]
	TIME [epoch: 200 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020832840812842292		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.020832840812842292 | validation: 0.009818599591097744]
	TIME [epoch: 200 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010937689243391245		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.010937689243391245 | validation: 0.008229553449873528]
	TIME [epoch: 200 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007950452032942494		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.007950452032942494 | validation: 0.007592836760413614]
	TIME [epoch: 200 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008192074264856741		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.008192074264856741 | validation: 0.006550395874533592]
	TIME [epoch: 200 sec]
	Saving model to: out/model_training/model_phi1_1b_v_mmd1_20240802_132858/states/model_phi1_1b_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010351352061217966		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.010351352061217966 | validation: 0.04851534618722426]
	TIME [epoch: 200 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057158310213966536		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.057158310213966536 | validation: 0.036094814645461056]
	TIME [epoch: 200 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213577893740656		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.04213577893740656 | validation: 0.010314825945504848]
	TIME [epoch: 200 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00911280821737662		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.00911280821737662 | validation: 0.01185702612647601]
	TIME [epoch: 200 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009332266943049545		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.009332266943049545 | validation: 0.013888479380820145]
	TIME [epoch: 200 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008831335495813077		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.008831335495813077 | validation: 0.010131798000355723]
	TIME [epoch: 200 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007205304269571934		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.007205304269571934 | validation: 0.007883970331487026]
	TIME [epoch: 200 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825641570798493		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.01825641570798493 | validation: 0.021860206497181185]
	TIME [epoch: 200 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019022939770323398		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.019022939770323398 | validation: 0.010808062328843598]
	TIME [epoch: 200 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007391697808097399		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.007391697808097399 | validation: 0.00968227733601253]
	TIME [epoch: 200 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010208940687267961		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.010208940687267961 | validation: 0.0082877865991348]
	TIME [epoch: 200 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016007137726123923		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.016007137726123923 | validation: 0.009291711460098839]
	TIME [epoch: 200 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008581691385585809		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.008581691385585809 | validation: 0.009539841325043251]
	TIME [epoch: 200 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007610455115940396		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.007610455115940396 | validation: 0.013651425429028925]
	TIME [epoch: 200 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0361423601422005		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.0361423601422005 | validation: 0.04653584116142153]
	TIME [epoch: 200 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03571292456307693		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.03571292456307693 | validation: 0.009481006143569122]
	TIME [epoch: 200 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00954074113688781		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.00954074113688781 | validation: 0.009395164306598014]
	TIME [epoch: 200 sec]
EPOCH 524/2000:
	Training over batches...
