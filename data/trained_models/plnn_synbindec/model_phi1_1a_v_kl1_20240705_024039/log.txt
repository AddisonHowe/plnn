Args:
Namespace(name='model_phi1_1a_v_kl1', outdir='out/model_training/model_phi1_1a_v_kl1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4254662953

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.119776473326532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.119776473326532 | validation: 10.094797377615084]
	TIME [epoch: 99.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.480357663720223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.480357663720223 | validation: 8.870017102326418]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.852003316384447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.852003316384447 | validation: 11.062069371288544]
	TIME [epoch: 8.09 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.274893931650968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.274893931650968 | validation: 10.827078310843778]
	TIME [epoch: 8.05 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.448386885091947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.448386885091947 | validation: 10.374940732023399]
	TIME [epoch: 8.06 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.175060203986495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.175060203986495 | validation: 10.428388011682905]
	TIME [epoch: 8.05 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.249954002671316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.249954002671316 | validation: 9.46380498927926]
	TIME [epoch: 8.05 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.168842805281137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.168842805281137 | validation: 8.858077469606142]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.970821028019507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.970821028019507 | validation: 9.084100460668608]
	TIME [epoch: 8.11 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.434890157419543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.434890157419543 | validation: 8.868383267246536]
	TIME [epoch: 8.06 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6165308778610905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6165308778610905 | validation: 9.164510913437407]
	TIME [epoch: 8.05 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.620722334282703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.620722334282703 | validation: 8.945723583676752]
	TIME [epoch: 8.05 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.175889289348225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.175889289348225 | validation: 8.4351073945673]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.955986063472359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.955986063472359 | validation: 8.445559337500288]
	TIME [epoch: 8.07 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.810894210867777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.810894210867777 | validation: 7.634345754717924]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.561220692775517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.561220692775517 | validation: 7.413732340866045]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.294838690151845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.294838690151845 | validation: 7.375535784733904]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2203955513618405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2203955513618405 | validation: 7.622372555267287]
	TIME [epoch: 8.05 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.262422451227221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.262422451227221 | validation: 7.368154253351678]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.207275151208516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.207275151208516 | validation: 7.454914100391678]
	TIME [epoch: 8.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.978693627461701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.978693627461701 | validation: 6.850516996285776]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.848226056028789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.848226056028789 | validation: 6.6961277516057365]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.831113801640207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.831113801640207 | validation: 6.70147847521716]
	TIME [epoch: 8.05 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.802900102164311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.802900102164311 | validation: 6.792494191924575]
	TIME [epoch: 8.05 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.564465180172209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.564465180172209 | validation: 6.590498283536453]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.567622632021747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.567622632021747 | validation: 6.537196522696043]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.530733548038531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.530733548038531 | validation: 6.358455125026046]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.454733287877592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.454733287877592 | validation: 6.600542490102281]
	TIME [epoch: 8.05 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.704570955589203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.704570955589203 | validation: 6.670208271797064]
	TIME [epoch: 8.05 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.513603210312548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.513603210312548 | validation: 6.174202739416115]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.537028035767566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.537028035767566 | validation: 6.102801736596398]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.299726578856765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.299726578856765 | validation: 6.053540573831393]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.289002964207419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.289002964207419 | validation: 6.128993320243655]
	TIME [epoch: 8.05 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.219650757338399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.219650757338399 | validation: 5.957554150679805]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.351605052311386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.351605052311386 | validation: 5.706425164474982]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.058345962913363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.058345962913363 | validation: 4.892368948110191]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.869007723337482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.869007723337482 | validation: 4.8054521238224215]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5688515787673225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5688515787673225 | validation: 4.737124279526779]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460635299012854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.460635299012854 | validation: 4.297138898204313]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.324222781790177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.324222781790177 | validation: 4.482864303144671]
	TIME [epoch: 8.05 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.11343247504141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.11343247504141 | validation: 4.521458751357731]
	TIME [epoch: 8.05 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.325843202629549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.325843202629549 | validation: 4.675941441455971]
	TIME [epoch: 8.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.14343656880205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.14343656880205 | validation: 4.039451593866561]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.33237340460781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.33237340460781 | validation: 4.055155167348474]
	TIME [epoch: 8.05 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.941315134439024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.941315134439024 | validation: 3.9828066133358884]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.803478823846074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.803478823846074 | validation: 4.10108361768275]
	TIME [epoch: 8.06 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.957290429282839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.957290429282839 | validation: 4.394606489279635]
	TIME [epoch: 8.06 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7950562060720276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7950562060720276 | validation: 3.554978258636964]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6010672107499793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6010672107499793 | validation: 3.47563610299302]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3993087259983086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3993087259983086 | validation: 3.0470334326448105]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2308132292387075		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.2308132292387075 | validation: 4.006224873421528]
	TIME [epoch: 8.05 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8227121160653335		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.8227121160653335 | validation: 3.248375427550049]
	TIME [epoch: 8.05 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.481593389029509		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.481593389029509 | validation: 3.1890807384490305]
	TIME [epoch: 8.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1886067193784737		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.1886067193784737 | validation: 4.146234465629634]
	TIME [epoch: 8.06 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097964551904408		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.2097964551904408 | validation: 2.892751425792836]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.001389547963954		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.001389547963954 | validation: 2.5979197770575713]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7747465440702124		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.7747465440702124 | validation: 3.326368603500159]
	TIME [epoch: 8.05 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.884738022647167		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.884738022647167 | validation: 2.6778025415546463]
	TIME [epoch: 8.06 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.860548361342881		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.860548361342881 | validation: 3.101510151914023]
	TIME [epoch: 8.11 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.581470832137679		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.581470832137679 | validation: 2.65032126483241]
	TIME [epoch: 8.05 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4373352707809124		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.4373352707809124 | validation: 2.9079927284889147]
	TIME [epoch: 8.06 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.397980288330141		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.397980288330141 | validation: 2.75136097649362]
	TIME [epoch: 8.05 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227060533091543		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.227060533091543 | validation: 2.423023031091427]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5281403968071947		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.5281403968071947 | validation: 2.36297406605748]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.593171838914297		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.593171838914297 | validation: 2.7352092230272698]
	TIME [epoch: 8.07 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.548867457481877		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.548867457481877 | validation: 2.826942352477289]
	TIME [epoch: 8.05 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4657916268741964		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.4657916268741964 | validation: 2.3386073428625593]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239522900012097		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.239522900012097 | validation: 3.776984409677093]
	TIME [epoch: 8.05 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8714014776880328		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.8714014776880328 | validation: 2.3078316230927194]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.55314322463597		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.55314322463597 | validation: 2.2005468002596276]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290442095686707		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.290442095686707 | validation: 2.0974390446105122]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1412560203757542		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.1412560203757542 | validation: 2.135081137677229]
	TIME [epoch: 8.05 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9689364770597728		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.9689364770597728 | validation: 2.4428884981038843]
	TIME [epoch: 8.05 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3450782674603725		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.3450782674603725 | validation: 2.1685636851922947]
	TIME [epoch: 8.05 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0213824424249793		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.0213824424249793 | validation: 2.33375718844161]
	TIME [epoch: 8.07 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2800209153882416		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.2800209153882416 | validation: 2.308233561862058]
	TIME [epoch: 8.07 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231180009433264		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.231180009433264 | validation: 2.6088845331841046]
	TIME [epoch: 8.05 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142433645999553		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.142433645999553 | validation: 3.418383830378156]
	TIME [epoch: 8.05 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330418264144126		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.330418264144126 | validation: 2.2492428532537367]
	TIME [epoch: 8.05 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0902995712120642		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.0902995712120642 | validation: 4.223497948048919]
	TIME [epoch: 8.05 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.96960297983971		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.96960297983971 | validation: 2.60858890432426]
	TIME [epoch: 8.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6500175953559726		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.6500175953559726 | validation: 2.259667812920097]
	TIME [epoch: 8.06 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050966909522927		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.050966909522927 | validation: 1.896743495589177]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8485269712382628		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8485269712382628 | validation: 1.8375563753837616]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2327087970909725		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.2327087970909725 | validation: 1.929111994520222]
	TIME [epoch: 8.05 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.952962591260802		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.952962591260802 | validation: 1.6755533892750047]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8127439872269235		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.8127439872269235 | validation: 2.3992807506022875]
	TIME [epoch: 8.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.976700678298833		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.976700678298833 | validation: 1.682394269321254]
	TIME [epoch: 8.05 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.689479009031106		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.689479009031106 | validation: 2.0695520705730726]
	TIME [epoch: 8.05 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9521140643990094		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.9521140643990094 | validation: 2.034198077006014]
	TIME [epoch: 8.04 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7802784173771606		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.7802784173771606 | validation: 1.7391892345706403]
	TIME [epoch: 8.05 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3018732617913207		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.3018732617913207 | validation: 1.7594392523507776]
	TIME [epoch: 8.07 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8389705602543565		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.8389705602543565 | validation: 1.5831608161580668]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7577233956135287		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.7577233956135287 | validation: 1.583900266175181]
	TIME [epoch: 8.06 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8501626534990965		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.8501626534990965 | validation: 1.5398461291420766]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7620913064990489		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7620913064990489 | validation: 2.467590041955327]
	TIME [epoch: 8.05 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0132417360072337		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.0132417360072337 | validation: 1.7083058521875119]
	TIME [epoch: 8.05 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630866864499327		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.630866864499327 | validation: 2.2245997278250087]
	TIME [epoch: 8.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8456395119506122		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.8456395119506122 | validation: 1.6451377207175137]
	TIME [epoch: 8.06 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6819711985832797		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.6819711985832797 | validation: 2.78673283134429]
	TIME [epoch: 8.06 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.966186345795219		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.966186345795219 | validation: 3.2923665486130353]
	TIME [epoch: 8.05 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222480009470273		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.222480009470273 | validation: 1.8723982448117265]
	TIME [epoch: 8.04 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.937992257098978		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.937992257098978 | validation: 1.9382890422885601]
	TIME [epoch: 8.06 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.766288803735483		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.766288803735483 | validation: 2.437392820652842]
	TIME [epoch: 8.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9759393042109137		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.9759393042109137 | validation: 1.4655668596463836]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8924533185601708		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.8924533185601708 | validation: 1.8736843170769704]
	TIME [epoch: 8.06 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7861308936724005		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7861308936724005 | validation: 3.346228565517109]
	TIME [epoch: 8.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.013743665501827		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.013743665501827 | validation: 1.427778080274368]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303442116584258		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.303442116584258 | validation: 3.408170464921839]
	TIME [epoch: 8.11 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232903323957876		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.232903323957876 | validation: 1.7605167542613025]
	TIME [epoch: 8.08 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9003072124645124		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.9003072124645124 | validation: 1.638191227767183]
	TIME [epoch: 8.06 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.811715926783337		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.811715926783337 | validation: 1.9463196797118578]
	TIME [epoch: 8.05 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7566545736014052		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.7566545736014052 | validation: 1.6739378445012905]
	TIME [epoch: 8.05 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.781803975528174		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.781803975528174 | validation: 1.7971328670386395]
	TIME [epoch: 8.05 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8147759798811112		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.8147759798811112 | validation: 4.50410665077778]
	TIME [epoch: 8.09 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6568892622506137		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.6568892622506137 | validation: 1.4693276820979664]
	TIME [epoch: 8.08 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6722063339726234		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.6722063339726234 | validation: 1.7346386440418275]
	TIME [epoch: 8.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6227714626129508		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.6227714626129508 | validation: 1.497324411574984]
	TIME [epoch: 8.07 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5959077276132936		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.5959077276132936 | validation: 1.272021472257566]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5765742533234068		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.5765742533234068 | validation: 1.7084370594046452]
	TIME [epoch: 8.07 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095864662491265		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.095864662491265 | validation: 1.495681827498121]
	TIME [epoch: 8.11 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275069512228755		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.275069512228755 | validation: 1.7218533151815452]
	TIME [epoch: 8.05 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8037345300640666		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8037345300640666 | validation: 2.0191359066629087]
	TIME [epoch: 8.05 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9016893251346998		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.9016893251346998 | validation: 1.3379379142064582]
	TIME [epoch: 8.05 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6924182530273466		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.6924182530273466 | validation: 1.6560888677681502]
	TIME [epoch: 8.04 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.641663680328985		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.641663680328985 | validation: 1.8021620304535815]
	TIME [epoch: 8.07 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8355196297882848		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.8355196297882848 | validation: 1.3928577499699335]
	TIME [epoch: 8.07 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5899071598895507		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.5899071598895507 | validation: 2.0672646817371794]
	TIME [epoch: 8.04 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6824249815841221		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.6824249815841221 | validation: 1.4874578364246833]
	TIME [epoch: 8.05 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.474123992329013		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.474123992329013 | validation: 1.9274490852297712]
	TIME [epoch: 8.05 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0191560061060776		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.0191560061060776 | validation: 1.5120996252463852]
	TIME [epoch: 8.05 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8222388027124563		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.8222388027124563 | validation: 1.927607326765917]
	TIME [epoch: 8.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6929325245285494		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.6929325245285494 | validation: 1.37900002946443]
	TIME [epoch: 8.06 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3886782119783492		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.3886782119783492 | validation: 1.9134542818383315]
	TIME [epoch: 8.05 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5648146921355208		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.5648146921355208 | validation: 1.6759375858929717]
	TIME [epoch: 8.04 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.952661454659649		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.952661454659649 | validation: 1.5463066168374702]
	TIME [epoch: 8.04 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333029369931665		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.333029369931665 | validation: 1.7533686188786013]
	TIME [epoch: 8.05 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5644591208290153		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.5644591208290153 | validation: 1.41526327072416]
	TIME [epoch: 8.09 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.547299814589519		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.547299814589519 | validation: 1.6125384049375127]
	TIME [epoch: 8.05 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4479716071875643		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4479716071875643 | validation: 2.703298155607786]
	TIME [epoch: 8.05 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9757942869006893		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.9757942869006893 | validation: 1.5956306567535297]
	TIME [epoch: 8.05 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.986631778325178		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.986631778325178 | validation: 2.570878955452516]
	TIME [epoch: 8.05 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.98814199320967		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.98814199320967 | validation: 1.3921917079580126]
	TIME [epoch: 8.05 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4413477842888438		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.4413477842888438 | validation: 1.6389331635980606]
	TIME [epoch: 8.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5358937617019923		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.5358937617019923 | validation: 1.5703361642325278]
	TIME [epoch: 8.05 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4916726127646007		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.4916726127646007 | validation: 2.0414860053456976]
	TIME [epoch: 8.05 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.445629524709599		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.445629524709599 | validation: 1.9027539107295808]
	TIME [epoch: 8.05 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6211938103328898		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.6211938103328898 | validation: 1.872427571974359]
	TIME [epoch: 8.05 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6324200327038176		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6324200327038176 | validation: 1.9325369611965812]
	TIME [epoch: 8.08 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6223459867035595		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.6223459867035595 | validation: 1.2312830399688317]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.45691762262206		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.45691762262206 | validation: 1.2824913704617422]
	TIME [epoch: 8.04 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5076960144568405		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.5076960144568405 | validation: 1.300987955008016]
	TIME [epoch: 8.04 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6215620446943422		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.6215620446943422 | validation: 2.0534407686616305]
	TIME [epoch: 8.04 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.645091387511402		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.645091387511402 | validation: 1.3693594170134693]
	TIME [epoch: 8.05 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3225322447211973		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.3225322447211973 | validation: 1.374174855902321]
	TIME [epoch: 8.08 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.278732350349682		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.278732350349682 | validation: 1.8187877242777]
	TIME [epoch: 8.05 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4476016985643538		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.4476016985643538 | validation: 1.872977442014161]
	TIME [epoch: 8.04 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.417289392966673		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.417289392966673 | validation: 1.3416235272439834]
	TIME [epoch: 8.04 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3202089066791594		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.3202089066791594 | validation: 1.354687186010624]
	TIME [epoch: 8.05 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266212714378949		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.266212714378949 | validation: 1.6619702381324415]
	TIME [epoch: 8.05 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5362205219554146		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.5362205219554146 | validation: 1.06951399857292]
	TIME [epoch: 8.09 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.400007121697387		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.400007121697387 | validation: 1.3032874045663587]
	TIME [epoch: 8.05 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.390552918533137		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.390552918533137 | validation: 1.195330691455407]
	TIME [epoch: 8.05 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.41913819910943		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.41913819910943 | validation: 1.568800033453901]
	TIME [epoch: 8.04 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324965135829963		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.324965135829963 | validation: 1.2186656708621575]
	TIME [epoch: 8.05 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3437898523441967		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.3437898523441967 | validation: 3.462613026070546]
	TIME [epoch: 8.07 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0395957304925307		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.0395957304925307 | validation: 1.9179922971978347]
	TIME [epoch: 8.08 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5908046635849735		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.5908046635849735 | validation: 1.8087910600340824]
	TIME [epoch: 8.05 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8189486807804287		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.8189486807804287 | validation: 1.4421263362921617]
	TIME [epoch: 8.05 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4483444147650637		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4483444147650637 | validation: 1.1846060450523601]
	TIME [epoch: 8.05 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.619944829257535		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.619944829257535 | validation: 1.4967899781529903]
	TIME [epoch: 8.05 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3543302832432407		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.3543302832432407 | validation: 1.565627700518054]
	TIME [epoch: 8.09 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5578895253543015		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.5578895253543015 | validation: 1.2819701316166436]
	TIME [epoch: 8.07 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4188769704087885		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.4188769704087885 | validation: 1.1522170749575809]
	TIME [epoch: 8.05 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4395756811910627		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.4395756811910627 | validation: 1.1156416372822862]
	TIME [epoch: 8.05 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.344021154442974		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.344021154442974 | validation: 1.3377426881739656]
	TIME [epoch: 8.05 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276365967700502		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.276365967700502 | validation: 2.6190777816929574]
	TIME [epoch: 8.05 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5109302766010295		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.5109302766010295 | validation: 1.536599322066663]
	TIME [epoch: 8.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220301034503775		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.220301034503775 | validation: 1.264022246644855]
	TIME [epoch: 8.06 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2654001919404148		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.2654001919404148 | validation: 1.1621945125545747]
	TIME [epoch: 8.06 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3082323380626255		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.3082323380626255 | validation: 1.257281075040901]
	TIME [epoch: 8.05 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2104743069890245		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.2104743069890245 | validation: 1.7224864236247863]
	TIME [epoch: 8.05 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5314364577020436		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.5314364577020436 | validation: 1.2031427443656397]
	TIME [epoch: 8.05 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402196193145746		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.1402196193145746 | validation: 1.4457435350856156]
	TIME [epoch: 8.09 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3571912959010934		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.3571912959010934 | validation: 1.4661141116932601]
	TIME [epoch: 8.06 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4292330637711317		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.4292330637711317 | validation: 1.556682752817935]
	TIME [epoch: 8.06 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3334716757026528		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.3334716757026528 | validation: 1.9212541254060582]
	TIME [epoch: 8.06 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.972670739973079		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.972670739973079 | validation: 1.965467061282795]
	TIME [epoch: 8.06 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.478961122188369		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.478961122188369 | validation: 1.2495006140080989]
	TIME [epoch: 8.08 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323329218879626		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.323329218879626 | validation: 1.2148835434513434]
	TIME [epoch: 8.09 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2607807475784893		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.2607807475784893 | validation: 1.3703067523271577]
	TIME [epoch: 8.06 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3879123747922117		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.3879123747922117 | validation: 1.9712972770729968]
	TIME [epoch: 8.06 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8941971098548267		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.8941971098548267 | validation: 1.956665073314512]
	TIME [epoch: 8.06 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7788820972746542		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.7788820972746542 | validation: 3.042910152468978]
	TIME [epoch: 8.06 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384264952756825		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.384264952756825 | validation: 1.5578965941610718]
	TIME [epoch: 8.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4298888096063735		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.4298888096063735 | validation: 1.1002043984892211]
	TIME [epoch: 8.07 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2865139029549684		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.2865139029549684 | validation: 1.3585745386025179]
	TIME [epoch: 8.05 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3514267519903949		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.3514267519903949 | validation: 1.2795313802936306]
	TIME [epoch: 8.06 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1337274671341868		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.1337274671341868 | validation: 2.2882014039090217]
	TIME [epoch: 8.06 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.465045472265756		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.465045472265756 | validation: 1.2657197975833738]
	TIME [epoch: 8.06 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1273952149494142		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.1273952149494142 | validation: 1.4998130868133444]
	TIME [epoch: 108 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4245249875207517		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.4245249875207517 | validation: 1.1272943553229888]
	TIME [epoch: 16 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1893559143801442		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.1893559143801442 | validation: 1.4028664231509604]
	TIME [epoch: 15.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526430753604605		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.526430753604605 | validation: 1.8860901094360942]
	TIME [epoch: 15.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.496766267879301		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.496766267879301 | validation: 3.990052328724095]
	TIME [epoch: 15.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3277668848827937		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.3277668848827937 | validation: 1.3460606841116574]
	TIME [epoch: 15.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297866823183983		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.2297866823183983 | validation: 1.2385263138712805]
	TIME [epoch: 15.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8591419215075966		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.8591419215075966 | validation: 1.2413859214661807]
	TIME [epoch: 16 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3244991507354216		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.3244991507354216 | validation: 1.4307676713164506]
	TIME [epoch: 16 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3366653557169625		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.3366653557169625 | validation: 1.3131476152310215]
	TIME [epoch: 15.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4563011187551478		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.4563011187551478 | validation: 1.8172855314058998]
	TIME [epoch: 15.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4081930831081053		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.4081930831081053 | validation: 1.3614343999294376]
	TIME [epoch: 16 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5573796261170345		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.5573796261170345 | validation: 1.4175401631483613]
	TIME [epoch: 16 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3108878084571927		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.3108878084571927 | validation: 1.1953735443772873]
	TIME [epoch: 15.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5332554388765443		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.5332554388765443 | validation: 2.0263390646382633]
	TIME [epoch: 16 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133976173105413		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.133976173105413 | validation: 2.0030646324930146]
	TIME [epoch: 15.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6075492771513678		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.6075492771513678 | validation: 1.2196284177162136]
	TIME [epoch: 15.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5198084770457458		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.5198084770457458 | validation: 2.109654792365326]
	TIME [epoch: 15.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5478295745679844		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.5478295745679844 | validation: 2.0689407075216506]
	TIME [epoch: 15.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6701261767853417		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.6701261767853417 | validation: 1.1930803593076056]
	TIME [epoch: 15.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3291328397081272		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.3291328397081272 | validation: 1.7610886784268023]
	TIME [epoch: 15.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4423183469896206		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.4423183469896206 | validation: 1.305103764122301]
	TIME [epoch: 15.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1750473128302192		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1750473128302192 | validation: 1.1068714068844863]
	TIME [epoch: 15.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3554434470536993		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.3554434470536993 | validation: 1.3632960459473287]
	TIME [epoch: 15.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2512275924922516		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.2512275924922516 | validation: 1.2410334031677368]
	TIME [epoch: 15.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2302890286771189		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.2302890286771189 | validation: 1.1714854646721466]
	TIME [epoch: 15.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1653118882913212		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.1653118882913212 | validation: 1.5687354899803105]
	TIME [epoch: 15.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4751051215587758		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.4751051215587758 | validation: 1.1605522181223176]
	TIME [epoch: 15.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3045788838140657		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.3045788838140657 | validation: 1.799883294788858]
	TIME [epoch: 15.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2621512622494508		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.2621512622494508 | validation: 2.5859365578018885]
	TIME [epoch: 15.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6383736192660614		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.6383736192660614 | validation: 1.2282903233480926]
	TIME [epoch: 15.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400677656724674		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.1400677656724674 | validation: 1.391068151028617]
	TIME [epoch: 15.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3402933209132621		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.3402933209132621 | validation: 1.388353035511712]
	TIME [epoch: 15.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268492364954875		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.268492364954875 | validation: 2.0801878026891476]
	TIME [epoch: 15.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5041170361985996		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.5041170361985996 | validation: 1.969092312568089]
	TIME [epoch: 15.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5628007726191258		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.5628007726191258 | validation: 1.235814943251384]
	TIME [epoch: 15.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4835985971583387		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.4835985971583387 | validation: 1.0157997720794034]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4706102630469853		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.4706102630469853 | validation: 1.2240200428318861]
	TIME [epoch: 15.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544445497232807		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.1544445497232807 | validation: 1.186323211049916]
	TIME [epoch: 15.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0948365713926664		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.0948365713926664 | validation: 2.121288716043492]
	TIME [epoch: 15.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.479555747963195		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.479555747963195 | validation: 1.1975503096851257]
	TIME [epoch: 15.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3113305250102691		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.3113305250102691 | validation: 1.385593465538261]
	TIME [epoch: 15.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4039293920474123		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.4039293920474123 | validation: 1.1192617990928342]
	TIME [epoch: 15.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228548189615252		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.228548189615252 | validation: 1.2943571850296534]
	TIME [epoch: 15.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1813512581281496		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.1813512581281496 | validation: 1.5406335934494408]
	TIME [epoch: 15.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290717721661864		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.290717721661864 | validation: 1.2374945124352124]
	TIME [epoch: 15.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3555433200694802		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.3555433200694802 | validation: 2.2169011394682987]
	TIME [epoch: 15.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5713234486237337		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.5713234486237337 | validation: 0.9903219532524481]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6485240223144029		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.6485240223144029 | validation: 1.4914409757918945]
	TIME [epoch: 15.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4417227129503372		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.4417227129503372 | validation: 1.3600173518599092]
	TIME [epoch: 15.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370384567395316		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.370384567395316 | validation: 1.1704338324215566]
	TIME [epoch: 15.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102057202098237		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.102057202098237 | validation: 1.2762804904203813]
	TIME [epoch: 15.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370806117908556		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.370806117908556 | validation: 1.4480438213100504]
	TIME [epoch: 15.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3642628613433259		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.3642628613433259 | validation: 1.200949092749957]
	TIME [epoch: 16 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186339677297279		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.186339677297279 | validation: 2.6247084278752153]
	TIME [epoch: 15.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8346929746527914		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.8346929746527914 | validation: 1.0853275918615353]
	TIME [epoch: 15.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.117346303942086		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.117346303942086 | validation: 3.1058324527887917]
	TIME [epoch: 15.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1380791116345863		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.1380791116345863 | validation: 1.630654190140788]
	TIME [epoch: 15.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484977130444336		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.484977130444336 | validation: 1.4123778785919847]
	TIME [epoch: 15.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162670533927635		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.2162670533927635 | validation: 1.2197957435114075]
	TIME [epoch: 15.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1183345839049947		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.1183345839049947 | validation: 1.115580237237722]
	TIME [epoch: 15.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3164988503653858		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.3164988503653858 | validation: 1.006735325107741]
	TIME [epoch: 15.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112786983724296		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.3112786983724296 | validation: 1.405063293886741]
	TIME [epoch: 15.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7760215953886085		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.7760215953886085 | validation: 1.5963715036458823]
	TIME [epoch: 15.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1980624651702965		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.1980624651702965 | validation: 1.620219463979303]
	TIME [epoch: 15.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3084958952798513		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.3084958952798513 | validation: 1.0692477886528566]
	TIME [epoch: 15.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2913131230314394		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.2913131230314394 | validation: 0.9478300977921053]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214064500905875		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.0214064500905875 | validation: 1.1993142502337262]
	TIME [epoch: 15.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058168885549421		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.058168885549421 | validation: 1.275123036262768]
	TIME [epoch: 15.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033321752288651		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.033321752288651 | validation: 1.8952756073101868]
	TIME [epoch: 15.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2782541508036842		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.2782541508036842 | validation: 0.9047779863683696]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1347602830715764		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.1347602830715764 | validation: 0.9651668510577956]
	TIME [epoch: 15.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1462314405601624		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1462314405601624 | validation: 1.564833856068104]
	TIME [epoch: 15.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4858286001747212		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.4858286001747212 | validation: 1.0468199179920838]
	TIME [epoch: 15.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0981187801186258		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0981187801186258 | validation: 1.1880234085216257]
	TIME [epoch: 15.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2986649651958886		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.2986649651958886 | validation: 1.162137440774636]
	TIME [epoch: 15.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1068388551684574		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.1068388551684574 | validation: 1.981567998795841]
	TIME [epoch: 15.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5179481068383809		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.5179481068383809 | validation: 0.971508764552552]
	TIME [epoch: 15.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9738756391305559		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9738756391305559 | validation: 1.7276126736438147]
	TIME [epoch: 15.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4153998076564922		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.4153998076564922 | validation: 1.3753394312582725]
	TIME [epoch: 15.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1166847096597683		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1166847096597683 | validation: 1.4011160629820334]
	TIME [epoch: 15.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0292880142188203		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.0292880142188203 | validation: 1.8351750015077042]
	TIME [epoch: 15.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2363553341861848		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.2363553341861848 | validation: 3.3564950193274194]
	TIME [epoch: 15.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.028365845080906		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.028365845080906 | validation: 1.137007942724518]
	TIME [epoch: 15.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4368222945230702		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.4368222945230702 | validation: 1.3871330276992833]
	TIME [epoch: 15.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1853543605234247		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.1853543605234247 | validation: 1.039401788458]
	TIME [epoch: 15.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4208360010217194		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.4208360010217194 | validation: 1.2714490603664568]
	TIME [epoch: 15.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3444222232147054		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.3444222232147054 | validation: 1.2540129257207053]
	TIME [epoch: 15.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921308666095474		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1921308666095474 | validation: 1.3849969973766592]
	TIME [epoch: 15.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250416080444284		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.250416080444284 | validation: 1.1788255921350834]
	TIME [epoch: 15.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0882957170090757		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.0882957170090757 | validation: 1.2996907772711006]
	TIME [epoch: 15.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173590676318335		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.173590676318335 | validation: 1.1776939169709015]
	TIME [epoch: 15.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1949103708831752		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.1949103708831752 | validation: 0.9317907451504055]
	TIME [epoch: 15.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0010833282185898		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.0010833282185898 | validation: 0.9914223623776469]
	TIME [epoch: 15.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1882810887347421		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.1882810887347421 | validation: 1.022832589670608]
	TIME [epoch: 16 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.425130999820413		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.425130999820413 | validation: 1.1351390539163697]
	TIME [epoch: 15.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292011714962909		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.292011714962909 | validation: 1.0830423391395247]
	TIME [epoch: 15.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1045033394826662		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.1045033394826662 | validation: 0.9749653069279727]
	TIME [epoch: 15.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.206135219168302		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.206135219168302 | validation: 0.9060241548358747]
	TIME [epoch: 15.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0894476762003882		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.0894476762003882 | validation: 1.3701316203349199]
	TIME [epoch: 15.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.225348795144503		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.225348795144503 | validation: 1.6786554270681382]
	TIME [epoch: 15.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301904947994933		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.2301904947994933 | validation: 1.1506909344091203]
	TIME [epoch: 15.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1602768063074977		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.1602768063074977 | validation: 1.1776972252146996]
	TIME [epoch: 15.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0880853372318766		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.0880853372318766 | validation: 0.9077732098953968]
	TIME [epoch: 15.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9512730374637518		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.9512730374637518 | validation: 0.8797988337333256]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953218924981435		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8953218924981435 | validation: 2.1100182632693536]
	TIME [epoch: 15.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1723714470551398		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.1723714470551398 | validation: 1.407534380890157]
	TIME [epoch: 15.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0084729637000822		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.0084729637000822 | validation: 3.0679125474341733]
	TIME [epoch: 15.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.173903126248592		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.173903126248592 | validation: 1.1546081520737834]
	TIME [epoch: 15.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0123969839920797		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.0123969839920797 | validation: 2.0245861106192913]
	TIME [epoch: 15.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6472131909800636		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.6472131909800636 | validation: 0.9724701149628179]
	TIME [epoch: 15.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8713255523467527		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.8713255523467527 | validation: 1.2229852422299572]
	TIME [epoch: 15.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9233294260974582		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.9233294260974582 | validation: 0.828719714676678]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8944366089503787		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.8944366089503787 | validation: 1.00800301949351]
	TIME [epoch: 16.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8892126020143207		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.8892126020143207 | validation: 1.8532473900218762]
	TIME [epoch: 15.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1145805383554128		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.1145805383554128 | validation: 1.1528918123197898]
	TIME [epoch: 15.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0935041878332816		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.0935041878332816 | validation: 1.3427506483678706]
	TIME [epoch: 15.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3684862937950686		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.3684862937950686 | validation: 1.1581023702715205]
	TIME [epoch: 15.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9643851571364656		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9643851571364656 | validation: 1.269133650345366]
	TIME [epoch: 15.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2340029269053603		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.2340029269053603 | validation: 0.8611836206010834]
	TIME [epoch: 15.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9392036291031582		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.9392036291031582 | validation: 2.4947402228932845]
	TIME [epoch: 15.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726418881487736		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.726418881487736 | validation: 1.3737836432153843]
	TIME [epoch: 15.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161342946759068		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.161342946759068 | validation: 1.1935621976404014]
	TIME [epoch: 15.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.971449827581021		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.971449827581021 | validation: 0.958370877195998]
	TIME [epoch: 15.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9919088382020631		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.9919088382020631 | validation: 0.9647563857638881]
	TIME [epoch: 15.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8814818359297929		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8814818359297929 | validation: 1.1910492340082777]
	TIME [epoch: 15.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9673372641139262		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.9673372641139262 | validation: 1.5989988959700852]
	TIME [epoch: 15.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2450066390193768		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.2450066390193768 | validation: 2.484677091283704]
	TIME [epoch: 15.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8068435604365558		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.8068435604365558 | validation: 2.8948463312702866]
	TIME [epoch: 15.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.819020806347297		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.819020806347297 | validation: 1.1612991837251916]
	TIME [epoch: 15.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9341081947644886		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.9341081947644886 | validation: 0.8916479373271116]
	TIME [epoch: 15.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0282607453790609		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0282607453790609 | validation: 1.0887407056785676]
	TIME [epoch: 15.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3022874869588212		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.3022874869588212 | validation: 1.6317696158536505]
	TIME [epoch: 15.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173552370192662		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.173552370192662 | validation: 1.970832037428608]
	TIME [epoch: 15.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.259052986070608		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.259052986070608 | validation: 1.103573303568653]
	TIME [epoch: 15.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8875158774920112		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.8875158774920112 | validation: 0.8624227610669825]
	TIME [epoch: 15.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1356430975066127		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.1356430975066127 | validation: 1.1447893043623782]
	TIME [epoch: 15.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836518025453096		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.9836518025453096 | validation: 0.8701820307178663]
	TIME [epoch: 15.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9604830393277365		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9604830393277365 | validation: 1.1574928125277582]
	TIME [epoch: 15.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8847932140197019		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8847932140197019 | validation: 1.0225338238767225]
	TIME [epoch: 15.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033920328751955		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.033920328751955 | validation: 0.8200866868782202]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1795017666847047		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.1795017666847047 | validation: 1.038265686945625]
	TIME [epoch: 15.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9661539203791257		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.9661539203791257 | validation: 0.8255588717698963]
	TIME [epoch: 15.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8699520935725837		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8699520935725837 | validation: 1.045247590121369]
	TIME [epoch: 15.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2370506426924424		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.2370506426924424 | validation: 0.9070412826911703]
	TIME [epoch: 15.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689318407186129		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7689318407186129 | validation: 0.8351413765721603]
	TIME [epoch: 15.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396927727646712		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8396927727646712 | validation: 1.0727272680595576]
	TIME [epoch: 15.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.949238171089688		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.949238171089688 | validation: 0.9733433214573366]
	TIME [epoch: 15.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9607775846582061		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.9607775846582061 | validation: 1.9622835588021665]
	TIME [epoch: 15.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5276722226210513		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.5276722226210513 | validation: 1.1692212774349644]
	TIME [epoch: 15.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9950386311695523		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.9950386311695523 | validation: 3.4319094690715053]
	TIME [epoch: 15.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9647592577929456		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.9647592577929456 | validation: 0.9919462099419243]
	TIME [epoch: 15.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9454054156444782		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.9454054156444782 | validation: 0.9683906609277029]
	TIME [epoch: 15.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056942478847616		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.056942478847616 | validation: 1.1263787688501117]
	TIME [epoch: 15.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597125102410613		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.9597125102410613 | validation: 1.3145012129205442]
	TIME [epoch: 15.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1230507270708399		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.1230507270708399 | validation: 0.921748644690072]
	TIME [epoch: 15.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060693853088154		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.9060693853088154 | validation: 1.1074832985084944]
	TIME [epoch: 15.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.877371024536801		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.877371024536801 | validation: 0.9047210966370476]
	TIME [epoch: 15.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8527594941391281		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8527594941391281 | validation: 0.940673149387014]
	TIME [epoch: 15.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0131647949414788		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.0131647949414788 | validation: 1.106545869673731]
	TIME [epoch: 15.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8506816701987262		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.8506816701987262 | validation: 1.0435217963669692]
	TIME [epoch: 15.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040484506840413		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.1040484506840413 | validation: 1.1375478382410789]
	TIME [epoch: 15.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655144328752923		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.0655144328752923 | validation: 1.371800697597977]
	TIME [epoch: 15.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8903025226956842		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.8903025226956842 | validation: 1.2235662460718029]
	TIME [epoch: 15.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92020888406255		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.92020888406255 | validation: 0.8066803756822486]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878652783564852		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.9878652783564852 | validation: 0.8524907988930241]
	TIME [epoch: 15.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043124955776736		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.043124955776736 | validation: 2.8449324511164535]
	TIME [epoch: 15.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6625277218117032		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.6625277218117032 | validation: 1.4138492859469423]
	TIME [epoch: 15.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0007573358227555		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.0007573358227555 | validation: 0.9113540291568257]
	TIME [epoch: 15.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182458632353113		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.8182458632353113 | validation: 1.1072616767324104]
	TIME [epoch: 15.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8928596301904264		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8928596301904264 | validation: 0.8877535901950202]
	TIME [epoch: 15.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8582420127817146		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8582420127817146 | validation: 1.366987388273107]
	TIME [epoch: 15.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014679104344245		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.014679104344245 | validation: 1.1451893868174634]
	TIME [epoch: 15.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9833793873921421		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.9833793873921421 | validation: 1.0492185362412387]
	TIME [epoch: 15.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3471117789975455		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.3471117789975455 | validation: 1.991331133157007]
	TIME [epoch: 15.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3157589149526612		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.3157589149526612 | validation: 0.8082460555651562]
	TIME [epoch: 15.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154908367549746		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8154908367549746 | validation: 1.3713283916396208]
	TIME [epoch: 15.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0191323941720802		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.0191323941720802 | validation: 0.9168269353944818]
	TIME [epoch: 15.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.225160235824532		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.225160235824532 | validation: 0.9270375402667029]
	TIME [epoch: 15.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8955252103302149		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.8955252103302149 | validation: 0.9189266476273259]
	TIME [epoch: 15.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9648671897096557		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.9648671897096557 | validation: 1.1073602085302219]
	TIME [epoch: 15.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1953486270147506		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.1953486270147506 | validation: 0.7770880832987861]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375011234857397		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.8375011234857397 | validation: 2.0592240100167793]
	TIME [epoch: 15.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3197540754209443		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.3197540754209443 | validation: 0.7959005113130164]
	TIME [epoch: 15.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8292508521940558		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8292508521940558 | validation: 1.0342111398864373]
	TIME [epoch: 15.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.955224478619573		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.955224478619573 | validation: 1.2868130531653774]
	TIME [epoch: 15.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9926526408206743		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.9926526408206743 | validation: 1.0020305782421899]
	TIME [epoch: 15.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0030523416300703		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.0030523416300703 | validation: 1.3327478320867239]
	TIME [epoch: 15.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0838406553927609		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.0838406553927609 | validation: 1.1820970910117716]
	TIME [epoch: 15.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9925929127099593		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.9925929127099593 | validation: 0.8165822190890969]
	TIME [epoch: 15.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8688826056823117		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8688826056823117 | validation: 0.9265677526453668]
	TIME [epoch: 15.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826904742423223		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.8826904742423223 | validation: 0.8308065411555727]
	TIME [epoch: 15.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9668877826243356		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9668877826243356 | validation: 0.8000601298333472]
	TIME [epoch: 15.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244460847784252		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.244460847784252 | validation: 0.9779423712829418]
	TIME [epoch: 15.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3686999943609788		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.3686999943609788 | validation: 1.8163229371408023]
	TIME [epoch: 15.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3475147890187227		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.3475147890187227 | validation: 1.0844384534865574]
	TIME [epoch: 15.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371694117942368		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.1371694117942368 | validation: 0.9488191681635005]
	TIME [epoch: 15.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133402480260517		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.133402480260517 | validation: 0.9222738202029437]
	TIME [epoch: 15.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809767496676263		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7809767496676263 | validation: 0.9778750810044724]
	TIME [epoch: 15.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9972959027508358		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.9972959027508358 | validation: 1.3719389217798577]
	TIME [epoch: 15.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350957491768934		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.1350957491768934 | validation: 1.1458341384036403]
	TIME [epoch: 15.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9106993179482908		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.9106993179482908 | validation: 0.8123003834993674]
	TIME [epoch: 15.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272075840544336		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.8272075840544336 | validation: 0.9309242346714286]
	TIME [epoch: 15.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8505935023517961		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8505935023517961 | validation: 1.077293565620204]
	TIME [epoch: 15.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8158517148940845		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.8158517148940845 | validation: 0.7191565746123421]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487176237430721		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.9487176237430721 | validation: 0.7603926383199429]
	TIME [epoch: 15.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329887491278502		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7329887491278502 | validation: 0.9900020961204026]
	TIME [epoch: 15.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9257461199519588		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.9257461199519588 | validation: 0.9574981489558219]
	TIME [epoch: 15.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509727762645372		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.8509727762645372 | validation: 1.2439074493095141]
	TIME [epoch: 15.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8414819381394232		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.8414819381394232 | validation: 0.6892922447038381]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956224064318318		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7956224064318318 | validation: 0.6511952548022901]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9941448042364297		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.9941448042364297 | validation: 0.7567596874446061]
	TIME [epoch: 15.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84761397049137		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.84761397049137 | validation: 0.7862063329874237]
	TIME [epoch: 15.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430717008552164		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.9430717008552164 | validation: 0.8170188927160313]
	TIME [epoch: 15.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7932831922518327		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7932831922518327 | validation: 0.80897842006811]
	TIME [epoch: 15.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786242462080286		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.786242462080286 | validation: 0.7408658607328471]
	TIME [epoch: 15.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9077602282814262		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.9077602282814262 | validation: 0.746549167532675]
	TIME [epoch: 15.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8525253905188064		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.8525253905188064 | validation: 0.7165580485258384]
	TIME [epoch: 15.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8757507197585573		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.8757507197585573 | validation: 0.6671562763933688]
	TIME [epoch: 15.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984126718548178		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.6984126718548178 | validation: 1.060802232393538]
	TIME [epoch: 15.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401541838429325		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.8401541838429325 | validation: 1.0567213915223128]
	TIME [epoch: 15.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9641483931834436		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.9641483931834436 | validation: 1.1148180928948548]
	TIME [epoch: 15.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810150432375642		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.810150432375642 | validation: 1.1149144232223893]
	TIME [epoch: 15.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8996521881964503		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.8996521881964503 | validation: 0.7264302037819292]
	TIME [epoch: 15.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8408865916255847		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8408865916255847 | validation: 0.7435575336929519]
	TIME [epoch: 15.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966564073832733		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.966564073832733 | validation: 1.126237893396655]
	TIME [epoch: 15.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9951160398961202		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.9951160398961202 | validation: 0.7686446212858438]
	TIME [epoch: 15.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8631628268850509		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.8631628268850509 | validation: 1.0189120652839752]
	TIME [epoch: 15.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8420808787540637		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.8420808787540637 | validation: 0.8435690533553987]
	TIME [epoch: 15.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8600821526227536		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.8600821526227536 | validation: 1.0387948673054277]
	TIME [epoch: 15.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3065882643335378		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.3065882643335378 | validation: 1.437157970683753]
	TIME [epoch: 15.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247880655947497		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.0247880655947497 | validation: 0.992054743157239]
	TIME [epoch: 15.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617823402750838		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.9617823402750838 | validation: 0.8892097340760663]
	TIME [epoch: 15.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589793821086743		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7589793821086743 | validation: 0.704856008172434]
	TIME [epoch: 15.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659614619633581		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7659614619633581 | validation: 0.7427267516752857]
	TIME [epoch: 15.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161550244048464		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7161550244048464 | validation: 0.7713856599838886]
	TIME [epoch: 15.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488982193259687		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.8488982193259687 | validation: 0.7966927559160863]
	TIME [epoch: 15.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8643795507472471		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8643795507472471 | validation: 1.0751635134761655]
	TIME [epoch: 15.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685399151152609		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.7685399151152609 | validation: 0.8274126489616564]
	TIME [epoch: 15.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.757579174456343		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.757579174456343 | validation: 0.9152235775354061]
	TIME [epoch: 15.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.809632795122111		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.809632795122111 | validation: 0.9097747438208779]
	TIME [epoch: 15.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1491404989972804		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.1491404989972804 | validation: 0.7676240643374213]
	TIME [epoch: 15.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9239693102874478		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.9239693102874478 | validation: 0.7335756157161997]
	TIME [epoch: 15.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683612935756245		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.683612935756245 | validation: 1.0562106133274813]
	TIME [epoch: 15.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90735590861064		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.90735590861064 | validation: 0.8952568334027318]
	TIME [epoch: 15.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170612149824581		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.8170612149824581 | validation: 0.8732867109759749]
	TIME [epoch: 15.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7913370521518028		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.7913370521518028 | validation: 0.8068608697280202]
	TIME [epoch: 15.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8791015424368074		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.8791015424368074 | validation: 0.8198534583985713]
	TIME [epoch: 15.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435355927638441		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6435355927638441 | validation: 0.6708430738328699]
	TIME [epoch: 15.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500118898240327		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.7500118898240327 | validation: 0.6279738106327225]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863749460112446		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.7863749460112446 | validation: 0.8549571405284304]
	TIME [epoch: 15.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685007643327879		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7685007643327879 | validation: 0.7090157230283289]
	TIME [epoch: 15.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937090636276573		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6937090636276573 | validation: 1.850402495675167]
	TIME [epoch: 15.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192025357186924		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.192025357186924 | validation: 0.950848677086285]
	TIME [epoch: 15.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8086204254326413		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.8086204254326413 | validation: 0.8511738270029421]
	TIME [epoch: 15.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6607491705882951		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.6607491705882951 | validation: 1.667316161218882]
	TIME [epoch: 15.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9335832034168787		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.9335832034168787 | validation: 1.1305161403344597]
	TIME [epoch: 15.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2923076568609762		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.2923076568609762 | validation: 1.8338168935759644]
	TIME [epoch: 15.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1019866294567684		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.1019866294567684 | validation: 0.7994451291061473]
	TIME [epoch: 15.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062832985056477		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7062832985056477 | validation: 0.7850818011470215]
	TIME [epoch: 15.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7407556014136176		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.7407556014136176 | validation: 0.8133731979921219]
	TIME [epoch: 15.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7877972565537892		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7877972565537892 | validation: 1.2252395000135938]
	TIME [epoch: 15.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475512287826336		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.8475512287826336 | validation: 0.8568075784012785]
	TIME [epoch: 15.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8330286364352232		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8330286364352232 | validation: 1.3141453313515918]
	TIME [epoch: 15.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8480761501197718		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.8480761501197718 | validation: 0.7443555208900692]
	TIME [epoch: 15.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608599776689284		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7608599776689284 | validation: 1.0255090981948294]
	TIME [epoch: 15.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623356100514606		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7623356100514606 | validation: 0.7869257049052483]
	TIME [epoch: 15.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545719798475634		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.7545719798475634 | validation: 0.8756352487330252]
	TIME [epoch: 15.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879322326576884		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.8879322326576884 | validation: 0.7178903206212996]
	TIME [epoch: 15.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972467264683708		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6972467264683708 | validation: 0.9208125358055192]
	TIME [epoch: 15.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882496343321596		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6882496343321596 | validation: 0.7901668689348473]
	TIME [epoch: 15.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232653016123909		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.7232653016123909 | validation: 0.827115824911457]
	TIME [epoch: 15.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302746151539516		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7302746151539516 | validation: 1.314051572465018]
	TIME [epoch: 15.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4589560307450595		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.4589560307450595 | validation: 1.9068765834424912]
	TIME [epoch: 15.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053378084163371		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.053378084163371 | validation: 0.8183826424344143]
	TIME [epoch: 15.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872882767442191		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6872882767442191 | validation: 0.6592706253668392]
	TIME [epoch: 15.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349380357486164		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7349380357486164 | validation: 0.8929240762762186]
	TIME [epoch: 15.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078755971739884		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7078755971739884 | validation: 0.8705728196661557]
	TIME [epoch: 15.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752334375104491		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.8752334375104491 | validation: 0.9223641769053614]
	TIME [epoch: 15.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7344854683975337		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.7344854683975337 | validation: 0.7586584754270203]
	TIME [epoch: 15.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7878351308720637		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.7878351308720637 | validation: 1.1750394463833902]
	TIME [epoch: 15.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371860683405711		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.8371860683405711 | validation: 1.0471423392256596]
	TIME [epoch: 15.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052196618515787		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.052196618515787 | validation: 0.7020661639452956]
	TIME [epoch: 16 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6595667649779603		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.6595667649779603 | validation: 0.7469954873071056]
	TIME [epoch: 15.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003994751181343		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7003994751181343 | validation: 0.7694115642892271]
	TIME [epoch: 15.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760976017652984		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6760976017652984 | validation: 0.6793473202108924]
	TIME [epoch: 15.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.838322959439066		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.838322959439066 | validation: 0.8877791290383925]
	TIME [epoch: 15.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85655243462187		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.85655243462187 | validation: 0.8184076472334885]
	TIME [epoch: 15.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749272604022133		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6749272604022133 | validation: 0.6950641586361892]
	TIME [epoch: 15.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603292430675094		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.6603292430675094 | validation: 0.7824546589482473]
	TIME [epoch: 15.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197137850829929		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7197137850829929 | validation: 0.9874860684683986]
	TIME [epoch: 15.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464879489295133		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.2464879489295133 | validation: 0.660641076618227]
	TIME [epoch: 15.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680191130017217		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6680191130017217 | validation: 0.9028739056209246]
	TIME [epoch: 15.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814424253406449		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.814424253406449 | validation: 0.6446859014051836]
	TIME [epoch: 15.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6573695345897508		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6573695345897508 | validation: 0.6487975961477002]
	TIME [epoch: 15.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802006517235051		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6802006517235051 | validation: 0.620115135199696]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271588440567414		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.7271588440567414 | validation: 0.802323496624287]
	TIME [epoch: 15.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421495809965274		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.8421495809965274 | validation: 0.8163236550590927]
	TIME [epoch: 15.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699895848271424		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6699895848271424 | validation: 0.5790840702910061]
	TIME [epoch: 15.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611708737632042		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5611708737632042 | validation: 0.5930230731125534]
	TIME [epoch: 15.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621214824845437		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.621214824845437 | validation: 1.2558712019370248]
	TIME [epoch: 127 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357306488827846		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7357306488827846 | validation: 0.6737943808433156]
	TIME [epoch: 34.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394784504297387		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6394784504297387 | validation: 0.5978476138620583]
	TIME [epoch: 34.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678114374212819		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7678114374212819 | validation: 0.6297232114252931]
	TIME [epoch: 34.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900850996304519		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5900850996304519 | validation: 0.624939883344213]
	TIME [epoch: 34.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376317284644125		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.7376317284644125 | validation: 0.5562401799618233]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7354797199344822		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.7354797199344822 | validation: 0.5677355134138724]
	TIME [epoch: 34.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670738268965374		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7670738268965374 | validation: 0.5276869497407928]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664076832960856		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.7664076832960856 | validation: 0.5580897599425441]
	TIME [epoch: 34.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8299716185203483		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.8299716185203483 | validation: 1.0179864900164526]
	TIME [epoch: 34.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8780246909389452		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.8780246909389452 | validation: 0.9778636416647712]
	TIME [epoch: 34.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7983732137347728		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7983732137347728 | validation: 0.6705773537940019]
	TIME [epoch: 34.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568475514592337		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.568475514592337 | validation: 0.7879601621083157]
	TIME [epoch: 34.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771364186459418		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.6771364186459418 | validation: 0.8330974379148461]
	TIME [epoch: 34.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7741314999948605		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7741314999948605 | validation: 0.9586452625087407]
	TIME [epoch: 34.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8156565930497335		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.8156565930497335 | validation: 0.5563444089047707]
	TIME [epoch: 34.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6340619087846675		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6340619087846675 | validation: 0.7444814868707804]
	TIME [epoch: 34.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312685184001003		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6312685184001003 | validation: 0.7841189478898706]
	TIME [epoch: 34.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536645193788729		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6536645193788729 | validation: 0.8862573432654093]
	TIME [epoch: 34.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547039159757149		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.6547039159757149 | validation: 0.6417821055628283]
	TIME [epoch: 34.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810445958931243		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5810445958931243 | validation: 1.230666330811898]
	TIME [epoch: 34.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8159478115107445		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.8159478115107445 | validation: 0.7301197585089412]
	TIME [epoch: 34.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001756018401048		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.9001756018401048 | validation: 1.3100764622696086]
	TIME [epoch: 34.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1896372025679638		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.1896372025679638 | validation: 0.8801708966102942]
	TIME [epoch: 34.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7072557456677397		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.7072557456677397 | validation: 0.5829826578820887]
	TIME [epoch: 34.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193507585099274		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.7193507585099274 | validation: 1.061736727656592]
	TIME [epoch: 34.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071527707767935		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.8071527707767935 | validation: 0.7799012786703785]
	TIME [epoch: 34.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599480009845638		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.599480009845638 | validation: 0.573327872730625]
	TIME [epoch: 34.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113113312928809		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.8113113312928809 | validation: 0.6492198314022245]
	TIME [epoch: 34.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5597241074695803		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.5597241074695803 | validation: 0.7353761887822621]
	TIME [epoch: 34.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095409449121655		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7095409449121655 | validation: 0.8742972448758712]
	TIME [epoch: 34.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6071924769132052		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.6071924769132052 | validation: 0.5359668503547962]
	TIME [epoch: 34.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394211685773378		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6394211685773378 | validation: 0.7539740029018371]
	TIME [epoch: 34.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453453924815379		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.6453453924815379 | validation: 0.7486354427212445]
	TIME [epoch: 34.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7152932454701965		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.7152932454701965 | validation: 0.7840744620177889]
	TIME [epoch: 34.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268490686622135		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.7268490686622135 | validation: 0.6176169215488745]
	TIME [epoch: 34.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726218578043976		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5726218578043976 | validation: 0.6194947160643605]
	TIME [epoch: 34.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.631920373577894		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.631920373577894 | validation: 0.7260440937053201]
	TIME [epoch: 34.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676439576376647		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.7676439576376647 | validation: 1.5890838693088183]
	TIME [epoch: 34.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2558724309610818		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.2558724309610818 | validation: 0.9089787925325514]
	TIME [epoch: 34.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664239580070132		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6664239580070132 | validation: 0.5233092098421616]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040868107335988		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7040868107335988 | validation: 0.6560001525020838]
	TIME [epoch: 34.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390323983961467		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6390323983961467 | validation: 0.6503381398536972]
	TIME [epoch: 34.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372894911040955		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5372894911040955 | validation: 0.6928070498935086]
	TIME [epoch: 34.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508621868263721		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.5508621868263721 | validation: 0.5108119175063045]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090756381046642		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.7090756381046642 | validation: 0.7648823557501618]
	TIME [epoch: 34.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024463951962812		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7024463951962812 | validation: 0.6653727190485326]
	TIME [epoch: 34.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451869124828298		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5451869124828298 | validation: 0.64977619581212]
	TIME [epoch: 34.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611417166073271		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5611417166073271 | validation: 0.5793830596653244]
	TIME [epoch: 34.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5599343610832964		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.5599343610832964 | validation: 0.6208858773379515]
	TIME [epoch: 34.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642904827466138		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5642904827466138 | validation: 0.7119090053642786]
	TIME [epoch: 34.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.915292350518779		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.915292350518779 | validation: 0.8961156533024477]
	TIME [epoch: 34.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411226859618999		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7411226859618999 | validation: 0.8298469054922963]
	TIME [epoch: 34.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518482237753638		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6518482237753638 | validation: 0.9258379725104793]
	TIME [epoch: 34.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7365476412636578		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7365476412636578 | validation: 1.1455716264437874]
	TIME [epoch: 34.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518392471934213		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6518392471934213 | validation: 0.6231784934905253]
	TIME [epoch: 34.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253112821222111		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6253112821222111 | validation: 0.587974150658054]
	TIME [epoch: 34.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630784395390408		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5630784395390408 | validation: 0.7838074982978724]
	TIME [epoch: 34.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084584893020355		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.6084584893020355 | validation: 0.8095552462878881]
	TIME [epoch: 34.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454356068351946		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6454356068351946 | validation: 0.5340869585666792]
	TIME [epoch: 34.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685324305834524		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5685324305834524 | validation: 0.7254287040891776]
	TIME [epoch: 34.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350415710900945		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5350415710900945 | validation: 0.6204184414741063]
	TIME [epoch: 34.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955724584620326		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5955724584620326 | validation: 0.5624377019313296]
	TIME [epoch: 34.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398816995211809		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5398816995211809 | validation: 0.5876009674856286]
	TIME [epoch: 34.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733529673732375		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.733529673732375 | validation: 0.8747316729286517]
	TIME [epoch: 34.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936722502929369		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6936722502929369 | validation: 0.5538608974161223]
	TIME [epoch: 34.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525705305965473		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5525705305965473 | validation: 0.5132613705582472]
	TIME [epoch: 34.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203889035887435		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6203889035887435 | validation: 0.5106237334633049]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8746860331404476		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.8746860331404476 | validation: 0.6739084946826379]
	TIME [epoch: 34.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6632406937548742		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6632406937548742 | validation: 0.6292621341820059]
	TIME [epoch: 34.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230397902266735		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5230397902266735 | validation: 0.5557756542324648]
	TIME [epoch: 34.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8626956250428749		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.8626956250428749 | validation: 0.5931833295124539]
	TIME [epoch: 34.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179121439327248		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.5179121439327248 | validation: 0.7464483794758494]
	TIME [epoch: 34.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770731538931069		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.5770731538931069 | validation: 0.7125059482470364]
	TIME [epoch: 34.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177755123213784		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5177755123213784 | validation: 0.6043433580303463]
	TIME [epoch: 34.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5729757897234772		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5729757897234772 | validation: 0.5123580634385771]
	TIME [epoch: 34.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5489105085542652		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5489105085542652 | validation: 0.5744608899772232]
	TIME [epoch: 34.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49659765801824357		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.49659765801824357 | validation: 0.5176591933942882]
	TIME [epoch: 34.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5250310385085977		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5250310385085977 | validation: 0.6838562666370056]
	TIME [epoch: 34.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6534583508441985		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6534583508441985 | validation: 0.6705919456444904]
	TIME [epoch: 34.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065720882413678		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6065720882413678 | validation: 0.7806086292557608]
	TIME [epoch: 34.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566470786327242		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.566470786327242 | validation: 0.5037414481974827]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553636827242965		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5553636827242965 | validation: 0.5995561012545711]
	TIME [epoch: 34.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368961980009737		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6368961980009737 | validation: 0.5871548262292712]
	TIME [epoch: 34.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118581065225719		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.6118581065225719 | validation: 0.7090414324248042]
	TIME [epoch: 34.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6638933441510546		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6638933441510546 | validation: 0.5083257595205695]
	TIME [epoch: 34.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5102326031743071		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5102326031743071 | validation: 0.5470252444694188]
	TIME [epoch: 34.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5750807208940666		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5750807208940666 | validation: 1.016290477684974]
	TIME [epoch: 34.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807755502474392		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6807755502474392 | validation: 0.658284003473249]
	TIME [epoch: 34.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104096420834148		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.5104096420834148 | validation: 0.5792923615083606]
	TIME [epoch: 34.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6426790201766003		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6426790201766003 | validation: 0.6612212836834435]
	TIME [epoch: 34.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897108713672932		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5897108713672932 | validation: 0.5511602575448216]
	TIME [epoch: 34.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454299144421166		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5454299144421166 | validation: 0.5253463053482629]
	TIME [epoch: 34.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716794155730084		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.6716794155730084 | validation: 0.5713765025849666]
	TIME [epoch: 34.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834473540589379		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.4834473540589379 | validation: 0.5025280342846681]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472248820788527		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.4472248820788527 | validation: 0.6488215374559656]
	TIME [epoch: 34.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416152565594439		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5416152565594439 | validation: 0.6831865152215844]
	TIME [epoch: 34.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207214034128111		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.5207214034128111 | validation: 0.4884182733431047]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277626221163423		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5277626221163423 | validation: 0.8183274102184055]
	TIME [epoch: 34.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307082023694472		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.7307082023694472 | validation: 0.6747056890139631]
	TIME [epoch: 34.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992319049009457		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5992319049009457 | validation: 0.6203581639546654]
	TIME [epoch: 34.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7460759507461444		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.7460759507461444 | validation: 0.6035171781358754]
	TIME [epoch: 34.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527287141206163		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5527287141206163 | validation: 0.5221123534137923]
	TIME [epoch: 34.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950013753144758		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5950013753144758 | validation: 0.5496327281561375]
	TIME [epoch: 34.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7488239248020129		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.7488239248020129 | validation: 0.5516232202880316]
	TIME [epoch: 34.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7946152406013298		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.7946152406013298 | validation: 0.5519563682900046]
	TIME [epoch: 34.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191320552085342		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5191320552085342 | validation: 0.539192494314103]
	TIME [epoch: 34.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47273745227730735		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.47273745227730735 | validation: 0.7357759637334945]
	TIME [epoch: 34.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585089052795515		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5585089052795515 | validation: 0.4450389798919342]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_609.pth
	Model improved!!!
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598831697148601		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.598831697148601 | validation: 1.1193722944030235]
	TIME [epoch: 34.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347783635105843		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.7347783635105843 | validation: 0.956996441373506]
	TIME [epoch: 34.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585389057822457		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.6585389057822457 | validation: 0.5754677635097936]
	TIME [epoch: 34.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758743784534187		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5758743784534187 | validation: 0.5826245857279883]
	TIME [epoch: 34.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643828173190503		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4643828173190503 | validation: 0.5517013054863726]
	TIME [epoch: 34.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049174225563317		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6049174225563317 | validation: 0.6441217318638863]
	TIME [epoch: 34.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663434603448257		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5663434603448257 | validation: 0.650972997919543]
	TIME [epoch: 34.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354976698721023		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5354976698721023 | validation: 0.648366610671204]
	TIME [epoch: 34.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571146008108509		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.7571146008108509 | validation: 0.5195007813034191]
	TIME [epoch: 34.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512581708504065		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.512581708504065 | validation: 0.49166061202867556]
	TIME [epoch: 34.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602531016339174		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5602531016339174 | validation: 1.3835780594087757]
	TIME [epoch: 34.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8890967360931892		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.8890967360931892 | validation: 0.6554061315175124]
	TIME [epoch: 34.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593151272479671		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5593151272479671 | validation: 0.739601038902403]
	TIME [epoch: 34.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936909919682103		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5936909919682103 | validation: 0.6370284208631192]
	TIME [epoch: 34.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006407444697002		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6006407444697002 | validation: 0.5707816458755914]
	TIME [epoch: 34.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967077546574996		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.4967077546574996 | validation: 0.6457008630484643]
	TIME [epoch: 34.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47386990823523173		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.47386990823523173 | validation: 0.5839023157829728]
	TIME [epoch: 34.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47681884904885385		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.47681884904885385 | validation: 0.5302947098940296]
	TIME [epoch: 34.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5292592629629892		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5292592629629892 | validation: 0.6687806204702513]
	TIME [epoch: 34.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5951451358030536		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5951451358030536 | validation: 0.5899616982054701]
	TIME [epoch: 34.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977150731608006		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.4977150731608006 | validation: 0.5005601958633616]
	TIME [epoch: 34.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5719050096197258		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5719050096197258 | validation: 0.43266280849537]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4438314329241354		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.4438314329241354 | validation: 0.598441227446171]
	TIME [epoch: 34.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733082404136814		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5733082404136814 | validation: 0.5047130470121831]
	TIME [epoch: 34.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399270162765066		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5399270162765066 | validation: 0.47366469336212347]
	TIME [epoch: 34.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711129861523826		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.4711129861523826 | validation: 0.8748163810773781]
	TIME [epoch: 34.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922069203792543		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.7922069203792543 | validation: 0.5408107464657882]
	TIME [epoch: 34.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992631256854135		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.4992631256854135 | validation: 0.42741618222568933]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45809354365823185		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.45809354365823185 | validation: 0.43950913979590256]
	TIME [epoch: 34.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5408626227500707		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5408626227500707 | validation: 0.4755369072076355]
	TIME [epoch: 34.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43818009248554973		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.43818009248554973 | validation: 0.70163740872851]
	TIME [epoch: 34.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787844047163401		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4787844047163401 | validation: 0.5613035004146187]
	TIME [epoch: 34.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852720635730661		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.4852720635730661 | validation: 0.9135349545364595]
	TIME [epoch: 34.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6750778307383385		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.6750778307383385 | validation: 0.6499907364691039]
	TIME [epoch: 34.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115714050816518		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6115714050816518 | validation: 0.6196949022418693]
	TIME [epoch: 34.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48124194375375673		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.48124194375375673 | validation: 0.48277123181517057]
	TIME [epoch: 34.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4706690077282932		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.4706690077282932 | validation: 0.5242609658298762]
	TIME [epoch: 34.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6558009677728034		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6558009677728034 | validation: 0.46585508627534844]
	TIME [epoch: 34.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48909949024280047		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.48909949024280047 | validation: 0.47072649803002065]
	TIME [epoch: 34.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460889126722296		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.5460889126722296 | validation: 0.6265176618724013]
	TIME [epoch: 34.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336451095174446		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.5336451095174446 | validation: 0.4615395411076228]
	TIME [epoch: 34.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894090679789993		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5894090679789993 | validation: 0.60878684381523]
	TIME [epoch: 34.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5683775343603048		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5683775343603048 | validation: 0.7484581423591359]
	TIME [epoch: 34.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924040371800432		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5924040371800432 | validation: 0.496586546659474]
	TIME [epoch: 34.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502390947074755		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.502390947074755 | validation: 0.4289915910279979]
	TIME [epoch: 34.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177977550915526		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5177977550915526 | validation: 0.43481153913939363]
	TIME [epoch: 34.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279859469728208		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.4279859469728208 | validation: 0.5695053657518688]
	TIME [epoch: 34.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199722061965071		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.6199722061965071 | validation: 0.48889079335250685]
	TIME [epoch: 34.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42898646406469876		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.42898646406469876 | validation: 0.878762456085415]
	TIME [epoch: 34.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026662469401531		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.7026662469401531 | validation: 0.5756034323836474]
	TIME [epoch: 34.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035771713018717		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5035771713018717 | validation: 0.5424733695512969]
	TIME [epoch: 34.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669454301969273		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5669454301969273 | validation: 0.5085091319946753]
	TIME [epoch: 34.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502428662544689		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.502428662544689 | validation: 0.482821678878445]
	TIME [epoch: 34.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231683806119293		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5231683806119293 | validation: 0.45330734076157864]
	TIME [epoch: 34.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764662719175083		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5764662719175083 | validation: 0.5068496407838439]
	TIME [epoch: 34.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.463275968141182		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.463275968141182 | validation: 0.6953472836282253]
	TIME [epoch: 34.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530027559093072		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.530027559093072 | validation: 0.5047319668941228]
	TIME [epoch: 34.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4806097116942917		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4806097116942917 | validation: 0.5569787140920308]
	TIME [epoch: 34.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743195409348333		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.4743195409348333 | validation: 0.7371041929382582]
	TIME [epoch: 34.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480679279094751		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5480679279094751 | validation: 0.47815086154928155]
	TIME [epoch: 34.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205897698127002		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4205897698127002 | validation: 0.4582123223849619]
	TIME [epoch: 34.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823610962631171		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.4823610962631171 | validation: 0.5303097090764044]
	TIME [epoch: 34.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739175058566971		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.4739175058566971 | validation: 0.6009476331838263]
	TIME [epoch: 34.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238525881554376		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5238525881554376 | validation: 0.5134562200314889]
	TIME [epoch: 34.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4997658549414673		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.4997658549414673 | validation: 0.4653357672257413]
	TIME [epoch: 34.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45000495867871604		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.45000495867871604 | validation: 0.4232090507720102]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4962361116058701		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.4962361116058701 | validation: 0.42899243465970316]
	TIME [epoch: 34.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540239744190477		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5540239744190477 | validation: 0.46894794761557757]
	TIME [epoch: 34.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46985255839605444		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.46985255839605444 | validation: 0.4396779940282879]
	TIME [epoch: 34.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549250408437864		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.549250408437864 | validation: 0.4949637351536228]
	TIME [epoch: 34.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48998149676188885		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.48998149676188885 | validation: 0.5488726117498561]
	TIME [epoch: 34.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592505944021829		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.592505944021829 | validation: 0.48287581879392455]
	TIME [epoch: 34.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770041116757676		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5770041116757676 | validation: 0.5823262829763507]
	TIME [epoch: 34.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011093625241313		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5011093625241313 | validation: 0.8624550999675042]
	TIME [epoch: 34.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387808753207938		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5387808753207938 | validation: 0.4575121374297311]
	TIME [epoch: 34.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4962173678467062		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.4962173678467062 | validation: 0.5663302985848859]
	TIME [epoch: 34.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279654541924738		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5279654541924738 | validation: 0.9052370764820898]
	TIME [epoch: 34.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5734021511347025		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5734021511347025 | validation: 0.4348730318086778]
	TIME [epoch: 34.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509399671202187		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.4509399671202187 | validation: 0.710243569711185]
	TIME [epoch: 34.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398726813731133		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5398726813731133 | validation: 1.018451997468452]
	TIME [epoch: 34.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6402059638672325		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.6402059638672325 | validation: 0.6859119926519193]
	TIME [epoch: 34.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924582269586836		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.6924582269586836 | validation: 0.4215211652449309]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_691.pth
	Model improved!!!
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583877984362945		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.4583877984362945 | validation: 0.4851282771569507]
	TIME [epoch: 34.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771511545562837		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6771511545562837 | validation: 0.7873850153753807]
	TIME [epoch: 34.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570715167500967		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6570715167500967 | validation: 0.9300733528326861]
	TIME [epoch: 34.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6037135638501057		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6037135638501057 | validation: 0.7146442434658296]
	TIME [epoch: 34.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769255036652764		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.6769255036652764 | validation: 0.6076966433071781]
	TIME [epoch: 34.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914499313135887		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.6914499313135887 | validation: 0.7993773633172846]
	TIME [epoch: 34.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165549341299984		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.7165549341299984 | validation: 0.4950121918855501]
	TIME [epoch: 34.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055959044963336		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5055959044963336 | validation: 0.4962311345458622]
	TIME [epoch: 34.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164083529225287		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5164083529225287 | validation: 0.6086712032415371]
	TIME [epoch: 34.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5371905065772918		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5371905065772918 | validation: 0.4714623987659417]
	TIME [epoch: 34.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44231139323877894		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.44231139323877894 | validation: 0.6195823102996383]
	TIME [epoch: 34.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045906579316031		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5045906579316031 | validation: 0.44365565915845023]
	TIME [epoch: 34.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43103018951545863		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.43103018951545863 | validation: 0.4971505062360485]
	TIME [epoch: 34.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49557893848256757		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.49557893848256757 | validation: 0.49960726721518767]
	TIME [epoch: 34.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41795021141171396		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.41795021141171396 | validation: 0.5109824435106275]
	TIME [epoch: 34.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.434173083715208		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.434173083715208 | validation: 0.40524472400398637]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462799181060611		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.462799181060611 | validation: 0.41972343222059005]
	TIME [epoch: 34.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49866854889086554		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.49866854889086554 | validation: 0.42642925443601526]
	TIME [epoch: 34.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753558920943572		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.6753558920943572 | validation: 0.9618859706526621]
	TIME [epoch: 34.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352544460408807		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6352544460408807 | validation: 0.689063503470593]
	TIME [epoch: 34.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695216492524267		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4695216492524267 | validation: 0.3966777379703113]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302613801867287		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.4302613801867287 | validation: 0.44789714341065745]
	TIME [epoch: 34.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43467098199070126		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.43467098199070126 | validation: 0.43451626485358896]
	TIME [epoch: 34.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41956357908550684		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.41956357908550684 | validation: 0.8658251066762925]
	TIME [epoch: 34.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542041115515396		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5542041115515396 | validation: 0.6082077492794222]
	TIME [epoch: 34.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4819978046364671		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.4819978046364671 | validation: 0.47694057057324024]
	TIME [epoch: 34.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4653436941779853		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.4653436941779853 | validation: 0.4203813807940969]
	TIME [epoch: 34.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779587996012913		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4779587996012913 | validation: 0.4982444505258724]
	TIME [epoch: 34.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372881093217661		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5372881093217661 | validation: 0.6866098579432582]
	TIME [epoch: 34.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6197673608935009		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6197673608935009 | validation: 0.4625530153934243]
	TIME [epoch: 34.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48284689130313607		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.48284689130313607 | validation: 0.4872471036039959]
	TIME [epoch: 34.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672230562661608		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.4672230562661608 | validation: 0.4139161591242543]
	TIME [epoch: 34.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47484243347531446		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.47484243347531446 | validation: 0.5360302056827116]
	TIME [epoch: 34.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432035797293994		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.432035797293994 | validation: 0.47063483893199043]
	TIME [epoch: 34.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39869205513099737		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.39869205513099737 | validation: 0.46008253948917543]
	TIME [epoch: 34.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468859626001489		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.4468859626001489 | validation: 0.40868267808166575]
	TIME [epoch: 34.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45729679219015795		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.45729679219015795 | validation: 0.46810716588002743]
	TIME [epoch: 34.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42983147993302956		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.42983147993302956 | validation: 0.40242957992621153]
	TIME [epoch: 34.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46737564818833344		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.46737564818833344 | validation: 0.5568319606884882]
	TIME [epoch: 34.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082493124197801		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5082493124197801 | validation: 0.44353318376990225]
	TIME [epoch: 34.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45324516972258505		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.45324516972258505 | validation: 0.4544780368057053]
	TIME [epoch: 34.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885745870514991		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3885745870514991 | validation: 0.46315039754180054]
	TIME [epoch: 34.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728358677544755		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.4728358677544755 | validation: 0.5380202563234242]
	TIME [epoch: 34.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002600187271173		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.7002600187271173 | validation: 0.5208819650476568]
	TIME [epoch: 34.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531898027483377		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.531898027483377 | validation: 0.48573078285642707]
	TIME [epoch: 34.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4318416739578234		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4318416739578234 | validation: 0.5262510170078916]
	TIME [epoch: 34.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525286081917158		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.525286081917158 | validation: 0.48279903558319803]
	TIME [epoch: 34.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941996095182397		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5941996095182397 | validation: 0.7180573793622123]
	TIME [epoch: 34.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499667131931402		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5499667131931402 | validation: 0.48974749245358945]
	TIME [epoch: 34.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785027436817169		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.3785027436817169 | validation: 0.4899458998316196]
	TIME [epoch: 34.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38760943628380395		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.38760943628380395 | validation: 0.5050103622279407]
	TIME [epoch: 34.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4611177958144986		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4611177958144986 | validation: 0.46095678503181675]
	TIME [epoch: 34.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414958941446538		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.414958941446538 | validation: 0.4741035213984266]
	TIME [epoch: 34.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45267119813559203		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.45267119813559203 | validation: 0.40363729719894686]
	TIME [epoch: 34.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.489811152723928		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.489811152723928 | validation: 0.5245808778201255]
	TIME [epoch: 34.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602777260656738		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.4602777260656738 | validation: 0.4807356331870719]
	TIME [epoch: 34.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161581296916524		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5161581296916524 | validation: 0.4011817422490032]
	TIME [epoch: 34.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461414280881779		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4461414280881779 | validation: 0.43959323508244397]
	TIME [epoch: 34.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44089258705733264		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.44089258705733264 | validation: 0.4781610936325157]
	TIME [epoch: 34.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134307870106778		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5134307870106778 | validation: 0.47961796906099463]
	TIME [epoch: 34.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335650689545775		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.6335650689545775 | validation: 0.6298638532613615]
	TIME [epoch: 34.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721653593329146		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4721653593329146 | validation: 0.4123920835881217]
	TIME [epoch: 34.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4260869581790433		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4260869581790433 | validation: 0.6276767989068114]
	TIME [epoch: 34.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235690534404146		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5235690534404146 | validation: 0.6460411067273607]
	TIME [epoch: 34.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46631296361944935		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.46631296361944935 | validation: 0.46279579388245323]
	TIME [epoch: 34.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158719261041618		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5158719261041618 | validation: 0.6867949766376048]
	TIME [epoch: 34.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4758749190091669		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4758749190091669 | validation: 0.46866974110952053]
	TIME [epoch: 34.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46253802041552383		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.46253802041552383 | validation: 0.6098599260222757]
	TIME [epoch: 34.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268767400780386		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5268767400780386 | validation: 0.4208390468560148]
	TIME [epoch: 34.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876906300355496		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5876906300355496 | validation: 0.9138974962903204]
	TIME [epoch: 34.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020309733615343		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.6020309733615343 | validation: 0.37656020753303093]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_762.pth
	Model improved!!!
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35919443644075394		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.35919443644075394 | validation: 0.4508336896169979]
	TIME [epoch: 34.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921086691084477		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.3921086691084477 | validation: 0.4463017163251526]
	TIME [epoch: 34.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929904174313285		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3929904174313285 | validation: 0.46163927221973844]
	TIME [epoch: 34.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721779145985742		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.3721779145985742 | validation: 0.37563579031642913]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46609132230619676		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.46609132230619676 | validation: 0.419880073225797]
	TIME [epoch: 34.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585837975639502		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3585837975639502 | validation: 0.4577934794563657]
	TIME [epoch: 34.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497927297232056		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4497927297232056 | validation: 0.45414974023499377]
	TIME [epoch: 34.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025357801090477		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4025357801090477 | validation: 0.462688577210516]
	TIME [epoch: 34.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674848166646457		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4674848166646457 | validation: 0.5231149701926485]
	TIME [epoch: 34.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702334473379186		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3702334473379186 | validation: 0.3584810826098213]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41417280481817553		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.41417280481817553 | validation: 1.0565871698898772]
	TIME [epoch: 34.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674491469472661		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.674491469472661 | validation: 0.5129346755062015]
	TIME [epoch: 34.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4835285742309703		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4835285742309703 | validation: 0.5123807834707672]
	TIME [epoch: 34.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190939899943683		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.4190939899943683 | validation: 0.44615010732838933]
	TIME [epoch: 34.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675691359610981		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.3675691359610981 | validation: 0.6181866202903004]
	TIME [epoch: 34.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830775883226618		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.4830775883226618 | validation: 0.5593457103423709]
	TIME [epoch: 34.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851976639883034		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3851976639883034 | validation: 0.42447316261366896]
	TIME [epoch: 34.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384376473428965		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3384376473428965 | validation: 0.5109689349513179]
	TIME [epoch: 34.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616564950952347		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.5616564950952347 | validation: 0.7211081716309499]
	TIME [epoch: 34.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664682315494837		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.4664682315494837 | validation: 0.5235783834727696]
	TIME [epoch: 34.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724901418835237		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5724901418835237 | validation: 0.7636169251406859]
	TIME [epoch: 34.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577578902299365		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.577578902299365 | validation: 0.7656109645413086]
	TIME [epoch: 34.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554549659402871		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.6554549659402871 | validation: 0.4841443033940853]
	TIME [epoch: 34.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895701889528198		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.3895701889528198 | validation: 0.5482137560127606]
	TIME [epoch: 34.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43029685123131234		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.43029685123131234 | validation: 0.46404298093659985]
	TIME [epoch: 34.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419045426245008		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4419045426245008 | validation: 0.49444329458162756]
	TIME [epoch: 34.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46405815344469964		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.46405815344469964 | validation: 0.41915252475520726]
	TIME [epoch: 34.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798637880733923		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.3798637880733923 | validation: 0.4087677606615715]
	TIME [epoch: 34.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40327901289560847		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.40327901289560847 | validation: 0.43512736148132347]
	TIME [epoch: 34.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810394591908122		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.3810394591908122 | validation: 0.6712550855620607]
	TIME [epoch: 34.4 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663001031022609		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4663001031022609 | validation: 0.4086638495756849]
	TIME [epoch: 34.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857760316826046		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.6857760316826046 | validation: 0.486475750736148]
	TIME [epoch: 34.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39270403331052917		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.39270403331052917 | validation: 0.3892556557919454]
	TIME [epoch: 34.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40481949974185316		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.40481949974185316 | validation: 0.42255198336957833]
	TIME [epoch: 34.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37828502715398493		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.37828502715398493 | validation: 0.40164479342927256]
	TIME [epoch: 34.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429215137088619		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3429215137088619 | validation: 0.4181208393680979]
	TIME [epoch: 34.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41308347214169555		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.41308347214169555 | validation: 0.40521632141195285]
	TIME [epoch: 34.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760972122945864		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.3760972122945864 | validation: 0.4102454054419046]
	TIME [epoch: 34.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3725349422799289		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3725349422799289 | validation: 0.4059290769263011]
	TIME [epoch: 34.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36185028607514247		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.36185028607514247 | validation: 0.41988187929948745]
	TIME [epoch: 34.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35023481380801225		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.35023481380801225 | validation: 0.39286106711836777]
	TIME [epoch: 34.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043288830533994		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4043288830533994 | validation: 0.44071055409452875]
	TIME [epoch: 34.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41260132853132125		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.41260132853132125 | validation: 0.5578631994004325]
	TIME [epoch: 34.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529663041118197		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5529663041118197 | validation: 0.49828113177969885]
	TIME [epoch: 34.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926906754123538		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3926906754123538 | validation: 0.43918230586772067]
	TIME [epoch: 34.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48237530033951403		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.48237530033951403 | validation: 0.4093324372469931]
	TIME [epoch: 34.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43255967034389775		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.43255967034389775 | validation: 0.4481703959240416]
	TIME [epoch: 34.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44135441376126205		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.44135441376126205 | validation: 0.5089911620152306]
	TIME [epoch: 34.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449883071825186		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.4449883071825186 | validation: 0.4141421544328926]
	TIME [epoch: 34.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4101349785966161		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4101349785966161 | validation: 0.3766636845182437]
	TIME [epoch: 34.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33059917911836		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.33059917911836 | validation: 0.4853030925463583]
	TIME [epoch: 34.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41231075312810206		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.41231075312810206 | validation: 0.5304412569751988]
	TIME [epoch: 34.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421177273328731		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.421177273328731 | validation: 0.4708296697596832]
	TIME [epoch: 34.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4242102789785234		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.4242102789785234 | validation: 0.42484793918970776]
	TIME [epoch: 34.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40755095245201356		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.40755095245201356 | validation: 0.5100005841474169]
	TIME [epoch: 34.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961489389278269		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3961489389278269 | validation: 0.37454429773901776]
	TIME [epoch: 34.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729225370915924		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3729225370915924 | validation: 0.3583203583947456]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_819.pth
	Model improved!!!
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34885240816768026		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.34885240816768026 | validation: 0.41808059952462684]
	TIME [epoch: 34.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46157339393126895		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.46157339393126895 | validation: 0.6974248758705519]
	TIME [epoch: 34.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5603435348267466		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.5603435348267466 | validation: 0.45737554605645814]
	TIME [epoch: 34.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686686260917747		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3686686260917747 | validation: 0.4238032773025674]
	TIME [epoch: 34.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44363648995086186		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.44363648995086186 | validation: 0.373973383157446]
	TIME [epoch: 34.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623514991990866		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.3623514991990866 | validation: 0.3914536966566951]
	TIME [epoch: 34.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754095800984019		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3754095800984019 | validation: 0.37279244051673555]
	TIME [epoch: 34.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480078131616967		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3480078131616967 | validation: 0.3996070899374764]
	TIME [epoch: 34.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3517888142576542		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.3517888142576542 | validation: 0.5666342635959757]
	TIME [epoch: 34.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166774171358628		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.5166774171358628 | validation: 0.5833110075803492]
	TIME [epoch: 34.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095552302096426		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4095552302096426 | validation: 0.41245094159542595]
	TIME [epoch: 34.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40719848777519924		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.40719848777519924 | validation: 0.6277652525708659]
	TIME [epoch: 34.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105993867062386		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.4105993867062386 | validation: 0.4178390173790215]
	TIME [epoch: 34.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33508740451058844		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.33508740451058844 | validation: 0.4070848004780456]
	TIME [epoch: 34.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36239758094278607		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.36239758094278607 | validation: 0.3825745550656835]
	TIME [epoch: 34.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34276444334662465		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.34276444334662465 | validation: 0.3697795504842494]
	TIME [epoch: 34.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34305918001225344		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.34305918001225344 | validation: 0.37741524192001386]
	TIME [epoch: 34.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614297358316517		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.3614297358316517 | validation: 0.43317355116021583]
	TIME [epoch: 34.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33428890175314474		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.33428890175314474 | validation: 0.4905699454714066]
	TIME [epoch: 34.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786097972680126		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3786097972680126 | validation: 0.44395460762623273]
	TIME [epoch: 34.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569516831546947		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3569516831546947 | validation: 0.5489759526415399]
	TIME [epoch: 34.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46578302286351125		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.46578302286351125 | validation: 0.3616521434923883]
	TIME [epoch: 34.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35789883669250233		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.35789883669250233 | validation: 0.46765394373194347]
	TIME [epoch: 34.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593375170092013		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3593375170092013 | validation: 0.40240393401543556]
	TIME [epoch: 34.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41787848168833		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.41787848168833 | validation: 0.5000074813295471]
	TIME [epoch: 34.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620494927942879		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.3620494927942879 | validation: 0.3685574144112478]
	TIME [epoch: 34.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872250783235193		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3872250783235193 | validation: 0.5099969250222769]
	TIME [epoch: 34.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36571047755288044		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.36571047755288044 | validation: 0.4524056837442598]
	TIME [epoch: 34.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44666472515323113		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.44666472515323113 | validation: 0.4581135224008034]
	TIME [epoch: 34.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811261328428741		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.3811261328428741 | validation: 0.36446178321985223]
	TIME [epoch: 34.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49938612416911843		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.49938612416911843 | validation: 0.3865741320493876]
	TIME [epoch: 34.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42353750207874347		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.42353750207874347 | validation: 0.6142601962885412]
	TIME [epoch: 34.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467186223562537		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4467186223562537 | validation: 0.43604995046148104]
	TIME [epoch: 34.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767073538577697		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.3767073538577697 | validation: 0.7901968286380199]
	TIME [epoch: 34.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5432371730242295		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.5432371730242295 | validation: 0.470152966853062]
	TIME [epoch: 34.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401165722960202		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.4401165722960202 | validation: 0.4764289212549142]
	TIME [epoch: 34.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34528511644712817		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.34528511644712817 | validation: 0.3359871295679949]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_856.pth
	Model improved!!!
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549256230996942		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.3549256230996942 | validation: 0.4898295510523033]
	TIME [epoch: 34.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551593861995851		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4551593861995851 | validation: 0.46772531317613214]
	TIME [epoch: 34.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515423036531887		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3515423036531887 | validation: 0.32999201686519997]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147762770302877		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.4147762770302877 | validation: 0.38140159089967235]
	TIME [epoch: 34.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39679103593340415		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.39679103593340415 | validation: 0.5016336259978305]
	TIME [epoch: 34.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37304472110179815		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.37304472110179815 | validation: 0.4155885082587405]
	TIME [epoch: 34.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363709995728102		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.3363709995728102 | validation: 0.39014587309138626]
	TIME [epoch: 34.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39578818649556		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.39578818649556 | validation: 0.38510308706287705]
	TIME [epoch: 34.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640853290494796		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.3640853290494796 | validation: 0.40780395058963004]
	TIME [epoch: 34.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307540920328876		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4307540920328876 | validation: 0.40667537368821516]
	TIME [epoch: 34.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.317965561857409		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.317965561857409 | validation: 0.35368635136845555]
	TIME [epoch: 34.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37312592506913883		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.37312592506913883 | validation: 0.4443520514944868]
	TIME [epoch: 34.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39125778112544196		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.39125778112544196 | validation: 0.6132380693909711]
	TIME [epoch: 34.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45701742479635876		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.45701742479635876 | validation: 0.4034867686014062]
	TIME [epoch: 34.4 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34125540663208065		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.34125540663208065 | validation: 0.41592603744920104]
	TIME [epoch: 34.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279690939837524		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5279690939837524 | validation: 0.5637426992117132]
	TIME [epoch: 34.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430791346718629		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4430791346718629 | validation: 0.4777173855499861]
	TIME [epoch: 34.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39626298721099523		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.39626298721099523 | validation: 0.4409303437692705]
	TIME [epoch: 34.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39248781272354866		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.39248781272354866 | validation: 0.53579376654234]
	TIME [epoch: 34.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378585053676033		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.378585053676033 | validation: 0.38465623220657774]
	TIME [epoch: 34.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782174337800852		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3782174337800852 | validation: 0.42296801096512937]
	TIME [epoch: 34.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42474221858377814		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.42474221858377814 | validation: 0.4981811487698926]
	TIME [epoch: 34.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38384638271672245		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.38384638271672245 | validation: 0.405214908602903]
	TIME [epoch: 34.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556674772975938		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.3556674772975938 | validation: 0.5322090217650859]
	TIME [epoch: 34.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216247077689047		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.5216247077689047 | validation: 0.5012484805769063]
	TIME [epoch: 34.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36769562917345		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.36769562917345 | validation: 0.38170645761194116]
	TIME [epoch: 34.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542072243384383		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.3542072243384383 | validation: 0.49723761871728606]
	TIME [epoch: 34.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510959595855214		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.3510959595855214 | validation: 0.38204995214710763]
	TIME [epoch: 34.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34749569859733853		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.34749569859733853 | validation: 0.4405386806623771]
	TIME [epoch: 34.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34151468569369003		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.34151468569369003 | validation: 0.3970779546631097]
	TIME [epoch: 34.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204389675807311		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3204389675807311 | validation: 0.35872954752307745]
	TIME [epoch: 34.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31590392717901905		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.31590392717901905 | validation: 0.5404255047901798]
	TIME [epoch: 34.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36291243680338736		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.36291243680338736 | validation: 0.33617779916771473]
	TIME [epoch: 34.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37645994059295196		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.37645994059295196 | validation: 0.3852379708213367]
	TIME [epoch: 34.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36280530185433074		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.36280530185433074 | validation: 0.3394929126633588]
	TIME [epoch: 34.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31382010024971385		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.31382010024971385 | validation: 0.3804830428164574]
	TIME [epoch: 34.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374865915522284		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3374865915522284 | validation: 0.38778150851231863]
	TIME [epoch: 34.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35538202117739937		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.35538202117739937 | validation: 0.4405882462489129]
	TIME [epoch: 34.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31840622311868416		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.31840622311868416 | validation: 0.5052052934272093]
	TIME [epoch: 34.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856856923751629		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.3856856923751629 | validation: 0.5551807947209475]
	TIME [epoch: 34.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37061695527022537		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.37061695527022537 | validation: 0.3853960327898703]
	TIME [epoch: 34.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067217134617265		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3067217134617265 | validation: 0.48296733935464886]
	TIME [epoch: 34.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4889867332178531		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4889867332178531 | validation: 0.44554883501986065]
	TIME [epoch: 34.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626647683003148		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3626647683003148 | validation: 0.35948000389567747]
	TIME [epoch: 34.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380374814791799		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3380374814791799 | validation: 0.37810523928737744]
	TIME [epoch: 34.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33863347470757		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.33863347470757 | validation: 0.3745058262160774]
	TIME [epoch: 34.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46101906573822593		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.46101906573822593 | validation: 0.575722223240808]
	TIME [epoch: 34.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45717605758723434		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.45717605758723434 | validation: 0.3626807270611532]
	TIME [epoch: 34.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36188477753684434		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.36188477753684434 | validation: 0.3854308786211237]
	TIME [epoch: 34.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623646011915164		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.3623646011915164 | validation: 0.3817828909814215]
	TIME [epoch: 34.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883357667562739		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.4883357667562739 | validation: 0.4169077399795673]
	TIME [epoch: 34.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32934417646338243		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.32934417646338243 | validation: 0.3448385769290623]
	TIME [epoch: 34.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257704419247913		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3257704419247913 | validation: 0.3449419092716892]
	TIME [epoch: 34.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42277831904049484		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.42277831904049484 | validation: 0.7478295417218788]
	TIME [epoch: 34.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717691048060458		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4717691048060458 | validation: 0.38692281439734455]
	TIME [epoch: 34.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34599152918791165		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.34599152918791165 | validation: 0.4642080074726248]
	TIME [epoch: 34.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36544964339886415		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.36544964339886415 | validation: 0.6109484026230918]
	TIME [epoch: 34.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.596320583685972		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.596320583685972 | validation: 0.646443944008696]
	TIME [epoch: 34.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43438945364185777		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.43438945364185777 | validation: 0.38364070563851527]
	TIME [epoch: 34.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353159719217877		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.353159719217877 | validation: 0.45296284271847354]
	TIME [epoch: 34.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374403108329462		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.374403108329462 | validation: 0.3578595249301677]
	TIME [epoch: 34.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329693454233101		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3329693454233101 | validation: 0.38766993563731966]
	TIME [epoch: 34.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741199184419892		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.3741199184419892 | validation: 0.5484919209416018]
	TIME [epoch: 34.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.417992469422721		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.417992469422721 | validation: 0.46355642302889116]
	TIME [epoch: 34.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34386906130519757		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.34386906130519757 | validation: 0.4510984454194379]
	TIME [epoch: 34.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661871723135638		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.3661871723135638 | validation: 0.3958268364678439]
	TIME [epoch: 34.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40802624473031074		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.40802624473031074 | validation: 0.40470219963035203]
	TIME [epoch: 34.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032573195101994		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.3032573195101994 | validation: 0.3410934881181863]
	TIME [epoch: 34.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38340769263253416		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.38340769263253416 | validation: 0.495667814902799]
	TIME [epoch: 34.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45642943267154934		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.45642943267154934 | validation: 0.4296904381012595]
	TIME [epoch: 34.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202602321075013		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.3202602321075013 | validation: 0.3551017983622706]
	TIME [epoch: 34.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30297049160729195		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.30297049160729195 | validation: 0.3581532820713301]
	TIME [epoch: 34.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3893406845526655		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.3893406845526655 | validation: 0.4822421228788371]
	TIME [epoch: 34.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.415181028443071		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.415181028443071 | validation: 0.3985075171277527]
	TIME [epoch: 34.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403127924641484		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.3403127924641484 | validation: 0.3683812989508242]
	TIME [epoch: 34.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842022433377553		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3842022433377553 | validation: 0.3701466784424611]
	TIME [epoch: 34.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3157993131021657		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.3157993131021657 | validation: 0.3698033928596425]
	TIME [epoch: 34.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417140774825632		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3417140774825632 | validation: 0.3731550359578698]
	TIME [epoch: 34.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32155667350058587		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.32155667350058587 | validation: 0.4142379347030771]
	TIME [epoch: 34.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130105988362608		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3130105988362608 | validation: 0.38762078001386413]
	TIME [epoch: 34.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676065761642428		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.3676065761642428 | validation: 0.41592311227633183]
	TIME [epoch: 34.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40758673500493336		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.40758673500493336 | validation: 0.37668293163266287]
	TIME [epoch: 34.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35168213010697247		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.35168213010697247 | validation: 0.3612820345719401]
	TIME [epoch: 34.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34156293411919836		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.34156293411919836 | validation: 0.3495908745744021]
	TIME [epoch: 34.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070248170296252		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3070248170296252 | validation: 0.35096682258794615]
	TIME [epoch: 34.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38176983565170736		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.38176983565170736 | validation: 0.3586074585247148]
	TIME [epoch: 34.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34096504221148205		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.34096504221148205 | validation: 0.357588977162832]
	TIME [epoch: 34.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32783858102499186		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.32783858102499186 | validation: 0.39514265493355105]
	TIME [epoch: 34.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215253160448291		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3215253160448291 | validation: 0.44052143965398355]
	TIME [epoch: 34.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3063897733776561		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.3063897733776561 | validation: 0.3998881080563619]
	TIME [epoch: 34.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33512644832808897		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.33512644832808897 | validation: 0.33367576862573955]
	TIME [epoch: 34.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35402031442462467		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.35402031442462467 | validation: 0.4711089332719134]
	TIME [epoch: 34.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35593806425271934		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.35593806425271934 | validation: 0.41825503145571064]
	TIME [epoch: 34.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39319920145601506		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.39319920145601506 | validation: 0.4158629091100552]
	TIME [epoch: 34.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4605905711758499		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.4605905711758499 | validation: 0.5148477988186588]
	TIME [epoch: 34.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40796225319382073		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.40796225319382073 | validation: 0.35762272009459306]
	TIME [epoch: 34.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32250149274567547		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.32250149274567547 | validation: 0.41864237686350697]
	TIME [epoch: 34.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068373700952298		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3068373700952298 | validation: 0.5783004856322422]
	TIME [epoch: 34.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6437691472934156		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.6437691472934156 | validation: 0.6447524500706239]
	TIME [epoch: 34.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019452724602432		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.4019452724602432 | validation: 0.3403230097017246]
	TIME [epoch: 34.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611766997621079		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3611766997621079 | validation: 0.4966185775942169]
	TIME [epoch: 34.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4101134752264746		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.4101134752264746 | validation: 0.4321433230966002]
	TIME [epoch: 34.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483958290392314		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.4483958290392314 | validation: 0.40780306567406]
	TIME [epoch: 34.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31841037445926723		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.31841037445926723 | validation: 0.37663717889877757]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl1_20240705_024039/states/model_phi1_1a_v_kl1_960.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 22598.132 seconds.
