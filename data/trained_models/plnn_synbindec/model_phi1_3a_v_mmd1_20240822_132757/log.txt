Args:
Namespace(name='model_phi1_3a_v_mmd1', outdir='out/model_training/model_phi1_3a_v_mmd1', training_data='data/training_data/data_phi1_3a/training', validation_data='data/training_data/data_phi1_3a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1926232085

Training model...

Saving initial model state to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.757749074346359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.757749074346359 | validation: 5.840285952865959]
	TIME [epoch: 26.7 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.210258036744064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.210258036744064 | validation: 4.5194513473651075]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.030732200263823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.030732200263823 | validation: 5.467425673759272]
	TIME [epoch: 0.921 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.90743543973471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.90743543973471 | validation: 4.589051341127716]
	TIME [epoch: 0.919 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.897892009761568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.897892009761568 | validation: 5.124596387856237]
	TIME [epoch: 0.917 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.471444899735346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.471444899735346 | validation: 4.8430731243013145]
	TIME [epoch: 0.923 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.1380340790458305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1380340790458305 | validation: 4.335779370564569]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7525494718232117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7525494718232117 | validation: 4.728210104704643]
	TIME [epoch: 0.92 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8024982019443248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8024982019443248 | validation: 4.449894769444868]
	TIME [epoch: 0.922 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.630374088888644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.630374088888644 | validation: 4.303884503590517]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6186522780024024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6186522780024024 | validation: 4.425800989893812]
	TIME [epoch: 0.922 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.567028643539761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.567028643539761 | validation: 4.30317429882508]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5278578945011736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5278578945011736 | validation: 4.325232575328012]
	TIME [epoch: 0.919 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.50738517977023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.50738517977023 | validation: 4.236190018080747]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.485954991956219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.485954991956219 | validation: 4.3772809216026465]
	TIME [epoch: 0.921 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5126480351057157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5126480351057157 | validation: 4.210858280495077]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6071247532444795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6071247532444795 | validation: 4.502394750704297]
	TIME [epoch: 0.923 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.67516980375808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.67516980375808 | validation: 4.213853808212141]
	TIME [epoch: 0.922 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.406909536990246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.406909536990246 | validation: 4.163548775942823]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4966936904523847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4966936904523847 | validation: 4.363504973287493]
	TIME [epoch: 0.92 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5328591283077113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5328591283077113 | validation: 4.153392625638452]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3658544216551958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3658544216551958 | validation: 4.123184526215659]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3813093362651023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3813093362651023 | validation: 4.2307068463472115]
	TIME [epoch: 0.922 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.406360073412112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.406360073412112 | validation: 4.090699715237542]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3481801715240302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3481801715240302 | validation: 4.122562020747455]
	TIME [epoch: 0.921 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3148520397606718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3148520397606718 | validation: 4.0721596339718955]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2945042876612076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2945042876612076 | validation: 4.082562984754957]
	TIME [epoch: 0.926 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2844424823178087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2844424823178087 | validation: 4.037709073278904]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2788027892242555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2788027892242555 | validation: 4.100657883402386]
	TIME [epoch: 0.923 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3014920259044307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3014920259044307 | validation: 4.036208379980102]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.314920131851766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.314920131851766 | validation: 4.120288439427883]
	TIME [epoch: 0.927 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.361331459198807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.361331459198807 | validation: 3.9802697272019567]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.222795616860007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.222795616860007 | validation: 3.972439937157247]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.186473681185994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.186473681185994 | validation: 3.9503410153499505]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.170580875454333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.170580875454333 | validation: 3.9452998830389063]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.155458910311618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.155458910311618 | validation: 3.921959733610004]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.147406891110989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.147406891110989 | validation: 3.8983128580163324]
	TIME [epoch: 0.947 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1336242243603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1336242243603 | validation: 3.913059952113242]
	TIME [epoch: 0.927 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.144617870370753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.144617870370753 | validation: 3.899638956246949]
	TIME [epoch: 0.924 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1789499264548695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1789499264548695 | validation: 3.985121855026031]
	TIME [epoch: 0.921 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2493523583687414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2493523583687414 | validation: 3.8373621645665135]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0845129302457934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0845129302457934 | validation: 3.8213308497717478]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.064688920219375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.064688920219375 | validation: 3.8346442263519593]
	TIME [epoch: 0.924 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0649884372800558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0649884372800558 | validation: 3.787036481980809]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0532904176721063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0532904176721063 | validation: 3.8104047446773386]
	TIME [epoch: 0.92 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0425969711595555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0425969711595555 | validation: 3.7601944508913108]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.021669683475743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.021669683475743 | validation: 3.770007924954881]
	TIME [epoch: 0.926 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.006262153566804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.006262153566804 | validation: 3.7287686317124016]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9853467648978484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9853467648978484 | validation: 3.731193288650691]
	TIME [epoch: 0.927 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9666888405485237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9666888405485237 | validation: 3.683160121871618]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.957991336298003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.957991336298003 | validation: 3.693044637750051]
	TIME [epoch: 0.925 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.948527378964781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.948527378964781 | validation: 3.6458495261918906]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.933887041311054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.933887041311054 | validation: 3.6720669515986373]
	TIME [epoch: 0.923 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9234074310410763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9234074310410763 | validation: 3.614709200892709]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.923830697760767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.923830697760767 | validation: 3.670139070641331]
	TIME [epoch: 0.923 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9132238811055244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9132238811055244 | validation: 3.5897657342513014]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8937454464164523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8937454464164523 | validation: 3.6189231918019957]
	TIME [epoch: 0.92 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8816229007197594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8816229007197594 | validation: 3.582361119412211]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8709898930051536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8709898930051536 | validation: 3.576709709563977]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8673514649076135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8673514649076135 | validation: 3.5399048169581215]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8441820252576107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8441820252576107 | validation: 3.547854954810584]
	TIME [epoch: 0.923 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8258285002166694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8258285002166694 | validation: 3.4883397580055533]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8147894846929944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8147894846929944 | validation: 3.5162555067536476]
	TIME [epoch: 0.922 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.807975957919672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.807975957919672 | validation: 3.4721597148354073]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7907002963073353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7907002963073353 | validation: 3.4940140069103194]
	TIME [epoch: 0.923 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7770413623769765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7770413623769765 | validation: 3.4387294050433597]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7740257294742547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7740257294742547 | validation: 3.4772923810147933]
	TIME [epoch: 0.921 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.762230190333864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.762230190333864 | validation: 3.3949824604542798]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.766272931771516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.766272931771516 | validation: 3.4858465847901066]
	TIME [epoch: 0.922 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7614995741314012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7614995741314012 | validation: 3.386247157421579]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.731910022564055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.731910022564055 | validation: 3.379608317951027]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.710977962499618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.710977962499618 | validation: 3.348712594470861]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6948354570640776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6948354570640776 | validation: 3.325877069421093]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.677901394233154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.677901394233154 | validation: 3.32583536882773]
	TIME [epoch: 0.932 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6678888970579164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6678888970579164 | validation: 3.262049178640949]
	TIME [epoch: 0.936 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6518107422797272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6518107422797272 | validation: 3.3410010114452433]
	TIME [epoch: 0.923 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6711863030518384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6711863030518384 | validation: 3.1464692172331348]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5811613265146094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5811613265146094 | validation: 2.843006388311636]
	TIME [epoch: 0.929 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2830020011948773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2830020011948773 | validation: 2.3831632997365126]
	TIME [epoch: 0.929 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.066675660120926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.066675660120926 | validation: 2.3856308062111444]
	TIME [epoch: 0.926 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0699805437454817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0699805437454817 | validation: 1.7875481863631535]
	TIME [epoch: 0.928 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6331745719073274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6331745719073274 | validation: 1.4581663403998333]
	TIME [epoch: 0.921 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3054662489833384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3054662489833384 | validation: 1.151227287474244]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.128622822660642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.128622822660642 | validation: 1.0229479028763107]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.213862001834963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.213862001834963 | validation: 1.4223427427311621]
	TIME [epoch: 0.92 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3642568348480038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3642568348480038 | validation: 0.9710582992038642]
	TIME [epoch: 0.917 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9437700490210518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9437700490210518 | validation: 0.9625114847921211]
	TIME [epoch: 0.92 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0522877087388236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0522877087388236 | validation: 1.072793399670913]
	TIME [epoch: 0.921 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9686375629339853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9686375629339853 | validation: 0.9999369261737642]
	TIME [epoch: 0.918 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.942636438490691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.942636438490691 | validation: 0.9021685647561036]
	TIME [epoch: 0.919 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9320802057858458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9320802057858458 | validation: 0.9301002217668913]
	TIME [epoch: 0.922 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9093362544611643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9093362544611643 | validation: 0.9376646131638641]
	TIME [epoch: 0.921 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9065150726464303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9065150726464303 | validation: 0.9091976251442283]
	TIME [epoch: 0.925 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8973468567710446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8973468567710446 | validation: 0.9420845211152626]
	TIME [epoch: 0.923 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8979016098620829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8979016098620829 | validation: 0.8861634983382669]
	TIME [epoch: 0.922 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8866567212289465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8866567212289465 | validation: 0.9382598300541295]
	TIME [epoch: 0.922 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8873732823520527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8873732823520527 | validation: 0.8932249392497082]
	TIME [epoch: 0.926 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8829955843385869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8829955843385869 | validation: 0.9509744185415596]
	TIME [epoch: 0.919 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8826175519775606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8826175519775606 | validation: 0.906591589862008]
	TIME [epoch: 0.922 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9020587663139028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9020587663139028 | validation: 1.024227862238932]
	TIME [epoch: 0.922 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9435329749892679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9435329749892679 | validation: 0.94763488554437]
	TIME [epoch: 0.92 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9282868400794646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9282868400794646 | validation: 1.0382520551922094]
	TIME [epoch: 0.918 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.939223479173239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.939223479173239 | validation: 0.9094949337880363]
	TIME [epoch: 0.92 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.875274837089208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.875274837089208 | validation: 0.9245931975776434]
	TIME [epoch: 0.92 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8683917635894877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8683917635894877 | validation: 0.9236244476539641]
	TIME [epoch: 0.919 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8909766590878943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8909766590878943 | validation: 0.9538561350857505]
	TIME [epoch: 0.924 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9268625731200427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9268625731200427 | validation: 1.0454541961593562]
	TIME [epoch: 0.922 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9969831625950029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9969831625950029 | validation: 0.916234063697989]
	TIME [epoch: 0.926 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8621257127220758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8621257127220758 | validation: 0.9299743669471685]
	TIME [epoch: 0.918 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8874160971860593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8874160971860593 | validation: 0.962577729286898]
	TIME [epoch: 0.919 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.916610586409505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.916610586409505 | validation: 0.9538553617750605]
	TIME [epoch: 0.922 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8847921822496088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8847921822496088 | validation: 0.9512384677878164]
	TIME [epoch: 0.926 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8968615739197964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8968615739197964 | validation: 1.099749856990812]
	TIME [epoch: 0.936 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9806771303356807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9806771303356807 | validation: 0.9185648524381297]
	TIME [epoch: 0.924 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8692813969338852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8692813969338852 | validation: 0.9259789207281668]
	TIME [epoch: 0.927 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.846465017397986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.846465017397986 | validation: 0.9176846667003334]
	TIME [epoch: 0.92 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469369197538861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469369197538861 | validation: 0.9207262074782495]
	TIME [epoch: 0.918 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8519292544025507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8519292544025507 | validation: 0.918992625268068]
	TIME [epoch: 0.919 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8615034177162179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8615034177162179 | validation: 0.9334652547741857]
	TIME [epoch: 0.92 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8651206729589273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8651206729589273 | validation: 1.0151348496321286]
	TIME [epoch: 0.917 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9262311529055773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9262311529055773 | validation: 0.9325762330419732]
	TIME [epoch: 0.921 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8849681335467969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8849681335467969 | validation: 0.9903346568036935]
	TIME [epoch: 0.921 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8773019764226399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8773019764226399 | validation: 0.9124587620346944]
	TIME [epoch: 0.922 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8513621929183071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8513621929183071 | validation: 0.9307328246014288]
	TIME [epoch: 0.918 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8610333415391116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8610333415391116 | validation: 0.9218239758773925]
	TIME [epoch: 0.919 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9122039649028563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9122039649028563 | validation: 1.0897487273921438]
	TIME [epoch: 0.917 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0502781364222467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0502781364222467 | validation: 0.9149184052846278]
	TIME [epoch: 0.921 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8427798763110215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8427798763110215 | validation: 0.9177797638913155]
	TIME [epoch: 0.921 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8692661920922674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8692661920922674 | validation: 0.9684144366890086]
	TIME [epoch: 0.921 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8983559967288405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8983559967288405 | validation: 0.8874245293238681]
	TIME [epoch: 0.919 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8458178605880164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8458178605880164 | validation: 0.9264077836052813]
	TIME [epoch: 0.917 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8457925897122562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8457925897122562 | validation: 0.9194899116118628]
	TIME [epoch: 0.919 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8634574840215388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8634574840215388 | validation: 1.015394287449929]
	TIME [epoch: 0.922 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9170242139487513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9170242139487513 | validation: 0.9333048563347796]
	TIME [epoch: 0.919 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8850922587550344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8850922587550344 | validation: 0.9769246307769992]
	TIME [epoch: 0.921 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.888565076215291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.888565076215291 | validation: 0.9130972567363428]
	TIME [epoch: 0.921 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8439330154886084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8439330154886084 | validation: 0.9262395511171045]
	TIME [epoch: 0.921 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469894529553201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469894529553201 | validation: 0.8801200616977192]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8434511660635089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8434511660635089 | validation: 0.9382423858090507]
	TIME [epoch: 0.919 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.865900427554271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.865900427554271 | validation: 0.9161449976526023]
	TIME [epoch: 0.921 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9026275331477653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9026275331477653 | validation: 1.0040749698234297]
	TIME [epoch: 0.919 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9595188636515496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9595188636515496 | validation: 0.8972566608244046]
	TIME [epoch: 0.923 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8396437791733263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8396437791733263 | validation: 0.9018763731251842]
	TIME [epoch: 0.918 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8430032898398682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8430032898398682 | validation: 0.9460481391502391]
	TIME [epoch: 0.918 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8840663743969058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8840663743969058 | validation: 0.9911702431695393]
	TIME [epoch: 0.92 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9063454709467336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9063454709467336 | validation: 0.9218343082356324]
	TIME [epoch: 0.923 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8725610495043844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8725610495043844 | validation: 0.9651886135331328]
	TIME [epoch: 0.923 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8738466670213103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8738466670213103 | validation: 0.9007649041834555]
	TIME [epoch: 0.924 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8565719000380126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8565719000380126 | validation: 0.9288286297067345]
	TIME [epoch: 0.927 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8487488619161176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8487488619161176 | validation: 0.8817706677354327]
	TIME [epoch: 0.921 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8462187154686438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8462187154686438 | validation: 0.9264344896891896]
	TIME [epoch: 0.92 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8520293713008562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8520293713008562 | validation: 0.8926720831345556]
	TIME [epoch: 0.918 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8500110291984023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8500110291984023 | validation: 0.920766685509157]
	TIME [epoch: 0.919 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8622134834207091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8622134834207091 | validation: 0.8918230981578539]
	TIME [epoch: 0.919 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8647538668806367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8647538668806367 | validation: 0.9670003584866553]
	TIME [epoch: 0.919 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8884097642309768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8884097642309768 | validation: 0.8761757592821215]
	TIME [epoch: 0.918 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8458473501181485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8458473501181485 | validation: 0.9693923814070321]
	TIME [epoch: 0.922 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8762666893776829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8762666893776829 | validation: 0.9376999821371244]
	TIME [epoch: 0.921 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9022858542037924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9022858542037924 | validation: 1.0246616081334057]
	TIME [epoch: 0.929 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9300624553727612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9300624553727612 | validation: 0.8720773947426168]
	TIME [epoch: 0.934 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8260574257912812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8260574257912812 | validation: 0.8734740846892411]
	TIME [epoch: 0.923 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8378801677799345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8378801677799345 | validation: 0.9393401586911225]
	TIME [epoch: 0.927 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8538567107774608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8538567107774608 | validation: 0.8627626343404222]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8437741069366927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8437741069366927 | validation: 0.9358216261385128]
	TIME [epoch: 0.925 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8745700074547282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8745700074547282 | validation: 0.8690974623092433]
	TIME [epoch: 0.922 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.865355838899724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.865355838899724 | validation: 0.9132932270507752]
	TIME [epoch: 0.93 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8683801396675442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8683801396675442 | validation: 0.890972192618574]
	TIME [epoch: 0.93 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8409941313882703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8409941313882703 | validation: 0.878263708387284]
	TIME [epoch: 0.923 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8390247794042265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8390247794042265 | validation: 0.9416295433042752]
	TIME [epoch: 0.923 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8638789458568661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8638789458568661 | validation: 0.8680330825317508]
	TIME [epoch: 0.925 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8566726754576136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8566726754576136 | validation: 0.9786472774301123]
	TIME [epoch: 0.924 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8713262893511063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8713262893511063 | validation: 0.8853583643369787]
	TIME [epoch: 0.924 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8543087371677714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8543087371677714 | validation: 0.921101075576893]
	TIME [epoch: 0.926 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8527400572632413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8527400572632413 | validation: 0.8603289851445439]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8644601262417027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8644601262417027 | validation: 0.9318403773555959]
	TIME [epoch: 0.927 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.889447360776105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.889447360776105 | validation: 0.8685133442960441]
	TIME [epoch: 0.93 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8300461564022058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8300461564022058 | validation: 0.8990007731959349]
	TIME [epoch: 0.926 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8195406083294355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8195406083294355 | validation: 0.866232296601228]
	TIME [epoch: 0.924 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8162258377828806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8162258377828806 | validation: 0.8920257386425089]
	TIME [epoch: 0.923 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.817805691312043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.817805691312043 | validation: 0.8629701016838563]
	TIME [epoch: 0.928 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.820001640256035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.820001640256035 | validation: 0.868140618297592]
	TIME [epoch: 0.922 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8356209114164287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8356209114164287 | validation: 0.9382454455355318]
	TIME [epoch: 0.925 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8964936304673704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8964936304673704 | validation: 0.9436521883982105]
	TIME [epoch: 0.927 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.937261834812947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.937261834812947 | validation: 0.9852159935382178]
	TIME [epoch: 0.932 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8897616227062415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8897616227062415 | validation: 0.8713457946734948]
	TIME [epoch: 0.926 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8714520273584312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8714520273584312 | validation: 0.9519087455172734]
	TIME [epoch: 0.921 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9182326075336343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9182326075336343 | validation: 0.8571346147141492]
	TIME [epoch: 0.923 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8166821267224394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8166821267224394 | validation: 0.8654156549590225]
	TIME [epoch: 0.924 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8224181630627253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8224181630627253 | validation: 0.8672078075233055]
	TIME [epoch: 0.936 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.824084918416754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.824084918416754 | validation: 0.8497093475015085]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8187280899888646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8187280899888646 | validation: 0.8913698218141353]
	TIME [epoch: 0.925 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8237025521718335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8237025521718335 | validation: 0.8470794744696719]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8374985829842936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8374985829842936 | validation: 0.9781869873669238]
	TIME [epoch: 0.925 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8937539901809123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8937539901809123 | validation: 0.8859453635411975]
	TIME [epoch: 0.922 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8738299796158805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8738299796158805 | validation: 0.9367348157127995]
	TIME [epoch: 0.925 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8643838210446319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8643838210446319 | validation: 0.8411627824827259]
	TIME [epoch: 0.924 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8256613845341348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8256613845341348 | validation: 0.8627142034981401]
	TIME [epoch: 0.926 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.825411381538386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.825411381538386 | validation: 0.8642993588003792]
	TIME [epoch: 0.94 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8229686599377687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8229686599377687 | validation: 0.850415614850053]
	TIME [epoch: 0.926 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8323811873644804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8323811873644804 | validation: 0.8883974479737238]
	TIME [epoch: 0.926 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8364697525121148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8364697525121148 | validation: 0.8509327237061011]
	TIME [epoch: 25.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8255869349305488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8255869349305488 | validation: 0.8636236256130136]
	TIME [epoch: 1.81 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.820672895508919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.820672895508919 | validation: 0.8416385138955262]
	TIME [epoch: 1.81 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.820714292003221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.820714292003221 | validation: 0.9041792780453115]
	TIME [epoch: 1.81 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8388081657208861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8388081657208861 | validation: 0.8708618194738182]
	TIME [epoch: 1.81 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8683428416028887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8683428416028887 | validation: 1.0047842975430488]
	TIME [epoch: 1.81 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9038316057739284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9038316057739284 | validation: 0.8511523387479354]
	TIME [epoch: 1.81 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8669921460798163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8669921460798163 | validation: 0.9199679975184936]
	TIME [epoch: 1.81 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9189439021130725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9189439021130725 | validation: 0.8476899559573354]
	TIME [epoch: 1.81 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8133274758179596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8133274758179596 | validation: 0.8476349027653214]
	TIME [epoch: 1.81 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8258467009155567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8258467009155567 | validation: 0.8746177557333141]
	TIME [epoch: 1.81 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8522919841392548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8522919841392548 | validation: 0.825605715190516]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8169957657576065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8169957657576065 | validation: 0.8405905644646211]
	TIME [epoch: 1.81 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8079328953860718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8079328953860718 | validation: 0.8328352364971935]
	TIME [epoch: 1.82 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8133930334245641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8133930334245641 | validation: 0.8528253953973319]
	TIME [epoch: 1.81 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8134211442934408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8134211442934408 | validation: 0.8431399225379134]
	TIME [epoch: 1.82 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8216170183627837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8216170183627837 | validation: 0.9618410135883789]
	TIME [epoch: 1.81 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8911862689293477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8911862689293477 | validation: 0.8647938648135951]
	TIME [epoch: 1.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8563502391149457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8563502391149457 | validation: 0.9025328421304686]
	TIME [epoch: 1.81 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8564414884952766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8564414884952766 | validation: 0.8401252109373085]
	TIME [epoch: 1.81 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8348785065450577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8348785065450577 | validation: 0.8555407831015311]
	TIME [epoch: 1.81 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8442325096525796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8442325096525796 | validation: 0.8409091565463976]
	TIME [epoch: 1.81 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8226826276876716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8226826276876716 | validation: 0.8287201528004298]
	TIME [epoch: 1.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8028729341711749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8028729341711749 | validation: 0.8132453828370872]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7913481989869697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7913481989869697 | validation: 0.8235509328093955]
	TIME [epoch: 1.81 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7892038804307758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7892038804307758 | validation: 0.8180145572831002]
	TIME [epoch: 1.81 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7979855277757851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7979855277757851 | validation: 0.8301428085423477]
	TIME [epoch: 1.81 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7999867742086769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7999867742086769 | validation: 0.8646555932186035]
	TIME [epoch: 1.81 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8361638515150859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8361638515150859 | validation: 0.9072323657764981]
	TIME [epoch: 1.81 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8935517033047077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8935517033047077 | validation: 0.9252572250074134]
	TIME [epoch: 1.81 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8766905722592964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8766905722592964 | validation: 0.8257793833336662]
	TIME [epoch: 1.81 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8027905941262778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8027905941262778 | validation: 0.8604162205956053]
	TIME [epoch: 1.81 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8501657908176381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8501657908176381 | validation: 0.8063208267061825]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8472576228584445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8472576228584445 | validation: 0.8878381055557188]
	TIME [epoch: 1.81 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8577570759094196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8577570759094196 | validation: 0.8297300273816165]
	TIME [epoch: 1.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.821735525725173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.821735525725173 | validation: 0.8333537579319675]
	TIME [epoch: 1.81 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8001973134440118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8001973134440118 | validation: 0.793251466095542]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7875002385257774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7875002385257774 | validation: 0.8148017098868148]
	TIME [epoch: 1.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7882285615370779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7882285615370779 | validation: 0.7963758860552851]
	TIME [epoch: 1.81 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7857097910905373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7857097910905373 | validation: 0.7927861000363372]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7806006343583797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7806006343583797 | validation: 0.798796469311057]
	TIME [epoch: 1.81 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7799756099005497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7799756099005497 | validation: 0.8005672582420886]
	TIME [epoch: 1.81 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7919883713736283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7919883713736283 | validation: 0.9221465522325677]
	TIME [epoch: 1.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8924968623235645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8924968623235645 | validation: 0.9658599053557517]
	TIME [epoch: 1.81 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0269552261746822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0269552261746822 | validation: 0.9685026590727959]
	TIME [epoch: 1.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8981920831989723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8981920831989723 | validation: 0.810973716241187]
	TIME [epoch: 1.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7834611144822315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7834611144822315 | validation: 0.8235574319066066]
	TIME [epoch: 1.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8277483800211729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8277483800211729 | validation: 0.8482868463550418]
	TIME [epoch: 1.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8019350043956448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8019350043956448 | validation: 0.7810706324781883]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7755140670403976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7755140670403976 | validation: 0.7792455854066769]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7941498337380105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7941498337380105 | validation: 0.8069765068068592]
	TIME [epoch: 1.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7900425934409174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7900425934409174 | validation: 0.7908038923325695]
	TIME [epoch: 1.81 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7818125039760639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7818125039760639 | validation: 0.7807923415414024]
	TIME [epoch: 1.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.77686648579607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.77686648579607 | validation: 0.7815323859752094]
	TIME [epoch: 1.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7718297188257752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7718297188257752 | validation: 0.8331314333379553]
	TIME [epoch: 1.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8085637949059423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8085637949059423 | validation: 0.8845810222152338]
	TIME [epoch: 1.81 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9062130158366466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9062130158366466 | validation: 0.9186722315591697]
	TIME [epoch: 1.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8835263581086477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8835263581086477 | validation: 0.7915102919985337]
	TIME [epoch: 1.81 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7834774025898694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7834774025898694 | validation: 0.7920765050709467]
	TIME [epoch: 1.81 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8134002035367042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8134002035367042 | validation: 0.8640217825047215]
	TIME [epoch: 1.82 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8237448870373697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8237448870373697 | validation: 0.7762135124157687]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7893680452569433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7893680452569433 | validation: 0.7954131006095547]
	TIME [epoch: 1.82 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7924016973748548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7924016973748548 | validation: 0.7657250045966026]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7810293079694124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7810293079694124 | validation: 0.7673526582371478]
	TIME [epoch: 1.82 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7798601622373198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7798601622373198 | validation: 0.7626279552023973]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7783589638234447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7783589638234447 | validation: 0.8158510509215943]
	TIME [epoch: 1.81 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8026263400484455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8026263400484455 | validation: 0.8031688080180173]
	TIME [epoch: 1.81 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8235746084646957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8235746084646957 | validation: 0.8650767927642907]
	TIME [epoch: 1.81 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8447203999923789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8447203999923789 | validation: 0.7850155696084333]
	TIME [epoch: 1.82 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7879677207124791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7879677207124791 | validation: 0.7915080532628171]
	TIME [epoch: 1.83 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7701321034180768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7701321034180768 | validation: 0.7618284501381929]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7616915454226413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7616915454226413 | validation: 0.7572013861571201]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7659819199517418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7659819199517418 | validation: 0.7472245981337976]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7713157164688963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7713157164688963 | validation: 0.7969885485763191]
	TIME [epoch: 1.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7759574988316444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7759574988316444 | validation: 0.7962467476878996]
	TIME [epoch: 1.81 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.802219997337644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.802219997337644 | validation: 0.8604332259540519]
	TIME [epoch: 1.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8229047420629593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8229047420629593 | validation: 0.7680277954822984]
	TIME [epoch: 1.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7783605777486255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7783605777486255 | validation: 0.7300191740131073]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7467900117932286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7467900117932286 | validation: 0.757012775187099]
	TIME [epoch: 1.82 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7617152908389235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7617152908389235 | validation: 0.7762624442387347]
	TIME [epoch: 1.81 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8114024132962354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8114024132962354 | validation: 0.9777064248208174]
	TIME [epoch: 1.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9461070546532026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9461070546532026 | validation: 0.7928766724571988]
	TIME [epoch: 1.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8052708558529689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8052708558529689 | validation: 0.7347526741321257]
	TIME [epoch: 1.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7679367869587749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7679367869587749 | validation: 0.7313686726190697]
	TIME [epoch: 1.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7514442638080223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7514442638080223 | validation: 0.7333174412022188]
	TIME [epoch: 1.81 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7429923580456779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7429923580456779 | validation: 0.7507668125517917]
	TIME [epoch: 1.83 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7504264288418885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7504264288418885 | validation: 0.7355519794684495]
	TIME [epoch: 1.82 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7522319773243877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7522319773243877 | validation: 0.7692233331637554]
	TIME [epoch: 1.81 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.774514772637672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.774514772637672 | validation: 0.7557421128250784]
	TIME [epoch: 1.81 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7923016041129715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7923016041129715 | validation: 0.8252837553073782]
	TIME [epoch: 1.81 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8218533369128668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8218533369128668 | validation: 0.7456864069024507]
	TIME [epoch: 1.82 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.779124055048552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.779124055048552 | validation: 0.7367272159306234]
	TIME [epoch: 1.81 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7524712285993224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7524712285993224 | validation: 0.7020120701506265]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7382169998996463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7382169998996463 | validation: 0.7157989168209465]
	TIME [epoch: 1.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7248983058883942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7248983058883942 | validation: 0.6900118642387776]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7191965328997856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7191965328997856 | validation: 0.7250254792629579]
	TIME [epoch: 1.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.718284183929068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.718284183929068 | validation: 0.7117562455207987]
	TIME [epoch: 1.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7223361247239337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7223361247239337 | validation: 0.7485844514770545]
	TIME [epoch: 1.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7977352572435887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7977352572435887 | validation: 0.8993412252598971]
	TIME [epoch: 1.81 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.890337753030492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.890337753030492 | validation: 0.7251708465153375]
	TIME [epoch: 1.81 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7546944894510419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7546944894510419 | validation: 0.680473244025106]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7147035294669246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7147035294669246 | validation: 0.7465661745258734]
	TIME [epoch: 1.81 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7314631473482703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7314631473482703 | validation: 0.7043240163683523]
	TIME [epoch: 1.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7608868495886444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7608868495886444 | validation: 0.8253219207734876]
	TIME [epoch: 1.81 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8251661694573034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8251661694573034 | validation: 0.7545947181170503]
	TIME [epoch: 1.86 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.78846185536886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.78846185536886 | validation: 0.7051565867874521]
	TIME [epoch: 1.81 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7215481741494937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7215481741494937 | validation: 0.6637241382347254]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6976658530827026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6976658530827026 | validation: 0.6364774357730858]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7019354264177164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7019354264177164 | validation: 0.6828314397919968]
	TIME [epoch: 1.81 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7075316432267539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7075316432267539 | validation: 0.659889649639768]
	TIME [epoch: 1.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7070815168748724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7070815168748724 | validation: 0.7093190485835805]
	TIME [epoch: 1.81 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7153333456484464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7153333456484464 | validation: 0.6812135716362122]
	TIME [epoch: 1.82 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7410644769083774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7410644769083774 | validation: 0.7396791310142771]
	TIME [epoch: 1.81 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7690129415833303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7690129415833303 | validation: 0.6953162037517122]
	TIME [epoch: 1.81 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7316085846541498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7316085846541498 | validation: 0.6500866572402355]
	TIME [epoch: 1.81 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6855853263146767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6855853263146767 | validation: 0.6117308328471318]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6734812421774228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6734812421774228 | validation: 0.6314445506359911]
	TIME [epoch: 1.81 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6728084585969998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6728084585969998 | validation: 0.639660169574126]
	TIME [epoch: 1.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6681174216990527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6681174216990527 | validation: 0.6175493549584321]
	TIME [epoch: 1.81 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6710387372535935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6710387372535935 | validation: 0.6861016174968078]
	TIME [epoch: 1.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7014329280884826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7014329280884826 | validation: 0.7175619242750073]
	TIME [epoch: 1.81 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7656359970289965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7656359970289965 | validation: 0.7743967240031644]
	TIME [epoch: 1.81 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7586109959615053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7586109959615053 | validation: 0.6296356367517636]
	TIME [epoch: 1.81 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6640691559695105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6640691559695105 | validation: 0.6504580675998041]
	TIME [epoch: 1.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7043295836581328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7043295836581328 | validation: 0.6357528677945185]
	TIME [epoch: 1.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6901306612187881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6901306612187881 | validation: 0.6929213895776358]
	TIME [epoch: 1.81 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6911459096085963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6911459096085963 | validation: 0.6242722200281206]
	TIME [epoch: 1.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6568239481044714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6568239481044714 | validation: 0.6145275012446633]
	TIME [epoch: 1.81 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6718089190517346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6718089190517346 | validation: 0.6187469405212599]
	TIME [epoch: 1.81 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6747000374768771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6747000374768771 | validation: 0.6510387495053713]
	TIME [epoch: 1.81 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6724180429376534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6724180429376534 | validation: 0.5833790361967529]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6542593778151665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6542593778151665 | validation: 0.6152979817310005]
	TIME [epoch: 1.81 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6394898614172759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6394898614172759 | validation: 0.5840895510637424]
	TIME [epoch: 1.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6383457836375114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6383457836375114 | validation: 0.6108234261301232]
	TIME [epoch: 1.81 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6230521107690254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6230521107690254 | validation: 0.547003026521526]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6203955235986093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6203955235986093 | validation: 0.5991280093338117]
	TIME [epoch: 1.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6205602683707114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6205602683707114 | validation: 0.5741097748941651]
	TIME [epoch: 1.81 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6209669018052074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6209669018052074 | validation: 0.5752617916838261]
	TIME [epoch: 1.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6333998402207928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6333998402207928 | validation: 0.6142215005861196]
	TIME [epoch: 1.81 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6463243467543481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6463243467543481 | validation: 0.6725933831199857]
	TIME [epoch: 1.81 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6856814118261961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6856814118261961 | validation: 0.5800195043888335]
	TIME [epoch: 1.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6102411613226101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6102411613226101 | validation: 0.6703009967536335]
	TIME [epoch: 1.81 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6866011403211354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6866011403211354 | validation: 0.5885718967982431]
	TIME [epoch: 1.81 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6123551213191238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6123551213191238 | validation: 0.6047766109751684]
	TIME [epoch: 1.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5971705119148488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5971705119148488 | validation: 0.5350358143937013]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5755460959626464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5755460959626464 | validation: 0.5219250639260377]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5471939994942635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5471939994942635 | validation: 0.5643936190072375]
	TIME [epoch: 1.81 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5471999610693873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5471999610693873 | validation: 0.4987240384856067]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5452266898049132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5452266898049132 | validation: 0.5334148282038481]
	TIME [epoch: 1.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.536789870949293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.536789870949293 | validation: 0.549316576736864]
	TIME [epoch: 1.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5493633950709049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5493633950709049 | validation: 0.699039073575227]
	TIME [epoch: 1.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7508820432833578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7508820432833578 | validation: 0.6695663073260312]
	TIME [epoch: 1.82 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6176261552873806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6176261552873806 | validation: 0.6383007888337668]
	TIME [epoch: 1.81 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6769475258760835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6769475258760835 | validation: 0.5155870879495156]
	TIME [epoch: 1.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5783963823495706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5783963823495706 | validation: 0.6284205491960405]
	TIME [epoch: 1.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5628920505769643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5628920505769643 | validation: 0.5206267499841467]
	TIME [epoch: 1.81 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206381152752172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5206381152752172 | validation: 0.4894798243719642]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5099479026803359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5099479026803359 | validation: 0.519413306149563]
	TIME [epoch: 1.81 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49605447120349044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49605447120349044 | validation: 0.48332886686152704]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4987550082797745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4987550082797745 | validation: 0.6552828166118921]
	TIME [epoch: 1.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5740944434583842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5740944434583842 | validation: 0.6772633141336892]
	TIME [epoch: 1.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6860666506741232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6860666506741232 | validation: 0.6012277810563049]
	TIME [epoch: 1.81 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5636203418376583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5636203418376583 | validation: 0.6261926936304787]
	TIME [epoch: 1.81 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5619870428360318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5619870428360318 | validation: 0.48026502819896816]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4954511716458032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4954511716458032 | validation: 0.532241139998176]
	TIME [epoch: 1.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47975363671308996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47975363671308996 | validation: 0.46988143516122904]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4560595903044525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4560595903044525 | validation: 0.4474447330912259]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44934822763771864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44934822763771864 | validation: 0.5240926067872557]
	TIME [epoch: 1.82 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4691190225083605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4691190225083605 | validation: 0.4891838548035867]
	TIME [epoch: 1.82 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5576930704174741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5576930704174741 | validation: 0.7926658215075953]
	TIME [epoch: 1.79 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6665340775367774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6665340775367774 | validation: 0.6973747389354052]
	TIME [epoch: 1.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6464367776764209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6464367776764209 | validation: 0.5240248023414388]
	TIME [epoch: 1.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5596466862589726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5596466862589726 | validation: 0.5788631382782382]
	TIME [epoch: 1.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4942189261551846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4942189261551846 | validation: 0.5241003084742627]
	TIME [epoch: 1.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4719158587026847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4719158587026847 | validation: 0.4701246971071882]
	TIME [epoch: 1.81 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46539845799438595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46539845799438595 | validation: 0.4959960663084715]
	TIME [epoch: 1.81 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44696835560992376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44696835560992376 | validation: 0.45307291520311055]
	TIME [epoch: 1.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4261160890648719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4261160890648719 | validation: 0.44954741745594196]
	TIME [epoch: 1.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4160376603725415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4160376603725415 | validation: 0.42372075499573864]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41314926525078577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41314926525078577 | validation: 0.5530835921531463]
	TIME [epoch: 1.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4507575176924331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4507575176924331 | validation: 0.5695257746739433]
	TIME [epoch: 1.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.638205084296766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.638205084296766 | validation: 0.6996912575323114]
	TIME [epoch: 1.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5782155506186831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5782155506186831 | validation: 0.6276558138254829]
	TIME [epoch: 1.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6071237754161904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6071237754161904 | validation: 0.5325699224356871]
	TIME [epoch: 1.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.513939911026371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.513939911026371 | validation: 0.597767069275687]
	TIME [epoch: 1.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5067909414229348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5067909414229348 | validation: 0.4940633195651096]
	TIME [epoch: 1.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.436027947923863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.436027947923863 | validation: 0.4657414865969052]
	TIME [epoch: 1.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44272283747862823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44272283747862823 | validation: 0.46143876826247365]
	TIME [epoch: 1.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41642454412924607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41642454412924607 | validation: 0.46582867286202667]
	TIME [epoch: 1.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42009239595033765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42009239595033765 | validation: 0.4466254942135252]
	TIME [epoch: 1.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41484092337634915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41484092337634915 | validation: 0.457225194402007]
	TIME [epoch: 1.81 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42745835482288697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42745835482288697 | validation: 0.5393501547060532]
	TIME [epoch: 1.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45195876121465545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45195876121465545 | validation: 0.4978539892148273]
	TIME [epoch: 1.81 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5666180477207243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5666180477207243 | validation: 0.7435314600728042]
	TIME [epoch: 1.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5681471367641181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5681471367641181 | validation: 0.5983662059316472]
	TIME [epoch: 1.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6349579478080234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6349579478080234 | validation: 0.5290087238203925]
	TIME [epoch: 1.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5090767819603391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5090767819603391 | validation: 0.6164403116681904]
	TIME [epoch: 1.81 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49261331585515167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49261331585515167 | validation: 0.46099787206736614]
	TIME [epoch: 1.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40939281937116945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40939281937116945 | validation: 0.47695373683125575]
	TIME [epoch: 1.81 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4294310176714042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4294310176714042 | validation: 0.49232714981719544]
	TIME [epoch: 1.83 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4003204606811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4003204606811 | validation: 0.44715547250910115]
	TIME [epoch: 1.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38905500265373966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38905500265373966 | validation: 0.47190232735226]
	TIME [epoch: 1.81 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38477914928211654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38477914928211654 | validation: 0.3688686841009478]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38771236473369924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38771236473369924 | validation: 0.6411540174362842]
	TIME [epoch: 1.81 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4586952359598662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4586952359598662 | validation: 0.5743138120025835]
	TIME [epoch: 1.81 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6041100688289838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6041100688289838 | validation: 0.49296115267505414]
	TIME [epoch: 1.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4096554522412975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4096554522412975 | validation: 0.5626655510757038]
	TIME [epoch: 1.81 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4630560778850131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4630560778850131 | validation: 0.45866587122850366]
	TIME [epoch: 1.81 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5059525164180155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5059525164180155 | validation: 0.4742971929314599]
	TIME [epoch: 1.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39842755595203294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39842755595203294 | validation: 0.5231502195330081]
	TIME [epoch: 1.81 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4162307405019613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4162307405019613 | validation: 0.4152582032638142]
	TIME [epoch: 1.81 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42702680147917416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42702680147917416 | validation: 0.5345717002113847]
	TIME [epoch: 1.81 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4102433292349821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4102433292349821 | validation: 0.40453842723309663]
	TIME [epoch: 1.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40404167086148224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40404167086148224 | validation: 0.5227904827775042]
	TIME [epoch: 1.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40368305425221834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40368305425221834 | validation: 0.3595242364988768]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39442730675564547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39442730675564547 | validation: 0.6304341165552002]
	TIME [epoch: 1.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4742427798460937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4742427798460937 | validation: 0.5613036599155883]
	TIME [epoch: 1.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5868554966374081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5868554966374081 | validation: 0.41497192038271336]
	TIME [epoch: 1.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4638043073640917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4638043073640917 | validation: 0.6992871468219786]
	TIME [epoch: 1.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5320594075884785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5320594075884785 | validation: 0.44720312069128276]
	TIME [epoch: 1.81 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40102395521807993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40102395521807993 | validation: 0.41250451683485506]
	TIME [epoch: 1.81 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4205321385189022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4205321385189022 | validation: 0.4745636541517357]
	TIME [epoch: 1.81 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36294287706704664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36294287706704664 | validation: 0.4128225033648625]
	TIME [epoch: 1.81 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3809848167405574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3809848167405574 | validation: 0.5852974990605765]
	TIME [epoch: 1.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4231023250059499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4231023250059499 | validation: 0.4501405617342032]
	TIME [epoch: 1.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4913944337081963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4913944337081963 | validation: 0.4301885839483426]
	TIME [epoch: 1.81 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35137847516286536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35137847516286536 | validation: 0.4350649120373305]
	TIME [epoch: 1.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3527640624617808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3527640624617808 | validation: 0.37844398926730005]
	TIME [epoch: 1.81 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3766692673094292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3766692673094292 | validation: 0.5400656425838963]
	TIME [epoch: 1.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39071569310183846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39071569310183846 | validation: 0.4002518365938067]
	TIME [epoch: 1.81 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.452191957885937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.452191957885937 | validation: 0.583844216945008]
	TIME [epoch: 1.81 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42634498794759124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42634498794759124 | validation: 0.36869108845884996]
	TIME [epoch: 1.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3412383695831681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3412383695831681 | validation: 0.38097847444037053]
	TIME [epoch: 1.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35642552563569274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35642552563569274 | validation: 0.4346862348174555]
	TIME [epoch: 1.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3465698132526084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3465698132526084 | validation: 0.3542629729750286]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33559577747807967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33559577747807967 | validation: 0.4813212804232032]
	TIME [epoch: 1.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36943408646149534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36943408646149534 | validation: 0.642127992339578]
	TIME [epoch: 1.81 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6849008701688054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6849008701688054 | validation: 0.39423484338309317]
	TIME [epoch: 1.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4024496033570828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4024496033570828 | validation: 0.778227366304709]
	TIME [epoch: 1.81 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6309509272342628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6309509272342628 | validation: 0.40318938285339095]
	TIME [epoch: 1.81 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4216383668095899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4216383668095899 | validation: 0.4381406405986248]
	TIME [epoch: 1.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45931526034255626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45931526034255626 | validation: 0.45833240605379405]
	TIME [epoch: 1.81 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3605270291536166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3605270291536166 | validation: 0.4157416818438286]
	TIME [epoch: 1.81 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3530415262184255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3530415262184255 | validation: 0.3985368934258029]
	TIME [epoch: 1.81 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3344911827663578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3344911827663578 | validation: 0.3546749949896786]
	TIME [epoch: 1.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.320564937479569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.320564937479569 | validation: 0.40133547849876994]
	TIME [epoch: 1.81 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3216115576886915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3216115576886915 | validation: 0.3324840471338511]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3159733361004256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3159733361004256 | validation: 0.4966895049205611]
	TIME [epoch: 1.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3468969245268768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3468969245268768 | validation: 0.4763054116386769]
	TIME [epoch: 1.81 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5890543638990121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5890543638990121 | validation: 0.5136460793706551]
	TIME [epoch: 1.81 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40912563837501287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40912563837501287 | validation: 0.37231077574906285]
	TIME [epoch: 1.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33699228219234284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33699228219234284 | validation: 0.3649578404872011]
	TIME [epoch: 1.81 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30641752605873535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30641752605873535 | validation: 0.38382024644805207]
	TIME [epoch: 1.81 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30613160151259794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30613160151259794 | validation: 0.3969070463513089]
	TIME [epoch: 1.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3187852252979289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3187852252979289 | validation: 0.32286507870075487]
	TIME [epoch: 1.82 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3389650861964114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3389650861964114 | validation: 0.7906255961654769]
	TIME [epoch: 1.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6241903699987476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6241903699987476 | validation: 0.47353450706762407]
	TIME [epoch: 1.81 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5201995071020586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5201995071020586 | validation: 0.4182506426294187]
	TIME [epoch: 1.81 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39919089227101523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39919089227101523 | validation: 0.6393043666542538]
	TIME [epoch: 1.81 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5275034762741189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5275034762741189 | validation: 0.36573807119514173]
	TIME [epoch: 1.82 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33933864908675465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33933864908675465 | validation: 0.4132316447685822]
	TIME [epoch: 1.81 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3587513719828621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3587513719828621 | validation: 0.3382058961015454]
	TIME [epoch: 1.81 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3184038242284355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3184038242284355 | validation: 0.4126191211962942]
	TIME [epoch: 1.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33240301839552194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33240301839552194 | validation: 0.3670780685553802]
	TIME [epoch: 1.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31261712776632566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31261712776632566 | validation: 0.3617627562109549]
	TIME [epoch: 1.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3039463941924462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3039463941924462 | validation: 0.318802817868889]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2961757515747826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2961757515747826 | validation: 0.38707864287358373]
	TIME [epoch: 1.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31027721404308445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31027721404308445 | validation: 0.31210986947066627]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3126570520139033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3126570520139033 | validation: 0.4073671293663285]
	TIME [epoch: 1.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3214969569352113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3214969569352113 | validation: 0.33309218431642373]
	TIME [epoch: 1.81 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4094292835340952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4094292835340952 | validation: 0.7464790515814085]
	TIME [epoch: 1.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5637367346251645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5637367346251645 | validation: 0.6459932940741766]
	TIME [epoch: 1.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5287370430040113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5287370430040113 | validation: 0.3996115220478296]
	TIME [epoch: 1.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3283568846652824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3283568846652824 | validation: 0.3267377261795232]
	TIME [epoch: 1.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37281227049565574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37281227049565574 | validation: 0.4849719368951787]
	TIME [epoch: 1.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3620204131781247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3620204131781247 | validation: 0.32987446972802376]
	TIME [epoch: 1.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36900035764911093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36900035764911093 | validation: 0.3908322751633494]
	TIME [epoch: 1.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3432270935297184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3432270935297184 | validation: 0.33586446701222655]
	TIME [epoch: 1.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30090140980954716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30090140980954716 | validation: 0.29356328522598174]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2883739720021146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2883739720021146 | validation: 0.3424830842832319]
	TIME [epoch: 1.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.268894307384407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.268894307384407 | validation: 0.27277469058751574]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2550130839002668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2550130839002668 | validation: 0.3741668625203877]
	TIME [epoch: 1.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2773738862242581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2773738862242581 | validation: 0.2846249889727349]
	TIME [epoch: 1.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38000934854830914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38000934854830914 | validation: 0.464713358158253]
	TIME [epoch: 1.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32061685132989964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32061685132989964 | validation: 0.24006943113785628]
	TIME [epoch: 1.8 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2867476689493841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2867476689493841 | validation: 0.32739422107003496]
	TIME [epoch: 1.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24599289332714094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24599289332714094 | validation: 0.252334982479488]
	TIME [epoch: 1.81 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24890836099286745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24890836099286745 | validation: 0.4459185614096283]
	TIME [epoch: 1.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3360145897938445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3360145897938445 | validation: 0.43812495584890254]
	TIME [epoch: 1.81 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6067626854395144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6067626854395144 | validation: 0.4146179940494159]
	TIME [epoch: 1.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.371102610249168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.371102610249168 | validation: 0.33546379982098046]
	TIME [epoch: 1.81 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2726393623065335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2726393623065335 | validation: 0.26091480621870833]
	TIME [epoch: 1.82 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27965143984523405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27965143984523405 | validation: 0.42105171510609535]
	TIME [epoch: 1.81 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31163691219177575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31163691219177575 | validation: 0.24288484554134568]
	TIME [epoch: 1.81 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2782080563226435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2782080563226435 | validation: 0.26803951834471695]
	TIME [epoch: 1.81 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2229521019468374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2229521019468374 | validation: 0.2578817559513001]
	TIME [epoch: 1.81 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.206315039172123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.206315039172123 | validation: 0.233496416952924]
	TIME [epoch: 1.81 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2532543607964612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2532543607964612 | validation: 0.4736860390013467]
	TIME [epoch: 1.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3452233804244954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3452233804244954 | validation: 0.31577564275528874]
	TIME [epoch: 1.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3549946332592424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3549946332592424 | validation: 0.2823906665437245]
	TIME [epoch: 1.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2542641981255265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2542641981255265 | validation: 0.44636794193880497]
	TIME [epoch: 27.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34610875828280896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34610875828280896 | validation: 0.30561356915085636]
	TIME [epoch: 3.58 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40624819134806595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40624819134806595 | validation: 0.3631099322641458]
	TIME [epoch: 3.58 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2672032235204019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2672032235204019 | validation: 0.22647898779140557]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20014950527649994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20014950527649994 | validation: 0.22436464157148334]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.200155465733801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.200155465733801 | validation: 0.2978055140778745]
	TIME [epoch: 3.58 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2153655946128818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2153655946128818 | validation: 0.2560895665292493]
	TIME [epoch: 3.58 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24061547767984168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24061547767984168 | validation: 0.3065673379942279]
	TIME [epoch: 3.62 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2802247630279436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2802247630279436 | validation: 0.48115624685372843]
	TIME [epoch: 3.62 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38942201313377556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38942201313377556 | validation: 0.26565209736983936]
	TIME [epoch: 3.62 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33763734425872016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33763734425872016 | validation: 0.346882271949528]
	TIME [epoch: 3.62 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2676901038108471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2676901038108471 | validation: 0.23017109681908596]
	TIME [epoch: 3.61 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.213445516845888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.213445516845888 | validation: 0.4617108483054992]
	TIME [epoch: 3.62 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3200771425911728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3200771425911728 | validation: 0.2503081701671125]
	TIME [epoch: 3.62 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31155885786758114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31155885786758114 | validation: 0.21562335180511455]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19572912020006178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19572912020006178 | validation: 0.23788377764624957]
	TIME [epoch: 3.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18117859673544906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18117859673544906 | validation: 0.23867487111241178]
	TIME [epoch: 3.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21462057700163878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21462057700163878 | validation: 0.34688748688104115]
	TIME [epoch: 3.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2752854400322298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2752854400322298 | validation: 0.20177160333854635]
	TIME [epoch: 3.6 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18764753540307802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18764753540307802 | validation: 0.19092784373892122]
	TIME [epoch: 3.6 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1799499168652605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1799499168652605 | validation: 0.3578601892194169]
	TIME [epoch: 3.61 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28408740640064895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28408740640064895 | validation: 0.2873037280528624]
	TIME [epoch: 3.61 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40714271399486296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40714271399486296 | validation: 0.3575495786423865]
	TIME [epoch: 3.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31187645313706414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31187645313706414 | validation: 0.20734568102935805]
	TIME [epoch: 3.61 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16448630654968924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16448630654968924 | validation: 0.2197275167393171]
	TIME [epoch: 3.62 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20193304995950825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20193304995950825 | validation: 0.33110285925091293]
	TIME [epoch: 3.59 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27959913524259544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27959913524259544 | validation: 0.22202160462999976]
	TIME [epoch: 3.61 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22012173819972478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22012173819972478 | validation: 0.2132935068232063]
	TIME [epoch: 3.62 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16672054993876795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16672054993876795 | validation: 0.2482355935235645]
	TIME [epoch: 3.61 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17463599456388096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17463599456388096 | validation: 0.16685772837239582]
	TIME [epoch: 3.61 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22683943228399314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22683943228399314 | validation: 0.29772665355120564]
	TIME [epoch: 3.62 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24030130216007525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24030130216007525 | validation: 0.20033038180773222]
	TIME [epoch: 3.57 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20117200694236195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20117200694236195 | validation: 0.2780388341564894]
	TIME [epoch: 3.58 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.171647686238716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.171647686238716 | validation: 0.15800414807746332]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_534.pth
	Model improved!!!
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17511234009747229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17511234009747229 | validation: 0.21905524966390405]
	TIME [epoch: 3.59 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16581794636315486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16581794636315486 | validation: 0.2135704127121187]
	TIME [epoch: 3.58 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19024929855232764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19024929855232764 | validation: 0.41063818427040283]
	TIME [epoch: 3.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3589392634044912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3589392634044912 | validation: 0.1937530081462192]
	TIME [epoch: 3.58 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21724350945978002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21724350945978002 | validation: 0.22916142563087202]
	TIME [epoch: 3.58 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2664967546264907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2664967546264907 | validation: 0.4482854331547966]
	TIME [epoch: 3.58 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3456045723704084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3456045723704084 | validation: 0.1912027235302711]
	TIME [epoch: 3.57 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2260342158533356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2260342158533356 | validation: 0.1262530849315222]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1458302204923538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1458302204923538 | validation: 0.21317276956031891]
	TIME [epoch: 3.58 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14227423369316922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14227423369316922 | validation: 0.18310714126576166]
	TIME [epoch: 3.58 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1351745128656589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1351745128656589 | validation: 0.18662985828321013]
	TIME [epoch: 3.58 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12998760750177776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12998760750177776 | validation: 0.17389401198576568]
	TIME [epoch: 3.58 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1716574383865966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1716574383865966 | validation: 0.35315343376684283]
	TIME [epoch: 3.57 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28258721408626136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28258721408626136 | validation: 0.34316208552853356]
	TIME [epoch: 3.58 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33329413462083196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33329413462083196 | validation: 0.14160175184561818]
	TIME [epoch: 3.57 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13917272965270364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13917272965270364 | validation: 0.20722328205914764]
	TIME [epoch: 3.59 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13077100682292142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13077100682292142 | validation: 0.13966227963247216]
	TIME [epoch: 3.58 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16954256508270577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16954256508270577 | validation: 0.33544713457339104]
	TIME [epoch: 3.57 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.277682899538262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.277682899538262 | validation: 0.21819067662911984]
	TIME [epoch: 3.63 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26832357799679996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26832357799679996 | validation: 0.22248622638193005]
	TIME [epoch: 3.59 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19579388956154944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19579388956154944 | validation: 0.1833034816659051]
	TIME [epoch: 3.58 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13814613357869118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13814613357869118 | validation: 0.2023405033474048]
	TIME [epoch: 3.58 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1801829298295803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1801829298295803 | validation: 0.20348690069277692]
	TIME [epoch: 3.57 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17427183280370165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17427183280370165 | validation: 0.15554328301678977]
	TIME [epoch: 3.56 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10948672398503781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10948672398503781 | validation: 0.13655796942301143]
	TIME [epoch: 3.57 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09589555709585725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09589555709585725 | validation: 0.13954890684100205]
	TIME [epoch: 3.57 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10210036088910741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10210036088910741 | validation: 0.12904473797975666]
	TIME [epoch: 3.57 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1342401555173142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1342401555173142 | validation: 0.3184043225183374]
	TIME [epoch: 3.58 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25354316556845957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25354316556845957 | validation: 0.2692321490812926]
	TIME [epoch: 3.58 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29809015282401496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29809015282401496 | validation: 0.2635705949607154]
	TIME [epoch: 3.57 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18949778993373417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18949778993373417 | validation: 0.20347438709001114]
	TIME [epoch: 3.57 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2462793454860689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2462793454860689 | validation: 0.2243780012302053]
	TIME [epoch: 3.58 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2120900003866837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2120900003866837 | validation: 0.16888378504511373]
	TIME [epoch: 3.57 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11243806593426608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11243806593426608 | validation: 0.17658281577004328]
	TIME [epoch: 3.57 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1509103112361517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1509103112361517 | validation: 0.21216117796702677]
	TIME [epoch: 3.57 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20876555573851222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20876555573851222 | validation: 0.12941212554257284]
	TIME [epoch: 3.57 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12266466993295813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12266466993295813 | validation: 0.12913913210183445]
	TIME [epoch: 3.57 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08495603810726912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08495603810726912 | validation: 0.12163520667092974]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09202785515919285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09202785515919285 | validation: 0.15703379582873575]
	TIME [epoch: 3.59 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14178073479790748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14178073479790748 | validation: 0.26027562677314686]
	TIME [epoch: 3.58 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2711216550680611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2711216550680611 | validation: 0.2708015700020003]
	TIME [epoch: 3.57 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24485565308906548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24485565308906548 | validation: 0.15305878767850595]
	TIME [epoch: 3.58 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17425881015077685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17425881015077685 | validation: 0.22726123783736785]
	TIME [epoch: 3.58 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15928199971076024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15928199971076024 | validation: 0.19583172660003587]
	TIME [epoch: 3.57 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22579013879920148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22579013879920148 | validation: 0.21076622752080426]
	TIME [epoch: 3.57 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19755620339354893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19755620339354893 | validation: 0.1598428198273203]
	TIME [epoch: 3.55 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15102002526929614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15102002526929614 | validation: 0.2054297428449787]
	TIME [epoch: 3.57 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13049555735352747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13049555735352747 | validation: 0.0920412379072466]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09877532997791491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09877532997791491 | validation: 0.14521639894304994]
	TIME [epoch: 3.58 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.091933600771818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.091933600771818 | validation: 0.10824572134814135]
	TIME [epoch: 3.56 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10899807717715224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10899807717715224 | validation: 0.1582593164444103]
	TIME [epoch: 3.57 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11248241481916449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11248241481916449 | validation: 0.13994322605135423]
	TIME [epoch: 3.58 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1418878314773143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1418878314773143 | validation: 0.300769205499406]
	TIME [epoch: 3.57 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23613810262670093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23613810262670093 | validation: 0.3420880297100151]
	TIME [epoch: 3.56 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4186100948981242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4186100948981242 | validation: 0.2142344893403621]
	TIME [epoch: 3.57 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24652574014517092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24652574014517092 | validation: 0.1639546158937391]
	TIME [epoch: 3.56 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13745167392901028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13745167392901028 | validation: 0.22454914382714375]
	TIME [epoch: 3.56 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20825463233567612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20825463233567612 | validation: 0.1545134263202702]
	TIME [epoch: 3.56 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1453833783505199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1453833783505199 | validation: 0.11786411332477204]
	TIME [epoch: 3.56 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08190820286739654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08190820286739654 | validation: 0.13557056840897644]
	TIME [epoch: 3.56 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09347636382931022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09347636382931022 | validation: 0.12529100847566169]
	TIME [epoch: 3.57 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08596712255380652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08596712255380652 | validation: 0.09089259837572915]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07353711204760566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07353711204760566 | validation: 0.09739429407056284]
	TIME [epoch: 3.58 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06547490003428263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06547490003428263 | validation: 0.08172581838998415]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06117850753238206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06117850753238206 | validation: 0.10412745813617895]
	TIME [epoch: 3.57 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06684062809505086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06684062809505086 | validation: 0.1379587794460349]
	TIME [epoch: 3.57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14189846596975694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14189846596975694 | validation: 0.4935611173762559]
	TIME [epoch: 3.57 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45407234088262527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45407234088262527 | validation: 0.19834261653023316]
	TIME [epoch: 3.57 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24968414301622222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24968414301622222 | validation: 0.1538901220789647]
	TIME [epoch: 3.57 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11698509880703835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11698509880703835 | validation: 0.22014322701270067]
	TIME [epoch: 3.56 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24620563317798938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24620563317798938 | validation: 0.21520102099479987]
	TIME [epoch: 3.57 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22231306266974632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22231306266974632 | validation: 0.1552677961401443]
	TIME [epoch: 3.57 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1136512963365541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1136512963365541 | validation: 0.15735119945385198]
	TIME [epoch: 3.57 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13094536784788827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13094536784788827 | validation: 0.11406039043845045]
	TIME [epoch: 3.57 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1091236901076842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1091236901076842 | validation: 0.12815469629268525]
	TIME [epoch: 3.57 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1083585015261907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1083585015261907 | validation: 0.14415153917403892]
	TIME [epoch: 3.58 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1062109805798184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1062109805798184 | validation: 0.10343910924400182]
	TIME [epoch: 3.57 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10804012621023269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10804012621023269 | validation: 0.19486544085349045]
	TIME [epoch: 3.57 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17228973694126423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17228973694126423 | validation: 0.17411101287956443]
	TIME [epoch: 3.57 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21087564508257067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21087564508257067 | validation: 0.23029137841945505]
	TIME [epoch: 3.56 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17327005142938923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17327005142938923 | validation: 0.1355563354185415]
	TIME [epoch: 3.57 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1604905080209962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1604905080209962 | validation: 0.12230196404276072]
	TIME [epoch: 3.56 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11809399877367317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11809399877367317 | validation: 0.14100857864872932]
	TIME [epoch: 3.56 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09189575345116335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09189575345116335 | validation: 0.1032130230220157]
	TIME [epoch: 3.56 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09121342089178672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09121342089178672 | validation: 0.09487016278038927]
	TIME [epoch: 3.56 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07721208925902633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07721208925902633 | validation: 0.11983953534158315]
	TIME [epoch: 3.56 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11297458392834753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11297458392834753 | validation: 0.13603371848273166]
	TIME [epoch: 3.59 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11823384553853902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11823384553853902 | validation: 0.17138680855166571]
	TIME [epoch: 3.58 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1477074100035436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1477074100035436 | validation: 0.1666934442976149]
	TIME [epoch: 3.58 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15651129701370006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15651129701370006 | validation: 0.10946555365479643]
	TIME [epoch: 3.57 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10308484962866978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10308484962866978 | validation: 0.12067954708831613]
	TIME [epoch: 3.57 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08399281449505291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08399281449505291 | validation: 0.10333076842418065]
	TIME [epoch: 3.57 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09320152677370164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09320152677370164 | validation: 0.2612697457104258]
	TIME [epoch: 3.56 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2602142098559993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2602142098559993 | validation: 0.29375300237179447]
	TIME [epoch: 3.55 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35711890026669835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35711890026669835 | validation: 0.22316178720949012]
	TIME [epoch: 3.57 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14399008242772826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14399008242772826 | validation: 0.07414611646546422]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09410478391388571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09410478391388571 | validation: 0.07978781506031772]
	TIME [epoch: 3.58 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07357566167063145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07357566167063145 | validation: 0.1333704800430361]
	TIME [epoch: 3.58 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07646587749357439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07646587749357439 | validation: 0.08268422055702547]
	TIME [epoch: 3.59 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08875602018501445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08875602018501445 | validation: 0.15372727347090676]
	TIME [epoch: 3.58 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12180934688296127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12180934688296127 | validation: 0.13602943864185055]
	TIME [epoch: 3.59 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15350456885296768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15350456885296768 | validation: 0.20881904884088318]
	TIME [epoch: 3.57 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17733811683149675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17733811683149675 | validation: 0.13759513781998897]
	TIME [epoch: 3.58 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16096471616130867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16096471616130867 | validation: 0.16667621660566284]
	TIME [epoch: 3.58 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13249645894640122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13249645894640122 | validation: 0.13254115214768247]
	TIME [epoch: 3.59 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09348985816677452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09348985816677452 | validation: 0.06962156738768258]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06384170888725961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06384170888725961 | validation: 0.08147988612413615]
	TIME [epoch: 3.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052706144152880795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052706144152880795 | validation: 0.058531482286649616]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06094901521375608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06094901521375608 | validation: 0.0839678246991401]
	TIME [epoch: 3.58 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07099819020134543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07099819020134543 | validation: 0.1600026455082822]
	TIME [epoch: 3.59 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1463793105165934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1463793105165934 | validation: 0.26187879106315454]
	TIME [epoch: 3.59 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28424393561317146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28424393561317146 | validation: 0.1552164728731035]
	TIME [epoch: 3.57 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16748270489669012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16748270489669012 | validation: 0.13737532460333768]
	TIME [epoch: 3.69 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1562900050800524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1562900050800524 | validation: 0.2765502253029899]
	TIME [epoch: 3.57 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23242793128478956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23242793128478956 | validation: 0.144149309847624]
	TIME [epoch: 3.57 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17171562922240458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17171562922240458 | validation: 0.11017477227009875]
	TIME [epoch: 3.57 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10004585729904879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10004585729904879 | validation: 0.10439450361351366]
	TIME [epoch: 3.58 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09613737889852716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09613737889852716 | validation: 0.08859517954131207]
	TIME [epoch: 3.57 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07094937113290786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07094937113290786 | validation: 0.05555048788186139]
	TIME [epoch: 3.59 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05385184549035703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05385184549035703 | validation: 0.09884015352201632]
	TIME [epoch: 3.58 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06037494628027584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06037494628027584 | validation: 0.05978664693504709]
	TIME [epoch: 3.58 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07616856819861913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07616856819861913 | validation: 0.1522487000917252]
	TIME [epoch: 3.58 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13513861947074432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13513861947074432 | validation: 0.17286443938752327]
	TIME [epoch: 3.58 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2185746980610378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2185746980610378 | validation: 0.20965495078292734]
	TIME [epoch: 3.57 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1946262630063266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1946262630063266 | validation: 0.1344371797359641]
	TIME [epoch: 3.56 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11389380625209565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11389380625209565 | validation: 0.1643343192578769]
	TIME [epoch: 3.57 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1213162339952984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1213162339952984 | validation: 0.1266709810858317]
	TIME [epoch: 3.58 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0909540155813797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0909540155813797 | validation: 0.11205013424928306]
	TIME [epoch: 3.57 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09510769399978347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09510769399978347 | validation: 0.09236603043064805]
	TIME [epoch: 3.57 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08557831474374136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08557831474374136 | validation: 0.07533570799233094]
	TIME [epoch: 3.57 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07177592287046146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07177592287046146 | validation: 0.07055598088817282]
	TIME [epoch: 3.57 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05174288208765253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05174288208765253 | validation: 0.055184553271362416]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047021491886271444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047021491886271444 | validation: 0.07657547542789232]
	TIME [epoch: 3.59 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046271304408947576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046271304408947576 | validation: 0.05203685875454999]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058565113458370066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058565113458370066 | validation: 0.14550521663772426]
	TIME [epoch: 3.59 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11659022015358936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11659022015358936 | validation: 0.23126176477783023]
	TIME [epoch: 3.57 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30587970706128725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30587970706128725 | validation: 0.27470622563673336]
	TIME [epoch: 3.56 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26378976174847646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26378976174847646 | validation: 0.15447477891980704]
	TIME [epoch: 3.56 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1581385695883047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1581385695883047 | validation: 0.22865131416363393]
	TIME [epoch: 3.56 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1850329502218687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1850329502218687 | validation: 0.08538793828867686]
	TIME [epoch: 3.57 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06470415212328398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06470415212328398 | validation: 0.05654788239734401]
	TIME [epoch: 3.57 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04196463757788473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04196463757788473 | validation: 0.06329471194772417]
	TIME [epoch: 3.56 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051296558039204077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051296558039204077 | validation: 0.0675041948184658]
	TIME [epoch: 3.57 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0569516588744506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0569516588744506 | validation: 0.06944778430113534]
	TIME [epoch: 3.57 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06283446013394048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06283446013394048 | validation: 0.09368762913059309]
	TIME [epoch: 3.57 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10357432746125327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10357432746125327 | validation: 0.1304421954319679]
	TIME [epoch: 3.57 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12801679033391214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12801679033391214 | validation: 0.15596131181913167]
	TIME [epoch: 3.57 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1357023639698336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1357023639698336 | validation: 0.12075584027991355]
	TIME [epoch: 3.57 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1518814531878471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1518814531878471 | validation: 0.21741802338317623]
	TIME [epoch: 3.57 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20596538223656005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20596538223656005 | validation: 0.13051894154485696]
	TIME [epoch: 3.57 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16796334359871268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16796334359871268 | validation: 0.1046256729908087]
	TIME [epoch: 3.58 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09896997243499414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09896997243499414 | validation: 0.12868177487229607]
	TIME [epoch: 3.59 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0946058459277611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0946058459277611 | validation: 0.0925604467071231]
	TIME [epoch: 3.58 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06506905775239498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06506905775239498 | validation: 0.04433989722455021]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04039484540942688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04039484540942688 | validation: 0.07193060848005062]
	TIME [epoch: 3.57 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04163637983994325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04163637983994325 | validation: 0.04750346002778984]
	TIME [epoch: 3.58 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04095341540199551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04095341540199551 | validation: 0.08304105352730409]
	TIME [epoch: 3.59 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04963030348926282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04963030348926282 | validation: 0.08305251217197118]
	TIME [epoch: 3.57 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0991130009708405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0991130009708405 | validation: 0.20889533366417876]
	TIME [epoch: 3.58 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19206520919011766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19206520919011766 | validation: 0.2059127038964924]
	TIME [epoch: 3.58 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2513986014606476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2513986014606476 | validation: 0.06780695130710704]
	TIME [epoch: 3.56 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0780303976869573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0780303976869573 | validation: 0.14784261162002005]
	TIME [epoch: 3.56 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12113282285200727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12113282285200727 | validation: 0.2617524564962246]
	TIME [epoch: 3.58 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23345464598731525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23345464598731525 | validation: 0.14416587648806609]
	TIME [epoch: 3.57 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1674778257042026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1674778257042026 | validation: 0.15019824213351007]
	TIME [epoch: 3.58 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1472061112355995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1472061112355995 | validation: 0.07826816169525547]
	TIME [epoch: 3.56 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09200230636510642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09200230636510642 | validation: 0.0691627480154842]
	TIME [epoch: 3.57 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04183609933188791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04183609933188791 | validation: 0.04981702529255845]
	TIME [epoch: 3.55 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037263044202725165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037263044202725165 | validation: 0.041604405299066616]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037159173717902505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037159173717902505 | validation: 0.056698533983166224]
	TIME [epoch: 3.58 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03641736240210206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03641736240210206 | validation: 0.03586901489493102]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04501378952077152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04501378952077152 | validation: 0.12238421192362717]
	TIME [epoch: 3.57 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09254375096815126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09254375096815126 | validation: 0.18833339041647662]
	TIME [epoch: 3.57 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22216225665442146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22216225665442146 | validation: 0.2877314221329412]
	TIME [epoch: 3.57 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2626022659408618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2626022659408618 | validation: 0.0798498716291549]
	TIME [epoch: 3.58 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08136539966443579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08136539966443579 | validation: 0.053688323142625886]
	TIME [epoch: 3.57 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036164492090857314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036164492090857314 | validation: 0.07632545962428146]
	TIME [epoch: 3.57 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0535568272224541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0535568272224541 | validation: 0.05004755930520173]
	TIME [epoch: 3.56 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06889704301385924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06889704301385924 | validation: 0.10520741708566093]
	TIME [epoch: 3.57 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07374908830795578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07374908830795578 | validation: 0.07044698611577055]
	TIME [epoch: 3.57 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09195040040016778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09195040040016778 | validation: 0.15235041740656177]
	TIME [epoch: 3.58 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11934478627911141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11934478627911141 | validation: 0.13229240984233812]
	TIME [epoch: 3.58 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14477073424061548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14477073424061548 | validation: 0.08980748760608033]
	TIME [epoch: 3.57 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09071812171637263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09071812171637263 | validation: 0.0550670820222545]
	TIME [epoch: 3.57 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05157058671404885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05157058671404885 | validation: 0.04502258397299904]
	TIME [epoch: 3.58 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03433549172010584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03433549172010584 | validation: 0.04513621030178814]
	TIME [epoch: 3.56 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031485793708620896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031485793708620896 | validation: 0.05639856020927517]
	TIME [epoch: 3.57 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03849841429329859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03849841429329859 | validation: 0.10696880976352384]
	TIME [epoch: 3.56 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08336409077373584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08336409077373584 | validation: 0.22611718304831874]
	TIME [epoch: 3.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19617198372978803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19617198372978803 | validation: 0.25020822600559395]
	TIME [epoch: 3.57 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25189641357562464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25189641357562464 | validation: 0.22713676868863183]
	TIME [epoch: 3.58 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22916836793972792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22916836793972792 | validation: 0.07526856276124311]
	TIME [epoch: 3.57 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12537278183653883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12537278183653883 | validation: 0.06104422470272848]
	TIME [epoch: 3.58 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06306151039486325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06306151039486325 | validation: 0.0888482549023829]
	TIME [epoch: 3.59 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06958102541544851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06958102541544851 | validation: 0.06177160247619982]
	TIME [epoch: 3.56 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03959984709748306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03959984709748306 | validation: 0.04193280047216053]
	TIME [epoch: 3.57 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03156876343226026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03156876343226026 | validation: 0.04340300311907622]
	TIME [epoch: 3.57 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031068595142005637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031068595142005637 | validation: 0.04955108390424487]
	TIME [epoch: 3.57 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02686094298225174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02686094298225174 | validation: 0.030570863741100962]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0337269467089504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0337269467089504 | validation: 0.10002055264662424]
	TIME [epoch: 3.57 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07029869403395292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07029869403395292 | validation: 0.18712927458798023]
	TIME [epoch: 3.58 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2293255429425757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2293255429425757 | validation: 0.27955995701270947]
	TIME [epoch: 3.57 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26835883644945385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26835883644945385 | validation: 0.08003550705651757]
	TIME [epoch: 3.57 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07845554274846922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07845554274846922 | validation: 0.09678690707530516]
	TIME [epoch: 3.58 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07338380569038597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07338380569038597 | validation: 0.13758061560754384]
	TIME [epoch: 3.58 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11337693494189961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11337693494189961 | validation: 0.1151831572380238]
	TIME [epoch: 3.58 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10615419415639518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10615419415639518 | validation: 0.06429463973857182]
	TIME [epoch: 3.57 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06657339457105044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06657339457105044 | validation: 0.07217147211041197]
	TIME [epoch: 3.57 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061096813202580716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061096813202580716 | validation: 0.06278607724146167]
	TIME [epoch: 3.57 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07816751332142126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07816751332142126 | validation: 0.09195083368878317]
	TIME [epoch: 3.58 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0750713334197905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0750713334197905 | validation: 0.07152312536337567]
	TIME [epoch: 3.58 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08194845635149486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08194845635149486 | validation: 0.13777626523059758]
	TIME [epoch: 3.58 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09573968413858448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09573968413858448 | validation: 0.09080489406820165]
	TIME [epoch: 3.58 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10131028274538398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10131028274538398 | validation: 0.14692246695267577]
	TIME [epoch: 3.58 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10967964369821123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10967964369821123 | validation: 0.08795658627902697]
	TIME [epoch: 3.58 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1040882322466616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1040882322466616 | validation: 0.07592468390901233]
	TIME [epoch: 3.58 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06349563497201115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06349563497201115 | validation: 0.04490458566262318]
	TIME [epoch: 3.58 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03618003944321638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03618003944321638 | validation: 0.04424202493834967]
	TIME [epoch: 3.59 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031636824888072325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031636824888072325 | validation: 0.04366718605056559]
	TIME [epoch: 3.59 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03476859899057613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03476859899057613 | validation: 0.07774314157382547]
	TIME [epoch: 3.57 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05827790379118749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05827790379118749 | validation: 0.1590237941932573]
	TIME [epoch: 3.59 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12936645846187841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12936645846187841 | validation: 0.21920479919990213]
	TIME [epoch: 3.57 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19363237223086402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19363237223086402 | validation: 0.12394526714573038]
	TIME [epoch: 3.58 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1142528524662914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1142528524662914 | validation: 0.06536279336765828]
	TIME [epoch: 3.57 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047579676805750155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.047579676805750155 | validation: 0.03904681966015146]
	TIME [epoch: 3.58 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05693470744327515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05693470744327515 | validation: 0.1150641857533842]
	TIME [epoch: 3.58 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09745344565830348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09745344565830348 | validation: 0.07770106560617492]
	TIME [epoch: 3.58 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11629888976279436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11629888976279436 | validation: 0.12879082550921359]
	TIME [epoch: 3.58 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11715946858391721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11715946858391721 | validation: 0.13300716389794534]
	TIME [epoch: 3.59 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13802519452672404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13802519452672404 | validation: 0.11605951069283788]
	TIME [epoch: 3.59 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09923473652591426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09923473652591426 | validation: 0.052767587473841374]
	TIME [epoch: 3.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054384727794945964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054384727794945964 | validation: 0.05914819835737056]
	TIME [epoch: 3.58 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03648280849898223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03648280849898223 | validation: 0.05788718091590398]
	TIME [epoch: 3.58 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03581410632937833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03581410632937833 | validation: 0.04611139645180974]
	TIME [epoch: 3.57 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039498118109410084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039498118109410084 | validation: 0.08822225004752814]
	TIME [epoch: 3.58 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060509416079748565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060509416079748565 | validation: 0.12437584337403061]
	TIME [epoch: 3.57 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14015404517552163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14015404517552163 | validation: 0.2289065828199103]
	TIME [epoch: 3.59 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2247933491470011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2247933491470011 | validation: 0.09922428588398607]
	TIME [epoch: 3.58 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11441357668746861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11441357668746861 | validation: 0.09779999190382638]
	TIME [epoch: 3.59 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06286067733723376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06286067733723376 | validation: 0.053956132194889164]
	TIME [epoch: 3.58 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06276417123510458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06276417123510458 | validation: 0.09196415114731893]
	TIME [epoch: 3.59 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0659512909768851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0659512909768851 | validation: 0.060361744145208784]
	TIME [epoch: 3.58 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06485875645047058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06485875645047058 | validation: 0.07118004543082143]
	TIME [epoch: 3.59 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053243035107726884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053243035107726884 | validation: 0.04042297953922123]
	TIME [epoch: 3.58 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05407588514320999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05407588514320999 | validation: 0.08445703053141394]
	TIME [epoch: 3.59 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06719201689202671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06719201689202671 | validation: 0.08287763059097691]
	TIME [epoch: 3.57 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10528546299956303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10528546299956303 | validation: 0.17338288532429497]
	TIME [epoch: 3.58 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16266951183569547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16266951183569547 | validation: 0.11762438421254638]
	TIME [epoch: 3.58 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13121386081672978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13121386081672978 | validation: 0.09456886854079427]
	TIME [epoch: 3.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06643280385662663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06643280385662663 | validation: 0.08133049236441309]
	TIME [epoch: 3.58 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050755869868192055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050755869868192055 | validation: 0.04329218386640891]
	TIME [epoch: 3.58 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046142387341700564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046142387341700564 | validation: 0.048038688642276214]
	TIME [epoch: 3.59 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03165063601494253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03165063601494253 | validation: 0.03313336452015678]
	TIME [epoch: 3.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02479566248983652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02479566248983652 | validation: 0.03309847182324129]
	TIME [epoch: 3.58 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022489087740858168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022489087740858168 | validation: 0.03164685760505639]
	TIME [epoch: 3.58 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027167921999401337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027167921999401337 | validation: 0.06523023801554938]
	TIME [epoch: 3.57 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060000067390751054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060000067390751054 | validation: 0.15283484447093248]
	TIME [epoch: 3.57 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20199379247475463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20199379247475463 | validation: 0.23062826196768338]
	TIME [epoch: 3.57 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22082504892856125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22082504892856125 | validation: 0.06787616261750111]
	TIME [epoch: 3.57 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08130093258815099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08130093258815099 | validation: 0.08136964739171633]
	TIME [epoch: 3.57 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04792951902027137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04792951902027137 | validation: 0.06082457473569974]
	TIME [epoch: 3.58 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06575834449057603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06575834449057603 | validation: 0.0727488840845859]
	TIME [epoch: 3.59 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06716999080929945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06716999080929945 | validation: 0.09390910685150242]
	TIME [epoch: 3.59 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0832732390669065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0832732390669065 | validation: 0.1304699841224016]
	TIME [epoch: 3.59 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11162258728369061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11162258728369061 | validation: 0.14545108487418723]
	TIME [epoch: 3.59 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15418611540959407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15418611540959407 | validation: 0.17274610453553213]
	TIME [epoch: 3.57 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13239827820735556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13239827820735556 | validation: 0.05642777772156709]
	TIME [epoch: 3.57 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046873112475856606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046873112475856606 | validation: 0.031769117411997845]
	TIME [epoch: 3.57 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023133419802167696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023133419802167696 | validation: 0.03729317169783539]
	TIME [epoch: 3.58 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022033245184296106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022033245184296106 | validation: 0.03849601095768441]
	TIME [epoch: 3.57 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027509178442190505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027509178442190505 | validation: 0.043178722235943545]
	TIME [epoch: 3.57 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03945631056070075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03945631056070075 | validation: 0.07872136692011727]
	TIME [epoch: 3.57 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06393669817770274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06393669817770274 | validation: 0.08653788210115763]
	TIME [epoch: 3.57 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08784108382292712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08784108382292712 | validation: 0.11762655621882323]
	TIME [epoch: 3.58 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08502614836955445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08502614836955445 | validation: 0.06878477014166054]
	TIME [epoch: 3.57 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057485874846060485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057485874846060485 | validation: 0.07130491129881147]
	TIME [epoch: 3.58 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057177011381414275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057177011381414275 | validation: 0.08641139795918683]
	TIME [epoch: 3.58 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09454394654921551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09454394654921551 | validation: 0.10400583311397771]
	TIME [epoch: 3.57 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11284746319497059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11284746319497059 | validation: 0.0651495326365447]
	TIME [epoch: 3.58 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07647228549845307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07647228549845307 | validation: 0.08865041138029084]
	TIME [epoch: 3.57 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11861331222795223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11861331222795223 | validation: 0.2282608884255104]
	TIME [epoch: 3.56 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1781791256124504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1781791256124504 | validation: 0.10663570066619923]
	TIME [epoch: 3.57 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14348446297121284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14348446297121284 | validation: 0.07473666463671225]
	TIME [epoch: 3.57 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06449270534049235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06449270534049235 | validation: 0.05291014175926443]
	TIME [epoch: 3.58 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036326587403178366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036326587403178366 | validation: 0.03515814752300461]
	TIME [epoch: 3.57 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023174155537777727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023174155537777727 | validation: 0.031409114108436026]
	TIME [epoch: 3.58 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02111277317281065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02111277317281065 | validation: 0.03057133088668197]
	TIME [epoch: 3.56 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022673513694024563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022673513694024563 | validation: 0.043342435432668504]
	TIME [epoch: 3.57 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026035573330373617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026035573330373617 | validation: 0.03787862214090618]
	TIME [epoch: 3.58 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0390389889179619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0390389889179619 | validation: 0.10943645259813853]
	TIME [epoch: 3.57 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09350827753945723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09350827753945723 | validation: 0.11713394881784674]
	TIME [epoch: 3.57 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1579058081911954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1579058081911954 | validation: 0.1844691414199089]
	TIME [epoch: 3.56 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1728265429298746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1728265429298746 | validation: 0.157348983192703]
	TIME [epoch: 3.57 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14751806827356725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14751806827356725 | validation: 0.18372886099520944]
	TIME [epoch: 3.58 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13410675253996396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13410675253996396 | validation: 0.06322196799073813]
	TIME [epoch: 3.57 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03674038825936648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03674038825936648 | validation: 0.03799953814581042]
	TIME [epoch: 3.57 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03401261443599285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03401261443599285 | validation: 0.058815749700052135]
	TIME [epoch: 3.61 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03818516189578348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03818516189578348 | validation: 0.04302946296028784]
	TIME [epoch: 3.57 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03856631518281864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03856631518281864 | validation: 0.05409576570961925]
	TIME [epoch: 3.59 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04272570865629157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04272570865629157 | validation: 0.05555817871360964]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_phi1_3a_v_mmd1_20240822_132757/states/model_phi1_3a_v_mmd1_834.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 2106.260 seconds.
