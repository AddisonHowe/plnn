Args:
Namespace(name='model_phi1_4c_v_mmd1', outdir='out/model_training/model_phi1_4c_v_mmd1', training_data='data/training_data/data_phi1_4c/training', validation_data='data/training_data/data_phi1_4c/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3762343619

Training model...

Saving initial model state to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.160543717684463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.160543717684463 | validation: 4.486516055352946]
	TIME [epoch: 44.7 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.1038096359572505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1038096359572505 | validation: 4.693332600098373]
	TIME [epoch: 3.69 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.741995244796234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.741995244796234 | validation: 6.437550177610537]
	TIME [epoch: 3.66 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.346001899509288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.346001899509288 | validation: 5.080494873937074]
	TIME [epoch: 3.64 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.462910009357202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.462910009357202 | validation: 4.52515160205133]
	TIME [epoch: 3.66 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.136120877510379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.136120877510379 | validation: 4.062144758526471]
	TIME [epoch: 3.68 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.785590941417002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.785590941417002 | validation: 3.94722670960241]
	TIME [epoch: 3.67 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.537984368879267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.537984368879267 | validation: 3.8826293176834668]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4817459388577743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4817459388577743 | validation: 3.676727723700313]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.426473163167305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.426473163167305 | validation: 3.8136084217232504]
	TIME [epoch: 3.65 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3671475498163366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3671475498163366 | validation: 3.6051972783155266]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.339642645769824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.339642645769824 | validation: 3.8096976044488486]
	TIME [epoch: 3.67 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3720869795628174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3720869795628174 | validation: 3.506736377439876]
	TIME [epoch: 3.68 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.341997694387625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.341997694387625 | validation: 3.6883762836973872]
	TIME [epoch: 3.66 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2331333067918413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2331333067918413 | validation: 3.5036227781492473]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1739570667288297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1739570667288297 | validation: 3.6151038961340918]
	TIME [epoch: 3.66 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.241802023170734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.241802023170734 | validation: 3.4188025097311185]
	TIME [epoch: 3.67 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.080122080501725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.080122080501725 | validation: 3.431931566229939]
	TIME [epoch: 3.63 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0106850991432417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0106850991432417 | validation: 3.161521020312026]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.011380067071733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.011380067071733 | validation: 3.110274404405378]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8744923462526635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8744923462526635 | validation: 2.372716167141653]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.235984407710616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.235984407710616 | validation: 2.8065612331775593]
	TIME [epoch: 3.66 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.545881013030315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.545881013030315 | validation: 1.8340567537489463]
	TIME [epoch: 3.67 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.993729737477807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.993729737477807 | validation: 1.9325802413330504]
	TIME [epoch: 3.65 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9791171727229926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9791171727229926 | validation: 1.6319091402251857]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.45999026483875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.45999026483875 | validation: 1.5545781059022206]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5579015217379424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5579015217379424 | validation: 1.4410212161281113]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4161165211812556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4161165211812556 | validation: 1.3599211728130103]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5245960055236278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5245960055236278 | validation: 1.3099232153175266]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2263667760189783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2263667760189783 | validation: 1.1893625522568587]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2645437045419436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2645437045419436 | validation: 1.3696923401873604]
	TIME [epoch: 3.64 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3383322537143059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3383322537143059 | validation: 1.278157616855606]
	TIME [epoch: 3.64 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.367993613941832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.367993613941832 | validation: 1.1129589780049531]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2223284525444558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2223284525444558 | validation: 1.2587051659898187]
	TIME [epoch: 3.68 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1888904721031082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1888904721031082 | validation: 1.2436510356144688]
	TIME [epoch: 3.66 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2178112743543728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2178112743543728 | validation: 1.2036775904349557]
	TIME [epoch: 3.66 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.084270867335622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.084270867335622 | validation: 1.216545546863843]
	TIME [epoch: 3.66 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1371428998495756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1371428998495756 | validation: 1.240205176118197]
	TIME [epoch: 3.66 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1617864064199135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1617864064199135 | validation: 1.1392156737815409]
	TIME [epoch: 3.67 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1264331675976424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1264331675976424 | validation: 1.2285178066416789]
	TIME [epoch: 3.66 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1024439111196909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1024439111196909 | validation: 1.1320187566407653]
	TIME [epoch: 3.66 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2550327720021337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2550327720021337 | validation: 1.0317323587845852]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0386071670439738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0386071670439738 | validation: 1.3098142265660488]
	TIME [epoch: 3.65 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2024942374276175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2024942374276175 | validation: 1.0300116547997171]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0808651713593385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0808651713593385 | validation: 0.9492815888206213]
	TIME [epoch: 3.69 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9938047025294057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9938047025294057 | validation: 1.2207977134085708]
	TIME [epoch: 3.64 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1159774369130713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1159774369130713 | validation: 1.041065564075746]
	TIME [epoch: 3.64 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.099116141819486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.099116141819486 | validation: 0.9077155367488775]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9743051851724708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9743051851724708 | validation: 1.0727699066039458]
	TIME [epoch: 3.65 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0471200175821238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0471200175821238 | validation: 0.9172970825786436]
	TIME [epoch: 3.65 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9943181514786403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9943181514786403 | validation: 0.9228298743398503]
	TIME [epoch: 3.66 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9840743745785817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9840743745785817 | validation: 0.9813396873428014]
	TIME [epoch: 3.64 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0166394575773896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0166394575773896 | validation: 0.8509323140344849]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9339080744911645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9339080744911645 | validation: 0.8457169267358204]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9311088820998507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9311088820998507 | validation: 0.850905817902437]
	TIME [epoch: 3.66 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9237399934690271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9237399934690271 | validation: 0.846253673362337]
	TIME [epoch: 3.66 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9140758748971356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9140758748971356 | validation: 0.8624492704815396]
	TIME [epoch: 3.65 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9142861561064348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9142861561064348 | validation: 0.8406091232120101]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9065858936158065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9065858936158065 | validation: 0.8249753132752251]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9147191500938736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9147191500938736 | validation: 0.8703647939312655]
	TIME [epoch: 3.64 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9914804556706065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9914804556706065 | validation: 1.1566512617115186]
	TIME [epoch: 3.64 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2146748316234368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2146748316234368 | validation: 0.8194145675934756]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9471687067969221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9471687067969221 | validation: 0.9267702816633856]
	TIME [epoch: 3.64 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0025155713818927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0025155713818927 | validation: 1.0277576305128668]
	TIME [epoch: 3.64 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0656858841304746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0656858841304746 | validation: 0.7981265466075991]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.924850810149571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.924850810149571 | validation: 0.9103800600578353]
	TIME [epoch: 3.65 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9897873955585077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9897873955585077 | validation: 0.8789886977773048]
	TIME [epoch: 3.65 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9694697982398646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9694697982398646 | validation: 0.7980994073454624]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9203244417097557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9203244417097557 | validation: 0.8220858708418621]
	TIME [epoch: 3.64 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9184954813989858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9184954813989858 | validation: 0.7911718496122874]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9004884846523709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9004884846523709 | validation: 0.7967423829720715]
	TIME [epoch: 3.65 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9411813316930951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9411813316930951 | validation: 0.817776272631458]
	TIME [epoch: 3.65 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.951334652392766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.951334652392766 | validation: 0.7965131122238303]
	TIME [epoch: 3.65 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9498233785052267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9498233785052267 | validation: 0.7948014160189116]
	TIME [epoch: 3.64 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8988145595680661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8988145595680661 | validation: 0.7694833234205475]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8812868612556293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8812868612556293 | validation: 0.8184180386586878]
	TIME [epoch: 3.66 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9444698318231949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9444698318231949 | validation: 0.7874286509148919]
	TIME [epoch: 3.67 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.927932352828428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.927932352828428 | validation: 0.8225783181941108]
	TIME [epoch: 3.66 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9275741048161588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9275741048161588 | validation: 0.7735530993108596]
	TIME [epoch: 3.65 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9164329160821102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9164329160821102 | validation: 0.7727484669751215]
	TIME [epoch: 3.65 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8750082006492318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8750082006492318 | validation: 0.7726246907891448]
	TIME [epoch: 3.65 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8788577456417536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8788577456417536 | validation: 0.8493773190696221]
	TIME [epoch: 3.65 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9508989273506501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9508989273506501 | validation: 0.8253766828606448]
	TIME [epoch: 3.64 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9417489609419615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9417489609419615 | validation: 0.8178885329901302]
	TIME [epoch: 3.64 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9193632508440424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9193632508440424 | validation: 0.7810924967058268]
	TIME [epoch: 3.64 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8832082533757477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8832082533757477 | validation: 0.767138735590426]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9026664261109849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9026664261109849 | validation: 0.8060581087358426]
	TIME [epoch: 3.64 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9251594611474048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9251594611474048 | validation: 0.7866962764983993]
	TIME [epoch: 3.64 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9316686154298996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9316686154298996 | validation: 0.7790503396429291]
	TIME [epoch: 3.66 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8899105612729846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8899105612729846 | validation: 0.7812078819657562]
	TIME [epoch: 3.65 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9071824087995161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9071824087995161 | validation: 0.7849064290756305]
	TIME [epoch: 3.64 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8936134037852261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8936134037852261 | validation: 0.7486089235616087]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8759499859591654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8759499859591654 | validation: 0.8238923838378366]
	TIME [epoch: 3.64 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.93004753561949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.93004753561949 | validation: 0.8092962104030254]
	TIME [epoch: 3.63 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9293329111265072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9293329111265072 | validation: 0.8747845668033343]
	TIME [epoch: 3.64 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9739353394455029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9739353394455029 | validation: 0.8165650788838111]
	TIME [epoch: 3.64 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8922316051631779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8922316051631779 | validation: 0.7735545744474116]
	TIME [epoch: 3.64 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8824114327973445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8824114327973445 | validation: 0.7523706347466849]
	TIME [epoch: 3.63 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8827872129515676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8827872129515676 | validation: 0.8466546372995611]
	TIME [epoch: 3.63 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0136118614758098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0136118614758098 | validation: 0.7757229663991437]
	TIME [epoch: 3.64 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8867011079051575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8867011079051575 | validation: 0.7526450267749829]
	TIME [epoch: 3.65 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8656633060059425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8656633060059425 | validation: 0.7257417141222936]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.876837054070957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.876837054070957 | validation: 0.7933863653813069]
	TIME [epoch: 3.63 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9406878372901002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9406878372901002 | validation: 0.8450585635801002]
	TIME [epoch: 3.64 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.005674089402592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.005674089402592 | validation: 0.7587536153292542]
	TIME [epoch: 3.63 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8715543523049591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8715543523049591 | validation: 0.8404365548473578]
	TIME [epoch: 3.64 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9532925786873417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9532925786873417 | validation: 0.8093570339813034]
	TIME [epoch: 3.64 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9792019197053716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9792019197053716 | validation: 0.7589204670853636]
	TIME [epoch: 3.64 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.879257932669795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.879257932669795 | validation: 0.7946746460905123]
	TIME [epoch: 3.64 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.891234615456497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.891234615456497 | validation: 0.7720829804551073]
	TIME [epoch: 3.64 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9157597899593101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9157597899593101 | validation: 0.7599929322184995]
	TIME [epoch: 3.64 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8656547904494595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8656547904494595 | validation: 0.7284361789254231]
	TIME [epoch: 3.65 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8675252473602447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8675252473602447 | validation: 0.7468730934976264]
	TIME [epoch: 3.66 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8532434645655443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8532434645655443 | validation: 0.747449766914134]
	TIME [epoch: 3.64 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8587504124130009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8587504124130009 | validation: 0.8206877880012844]
	TIME [epoch: 3.64 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9049289097331226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9049289097331226 | validation: 0.9051655949093874]
	TIME [epoch: 3.64 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9819395237425869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9819395237425869 | validation: 0.7821976976468012]
	TIME [epoch: 3.64 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8696735973560061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8696735973560061 | validation: 0.7265590555276313]
	TIME [epoch: 3.64 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8485798123299347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8485798123299347 | validation: 0.747067720235863]
	TIME [epoch: 3.64 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8458879575583589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8458879575583589 | validation: 0.7437332984505195]
	TIME [epoch: 3.64 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8625386381589462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8625386381589462 | validation: 0.856583371280414]
	TIME [epoch: 3.63 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0237139141995033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0237139141995033 | validation: 0.9681468539513288]
	TIME [epoch: 3.64 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1505169790982048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1505169790982048 | validation: 0.7856567961482889]
	TIME [epoch: 3.64 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.946515782470354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.946515782470354 | validation: 0.898970590331321]
	TIME [epoch: 3.64 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0221210474431508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0221210474431508 | validation: 0.7131947525424419]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8349153767600183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8349153767600183 | validation: 0.73433390379682]
	TIME [epoch: 3.68 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.884443742433776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.884443742433776 | validation: 0.7966995413293138]
	TIME [epoch: 3.66 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.87859986980442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.87859986980442 | validation: 0.7857440875094064]
	TIME [epoch: 3.65 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9014252632781349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9014252632781349 | validation: 0.8862370381698039]
	TIME [epoch: 3.66 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9421729723973391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9421729723973391 | validation: 0.7973210896593861]
	TIME [epoch: 3.66 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8807685372354871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8807685372354871 | validation: 0.7109264557885652]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8593149869857455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8593149869857455 | validation: 0.715050065140326]
	TIME [epoch: 3.65 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.817285299571064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.817285299571064 | validation: 0.7259338500731216]
	TIME [epoch: 3.66 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8184436160729172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8184436160729172 | validation: 0.7278928665149378]
	TIME [epoch: 3.63 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8546145203885204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8546145203885204 | validation: 0.7712127325514047]
	TIME [epoch: 3.63 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8409565322524484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8409565322524484 | validation: 1.2130177546132412]
	TIME [epoch: 3.63 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1899263990416682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1899263990416682 | validation: 1.2832455601979795]
	TIME [epoch: 3.63 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.356553690783798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.356553690783798 | validation: 0.7647964458756705]
	TIME [epoch: 3.65 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.863151794337691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.863151794337691 | validation: 0.8738665498010072]
	TIME [epoch: 3.64 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9523823896622869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9523823896622869 | validation: 0.7802564040400709]
	TIME [epoch: 3.63 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8727367846377331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8727367846377331 | validation: 0.7363687631676824]
	TIME [epoch: 3.65 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8443625431542341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8443625431542341 | validation: 0.7388386922251112]
	TIME [epoch: 3.64 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.832626012249661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.832626012249661 | validation: 0.7369197472661191]
	TIME [epoch: 3.64 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8229892733459121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8229892733459121 | validation: 0.7520928039296578]
	TIME [epoch: 3.66 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.829075704782861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.829075704782861 | validation: 0.7246094438062075]
	TIME [epoch: 3.66 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8198560508436477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8198560508436477 | validation: 0.7444928170053651]
	TIME [epoch: 3.66 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8341391868721378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8341391868721378 | validation: 0.7498801685229767]
	TIME [epoch: 3.66 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8804334338215071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8804334338215071 | validation: 0.7485281623297897]
	TIME [epoch: 3.67 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8414133529896992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8414133529896992 | validation: 0.7358697801312859]
	TIME [epoch: 3.64 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8419782931022286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8419782931022286 | validation: 0.7374903263597843]
	TIME [epoch: 3.66 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8088329484364273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8088329484364273 | validation: 0.7054356860536007]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8108428449960994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8108428449960994 | validation: 0.750085749731718]
	TIME [epoch: 3.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8233665956239575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8233665956239575 | validation: 1.1049384066718002]
	TIME [epoch: 3.65 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1260494121034348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1260494121034348 | validation: 1.0923526977971272]
	TIME [epoch: 3.66 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1423370645345485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1423370645345485 | validation: 0.7230769445618253]
	TIME [epoch: 3.66 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.869300932219991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.869300932219991 | validation: 0.8013574494601863]
	TIME [epoch: 3.66 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8954759051008404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8954759051008404 | validation: 0.7256164346293439]
	TIME [epoch: 3.66 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8230795707419851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8230795707419851 | validation: 0.7402653890203826]
	TIME [epoch: 3.66 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8475980182338287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8475980182338287 | validation: 0.7140591486529891]
	TIME [epoch: 3.66 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7921807151444739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7921807151444739 | validation: 0.7040124437040826]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7728268175192046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7728268175192046 | validation: 0.6769151422929477]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.766301194141322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.766301194141322 | validation: 0.7055171267739885]
	TIME [epoch: 3.67 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7479322913189294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7479322913189294 | validation: 0.694086391016827]
	TIME [epoch: 3.67 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.760496078730744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.760496078730744 | validation: 0.9312236377708385]
	TIME [epoch: 3.66 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0093198804720909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0093198804720909 | validation: 1.2125295882945335]
	TIME [epoch: 3.65 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.281775524442087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.281775524442087 | validation: 0.8696785213419993]
	TIME [epoch: 3.65 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0236138215277402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0236138215277402 | validation: 0.7871359375317198]
	TIME [epoch: 3.66 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.881359950718976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.881359950718976 | validation: 0.7234537598148228]
	TIME [epoch: 3.65 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8372782243140868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8372782243140868 | validation: 0.6927105682660607]
	TIME [epoch: 3.65 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8003686496556094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8003686496556094 | validation: 0.700439624950779]
	TIME [epoch: 3.65 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7753001311837576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7753001311837576 | validation: 0.7112321001184845]
	TIME [epoch: 3.66 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7689175827177407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7689175827177407 | validation: 0.6825076677671862]
	TIME [epoch: 3.65 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7497656912977876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7497656912977876 | validation: 0.7154837007405975]
	TIME [epoch: 3.65 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7395078530658087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7395078530658087 | validation: 0.6487958014733988]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.727530870671414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.727530870671414 | validation: 0.7612605167803169]
	TIME [epoch: 3.68 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7381206532999637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7381206532999637 | validation: 0.6682248225739956]
	TIME [epoch: 3.66 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7603815702306159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7603815702306159 | validation: 0.880404568556688]
	TIME [epoch: 3.65 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.817393593699907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.817393593699907 | validation: 1.0242157106980354]
	TIME [epoch: 3.66 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.064641474446017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.064641474446017 | validation: 0.8110220166389127]
	TIME [epoch: 3.65 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9460131762678587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9460131762678587 | validation: 0.6816128559023814]
	TIME [epoch: 3.65 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.749989985068693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.749989985068693 | validation: 0.7635977103302287]
	TIME [epoch: 3.66 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8105216522033447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8105216522033447 | validation: 0.7974645503915658]
	TIME [epoch: 3.66 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9178387431749748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9178387431749748 | validation: 0.7491389436985806]
	TIME [epoch: 3.65 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7985567526620977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7985567526620977 | validation: 0.7648501702122985]
	TIME [epoch: 3.65 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7704641760884599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7704641760884599 | validation: 0.6542346635513132]
	TIME [epoch: 3.65 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7093556112984982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7093556112984982 | validation: 0.6929753537734996]
	TIME [epoch: 3.66 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6892665544056896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6892665544056896 | validation: 0.7191317839207773]
	TIME [epoch: 3.67 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7583553004602814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7583553004602814 | validation: 1.1543754576781777]
	TIME [epoch: 3.67 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1764038155253804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1764038155253804 | validation: 1.0230738470354208]
	TIME [epoch: 3.65 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0682434415494677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0682434415494677 | validation: 0.6878709651803852]
	TIME [epoch: 3.65 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7604659512494546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7604659512494546 | validation: 0.7225298664343045]
	TIME [epoch: 3.65 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8140447901581493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8140447901581493 | validation: 0.6922317179136072]
	TIME [epoch: 3.66 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7474076175252685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7474076175252685 | validation: 0.6635964156449845]
	TIME [epoch: 3.65 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7466168428178286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7466168428178286 | validation: 0.6808635526474707]
	TIME [epoch: 3.66 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7160126964587077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7160126964587077 | validation: 0.6768401151178415]
	TIME [epoch: 3.66 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6853077461781568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6853077461781568 | validation: 0.6412028954621076]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6928411290813868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6928411290813868 | validation: 0.71942749587646]
	TIME [epoch: 3.64 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6843841020790667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6843841020790667 | validation: 0.811755681336117]
	TIME [epoch: 3.65 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8189546064662935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8189546064662935 | validation: 0.9663177747332061]
	TIME [epoch: 3.66 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0912550727307766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0912550727307766 | validation: 0.7141589360240489]
	TIME [epoch: 3.66 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7519046946973845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7519046946973845 | validation: 0.6686215611188422]
	TIME [epoch: 48.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7230949547996406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7230949547996406 | validation: 0.6438402514644259]
	TIME [epoch: 7.94 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7065130228031911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7065130228031911 | validation: 0.6698184405186681]
	TIME [epoch: 7.95 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6788379398391676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6788379398391676 | validation: 0.74638164238908]
	TIME [epoch: 7.91 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7671460203133356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7671460203133356 | validation: 1.0071742360188114]
	TIME [epoch: 7.92 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0312322456072596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0312322456072596 | validation: 0.9659352246725679]
	TIME [epoch: 7.92 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9033353623675078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9033353623675078 | validation: 0.6423173020373154]
	TIME [epoch: 7.91 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6839137172273405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6839137172273405 | validation: 0.6149211209611928]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7126058307387573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7126058307387573 | validation: 0.6143475876058729]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6414223520760163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6414223520760163 | validation: 0.6364448282835339]
	TIME [epoch: 7.91 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.634693418779526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.634693418779526 | validation: 0.6126065937538739]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6706359955200253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6706359955200253 | validation: 0.8243628581439548]
	TIME [epoch: 7.91 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8225222699760781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8225222699760781 | validation: 0.8834384010289711]
	TIME [epoch: 7.89 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9625831116109733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9625831116109733 | validation: 0.7621628683188668]
	TIME [epoch: 7.91 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8007151679910725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8007151679910725 | validation: 0.688458260229117]
	TIME [epoch: 7.91 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7271085480228939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7271085480228939 | validation: 0.6423586881590446]
	TIME [epoch: 7.91 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6979572211691522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6979572211691522 | validation: 0.629941391540403]
	TIME [epoch: 7.89 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6562935161815817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6562935161815817 | validation: 0.655796401281675]
	TIME [epoch: 7.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6626008323120124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6626008323120124 | validation: 0.7028889369307523]
	TIME [epoch: 7.89 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7198294682785854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7198294682785854 | validation: 0.6562599773727187]
	TIME [epoch: 7.93 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7380553821777164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7380553821777164 | validation: 0.711513374383026]
	TIME [epoch: 7.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7367555173768066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7367555173768066 | validation: 0.6071234098249066]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6860419077715991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6860419077715991 | validation: 0.5874938509824713]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6055950300301853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6055950300301853 | validation: 0.5973720493707659]
	TIME [epoch: 7.92 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5890627648290739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5890627648290739 | validation: 0.5872032206156016]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6083788379201367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6083788379201367 | validation: 0.8461385643197001]
	TIME [epoch: 7.93 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7971492463609466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7971492463609466 | validation: 0.9846464566422622]
	TIME [epoch: 7.92 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0478565004343077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0478565004343077 | validation: 0.7102956949982145]
	TIME [epoch: 7.91 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8281882336689138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8281882336689138 | validation: 0.6878658479486975]
	TIME [epoch: 7.92 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7573469904395306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7573469904395306 | validation: 0.6975768903210879]
	TIME [epoch: 7.91 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7103787451966149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7103787451966149 | validation: 0.66218613943119]
	TIME [epoch: 7.95 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7617559994968296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7617559994968296 | validation: 0.6446442100194866]
	TIME [epoch: 7.91 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6320293125653149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6320293125653149 | validation: 0.657001103116553]
	TIME [epoch: 7.92 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6724695717272079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6724695717272079 | validation: 0.8380468102728398]
	TIME [epoch: 7.91 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8310586867510215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8310586867510215 | validation: 0.627905649832791]
	TIME [epoch: 7.92 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6599128193937708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6599128193937708 | validation: 0.5580681304016423]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.590934883843831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.590934883843831 | validation: 0.626093592073368]
	TIME [epoch: 7.93 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5952534760809817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5952534760809817 | validation: 0.6123587976203453]
	TIME [epoch: 7.91 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6414398208103772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6414398208103772 | validation: 0.8109802489474843]
	TIME [epoch: 7.91 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7608318060794791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7608318060794791 | validation: 0.8589994822871367]
	TIME [epoch: 7.89 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.894500201053098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.894500201053098 | validation: 0.6320726739469431]
	TIME [epoch: 7.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7498605277802937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7498605277802937 | validation: 0.6229325965331267]
	TIME [epoch: 7.91 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6811213668923961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6811213668923961 | validation: 0.6551673222782227]
	TIME [epoch: 7.92 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6559676209897671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6559676209897671 | validation: 0.6712992957583099]
	TIME [epoch: 7.91 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7333014535273179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7333014535273179 | validation: 0.8611756518766861]
	TIME [epoch: 7.91 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8672260533756465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8672260533756465 | validation: 0.5735519497423062]
	TIME [epoch: 7.91 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6338333929616262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6338333929616262 | validation: 0.560130847292972]
	TIME [epoch: 7.91 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5666293329884088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5666293329884088 | validation: 0.5626295256061422]
	TIME [epoch: 7.92 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5674755135147017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5674755135147017 | validation: 0.756364141340696]
	TIME [epoch: 7.91 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.706716378900017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.706716378900017 | validation: 0.936988253410484]
	TIME [epoch: 7.91 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9822281723308308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9822281723308308 | validation: 0.6173824834195929]
	TIME [epoch: 7.91 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6734613971286967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6734613971286967 | validation: 0.6116956400030473]
	TIME [epoch: 7.92 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.63916865251629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.63916865251629 | validation: 0.6076370731242197]
	TIME [epoch: 7.91 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6016915059090898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6016915059090898 | validation: 0.7121914637057513]
	TIME [epoch: 7.93 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7219695132190526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7219695132190526 | validation: 0.8957229107082496]
	TIME [epoch: 7.91 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8935519144055762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8935519144055762 | validation: 0.5726640041534221]
	TIME [epoch: 7.91 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6466700453348848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6466700453348848 | validation: 0.5780195647930061]
	TIME [epoch: 7.91 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5995110447849122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5995110447849122 | validation: 0.6437653982849283]
	TIME [epoch: 7.91 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6265080033347867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6265080033347867 | validation: 0.7344444432433609]
	TIME [epoch: 7.92 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7379078044646855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7379078044646855 | validation: 0.7684965013035587]
	TIME [epoch: 7.93 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7875565971070495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7875565971070495 | validation: 0.6065104057092938]
	TIME [epoch: 7.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.653276374314266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.653276374314266 | validation: 0.6069050599899977]
	TIME [epoch: 7.91 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6110734485379684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6110734485379684 | validation: 0.5745244511807954]
	TIME [epoch: 7.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5853921301819581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5853921301819581 | validation: 0.6794674889394746]
	TIME [epoch: 7.92 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6703711265175069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6703711265175069 | validation: 0.8001892273925062]
	TIME [epoch: 7.92 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7938437838870275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7938437838870275 | validation: 0.5902316216432871]
	TIME [epoch: 7.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6349930558703697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6349930558703697 | validation: 0.5187341043131015]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5417011743533207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5417011743533207 | validation: 0.5288364439515422]
	TIME [epoch: 7.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5566984194728454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5566984194728454 | validation: 0.8173570342300863]
	TIME [epoch: 7.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7426923229030902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7426923229030902 | validation: 0.8508530228650978]
	TIME [epoch: 7.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8788722997961754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8788722997961754 | validation: 0.6115576038046914]
	TIME [epoch: 7.92 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6455655379248705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6455655379248705 | validation: 0.6183966548137934]
	TIME [epoch: 7.91 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6445268516696843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6445268516696843 | validation: 0.5615975058307188]
	TIME [epoch: 7.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5802100258657384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5802100258657384 | validation: 0.5648268016047869]
	TIME [epoch: 7.89 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5983753612758044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5983753612758044 | validation: 0.8120919043792777]
	TIME [epoch: 7.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7612852595910061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7612852595910061 | validation: 0.6000058457956021]
	TIME [epoch: 7.91 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6790892080648367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6790892080648367 | validation: 0.5590536471137434]
	TIME [epoch: 7.93 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5511469937393834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5511469937393834 | validation: 0.4919554565340966]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5264260809803207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5264260809803207 | validation: 0.5060049743955186]
	TIME [epoch: 7.92 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5043339826655121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5043339826655121 | validation: 0.5117656547222252]
	TIME [epoch: 7.92 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5109277964392009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5109277964392009 | validation: 0.6065825583824298]
	TIME [epoch: 7.92 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.578627770330062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.578627770330062 | validation: 0.8008427251083557]
	TIME [epoch: 7.95 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8691023291418253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8691023291418253 | validation: 0.6016533590032966]
	TIME [epoch: 7.92 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6265056898517282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6265056898517282 | validation: 0.5450190681838261]
	TIME [epoch: 7.92 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5246318236186958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5246318236186958 | validation: 0.5352753160919699]
	TIME [epoch: 7.91 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5637403788601429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5637403788601429 | validation: 0.6434187878958513]
	TIME [epoch: 7.92 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5866393966987469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5866393966987469 | validation: 0.5674503135893539]
	TIME [epoch: 7.95 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6513390744246111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6513390744246111 | validation: 0.6326218519764325]
	TIME [epoch: 7.93 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6384793125922412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6384793125922412 | validation: 0.5641249575715017]
	TIME [epoch: 7.92 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6002951296783361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6002951296783361 | validation: 0.6538300091874838]
	TIME [epoch: 7.92 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6789442308621634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6789442308621634 | validation: 0.499059831465539]
	TIME [epoch: 7.93 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5375919728665649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5375919728665649 | validation: 0.5024621596976487]
	TIME [epoch: 7.92 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48562085784842324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48562085784842324 | validation: 0.5995374883977495]
	TIME [epoch: 7.96 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6004819798152355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6004819798152355 | validation: 0.719670293031815]
	TIME [epoch: 7.92 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7135569758447629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7135569758447629 | validation: 0.6647650118865491]
	TIME [epoch: 7.92 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.705215800224718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.705215800224718 | validation: 0.5744503806621564]
	TIME [epoch: 7.93 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6093534906739392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6093534906739392 | validation: 0.48246765642861916]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5301824585066575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5301824585066575 | validation: 0.550393373562325]
	TIME [epoch: 7.91 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5148369243920555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5148369243920555 | validation: 0.4620949720617227]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49938754706412875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49938754706412875 | validation: 0.574000945991034]
	TIME [epoch: 7.91 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5494820045360412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5494820045360412 | validation: 0.5345738374077239]
	TIME [epoch: 7.93 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.572144151555909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.572144151555909 | validation: 0.5978011996584771]
	TIME [epoch: 7.94 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5830154458280593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5830154458280593 | validation: 0.6413163117508449]
	TIME [epoch: 7.93 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5977651559431534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5977651559431534 | validation: 0.6309526049611089]
	TIME [epoch: 7.95 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7103222400712607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7103222400712607 | validation: 0.5388486225360423]
	TIME [epoch: 7.93 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5333789842085189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5333789842085189 | validation: 0.45519497843482654]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.462496429282897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.462496429282897 | validation: 0.57296709703669]
	TIME [epoch: 7.91 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5365477590950386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5365477590950386 | validation: 0.794246203100884]
	TIME [epoch: 7.91 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.767726626925084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.767726626925084 | validation: 0.6752134945851762]
	TIME [epoch: 7.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7147413694974648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7147413694974648 | validation: 0.6019685394044052]
	TIME [epoch: 7.93 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6740294669981916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6740294669981916 | validation: 0.590553583558257]
	TIME [epoch: 7.89 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5805046144844316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5805046144844316 | validation: 0.5044554578529408]
	TIME [epoch: 7.91 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5166301871232166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5166301871232166 | validation: 0.5584039325666673]
	TIME [epoch: 7.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5633635520969249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5633635520969249 | validation: 0.7047875897622408]
	TIME [epoch: 7.89 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6511667075745181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6511667075745181 | validation: 0.5849593089394122]
	TIME [epoch: 7.94 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5401453371437225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5401453371437225 | validation: 0.5016912029005292]
	TIME [epoch: 7.89 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4969625580337691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4969625580337691 | validation: 0.4547072671074639]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4427178227862924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4427178227862924 | validation: 0.4478780009990093]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4186865117391605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4186865117391605 | validation: 0.440281690523618]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42230929216352714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42230929216352714 | validation: 0.504125645087175]
	TIME [epoch: 7.94 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4461402158599182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4461402158599182 | validation: 0.5115519984553174]
	TIME [epoch: 7.92 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6104839650503955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6104839650503955 | validation: 0.5854227924671863]
	TIME [epoch: 7.91 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5388480311993228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5388480311993228 | validation: 0.43658273885807025]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4418023244457853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4418023244457853 | validation: 0.4900011739526276]
	TIME [epoch: 7.92 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49257248031223055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49257248031223055 | validation: 0.6988549557941882]
	TIME [epoch: 7.93 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.626002740861016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.626002740861016 | validation: 0.529513538010831]
	TIME [epoch: 7.92 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5792505296179453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5792505296179453 | validation: 0.43670788031382557]
	TIME [epoch: 7.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45317225390844984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45317225390844984 | validation: 0.5176085880025987]
	TIME [epoch: 7.91 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4459042850341794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4459042850341794 | validation: 0.4825545860142579]
	TIME [epoch: 7.91 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4975499543086974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4975499543086974 | validation: 0.568293779399666]
	TIME [epoch: 7.93 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4873316429113339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4873316429113339 | validation: 0.46427226477708267]
	TIME [epoch: 7.91 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5011569461071923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5011569461071923 | validation: 0.6053191177759079]
	TIME [epoch: 7.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5852504488934985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5852504488934985 | validation: 0.7304313447736984]
	TIME [epoch: 7.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6634319089322424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6634319089322424 | validation: 0.5179977087852315]
	TIME [epoch: 7.91 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5155498711404495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5155498711404495 | validation: 0.4332774073158623]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46174438748401037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46174438748401037 | validation: 0.40999425730323424]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3687584450426596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3687584450426596 | validation: 0.4342294321488018]
	TIME [epoch: 7.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4029726018259337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4029726018259337 | validation: 0.5530863201985298]
	TIME [epoch: 7.91 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4796228567350774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4796228567350774 | validation: 0.4744451285527568]
	TIME [epoch: 7.91 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4860862544444578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4860862544444578 | validation: 0.4590411069035675]
	TIME [epoch: 7.91 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4183587290109548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4183587290109548 | validation: 0.44779239824481554]
	TIME [epoch: 7.92 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3962464932962892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3962464932962892 | validation: 0.4473639790995676]
	TIME [epoch: 7.92 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44584665057585254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44584665057585254 | validation: 0.48339338892246336]
	TIME [epoch: 7.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4163073699092421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4163073699092421 | validation: 0.39968594581331784]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4044664278542074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4044664278542074 | validation: 0.5351518281015191]
	TIME [epoch: 7.88 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42794591431296186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42794591431296186 | validation: 0.3862081821500641]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3999843501961085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3999843501961085 | validation: 0.3716936396106224]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34534409628317575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34534409628317575 | validation: 0.40328824092596954]
	TIME [epoch: 7.88 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36343440609090644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36343440609090644 | validation: 0.4940709018610857]
	TIME [epoch: 7.89 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5155753486850534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5155753486850534 | validation: 0.6598806149341992]
	TIME [epoch: 7.88 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6600739744809223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6600739744809223 | validation: 0.4302199733271815]
	TIME [epoch: 7.88 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4868015245196905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4868015245196905 | validation: 0.3352771823694338]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3033329942638867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3033329942638867 | validation: 0.39651451968712254]
	TIME [epoch: 7.89 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36025940260839023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36025940260839023 | validation: 0.4155384188203852]
	TIME [epoch: 7.89 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3895310972819636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3895310972819636 | validation: 0.45499039447934386]
	TIME [epoch: 7.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43182681928289657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43182681928289657 | validation: 0.3883792922440173]
	TIME [epoch: 7.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3393756428004107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3393756428004107 | validation: 0.3304989404370393]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32996152817964186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32996152817964186 | validation: 0.48530337115550926]
	TIME [epoch: 7.91 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38498773034243144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38498773034243144 | validation: 0.4312014445322583]
	TIME [epoch: 7.92 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5040362384992012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5040362384992012 | validation: 0.44492829746100715]
	TIME [epoch: 7.93 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.385341340068549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.385341340068549 | validation: 0.32019256684034764]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27994911696915453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27994911696915453 | validation: 0.34502883519384037]
	TIME [epoch: 7.91 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.313061580034208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.313061580034208 | validation: 0.5153286632050647]
	TIME [epoch: 7.93 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.502535704262748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.502535704262748 | validation: 0.42654978201506194]
	TIME [epoch: 7.92 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4895336806895665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4895336806895665 | validation: 0.3931628331336978]
	TIME [epoch: 7.91 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32227150730337073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32227150730337073 | validation: 0.4775468060612449]
	TIME [epoch: 7.91 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45448746734524903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45448746734524903 | validation: 0.44732944562870014]
	TIME [epoch: 7.91 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4517129442727175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4517129442727175 | validation: 0.29406155493452263]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2608422583673713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2608422583673713 | validation: 0.34715329986815635]
	TIME [epoch: 7.91 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29195186230488157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29195186230488157 | validation: 0.3775839633354575]
	TIME [epoch: 7.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35793908141835323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35793908141835323 | validation: 0.3807568101590633]
	TIME [epoch: 7.91 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3768861434706501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3768861434706501 | validation: 0.3458040310237457]
	TIME [epoch: 7.89 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30908644909548777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30908644909548777 | validation: 0.5431382241799915]
	TIME [epoch: 7.92 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4344510334623405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4344510334623405 | validation: 0.5475552605495141]
	TIME [epoch: 7.91 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6188749219717963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6188749219717963 | validation: 0.5835023673487831]
	TIME [epoch: 7.91 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6073954246421253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6073954246421253 | validation: 0.47913725265193713]
	TIME [epoch: 7.92 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5509079331511256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5509079331511256 | validation: 0.3159993343296619]
	TIME [epoch: 7.89 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2764864935981747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2764864935981747 | validation: 0.4556060840878695]
	TIME [epoch: 7.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.351269315981029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.351269315981029 | validation: 0.39150293904611855]
	TIME [epoch: 7.92 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38502497766518207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38502497766518207 | validation: 0.34338710574400183]
	TIME [epoch: 7.91 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30312188617608266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30312188617608266 | validation: 0.2882066892751025]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26475341321175433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26475341321175433 | validation: 0.35534758238485226]
	TIME [epoch: 7.89 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3331602939326622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3331602939326622 | validation: 0.467698821891368]
	TIME [epoch: 7.91 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38615457464421843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38615457464421843 | validation: 0.32482901908503076]
	TIME [epoch: 7.93 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3096884287737619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3096884287737619 | validation: 0.2897814953144573]
	TIME [epoch: 7.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23440530557941214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23440530557941214 | validation: 0.3065368382676915]
	TIME [epoch: 7.89 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24919019361514738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24919019361514738 | validation: 0.3717329544040491]
	TIME [epoch: 7.91 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3828157001377156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3828157001377156 | validation: 0.4511047680677158]
	TIME [epoch: 7.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.362596280774234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.362596280774234 | validation: 0.30811876251055037]
	TIME [epoch: 7.93 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32165316236317326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32165316236317326 | validation: 0.39760087709124853]
	TIME [epoch: 7.91 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30364325257036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30364325257036 | validation: 0.31596413030156784]
	TIME [epoch: 7.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.334516102141787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.334516102141787 | validation: 0.30768474812719965]
	TIME [epoch: 7.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27109400526418337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27109400526418337 | validation: 0.3699894805835302]
	TIME [epoch: 7.91 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2936482044834222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2936482044834222 | validation: 0.4322124211391513]
	TIME [epoch: 7.91 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42110502624459484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42110502624459484 | validation: 0.3603960756143057]
	TIME [epoch: 7.92 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33780293467497147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33780293467497147 | validation: 0.3059159198281862]
	TIME [epoch: 7.89 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2892146583266873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2892146583266873 | validation: 0.2904160750254346]
	TIME [epoch: 7.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23850313073522128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23850313073522128 | validation: 0.3610095072607563]
	TIME [epoch: 7.89 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2686182213589949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2686182213589949 | validation: 0.3392523336850461]
	TIME [epoch: 7.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3840217409975998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3840217409975998 | validation: 0.3961615145023898]
	TIME [epoch: 7.92 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2962258070950039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2962258070950039 | validation: 0.3007015510332532]
	TIME [epoch: 7.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30111260236804294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30111260236804294 | validation: 0.48002117366089286]
	TIME [epoch: 7.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3765811625574509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3765811625574509 | validation: 0.4823209028464504]
	TIME [epoch: 7.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49216257585515144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49216257585515144 | validation: 0.35103778782560635]
	TIME [epoch: 7.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37612536619139575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37612536619139575 | validation: 0.28624811189866173]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2342326273182826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2342326273182826 | validation: 0.33389881408772226]
	TIME [epoch: 7.91 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2539828375338385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2539828375338385 | validation: 0.2947282230586513]
	TIME [epoch: 7.89 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23479096302853517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23479096302853517 | validation: 0.35213762009665894]
	TIME [epoch: 7.89 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3136578483479059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3136578483479059 | validation: 0.34416324325738135]
	TIME [epoch: 7.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3162773114319883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162773114319883 | validation: 0.3200273421186997]
	TIME [epoch: 7.91 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24542709364304258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24542709364304258 | validation: 0.27301567772963653]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2634862956076039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2634862956076039 | validation: 0.379361497009588]
	TIME [epoch: 7.91 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28214116401804573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28214116401804573 | validation: 0.3550783969191661]
	TIME [epoch: 7.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38151696259092005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38151696259092005 | validation: 0.41386140930894516]
	TIME [epoch: 7.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3087792250677587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3087792250677587 | validation: 0.2668744975404743]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26405190169398096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26405190169398096 | validation: 0.2851514250294172]
	TIME [epoch: 7.96 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26245374879508027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26245374879508027 | validation: 0.3712298688443257]
	TIME [epoch: 7.94 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29038892625336304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29038892625336304 | validation: 0.35540734265699936]
	TIME [epoch: 7.95 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3546943226644173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3546943226644173 | validation: 0.2656639661497786]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2456071189175004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2456071189175004 | validation: 0.3781117005737859]
	TIME [epoch: 7.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2946927969393099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2946927969393099 | validation: 0.4275231448975902]
	TIME [epoch: 7.91 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3880313006907079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3880313006907079 | validation: 0.2959660288405063]
	TIME [epoch: 7.91 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25078184983079604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25078184983079604 | validation: 0.23742831266166808]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21025382792996408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21025382792996408 | validation: 0.3057919520095163]
	TIME [epoch: 7.91 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23688937140990127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23688937140990127 | validation: 0.34475539145096556]
	TIME [epoch: 7.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30811453372117226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30811453372117226 | validation: 0.29048658910099595]
	TIME [epoch: 7.91 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26530768047578795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26530768047578795 | validation: 0.271326330324686]
	TIME [epoch: 7.92 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19630232460304342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19630232460304342 | validation: 0.24038213974300918]
	TIME [epoch: 7.91 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23629467201979595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23629467201979595 | validation: 0.5019255026219733]
	TIME [epoch: 7.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3601439819345808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3601439819345808 | validation: 0.39318851741862043]
	TIME [epoch: 7.91 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3793604401519025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3793604401519025 | validation: 0.2705101908923637]
	TIME [epoch: 7.91 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24496562280565223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24496562280565223 | validation: 0.28143000755726116]
	TIME [epoch: 7.92 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21301643164236414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21301643164236414 | validation: 0.3776538935662847]
	TIME [epoch: 7.89 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3554603018446367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3554603018446367 | validation: 0.35302627094514116]
	TIME [epoch: 7.88 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3110540224012733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3110540224012733 | validation: 0.28774974351137667]
	TIME [epoch: 7.89 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23195089761293705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23195089761293705 | validation: 0.21786553086798566]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19856406660797696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19856406660797696 | validation: 0.22952877907324065]
	TIME [epoch: 7.92 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18280016240514044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18280016240514044 | validation: 0.22369528557962914]
	TIME [epoch: 7.93 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18207605366178722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18207605366178722 | validation: 0.2597844265335272]
	TIME [epoch: 7.92 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2504431943265413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2504431943265413 | validation: 0.4165844377870386]
	TIME [epoch: 7.92 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3364743269941404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3364743269941404 | validation: 0.4289168778435133]
	TIME [epoch: 7.91 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49057116394770234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49057116394770234 | validation: 0.5623113115045341]
	TIME [epoch: 7.91 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4920440159987195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4920440159987195 | validation: 0.331052225048608]
	TIME [epoch: 7.93 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2907834316737742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2907834316737742 | validation: 0.27314784791377705]
	TIME [epoch: 7.91 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26986887189553177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26986887189553177 | validation: 0.3354920558278174]
	TIME [epoch: 7.92 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2373169605157294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2373169605157294 | validation: 0.21784563342039887]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2393489320391471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2393489320391471 | validation: 0.23997390826511866]
	TIME [epoch: 7.91 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19554322633561036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19554322633561036 | validation: 0.24852135831355598]
	TIME [epoch: 7.95 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2057822499710538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2057822499710538 | validation: 0.27997817318949164]
	TIME [epoch: 7.91 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24118025568341758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24118025568341758 | validation: 0.24971870449805766]
	TIME [epoch: 7.93 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22546920946861085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22546920946861085 | validation: 0.31034213151710177]
	TIME [epoch: 7.92 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24401279834799774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24401279834799774 | validation: 0.3061327957748848]
	TIME [epoch: 7.93 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2870543111230053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2870543111230053 | validation: 0.3701945880307368]
	TIME [epoch: 7.92 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27366242644935695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27366242644935695 | validation: 0.21757647532755042]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21167471289403267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21167471289403267 | validation: 0.24213117525313593]
	TIME [epoch: 7.87 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17576089221487487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17576089221487487 | validation: 0.2247057284199824]
	TIME [epoch: 7.89 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21627048731249993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21627048731249993 | validation: 0.2840101691298268]
	TIME [epoch: 7.93 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2344903315803191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2344903315803191 | validation: 0.27971788687216403]
	TIME [epoch: 7.92 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2538510556711877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2538510556711877 | validation: 0.27789124571872614]
	TIME [epoch: 7.93 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19507763537819434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19507763537819434 | validation: 0.2228277475865336]
	TIME [epoch: 7.92 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23017157666032184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23017157666032184 | validation: 0.24046178122765458]
	TIME [epoch: 7.92 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17641557663442542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17641557663442542 | validation: 0.21090365815225298]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2068118090170671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2068118090170671 | validation: 0.3118169723872424]
	TIME [epoch: 7.93 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23344940453097102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23344940453097102 | validation: 0.3029806316783533]
	TIME [epoch: 7.94 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30516926598326194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30516926598326194 | validation: 0.27262917903256834]
	TIME [epoch: 7.92 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22633011351704418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22633011351704418 | validation: 0.2679813722654271]
	TIME [epoch: 7.92 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2137946914845461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2137946914845461 | validation: 0.2748405522228176]
	TIME [epoch: 7.93 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23668153332125005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23668153332125005 | validation: 0.25641755650209713]
	TIME [epoch: 7.92 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21696382796685337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21696382796685337 | validation: 0.23964981489313023]
	TIME [epoch: 7.93 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20545487681938956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20545487681938956 | validation: 0.2258610489271284]
	TIME [epoch: 7.92 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17079933070954922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17079933070954922 | validation: 0.17850622549595926]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18343654887323574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18343654887323574 | validation: 0.40274365769980136]
	TIME [epoch: 7.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30395494358488195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30395494358488195 | validation: 0.4435584170134769]
	TIME [epoch: 7.92 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48173404996757796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48173404996757796 | validation: 0.33503487446039076]
	TIME [epoch: 7.91 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3180779395256007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3180779395256007 | validation: 0.38523095570842114]
	TIME [epoch: 7.94 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35348098856533283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35348098856533283 | validation: 0.19925438005528376]
	TIME [epoch: 7.91 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17771068829432377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17771068829432377 | validation: 0.2165383576860308]
	TIME [epoch: 7.91 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17022652164504545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17022652164504545 | validation: 0.21947613708785238]
	TIME [epoch: 7.91 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20513244260091776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20513244260091776 | validation: 0.25209790284078776]
	TIME [epoch: 7.91 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17620483852397206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17620483852397206 | validation: 0.17891944583920197]
	TIME [epoch: 7.93 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17390591780646966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17390591780646966 | validation: 0.28644356560982986]
	TIME [epoch: 7.91 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19591420321258515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19591420321258515 | validation: 0.23729173007436374]
	TIME [epoch: 7.89 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25801672299508094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25801672299508094 | validation: 0.21316690895561888]
	TIME [epoch: 7.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1651819460936575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1651819460936575 | validation: 0.16024656159970962]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15617472636045096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15617472636045096 | validation: 0.25062397669413267]
	TIME [epoch: 7.92 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18443565157810754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18443565157810754 | validation: 0.2394658370596483]
	TIME [epoch: 7.93 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2647410566087986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2647410566087986 | validation: 0.1993807102680884]
	TIME [epoch: 7.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16987179487424683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16987179487424683 | validation: 0.18759308228085012]
	TIME [epoch: 7.91 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14807051811253144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14807051811253144 | validation: 0.17874255270865855]
	TIME [epoch: 7.91 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14913047707227964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14913047707227964 | validation: 0.22104353427861573]
	TIME [epoch: 7.91 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.186561754407795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.186561754407795 | validation: 0.26634553277462425]
	TIME [epoch: 7.95 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2132201919501576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2132201919501576 | validation: 0.18765926850409043]
	TIME [epoch: 7.92 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20622633229442644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20622633229442644 | validation: 0.5943369295793616]
	TIME [epoch: 7.92 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4070560800624227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4070560800624227 | validation: 0.2629596359238217]
	TIME [epoch: 7.91 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2757709225740203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2757709225740203 | validation: 0.16817476002367848]
	TIME [epoch: 7.92 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13477802754287713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13477802754287713 | validation: 0.23652473573185598]
	TIME [epoch: 7.92 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17037463678158588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17037463678158588 | validation: 0.23779321811294302]
	TIME [epoch: 7.93 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2386843815329075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2386843815329075 | validation: 0.18627120370115846]
	TIME [epoch: 7.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16151705311428557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16151705311428557 | validation: 0.37689160768945035]
	TIME [epoch: 7.91 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25876924889493325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25876924889493325 | validation: 0.2721360050151744]
	TIME [epoch: 7.92 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31897066930892604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31897066930892604 | validation: 0.23682290107866566]
	TIME [epoch: 57.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2268298111472371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2268298111472371 | validation: 0.26616149256695854]
	TIME [epoch: 17 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19273723834068307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19273723834068307 | validation: 0.24552803192388734]
	TIME [epoch: 16.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23720905965692204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23720905965692204 | validation: 0.29984603879570493]
	TIME [epoch: 16.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19927674778540913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19927674778540913 | validation: 0.16493380735279586]
	TIME [epoch: 16.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16901802788366677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16901802788366677 | validation: 0.17822290157928278]
	TIME [epoch: 16.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13768025042089962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13768025042089962 | validation: 0.1948692950892802]
	TIME [epoch: 16.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16863326649385282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16863326649385282 | validation: 0.26606836631139047]
	TIME [epoch: 17 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22267084552364508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22267084552364508 | validation: 0.17718467219730658]
	TIME [epoch: 16.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18731745673099567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18731745673099567 | validation: 0.1753077261079585]
	TIME [epoch: 16.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14318586907267158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14318586907267158 | validation: 0.16416243300789365]
	TIME [epoch: 17 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14890273260172546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14890273260172546 | validation: 0.29110540094927834]
	TIME [epoch: 16.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18485757244573023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18485757244573023 | validation: 0.1952674652651864]
	TIME [epoch: 16.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23313908335561223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23313908335561223 | validation: 0.2512402212107484]
	TIME [epoch: 16.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17337468415902774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17337468415902774 | validation: 0.21313174406408333]
	TIME [epoch: 16.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2146583318047526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2146583318047526 | validation: 0.21154003028684626]
	TIME [epoch: 16.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17527059257634311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17527059257634311 | validation: 0.1527346540135477]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1390911277053972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1390911277053972 | validation: 0.2028167717502056]
	TIME [epoch: 16.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14393448233298617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14393448233298617 | validation: 0.1727035645672125]
	TIME [epoch: 16.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20956075086815684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20956075086815684 | validation: 0.25275014271077395]
	TIME [epoch: 16.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17200576381044844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17200576381044844 | validation: 0.1465225970956497]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17641173513564087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17641173513564087 | validation: 0.21019262768518396]
	TIME [epoch: 16.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16311248484519333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16311248484519333 | validation: 0.20977521468986457]
	TIME [epoch: 16.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2044437818936655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2044437818936655 | validation: 0.19726046826483498]
	TIME [epoch: 16.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1671013384826528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1671013384826528 | validation: 0.13727821771932722]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1281069096863904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1281069096863904 | validation: 0.23579625309452937]
	TIME [epoch: 16.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14464400270358924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14464400270358924 | validation: 0.19962302284023736]
	TIME [epoch: 16.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24643319809976225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24643319809976225 | validation: 0.3046178625758027]
	TIME [epoch: 17 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19251720876640527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19251720876640527 | validation: 0.17469431863364285]
	TIME [epoch: 16.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16941320062721338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16941320062721338 | validation: 0.17410948336139453]
	TIME [epoch: 16.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1351470210333333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1351470210333333 | validation: 0.22343459595128126]
	TIME [epoch: 17 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18341195528528084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18341195528528084 | validation: 0.3144094527888233]
	TIME [epoch: 16.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2759898256985679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2759898256985679 | validation: 0.14095480101960442]
	TIME [epoch: 16.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16207718176209723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16207718176209723 | validation: 0.28693591853046546]
	TIME [epoch: 17 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1586265630130628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1586265630130628 | validation: 0.13772371625303623]
	TIME [epoch: 16.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18170782848650752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18170782848650752 | validation: 0.26125483978414116]
	TIME [epoch: 16.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16568594008442866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16568594008442866 | validation: 0.14379512349654097]
	TIME [epoch: 16.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1472229612742126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1472229612742126 | validation: 0.16413292842216945]
	TIME [epoch: 16.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12342900624269255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12342900624269255 | validation: 0.11779154083137283]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_539.pth
	Model improved!!!
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13026609641085865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13026609641085865 | validation: 0.2007105152338327]
	TIME [epoch: 17 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1417388486450556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1417388486450556 | validation: 0.17153525401077374]
	TIME [epoch: 16.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21067450923064804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21067450923064804 | validation: 0.199126519958445]
	TIME [epoch: 17 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13906153116583858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13906153116583858 | validation: 0.1487575021768377]
	TIME [epoch: 17 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15003240271250953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15003240271250953 | validation: 0.12576678131262406]
	TIME [epoch: 17 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11148523558029458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11148523558029458 | validation: 0.14527103412914585]
	TIME [epoch: 17 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11117591581947188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11117591581947188 | validation: 0.11525594121569449]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17640801659351632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17640801659351632 | validation: 0.4457864123560164]
	TIME [epoch: 16.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3037445820662483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3037445820662483 | validation: 0.21990163765263004]
	TIME [epoch: 16.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24102078436437008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24102078436437008 | validation: 0.18801527049719458]
	TIME [epoch: 16.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1366105134228895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1366105134228895 | validation: 0.4150375356282421]
	TIME [epoch: 16.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35157335499025677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35157335499025677 | validation: 0.15452139382789365]
	TIME [epoch: 16.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18425584081430635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18425584081430635 | validation: 0.14866090437305554]
	TIME [epoch: 16.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11437111922316802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11437111922316802 | validation: 0.10692616310598871]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11340280903515351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11340280903515351 | validation: 0.23227783316863548]
	TIME [epoch: 16.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13479166083538235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13479166083538235 | validation: 0.12013966494967732]
	TIME [epoch: 16.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16159826268274685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16159826268274685 | validation: 0.22206416046399582]
	TIME [epoch: 16.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13343399123127533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13343399123127533 | validation: 0.11302758954054802]
	TIME [epoch: 16.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1312840280311464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1312840280311464 | validation: 0.14656872630340975]
	TIME [epoch: 16.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11113125085665393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11113125085665393 | validation: 0.10212992822579679]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10304021417853758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10304021417853758 | validation: 0.16401935363467068]
	TIME [epoch: 16.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1552826850768514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1552826850768514 | validation: 0.16663911843492074]
	TIME [epoch: 16.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16142144324303032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16142144324303032 | validation: 0.15479867838072717]
	TIME [epoch: 17 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12306546351738823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12306546351738823 | validation: 0.09938445470309604]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_563.pth
	Model improved!!!
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1436632575427935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1436632575427935 | validation: 0.2607742807348034]
	TIME [epoch: 16.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16596663575803555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16596663575803555 | validation: 0.12882376656072264]
	TIME [epoch: 16.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17659865508622852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17659865508622852 | validation: 0.2630078679457099]
	TIME [epoch: 16.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13445533315606903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13445533315606903 | validation: 0.09418143890297972]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11282199167734229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11282199167734229 | validation: 0.15433347622923801]
	TIME [epoch: 16.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10474086425889939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10474086425889939 | validation: 0.09464726900871885]
	TIME [epoch: 17 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1015394885211747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1015394885211747 | validation: 0.18186971717708117]
	TIME [epoch: 16.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12094187832407659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12094187832407659 | validation: 0.14518674564517928]
	TIME [epoch: 16.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19772034580001305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19772034580001305 | validation: 0.2401760135098562]
	TIME [epoch: 16.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2094714862398505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2094714862398505 | validation: 0.1118362974609525]
	TIME [epoch: 16.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11843798761379186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11843798761379186 | validation: 0.09672846207388333]
	TIME [epoch: 16.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09714421326697341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09714421326697341 | validation: 0.13571122953075063]
	TIME [epoch: 17 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10238932056649404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10238932056649404 | validation: 0.10933702545855986]
	TIME [epoch: 16.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10512482070531229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10512482070531229 | validation: 0.2167728569772189]
	TIME [epoch: 16.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13930603152080465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13930603152080465 | validation: 0.13946942141459445]
	TIME [epoch: 16.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25044086837165563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25044086837165563 | validation: 0.4092182830474297]
	TIME [epoch: 16.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2609821631679998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2609821631679998 | validation: 0.13330420614823227]
	TIME [epoch: 16.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1383455519350344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1383455519350344 | validation: 0.09673253833821675]
	TIME [epoch: 16.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1466168440850529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1466168440850529 | validation: 0.2464483969778058]
	TIME [epoch: 16.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14579522611821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14579522611821 | validation: 0.0814670236860086]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10418631011327648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10418631011327648 | validation: 0.12130627839512674]
	TIME [epoch: 16.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09162922842328419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09162922842328419 | validation: 0.08922060944589126]
	TIME [epoch: 16.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08971169063321505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08971169063321505 | validation: 0.13195602663551917]
	TIME [epoch: 16.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09981029081683815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09981029081683815 | validation: 0.09164012576628716]
	TIME [epoch: 16.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1326078111089309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1326078111089309 | validation: 0.3668908071032307]
	TIME [epoch: 16.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2128123072412206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2128123072412206 | validation: 0.10693309611512586]
	TIME [epoch: 16.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17019530418248274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17019530418248274 | validation: 0.16224271760139042]
	TIME [epoch: 16.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09932365557848241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09932365557848241 | validation: 0.10707169385216529]
	TIME [epoch: 16.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09460703034011914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09460703034011914 | validation: 0.08383195079541338]
	TIME [epoch: 16.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0911974972870188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0911974972870188 | validation: 0.1679199334724582]
	TIME [epoch: 16.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11513607913063084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11513607913063084 | validation: 0.10062184787654589]
	TIME [epoch: 16.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14530653802531446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14530653802531446 | validation: 0.29693380595847757]
	TIME [epoch: 16.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16838635330439033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16838635330439033 | validation: 0.07760154584394617]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11792518359179528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11792518359179528 | validation: 0.1428682905969971]
	TIME [epoch: 16.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08830920590738592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08830920590738592 | validation: 0.09096116552710758]
	TIME [epoch: 17 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09171753227698293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09171753227698293 | validation: 0.09390542475345057]
	TIME [epoch: 17 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08933283941854332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08933283941854332 | validation: 0.1081482935566009]
	TIME [epoch: 17 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09231570233331318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09231570233331318 | validation: 0.13809974766980987]
	TIME [epoch: 16.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1223933626076266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1223933626076266 | validation: 0.1326759889998816]
	TIME [epoch: 17 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16504299719427912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16504299719427912 | validation: 0.2811053996754524]
	TIME [epoch: 17 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2003079752102848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2003079752102848 | validation: 0.10736191683366476]
	TIME [epoch: 16.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12031015747702047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12031015747702047 | validation: 0.2558648881440741]
	TIME [epoch: 16.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13185065076927055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13185065076927055 | validation: 0.07617681902633532]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13161166717498046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13161166717498046 | validation: 0.139043964689725]
	TIME [epoch: 17 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10130155079732354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10130155079732354 | validation: 0.06963964271738524]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07754627765051683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07754627765051683 | validation: 0.10220367022004262]
	TIME [epoch: 16.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10124737125941398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10124737125941398 | validation: 0.1904112121065775]
	TIME [epoch: 16.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14856661094739243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14856661094739243 | validation: 0.11244736734619497]
	TIME [epoch: 17 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14145474006610737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14145474006610737 | validation: 0.15197763552610632]
	TIME [epoch: 16.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09519738337884671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09519738337884671 | validation: 0.06694010959977119]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11200718895561891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11200718895561891 | validation: 0.2720282800902842]
	TIME [epoch: 17 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14295314416669955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14295314416669955 | validation: 0.06482915315852769]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09744884572781264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09744884572781264 | validation: 0.17895421308316373]
	TIME [epoch: 16.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09857420350410517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09857420350410517 | validation: 0.06860301831447513]
	TIME [epoch: 16.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09859689271495135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09859689271495135 | validation: 0.1920815225823369]
	TIME [epoch: 16.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10695365760366393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10695365760366393 | validation: 0.08208961375180676]
	TIME [epoch: 16.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11489148617683025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11489148617683025 | validation: 0.15850464954864654]
	TIME [epoch: 16.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12356522430243265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12356522430243265 | validation: 0.13088443154749405]
	TIME [epoch: 16.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11597737741997566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11597737741997566 | validation: 0.10543880448314016]
	TIME [epoch: 16.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09016541988449438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09016541988449438 | validation: 0.06525804713202615]
	TIME [epoch: 16.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07830513643341819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07830513643341819 | validation: 0.16598536717641618]
	TIME [epoch: 16.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09494488270292645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09494488270292645 | validation: 0.07935509164234666]
	TIME [epoch: 16.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1381537458609605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1381537458609605 | validation: 0.3992030326061933]
	TIME [epoch: 16.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19150912058431732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19150912058431732 | validation: 0.05394241216578667]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09199901249441535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09199901249441535 | validation: 0.09006492729257265]
	TIME [epoch: 17 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0718143207387405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0718143207387405 | validation: 0.08367205044015935]
	TIME [epoch: 16.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07771366138073853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07771366138073853 | validation: 0.10415264938837701]
	TIME [epoch: 16.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10549297172357276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10549297172357276 | validation: 0.20872998091195855]
	TIME [epoch: 16.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16855086859795448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16855086859795448 | validation: 0.14090667477339275]
	TIME [epoch: 16.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11843587513871033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11843587513871033 | validation: 0.10437902688695316]
	TIME [epoch: 17 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09880598976408546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09880598976408546 | validation: 0.10887320685733592]
	TIME [epoch: 16.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08512039167226713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08512039167226713 | validation: 0.06542851692750185]
	TIME [epoch: 17 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08941839442285929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08941839442285929 | validation: 0.18409766794933846]
	TIME [epoch: 16.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11501097371727541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11501097371727541 | validation: 0.08603286882768009]
	TIME [epoch: 16.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14012647132256276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14012647132256276 | validation: 0.2642038630608265]
	TIME [epoch: 16.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13915019660344569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13915019660344569 | validation: 0.0496691226292202]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07773125327636607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07773125327636607 | validation: 0.06523453225398125]
	TIME [epoch: 16.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05934898414827927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05934898414827927 | validation: 0.09833597958635788]
	TIME [epoch: 16.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07032473668849656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07032473668849656 | validation: 0.07661449601474936]
	TIME [epoch: 16.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08928994552249264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08928994552249264 | validation: 0.17575837840000005]
	TIME [epoch: 16.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11886196604043395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11886196604043395 | validation: 0.1704484219207236]
	TIME [epoch: 16.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14842426791402438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14842426791402438 | validation: 0.07289084666952525]
	TIME [epoch: 16.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11422764950569146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11422764950569146 | validation: 0.20759521492750907]
	TIME [epoch: 17 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1134026967132953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1134026967132953 | validation: 0.06138066872369488]
	TIME [epoch: 16.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07870640624045946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07870640624045946 | validation: 0.08443650941426949]
	TIME [epoch: 16.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07091554890147418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07091554890147418 | validation: 0.06594652945072435]
	TIME [epoch: 16.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07215375458661305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07215375458661305 | validation: 0.20041911116027086]
	TIME [epoch: 16.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1758779542944456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1758779542944456 | validation: 0.13179289620975723]
	TIME [epoch: 16.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11368619426917988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11368619426917988 | validation: 0.11142083945040959]
	TIME [epoch: 16.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09499591981985621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09499591981985621 | validation: 0.11050689851830242]
	TIME [epoch: 16.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08085994723443474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08085994723443474 | validation: 0.07580621899430035]
	TIME [epoch: 16.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0744154385994019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0744154385994019 | validation: 0.07030311090086191]
	TIME [epoch: 17 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0778374435094235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0778374435094235 | validation: 0.05460380888543773]
	TIME [epoch: 16.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0646082132659651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0646082132659651 | validation: 0.17644207714192475]
	TIME [epoch: 16.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.097607298360035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.097607298360035 | validation: 0.09236890293060172]
	TIME [epoch: 17 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14436649514853223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14436649514853223 | validation: 0.28114492062167257]
	TIME [epoch: 16.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15261439832296464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15261439832296464 | validation: 0.059886621907581386]
	TIME [epoch: 16.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0610611752186027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0610611752186027 | validation: 0.05883588954469682]
	TIME [epoch: 16.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08559452025829734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08559452025829734 | validation: 0.18444248964916932]
	TIME [epoch: 16.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09417120679959283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09417120679959283 | validation: 0.0641465865684177]
	TIME [epoch: 16.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07504720013620242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07504720013620242 | validation: 0.05836325694264599]
	TIME [epoch: 16.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07149873003117384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07149873003117384 | validation: 0.09349364315924512]
	TIME [epoch: 16.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08627150500556185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08627150500556185 | validation: 0.1066639537748486]
	TIME [epoch: 16.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11750581970488697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11750581970488697 | validation: 0.18746097865283198]
	TIME [epoch: 16.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.152109923600167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.152109923600167 | validation: 0.07122199116557816]
	TIME [epoch: 16.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09982059277954623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09982059277954623 | validation: 0.20933465450956798]
	TIME [epoch: 17 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08843830692305436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08843830692305436 | validation: 0.04787937110076898]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06548872926928165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06548872926928165 | validation: 0.08426069003954348]
	TIME [epoch: 17 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06992342927830009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06992342927830009 | validation: 0.068798134887033]
	TIME [epoch: 16.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07249642126459874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07249642126459874 | validation: 0.07565516844141118]
	TIME [epoch: 16.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07211675561862105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07211675561862105 | validation: 0.06350188214652303]
	TIME [epoch: 16.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08313111390210481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08313111390210481 | validation: 0.13704899185109082]
	TIME [epoch: 16.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10910755262576023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10910755262576023 | validation: 0.0768971203050315]
	TIME [epoch: 16.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1000924799950269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1000924799950269 | validation: 0.15709176580521353]
	TIME [epoch: 17 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09323310273957347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09323310273957347 | validation: 0.06832755246115599]
	TIME [epoch: 16.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08953715161122823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08953715161122823 | validation: 0.1667479338046575]
	TIME [epoch: 16.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10774267788956547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10774267788956547 | validation: 0.05858135411955735]
	TIME [epoch: 16.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09816357850188859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09816357850188859 | validation: 0.2562543501214613]
	TIME [epoch: 16.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11913830965119437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11913830965119437 | validation: 0.04578380852159665]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06837755173181373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06837755173181373 | validation: 0.06456765324390538]
	TIME [epoch: 16.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07045868099011153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07045868099011153 | validation: 0.09038540198656314]
	TIME [epoch: 16.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0788102293357376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0788102293357376 | validation: 0.13125342009818933]
	TIME [epoch: 17 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10123390251330353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10123390251330353 | validation: 0.0822612735190378]
	TIME [epoch: 16.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10584658874402493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10584658874402493 | validation: 0.1247908762554577]
	TIME [epoch: 16.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0991065771846738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0991065771846738 | validation: 0.0451951966477909]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06507084902629673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06507084902629673 | validation: 0.06937546066561331]
	TIME [epoch: 16.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05685994904715184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05685994904715184 | validation: 0.04806460577585269]
	TIME [epoch: 16.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061462843889508526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061462843889508526 | validation: 0.10310521130407034]
	TIME [epoch: 17 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07387334889930887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07387334889930887 | validation: 0.06490463737589088]
	TIME [epoch: 17 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10513595915488477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10513595915488477 | validation: 0.3401000809943034]
	TIME [epoch: 17 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15557272518702173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15557272518702173 | validation: 0.04989993252193479]
	TIME [epoch: 16.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06912908126890516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06912908126890516 | validation: 0.05750508154387038]
	TIME [epoch: 16.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06767003259243637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06767003259243637 | validation: 0.06361823242992777]
	TIME [epoch: 16.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0608745854268429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0608745854268429 | validation: 0.07583204106766082]
	TIME [epoch: 17 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05831842194441579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05831842194441579 | validation: 0.044177364466502556]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05237596509192331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05237596509192331 | validation: 0.05469227418711384]
	TIME [epoch: 16.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05291095209668137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05291095209668137 | validation: 0.09251051801181427]
	TIME [epoch: 16.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07880393261930427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07880393261930427 | validation: 0.15783361010962027]
	TIME [epoch: 17 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16029883696786051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16029883696786051 | validation: 0.10172187466913547]
	TIME [epoch: 17 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12778958065433774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12778958065433774 | validation: 0.09962499931148587]
	TIME [epoch: 17 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07996577839487296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07996577839487296 | validation: 0.05042903385926754]
	TIME [epoch: 17 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0666186523530796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0666186523530796 | validation: 0.20643066138158805]
	TIME [epoch: 17 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.098844768624213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.098844768624213 | validation: 0.053065238684361415]
	TIME [epoch: 16.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07910003700407142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07910003700407142 | validation: 0.0686420925422601]
	TIME [epoch: 17 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059462455677686495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059462455677686495 | validation: 0.04711823040126742]
	TIME [epoch: 16.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061719417606579105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061719417606579105 | validation: 0.10366052525683078]
	TIME [epoch: 16.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07344117388845688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07344117388845688 | validation: 0.053023128394967194]
	TIME [epoch: 17 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08542371879222603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08542371879222603 | validation: 0.21679122573035903]
	TIME [epoch: 16.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0993692239861809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0993692239861809 | validation: 0.04916640322098603]
	TIME [epoch: 16.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06549033093527186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06549033093527186 | validation: 0.3294583563229699]
	TIME [epoch: 17 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40723144914309145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40723144914309145 | validation: 0.585385549439806]
	TIME [epoch: 16.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36116459247725907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36116459247725907 | validation: 0.1976592459845179]
	TIME [epoch: 17 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1341639174205581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1341639174205581 | validation: 0.10953189554849443]
	TIME [epoch: 17 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1281568837742482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1281568837742482 | validation: 0.06106126593232854]
	TIME [epoch: 17 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06536110738047284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06536110738047284 | validation: 0.07418253858976472]
	TIME [epoch: 17 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05478915362232347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05478915362232347 | validation: 0.053042460052305965]
	TIME [epoch: 17 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05357144431027346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05357144431027346 | validation: 0.040137526991924105]
	TIME [epoch: 17 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049635514524406496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049635514524406496 | validation: 0.04957089311598231]
	TIME [epoch: 17 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048750480998218944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048750480998218944 | validation: 0.05194238449931298]
	TIME [epoch: 17 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05741369929667711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05741369929667711 | validation: 0.08714141509697909]
	TIME [epoch: 16.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08224337616900208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08224337616900208 | validation: 0.08174888119853829]
	TIME [epoch: 17 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10489215594844083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10489215594844083 | validation: 0.14495646695377304]
	TIME [epoch: 16.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11008700918022939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11008700918022939 | validation: 0.04813473024690064]
	TIME [epoch: 17 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057182529562753055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057182529562753055 | validation: 0.048963190771776736]
	TIME [epoch: 17 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04692917974138113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04692917974138113 | validation: 0.06136244716622925]
	TIME [epoch: 17 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04662715040325813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04662715040325813 | validation: 0.04026964897794525]
	TIME [epoch: 17 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0415064615379011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0415064615379011 | validation: 0.04306504136614009]
	TIME [epoch: 17 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04851809413333589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04851809413333589 | validation: 0.09781955171710686]
	TIME [epoch: 16.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07451554489088406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07451554489088406 | validation: 0.0947539461620786]
	TIME [epoch: 17 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13107686011513686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13107686011513686 | validation: 0.18901676033246784]
	TIME [epoch: 17 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11626706416903015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11626706416903015 | validation: 0.04603073109697652]
	TIME [epoch: 16.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05833118285418782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05833118285418782 | validation: 0.04371468658405107]
	TIME [epoch: 17 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06279335591394677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06279335591394677 | validation: 0.1734621994496206]
	TIME [epoch: 16.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09199003067635304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09199003067635304 | validation: 0.07126556105739025]
	TIME [epoch: 17 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09636951440713225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09636951440713225 | validation: 0.5787491042208615]
	TIME [epoch: 16.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6014761819289267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6014761819289267 | validation: 0.21771598058223451]
	TIME [epoch: 16.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21007331203848154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21007331203848154 | validation: 0.1754854096669001]
	TIME [epoch: 16.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11329381213660605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11329381213660605 | validation: 0.09925431098828501]
	TIME [epoch: 16.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08370013917556278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08370013917556278 | validation: 0.06021710589820663]
	TIME [epoch: 16.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06555977868096577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06555977868096577 | validation: 0.06840477356610762]
	TIME [epoch: 16.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060249681212413794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060249681212413794 | validation: 0.055478459820223786]
	TIME [epoch: 16.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046147380668323405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.046147380668323405 | validation: 0.05674622759961876]
	TIME [epoch: 17 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042406162694487305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042406162694487305 | validation: 0.048369091371904815]
	TIME [epoch: 16.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04119460454124734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04119460454124734 | validation: 0.04522336316106425]
	TIME [epoch: 16.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04129390797990732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04129390797990732 | validation: 0.10345671300490214]
	TIME [epoch: 16.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12091074308024206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12091074308024206 | validation: 0.14007882266211766]
	TIME [epoch: 16.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09269486841147771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09269486841147771 | validation: 0.06733737077332505]
	TIME [epoch: 16.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07129342587018828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07129342587018828 | validation: 0.09672335962667926]
	TIME [epoch: 16.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07766208627100571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07766208627100571 | validation: 0.05267759282293819]
	TIME [epoch: 17 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06685878917301952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06685878917301952 | validation: 0.06845291171935618]
	TIME [epoch: 17 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05618582520250671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05618582520250671 | validation: 0.06220729377342426]
	TIME [epoch: 16.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05663507645993212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05663507645993212 | validation: 0.06776395903163872]
	TIME [epoch: 16.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05165299356132207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05165299356132207 | validation: 0.03804850041949456]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04895665772862495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04895665772862495 | validation: 0.06809134234110861]
	TIME [epoch: 16.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049203332495141694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049203332495141694 | validation: 0.03555566163702757]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05803717694239316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05803717694239316 | validation: 0.16903224896031538]
	TIME [epoch: 16.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08945054315028063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08945054315028063 | validation: 0.037918994581172205]
	TIME [epoch: 17 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05961810483121918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05961810483121918 | validation: 0.08968371320224296]
	TIME [epoch: 16.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06395214850120805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06395214850120805 | validation: 0.08809393457958065]
	TIME [epoch: 16.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07610096137190485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07610096137190485 | validation: 0.0504128210998892]
	TIME [epoch: 17 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0567357533728641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0567357533728641 | validation: 0.049506633438653615]
	TIME [epoch: 17 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06129130682028199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06129130682028199 | validation: 0.11194257526053196]
	TIME [epoch: 16.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07035520844068581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07035520844068581 | validation: 0.04087659031034538]
	TIME [epoch: 17 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06067563687551531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06067563687551531 | validation: 0.07828000224410704]
	TIME [epoch: 16.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06893400913334113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06893400913334113 | validation: 0.10409340732284787]
	TIME [epoch: 17 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10743789996043143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10743789996043143 | validation: 0.3177699292965343]
	TIME [epoch: 16.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23201973461087025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23201973461087025 | validation: 0.21181840574860866]
	TIME [epoch: 16.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12440465936076908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12440465936076908 | validation: 0.14006796556290144]
	TIME [epoch: 17 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09526689256359137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09526689256359137 | validation: 0.0943618283467858]
	TIME [epoch: 17 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07984831148748549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07984831148748549 | validation: 0.0821974273498772]
	TIME [epoch: 16.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07129073600602641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07129073600602641 | validation: 0.08830482825138]
	TIME [epoch: 17 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05906186207896658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05906186207896658 | validation: 0.10241695016687505]
	TIME [epoch: 16.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05786984857376254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05786984857376254 | validation: 0.058368550926877455]
	TIME [epoch: 16.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05288066402252062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05288066402252062 | validation: 0.0602776211476678]
	TIME [epoch: 17 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04856109829852504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04856109829852504 | validation: 0.06774047235446586]
	TIME [epoch: 16.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04926953950136714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04926953950136714 | validation: 0.0473977241163133]
	TIME [epoch: 16.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05419119258465918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05419119258465918 | validation: 0.08987076941469306]
	TIME [epoch: 16.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06886407957835677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06886407957835677 | validation: 0.07077285491221916]
	TIME [epoch: 16.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0658284742428862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0658284742428862 | validation: 0.050431918212448745]
	TIME [epoch: 16.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06653814090714077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06653814090714077 | validation: 0.09614659781806074]
	TIME [epoch: 16.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06757799225860926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06757799225860926 | validation: 0.037407511353469834]
	TIME [epoch: 16.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049403274201863294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049403274201863294 | validation: 0.05442870881183418]
	TIME [epoch: 16.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04327495053334117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04327495053334117 | validation: 0.04749060872889038]
	TIME [epoch: 16.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048587062498271716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048587062498271716 | validation: 0.07080480567339405]
	TIME [epoch: 16.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06113140928379943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06113140928379943 | validation: 0.06493678288430403]
	TIME [epoch: 16.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06683886963311358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06683886963311358 | validation: 0.06824891170465147]
	TIME [epoch: 16.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054978753771959765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054978753771959765 | validation: 0.03641961616080815]
	TIME [epoch: 16.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049434456728219875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049434456728219875 | validation: 0.07148602585836027]
	TIME [epoch: 16.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05904544162225612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05904544162225612 | validation: 0.052660179643197184]
	TIME [epoch: 16.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0674224157021177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0674224157021177 | validation: 0.09070912339858857]
	TIME [epoch: 16.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07463874013876297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07463874013876297 | validation: 0.05230329280411308]
	TIME [epoch: 16.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06618162584757094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06618162584757094 | validation: 0.11169228243310508]
	TIME [epoch: 16.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08588242809606293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08588242809606293 | validation: 0.06271070172047864]
	TIME [epoch: 16.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05595408918167893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05595408918167893 | validation: 0.043696649073721186]
	TIME [epoch: 16.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05350176909820051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05350176909820051 | validation: 0.08256825192656045]
	TIME [epoch: 16.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06828075181026598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06828075181026598 | validation: 0.0490024856354071]
	TIME [epoch: 16.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06472086233672415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06472086233672415 | validation: 0.05529400398179279]
	TIME [epoch: 16.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05724954651137559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05724954651137559 | validation: 0.039701046492810046]
	TIME [epoch: 16.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04699971271459979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04699971271459979 | validation: 0.04589949265022494]
	TIME [epoch: 16.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04773940143913562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04773940143913562 | validation: 0.04747872317248658]
	TIME [epoch: 16.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05371896054633301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05371896054633301 | validation: 0.07082103032733503]
	TIME [epoch: 16.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05670823669313538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05670823669313538 | validation: 0.04505849049178676]
	TIME [epoch: 16.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05079222315046547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05079222315046547 | validation: 0.06223516304336411]
	TIME [epoch: 16.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05158695142014077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05158695142014077 | validation: 0.06066041104040407]
	TIME [epoch: 16.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1035138144018404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1035138144018404 | validation: 0.2464952883064019]
	TIME [epoch: 16.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11148261781767475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11148261781767475 | validation: 0.04997864349273287]
	TIME [epoch: 16.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03375958292243362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03375958292243362 | validation: 0.025772909821072235]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04155375738686821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04155375738686821 | validation: 0.04599433470589035]
	TIME [epoch: 16.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053909506409198026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053909506409198026 | validation: 0.06449088560024607]
	TIME [epoch: 16.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05685085683009564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05685085683009564 | validation: 0.0753235406712545]
	TIME [epoch: 17 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08464261739066131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08464261739066131 | validation: 0.09955258243175039]
	TIME [epoch: 16.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08736203173090305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08736203173090305 | validation: 0.05499357471607333]
	TIME [epoch: 16.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06270351842269768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06270351842269768 | validation: 0.045393202510413566]
	TIME [epoch: 16.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043411103783305476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043411103783305476 | validation: 0.05162198988194319]
	TIME [epoch: 16.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04020319177832375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04020319177832375 | validation: 0.01951176067291085]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03254065830856189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03254065830856189 | validation: 0.024205759133437955]
	TIME [epoch: 16.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027136256457064755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027136256457064755 | validation: 0.021509074490929248]
	TIME [epoch: 16.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024500952650423333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024500952650423333 | validation: 0.025807546524700853]
	TIME [epoch: 16.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02881504806535042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02881504806535042 | validation: 0.032914571510788075]
	TIME [epoch: 16.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06201322437339644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06201322437339644 | validation: 0.22813298116332678]
	TIME [epoch: 16.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1572095753291757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1572095753291757 | validation: 0.05490069778441527]
	TIME [epoch: 16.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06918636139832393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06918636139832393 | validation: 0.08616123457361612]
	TIME [epoch: 16.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10046639097347121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10046639097347121 | validation: 0.13963015091953654]
	TIME [epoch: 16.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12296949097685421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12296949097685421 | validation: 0.02771877458663388]
	TIME [epoch: 16.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0440305274940792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0440305274940792 | validation: 0.026127119316614877]
	TIME [epoch: 16.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03140547100981541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03140547100981541 | validation: 0.04031796386756793]
	TIME [epoch: 16.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034098218355930354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034098218355930354 | validation: 0.1285144266159338]
	TIME [epoch: 16.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10302935384064035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10302935384064035 | validation: 0.09610141443249196]
	TIME [epoch: 16.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10077262588719886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10077262588719886 | validation: 0.11575533312176244]
	TIME [epoch: 17 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09263907478380924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09263907478380924 | validation: 0.06304262956631786]
	TIME [epoch: 16.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07119522070541354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07119522070541354 | validation: 0.09525752493484173]
	TIME [epoch: 16.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06000408158211939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06000408158211939 | validation: 0.05478396621912373]
	TIME [epoch: 16.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06094384909566349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06094384909566349 | validation: 0.10060008432882594]
	TIME [epoch: 16.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07895037903072455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07895037903072455 | validation: 0.04729508231370619]
	TIME [epoch: 17 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053026306921383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053026306921383 | validation: 0.04299538352447377]
	TIME [epoch: 17 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04145206107288707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04145206107288707 | validation: 0.027423538057560704]
	TIME [epoch: 17.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028221646536881834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028221646536881834 | validation: 0.046021320885896125]
	TIME [epoch: 17 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032335875644048606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032335875644048606 | validation: 0.03146301090360448]
	TIME [epoch: 17 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04127047389315473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04127047389315473 | validation: 0.07766967317550288]
	TIME [epoch: 17.1 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061520618525433515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061520618525433515 | validation: 0.05383473626209151]
	TIME [epoch: 17.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06853175529696186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06853175529696186 | validation: 0.08048747189314137]
	TIME [epoch: 17.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07528965744064052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07528965744064052 | validation: 0.04012788601488129]
	TIME [epoch: 17 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04993988987443382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04993988987443382 | validation: 0.04434674259702123]
	TIME [epoch: 17.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.040897375062382724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.040897375062382724 | validation: 0.03348728031092279]
	TIME [epoch: 17.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03598388855708474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03598388855708474 | validation: 0.033123904781757696]
	TIME [epoch: 17 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03899360822850954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03899360822850954 | validation: 0.051898247859559765]
	TIME [epoch: 17.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0517552566699116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0517552566699116 | validation: 0.06366533604115641]
	TIME [epoch: 17.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0578948106504207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0578948106504207 | validation: 0.05205765483959112]
	TIME [epoch: 17 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06515788471392302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06515788471392302 | validation: 0.2037512604789236]
	TIME [epoch: 17.1 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10740577632208302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10740577632208302 | validation: 0.03783273500046687]
	TIME [epoch: 17.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04237317916660242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04237317916660242 | validation: 0.04148715636410402]
	TIME [epoch: 17.1 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04211703686612377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04211703686612377 | validation: 0.05432234705038905]
	TIME [epoch: 17.1 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037677681898537985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037677681898537985 | validation: 0.03221887415688881]
	TIME [epoch: 17.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04018520867786966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04018520867786966 | validation: 0.10819020763675558]
	TIME [epoch: 17.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09854236625307036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09854236625307036 | validation: 0.06683161060948237]
	TIME [epoch: 17.1 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08805820838949263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08805820838949263 | validation: 0.06827350241682681]
	TIME [epoch: 17.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07056703039727702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07056703039727702 | validation: 0.0788849358484695]
	TIME [epoch: 17.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05240407978207234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05240407978207234 | validation: 0.03805560228009394]
	TIME [epoch: 17.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054677233639459505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054677233639459505 | validation: 0.052442145789119946]
	TIME [epoch: 17.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0559116139058778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0559116139058778 | validation: 0.025908097259912055]
	TIME [epoch: 17.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03126207005748598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03126207005748598 | validation: 0.04100407463320293]
	TIME [epoch: 17.2 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050524073200046225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050524073200046225 | validation: 0.11781262927853708]
	TIME [epoch: 17.1 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07311087144240996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07311087144240996 | validation: 0.01836256638986572]
	TIME [epoch: 17.2 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_866.pth
	Model improved!!!
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038469345618543684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038469345618543684 | validation: 0.026221633985073902]
	TIME [epoch: 17.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032198039840177446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032198039840177446 | validation: 0.03802825010474761]
	TIME [epoch: 17.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03359101863440728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03359101863440728 | validation: 0.028627824551448158]
	TIME [epoch: 17.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02993103410169812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02993103410169812 | validation: 0.041614705092557484]
	TIME [epoch: 17.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05580232715474783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05580232715474783 | validation: 0.0859024421987202]
	TIME [epoch: 17.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08465164382525854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08465164382525854 | validation: 0.036532477332551015]
	TIME [epoch: 17.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04886568157180431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04886568157180431 | validation: 0.03055391773261519]
	TIME [epoch: 17.2 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03312069228542684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03312069228542684 | validation: 0.019493543073898712]
	TIME [epoch: 17.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032029618673437114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032029618673437114 | validation: 0.056827685220199146]
	TIME [epoch: 17.1 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045170686146774275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045170686146774275 | validation: 0.06892174941463074]
	TIME [epoch: 17.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08572352149824548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08572352149824548 | validation: 0.24380987464959342]
	TIME [epoch: 17.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1342232955275655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1342232955275655 | validation: 0.047568199920594856]
	TIME [epoch: 17.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04487753215945693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04487753215945693 | validation: 0.03265158661616452]
	TIME [epoch: 17.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04518222527551121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04518222527551121 | validation: 0.054307209556032736]
	TIME [epoch: 17.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050604173837897656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050604173837897656 | validation: 0.022439161149960876]
	TIME [epoch: 17.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02524595710417592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02524595710417592 | validation: 0.020106873878230437]
	TIME [epoch: 17.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03191977962219682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03191977962219682 | validation: 0.053617670455684135]
	TIME [epoch: 17.1 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04857509002368872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04857509002368872 | validation: 0.03039894230871091]
	TIME [epoch: 17.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04641320989546852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04641320989546852 | validation: 0.06391789901146883]
	TIME [epoch: 17.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06520508965455256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06520508965455256 | validation: 0.050830103338573934]
	TIME [epoch: 17.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05786491452332241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05786491452332241 | validation: 0.037246105456536054]
	TIME [epoch: 17.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04332645041603174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04332645041603174 | validation: 0.04051121029988361]
	TIME [epoch: 17.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04384564426719537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04384564426719537 | validation: 0.018090071867780833]
	TIME [epoch: 17.1 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02865401786877235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02865401786877235 | validation: 0.04671948569792304]
	TIME [epoch: 17.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027866413695444056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027866413695444056 | validation: 0.01721430760687227]
	TIME [epoch: 17.2 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02967214778952734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02967214778952734 | validation: 0.0434674569824591]
	TIME [epoch: 17.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03638955447430254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03638955447430254 | validation: 0.07059491260250116]
	TIME [epoch: 17.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08193758759005182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08193758759005182 | validation: 0.1079503962519816]
	TIME [epoch: 17.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08994565257168861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08994565257168861 | validation: 0.04548109286060286]
	TIME [epoch: 17.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050104036775079804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.050104036775079804 | validation: 0.055821523952354415]
	TIME [epoch: 17.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05499928642893551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05499928642893551 | validation: 0.07999008681274422]
	TIME [epoch: 17.1 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06585142353099134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06585142353099134 | validation: 0.08406707695518639]
	TIME [epoch: 17.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07773375399397525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07773375399397525 | validation: 0.06809713689139932]
	TIME [epoch: 17.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05191869291245535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05191869291245535 | validation: 0.046133553096260826]
	TIME [epoch: 17.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036649480159799824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036649480159799824 | validation: 0.04216163707493717]
	TIME [epoch: 17.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0452756461403616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0452756461403616 | validation: 0.046863633719355646]
	TIME [epoch: 17.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05683556313845234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05683556313845234 | validation: 0.049492777677705616]
	TIME [epoch: 17.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06388767050060215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06388767050060215 | validation: 0.0466230914537931]
	TIME [epoch: 17.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04829327373056005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04829327373056005 | validation: 0.027108913483250143]
	TIME [epoch: 17.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03517162113679691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03517162113679691 | validation: 0.03684609874073809]
	TIME [epoch: 17.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04119753724091248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04119753724091248 | validation: 0.05280988088438146]
	TIME [epoch: 17.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06264387705843077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06264387705843077 | validation: 0.1343607730481562]
	TIME [epoch: 17.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08147289642982637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08147289642982637 | validation: 0.038707823296081315]
	TIME [epoch: 17.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03947010719094779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03947010719094779 | validation: 0.027548962291106385]
	TIME [epoch: 17.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032048211380512406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032048211380512406 | validation: 0.03536066608697556]
	TIME [epoch: 17 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03788345103579781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03788345103579781 | validation: 0.016155184948404268]
	TIME [epoch: 17.2 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_912.pth
	Model improved!!!
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024982862775245827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024982862775245827 | validation: 0.028076079722595272]
	TIME [epoch: 17.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02939984367304211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02939984367304211 | validation: 0.04570239945597951]
	TIME [epoch: 17.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04562460722620787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04562460722620787 | validation: 0.04351715638322982]
	TIME [epoch: 17.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05059620960954979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05059620960954979 | validation: 0.037729378594839075]
	TIME [epoch: 17.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045130685225845235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045130685225845235 | validation: 0.04874575511060533]
	TIME [epoch: 17.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0551868497295154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0551868497295154 | validation: 0.05051931293406138]
	TIME [epoch: 17.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05807350966234729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05807350966234729 | validation: 0.026257480753079376]
	TIME [epoch: 17.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0313692789968325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0313692789968325 | validation: 0.0205389441689148]
	TIME [epoch: 17.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022311123000492643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022311123000492643 | validation: 0.021995525271257334]
	TIME [epoch: 17.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030046603501024213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030046603501024213 | validation: 0.06371820093924278]
	TIME [epoch: 17.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06497558650280848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06497558650280848 | validation: 0.2012706502064046]
	TIME [epoch: 17.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11551735641819452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11551735641819452 | validation: 0.0419248521811511]
	TIME [epoch: 17.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054899391556232364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054899391556232364 | validation: 0.025742665392351274]
	TIME [epoch: 17.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03196739511196392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03196739511196392 | validation: 0.0663746890979156]
	TIME [epoch: 17.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05815892053864123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05815892053864123 | validation: 0.1210159113471374]
	TIME [epoch: 17.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09348978835284484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09348978835284484 | validation: 0.08076935268413435]
	TIME [epoch: 17.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09161307132148407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09161307132148407 | validation: 0.7884703951476828]
	TIME [epoch: 17.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0058663716911698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0058663716911698 | validation: 0.8096297084752111]
	TIME [epoch: 17.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0240556781406316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0240556781406316 | validation: 0.602321936760562]
	TIME [epoch: 17.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5404940608929069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5404940608929069 | validation: 0.28107936112467846]
	TIME [epoch: 17.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25234724569971334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25234724569971334 | validation: 0.10009439765257362]
	TIME [epoch: 17.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09747778665947614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09747778665947614 | validation: 0.10354182320010077]
	TIME [epoch: 17.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10070342155451084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10070342155451084 | validation: 0.0536499750383617]
	TIME [epoch: 17.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06727387269401179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06727387269401179 | validation: 0.08577614995162802]
	TIME [epoch: 17.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08062058242223491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08062058242223491 | validation: 0.06984821200233218]
	TIME [epoch: 17.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07863246382219094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07863246382219094 | validation: 0.06459193878370319]
	TIME [epoch: 17.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06133462950022912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06133462950022912 | validation: 0.051905920847803357]
	TIME [epoch: 17.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053396645542956755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.053396645542956755 | validation: 0.040094757774179174]
	TIME [epoch: 17.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04672453866358831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04672453866358831 | validation: 0.040403998894888396]
	TIME [epoch: 17.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03653136687310848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03653136687310848 | validation: 0.0399509968967157]
	TIME [epoch: 17.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03546208754440579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03546208754440579 | validation: 0.04351066824864014]
	TIME [epoch: 17.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031817991483738435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031817991483738435 | validation: 0.03475020277795964]
	TIME [epoch: 17.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03235517308093691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03235517308093691 | validation: 0.036937237439221726]
	TIME [epoch: 17.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03526230354901951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03526230354901951 | validation: 0.04923459883176459]
	TIME [epoch: 17.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041123147824248585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041123147824248585 | validation: 0.05929083342872852]
	TIME [epoch: 17.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05454963082272417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05454963082272417 | validation: 0.0676356362418906]
	TIME [epoch: 17.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06187511163598691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06187511163598691 | validation: 0.05947065319006087]
	TIME [epoch: 17.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05551938064611932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05551938064611932 | validation: 0.047716309930687276]
	TIME [epoch: 17.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04693245464171171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04693245464171171 | validation: 0.036355463010130984]
	TIME [epoch: 17.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033570226582304595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033570226582304595 | validation: 0.027131242972863203]
	TIME [epoch: 17.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025447457089356928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025447457089356928 | validation: 0.02782016402444113]
	TIME [epoch: 17.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025875840700887283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025875840700887283 | validation: 0.030108267605329555]
	TIME [epoch: 17.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025653295823875537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025653295823875537 | validation: 0.024433573337605853]
	TIME [epoch: 17.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023361606725542442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023361606725542442 | validation: 0.02377618869230649]
	TIME [epoch: 17.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024574805555303846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024574805555303846 | validation: 0.04170083647727958]
	TIME [epoch: 17.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03475837289887006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03475837289887006 | validation: 0.15120907373582015]
	TIME [epoch: 17.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11529282957288374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11529282957288374 | validation: 0.1306289809977792]
	TIME [epoch: 17.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1371796799333794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1371796799333794 | validation: 0.08798351809915649]
	TIME [epoch: 17.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06784359662987541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06784359662987541 | validation: 0.054728148195985406]
	TIME [epoch: 17.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04001997648328507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04001997648328507 | validation: 0.033002525936988616]
	TIME [epoch: 17.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03363828376055699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03363828376055699 | validation: 0.026785998896612206]
	TIME [epoch: 17.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027439355275183847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027439355275183847 | validation: 0.03840677894731277]
	TIME [epoch: 17.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.039077564148676934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.039077564148676934 | validation: 0.03574446054605234]
	TIME [epoch: 17.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04851472176156751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04851472176156751 | validation: 0.0757826455885497]
	TIME [epoch: 17.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06445899371701849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06445899371701849 | validation: 0.04666833775916859]
	TIME [epoch: 17.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056719081199832114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056719081199832114 | validation: 0.0397937018806931]
	TIME [epoch: 17.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034447411973172776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034447411973172776 | validation: 0.022422667347178273]
	TIME [epoch: 17.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021389919123046826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021389919123046826 | validation: 0.025203510775996443]
	TIME [epoch: 17.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024179379666471875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024179379666471875 | validation: 0.02564923824008566]
	TIME [epoch: 17.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024492321705588647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024492321705588647 | validation: 0.027434090289405758]
	TIME [epoch: 17.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027090020786287524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027090020786287524 | validation: 0.03580055080074725]
	TIME [epoch: 17.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034375547531607306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034375547531607306 | validation: 0.05404163615595752]
	TIME [epoch: 17.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05472737592281829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05472737592281829 | validation: 0.05613699795021598]
	TIME [epoch: 17.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05878804990607708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05878804990607708 | validation: 0.05532114717758518]
	TIME [epoch: 17.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05782781373297289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05782781373297289 | validation: 0.08292972354841106]
	TIME [epoch: 17.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08387783061893775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08387783061893775 | validation: 0.16149846392557077]
	TIME [epoch: 17.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14402529485506302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14402529485506302 | validation: 0.15657425090258115]
	TIME [epoch: 17.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12532476447470597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12532476447470597 | validation: 0.12425727244532703]
	TIME [epoch: 17.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11240154771937837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11240154771937837 | validation: 0.07833204251516929]
	TIME [epoch: 17.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07557027600950914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07557027600950914 | validation: 0.043998996983045026]
	TIME [epoch: 17.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04695293599987851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04695293599987851 | validation: 0.03914852615190465]
	TIME [epoch: 17.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03078579267087265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03078579267087265 | validation: 0.029946459242951518]
	TIME [epoch: 17.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028906658490900978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.028906658490900978 | validation: 0.030628040848761907]
	TIME [epoch: 17.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03370408278073644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03370408278073644 | validation: 0.05145771682336058]
	TIME [epoch: 17.1 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04747285726168184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04747285726168184 | validation: 0.056651336463850344]
	TIME [epoch: 17.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06383445975387034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06383445975387034 | validation: 0.06059047088708006]
	TIME [epoch: 17.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05997189794701784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05997189794701784 | validation: 0.03297736875923281]
	TIME [epoch: 17.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03845901389215595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03845901389215595 | validation: 0.027597433485372004]
	TIME [epoch: 17.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0262787872402781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0262787872402781 | validation: 0.022169255338187366]
	TIME [epoch: 17.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022190590455392876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022190590455392876 | validation: 0.029195166437510536]
	TIME [epoch: 17.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030967905285752155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030967905285752155 | validation: 0.03997129078152554]
	TIME [epoch: 17.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04394466304234267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04394466304234267 | validation: 0.037069482824927016]
	TIME [epoch: 17.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04400516092718466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04400516092718466 | validation: 0.028652007249207412]
	TIME [epoch: 17.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03284972531913357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03284972531913357 | validation: 0.023460031568536932]
	TIME [epoch: 17.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030498155750260176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030498155750260176 | validation: 0.03877001206829145]
	TIME [epoch: 17.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04135087551780886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04135087551780886 | validation: 0.06446133411048907]
	TIME [epoch: 17.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07990117974224495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07990117974224495 | validation: 0.1864181539252425]
	TIME [epoch: 17.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08839781027358834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08839781027358834 | validation: 0.03570142339245415]
	TIME [epoch: 17.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03297161060045103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03297161060045103 | validation: 0.04443558777438929]
	TIME [epoch: 73.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04320695150578467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04320695150578467 | validation: 0.032544116225484136]
	TIME [epoch: 35.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.035449967345562265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.035449967345562265 | validation: 0.017892714103481012]
	TIME [epoch: 35.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022369691242494407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022369691242494407 | validation: 0.02298468352324521]
	TIME [epoch: 35.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0268103704868648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0268103704868648 | validation: 0.025554422324178774]
	TIME [epoch: 35.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030090982925977547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030090982925977547 | validation: 0.03566807197068857]
	TIME [epoch: 35.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.036449156916205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036449156916205 | validation: 0.0487349401070386]
	TIME [epoch: 35.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05247658208384861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05247658208384861 | validation: 0.04403461689437554]
	TIME [epoch: 35.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0516798819632378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0516798819632378 | validation: 0.020558038045371943]
	TIME [epoch: 35.4 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029459403042705803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029459403042705803 | validation: 0.031031075931185804]
	TIME [epoch: 35.2 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031778812451589124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031778812451589124 | validation: 0.033415043038550155]
	TIME [epoch: 35.1 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03226993401540673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03226993401540673 | validation: 0.02862439045311882]
	TIME [epoch: 35.2 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031402222921003024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031402222921003024 | validation: 0.026757097301317635]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20240823_171535/states/model_phi1_4c_v_mmd1_1013.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 12347.521 seconds.
