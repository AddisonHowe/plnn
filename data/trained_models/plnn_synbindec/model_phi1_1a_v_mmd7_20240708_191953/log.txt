Args:
Namespace(name='model_phi1_1a_v_mmd7', outdir='out/model_training/model_phi1_1a_v_mmd7', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1564536751

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841259772008799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.841259772008799 | validation: 2.443237245523317]
	TIME [epoch: 124 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356094950845651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.356094950845651 | validation: 2.100702188470906]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089248369956708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.089248369956708 | validation: 1.8552505503937984]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8387333405557242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8387333405557242 | validation: 1.9733219511389075]
	TIME [epoch: 7.5 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8352688559466808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8352688559466808 | validation: 1.715689635458546]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.756881593883675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.756881593883675 | validation: 1.5804680896736512]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5985275805729997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5985275805729997 | validation: 1.44911521190284]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5421067670017874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5421067670017874 | validation: 1.412718957097959]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5716381604949812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5716381604949812 | validation: 1.4033571954202222]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4871127832984539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4871127832984539 | validation: 1.3602512282616472]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4320565014136792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4320565014136792 | validation: 1.3291833453047703]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.39434916328826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.39434916328826 | validation: 1.2947822691359532]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3685662153722584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3685662153722584 | validation: 1.326476530520733]
	TIME [epoch: 7.51 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3472466573716675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3472466573716675 | validation: 1.2873685005063056]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3281829630434066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3281829630434066 | validation: 1.274620671163559]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2889770885302676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2889770885302676 | validation: 1.276816379714226]
	TIME [epoch: 7.49 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2684227588642547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2684227588642547 | validation: 1.265060526774055]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2429479570389765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2429479570389765 | validation: 1.2640493305443063]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3409293993807725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3409293993807725 | validation: 1.3256684345352348]
	TIME [epoch: 7.53 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2532410043812692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2532410043812692 | validation: 1.258517704821167]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1965143494263546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1965143494263546 | validation: 1.2663897740216266]
	TIME [epoch: 7.51 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3535368816968893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3535368816968893 | validation: 1.2287744498768305]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081667309209072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.081667309209072 | validation: 1.2075872970418273]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9980999696797193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9980999696797193 | validation: 1.0992245168262005]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9733649327893392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9733649327893392 | validation: 1.0323405519212097]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9079384143266289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9079384143266289 | validation: 1.0636259192524113]
	TIME [epoch: 7.53 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9664175962429087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9664175962429087 | validation: 1.0017332582724847]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862003687766926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.862003687766926 | validation: 0.9550052210869593]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9576129878554871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9576129878554871 | validation: 0.9370247244246699]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84148541813385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.84148541813385 | validation: 0.91527237373107]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8262203671358527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8262203671358527 | validation: 0.9071556903682871]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8297701456479203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8297701456479203 | validation: 0.8881899874738126]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114676984498388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8114676984498388 | validation: 0.8480818082513708]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8614148917419525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8614148917419525 | validation: 0.8491783058103629]
	TIME [epoch: 7.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231637616507197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7231637616507197 | validation: 0.6845767750190569]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295850641277177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7295850641277177 | validation: 0.7202896950439156]
	TIME [epoch: 7.53 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003181877406399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7003181877406399 | validation: 0.5940084870281321]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6612018314537818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6612018314537818 | validation: 0.6942409729684182]
	TIME [epoch: 7.55 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6266324077503509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6266324077503509 | validation: 0.6572214580727807]
	TIME [epoch: 7.52 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310647756001141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6310647756001141 | validation: 0.6514346726341715]
	TIME [epoch: 7.52 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466253393982093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5466253393982093 | validation: 0.4743547254695991]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686685585865034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5686685585865034 | validation: 0.7011751495525973]
	TIME [epoch: 7.55 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5659749574004577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5659749574004577 | validation: 0.5089785268330969]
	TIME [epoch: 7.51 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635045363627589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4635045363627589 | validation: 0.43828047800899445]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48772994590481467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48772994590481467 | validation: 0.5708449878800872]
	TIME [epoch: 7.51 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810090581920349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5810090581920349 | validation: 0.5281274628016597]
	TIME [epoch: 7.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4983557133888817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4983557133888817 | validation: 0.4747799721156972]
	TIME [epoch: 7.55 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42497449983918156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42497449983918156 | validation: 0.663838905313245]
	TIME [epoch: 7.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49165193232648596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49165193232648596 | validation: 0.44720372774993056]
	TIME [epoch: 7.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.448776831831997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.448776831831997 | validation: 0.4003841204067338]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716779423163032		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.3716779423163032 | validation: 0.439830063009468]
	TIME [epoch: 7.51 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548934566855759		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.548934566855759 | validation: 0.45784816446811527]
	TIME [epoch: 7.55 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5027708562481286		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5027708562481286 | validation: 0.5428100674003946]
	TIME [epoch: 7.51 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39531067874756504		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.39531067874756504 | validation: 0.32555255426218616]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4422407908493775		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.4422407908493775 | validation: 0.45965222834899316]
	TIME [epoch: 7.51 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441692729813269		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.441692729813269 | validation: 0.547801037204198]
	TIME [epoch: 7.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017723242108376		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.4017723242108376 | validation: 0.3077202864684704]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34902236075782656		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.34902236075782656 | validation: 0.35575489280069517]
	TIME [epoch: 7.49 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35213445208200705		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.35213445208200705 | validation: 0.4513889202363647]
	TIME [epoch: 7.49 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414784849442079		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.414784849442079 | validation: 0.6391917437704011]
	TIME [epoch: 7.49 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.397010103517122		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.397010103517122 | validation: 0.39493831810099905]
	TIME [epoch: 7.49 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31861370855112875		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.31861370855112875 | validation: 0.2751035319016706]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28591243785019194		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.28591243785019194 | validation: 0.47017712820674173]
	TIME [epoch: 7.54 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420963211193056		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.420963211193056 | validation: 0.42234122713311056]
	TIME [epoch: 7.54 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3416619171693514		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.3416619171693514 | validation: 0.37251318520147136]
	TIME [epoch: 7.54 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017653756007475		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.3017653756007475 | validation: 0.4595269739476969]
	TIME [epoch: 7.54 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3063175116471414		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.3063175116471414 | validation: 0.26119853507305496]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952968663408535		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.2952968663408535 | validation: 0.3380263690700385]
	TIME [epoch: 7.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330937621688308		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.330937621688308 | validation: 0.2911898974061308]
	TIME [epoch: 7.52 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887675058448602		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.2887675058448602 | validation: 0.26087075700358575]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31472564015553217		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.31472564015553217 | validation: 0.39659956727089185]
	TIME [epoch: 7.54 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30316554533963463		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.30316554533963463 | validation: 0.2795675018507974]
	TIME [epoch: 7.55 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690295003615013		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.2690295003615013 | validation: 0.33565854333317213]
	TIME [epoch: 7.51 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29868359168865494		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.29868359168865494 | validation: 0.3339891897204948]
	TIME [epoch: 7.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264742403989852		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.3264742403989852 | validation: 0.3128464837463223]
	TIME [epoch: 7.52 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29986415705176356		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.29986415705176356 | validation: 0.34015037772912843]
	TIME [epoch: 7.54 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29735772540675093		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.29735772540675093 | validation: 0.24149390614038604]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26636646804521247		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.26636646804521247 | validation: 0.28494959794209224]
	TIME [epoch: 7.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298688015554973		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.2298688015554973 | validation: 0.2392468069581657]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012412000292866		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.3012412000292866 | validation: 0.22658299738197352]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726914108953786		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.2726914108953786 | validation: 0.2234377806122282]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25676250780248916		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.25676250780248916 | validation: 0.464672012520634]
	TIME [epoch: 7.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26656637388965876		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.26656637388965876 | validation: 0.2932950834705452]
	TIME [epoch: 7.49 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27033691077118877		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.27033691077118877 | validation: 0.2874869113047968]
	TIME [epoch: 7.49 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21711108880875007		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.21711108880875007 | validation: 0.3157170400972099]
	TIME [epoch: 7.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169677267342402		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.21169677267342402 | validation: 0.34517078493666165]
	TIME [epoch: 7.54 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351702402959601		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.351702402959601 | validation: 0.3445510016500959]
	TIME [epoch: 7.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24163349489290376		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.24163349489290376 | validation: 0.1970953088534677]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303382885466173		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.2303382885466173 | validation: 0.2440755395006076]
	TIME [epoch: 7.54 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22632749624301018		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.22632749624301018 | validation: 0.23649205075504204]
	TIME [epoch: 7.54 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2262169415901111		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.2262169415901111 | validation: 0.1814378040144986]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191661038974426		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.20191661038974426 | validation: 0.3309684200126569]
	TIME [epoch: 7.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28620889173921266		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.28620889173921266 | validation: 0.20120759515218517]
	TIME [epoch: 7.52 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26484247200389277		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.26484247200389277 | validation: 0.23596832191095393]
	TIME [epoch: 7.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915310197827905		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.1915310197827905 | validation: 0.3812053649566871]
	TIME [epoch: 7.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27274016064794654		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.27274016064794654 | validation: 0.26732229471423746]
	TIME [epoch: 7.57 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593994026910764		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.20593994026910764 | validation: 0.197837357717085]
	TIME [epoch: 7.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22897086242827475		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.22897086242827475 | validation: 0.22386460683764645]
	TIME [epoch: 7.53 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19284725927210508		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.19284725927210508 | validation: 0.3753281465998866]
	TIME [epoch: 7.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20601588213306563		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.20601588213306563 | validation: 0.17876470194300348]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2260716469425352		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.2260716469425352 | validation: 0.33168932815526647]
	TIME [epoch: 7.57 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202691438120233		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.202691438120233 | validation: 0.2133959862965806]
	TIME [epoch: 7.52 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16603731549423448		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.16603731549423448 | validation: 0.24922224670300325]
	TIME [epoch: 7.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338203367562188		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.2338203367562188 | validation: 0.16858441065146057]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18744228212226588		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.18744228212226588 | validation: 0.3917829303653899]
	TIME [epoch: 7.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208146950764142		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.2208146950764142 | validation: 0.18053284349505574]
	TIME [epoch: 7.56 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19131667157958285		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.19131667157958285 | validation: 0.16242094207522847]
	TIME [epoch: 7.5 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469824510003314		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.1469824510003314 | validation: 0.21794192226127562]
	TIME [epoch: 7.51 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21706500211613475		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.21706500211613475 | validation: 0.48540845402455823]
	TIME [epoch: 7.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225848300021116		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3225848300021116 | validation: 0.2353234053677588]
	TIME [epoch: 7.49 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21713052142314512		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.21713052142314512 | validation: 0.1763811253318262]
	TIME [epoch: 7.55 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197270432501416		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.17197270432501416 | validation: 0.20876142583961993]
	TIME [epoch: 7.51 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18556738180757146		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.18556738180757146 | validation: 0.17606916634912756]
	TIME [epoch: 7.49 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19769538058879527		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.19769538058879527 | validation: 0.18819450005962546]
	TIME [epoch: 7.51 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15523509161443488		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.15523509161443488 | validation: 0.20692108285374472]
	TIME [epoch: 7.49 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17311493095377944		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.17311493095377944 | validation: 0.1648000328839317]
	TIME [epoch: 7.55 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085641794314802		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.18085641794314802 | validation: 0.1787236646114376]
	TIME [epoch: 7.49 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981446834519317		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.1981446834519317 | validation: 0.18340678591555587]
	TIME [epoch: 7.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440992117180856		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.1440992117180856 | validation: 0.12648594480465605]
	TIME [epoch: 7.49 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706492776714648		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.12706492776714648 | validation: 0.22023811087976802]
	TIME [epoch: 7.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24979817899257328		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.24979817899257328 | validation: 0.2672186741022873]
	TIME [epoch: 7.53 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471214380990056		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.2471214380990056 | validation: 0.22554265717578842]
	TIME [epoch: 7.48 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18212913474760226		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.18212913474760226 | validation: 0.125420112007138]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962741779706293		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.11962741779706293 | validation: 0.23716125773957292]
	TIME [epoch: 7.49 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899957617176472		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.1899957617176472 | validation: 0.13079432595613077]
	TIME [epoch: 7.51 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442756713241788		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.13442756713241788 | validation: 0.13483566723146478]
	TIME [epoch: 7.53 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20365937115039243		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.20365937115039243 | validation: 0.19495011452357291]
	TIME [epoch: 7.49 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896168943476536		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.1896168943476536 | validation: 0.27879725966224617]
	TIME [epoch: 7.49 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608973992086865		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.1608973992086865 | validation: 0.15454199385239892]
	TIME [epoch: 7.49 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613366525936255		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.1613366525936255 | validation: 0.1885579673088587]
	TIME [epoch: 7.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361950721682852		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.1361950721682852 | validation: 0.23682417973804656]
	TIME [epoch: 7.54 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17369688576809914		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.17369688576809914 | validation: 0.20421842703593107]
	TIME [epoch: 7.49 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528418888757168		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.1528418888757168 | validation: 0.16141732219425578]
	TIME [epoch: 7.49 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947871578609981		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.11947871578609981 | validation: 0.2634698620163619]
	TIME [epoch: 7.49 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15466549509959243		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.15466549509959243 | validation: 0.20173731892119823]
	TIME [epoch: 7.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16576117364455		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.16576117364455 | validation: 0.1777285788101344]
	TIME [epoch: 7.53 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15444683128040396		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.15444683128040396 | validation: 0.2128432149933735]
	TIME [epoch: 7.49 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15120073956831498		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.15120073956831498 | validation: 0.24660509925827254]
	TIME [epoch: 7.48 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051093450268672		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.13051093450268672 | validation: 0.1812145678902577]
	TIME [epoch: 7.51 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358693175969836		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.1358693175969836 | validation: 0.19178205553749877]
	TIME [epoch: 7.49 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19578229258914984		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.19578229258914984 | validation: 0.09564972664709448]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705396522124743		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.09705396522124743 | validation: 0.1055332476557245]
	TIME [epoch: 7.49 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15235268793831414		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.15235268793831414 | validation: 0.2326754373086713]
	TIME [epoch: 7.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798460293982114		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.1798460293982114 | validation: 0.15085404577025022]
	TIME [epoch: 7.48 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407333543186001		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.12407333543186001 | validation: 0.1336873992064951]
	TIME [epoch: 7.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307142175186571		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.1307142175186571 | validation: 0.12735177668652564]
	TIME [epoch: 7.54 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12751061500385413		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.12751061500385413 | validation: 0.1300676494059302]
	TIME [epoch: 7.48 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16187729247354704		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.16187729247354704 | validation: 0.15176376317718207]
	TIME [epoch: 7.48 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316228439451121		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.12316228439451121 | validation: 0.1688694889446481]
	TIME [epoch: 7.49 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479058110970446		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.13479058110970446 | validation: 0.13279963917823429]
	TIME [epoch: 7.51 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094795181933206		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.1094795181933206 | validation: 0.17799391684688914]
	TIME [epoch: 7.54 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15024280795514774		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.15024280795514774 | validation: 0.14645655633796806]
	TIME [epoch: 7.51 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11696426438993256		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.11696426438993256 | validation: 0.13376968581127846]
	TIME [epoch: 7.49 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12036947557199175		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.12036947557199175 | validation: 0.13259482748316687]
	TIME [epoch: 7.51 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622891128975507		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.1622891128975507 | validation: 0.10645564926445056]
	TIME [epoch: 7.51 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266798153738536		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.08266798153738536 | validation: 0.07582609180779432]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10535893613319969		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.10535893613319969 | validation: 0.13111169541058815]
	TIME [epoch: 7.54 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18607265108076956		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.18607265108076956 | validation: 0.15364558210972218]
	TIME [epoch: 7.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061171057389992		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.10061171057389992 | validation: 0.09075547447622923]
	TIME [epoch: 7.51 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802097455556839		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.10802097455556839 | validation: 0.15102097028248485]
	TIME [epoch: 7.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191507237754996		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.16191507237754996 | validation: 0.1258159331089564]
	TIME [epoch: 7.56 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066670555485299		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.1066670555485299 | validation: 0.1387024999073404]
	TIME [epoch: 7.53 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038697927156599		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.11038697927156599 | validation: 0.18497451113008698]
	TIME [epoch: 7.51 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15201543579069887		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.15201543579069887 | validation: 0.1326561323813109]
	TIME [epoch: 7.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933372106970297		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.11933372106970297 | validation: 0.17600374132127572]
	TIME [epoch: 7.54 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695134340997257		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.10695134340997257 | validation: 0.10505286065854355]
	TIME [epoch: 7.55 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201881992234113		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.11201881992234113 | validation: 0.12140929816605221]
	TIME [epoch: 7.53 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08836079825609987		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.08836079825609987 | validation: 0.09609950581286268]
	TIME [epoch: 7.49 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11548942947672525		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.11548942947672525 | validation: 0.1147788863120704]
	TIME [epoch: 7.53 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10816284156246156		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.10816284156246156 | validation: 0.2269249635259648]
	TIME [epoch: 7.54 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291735908622573		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.1291735908622573 | validation: 0.1034844090143937]
	TIME [epoch: 7.55 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927713095947352		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.09927713095947352 | validation: 0.22311119843120983]
	TIME [epoch: 7.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124910151191266		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.13124910151191266 | validation: 0.08118234634713335]
	TIME [epoch: 7.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07491663472639387		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.07491663472639387 | validation: 0.14799848062995957]
	TIME [epoch: 7.51 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183828092064855		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.15183828092064855 | validation: 0.13947104558777979]
	TIME [epoch: 7.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10511616170525136		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.10511616170525136 | validation: 0.07378128350629451]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345271952294367		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.08345271952294367 | validation: 0.0922232055530833]
	TIME [epoch: 7.51 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10015648224471253		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.10015648224471253 | validation: 0.20161827296107593]
	TIME [epoch: 7.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919305514835316		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.12919305514835316 | validation: 0.09632834699189904]
	TIME [epoch: 7.49 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07345247879254584		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.07345247879254584 | validation: 0.11118221767701902]
	TIME [epoch: 7.54 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935917913946535		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.09935917913946535 | validation: 0.1446161324100465]
	TIME [epoch: 7.52 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15058856329741743		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.15058856329741743 | validation: 0.07004876974393347]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187878701301892		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.06187878701301892 | validation: 0.11075982687831183]
	TIME [epoch: 7.49 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320580609905835		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.1320580609905835 | validation: 0.09941590960993751]
	TIME [epoch: 7.49 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07769049092178598		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.07769049092178598 | validation: 0.21271845749057106]
	TIME [epoch: 7.54 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307648553361897		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.1307648553361897 | validation: 0.10079816501367109]
	TIME [epoch: 7.53 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224151301467806		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.10224151301467806 | validation: 0.12432327003396343]
	TIME [epoch: 7.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09420407352800156		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.09420407352800156 | validation: 0.10356385481226346]
	TIME [epoch: 7.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12361847378263215		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.12361847378263215 | validation: 0.10619856945138063]
	TIME [epoch: 7.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323486154362162		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.07323486154362162 | validation: 0.10067620089582709]
	TIME [epoch: 7.53 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12874806393243626		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.12874806393243626 | validation: 0.09600236852143895]
	TIME [epoch: 7.53 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06780051549270252		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.06780051549270252 | validation: 0.0966298377345249]
	TIME [epoch: 7.49 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07054987976928727		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.07054987976928727 | validation: 0.09942288809323659]
	TIME [epoch: 7.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015026478551963		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.12015026478551963 | validation: 0.17302565084941215]
	TIME [epoch: 7.49 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285662137960962		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.1285662137960962 | validation: 0.10178630813033789]
	TIME [epoch: 7.53 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928557033180984		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.05928557033180984 | validation: 0.1096112230969741]
	TIME [epoch: 7.52 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108522766534423		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.108522766534423 | validation: 0.19907801451686963]
	TIME [epoch: 7.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10816188937191949		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.10816188937191949 | validation: 0.06837308644143625]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07779383882472428		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.07779383882472428 | validation: 0.13098040404512926]
	TIME [epoch: 7.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09806150152478897		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.09806150152478897 | validation: 0.07826600857510337]
	TIME [epoch: 7.51 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06906994439839051		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.06906994439839051 | validation: 0.1084140009901591]
	TIME [epoch: 132 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10738863542464777		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.10738863542464777 | validation: 0.10865435326881115]
	TIME [epoch: 15 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08717197582039687		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.08717197582039687 | validation: 0.06584562061868134]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06770382466269176		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.06770382466269176 | validation: 0.11533191148283278]
	TIME [epoch: 14.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715860225117475		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.11715860225117475 | validation: 0.07484661737590131]
	TIME [epoch: 14.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928551727414041		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.05928551727414041 | validation: 0.0966777906837353]
	TIME [epoch: 14.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10487053806077373		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.10487053806077373 | validation: 0.14434851636713328]
	TIME [epoch: 14.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507555037984293		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.09507555037984293 | validation: 0.07691903236026654]
	TIME [epoch: 14.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662493621021164		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.05662493621021164 | validation: 0.14893385191444852]
	TIME [epoch: 14.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10888660954366239		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.10888660954366239 | validation: 0.15451780732572243]
	TIME [epoch: 14.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07766764727008761		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.07766764727008761 | validation: 0.07118096419166249]
	TIME [epoch: 14.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06036891658665305		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.06036891658665305 | validation: 0.06930981136901933]
	TIME [epoch: 14.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248147704142278		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.10248147704142278 | validation: 0.182167461837958]
	TIME [epoch: 14.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890908456820405		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.09890908456820405 | validation: 0.05958138453754405]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711720672385339		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.0711720672385339 | validation: 0.14107439652877696]
	TIME [epoch: 14.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09563326311553529		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.09563326311553529 | validation: 0.07021131116880713]
	TIME [epoch: 14.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05189155797418514		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.05189155797418514 | validation: 0.07698036055560847]
	TIME [epoch: 14.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058613268768912895		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.058613268768912895 | validation: 0.1629336509318643]
	TIME [epoch: 14.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11171240075670003		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.11171240075670003 | validation: 0.0984158029260063]
	TIME [epoch: 14.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127365752298716		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.07127365752298716 | validation: 0.10600631940877275]
	TIME [epoch: 14.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172855776035616		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.09172855776035616 | validation: 0.11220806090671182]
	TIME [epoch: 14.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729074600116398		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.0729074600116398 | validation: 0.06617342287338035]
	TIME [epoch: 14.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740709360227662		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.0740709360227662 | validation: 0.08896500445304933]
	TIME [epoch: 14.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07649814854517809		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.07649814854517809 | validation: 0.09018160148928889]
	TIME [epoch: 14.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308497827358612		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.08308497827358612 | validation: 0.09197901821875268]
	TIME [epoch: 14.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659117724033283		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.0659117724033283 | validation: 0.10635677963079021]
	TIME [epoch: 14.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329889845671995		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.07329889845671995 | validation: 0.16132154156154138]
	TIME [epoch: 14.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748481949618425		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.08748481949618425 | validation: 0.05701322083036803]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07107395941826429		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.07107395941826429 | validation: 0.058533223684637384]
	TIME [epoch: 14.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04803355067218551		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.04803355067218551 | validation: 0.07926904074055016]
	TIME [epoch: 14.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102299039107405		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.11102299039107405 | validation: 0.0794912339688224]
	TIME [epoch: 14.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116538904999709		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.06116538904999709 | validation: 0.05702379388535822]
	TIME [epoch: 14.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803532974034557		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.0803532974034557 | validation: 0.12064483860747502]
	TIME [epoch: 14.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590806133576603		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.06590806133576603 | validation: 0.05470596753439319]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625644426214436		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.0625644426214436 | validation: 0.14098431189059676]
	TIME [epoch: 14.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361092453154676		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.09361092453154676 | validation: 0.08150996093176803]
	TIME [epoch: 14.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761645422449025		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.06761645422449025 | validation: 0.09389023159748651]
	TIME [epoch: 14.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08206901478997909		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.08206901478997909 | validation: 0.07310819907708445]
	TIME [epoch: 14.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06956875192105812		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.06956875192105812 | validation: 0.08641280008310531]
	TIME [epoch: 14.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028845149540477		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.07028845149540477 | validation: 0.07137297348673559]
	TIME [epoch: 14.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294726109806928		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.06294726109806928 | validation: 0.09009691109248025]
	TIME [epoch: 14.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08629071292959858		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.08629071292959858 | validation: 0.06785743661895512]
	TIME [epoch: 14.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06369977101421209		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.06369977101421209 | validation: 0.060649615943364245]
	TIME [epoch: 14.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07559623077756544		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.07559623077756544 | validation: 0.0691170762583807]
	TIME [epoch: 14.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061365140000356255		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.061365140000356255 | validation: 0.08898878937863855]
	TIME [epoch: 14.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07763517903085204		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.07763517903085204 | validation: 0.061594690880968986]
	TIME [epoch: 14.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235027499325345		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.05235027499325345 | validation: 0.05344480419664483]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872977888352696		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.0872977888352696 | validation: 0.06074422246528126]
	TIME [epoch: 14.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056739507345705126		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.056739507345705126 | validation: 0.06933838147799502]
	TIME [epoch: 14.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08333641764051868		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.08333641764051868 | validation: 0.0662573013031975]
	TIME [epoch: 14.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053409215000380206		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.053409215000380206 | validation: 0.06224222207954148]
	TIME [epoch: 14.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277187320374074		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.08277187320374074 | validation: 0.07227178339107215]
	TIME [epoch: 14.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05485273012994061		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.05485273012994061 | validation: 0.08341615054647998]
	TIME [epoch: 14.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211195045699566		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.06211195045699566 | validation: 0.10742243839474344]
	TIME [epoch: 14.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07611122984413635		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.07611122984413635 | validation: 0.0788559606601349]
	TIME [epoch: 14.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913393221390745		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.05913393221390745 | validation: 0.07344011057092333]
	TIME [epoch: 14.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057133947277147434		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.057133947277147434 | validation: 0.0530590625563125]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666185529704712		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.08666185529704712 | validation: 0.06804701865996754]
	TIME [epoch: 14.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052112875160767944		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.052112875160767944 | validation: 0.07051351132846173]
	TIME [epoch: 14.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07544252093934493		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.07544252093934493 | validation: 0.06532846631022066]
	TIME [epoch: 14.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812797106400054		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.06812797106400054 | validation: 0.051525839084145444]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445589042814951		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.0445589042814951 | validation: 0.09815989784649105]
	TIME [epoch: 14.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07820498785458839		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.07820498785458839 | validation: 0.050944153502629215]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061568047494301295		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.061568047494301295 | validation: 0.08456802299599687]
	TIME [epoch: 14.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303589468402331		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.07303589468402331 | validation: 0.06185960085369349]
	TIME [epoch: 14.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05766874636493794		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.05766874636493794 | validation: 0.05939078139006748]
	TIME [epoch: 14.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478549917200366		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.05478549917200366 | validation: 0.09733930750824851]
	TIME [epoch: 14.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803285668542165		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.07803285668542165 | validation: 0.059915720339864614]
	TIME [epoch: 14.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578412079379143		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.04578412079379143 | validation: 0.056295543295847655]
	TIME [epoch: 14.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840935801035003		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.06840935801035003 | validation: 0.08602841947432097]
	TIME [epoch: 14.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663262026016933		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.0663262026016933 | validation: 0.06670842746628179]
	TIME [epoch: 14.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542584973675208		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.0542584973675208 | validation: 0.053983201930188233]
	TIME [epoch: 14.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773432386696955		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.05773432386696955 | validation: 0.13218863168877357]
	TIME [epoch: 14.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0677258962613281		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.0677258962613281 | validation: 0.05708683892488632]
	TIME [epoch: 14.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943269366478204		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.06943269366478204 | validation: 0.05442728091619131]
	TIME [epoch: 14.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688399179231515		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.04688399179231515 | validation: 0.08006668343564069]
	TIME [epoch: 14.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06117899495769514		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.06117899495769514 | validation: 0.1390854232405236]
	TIME [epoch: 14.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564234102225257		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.06564234102225257 | validation: 0.0503074250184209]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06133056834815175		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.06133056834815175 | validation: 0.10187206799647269]
	TIME [epoch: 14.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191478345854295		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.06191478345854295 | validation: 0.05180107945198305]
	TIME [epoch: 14.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05652553773692755		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.05652553773692755 | validation: 0.11082549045174228]
	TIME [epoch: 14.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06485644421598		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.06485644421598 | validation: 0.050090736469501254]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04461135570550827		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.04461135570550827 | validation: 0.06138349099753269]
	TIME [epoch: 14.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07977376520385779		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.07977376520385779 | validation: 0.06021051819319405]
	TIME [epoch: 14.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529375186188724		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.0529375186188724 | validation: 0.07683002022280755]
	TIME [epoch: 14.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123076971895571		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.06123076971895571 | validation: 0.06452953180281495]
	TIME [epoch: 14.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055397235622207205		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.055397235622207205 | validation: 0.06914330504120134]
	TIME [epoch: 14.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569778427247807		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.04569778427247807 | validation: 0.05428654049486187]
	TIME [epoch: 14.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404499893756801		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.05404499893756801 | validation: 0.1419046323022683]
	TIME [epoch: 14.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099548693741312		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.07099548693741312 | validation: 0.06691939376707531]
	TIME [epoch: 14.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04699039498767396		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.04699039498767396 | validation: 0.04981205007796041]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045848183037265025		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.045848183037265025 | validation: 0.08027338710270486]
	TIME [epoch: 14.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107676361726288		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.08107676361726288 | validation: 0.06412414589082141]
	TIME [epoch: 14.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129584213094708		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.05129584213094708 | validation: 0.05889979232456076]
	TIME [epoch: 14.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069455958205038		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.05069455958205038 | validation: 0.08610151255610399]
	TIME [epoch: 14.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057706697780076664		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.057706697780076664 | validation: 0.05975552210539545]
	TIME [epoch: 14.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047455364467140444		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.047455364467140444 | validation: 0.09116724118030586]
	TIME [epoch: 14.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877283889560067		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.06877283889560067 | validation: 0.05002170023182236]
	TIME [epoch: 14.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04131595651789685		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.04131595651789685 | validation: 0.06082348040909836]
	TIME [epoch: 14.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05753770596451035		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.05753770596451035 | validation: 0.07796477180410465]
	TIME [epoch: 14.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560471899723454		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.05560471899723454 | validation: 0.0743317361498372]
	TIME [epoch: 14.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055694795550432524		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.055694795550432524 | validation: 0.04574840225260457]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047186912181360535		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.047186912181360535 | validation: 0.06669759141328725]
	TIME [epoch: 14.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06523301751524516		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.06523301751524516 | validation: 0.07667834425504585]
	TIME [epoch: 14.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04346844174381654		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.04346844174381654 | validation: 0.04208849510117659]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230733255083907		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.05230733255083907 | validation: 0.10899073249535146]
	TIME [epoch: 14.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061775245584645214		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.061775245584645214 | validation: 0.047619768841222605]
	TIME [epoch: 14.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051357481934706614		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.051357481934706614 | validation: 0.08240465709562958]
	TIME [epoch: 14.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05268848511157142		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.05268848511157142 | validation: 0.04660757360865439]
	TIME [epoch: 14.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791878616267692		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.04791878616267692 | validation: 0.06843142208437797]
	TIME [epoch: 14.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542743426438422		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.0542743426438422 | validation: 0.08926805848498245]
	TIME [epoch: 14.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060024295497693114		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.060024295497693114 | validation: 0.053513216645365694]
	TIME [epoch: 14.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052123814838458536		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.052123814838458536 | validation: 0.06515680567282789]
	TIME [epoch: 14.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043395444223071455		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.043395444223071455 | validation: 0.0733995306523901]
	TIME [epoch: 14.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295766215111816		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.06295766215111816 | validation: 0.07929654605440825]
	TIME [epoch: 14.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385483735897136		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.04385483735897136 | validation: 0.052100040868666514]
	TIME [epoch: 14.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04170784544666638		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.04170784544666638 | validation: 0.07560426793967626]
	TIME [epoch: 14.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450539567225526		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.0450539567225526 | validation: 0.04873601543709735]
	TIME [epoch: 14.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039248351680396		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.039248351680396 | validation: 0.08551471960469559]
	TIME [epoch: 14.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08629887107123907		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08629887107123907 | validation: 0.048476129313551455]
	TIME [epoch: 14.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713771840003161		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.03713771840003161 | validation: 0.049093542639807204]
	TIME [epoch: 14.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541974652175218		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.04541974652175218 | validation: 0.05088674973829334]
	TIME [epoch: 14.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06084873090320529		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.06084873090320529 | validation: 0.04216253671335278]
	TIME [epoch: 14.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04790775891330076		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.04790775891330076 | validation: 0.04190318676841709]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940803384709665		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.03940803384709665 | validation: 0.07260866085019353]
	TIME [epoch: 14.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472023078415612		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.06472023078415612 | validation: 0.04558634908783005]
	TIME [epoch: 14.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284632673896304		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.03284632673896304 | validation: 0.052511650581939975]
	TIME [epoch: 14.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046735183953878275		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.046735183953878275 | validation: 0.05523537907518292]
	TIME [epoch: 14.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0596382900328661		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.0596382900328661 | validation: 0.05226740508421747]
	TIME [epoch: 14.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041778611494977864		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.041778611494977864 | validation: 0.05945634046982956]
	TIME [epoch: 14.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043370497574211464		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.043370497574211464 | validation: 0.059521081086601854]
	TIME [epoch: 14.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952081286730486		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.05952081286730486 | validation: 0.0509288664297991]
	TIME [epoch: 14.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037148689476921515		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.037148689476921515 | validation: 0.047194702707490835]
	TIME [epoch: 14.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052556842547515345		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.052556842547515345 | validation: 0.07529552836550663]
	TIME [epoch: 14.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04665282579093366		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.04665282579093366 | validation: 0.055035191743321374]
	TIME [epoch: 14.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913241997153539		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.03913241997153539 | validation: 0.07609525673283223]
	TIME [epoch: 14.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271362315294092		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.06271362315294092 | validation: 0.06095163743678202]
	TIME [epoch: 14.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037963088180946104		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.037963088180946104 | validation: 0.052575050561700976]
	TIME [epoch: 14.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754793632779997		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.04754793632779997 | validation: 0.04123230351999953]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853750698537146		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.04853750698537146 | validation: 0.06980239490212584]
	TIME [epoch: 14.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148105982045328		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.05148105982045328 | validation: 0.045172289252193146]
	TIME [epoch: 14.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460652507326501		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.04460652507326501 | validation: 0.06147695236727365]
	TIME [epoch: 14.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956443849130349		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.04956443849130349 | validation: 0.0409217621383063]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034873351362992376		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.034873351362992376 | validation: 0.07163220860377964]
	TIME [epoch: 14.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366004794424059		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.06366004794424059 | validation: 0.05015502216329053]
	TIME [epoch: 14.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036092895932222174		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.036092895932222174 | validation: 0.04356022172303904]
	TIME [epoch: 14.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03973834765468217		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.03973834765468217 | validation: 0.06278001508880188]
	TIME [epoch: 14.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053218644546246995		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.053218644546246995 | validation: 0.03777061782357074]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034947332824547345		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.034947332824547345 | validation: 0.048798453816474414]
	TIME [epoch: 14.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050329443611342325		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.050329443611342325 | validation: 0.07912874810849829]
	TIME [epoch: 14.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381159748069958		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.04381159748069958 | validation: 0.04351265834851519]
	TIME [epoch: 14.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037373052924915516		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.037373052924915516 | validation: 0.0567806396360019]
	TIME [epoch: 14.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056802753149245225		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.056802753149245225 | validation: 0.05819771037630053]
	TIME [epoch: 14.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04211028109999068		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.04211028109999068 | validation: 0.038927104358187366]
	TIME [epoch: 14.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03547913220027479		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.03547913220027479 | validation: 0.05667518445947036]
	TIME [epoch: 14.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458023992459973		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.05458023992459973 | validation: 0.05297508218585159]
	TIME [epoch: 14.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039172674555462		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.039172674555462 | validation: 0.05014217483088304]
	TIME [epoch: 14.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040020306891466975		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.040020306891466975 | validation: 0.08405248628907516]
	TIME [epoch: 14.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025794089331243		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.05025794089331243 | validation: 0.042262253666240604]
	TIME [epoch: 14.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052160091665751626		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.052160091665751626 | validation: 0.03988327149741451]
	TIME [epoch: 14.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030369485124604044		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.030369485124604044 | validation: 0.04504192591071472]
	TIME [epoch: 14.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043218898349865316		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.043218898349865316 | validation: 0.06891661897846048]
	TIME [epoch: 14.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04427859813202903		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.04427859813202903 | validation: 0.048944159546351444]
	TIME [epoch: 14.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099699856157606		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.04099699856157606 | validation: 0.04363262161836001]
	TIME [epoch: 14.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126842198919279		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.03126842198919279 | validation: 0.052040463305462845]
	TIME [epoch: 14.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04543651329496002		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.04543651329496002 | validation: 0.06895902818919382]
	TIME [epoch: 14.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731819523007118		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.04731819523007118 | validation: 0.03982446037017873]
	TIME [epoch: 14.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040400933897437416		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.040400933897437416 | validation: 0.0671256619997085]
	TIME [epoch: 14.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455929335787779		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.0455929335787779 | validation: 0.04204256854588788]
	TIME [epoch: 14.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388302928691896		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.03388302928691896 | validation: 0.06165861345829356]
	TIME [epoch: 14.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056601343739471593		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.056601343739471593 | validation: 0.05502280873233602]
	TIME [epoch: 14.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035451408938481685		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.035451408938481685 | validation: 0.04404742106437069]
	TIME [epoch: 14.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166086979603596		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.03166086979603596 | validation: 0.04410360226321436]
	TIME [epoch: 14.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03540144963449193		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.03540144963449193 | validation: 0.0764273132987435]
	TIME [epoch: 14.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05198928935189483		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.05198928935189483 | validation: 0.06209208771621798]
	TIME [epoch: 14.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051139402889891175		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.051139402889891175 | validation: 0.04677237827486737]
	TIME [epoch: 14.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03765010150469396		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.03765010150469396 | validation: 0.050161316264778835]
	TIME [epoch: 14.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879630560445113		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.03879630560445113 | validation: 0.04664988029850299]
	TIME [epoch: 14.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03896249009489946		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.03896249009489946 | validation: 0.04348935932538775]
	TIME [epoch: 14.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03635297084232976		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.03635297084232976 | validation: 0.051661827989652104]
	TIME [epoch: 14.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112650489376747		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.04112650489376747 | validation: 0.04846633252969394]
	TIME [epoch: 14.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03521288370346152		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.03521288370346152 | validation: 0.05235494161313521]
	TIME [epoch: 14.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434089485909134		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.04434089485909134 | validation: 0.04767094090515672]
	TIME [epoch: 14.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02976386400246161		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.02976386400246161 | validation: 0.04880429699813897]
	TIME [epoch: 14.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024977439536242		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.04024977439536242 | validation: 0.05601714795262888]
	TIME [epoch: 14.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05229639541296449		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.05229639541296449 | validation: 0.036180507073267795]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028793652162404804		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.028793652162404804 | validation: 0.03877387699723156]
	TIME [epoch: 14.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803183405603859		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.03803183405603859 | validation: 0.05480762654526136]
	TIME [epoch: 14.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03953891811608287		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.03953891811608287 | validation: 0.04565342200527442]
	TIME [epoch: 14.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031152396658701512		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.031152396658701512 | validation: 0.048514562037598775]
	TIME [epoch: 14.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062316031038609		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.05062316031038609 | validation: 0.03473099488371663]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334360619171553		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.03334360619171553 | validation: 0.03906362059567245]
	TIME [epoch: 14.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543216361734662		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.03543216361734662 | validation: 0.03816500068162484]
	TIME [epoch: 14.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451795658512882		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.03451795658512882 | validation: 0.04516487202720372]
	TIME [epoch: 14.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414247764172119		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.0414247764172119 | validation: 0.03924951812538891]
	TIME [epoch: 14.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032224107051727714		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.032224107051727714 | validation: 0.039912764425774114]
	TIME [epoch: 14.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036611510157704856		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.036611510157704856 | validation: 0.06858563293505557]
	TIME [epoch: 14.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593933040826591		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.04593933040826591 | validation: 0.04216972555173168]
	TIME [epoch: 14.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137414645764376		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.04137414645764376 | validation: 0.05437051923579383]
	TIME [epoch: 14.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147130430949295		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.03147130430949295 | validation: 0.04073831069147468]
	TIME [epoch: 14.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02561296885007524		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.02561296885007524 | validation: 0.03564131945495557]
	TIME [epoch: 14.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053264947033757934		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.053264947033757934 | validation: 0.06274173974322865]
	TIME [epoch: 14.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033039504493351274		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.033039504493351274 | validation: 0.035760815962345344]
	TIME [epoch: 14.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027873567164596418		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.027873567164596418 | validation: 0.03670503235727679]
	TIME [epoch: 14.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028336548530623736		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.028336548530623736 | validation: 0.05951132403770513]
	TIME [epoch: 14.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056193446919970025		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.056193446919970025 | validation: 0.051925392615257665]
	TIME [epoch: 14.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030741472930285015		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.030741472930285015 | validation: 0.04222907224193512]
	TIME [epoch: 14.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553706040048317		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.03553706040048317 | validation: 0.03393143529541316]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025886465674454857		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.025886465674454857 | validation: 0.04012263708781448]
	TIME [epoch: 14.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536720325787762		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.03536720325787762 | validation: 0.06146449039436575]
	TIME [epoch: 14.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755005905566976		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.04755005905566976 | validation: 0.038951053330350344]
	TIME [epoch: 14.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02897009122409224		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.02897009122409224 | validation: 0.03631384746919886]
	TIME [epoch: 14.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03041711913645776		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.03041711913645776 | validation: 0.07498890839859007]
	TIME [epoch: 14.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342921847006531		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.04342921847006531 | validation: 0.03179548493671863]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029079566192855278		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.029079566192855278 | validation: 0.04414499892282413]
	TIME [epoch: 14.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306953087209104		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.03306953087209104 | validation: 0.052218988732333126]
	TIME [epoch: 14.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433836960739363		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.04433836960739363 | validation: 0.039084244360593504]
	TIME [epoch: 14.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028897687040111357		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.028897687040111357 | validation: 0.03434595929261515]
	TIME [epoch: 14.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031437259149379906		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.031437259149379906 | validation: 0.049405512033337665]
	TIME [epoch: 14.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632430369190588		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.03632430369190588 | validation: 0.0437434422354748]
	TIME [epoch: 14.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037173179287082185		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.037173179287082185 | validation: 0.07629284460662658]
	TIME [epoch: 14.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345830559455368		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.03345830559455368 | validation: 0.03496180670620741]
	TIME [epoch: 14.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026462876553607684		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.026462876553607684 | validation: 0.0351208719071549]
	TIME [epoch: 14.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0453379606580272		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.0453379606580272 | validation: 0.06934563411303649]
	TIME [epoch: 14.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033268441910624974		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.033268441910624974 | validation: 0.039397482485771754]
	TIME [epoch: 14.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504070197334941		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.03504070197334941 | validation: 0.030867646691860852]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349860509863269		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.03349860509863269 | validation: 0.040722435361401375]
	TIME [epoch: 14.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030963157893246773		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.030963157893246773 | validation: 0.03376787502695901]
	TIME [epoch: 14.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616652608694384		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.03616652608694384 | validation: 0.06409701254209076]
	TIME [epoch: 14.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03848224045594635		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.03848224045594635 | validation: 0.037831896353344725]
	TIME [epoch: 14.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027138197951873222		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.027138197951873222 | validation: 0.038484850218857405]
	TIME [epoch: 14.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893368682755508		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.03893368682755508 | validation: 0.038626209025444905]
	TIME [epoch: 14.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027572348762101812		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.027572348762101812 | validation: 0.04057379009069126]
	TIME [epoch: 14.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734708511410835		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.03734708511410835 | validation: 0.03518436798338315]
	TIME [epoch: 14.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02678874189360654		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.02678874189360654 | validation: 0.03018395338944555]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024446391283922817		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.024446391283922817 | validation: 0.04221519514640086]
	TIME [epoch: 14.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427063609856209		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.0427063609856209 | validation: 0.048503082406440974]
	TIME [epoch: 14.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03279770871958976		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.03279770871958976 | validation: 0.04768422734784941]
	TIME [epoch: 14.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036713968627936605		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.036713968627936605 | validation: 0.03755461572828854]
	TIME [epoch: 14.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024892892763409485		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.024892892763409485 | validation: 0.03237469078199717]
	TIME [epoch: 14.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026860449048420235		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.026860449048420235 | validation: 0.04938024533953665]
	TIME [epoch: 14.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045989647673974135		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.045989647673974135 | validation: 0.05261596643320923]
	TIME [epoch: 14.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026948564141353375		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.026948564141353375 | validation: 0.028953951945939402]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331151699787599		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.02331151699787599 | validation: 0.029752548341237514]
	TIME [epoch: 14.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620425819428701		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.03620425819428701 | validation: 0.05673931770654889]
	TIME [epoch: 14.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282346931958132		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.03282346931958132 | validation: 0.04612620144430339]
	TIME [epoch: 14.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029765528924624952		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.029765528924624952 | validation: 0.031096004347054538]
	TIME [epoch: 14.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02703858521508393		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.02703858521508393 | validation: 0.029529734606295176]
	TIME [epoch: 14.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026840778616568414		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.026840778616568414 | validation: 0.04893787784645378]
	TIME [epoch: 14.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235187123825713		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.04235187123825713 | validation: 0.04289037249804656]
	TIME [epoch: 14.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030734245646561048		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.030734245646561048 | validation: 0.029267874568554515]
	TIME [epoch: 14.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639093361431591		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.02639093361431591 | validation: 0.03397131258358707]
	TIME [epoch: 14.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02462730203888349		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.02462730203888349 | validation: 0.030641625811484042]
	TIME [epoch: 14.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505833333294828		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.03505833333294828 | validation: 0.0454642436274752]
	TIME [epoch: 14.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029082116382257155		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.029082116382257155 | validation: 0.03252485250359877]
	TIME [epoch: 14.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0238409396087585		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.0238409396087585 | validation: 0.03859260122422396]
	TIME [epoch: 14.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035368099318936655		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.035368099318936655 | validation: 0.05074017400173733]
	TIME [epoch: 14.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028195618821445678		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.028195618821445678 | validation: 0.03326233596645634]
	TIME [epoch: 14.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028285931861547934		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.028285931861547934 | validation: 0.0338865905156136]
	TIME [epoch: 14.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920673254211169		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.02920673254211169 | validation: 0.03896676117067332]
	TIME [epoch: 14.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328147553877399		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.0328147553877399 | validation: 0.03014998767424162]
	TIME [epoch: 14.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02208775543945269		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.02208775543945269 | validation: 0.03220412945120042]
	TIME [epoch: 14.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03243585307448969		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.03243585307448969 | validation: 0.04615760202807789]
	TIME [epoch: 14.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027975700930033612		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.027975700930033612 | validation: 0.05016590797530636]
	TIME [epoch: 14.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048285911425821997		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.048285911425821997 | validation: 0.037063280208941445]
	TIME [epoch: 14.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02885926954530731		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.02885926954530731 | validation: 0.028897371665226046]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02611532288752323		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.02611532288752323 | validation: 0.05681360904646043]
	TIME [epoch: 14.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126250353549332		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.03126250353549332 | validation: 0.037446457715601414]
	TIME [epoch: 14.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03095467526199619		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.03095467526199619 | validation: 0.032188675106487236]
	TIME [epoch: 14.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027868090820152066		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.027868090820152066 | validation: 0.031217946333959003]
	TIME [epoch: 14.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02701392470468584		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.02701392470468584 | validation: 0.03207360304310443]
	TIME [epoch: 14.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023849481263357106		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.023849481263357106 | validation: 0.03267993047095806]
	TIME [epoch: 14.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02637927676565844		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.02637927676565844 | validation: 0.042532323865927056]
	TIME [epoch: 14.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284195772783587		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.03284195772783587 | validation: 0.03274798368812164]
	TIME [epoch: 14.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02971105604797233		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.02971105604797233 | validation: 0.03309023068500893]
	TIME [epoch: 14.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025887901036561814		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.025887901036561814 | validation: 0.02937060761462118]
	TIME [epoch: 14.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023705641165206667		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.023705641165206667 | validation: 0.03751552208945347]
	TIME [epoch: 14.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032362500003513095		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.032362500003513095 | validation: 0.02773995782890441]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026234174602224505		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.026234174602224505 | validation: 0.04353024972337327]
	TIME [epoch: 14.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025297724341220074		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.025297724341220074 | validation: 0.029491590616006834]
	TIME [epoch: 14.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025785402267307196		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.025785402267307196 | validation: 0.050254826764496004]
	TIME [epoch: 14.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025301078606867068		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.025301078606867068 | validation: 0.026394331997308694]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024115330774563168		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.024115330774563168 | validation: 0.034113912232871094]
	TIME [epoch: 14.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607329778311884		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.02607329778311884 | validation: 0.02867900038420388]
	TIME [epoch: 14.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317772137968467		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.0317772137968467 | validation: 0.03667002007762687]
	TIME [epoch: 14.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02447877696376223		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.02447877696376223 | validation: 0.029061897339932037]
	TIME [epoch: 14.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027659508562282574		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.027659508562282574 | validation: 0.032763176953508624]
	TIME [epoch: 14.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025696700231745244		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.025696700231745244 | validation: 0.029683776383972762]
	TIME [epoch: 14.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0242389412056832		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.0242389412056832 | validation: 0.031314533305082506]
	TIME [epoch: 14.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024771874389750224		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.024771874389750224 | validation: 0.03200325593719298]
	TIME [epoch: 14.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030594665566787187		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.030594665566787187 | validation: 0.03770296794873855]
	TIME [epoch: 14.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02427683916610133		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.02427683916610133 | validation: 0.029079182609570497]
	TIME [epoch: 14.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024450210251986754		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.024450210251986754 | validation: 0.03156439288042716]
	TIME [epoch: 14.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024399143684486188		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.024399143684486188 | validation: 0.04359189564347886]
	TIME [epoch: 14.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02107086283406681		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.02107086283406681 | validation: 0.0329009359000729]
	TIME [epoch: 14.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03308722716210871		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.03308722716210871 | validation: 0.0346159780140257]
	TIME [epoch: 14.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02317034790616082		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.02317034790616082 | validation: 0.03274344907324041]
	TIME [epoch: 14.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02514763965007289		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.02514763965007289 | validation: 0.03212942535019975]
	TIME [epoch: 14.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026841649638088202		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.026841649638088202 | validation: 0.03220142359288056]
	TIME [epoch: 14.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021342534305164883		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.021342534305164883 | validation: 0.029978127089758378]
	TIME [epoch: 14.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365297342042545		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.02365297342042545 | validation: 0.030316936819809986]
	TIME [epoch: 142 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025224369352529984		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.025224369352529984 | validation: 0.035437302735412526]
	TIME [epoch: 32.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027130406329256056		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.027130406329256056 | validation: 0.026204723530072097]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020991815989143237		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.020991815989143237 | validation: 0.042233571651278265]
	TIME [epoch: 32.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030088607150951373		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.030088607150951373 | validation: 0.03439424569234681]
	TIME [epoch: 32.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023780706168949013		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.023780706168949013 | validation: 0.027128476256459675]
	TIME [epoch: 32.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021614230033174364		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.021614230033174364 | validation: 0.027630750166154284]
	TIME [epoch: 32.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473940799708578		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.02473940799708578 | validation: 0.03449382584014596]
	TIME [epoch: 32.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02501541676825941		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.02501541676825941 | validation: 0.024729141457377958]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020332431345263732		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.020332431345263732 | validation: 0.02364727261373595]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027424572290714856		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.027424572290714856 | validation: 0.04388825063122033]
	TIME [epoch: 32.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027136008562318775		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.027136008562318775 | validation: 0.03508325824657118]
	TIME [epoch: 32.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024384213432129282		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.024384213432129282 | validation: 0.02898552600062848]
	TIME [epoch: 32.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114057514171234		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.02114057514171234 | validation: 0.029841386571952885]
	TIME [epoch: 32.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026142599810998743		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.026142599810998743 | validation: 0.028441722161325046]
	TIME [epoch: 32.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023233073459059797		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.023233073459059797 | validation: 0.039573191299890564]
	TIME [epoch: 32.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02124229548619507		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.02124229548619507 | validation: 0.02720291789000054]
	TIME [epoch: 32.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02596549300631173		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.02596549300631173 | validation: 0.0281442163219955]
	TIME [epoch: 32.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198672251988828		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.02198672251988828 | validation: 0.028772536185086198]
	TIME [epoch: 32.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020037948190731163		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.020037948190731163 | validation: 0.026355931319933364]
	TIME [epoch: 32.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02537595696066546		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.02537595696066546 | validation: 0.028935182914438445]
	TIME [epoch: 32.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308844976246116		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.02308844976246116 | validation: 0.034424145949027526]
	TIME [epoch: 32.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590970441356893		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.02590970441356893 | validation: 0.033981464301224756]
	TIME [epoch: 32.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047745411832073		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.02047745411832073 | validation: 0.03138220420044519]
	TIME [epoch: 32.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02172529157457319		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.02172529157457319 | validation: 0.03917538826716602]
	TIME [epoch: 32.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024798769069998006		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.024798769069998006 | validation: 0.02793971982427993]
	TIME [epoch: 32.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017408173631480575		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.017408173631480575 | validation: 0.022902352379891827]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018623277114329324		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.018623277114329324 | validation: 0.049849099648648774]
	TIME [epoch: 32.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02716761679895326		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.02716761679895326 | validation: 0.027889202751596634]
	TIME [epoch: 32.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01952541661751294		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.01952541661751294 | validation: 0.029235075718697278]
	TIME [epoch: 32.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02097369428793227		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.02097369428793227 | validation: 0.03398271578742033]
	TIME [epoch: 32.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023382504468748053		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.023382504468748053 | validation: 0.02750473008224258]
	TIME [epoch: 32.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020663528111307568		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.020663528111307568 | validation: 0.023881216847419822]
	TIME [epoch: 32.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019447959387577703		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.019447959387577703 | validation: 0.025385129280523618]
	TIME [epoch: 32.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026959780659331183		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.026959780659331183 | validation: 0.03188412481953781]
	TIME [epoch: 32.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023387200647208808		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.023387200647208808 | validation: 0.029010863078538833]
	TIME [epoch: 32.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019019276632612978		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.019019276632612978 | validation: 0.02337673812672412]
	TIME [epoch: 32.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019093360168279366		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.019093360168279366 | validation: 0.04956628048169043]
	TIME [epoch: 32.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02562070179853829		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.02562070179853829 | validation: 0.02411131738192543]
	TIME [epoch: 32.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02256809175998589		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.02256809175998589 | validation: 0.032763444474154656]
	TIME [epoch: 32.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020471145859192547		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.020471145859192547 | validation: 0.029536141900577805]
	TIME [epoch: 32.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020963116700799006		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.020963116700799006 | validation: 0.02257039689072434]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019836410470521697		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.019836410470521697 | validation: 0.024156753557490016]
	TIME [epoch: 32.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018988094114185367		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.018988094114185367 | validation: 0.027787656356438067]
	TIME [epoch: 32.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02125051300395862		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.02125051300395862 | validation: 0.032330981579818334]
	TIME [epoch: 32.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253499410445952		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.02253499410445952 | validation: 0.03387141836513514]
	TIME [epoch: 32 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288072539520855		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.02288072539520855 | validation: 0.02648669855532132]
	TIME [epoch: 32.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0187416889267173		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.0187416889267173 | validation: 0.030465071180487593]
	TIME [epoch: 32.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023000563742616234		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.023000563742616234 | validation: 0.030549374675182178]
	TIME [epoch: 32.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019144705683961344		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.019144705683961344 | validation: 0.03130901959801388]
	TIME [epoch: 32.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02078510046697413		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.02078510046697413 | validation: 0.026106004881436475]
	TIME [epoch: 32 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01730566620014296		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.01730566620014296 | validation: 0.024135081983867795]
	TIME [epoch: 32.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01976469844409672		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.01976469844409672 | validation: 0.03622775701543127]
	TIME [epoch: 32.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020336104459726403		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.020336104459726403 | validation: 0.025305123553720284]
	TIME [epoch: 32.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022571420544007285		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.022571420544007285 | validation: 0.02753626086535524]
	TIME [epoch: 32 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018620203463844277		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.018620203463844277 | validation: 0.022424235546047888]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01858404091649249		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.01858404091649249 | validation: 0.037557758759104075]
	TIME [epoch: 32.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025379420687714642		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.025379420687714642 | validation: 0.029822723588158115]
	TIME [epoch: 32.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027783385600734546		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.027783385600734546 | validation: 0.07149536595182981]
	TIME [epoch: 32.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573213756035473		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.05573213756035473 | validation: 0.051881879491943894]
	TIME [epoch: 32 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744537833514052		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.03744537833514052 | validation: 0.03275572893405828]
	TIME [epoch: 32 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021244078076574836		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.021244078076574836 | validation: 0.03141546194452084]
	TIME [epoch: 32.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019603777809671277		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.019603777809671277 | validation: 0.02507221361981298]
	TIME [epoch: 32.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857954952800108		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.01857954952800108 | validation: 0.043362872530052034]
	TIME [epoch: 32.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02454908947109593		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.02454908947109593 | validation: 0.02626918639956343]
	TIME [epoch: 32 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017403979377488978		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.017403979377488978 | validation: 0.024751152509944523]
	TIME [epoch: 32 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017159916951495643		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.017159916951495643 | validation: 0.02447873626283806]
	TIME [epoch: 32.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024234702553734083		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.024234702553734083 | validation: 0.02424781424568608]
	TIME [epoch: 32.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016913430573845502		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.016913430573845502 | validation: 0.024566142567902093]
	TIME [epoch: 32 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017888459667285084		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.017888459667285084 | validation: 0.030181086443851896]
	TIME [epoch: 32.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373075361418821		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.02373075361418821 | validation: 0.026902700200781976]
	TIME [epoch: 32 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018469916317313248		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.018469916317313248 | validation: 0.026736122298312976]
	TIME [epoch: 32.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019018502972786067		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.019018502972786067 | validation: 0.020907245224323856]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01858193033234921		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.01858193033234921 | validation: 0.03482275928779936]
	TIME [epoch: 32.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020644284892680918		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.020644284892680918 | validation: 0.02048029243885119]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01907958215004834		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.01907958215004834 | validation: 0.047894739376767845]
	TIME [epoch: 32.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566427151277228		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.04566427151277228 | validation: 0.027244926358236804]
	TIME [epoch: 32.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022582289224368064		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.022582289224368064 | validation: 0.04908004907447367]
	TIME [epoch: 32.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02247426891241523		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.02247426891241523 | validation: 0.021009291507719775]
	TIME [epoch: 32 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016055058614904152		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.016055058614904152 | validation: 0.024526969173601185]
	TIME [epoch: 32 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831455528252513		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.01831455528252513 | validation: 0.026102946800340802]
	TIME [epoch: 32.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02158081952029197		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.02158081952029197 | validation: 0.029178952023133413]
	TIME [epoch: 32 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020158488955142453		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.020158488955142453 | validation: 0.022373624357217563]
	TIME [epoch: 32 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743353880549756		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.04743353880549756 | validation: 0.05617518627512607]
	TIME [epoch: 32 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06214435352905586		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.06214435352905586 | validation: 0.05176730689396898]
	TIME [epoch: 32 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475714091163719		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.0475714091163719 | validation: 0.0343021696221604]
	TIME [epoch: 32 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03021971270685419		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.03021971270685419 | validation: 0.024831088674388845]
	TIME [epoch: 32 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021142017164407993		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.021142017164407993 | validation: 0.02310455167862103]
	TIME [epoch: 32 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0195406244458891		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.0195406244458891 | validation: 0.021875175390031226]
	TIME [epoch: 32 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017760177525771515		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.017760177525771515 | validation: 0.020745971298564245]
	TIME [epoch: 32 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015907609414104577		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.015907609414104577 | validation: 0.02851781723542869]
	TIME [epoch: 32.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020592221973269414		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.020592221973269414 | validation: 0.027391339885778014]
	TIME [epoch: 32 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016451774663769923		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.016451774663769923 | validation: 0.022332813756623587]
	TIME [epoch: 32 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016085761339015313		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.016085761339015313 | validation: 0.02293753286882784]
	TIME [epoch: 31.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017198785235724323		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.017198785235724323 | validation: 0.03528673091120495]
	TIME [epoch: 32 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01909299447334519		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.01909299447334519 | validation: 0.019951673483571478]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016569767871240884		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.016569767871240884 | validation: 0.02473826911792841]
	TIME [epoch: 32 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02163294831917651		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.02163294831917651 | validation: 0.031058525231791957]
	TIME [epoch: 32 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017652726526911567		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.017652726526911567 | validation: 0.020047024905873647]
	TIME [epoch: 32 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015732169175175906		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.015732169175175906 | validation: 0.028410047647614137]
	TIME [epoch: 32 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021849361328394823		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.021849361328394823 | validation: 0.02454598268958555]
	TIME [epoch: 32 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016728184464873758		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.016728184464873758 | validation: 0.022340369438965786]
	TIME [epoch: 32.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688247684638321		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.01688247684638321 | validation: 0.02191567383857902]
	TIME [epoch: 32.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015885226841991035		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.015885226841991035 | validation: 0.02480322389572058]
	TIME [epoch: 32 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696712220081623		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.01696712220081623 | validation: 0.024920350798758775]
	TIME [epoch: 32 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932233415693764		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.01932233415693764 | validation: 0.02035470141596938]
	TIME [epoch: 32 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01776016136063282		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.01776016136063282 | validation: 0.032670055790739366]
	TIME [epoch: 32 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018398441687132498		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.018398441687132498 | validation: 0.021507231483382336]
	TIME [epoch: 32 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014975381349983245		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.014975381349983245 | validation: 0.02070810731072229]
	TIME [epoch: 32 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016723406990381003		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.016723406990381003 | validation: 0.022596839636083773]
	TIME [epoch: 32 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533681082956696		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.03533681082956696 | validation: 0.04063202555813247]
	TIME [epoch: 32 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022681490431575253		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.022681490431575253 | validation: 0.027825422026804048]
	TIME [epoch: 32 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016197615078494744		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.016197615078494744 | validation: 0.02191304830615598]
	TIME [epoch: 31.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590880926772558		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.01590880926772558 | validation: 0.02283789127942195]
	TIME [epoch: 31.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015660969090939947		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.015660969090939947 | validation: 0.025963449348947815]
	TIME [epoch: 32 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181408539597324		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.0181408539597324 | validation: 0.024737127193469866]
	TIME [epoch: 32 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014364855246368997		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.014364855246368997 | validation: 0.021626644960743874]
	TIME [epoch: 32 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020160613173141474		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.020160613173141474 | validation: 0.025515908453630783]
	TIME [epoch: 32 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016745883642499307		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.016745883642499307 | validation: 0.024069067947340813]
	TIME [epoch: 32 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015109505877631895		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.015109505877631895 | validation: 0.022707128559900005]
	TIME [epoch: 32 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016933545124687165		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.016933545124687165 | validation: 0.023286372916265653]
	TIME [epoch: 32.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01453692504148375		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.01453692504148375 | validation: 0.023989469255506164]
	TIME [epoch: 32 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017735813981255323		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.017735813981255323 | validation: 0.023234453157111923]
	TIME [epoch: 32 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016264538947708646		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.016264538947708646 | validation: 0.06040785166146494]
	TIME [epoch: 32 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04809307027594284		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.04809307027594284 | validation: 0.033842139598960666]
	TIME [epoch: 32 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486455716759758		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.02486455716759758 | validation: 0.018824499289844768]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015636760292702938		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.015636760292702938 | validation: 0.017729773590370958]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015308240724461162		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.015308240724461162 | validation: 0.02453028733608341]
	TIME [epoch: 32 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01917984280185006		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.01917984280185006 | validation: 0.01878301816885808]
	TIME [epoch: 32 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014162560921534785		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.014162560921534785 | validation: 0.019432255140516073]
	TIME [epoch: 32.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409592762952206		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.01409592762952206 | validation: 0.020715740635860003]
	TIME [epoch: 32 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01676133101778736		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.01676133101778736 | validation: 0.021937780240290514]
	TIME [epoch: 32 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018576039193767945		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.018576039193767945 | validation: 0.02336405751303268]
	TIME [epoch: 32 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01769271086032128		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.01769271086032128 | validation: 0.022155775750698298]
	TIME [epoch: 32 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01487917248213107		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.01487917248213107 | validation: 0.021653783403796388]
	TIME [epoch: 32.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015833842523306635		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.015833842523306635 | validation: 0.018429406223815004]
	TIME [epoch: 32.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014376491232614825		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.014376491232614825 | validation: 0.01986219111038618]
	TIME [epoch: 32.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015077454701712855		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.015077454701712855 | validation: 0.02194839002931545]
	TIME [epoch: 32 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01522818876245574		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.01522818876245574 | validation: 0.02087897644911224]
	TIME [epoch: 32.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018322024002489473		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.018322024002489473 | validation: 0.032603023030121844]
	TIME [epoch: 32.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016982248314770042		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.016982248314770042 | validation: 0.029886390046953776]
	TIME [epoch: 32.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018861300554839082		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.018861300554839082 | validation: 0.019202895620799493]
	TIME [epoch: 32 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013703941219727603		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.013703941219727603 | validation: 0.0179378036905998]
	TIME [epoch: 32 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01419858177156348		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.01419858177156348 | validation: 0.02642915252636401]
	TIME [epoch: 32.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01795850048430824		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.01795850048430824 | validation: 0.018311611581641386]
	TIME [epoch: 32.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01440651377940724		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.01440651377940724 | validation: 0.01988821217104836]
	TIME [epoch: 32.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015471284557416474		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.015471284557416474 | validation: 0.018903626965835495]
	TIME [epoch: 32 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014205033936957505		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.014205033936957505 | validation: 0.020377667541810286]
	TIME [epoch: 32 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014924233156057766		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.014924233156057766 | validation: 0.035190073758310084]
	TIME [epoch: 32.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018886511272913274		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.018886511272913274 | validation: 0.02238495362626995]
	TIME [epoch: 32.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01563126083956514		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.01563126083956514 | validation: 0.022274706499236838]
	TIME [epoch: 32 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0157132964378221		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.0157132964378221 | validation: 0.019992042630230876]
	TIME [epoch: 32 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013661831345102935		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.013661831345102935 | validation: 0.021373546318381686]
	TIME [epoch: 32.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01612382191902688		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.01612382191902688 | validation: 0.020538747568736856]
	TIME [epoch: 32.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014016479517351577		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.014016479517351577 | validation: 0.02279068057453817]
	TIME [epoch: 32.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01374053878813781		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.01374053878813781 | validation: 0.018907310800584484]
	TIME [epoch: 32.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016453908933280373		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.016453908933280373 | validation: 0.020287101307807857]
	TIME [epoch: 32 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01353803511720306		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.01353803511720306 | validation: 0.024685109619722433]
	TIME [epoch: 32.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017926233014467934		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.017926233014467934 | validation: 0.017964545899919984]
	TIME [epoch: 32.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013191499735146632		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.013191499735146632 | validation: 0.01814254652882716]
	TIME [epoch: 32 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017246061998993728		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.017246061998993728 | validation: 0.022583733518863502]
	TIME [epoch: 32 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013184400055824844		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.013184400055824844 | validation: 0.018001153406117923]
	TIME [epoch: 32 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01558793949923003		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.01558793949923003 | validation: 0.02044119169861304]
	TIME [epoch: 32.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013774124794387122		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.013774124794387122 | validation: 0.02014525109223635]
	TIME [epoch: 32.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012920479564481224		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.012920479564481224 | validation: 0.022231234556500737]
	TIME [epoch: 32.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015655126725675178		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.015655126725675178 | validation: 0.024920833924430487]
	TIME [epoch: 32.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015149051026223118		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.015149051026223118 | validation: 0.018723412587679157]
	TIME [epoch: 32.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014621879640975156		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.014621879640975156 | validation: 0.020157541243674217]
	TIME [epoch: 32.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015939359562942523		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.015939359562942523 | validation: 0.018116918024322096]
	TIME [epoch: 32.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014465420091024424		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.014465420091024424 | validation: 0.018207285995082558]
	TIME [epoch: 32.1 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016842503009733098		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.016842503009733098 | validation: 0.02160832239177071]
	TIME [epoch: 32 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015503170964465197		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.015503170964465197 | validation: 0.01806824606690424]
	TIME [epoch: 32.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013724203221816528		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.013724203221816528 | validation: 0.018159459365946762]
	TIME [epoch: 32.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012652668125230748		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.012652668125230748 | validation: 0.020640899892464117]
	TIME [epoch: 32 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017056125808277492		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.017056125808277492 | validation: 0.020762545746360717]
	TIME [epoch: 32 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01380435272558763		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.01380435272558763 | validation: 0.01813297545177398]
	TIME [epoch: 32 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013281787481692908		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.013281787481692908 | validation: 0.020405676692339298]
	TIME [epoch: 32 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016839770298467976		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.016839770298467976 | validation: 0.027482564759311018]
	TIME [epoch: 32.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017129816726125104		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.017129816726125104 | validation: 0.020859912766382487]
	TIME [epoch: 32.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01387083026758623		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.01387083026758623 | validation: 0.017499727657379317]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015416034050091544		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.015416034050091544 | validation: 0.01787570309434321]
	TIME [epoch: 32 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013598008394189648		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.013598008394189648 | validation: 0.01865852633736726]
	TIME [epoch: 32 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012952228096752387		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.012952228096752387 | validation: 0.017117503334054707]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013079118336295634		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.013079118336295634 | validation: 0.03410177282412528]
	TIME [epoch: 32 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01656817200102306		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.01656817200102306 | validation: 0.019787857503820346]
	TIME [epoch: 32 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014317059363210555		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.014317059363210555 | validation: 0.016701872126983687]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_686.pth
	Model improved!!!
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013117954449664938		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.013117954449664938 | validation: 0.01925462393027841]
	TIME [epoch: 32 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015438269796098653		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.015438269796098653 | validation: 0.019437893352788213]
	TIME [epoch: 32 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012774037803771541		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.012774037803771541 | validation: 0.016903745074254028]
	TIME [epoch: 32 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015896943915655735		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.015896943915655735 | validation: 0.020687144259887044]
	TIME [epoch: 32 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014737684928065877		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.014737684928065877 | validation: 0.019002466618420043]
	TIME [epoch: 32 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014035809164592081		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.014035809164592081 | validation: 0.021084035301107203]
	TIME [epoch: 32 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013524258594722272		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.013524258594722272 | validation: 0.021388061874708444]
	TIME [epoch: 32 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015357803032238377		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.015357803032238377 | validation: 0.01906266546841684]
	TIME [epoch: 32 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012468183068133036		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.012468183068133036 | validation: 0.019701436788456685]
	TIME [epoch: 32 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012729138523519963		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.012729138523519963 | validation: 0.018630726769116597]
	TIME [epoch: 32 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014160053756867807		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.014160053756867807 | validation: 0.02804916347921916]
	TIME [epoch: 32 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019828637508385805		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.019828637508385805 | validation: 0.018815882118991413]
	TIME [epoch: 32 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013090408030410255		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.013090408030410255 | validation: 0.020331332596228054]
	TIME [epoch: 32 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01288297111706801		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.01288297111706801 | validation: 0.01665475275627151]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012858531844877646		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.012858531844877646 | validation: 0.018265552880793155]
	TIME [epoch: 32 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013443461534221473		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.013443461534221473 | validation: 0.02158763355418402]
	TIME [epoch: 32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015965279871262623		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.015965279871262623 | validation: 0.018704504024295965]
	TIME [epoch: 32 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014114844486066062		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.014114844486066062 | validation: 0.01923518496177877]
	TIME [epoch: 32 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01296493805567793		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.01296493805567793 | validation: 0.01875089025567709]
	TIME [epoch: 32 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01374537858554701		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.01374537858554701 | validation: 0.018304498924298647]
	TIME [epoch: 32 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013414465740237837		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.013414465740237837 | validation: 0.02003427051924197]
	TIME [epoch: 32 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014066934231411714		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.014066934231411714 | validation: 0.02111482261093403]
	TIME [epoch: 32 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015364954700132678		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.015364954700132678 | validation: 0.020988997727801793]
	TIME [epoch: 32 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01359717537938515		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.01359717537938515 | validation: 0.020306586727541737]
	TIME [epoch: 32 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012732623656739758		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.012732623656739758 | validation: 0.017983286822251178]
	TIME [epoch: 32 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013186443120812921		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.013186443120812921 | validation: 0.02304359633037318]
	TIME [epoch: 32 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014421327085804202		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.014421327085804202 | validation: 0.018071381735679196]
	TIME [epoch: 32 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01275523600858234		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.01275523600858234 | validation: 0.017023580882595972]
	TIME [epoch: 32 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015501935370102615		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.015501935370102615 | validation: 0.02158137976262462]
	TIME [epoch: 32 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014817752790239228		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.014817752790239228 | validation: 0.016197292809348077]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013314300541851166		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.013314300541851166 | validation: 0.01907875148198227]
	TIME [epoch: 32 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013229420158996301		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.013229420158996301 | validation: 0.01854478598906906]
	TIME [epoch: 32 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013399551763957736		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.013399551763957736 | validation: 0.021096199183186608]
	TIME [epoch: 32 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01295722828761317		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.01295722828761317 | validation: 0.016878291094222106]
	TIME [epoch: 32 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012975324936862095		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.012975324936862095 | validation: 0.017232530127554373]
	TIME [epoch: 32 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0134579952680594		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0134579952680594 | validation: 0.02227485316601533]
	TIME [epoch: 32 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015206692609762597		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.015206692609762597 | validation: 0.01908374940918936]
	TIME [epoch: 32 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013229137148653147		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.013229137148653147 | validation: 0.018883353927161176]
	TIME [epoch: 32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012812503967567765		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.012812503967567765 | validation: 0.01837869591959709]
	TIME [epoch: 32 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012991514057246027		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.012991514057246027 | validation: 0.01635409493259249]
	TIME [epoch: 32 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012692086119182117		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.012692086119182117 | validation: 0.017490144874392245]
	TIME [epoch: 32 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0127524464907438		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.0127524464907438 | validation: 0.01777606813266394]
	TIME [epoch: 32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012209240932179715		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.012209240932179715 | validation: 0.01718520857406314]
	TIME [epoch: 32 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012600940916883137		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.012600940916883137 | validation: 0.019121895579810536]
	TIME [epoch: 32 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013394500265720522		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.013394500265720522 | validation: 0.015956766810138655]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013973729548406916		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.013973729548406916 | validation: 0.021285972556191607]
	TIME [epoch: 32.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014814782255346387		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.014814782255346387 | validation: 0.018294897917122598]
	TIME [epoch: 32 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012434705298437116		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.012434705298437116 | validation: 0.02098090292335348]
	TIME [epoch: 32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014191263620246924		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.014191263620246924 | validation: 0.018729323952768093]
	TIME [epoch: 32.1 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012767057635468329		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.012767057635468329 | validation: 0.016751590237298497]
	TIME [epoch: 32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012423682849519429		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.012423682849519429 | validation: 0.017509535621333852]
	TIME [epoch: 32 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013135906994647688		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.013135906994647688 | validation: 0.016992674739930002]
	TIME [epoch: 32 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011330130639950614		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.011330130639950614 | validation: 0.016739322454379375]
	TIME [epoch: 32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012677828524937282		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.012677828524937282 | validation: 0.01910253768535142]
	TIME [epoch: 32 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013440187137319447		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.013440187137319447 | validation: 0.018698139953775332]
	TIME [epoch: 32.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012937899840934214		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.012937899840934214 | validation: 0.016069395282626513]
	TIME [epoch: 32.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012719193058206141		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.012719193058206141 | validation: 0.01842881719788012]
	TIME [epoch: 32 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013117637226982188		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.013117637226982188 | validation: 0.018600660169802247]
	TIME [epoch: 32 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012649996150016793		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.012649996150016793 | validation: 0.017014070442117484]
	TIME [epoch: 32 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012324111272170037		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.012324111272170037 | validation: 0.017208416955254123]
	TIME [epoch: 32.1 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01264113809539704		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.01264113809539704 | validation: 0.018523785528006438]
	TIME [epoch: 32 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012801417009688456		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.012801417009688456 | validation: 0.019489167328807955]
	TIME [epoch: 32 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013648778271424019		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.013648778271424019 | validation: 0.015900563036191806]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_749.pth
	Model improved!!!
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012558005216406319		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.012558005216406319 | validation: 0.0161679635697414]
	TIME [epoch: 32.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011490654099521137		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.011490654099521137 | validation: 0.031144006065125875]
	TIME [epoch: 32.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02242136491943882		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.02242136491943882 | validation: 0.019343394981215366]
	TIME [epoch: 32.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012023335386386905		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.012023335386386905 | validation: 0.01797011040162703]
	TIME [epoch: 32 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012110905967005004		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.012110905967005004 | validation: 0.016480895364810507]
	TIME [epoch: 32.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01135535471911528		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.01135535471911528 | validation: 0.020183090793014894]
	TIME [epoch: 32.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01301718629840692		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.01301718629840692 | validation: 0.017650661197821695]
	TIME [epoch: 32.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01215488258178981		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.01215488258178981 | validation: 0.02119417174415457]
	TIME [epoch: 32 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012413473606794827		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.012413473606794827 | validation: 0.016402633537417055]
	TIME [epoch: 32 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014720473008302691		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.014720473008302691 | validation: 0.018283689734961344]
	TIME [epoch: 32.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012235863736429979		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.012235863736429979 | validation: 0.016142484406646947]
	TIME [epoch: 32.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011747369565016921		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.011747369565016921 | validation: 0.019037708082179063]
	TIME [epoch: 32.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011663899630816592		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.011663899630816592 | validation: 0.017314488933831768]
	TIME [epoch: 32.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012639732432942832		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.012639732432942832 | validation: 0.018993476160628207]
	TIME [epoch: 32 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012317287503936776		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.012317287503936776 | validation: 0.017391098446917948]
	TIME [epoch: 32.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012627545321763748		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.012627545321763748 | validation: 0.017481321587527358]
	TIME [epoch: 32.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01299785985498354		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.01299785985498354 | validation: 0.016141595853537544]
	TIME [epoch: 32.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012496328401856561		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.012496328401856561 | validation: 0.025181698185671397]
	TIME [epoch: 32 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019041493600642546		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.019041493600642546 | validation: 0.01871879466474495]
	TIME [epoch: 32 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01208673685661489		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.01208673685661489 | validation: 0.01533656501046645]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011675230221353184		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.011675230221353184 | validation: 0.01790304432194599]
	TIME [epoch: 32.1 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012059184544639601		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.012059184544639601 | validation: 0.017249716114879354]
	TIME [epoch: 32.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012239021071468785		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.012239021071468785 | validation: 0.01724714357778388]
	TIME [epoch: 32 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011723179510627488		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.011723179510627488 | validation: 0.016708536048812443]
	TIME [epoch: 32 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01186351018647374		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.01186351018647374 | validation: 0.018114321038289277]
	TIME [epoch: 32.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014403365977753779		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.014403365977753779 | validation: 0.016767870428760486]
	TIME [epoch: 32.1 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012241136851101024		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.012241136851101024 | validation: 0.014202747829892962]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010737112930041851		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.010737112930041851 | validation: 0.016057042059252926]
	TIME [epoch: 32 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012100916857638547		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.012100916857638547 | validation: 0.02050216277733901]
	TIME [epoch: 32 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01179821490371393		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.01179821490371393 | validation: 0.01680253314884736]
	TIME [epoch: 32.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010915115718947285		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.010915115718947285 | validation: 0.01850024783725801]
	TIME [epoch: 32 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012503465926096238		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.012503465926096238 | validation: 0.014359884384057924]
	TIME [epoch: 32 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01370562179300378		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.01370562179300378 | validation: 0.01605725856741765]
	TIME [epoch: 32 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01142032365984418		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.01142032365984418 | validation: 0.014602571559623412]
	TIME [epoch: 32 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011474472346377756		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.011474472346377756 | validation: 0.015270231709320976]
	TIME [epoch: 32.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011886420461551667		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.011886420461551667 | validation: 0.017368384687329805]
	TIME [epoch: 32.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011484527348246494		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.011484527348246494 | validation: 0.017654650454753364]
	TIME [epoch: 32 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01235961029275436		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.01235961029275436 | validation: 0.017650352824624585]
	TIME [epoch: 32 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011906713241557221		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.011906713241557221 | validation: 0.01652938583037577]
	TIME [epoch: 32.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011140981915208195		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.011140981915208195 | validation: 0.01750095290631384]
	TIME [epoch: 32 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011092058475097994		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.011092058475097994 | validation: 0.018639274085739656]
	TIME [epoch: 32.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012817255503960352		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.012817255503960352 | validation: 0.015514620294817517]
	TIME [epoch: 32.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011630511846563257		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.011630511846563257 | validation: 0.015808879548305926]
	TIME [epoch: 32 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012112482270261023		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.012112482270261023 | validation: 0.01835841323536656]
	TIME [epoch: 32.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011638664711862843		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.011638664711862843 | validation: 0.015432304391115103]
	TIME [epoch: 32.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0117328306658963		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0117328306658963 | validation: 0.019077381269260087]
	TIME [epoch: 32.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012536175023054758		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.012536175023054758 | validation: 0.015590412301150183]
	TIME [epoch: 32 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0114192306502763		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0114192306502763 | validation: 0.015452682081604817]
	TIME [epoch: 32 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011562369325137274		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.011562369325137274 | validation: 0.01905663850809778]
	TIME [epoch: 32.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011826994070381604		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.011826994070381604 | validation: 0.0172026863530738]
	TIME [epoch: 32.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011124461827142516		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.011124461827142516 | validation: 0.01604297025108674]
	TIME [epoch: 32.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011648016557642572		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.011648016557642572 | validation: 0.015173695065959978]
	TIME [epoch: 32 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01108539989468644		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.01108539989468644 | validation: 0.016595321393085886]
	TIME [epoch: 32 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01140260677857204		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.01140260677857204 | validation: 0.01624801403581988]
	TIME [epoch: 32.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011608779718382322		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.011608779718382322 | validation: 0.018103972608452625]
	TIME [epoch: 32.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016109502980613775		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.016109502980613775 | validation: 0.024943883944477656]
	TIME [epoch: 32 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01992047749101848		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.01992047749101848 | validation: 0.018589372817115493]
	TIME [epoch: 32.1 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015426795576058574		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.015426795576058574 | validation: 0.01583157635344465]
	TIME [epoch: 32 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012843817876141691		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.012843817876141691 | validation: 0.013910986893882052]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_808.pth
	Model improved!!!
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011493465081841632		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.011493465081841632 | validation: 0.015392429457241282]
	TIME [epoch: 32 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010910058146719394		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.010910058146719394 | validation: 0.013500759873660418]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011320789749020076		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.011320789749020076 | validation: 0.015469211672492725]
	TIME [epoch: 32 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011125428608966715		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.011125428608966715 | validation: 0.01781935738201386]
	TIME [epoch: 32 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010985308316684903		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.010985308316684903 | validation: 0.01577151647323391]
	TIME [epoch: 32 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010638208705629135		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.010638208705629135 | validation: 0.01334957191616257]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011611428191668542		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.011611428191668542 | validation: 0.014847386488291552]
	TIME [epoch: 32 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011076209664406214		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.011076209664406214 | validation: 0.016792843520665825]
	TIME [epoch: 32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013385818526719745		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.013385818526719745 | validation: 0.01634226421501129]
	TIME [epoch: 32 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010535437893835516		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.010535437893835516 | validation: 0.016387590254549535]
	TIME [epoch: 32 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011001698013624484		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.011001698013624484 | validation: 0.015884655129934967]
	TIME [epoch: 32 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011311607416881388		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.011311607416881388 | validation: 0.01738395903396497]
	TIME [epoch: 32 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012183139463927203		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.012183139463927203 | validation: 0.015545695490243332]
	TIME [epoch: 32 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010850365785701371		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.010850365785701371 | validation: 0.017389035641369295]
	TIME [epoch: 32 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011265537808885527		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.011265537808885527 | validation: 0.014231004370010562]
	TIME [epoch: 32 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0111471391624208		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0111471391624208 | validation: 0.013954517307137124]
	TIME [epoch: 32 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010447187579493481		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.010447187579493481 | validation: 0.014968141374502114]
	TIME [epoch: 32 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012391663286788273		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.012391663286788273 | validation: 0.014870727934915527]
	TIME [epoch: 32 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01088120998951657		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.01088120998951657 | validation: 0.015180466464448643]
	TIME [epoch: 32 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011257594415118588		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.011257594415118588 | validation: 0.0156181212466937]
	TIME [epoch: 32 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011072659171274271		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.011072659171274271 | validation: 0.01524415682129859]
	TIME [epoch: 32 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01096358754347737		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.01096358754347737 | validation: 0.014387663382819677]
	TIME [epoch: 32 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011321862233456628		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.011321862233456628 | validation: 0.01813698402268988]
	TIME [epoch: 32 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011785506620362332		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.011785506620362332 | validation: 0.016408968600338192]
	TIME [epoch: 32 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011486569556912647		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.011486569556912647 | validation: 0.014248209174954412]
	TIME [epoch: 32 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011049832899285544		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.011049832899285544 | validation: 0.015131239354698404]
	TIME [epoch: 32 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010384748624892696		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.010384748624892696 | validation: 0.01618721010631809]
	TIME [epoch: 32 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01032287051039952		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.01032287051039952 | validation: 0.014616365020728828]
	TIME [epoch: 32 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01181958868970522		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.01181958868970522 | validation: 0.015100388741132183]
	TIME [epoch: 32 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010341181713373268		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.010341181713373268 | validation: 0.014702083106893063]
	TIME [epoch: 32 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011415947501020709		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.011415947501020709 | validation: 0.01518008067430282]
	TIME [epoch: 32 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010757012065662631		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.010757012065662631 | validation: 0.016500797908763524]
	TIME [epoch: 32 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010829042979671957		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.010829042979671957 | validation: 0.014688867449015392]
	TIME [epoch: 32 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011171955647177888		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.011171955647177888 | validation: 0.016802965249015242]
	TIME [epoch: 32 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010458043660064571		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.010458043660064571 | validation: 0.015109539325042144]
	TIME [epoch: 32 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010933251336297604		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.010933251336297604 | validation: 0.016278156749098167]
	TIME [epoch: 32 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011261332852946645		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.011261332852946645 | validation: 0.015056934447570947]
	TIME [epoch: 32 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010829606391665445		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.010829606391665445 | validation: 0.019703042664961035]
	TIME [epoch: 32 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01125730437793049		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.01125730437793049 | validation: 0.014772237475694686]
	TIME [epoch: 32 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011099912668320864		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.011099912668320864 | validation: 0.014879677997489502]
	TIME [epoch: 32 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010836889749132292		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.010836889749132292 | validation: 0.01552671547226435]
	TIME [epoch: 32 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011730565539609097		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.011730565539609097 | validation: 0.015511315365653585]
	TIME [epoch: 32 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010712848408178263		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.010712848408178263 | validation: 0.015661460543279316]
	TIME [epoch: 32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010758345335797934		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.010758345335797934 | validation: 0.014166806516845869]
	TIME [epoch: 32 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011193574601614364		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.011193574601614364 | validation: 0.014841765566597335]
	TIME [epoch: 32 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010939708249584056		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.010939708249584056 | validation: 0.015387850705207417]
	TIME [epoch: 32 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011247743490457079		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.011247743490457079 | validation: 0.017239150320623238]
	TIME [epoch: 31.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011420371801129925		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.011420371801129925 | validation: 0.014748007521129189]
	TIME [epoch: 32 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01044800852465729		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.01044800852465729 | validation: 0.014646981774315483]
	TIME [epoch: 32 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01029423667300682		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.01029423667300682 | validation: 0.014778218342675543]
	TIME [epoch: 32 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011473365802918517		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.011473365802918517 | validation: 0.015543343075802843]
	TIME [epoch: 32 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011055313863099594		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.011055313863099594 | validation: 0.014817349778335478]
	TIME [epoch: 32 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010760751194405466		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.010760751194405466 | validation: 0.014973954573963416]
	TIME [epoch: 32 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010668359143296977		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.010668359143296977 | validation: 0.015436549277472256]
	TIME [epoch: 32 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010953563507248985		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.010953563507248985 | validation: 0.014841066664850524]
	TIME [epoch: 32 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009904833969672486		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.009904833969672486 | validation: 0.014754328450109313]
	TIME [epoch: 31.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011463124979775077		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.011463124979775077 | validation: 0.016148649206944938]
	TIME [epoch: 32 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010992113726904947		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.010992113726904947 | validation: 0.015926504971114596]
	TIME [epoch: 32.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010804621158678581		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.010804621158678581 | validation: 0.016190707159415632]
	TIME [epoch: 32.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010450195537788956		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.010450195537788956 | validation: 0.01539666365099767]
	TIME [epoch: 32.1 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010346479037285632		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.010346479037285632 | validation: 0.015542636347234613]
	TIME [epoch: 32 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01029759958175556		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.01029759958175556 | validation: 0.014172439917038418]
	TIME [epoch: 32.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010203248222508517		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.010203248222508517 | validation: 0.014504359361625332]
	TIME [epoch: 32.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011061927818671935		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.011061927818671935 | validation: 0.01533814992422374]
	TIME [epoch: 32.1 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01026430212411795		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.01026430212411795 | validation: 0.01582894855779632]
	TIME [epoch: 32.1 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011234952581437778		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.011234952581437778 | validation: 0.014110977642493552]
	TIME [epoch: 32.1 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010469948817367462		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.010469948817367462 | validation: 0.014657403230649894]
	TIME [epoch: 32.1 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010296798005697426		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.010296798005697426 | validation: 0.014276826148501152]
	TIME [epoch: 32.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010343334370138008		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.010343334370138008 | validation: 0.015799493142023936]
	TIME [epoch: 32.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010548095117091294		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.010548095117091294 | validation: 0.015231614699750073]
	TIME [epoch: 32 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010572542509481683		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.010572542509481683 | validation: 0.01492433424585409]
	TIME [epoch: 32 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010640055650974431		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.010640055650974431 | validation: 0.01512917870124944]
	TIME [epoch: 32.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010168863361385491		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.010168863361385491 | validation: 0.0164400082463409]
	TIME [epoch: 32.1 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01074545451565171		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.01074545451565171 | validation: 0.014064200150992833]
	TIME [epoch: 32.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010773418298322894		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.010773418298322894 | validation: 0.01705214270535821]
	TIME [epoch: 32 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010536994140628572		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.010536994140628572 | validation: 0.014432319553601315]
	TIME [epoch: 32 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010526522295229256		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.010526522295229256 | validation: 0.014636412801238655]
	TIME [epoch: 32.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011377061112694018		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.011377061112694018 | validation: 0.01449280006590651]
	TIME [epoch: 32.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010378209812384815		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.010378209812384815 | validation: 0.01511705375310526]
	TIME [epoch: 32.1 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01029584296569632		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.01029584296569632 | validation: 0.015444401364294053]
	TIME [epoch: 32 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010400287206994914		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.010400287206994914 | validation: 0.017627015593741722]
	TIME [epoch: 32.1 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011854587811151123		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.011854587811151123 | validation: 0.014294906280156582]
	TIME [epoch: 32.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010079436466821426		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.010079436466821426 | validation: 0.014825364058822284]
	TIME [epoch: 32.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010089609347685373		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.010089609347685373 | validation: 0.01386532009504565]
	TIME [epoch: 32.1 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01017631541472263		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.01017631541472263 | validation: 0.014144389402061804]
	TIME [epoch: 32.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010081465067487463		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.010081465067487463 | validation: 0.016219827316250154]
	TIME [epoch: 32.1 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010368833143000179		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.010368833143000179 | validation: 0.01448314841810178]
	TIME [epoch: 32.1 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010487002004386861		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.010487002004386861 | validation: 0.01341374352201715]
	TIME [epoch: 32.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010157804206408508		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.010157804206408508 | validation: 0.015292904879179042]
	TIME [epoch: 32.1 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01091416589159517		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.01091416589159517 | validation: 0.016365905043738718]
	TIME [epoch: 32 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010848650314715469		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.010848650314715469 | validation: 0.015152725864952258]
	TIME [epoch: 32.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010564500793395331		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.010564500793395331 | validation: 0.014064073213419022]
	TIME [epoch: 32.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010078387531752542		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.010078387531752542 | validation: 0.014404956919690248]
	TIME [epoch: 32.1 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010724644403049141		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.010724644403049141 | validation: 0.014944270679651483]
	TIME [epoch: 32 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01119631149661543		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.01119631149661543 | validation: 0.014451449093751394]
	TIME [epoch: 32 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009813178368895413		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.009813178368895413 | validation: 0.01341548851541629]
	TIME [epoch: 32 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009886701076056567		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.009886701076056567 | validation: 0.014037527765678631]
	TIME [epoch: 32.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009943679668294292		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.009943679668294292 | validation: 0.026451886617188735]
	TIME [epoch: 32.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014242230457329627		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.014242230457329627 | validation: 0.015029247286755672]
	TIME [epoch: 32 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010663147350491915		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.010663147350491915 | validation: 0.013674402699563269]
	TIME [epoch: 32 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010068686978311968		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.010068686978311968 | validation: 0.013807691689418486]
	TIME [epoch: 32.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01000792088121894		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.01000792088121894 | validation: 0.014408101515934952]
	TIME [epoch: 32.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010244014493872076		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.010244014493872076 | validation: 0.015123942921160528]
	TIME [epoch: 32.1 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010466442374576062		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.010466442374576062 | validation: 0.014352135066410372]
	TIME [epoch: 32 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010010752561922997		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.010010752561922997 | validation: 0.014943220727858822]
	TIME [epoch: 32 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010330671526233326		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.010330671526233326 | validation: 0.015361057561290116]
	TIME [epoch: 32.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010351208277719038		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.010351208277719038 | validation: 0.01503079565409366]
	TIME [epoch: 32.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd7_20240708_191953/states/model_phi1_1a_v_mmd7_915.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 19711.002 seconds.
