Args:
Namespace(name='model_phi1_1a_v_kl2', outdir='out/model_training/model_phi1_1a_v_kl2', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=10.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 271770526

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.294263381146559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.294263381146559 | validation: 12.648282751607681]
	TIME [epoch: 100 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.000253094688093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.000253094688093 | validation: 12.672029762142602]
	TIME [epoch: 8.18 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.887991862648052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.887991862648052 | validation: 12.151031516845809]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.323767697911912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.323767697911912 | validation: 12.210587820018922]
	TIME [epoch: 8.12 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.10000512835297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.10000512835297 | validation: 11.690337742697015]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.8976505056155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.8976505056155 | validation: 11.613657774411422]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.717467756402424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.717467756402424 | validation: 11.44934545623401]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.349145928925884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.349145928925884 | validation: 11.314959198886406]
	TIME [epoch: 8.17 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.142796293294566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.142796293294566 | validation: 11.217607862846425]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.930541110007294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.930541110007294 | validation: 11.113680728669536]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.684266741477007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.684266741477007 | validation: 11.161837499735526]
	TIME [epoch: 8.12 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.620423829279982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.620423829279982 | validation: 10.807607113289333]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.334215085848362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.334215085848362 | validation: 9.73424363569276]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.082374125364014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.082374125364014 | validation: 9.065554586149094]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.701630281271412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.701630281271412 | validation: 8.728668441375348]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.032830641129843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.032830641129843 | validation: 7.8425535795811925]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.669700254261361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.669700254261361 | validation: 7.582581196740351]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.29810233626428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.29810233626428 | validation: 7.638848961424737]
	TIME [epoch: 8.15 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.425037093962247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.425037093962247 | validation: 7.910123433341378]
	TIME [epoch: 8.14 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.367906975499545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.367906975499545 | validation: 7.348866231711261]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.068055589956578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.068055589956578 | validation: 7.164699908456651]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.932580329629258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.932580329629258 | validation: 7.0793580302182075]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.916891737675415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.916891737675415 | validation: 7.021611152710534]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9726791750311365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9726791750311365 | validation: 7.021756610248578]
	TIME [epoch: 8.19 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.814647006994072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.814647006994072 | validation: 6.948548425885765]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.686295451108831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.686295451108831 | validation: 6.886193617814493]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5711068462935325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5711068462935325 | validation: 6.4857654178993025]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.222130544276742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.222130544276742 | validation: 6.162635273229947]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.390486492191712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.390486492191712 | validation: 8.309304041670815]
	TIME [epoch: 8.17 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.4504402510979855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4504402510979855 | validation: 7.457018715464908]
	TIME [epoch: 8.13 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.356243592022912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.356243592022912 | validation: 5.579988330732915]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.629761316988494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.629761316988494 | validation: 5.359439806184363]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.404637348380656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.404637348380656 | validation: 6.0716300120656745]
	TIME [epoch: 8.15 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.934421758363369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.934421758363369 | validation: 4.9833684375664635]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.236219675891807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.236219675891807 | validation: 4.652658676249044]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.167751504726246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.167751504726246 | validation: 4.434020354883881]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.867196293557887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.867196293557887 | validation: 4.038470189652932]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6229819301597086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6229819301597086 | validation: 4.535570709690699]
	TIME [epoch: 8.13 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.879114934053741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.879114934053741 | validation: 4.849402025399462]
	TIME [epoch: 8.11 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5778053223328996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5778053223328996 | validation: 3.035725859352552]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.204280155274281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.204280155274281 | validation: 5.871542598630176]
	TIME [epoch: 8.14 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.185164761799133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.185164761799133 | validation: 3.8783788218992967]
	TIME [epoch: 8.12 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.604170155760231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.604170155760231 | validation: 4.615770388385482]
	TIME [epoch: 8.12 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.671298993752771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.671298993752771 | validation: 3.036911062692216]
	TIME [epoch: 8.11 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8732112370761227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8732112370761227 | validation: 3.499120216182426]
	TIME [epoch: 8.12 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0777029866045185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0777029866045185 | validation: 10.76544614342092]
	TIME [epoch: 8.15 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.30243639103065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.30243639103065 | validation: 10.659986879609612]
	TIME [epoch: 8.12 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.235468655492044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.235468655492044 | validation: 10.635338202144718]
	TIME [epoch: 8.12 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.199123796188568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.199123796188568 | validation: 10.595874410187076]
	TIME [epoch: 8.12 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.14130545941893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.14130545941893 | validation: 10.392600058975558]
	TIME [epoch: 8.11 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.886425249720393		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 8.886425249720393 | validation: 10.12555993211902]
	TIME [epoch: 8.14 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.696623164437804		[learning rate: 0.0099588]
	Learning Rate: 0.00995876
	LOSS [training: 7.696623164437804 | validation: 7.853897493339259]
	TIME [epoch: 8.15 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.973173146711346		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 5.973173146711346 | validation: 6.410330495701498]
	TIME [epoch: 8.12 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.027556945046626		[learning rate: 0.0099118]
	Learning Rate: 0.00991183
	LOSS [training: 5.027556945046626 | validation: 6.150805577329393]
	TIME [epoch: 8.12 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.733125890281942		[learning rate: 0.0098884]
	Learning Rate: 0.00988845
	LOSS [training: 4.733125890281942 | validation: 6.428249796955651]
	TIME [epoch: 8.12 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.992747532841063		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 4.992747532841063 | validation: 5.724047237878596]
	TIME [epoch: 8.12 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.880447664577443		[learning rate: 0.0098419]
	Learning Rate: 0.00984185
	LOSS [training: 7.880447664577443 | validation: 11.84389136782788]
	TIME [epoch: 8.16 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.518816602303088		[learning rate: 0.0098186]
	Learning Rate: 0.00981864
	LOSS [training: 10.518816602303088 | validation: 11.687420752544647]
	TIME [epoch: 8.13 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.226539873148042		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 10.226539873148042 | validation: 10.989161942083816]
	TIME [epoch: 8.12 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.803996523181098		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 9.803996523181098 | validation: 10.519011676455808]
	TIME [epoch: 8.12 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.178332666172388		[learning rate: 0.0097493]
	Learning Rate: 0.00974932
	LOSS [training: 9.178332666172388 | validation: 8.430449306493584]
	TIME [epoch: 8.12 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.273839041060047		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 8.273839041060047 | validation: 8.815261887520421]
	TIME [epoch: 8.12 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.023230050350643		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 8.023230050350643 | validation: 6.94904166385687]
	TIME [epoch: 8.16 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.345841034852452		[learning rate: 0.0096805]
	Learning Rate: 0.00968049
	LOSS [training: 5.345841034852452 | validation: 3.414227848188888]
	TIME [epoch: 8.12 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.089916059396086		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 3.089916059396086 | validation: 2.7169151794084616]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.833885315807354		[learning rate: 0.0096349]
	Learning Rate: 0.00963488
	LOSS [training: 2.833885315807354 | validation: 2.6866322436220216]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793157724358146		[learning rate: 0.0096121]
	Learning Rate: 0.00961215
	LOSS [training: 2.793157724358146 | validation: 3.9725121017326783]
	TIME [epoch: 8.11 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106241228224963		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 3.2106241228224963 | validation: 2.5558899106889097]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6349397897751143		[learning rate: 0.0095669]
	Learning Rate: 0.00956686
	LOSS [training: 2.6349397897751143 | validation: 2.8825986552329783]
	TIME [epoch: 8.15 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.788861626284975		[learning rate: 0.0095443]
	Learning Rate: 0.00954429
	LOSS [training: 2.788861626284975 | validation: 2.8076622022053357]
	TIME [epoch: 8.11 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5606418224357927		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 2.5606418224357927 | validation: 2.5704233816102375]
	TIME [epoch: 8.12 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397654287116616		[learning rate: 0.0094993]
	Learning Rate: 0.00949931
	LOSS [training: 2.397654287116616 | validation: 2.289933189360749]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5385787548350676		[learning rate: 0.0094769]
	Learning Rate: 0.00947691
	LOSS [training: 2.5385787548350676 | validation: 2.424881794083414]
	TIME [epoch: 8.12 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313611250637513		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 2.313611250637513 | validation: 3.293888997833668]
	TIME [epoch: 8.16 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4193858204899503		[learning rate: 0.0094323]
	Learning Rate: 0.00943225
	LOSS [training: 2.4193858204899503 | validation: 2.846072356010432]
	TIME [epoch: 8.12 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9987437008296487		[learning rate: 0.00941]
	Learning Rate: 0.00941
	LOSS [training: 2.9987437008296487 | validation: 3.512258536226841]
	TIME [epoch: 8.13 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.647687741822267		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 2.647687741822267 | validation: 2.86099379506585]
	TIME [epoch: 8.12 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3397204693421627		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 2.3397204693421627 | validation: 2.167737871904118]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169863823109456		[learning rate: 0.0093436]
	Learning Rate: 0.00934357
	LOSS [training: 2.169863823109456 | validation: 2.1410834155404177]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.237091883160412		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 2.237091883160412 | validation: 2.1833380438838637]
	TIME [epoch: 8.15 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.198193446968869		[learning rate: 0.0092995]
	Learning Rate: 0.00929954
	LOSS [training: 2.198193446968869 | validation: 4.065089695485719]
	TIME [epoch: 8.12 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5602305701933785		[learning rate: 0.0092776]
	Learning Rate: 0.00927761
	LOSS [training: 2.5602305701933785 | validation: 2.0184049930002588]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.161423327872224		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 2.161423327872224 | validation: 2.2577413774171964]
	TIME [epoch: 8.12 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.810625834179502		[learning rate: 0.0092339]
	Learning Rate: 0.00923389
	LOSS [training: 1.810625834179502 | validation: 2.0706646694965034]
	TIME [epoch: 8.12 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3940483331763485		[learning rate: 0.0092121]
	Learning Rate: 0.00921211
	LOSS [training: 2.3940483331763485 | validation: 3.3723364125453568]
	TIME [epoch: 8.16 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375193481837382		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 2.375193481837382 | validation: 3.222202874326616]
	TIME [epoch: 8.13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0430083045029197		[learning rate: 0.0091687]
	Learning Rate: 0.0091687
	LOSS [training: 2.0430083045029197 | validation: 1.9450672443033192]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.865706704409142		[learning rate: 0.0091471]
	Learning Rate: 0.00914707
	LOSS [training: 1.865706704409142 | validation: 2.2452809134505474]
	TIME [epoch: 8.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0873145293441064		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 2.0873145293441064 | validation: 2.0043352751745287]
	TIME [epoch: 8.11 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9824088897009182		[learning rate: 0.009104]
	Learning Rate: 0.00910397
	LOSS [training: 1.9824088897009182 | validation: 1.7765507377261476]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.693314424681919		[learning rate: 0.0090825]
	Learning Rate: 0.00908249
	LOSS [training: 1.693314424681919 | validation: 2.8889798698772067]
	TIME [epoch: 8.16 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9423831737224806		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 1.9423831737224806 | validation: 1.8752560123329718]
	TIME [epoch: 8.12 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7810636682103704		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 1.7810636682103704 | validation: 1.9332644582236516]
	TIME [epoch: 8.12 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9008965314846227		[learning rate: 0.0090184]
	Learning Rate: 0.00901837
	LOSS [training: 1.9008965314846227 | validation: 2.335952721829988]
	TIME [epoch: 8.11 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9972222567740205		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 1.9972222567740205 | validation: 1.6734751241443382]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6263470178011883		[learning rate: 0.0089759]
	Learning Rate: 0.00897588
	LOSS [training: 1.6263470178011883 | validation: 2.1934629277276354]
	TIME [epoch: 8.16 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1797738446512884		[learning rate: 0.0089547]
	Learning Rate: 0.0089547
	LOSS [training: 2.1797738446512884 | validation: 1.9182113758317954]
	TIME [epoch: 8.14 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.537910097463533		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 1.537910097463533 | validation: 1.9918312794756265]
	TIME [epoch: 8.11 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9183340868193803		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 1.9183340868193803 | validation: 2.89486856402021]
	TIME [epoch: 8.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1360420545774788		[learning rate: 0.0088915]
	Learning Rate: 0.00889149
	LOSS [training: 2.1360420545774788 | validation: 2.2382852464221923]
	TIME [epoch: 8.12 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.66066449788783		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 1.66066449788783 | validation: 3.077590031500887]
	TIME [epoch: 8.13 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.022765847286987		[learning rate: 0.0088496]
	Learning Rate: 0.00884959
	LOSS [training: 2.022765847286987 | validation: 1.8954180858559542]
	TIME [epoch: 8.16 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.498388706760725		[learning rate: 0.0088287]
	Learning Rate: 0.00882871
	LOSS [training: 1.498388706760725 | validation: 2.1033312771734676]
	TIME [epoch: 8.13 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739681922739057		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 1.739681922739057 | validation: 1.8695301768937194]
	TIME [epoch: 8.12 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4464338843825493		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 1.4464338843825493 | validation: 2.6119530745065394]
	TIME [epoch: 8.12 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9275216727484086		[learning rate: 0.0087664]
	Learning Rate: 0.00876638
	LOSS [training: 1.9275216727484086 | validation: 1.573290774951242]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343076751981922		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 1.343076751981922 | validation: 2.0937176937052366]
	TIME [epoch: 8.14 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8369645387275377		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 1.8369645387275377 | validation: 1.4969626057566052]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7577404120547093		[learning rate: 0.0087045]
	Learning Rate: 0.00870449
	LOSS [training: 1.7577404120547093 | validation: 1.9271069346018788]
	TIME [epoch: 8.12 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4844857008966554		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 1.4844857008966554 | validation: 1.591773327190781]
	TIME [epoch: 8.12 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7860353189955227		[learning rate: 0.0086635]
	Learning Rate: 0.00866348
	LOSS [training: 1.7860353189955227 | validation: 1.4986585292309849]
	TIME [epoch: 8.12 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4934676657836328		[learning rate: 0.008643]
	Learning Rate: 0.00864304
	LOSS [training: 1.4934676657836328 | validation: 1.53082484723353]
	TIME [epoch: 8.12 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.45021347365285		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 1.45021347365285 | validation: 1.5214739790132874]
	TIME [epoch: 8.16 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124326445964764		[learning rate: 0.0086023]
	Learning Rate: 0.00860232
	LOSS [training: 2.124326445964764 | validation: 2.179082501368903]
	TIME [epoch: 8.13 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1463466594801996		[learning rate: 0.008582]
	Learning Rate: 0.00858202
	LOSS [training: 2.1463466594801996 | validation: 2.055253748880109]
	TIME [epoch: 8.12 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6841462461930305		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 1.6841462461930305 | validation: 2.6233779209727173]
	TIME [epoch: 8.12 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5689416299877714		[learning rate: 0.0085416]
	Learning Rate: 0.00854158
	LOSS [training: 1.5689416299877714 | validation: 1.6225356549778867]
	TIME [epoch: 8.12 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5094720395169072		[learning rate: 0.0085214]
	Learning Rate: 0.00852144
	LOSS [training: 1.5094720395169072 | validation: 1.554177337734239]
	TIME [epoch: 8.13 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7208758230108858		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 1.7208758230108858 | validation: 1.7066777658577006]
	TIME [epoch: 8.15 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.472189768623408		[learning rate: 0.0084813]
	Learning Rate: 0.00848128
	LOSS [training: 1.472189768623408 | validation: 2.6318676948364894]
	TIME [epoch: 8.12 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.617490117778874		[learning rate: 0.0084613]
	Learning Rate: 0.00846128
	LOSS [training: 1.617490117778874 | validation: 1.4556344546993518]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5054022448356816		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 1.5054022448356816 | validation: 2.5366259985260307]
	TIME [epoch: 8.12 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4897726347903446		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 1.4897726347903446 | validation: 1.781124751530032]
	TIME [epoch: 8.12 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4150105524043437		[learning rate: 0.0084015]
	Learning Rate: 0.00840154
	LOSS [training: 1.4150105524043437 | validation: 2.0473997648192697]
	TIME [epoch: 8.14 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.691015399272017		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 1.691015399272017 | validation: 2.475221177539626]
	TIME [epoch: 8.15 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6857845178516269		[learning rate: 0.008362]
	Learning Rate: 0.00836195
	LOSS [training: 1.6857845178516269 | validation: 1.5369760143344497]
	TIME [epoch: 8.11 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6358603839185242		[learning rate: 0.0083422]
	Learning Rate: 0.00834223
	LOSS [training: 1.6358603839185242 | validation: 1.9738888204976959]
	TIME [epoch: 8.12 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.472911850864269		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 1.472911850864269 | validation: 2.4347582419382716]
	TIME [epoch: 8.12 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5857380672364956		[learning rate: 0.0083029]
	Learning Rate: 0.00830292
	LOSS [training: 1.5857380672364956 | validation: 2.3072945351888414]
	TIME [epoch: 8.12 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.621644290529451		[learning rate: 0.0082833]
	Learning Rate: 0.00828333
	LOSS [training: 1.621644290529451 | validation: 1.4010882832051004]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4419079224868487		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 1.4419079224868487 | validation: 1.875615724454468]
	TIME [epoch: 8.12 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2354211184329464		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 1.2354211184329464 | validation: 2.008501177041385]
	TIME [epoch: 8.12 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7093539725601639		[learning rate: 0.0082249]
	Learning Rate: 0.00822485
	LOSS [training: 1.7093539725601639 | validation: 2.3253806907063312]
	TIME [epoch: 8.11 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2858007808018885		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 1.2858007808018885 | validation: 1.4706388150500294]
	TIME [epoch: 8.11 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738330178492527		[learning rate: 0.0081861]
	Learning Rate: 0.0081861
	LOSS [training: 1.738330178492527 | validation: 1.7544367725861876]
	TIME [epoch: 8.13 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6127161967360208		[learning rate: 0.0081668]
	Learning Rate: 0.00816679
	LOSS [training: 1.6127161967360208 | validation: 1.597185668090715]
	TIME [epoch: 8.16 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087915207386532		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 1.1087915207386532 | validation: 1.193995520134286]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5795944546080642		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 1.5795944546080642 | validation: 1.6874432221819653]
	TIME [epoch: 8.12 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3247036819760476		[learning rate: 0.0081091]
	Learning Rate: 0.00810913
	LOSS [training: 1.3247036819760476 | validation: 1.6163231748973053]
	TIME [epoch: 8.11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.258655142336153		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 1.258655142336153 | validation: 2.0120877881733277]
	TIME [epoch: 8.11 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484519925734077		[learning rate: 0.0080709]
	Learning Rate: 0.00807092
	LOSS [training: 1.484519925734077 | validation: 1.3099843192841742]
	TIME [epoch: 8.15 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5380899794259626		[learning rate: 0.0080519]
	Learning Rate: 0.00805188
	LOSS [training: 1.5380899794259626 | validation: 1.637495363338743]
	TIME [epoch: 8.12 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1206743373840853		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 1.1206743373840853 | validation: 1.6028018690569799]
	TIME [epoch: 8.11 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.552906438317557		[learning rate: 0.0080139]
	Learning Rate: 0.00801394
	LOSS [training: 1.552906438317557 | validation: 1.5833096846476746]
	TIME [epoch: 8.11 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650924233293468		[learning rate: 0.007995]
	Learning Rate: 0.00799504
	LOSS [training: 1.2650924233293468 | validation: 1.6312222317417362]
	TIME [epoch: 8.11 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.380013579372855		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 1.380013579372855 | validation: 1.2906586173837091]
	TIME [epoch: 8.11 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4520508003032493		[learning rate: 0.0079574]
	Learning Rate: 0.00795736
	LOSS [training: 1.4520508003032493 | validation: 1.6095846896954622]
	TIME [epoch: 8.16 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0767651697949085		[learning rate: 0.0079386]
	Learning Rate: 0.00793859
	LOSS [training: 1.0767651697949085 | validation: 2.707286501197477]
	TIME [epoch: 8.13 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4197963456748681		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 1.4197963456748681 | validation: 1.6649089433345472]
	TIME [epoch: 8.11 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5569380106865343		[learning rate: 0.0079012]
	Learning Rate: 0.00790119
	LOSS [training: 1.5569380106865343 | validation: 1.1874180669821124]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193352304265197		[learning rate: 0.0078825]
	Learning Rate: 0.00788255
	LOSS [training: 1.193352304265197 | validation: 1.1723292456127126]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1211670926641661		[learning rate: 0.007864]
	Learning Rate: 0.00786396
	LOSS [training: 1.1211670926641661 | validation: 3.082452320374355]
	TIME [epoch: 8.14 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3133748439240818		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 1.3133748439240818 | validation: 0.961809389845095]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108582884858524		[learning rate: 0.0078269]
	Learning Rate: 0.0078269
	LOSS [training: 1.108582884858524 | validation: 1.6577582670726967]
	TIME [epoch: 8.12 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4976510843709405		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 1.4976510843709405 | validation: 1.0099641974512064]
	TIME [epoch: 8.12 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0807099846448718		[learning rate: 0.00779]
	Learning Rate: 0.00779002
	LOSS [training: 1.0807099846448718 | validation: 2.0571991931197724]
	TIME [epoch: 8.12 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.336189344468949		[learning rate: 0.0077716]
	Learning Rate: 0.00777164
	LOSS [training: 1.336189344468949 | validation: 1.3500192274543448]
	TIME [epoch: 8.13 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1733056544362008		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 1.1733056544362008 | validation: 1.421636779428767]
	TIME [epoch: 8.16 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060366709233892		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 1.060366709233892 | validation: 2.1527951975760047]
	TIME [epoch: 8.13 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3683197657974089		[learning rate: 0.0077168]
	Learning Rate: 0.00771678
	LOSS [training: 1.3683197657974089 | validation: 1.16843196942443]
	TIME [epoch: 8.13 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1326969572153007		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 1.1326969572153007 | validation: 0.9484047226336074]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.326082662794997		[learning rate: 0.0076804]
	Learning Rate: 0.00768041
	LOSS [training: 1.326082662794997 | validation: 0.9718922165181245]
	TIME [epoch: 8.12 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.998755178000639		[learning rate: 0.0076623]
	Learning Rate: 0.0076623
	LOSS [training: 0.998755178000639 | validation: 1.136840325581639]
	TIME [epoch: 8.12 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684577550924343		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.7684577550924343 | validation: 1.4942877768054883]
	TIME [epoch: 8.15 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294404345591119		[learning rate: 0.0076262]
	Learning Rate: 0.00762619
	LOSS [training: 1.294404345591119 | validation: 1.8966751271954734]
	TIME [epoch: 8.12 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1167235028436393		[learning rate: 0.0076082]
	Learning Rate: 0.0076082
	LOSS [training: 1.1167235028436393 | validation: 2.2839723479866407]
	TIME [epoch: 8.12 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3656226902693573		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 1.3656226902693573 | validation: 1.3679551385527402]
	TIME [epoch: 8.12 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3403433507190048		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 1.3403433507190048 | validation: 1.5343019990156068]
	TIME [epoch: 8.12 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1191989838198237		[learning rate: 0.0075545]
	Learning Rate: 0.00755449
	LOSS [training: 1.1191989838198237 | validation: 2.0054610407149474]
	TIME [epoch: 8.14 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2711030615465284		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 1.2711030615465284 | validation: 1.1648465116097344]
	TIME [epoch: 8.14 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3135748251152912		[learning rate: 0.0075189]
	Learning Rate: 0.00751889
	LOSS [training: 2.3135748251152912 | validation: 3.0355292357636747]
	TIME [epoch: 8.12 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0290029813308834		[learning rate: 0.0075012]
	Learning Rate: 0.00750116
	LOSS [training: 2.0290029813308834 | validation: 1.478164043145748]
	TIME [epoch: 8.12 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2005681111068771		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 1.2005681111068771 | validation: 1.264261497084349]
	TIME [epoch: 8.13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0791439637905031		[learning rate: 0.0074658]
	Learning Rate: 0.00746581
	LOSS [training: 1.0791439637905031 | validation: 1.2727885256073708]
	TIME [epoch: 8.12 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1147837545685884		[learning rate: 0.0074482]
	Learning Rate: 0.0074482
	LOSS [training: 1.1147837545685884 | validation: 1.4196211151372051]
	TIME [epoch: 8.15 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.400707243815629		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 1.400707243815629 | validation: 1.188026324275175]
	TIME [epoch: 8.13 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1269337464255331		[learning rate: 0.0074131]
	Learning Rate: 0.0074131
	LOSS [training: 1.1269337464255331 | validation: 1.0004154345279852]
	TIME [epoch: 8.12 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3317837052418748		[learning rate: 0.0073956]
	Learning Rate: 0.00739562
	LOSS [training: 1.3317837052418748 | validation: 1.1371629276978206]
	TIME [epoch: 8.12 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4436858324930997		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 1.4436858324930997 | validation: 1.5335483710906992]
	TIME [epoch: 8.12 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0521825327878442		[learning rate: 0.0073608]
	Learning Rate: 0.00736077
	LOSS [training: 1.0521825327878442 | validation: 1.8877626799887464]
	TIME [epoch: 8.12 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2123003728934758		[learning rate: 0.0073434]
	Learning Rate: 0.0073434
	LOSS [training: 1.2123003728934758 | validation: 1.1065082921949179]
	TIME [epoch: 8.16 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135756578671117		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 1.135756578671117 | validation: 1.0342433018740753]
	TIME [epoch: 8.12 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034533729287396		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 1.0034533729287396 | validation: 2.7396640121823888]
	TIME [epoch: 8.12 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6900515672990204		[learning rate: 0.0072916]
	Learning Rate: 0.00729156
	LOSS [training: 1.6900515672990204 | validation: 1.0860203764700578]
	TIME [epoch: 8.12 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019933207901793		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 1.019933207901793 | validation: 1.6232843982815086]
	TIME [epoch: 8.12 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6728014102982878		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 1.6728014102982878 | validation: 1.286370953791581]
	TIME [epoch: 8.13 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2112043443021132		[learning rate: 0.0072401]
	Learning Rate: 0.00724008
	LOSS [training: 1.2112043443021132 | validation: 1.1181767935502003]
	TIME [epoch: 8.16 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1010118195005987		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 1.1010118195005987 | validation: 1.869100824396543]
	TIME [epoch: 8.12 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6456616823366388		[learning rate: 0.007206]
	Learning Rate: 0.00720597
	LOSS [training: 1.6456616823366388 | validation: 1.0551526956957162]
	TIME [epoch: 8.12 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2155627756908276		[learning rate: 0.007189]
	Learning Rate: 0.00718897
	LOSS [training: 1.2155627756908276 | validation: 1.1634467141190563]
	TIME [epoch: 8.12 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.170198410985235		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 1.170198410985235 | validation: 1.1270640793072118]
	TIME [epoch: 8.12 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2203950974269633		[learning rate: 0.0071551]
	Learning Rate: 0.00715509
	LOSS [training: 1.2203950974269633 | validation: 1.6246951903548974]
	TIME [epoch: 8.15 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4608587447796142		[learning rate: 0.0071382]
	Learning Rate: 0.00713822
	LOSS [training: 1.4608587447796142 | validation: 1.3287365982067674]
	TIME [epoch: 8.13 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2145041408869375		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 1.2145041408869375 | validation: 1.0183908996821391]
	TIME [epoch: 8.12 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9745689289428962		[learning rate: 0.0071046]
	Learning Rate: 0.00710458
	LOSS [training: 0.9745689289428962 | validation: 1.8552346781169287]
	TIME [epoch: 8.12 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2168568912018989		[learning rate: 0.0070878]
	Learning Rate: 0.00708782
	LOSS [training: 1.2168568912018989 | validation: 0.9754728265831216]
	TIME [epoch: 8.11 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8688821916508621		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.8688821916508621 | validation: 1.2728427426354036]
	TIME [epoch: 8.11 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004856432218242		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 1.004856432218242 | validation: 1.3862158357396164]
	TIME [epoch: 8.16 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1652121545708323		[learning rate: 0.0070378]
	Learning Rate: 0.00703778
	LOSS [training: 1.1652121545708323 | validation: 1.1952575681735045]
	TIME [epoch: 8.12 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594104239944917		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 1.0594104239944917 | validation: 0.8365096820774383]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.981346777712176		[learning rate: 0.0070046]
	Learning Rate: 0.00700462
	LOSS [training: 0.981346777712176 | validation: 0.971830165712567]
	TIME [epoch: 108 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876118591699915		[learning rate: 0.0069881]
	Learning Rate: 0.0069881
	LOSS [training: 0.876118591699915 | validation: 1.703197662228459]
	TIME [epoch: 16.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3345134392675766		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 1.3345134392675766 | validation: 1.231793563034748]
	TIME [epoch: 16 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1784274173293547		[learning rate: 0.0069552]
	Learning Rate: 0.00695517
	LOSS [training: 1.1784274173293547 | validation: 1.6822214646512545]
	TIME [epoch: 16.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4350410610775097		[learning rate: 0.0069388]
	Learning Rate: 0.00693876
	LOSS [training: 1.4350410610775097 | validation: 1.2346644561866313]
	TIME [epoch: 16 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5653266837316686		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 1.5653266837316686 | validation: 1.6082851105573792]
	TIME [epoch: 16 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3050720866114416		[learning rate: 0.0069061]
	Learning Rate: 0.00690607
	LOSS [training: 1.3050720866114416 | validation: 1.2270466855518127]
	TIME [epoch: 16.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167945028162799		[learning rate: 0.0068898]
	Learning Rate: 0.00688978
	LOSS [training: 1.167945028162799 | validation: 0.9013935601449337]
	TIME [epoch: 16 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7815069139374979		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.7815069139374979 | validation: 0.8998544417991146]
	TIME [epoch: 16 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1538552242184357		[learning rate: 0.0068573]
	Learning Rate: 0.00685731
	LOSS [training: 1.1538552242184357 | validation: 1.2294162089802247]
	TIME [epoch: 16.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8737313670626166		[learning rate: 0.0068411]
	Learning Rate: 0.00684114
	LOSS [training: 0.8737313670626166 | validation: 1.1862846925964097]
	TIME [epoch: 16 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0115753119992543		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 1.0115753119992543 | validation: 0.8701109584567768]
	TIME [epoch: 16 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.528709266058421		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 1.528709266058421 | validation: 2.0149380086021615]
	TIME [epoch: 16 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4200950385008873		[learning rate: 0.0067928]
	Learning Rate: 0.00679284
	LOSS [training: 1.4200950385008873 | validation: 1.2169976324799414]
	TIME [epoch: 16.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2923355127569423		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 1.2923355127569423 | validation: 1.2314567235299783]
	TIME [epoch: 16 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0292336828784592		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 1.0292336828784592 | validation: 1.1307180201289333]
	TIME [epoch: 16 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9786178051462224		[learning rate: 0.0067449]
	Learning Rate: 0.00674488
	LOSS [training: 0.9786178051462224 | validation: 1.6962923704320634]
	TIME [epoch: 16.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2782320515696912		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 1.2782320515696912 | validation: 1.0558638807742298]
	TIME [epoch: 16 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0167454878946707		[learning rate: 0.0067131]
	Learning Rate: 0.0067131
	LOSS [training: 1.0167454878946707 | validation: 1.1675984095701357]
	TIME [epoch: 16 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9092412038578723		[learning rate: 0.0066973]
	Learning Rate: 0.00669726
	LOSS [training: 0.9092412038578723 | validation: 1.439694842225752]
	TIME [epoch: 16.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0369400771557764		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 1.0369400771557764 | validation: 1.528420588199661]
	TIME [epoch: 16 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1128193011910554		[learning rate: 0.0066657]
	Learning Rate: 0.00666571
	LOSS [training: 1.1128193011910554 | validation: 1.0540623226232912]
	TIME [epoch: 16 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268789108368682		[learning rate: 0.00665]
	Learning Rate: 0.00664998
	LOSS [training: 0.9268789108368682 | validation: 1.653774681719474]
	TIME [epoch: 16.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.295223982971669		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 1.295223982971669 | validation: 0.9083854149116687]
	TIME [epoch: 16 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2775019191642336		[learning rate: 0.0066186]
	Learning Rate: 0.00661865
	LOSS [training: 1.2775019191642336 | validation: 2.876191778918387]
	TIME [epoch: 16 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.439675092081592		[learning rate: 0.006603]
	Learning Rate: 0.00660304
	LOSS [training: 2.439675092081592 | validation: 1.7337938801274588]
	TIME [epoch: 16.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.652655345571546		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 1.652655345571546 | validation: 1.1679970508163922]
	TIME [epoch: 16 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1809721845151782		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 1.1809721845151782 | validation: 1.0396922184468105]
	TIME [epoch: 16 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0321608089881162		[learning rate: 0.0065564]
	Learning Rate: 0.00655642
	LOSS [training: 1.0321608089881162 | validation: 1.1053435053230194]
	TIME [epoch: 16.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.088136597389016		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 1.088136597389016 | validation: 1.0236074922289542]
	TIME [epoch: 16 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.939402781197858		[learning rate: 0.0065255]
	Learning Rate: 0.00652552
	LOSS [training: 0.939402781197858 | validation: 0.9924851325447756]
	TIME [epoch: 16 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1502385668483754		[learning rate: 0.0065101]
	Learning Rate: 0.00651013
	LOSS [training: 1.1502385668483754 | validation: 0.8912978671151588]
	TIME [epoch: 16.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900104228713499		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.900104228713499 | validation: 1.024824338551113]
	TIME [epoch: 16.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1028974426941165		[learning rate: 0.0064795]
	Learning Rate: 0.00647945
	LOSS [training: 1.1028974426941165 | validation: 0.9183825606546161]
	TIME [epoch: 16 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8798352915151948		[learning rate: 0.0064642]
	Learning Rate: 0.00646417
	LOSS [training: 0.8798352915151948 | validation: 0.8190141851659143]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677162245082698		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.9677162245082698 | validation: 1.0434514612673196]
	TIME [epoch: 16.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2924879394076971		[learning rate: 0.0064337]
	Learning Rate: 0.00643371
	LOSS [training: 1.2924879394076971 | validation: 1.5725536962232605]
	TIME [epoch: 16 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2106502296412538		[learning rate: 0.0064185]
	Learning Rate: 0.00641853
	LOSS [training: 1.2106502296412538 | validation: 1.388968938502421]
	TIME [epoch: 16 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9357716441675377		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.9357716441675377 | validation: 1.4240996735289717]
	TIME [epoch: 16.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.906325293079524		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.906325293079524 | validation: 0.8458656045366858]
	TIME [epoch: 16 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270277008005458		[learning rate: 0.0063732]
	Learning Rate: 0.00637322
	LOSS [training: 0.8270277008005458 | validation: 0.7970664736253625]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.916477393818597		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.916477393818597 | validation: 1.2370440582172755]
	TIME [epoch: 16.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8868907857875034		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.8868907857875034 | validation: 0.6877226717819073]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024994669075027		[learning rate: 0.0063282]
	Learning Rate: 0.00632823
	LOSS [training: 1.024994669075027 | validation: 1.065250875226428]
	TIME [epoch: 16.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1008904568112334		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 1.1008904568112334 | validation: 1.1014705735079908]
	TIME [epoch: 16.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8862461701029819		[learning rate: 0.0062984]
	Learning Rate: 0.00629841
	LOSS [training: 0.8862461701029819 | validation: 1.6410958958643171]
	TIME [epoch: 16.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9748933489693095		[learning rate: 0.0062836]
	Learning Rate: 0.00628355
	LOSS [training: 0.9748933489693095 | validation: 0.8063171815714749]
	TIME [epoch: 16.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0557363033217901		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 1.0557363033217901 | validation: 1.0355445251006805]
	TIME [epoch: 16.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9450487390749154		[learning rate: 0.0062539]
	Learning Rate: 0.00625394
	LOSS [training: 0.9450487390749154 | validation: 0.695714898688386]
	TIME [epoch: 16 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212627566872615		[learning rate: 0.0062392]
	Learning Rate: 0.00623919
	LOSS [training: 0.8212627566872615 | validation: 0.9415500891202357]
	TIME [epoch: 16 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9989323765167825		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.9989323765167825 | validation: 1.1473192854443417]
	TIME [epoch: 16.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066263100074352		[learning rate: 0.0062098]
	Learning Rate: 0.00620979
	LOSS [training: 0.8066263100074352 | validation: 0.8220485894977811]
	TIME [epoch: 16 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092113314116248		[learning rate: 0.0061951]
	Learning Rate: 0.00619514
	LOSS [training: 1.092113314116248 | validation: 1.1043862771570268]
	TIME [epoch: 16 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382216415574229		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.7382216415574229 | validation: 0.7377954969485829]
	TIME [epoch: 16.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8116230529255742		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.8116230529255742 | validation: 0.9234947087267897]
	TIME [epoch: 16 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2659112987384478		[learning rate: 0.0061514]
	Learning Rate: 0.00615141
	LOSS [training: 1.2659112987384478 | validation: 0.7337195438295039]
	TIME [epoch: 16.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7682142940784389		[learning rate: 0.0061369]
	Learning Rate: 0.0061369
	LOSS [training: 0.7682142940784389 | validation: 0.9107026789350539]
	TIME [epoch: 16.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9409961094760266		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.9409961094760266 | validation: 1.0167797211615253]
	TIME [epoch: 16.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608884933497113		[learning rate: 0.006108]
	Learning Rate: 0.00610798
	LOSS [training: 0.7608884933497113 | validation: 0.9821539767392844]
	TIME [epoch: 16.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963533090305486		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.7963533090305486 | validation: 1.3344208976537406]
	TIME [epoch: 16.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8846237901686017		[learning rate: 0.0060792]
	Learning Rate: 0.0060792
	LOSS [training: 0.8846237901686017 | validation: 1.1246063970651088]
	TIME [epoch: 16 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7957509671617802		[learning rate: 0.0060649]
	Learning Rate: 0.00606486
	LOSS [training: 0.7957509671617802 | validation: 0.6490821480274989]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612543801349366		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.612543801349366 | validation: 0.9400721065688995]
	TIME [epoch: 16.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0637868684544471		[learning rate: 0.0060363]
	Learning Rate: 0.00603628
	LOSS [training: 1.0637868684544471 | validation: 0.7366689026235675]
	TIME [epoch: 16 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9610686888150475		[learning rate: 0.006022]
	Learning Rate: 0.00602204
	LOSS [training: 0.9610686888150475 | validation: 1.2310887636944816]
	TIME [epoch: 16.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112431533951378		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 1.112431533951378 | validation: 0.9360725713031168]
	TIME [epoch: 16.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068430819644463		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.7068430819644463 | validation: 1.4923857937630856]
	TIME [epoch: 16 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0364106728470368		[learning rate: 0.0059795]
	Learning Rate: 0.00597952
	LOSS [training: 1.0364106728470368 | validation: 0.7209105092176802]
	TIME [epoch: 16.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100960095392056		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.9100960095392056 | validation: 0.6609825920942931]
	TIME [epoch: 16.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002441490071146		[learning rate: 0.0059513]
	Learning Rate: 0.00595135
	LOSS [training: 0.8002441490071146 | validation: 0.6826139001256334]
	TIME [epoch: 16 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8575895938457063		[learning rate: 0.0059373]
	Learning Rate: 0.00593731
	LOSS [training: 0.8575895938457063 | validation: 1.115492214962943]
	TIME [epoch: 16.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9339928687856369		[learning rate: 0.0059233]
	Learning Rate: 0.00592331
	LOSS [training: 0.9339928687856369 | validation: 1.5474492395977326]
	TIME [epoch: 16.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2146692978006377		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 1.2146692978006377 | validation: 1.029710620159705]
	TIME [epoch: 16.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8368985691672308		[learning rate: 0.0058954]
	Learning Rate: 0.00589539
	LOSS [training: 0.8368985691672308 | validation: 1.3468978874956967]
	TIME [epoch: 16.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3225115842266673		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 1.3225115842266673 | validation: 1.1712503661397835]
	TIME [epoch: 16.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1180207316386501		[learning rate: 0.0058676]
	Learning Rate: 0.00586761
	LOSS [training: 1.1180207316386501 | validation: 1.0828689286466435]
	TIME [epoch: 16 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1008213430657792		[learning rate: 0.0058538]
	Learning Rate: 0.00585377
	LOSS [training: 1.1008213430657792 | validation: 0.6724977563942696]
	TIME [epoch: 16.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7944283862071194		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.7944283862071194 | validation: 0.7107867816750708]
	TIME [epoch: 16 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839976176215049		[learning rate: 0.0058262]
	Learning Rate: 0.00582619
	LOSS [training: 0.839976176215049 | validation: 0.8932338269518123]
	TIME [epoch: 16 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753202093442131		[learning rate: 0.0058124]
	Learning Rate: 0.00581245
	LOSS [training: 0.8753202093442131 | validation: 2.09590385034968]
	TIME [epoch: 16.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2759074742297527		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 1.2759074742297527 | validation: 0.7581775697632722]
	TIME [epoch: 16 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869125351985839		[learning rate: 0.0057851]
	Learning Rate: 0.00578506
	LOSS [training: 0.6869125351985839 | validation: 0.8100650527721285]
	TIME [epoch: 16 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824808206077534		[learning rate: 0.0057714]
	Learning Rate: 0.00577141
	LOSS [training: 0.7824808206077534 | validation: 0.7009182445347557]
	TIME [epoch: 16.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663355255230552		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.6663355255230552 | validation: 0.6313069189295308]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437792058612487		[learning rate: 0.0057442]
	Learning Rate: 0.00574422
	LOSS [training: 0.9437792058612487 | validation: 0.8857772369374521]
	TIME [epoch: 16 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9055958779161435		[learning rate: 0.0057307]
	Learning Rate: 0.00573067
	LOSS [training: 0.9055958779161435 | validation: 0.921767357578271]
	TIME [epoch: 16.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9689808119367362		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.9689808119367362 | validation: 1.285555900539003]
	TIME [epoch: 16 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7793968253053727		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.7793968253053727 | validation: 1.296566981223211]
	TIME [epoch: 16 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8850476581806511		[learning rate: 0.0056902]
	Learning Rate: 0.00569021
	LOSS [training: 0.8850476581806511 | validation: 0.767025372335981]
	TIME [epoch: 16.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8051264764877933		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.8051264764877933 | validation: 0.8387208668965483]
	TIME [epoch: 16 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7706477730527526		[learning rate: 0.0056634]
	Learning Rate: 0.0056634
	LOSS [training: 0.7706477730527526 | validation: 0.8668431485915531]
	TIME [epoch: 16 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751798782938819		[learning rate: 0.00565]
	Learning Rate: 0.00565004
	LOSS [training: 0.7751798782938819 | validation: 0.9921981941418672]
	TIME [epoch: 16.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.992475636543583		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.992475636543583 | validation: 0.8304539470394805]
	TIME [epoch: 16 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6510893238210618		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.6510893238210618 | validation: 0.6625662283847402]
	TIME [epoch: 16 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382537341797262		[learning rate: 0.0056101]
	Learning Rate: 0.00561015
	LOSS [training: 0.8382537341797262 | validation: 0.6096230425673405]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028355660217488		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.7028355660217488 | validation: 0.5917003436166738]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1721963249273029		[learning rate: 0.0055837]
	Learning Rate: 0.00558371
	LOSS [training: 1.1721963249273029 | validation: 1.8198915888447424]
	TIME [epoch: 16 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0931398384122342		[learning rate: 0.0055705]
	Learning Rate: 0.00557054
	LOSS [training: 1.0931398384122342 | validation: 1.3215153515992608]
	TIME [epoch: 16.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240286235546175		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.8240286235546175 | validation: 1.1884457321949058]
	TIME [epoch: 16 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589369989865781		[learning rate: 0.0055443]
	Learning Rate: 0.00554429
	LOSS [training: 0.7589369989865781 | validation: 1.11120614363137]
	TIME [epoch: 16 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294144117102426		[learning rate: 0.0055312]
	Learning Rate: 0.00553121
	LOSS [training: 0.7294144117102426 | validation: 0.6678966143142357]
	TIME [epoch: 16.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5857642228639893		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.5857642228639893 | validation: 0.5930320183792088]
	TIME [epoch: 16 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8472127536394163		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.8472127536394163 | validation: 0.7215588688184416]
	TIME [epoch: 16 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183103554802284		[learning rate: 0.0054922]
	Learning Rate: 0.00549216
	LOSS [training: 0.7183103554802284 | validation: 1.0260692998038512]
	TIME [epoch: 16.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317821995786458		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 1.2317821995786458 | validation: 0.6260819655718546]
	TIME [epoch: 16 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370516381217064		[learning rate: 0.0054663]
	Learning Rate: 0.00546629
	LOSS [training: 0.6370516381217064 | validation: 0.6938344993638068]
	TIME [epoch: 16 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911691013517218		[learning rate: 0.0054534]
	Learning Rate: 0.00545339
	LOSS [training: 0.911691013517218 | validation: 1.2838615902290251]
	TIME [epoch: 16.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0650748197984825		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 1.0650748197984825 | validation: 1.142719684156626]
	TIME [epoch: 16 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723455150771879		[learning rate: 0.0054277]
	Learning Rate: 0.00542769
	LOSS [training: 0.723455150771879 | validation: 0.7193897220420242]
	TIME [epoch: 16 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1463592142695922		[learning rate: 0.0054149]
	Learning Rate: 0.00541489
	LOSS [training: 1.1463592142695922 | validation: 1.5482651200836133]
	TIME [epoch: 16.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049205719852266		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 2.049205719852266 | validation: 0.7483042108732567]
	TIME [epoch: 16 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8731618541256685		[learning rate: 0.0053894]
	Learning Rate: 0.00538938
	LOSS [training: 0.8731618541256685 | validation: 1.355029302956144]
	TIME [epoch: 16 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7920073554026743		[learning rate: 0.0053767]
	Learning Rate: 0.00537666
	LOSS [training: 0.7920073554026743 | validation: 0.9392702569257331]
	TIME [epoch: 16.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238460680213748		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.6238460680213748 | validation: 1.3626086583140449]
	TIME [epoch: 16 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8268540457900431		[learning rate: 0.0053513]
	Learning Rate: 0.00535133
	LOSS [training: 0.8268540457900431 | validation: 0.7326259893962562]
	TIME [epoch: 16 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.673704518308355		[learning rate: 0.0053387]
	Learning Rate: 0.00533871
	LOSS [training: 0.673704518308355 | validation: 0.7711534317607613]
	TIME [epoch: 16.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764717669542496		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.7764717669542496 | validation: 0.7188217358134013]
	TIME [epoch: 16 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253614810100917		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.6253614810100917 | validation: 0.5161589349597202]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2050699763564938		[learning rate: 0.005301]
	Learning Rate: 0.00530101
	LOSS [training: 1.2050699763564938 | validation: 0.7672877416532158]
	TIME [epoch: 16.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702855478198392		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.702855478198392 | validation: 0.6283732534038325]
	TIME [epoch: 16 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345970546293223		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.7345970546293223 | validation: 0.8345601843937502]
	TIME [epoch: 16 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449562460183344		[learning rate: 0.0052636]
	Learning Rate: 0.00526359
	LOSS [training: 0.7449562460183344 | validation: 0.7405879740729153]
	TIME [epoch: 16.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950848986963259		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.950848986963259 | validation: 0.751450714321011]
	TIME [epoch: 16 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750054408435378		[learning rate: 0.0052388]
	Learning Rate: 0.00523879
	LOSS [training: 0.7750054408435378 | validation: 0.7763306344649485]
	TIME [epoch: 16 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078203726712812		[learning rate: 0.0052264]
	Learning Rate: 0.00522643
	LOSS [training: 0.7078203726712812 | validation: 0.633121286256134]
	TIME [epoch: 16.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6064893890313141		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.6064893890313141 | validation: 0.7248245330514638]
	TIME [epoch: 16 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8661207792498478		[learning rate: 0.0052018]
	Learning Rate: 0.0052018
	LOSS [training: 0.8661207792498478 | validation: 0.869866126566978]
	TIME [epoch: 16 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812121090458402		[learning rate: 0.0051895]
	Learning Rate: 0.00518953
	LOSS [training: 0.5812121090458402 | validation: 0.5532454466600207]
	TIME [epoch: 16.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.190300306886286		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 1.190300306886286 | validation: 1.3402308299628354]
	TIME [epoch: 16 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1056255371615387		[learning rate: 0.0051651]
	Learning Rate: 0.00516508
	LOSS [training: 1.1056255371615387 | validation: 1.3534343916163745]
	TIME [epoch: 16 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.017264117901994		[learning rate: 0.0051529]
	Learning Rate: 0.00515289
	LOSS [training: 1.017264117901994 | validation: 0.868729287096422]
	TIME [epoch: 16.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8949525925090329		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.8949525925090329 | validation: 0.9125785991001805]
	TIME [epoch: 16 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083350878893274		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.8083350878893274 | validation: 0.8411478065179987]
	TIME [epoch: 16 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956578197313957		[learning rate: 0.0051165]
	Learning Rate: 0.00511652
	LOSS [training: 0.7956578197313957 | validation: 1.0846119215843688]
	TIME [epoch: 16.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612836983987068		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.8612836983987068 | validation: 0.6634725171499254]
	TIME [epoch: 16 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362859782769264		[learning rate: 0.0050924]
	Learning Rate: 0.00509241
	LOSS [training: 0.7362859782769264 | validation: 0.8949273613044599]
	TIME [epoch: 16 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866154469647846		[learning rate: 0.0050804]
	Learning Rate: 0.00508039
	LOSS [training: 0.866154469647846 | validation: 0.9346802554752489]
	TIME [epoch: 16.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0491237613767275		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 1.0491237613767275 | validation: 0.8561643209242562]
	TIME [epoch: 16 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471698312874661		[learning rate: 0.0050565]
	Learning Rate: 0.00505645
	LOSS [training: 0.7471698312874661 | validation: 0.854819491638516]
	TIME [epoch: 16 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374832454728507		[learning rate: 0.0050445]
	Learning Rate: 0.00504453
	LOSS [training: 0.6374832454728507 | validation: 0.846551293535547]
	TIME [epoch: 16.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8785251772536282		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.8785251772536282 | validation: 0.9393750433544147]
	TIME [epoch: 16 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238917229931016		[learning rate: 0.0050208]
	Learning Rate: 0.00502076
	LOSS [training: 0.7238917229931016 | validation: 0.8906850100631198]
	TIME [epoch: 16 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161890165386848		[learning rate: 0.0050089]
	Learning Rate: 0.00500891
	LOSS [training: 0.7161890165386848 | validation: 0.5279212523523544]
	TIME [epoch: 16.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6055526938928086		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.6055526938928086 | validation: 0.8688961524047225]
	TIME [epoch: 16 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773655944860426		[learning rate: 0.0049853]
	Learning Rate: 0.00498531
	LOSS [training: 0.773655944860426 | validation: 1.0065503009962642]
	TIME [epoch: 16 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344635765274933		[learning rate: 0.0049736]
	Learning Rate: 0.00497355
	LOSS [training: 0.6344635765274933 | validation: 0.8415872855672626]
	TIME [epoch: 16.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371327574081937		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.8371327574081937 | validation: 0.6377884320904411]
	TIME [epoch: 16 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7441772913825829		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.7441772913825829 | validation: 0.6811085721730207]
	TIME [epoch: 16 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9942171525174113		[learning rate: 0.0049384]
	Learning Rate: 0.00493844
	LOSS [training: 0.9942171525174113 | validation: 0.7574798615731198]
	TIME [epoch: 16.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7745007681788634		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.7745007681788634 | validation: 0.6798986856965443]
	TIME [epoch: 16 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663728626952391		[learning rate: 0.0049152]
	Learning Rate: 0.00491517
	LOSS [training: 0.6663728626952391 | validation: 0.6116604193624444]
	TIME [epoch: 16.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7681230679896753		[learning rate: 0.0049036]
	Learning Rate: 0.00490357
	LOSS [training: 0.7681230679896753 | validation: 0.6979186030732965]
	TIME [epoch: 16.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829683899780906		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.5829683899780906 | validation: 0.5789859863007021]
	TIME [epoch: 16 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292908847970496		[learning rate: 0.0048805]
	Learning Rate: 0.00488047
	LOSS [training: 0.7292908847970496 | validation: 0.5241290291937837]
	TIME [epoch: 16.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5570978124428287		[learning rate: 0.004869]
	Learning Rate: 0.00486896
	LOSS [training: 0.5570978124428287 | validation: 1.2064243700625512]
	TIME [epoch: 16.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165533666897754		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.7165533666897754 | validation: 0.6046259544008088]
	TIME [epoch: 16 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9601897302809972		[learning rate: 0.004846]
	Learning Rate: 0.00484601
	LOSS [training: 0.9601897302809972 | validation: 0.9359970275980933]
	TIME [epoch: 16.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7416744071149617		[learning rate: 0.0048346]
	Learning Rate: 0.00483458
	LOSS [training: 0.7416744071149617 | validation: 0.624122487202373]
	TIME [epoch: 16.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693770399330563		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.6693770399330563 | validation: 1.4825546396623872]
	TIME [epoch: 16 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9636552274155433		[learning rate: 0.0048118]
	Learning Rate: 0.0048118
	LOSS [training: 0.9636552274155433 | validation: 0.6129798796981732]
	TIME [epoch: 16.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722633080968144		[learning rate: 0.0048005]
	Learning Rate: 0.00480045
	LOSS [training: 0.7722633080968144 | validation: 0.9436426980197687]
	TIME [epoch: 16.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791093440590681		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.6791093440590681 | validation: 0.556898539375452]
	TIME [epoch: 16 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6129853740127782		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.6129853740127782 | validation: 1.0878803769968903]
	TIME [epoch: 16.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5902235394209076		[learning rate: 0.0047666]
	Learning Rate: 0.00476656
	LOSS [training: 0.5902235394209076 | validation: 0.6240183155721633]
	TIME [epoch: 16 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586961544834432		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.5586961544834432 | validation: 0.7413893290089395]
	TIME [epoch: 16 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759479094122956		[learning rate: 0.0047441]
	Learning Rate: 0.0047441
	LOSS [training: 0.759479094122956 | validation: 0.9535962326848488]
	TIME [epoch: 16.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9791218841089582		[learning rate: 0.0047329]
	Learning Rate: 0.00473291
	LOSS [training: 0.9791218841089582 | validation: 0.7333005615723573]
	TIME [epoch: 16.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8061871947333967		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.8061871947333967 | validation: 0.6851020963456828]
	TIME [epoch: 16 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.50125866582081		[learning rate: 0.0047106]
	Learning Rate: 0.00471061
	LOSS [training: 0.50125866582081 | validation: 1.0202794834905595]
	TIME [epoch: 16.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483757072653216		[learning rate: 0.0046995]
	Learning Rate: 0.0046995
	LOSS [training: 0.6483757072653216 | validation: 0.8957822826710682]
	TIME [epoch: 16.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710944988121001		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.5710944988121001 | validation: 2.0491437038585776]
	TIME [epoch: 16 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808550920720017		[learning rate: 0.0046774]
	Learning Rate: 0.00467735
	LOSS [training: 0.8808550920720017 | validation: 0.7897403980119937]
	TIME [epoch: 16.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6634305374639426		[learning rate: 0.0046663]
	Learning Rate: 0.00466632
	LOSS [training: 0.6634305374639426 | validation: 0.5985659724286547]
	TIME [epoch: 16.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543849170733225		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.6543849170733225 | validation: 0.7454835410871118]
	TIME [epoch: 16 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509700548139125		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.7509700548139125 | validation: 0.4522814084586706]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543725724611399		[learning rate: 0.0046334]
	Learning Rate: 0.00463338
	LOSS [training: 0.5543725724611399 | validation: 0.5657623113461916]
	TIME [epoch: 16 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6197069876161623		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.6197069876161623 | validation: 0.8667058393961107]
	TIME [epoch: 16 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8298224826696425		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.8298224826696425 | validation: 0.5078798955044829]
	TIME [epoch: 16.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678791151600748		[learning rate: 0.0046007]
	Learning Rate: 0.00460066
	LOSS [training: 0.5678791151600748 | validation: 0.7541059592901029]
	TIME [epoch: 16 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8725955910757643		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.8725955910757643 | validation: 0.7504596715402081]
	TIME [epoch: 16 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792308863734912		[learning rate: 0.004579]
	Learning Rate: 0.00457899
	LOSS [training: 0.792308863734912 | validation: 0.7682726129485349]
	TIME [epoch: 16.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7097606963528716		[learning rate: 0.0045682]
	Learning Rate: 0.00456818
	LOSS [training: 0.7097606963528716 | validation: 0.5342887266298023]
	TIME [epoch: 16 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380801886297439		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.5380801886297439 | validation: 0.48358565759507044]
	TIME [epoch: 16 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560192223449856		[learning rate: 0.0045467]
	Learning Rate: 0.00454666
	LOSS [training: 0.560192223449856 | validation: 0.727309407262756]
	TIME [epoch: 16.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5712833526598536		[learning rate: 0.0045359]
	Learning Rate: 0.00453593
	LOSS [training: 0.5712833526598536 | validation: 0.8032272014583101]
	TIME [epoch: 16 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823714511881397		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.7823714511881397 | validation: 0.5156309812798197]
	TIME [epoch: 16 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6455642288196797		[learning rate: 0.0045146]
	Learning Rate: 0.00451456
	LOSS [training: 0.6455642288196797 | validation: 1.2470934254603643]
	TIME [epoch: 16.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.897985430295795		[learning rate: 0.0045039]
	Learning Rate: 0.00450391
	LOSS [training: 0.897985430295795 | validation: 0.8548126718327979]
	TIME [epoch: 16 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8807367551156502		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.8807367551156502 | validation: 0.614179670824267]
	TIME [epoch: 16 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955177612193308		[learning rate: 0.0044827]
	Learning Rate: 0.00448269
	LOSS [training: 0.6955177612193308 | validation: 1.1392543916139226]
	TIME [epoch: 16.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9027371876408125		[learning rate: 0.0044721]
	Learning Rate: 0.00447211
	LOSS [training: 0.9027371876408125 | validation: 1.197662888051898]
	TIME [epoch: 16 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7843866520022654		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.7843866520022654 | validation: 1.0936896464005055]
	TIME [epoch: 16 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587072018400234		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.587072018400234 | validation: 0.5212438117218559]
	TIME [epoch: 16.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540403289859905		[learning rate: 0.0044405]
	Learning Rate: 0.00444054
	LOSS [training: 0.5540403289859905 | validation: 0.7043099702636654]
	TIME [epoch: 16 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316987887474638		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.5316987887474638 | validation: 0.4966811673696923]
	TIME [epoch: 16 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560817048799083		[learning rate: 0.0044196]
	Learning Rate: 0.00441962
	LOSS [training: 0.560817048799083 | validation: 1.4522137246159446]
	TIME [epoch: 16.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163318190214268		[learning rate: 0.0044092]
	Learning Rate: 0.00440919
	LOSS [training: 0.7163318190214268 | validation: 0.5953054812503271]
	TIME [epoch: 16.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383463819132349		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.5383463819132349 | validation: 0.4293095867810031]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965922759568382		[learning rate: 0.0043884]
	Learning Rate: 0.00438841
	LOSS [training: 0.5965922759568382 | validation: 0.5931079008476221]
	TIME [epoch: 16.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639682690345897		[learning rate: 0.0043781]
	Learning Rate: 0.00437806
	LOSS [training: 0.5639682690345897 | validation: 0.47976069051440695]
	TIME [epoch: 16 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22905738742271		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 1.22905738742271 | validation: 1.99969553314219]
	TIME [epoch: 16 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0383377509537652		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 1.0383377509537652 | validation: 0.6397635482585068]
	TIME [epoch: 16.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466244745421569		[learning rate: 0.0043472]
	Learning Rate: 0.00434715
	LOSS [training: 0.5466244745421569 | validation: 0.5847529651983704]
	TIME [epoch: 16 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265316517794891		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.5265316517794891 | validation: 0.7578618273179201]
	TIME [epoch: 16 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6019677877821824		[learning rate: 0.0043267]
	Learning Rate: 0.00432667
	LOSS [training: 0.6019677877821824 | validation: 0.7388509658216176]
	TIME [epoch: 16.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578330332635104		[learning rate: 0.0043165]
	Learning Rate: 0.00431646
	LOSS [training: 0.5578330332635104 | validation: 0.6251109782766721]
	TIME [epoch: 16 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382296847399075		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.5382296847399075 | validation: 1.1837714745325478]
	TIME [epoch: 16 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7505103482319232		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.7505103482319232 | validation: 0.74866591896226]
	TIME [epoch: 16.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107098895087063		[learning rate: 0.004286]
	Learning Rate: 0.00428599
	LOSS [training: 0.5107098895087063 | validation: 1.1360208152896365]
	TIME [epoch: 16 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427703298356052		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.7427703298356052 | validation: 0.6148803101540582]
	TIME [epoch: 16 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895720807263378		[learning rate: 0.0042658]
	Learning Rate: 0.0042658
	LOSS [training: 0.7895720807263378 | validation: 1.1445960572375387]
	TIME [epoch: 16.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9680788773704376		[learning rate: 0.0042557]
	Learning Rate: 0.00425573
	LOSS [training: 0.9680788773704376 | validation: 0.763432826645347]
	TIME [epoch: 16 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8125450694588503		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.8125450694588503 | validation: 0.5651623711265716]
	TIME [epoch: 16 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5514077631564804		[learning rate: 0.0042357]
	Learning Rate: 0.00423568
	LOSS [training: 0.5514077631564804 | validation: 0.626089259014611]
	TIME [epoch: 16.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119452807444873		[learning rate: 0.0042257]
	Learning Rate: 0.00422569
	LOSS [training: 0.5119452807444873 | validation: 0.5738206156300815]
	TIME [epoch: 16.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877929195859334		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.5877929195859334 | validation: 0.6396216727768782]
	TIME [epoch: 16 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5866847997849522		[learning rate: 0.0042058]
	Learning Rate: 0.00420578
	LOSS [training: 0.5866847997849522 | validation: 0.5393692278480277]
	TIME [epoch: 16.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0915472610700747		[learning rate: 0.0041959]
	Learning Rate: 0.00419585
	LOSS [training: 3.0915472610700747 | validation: 2.7142724890227345]
	TIME [epoch: 16 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13141747092216		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 2.13141747092216 | validation: 1.3780236900080443]
	TIME [epoch: 16 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0988381937877114		[learning rate: 0.0041761]
	Learning Rate: 0.00417608
	LOSS [training: 1.0988381937877114 | validation: 0.9549697479055842]
	TIME [epoch: 16.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837655015168094		[learning rate: 0.0041662]
	Learning Rate: 0.00416623
	LOSS [training: 0.6837655015168094 | validation: 0.6271704233026776]
	TIME [epoch: 16 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5646366422770077		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.5646366422770077 | validation: 0.6007454892633298]
	TIME [epoch: 16 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5420645864613628		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.5420645864613628 | validation: 0.609792903458273]
	TIME [epoch: 16.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664085230528643		[learning rate: 0.0041368]
	Learning Rate: 0.00413682
	LOSS [training: 0.5664085230528643 | validation: 0.5769177988668167]
	TIME [epoch: 16 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626634726497711		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.626634726497711 | validation: 0.6451156443322222]
	TIME [epoch: 16 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238525464210736		[learning rate: 0.0041173]
	Learning Rate: 0.00411733
	LOSS [training: 0.5238525464210736 | validation: 0.6118178692150974]
	TIME [epoch: 16.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47201375813399965		[learning rate: 0.0041076]
	Learning Rate: 0.00410762
	LOSS [training: 0.47201375813399965 | validation: 0.5849342262992251]
	TIME [epoch: 16 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5063095604192763		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.5063095604192763 | validation: 0.6869246345133588]
	TIME [epoch: 16 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5524779181715422		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.5524779181715422 | validation: 0.6894038120792713]
	TIME [epoch: 16.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6171109289424801		[learning rate: 0.0040786]
	Learning Rate: 0.00407862
	LOSS [training: 0.6171109289424801 | validation: 1.0361470858675692]
	TIME [epoch: 16 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642949072464722		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.5642949072464722 | validation: 0.5093766833681284]
	TIME [epoch: 16 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508902635917163		[learning rate: 0.0040594]
	Learning Rate: 0.0040594
	LOSS [training: 0.5508902635917163 | validation: 1.3315281059678923]
	TIME [epoch: 16.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8983944142715297		[learning rate: 0.0040498]
	Learning Rate: 0.00404982
	LOSS [training: 0.8983944142715297 | validation: 0.6056387723147885]
	TIME [epoch: 16 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356098186294456		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.5356098186294456 | validation: 0.5505188961447242]
	TIME [epoch: 16 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49279012454518756		[learning rate: 0.0040307]
	Learning Rate: 0.00403074
	LOSS [training: 0.49279012454518756 | validation: 0.5652553585354156]
	TIME [epoch: 16.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4946274616307578		[learning rate: 0.0040212]
	Learning Rate: 0.00402123
	LOSS [training: 0.4946274616307578 | validation: 0.4519497550047591]
	TIME [epoch: 16 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48927953077552067		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.48927953077552067 | validation: 0.5670605072523328]
	TIME [epoch: 16 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694821329549748		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.7694821329549748 | validation: 0.8593103814314385]
	TIME [epoch: 16.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687655037427788		[learning rate: 0.0039928]
	Learning Rate: 0.00399284
	LOSS [training: 0.687655037427788 | validation: 0.4164740065089175]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053389879089319		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.7053389879089319 | validation: 0.516152349150368]
	TIME [epoch: 16 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387876168535567		[learning rate: 0.003974]
	Learning Rate: 0.00397403
	LOSS [training: 0.5387876168535567 | validation: 0.7143819199007806]
	TIME [epoch: 16.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5571076924341054		[learning rate: 0.0039647]
	Learning Rate: 0.00396465
	LOSS [training: 0.5571076924341054 | validation: 0.4654246007854913]
	TIME [epoch: 16 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128063886093983		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.5128063886093983 | validation: 0.657414926146091]
	TIME [epoch: 16 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522212598471534		[learning rate: 0.003946]
	Learning Rate: 0.00394597
	LOSS [training: 0.522212598471534 | validation: 0.43741897769474214]
	TIME [epoch: 16.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139056762267533		[learning rate: 0.0039367]
	Learning Rate: 0.00393666
	LOSS [training: 0.5139056762267533 | validation: 0.40409317197280303]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397626024062788		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.6397626024062788 | validation: 0.4041449488263535]
	TIME [epoch: 16.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812954033103676		[learning rate: 0.0039181]
	Learning Rate: 0.00391811
	LOSS [training: 0.5812954033103676 | validation: 0.5594018996026191]
	TIME [epoch: 16.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986806084579748		[learning rate: 0.0039089]
	Learning Rate: 0.00390887
	LOSS [training: 0.5986806084579748 | validation: 0.5627938201613019]
	TIME [epoch: 16 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143106301016409		[learning rate: 0.0038996]
	Learning Rate: 0.00389965
	LOSS [training: 0.5143106301016409 | validation: 0.7409299912877474]
	TIME [epoch: 16.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596478873265375		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.6596478873265375 | validation: 0.5392722059651188]
	TIME [epoch: 16.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074568607329019		[learning rate: 0.0038813]
	Learning Rate: 0.00388127
	LOSS [training: 0.5074568607329019 | validation: 0.3857160029657398]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4755590933134621		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.4755590933134621 | validation: 0.6515186579644803]
	TIME [epoch: 16.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5750570533582313		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.5750570533582313 | validation: 1.1856361758404956]
	TIME [epoch: 16.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8648142655302358		[learning rate: 0.0038539]
	Learning Rate: 0.00385387
	LOSS [training: 0.8648142655302358 | validation: 0.6918262269754143]
	TIME [epoch: 16 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764548413415462		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.5764548413415462 | validation: 1.554848788017361]
	TIME [epoch: 16.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.365791068597667		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 1.365791068597667 | validation: 0.8000132781983129]
	TIME [epoch: 16.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7902332148452953		[learning rate: 0.0038267]
	Learning Rate: 0.00382667
	LOSS [training: 0.7902332148452953 | validation: 0.4341486409045887]
	TIME [epoch: 16 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142183073774147		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.6142183073774147 | validation: 0.7089495962607015]
	TIME [epoch: 16.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643794343121081		[learning rate: 0.0038086]
	Learning Rate: 0.00380863
	LOSS [training: 0.6643794343121081 | validation: 0.6063605513912357]
	TIME [epoch: 16.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293238737738117		[learning rate: 0.0037996]
	Learning Rate: 0.00379965
	LOSS [training: 0.4293238737738117 | validation: 0.7090179101911968]
	TIME [epoch: 16 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535346838002175		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.6535346838002175 | validation: 0.6011222502812539]
	TIME [epoch: 16.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6719144347512604		[learning rate: 0.0037817]
	Learning Rate: 0.00378175
	LOSS [training: 0.6719144347512604 | validation: 0.6524609374622432]
	TIME [epoch: 16 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054442921626614		[learning rate: 0.0037728]
	Learning Rate: 0.00377283
	LOSS [training: 0.6054442921626614 | validation: 0.43717031243690113]
	TIME [epoch: 16 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42962511822853433		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.42962511822853433 | validation: 0.7567386308046996]
	TIME [epoch: 16.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48159960520310285		[learning rate: 0.003755]
	Learning Rate: 0.00375505
	LOSS [training: 0.48159960520310285 | validation: 0.666390980317541]
	TIME [epoch: 16 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523143488492436		[learning rate: 0.0037462]
	Learning Rate: 0.00374619
	LOSS [training: 0.523143488492436 | validation: 0.46626126847740773]
	TIME [epoch: 16 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327703260024857		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.6327703260024857 | validation: 0.47655748111001567]
	TIME [epoch: 16.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1171291002303667		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 1.1171291002303667 | validation: 1.736751637120841]
	TIME [epoch: 16 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1984311730384896		[learning rate: 0.0037197]
	Learning Rate: 0.00371974
	LOSS [training: 1.1984311730384896 | validation: 0.927087371207763]
	TIME [epoch: 16 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405258921971331		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.8405258921971331 | validation: 1.0336082671492108]
	TIME [epoch: 16.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9995271096422702		[learning rate: 0.0037022]
	Learning Rate: 0.00370221
	LOSS [training: 0.9995271096422702 | validation: 1.3128628066048473]
	TIME [epoch: 16 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108619837576707		[learning rate: 0.0036935]
	Learning Rate: 0.00369348
	LOSS [training: 0.8108619837576707 | validation: 0.8569449266960467]
	TIME [epoch: 16 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980712874539215		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.5980712874539215 | validation: 0.5281004208848006]
	TIME [epoch: 16.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053222883677134		[learning rate: 0.0036761]
	Learning Rate: 0.00367608
	LOSS [training: 0.6053222883677134 | validation: 0.716215244140832]
	TIME [epoch: 16 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832587534255091		[learning rate: 0.0036674]
	Learning Rate: 0.00366741
	LOSS [training: 0.832587534255091 | validation: 0.8337354141044565]
	TIME [epoch: 16 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062764055887735		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.7062764055887735 | validation: 1.0426244231630655]
	TIME [epoch: 16.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253015917854958		[learning rate: 0.0036501]
	Learning Rate: 0.00365012
	LOSS [training: 0.7253015917854958 | validation: 1.1256776973596807]
	TIME [epoch: 16 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6079324666791563		[learning rate: 0.0036415]
	Learning Rate: 0.00364151
	LOSS [training: 0.6079324666791563 | validation: 0.8787380649081654]
	TIME [epoch: 16 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9024853078088096		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.9024853078088096 | validation: 0.44877939440455294]
	TIME [epoch: 16.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375215449249788		[learning rate: 0.0036244]
	Learning Rate: 0.00362436
	LOSS [training: 0.8375215449249788 | validation: 1.081845601966347]
	TIME [epoch: 16.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8388800228078729		[learning rate: 0.0036158]
	Learning Rate: 0.00361581
	LOSS [training: 0.8388800228078729 | validation: 0.6829910713996963]
	TIME [epoch: 16 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334788898951359		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.6334788898951359 | validation: 1.0326982040216417]
	TIME [epoch: 16.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479804018271973		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.6479804018271973 | validation: 0.5814092082560222]
	TIME [epoch: 16.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355216948004969		[learning rate: 0.0035903]
	Learning Rate: 0.00359028
	LOSS [training: 0.7355216948004969 | validation: 1.5736922792925299]
	TIME [epoch: 16 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028873438100384		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 1.028873438100384 | validation: 1.1274376861153113]
	TIME [epoch: 16.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066758068661849		[learning rate: 0.0035734]
	Learning Rate: 0.00357336
	LOSS [training: 0.7066758068661849 | validation: 0.5968159021286801]
	TIME [epoch: 16.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188759565118332		[learning rate: 0.0035649]
	Learning Rate: 0.00356493
	LOSS [training: 0.5188759565118332 | validation: 0.39116623441670073]
	TIME [epoch: 16.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41937527987310136		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.41937527987310136 | validation: 0.5079627778925409]
	TIME [epoch: 16.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9214867414552257		[learning rate: 0.0035481]
	Learning Rate: 0.00354813
	LOSS [training: 0.9214867414552257 | validation: 0.7062183157490471]
	TIME [epoch: 16 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49194587653464644		[learning rate: 0.0035398]
	Learning Rate: 0.00353976
	LOSS [training: 0.49194587653464644 | validation: 0.7596776141262026]
	TIME [epoch: 16 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5727727857599547		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.5727727857599547 | validation: 0.7309566507977762]
	TIME [epoch: 16.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908704338297622		[learning rate: 0.0035231]
	Learning Rate: 0.00352308
	LOSS [training: 0.5908704338297622 | validation: 0.4633240625153121]
	TIME [epoch: 16 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153208625349194		[learning rate: 0.0035148]
	Learning Rate: 0.00351477
	LOSS [training: 0.6153208625349194 | validation: 0.8470997528658164]
	TIME [epoch: 16.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794330828459344		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.5794330828459344 | validation: 0.6170406405393597]
	TIME [epoch: 16.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6246513545460108		[learning rate: 0.0034982]
	Learning Rate: 0.00349821
	LOSS [training: 0.6246513545460108 | validation: 0.6478046520047116]
	TIME [epoch: 16.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668094980421375		[learning rate: 0.00349]
	Learning Rate: 0.00348996
	LOSS [training: 0.668094980421375 | validation: 0.46517092204549615]
	TIME [epoch: 16 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43655062949570445		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.43655062949570445 | validation: 0.8755529847759903]
	TIME [epoch: 16.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124118221285227		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.5124118221285227 | validation: 0.4197700629468875]
	TIME [epoch: 16.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4613892990594636		[learning rate: 0.0034653]
	Learning Rate: 0.00346532
	LOSS [training: 0.4613892990594636 | validation: 0.9183338048977082]
	TIME [epoch: 16.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9074528555881424		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.9074528555881424 | validation: 0.7886124803398022]
	TIME [epoch: 16.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357570306833181		[learning rate: 0.003449]
	Learning Rate: 0.00344899
	LOSS [training: 0.5357570306833181 | validation: 0.4861784298356064]
	TIME [epoch: 128 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500323193349835		[learning rate: 0.0034409]
	Learning Rate: 0.00344086
	LOSS [training: 0.4500323193349835 | validation: 0.4838171639352218]
	TIME [epoch: 34.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006992234287784		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.4006992234287784 | validation: 0.6347501516985612]
	TIME [epoch: 34.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237958127499909		[learning rate: 0.0034246]
	Learning Rate: 0.00342464
	LOSS [training: 0.4237958127499909 | validation: 0.41370521258713966]
	TIME [epoch: 34.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031751860362929		[learning rate: 0.0034166]
	Learning Rate: 0.00341657
	LOSS [training: 0.4031751860362929 | validation: 0.9057624518144369]
	TIME [epoch: 34.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109127514944238		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.5109127514944238 | validation: 0.8075666038740219]
	TIME [epoch: 34.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7702050776758526		[learning rate: 0.0034005]
	Learning Rate: 0.00340047
	LOSS [training: 0.7702050776758526 | validation: 1.2667474169826272]
	TIME [epoch: 34.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7894776336119037		[learning rate: 0.0033924]
	Learning Rate: 0.00339244
	LOSS [training: 0.7894776336119037 | validation: 0.6267371439814715]
	TIME [epoch: 34.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973493823446211		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.6973493823446211 | validation: 0.5809623174238437]
	TIME [epoch: 34.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748125286160394		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.748125286160394 | validation: 0.8594460152421048]
	TIME [epoch: 34.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242846258148539		[learning rate: 0.0033685]
	Learning Rate: 0.0033685
	LOSS [training: 0.7242846258148539 | validation: 0.463163983829218]
	TIME [epoch: 34.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329818452067446		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.5329818452067446 | validation: 0.780242722742136]
	TIME [epoch: 34.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5614897072862347		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.5614897072862347 | validation: 0.37802110865237154]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098614161389892		[learning rate: 0.0033447]
	Learning Rate: 0.00334471
	LOSS [training: 0.5098614161389892 | validation: 0.41857441667998296]
	TIME [epoch: 34.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43607685644513433		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.43607685644513433 | validation: 0.6081387171678804]
	TIME [epoch: 34.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688508619620891		[learning rate: 0.003329]
	Learning Rate: 0.00332895
	LOSS [training: 0.6688508619620891 | validation: 0.5653101316284093]
	TIME [epoch: 34.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6146560522910272		[learning rate: 0.0033211]
	Learning Rate: 0.0033211
	LOSS [training: 0.6146560522910272 | validation: 0.4522096216447866]
	TIME [epoch: 34.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824115919761641		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.4824115919761641 | validation: 0.7260566258124284]
	TIME [epoch: 34.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035661984710678		[learning rate: 0.0033055]
	Learning Rate: 0.00330545
	LOSS [training: 0.5035661984710678 | validation: 0.45555965055124337]
	TIME [epoch: 34.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5498441358114108		[learning rate: 0.0032977]
	Learning Rate: 0.00329765
	LOSS [training: 0.5498441358114108 | validation: 0.45523024695807524]
	TIME [epoch: 34.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5160008373471471		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.5160008373471471 | validation: 0.3604471063556994]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303854171614942		[learning rate: 0.0032821]
	Learning Rate: 0.00328212
	LOSS [training: 0.4303854171614942 | validation: 0.4220787174156312]
	TIME [epoch: 34.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48848500616715634		[learning rate: 0.0032744]
	Learning Rate: 0.00327437
	LOSS [training: 0.48848500616715634 | validation: 0.4809040601189213]
	TIME [epoch: 34.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3750511956049053		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.3750511956049053 | validation: 0.6654619048161005]
	TIME [epoch: 34.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125055408571022		[learning rate: 0.0032589]
	Learning Rate: 0.00325894
	LOSS [training: 0.5125055408571022 | validation: 0.7991100398348632]
	TIME [epoch: 34.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669320700058977		[learning rate: 0.0032513]
	Learning Rate: 0.00325126
	LOSS [training: 0.4669320700058977 | validation: 0.8151379635945717]
	TIME [epoch: 34.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4784400764928597		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.4784400764928597 | validation: 0.43300537191624433]
	TIME [epoch: 34.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139532233890222		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.5139532233890222 | validation: 0.5883827345418422]
	TIME [epoch: 34.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787946774602766		[learning rate: 0.0032283]
	Learning Rate: 0.0032283
	LOSS [training: 0.4787946774602766 | validation: 0.38963027281211104]
	TIME [epoch: 34.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936227906151692		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.4936227906151692 | validation: 0.6465601069964757]
	TIME [epoch: 34.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290692752566595		[learning rate: 0.0032131]
	Learning Rate: 0.00321309
	LOSS [training: 0.4290692752566595 | validation: 0.37819806936017386]
	TIME [epoch: 34.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44020288515670697		[learning rate: 0.0032055]
	Learning Rate: 0.00320551
	LOSS [training: 0.44020288515670697 | validation: 0.967160770330544]
	TIME [epoch: 34.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6412176324960285		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.6412176324960285 | validation: 0.6181017009549488]
	TIME [epoch: 34.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5175794801142589		[learning rate: 0.0031904]
	Learning Rate: 0.00319041
	LOSS [training: 0.5175794801142589 | validation: 0.5029637528365158]
	TIME [epoch: 34.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309688715080708		[learning rate: 0.0031829]
	Learning Rate: 0.00318288
	LOSS [training: 0.4309688715080708 | validation: 0.3398845053600231]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905311152677355		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.4905311152677355 | validation: 0.7541688731370666]
	TIME [epoch: 34.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5367789610288831		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.5367789610288831 | validation: 0.49323470382618956]
	TIME [epoch: 34.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42540580000957473		[learning rate: 0.0031604]
	Learning Rate: 0.00316041
	LOSS [training: 0.42540580000957473 | validation: 0.32244106738380174]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851384704385104		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.3851384704385104 | validation: 0.7960646953833832]
	TIME [epoch: 34.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7802311326602092		[learning rate: 0.0031455]
	Learning Rate: 0.00314552
	LOSS [training: 0.7802311326602092 | validation: 1.0767107550382198]
	TIME [epoch: 34.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8958656130604905		[learning rate: 0.0031381]
	Learning Rate: 0.0031381
	LOSS [training: 0.8958656130604905 | validation: 0.6229038279326862]
	TIME [epoch: 34.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263950341598466		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.5263950341598466 | validation: 0.4180403998168841]
	TIME [epoch: 34.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37348813984160656		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.37348813984160656 | validation: 0.3724012419841914]
	TIME [epoch: 34.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735153710162237		[learning rate: 0.0031159]
	Learning Rate: 0.00311594
	LOSS [training: 0.3735153710162237 | validation: 0.5602811346474486]
	TIME [epoch: 34.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024129352858686		[learning rate: 0.0031086]
	Learning Rate: 0.0031086
	LOSS [training: 0.5024129352858686 | validation: 0.5018309287073288]
	TIME [epoch: 34.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47601062849329656		[learning rate: 0.0031013]
	Learning Rate: 0.00310126
	LOSS [training: 0.47601062849329656 | validation: 0.38089872382609674]
	TIME [epoch: 34.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34817587269048306		[learning rate: 0.0030939]
	Learning Rate: 0.00309395
	LOSS [training: 0.34817587269048306 | validation: 0.582710508701015]
	TIME [epoch: 34.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.419558953403546		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.419558953403546 | validation: 0.27650113376411595]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654175651213748		[learning rate: 0.0030794]
	Learning Rate: 0.00307937
	LOSS [training: 0.3654175651213748 | validation: 0.5857235576066562]
	TIME [epoch: 34.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41621191380375727		[learning rate: 0.0030721]
	Learning Rate: 0.0030721
	LOSS [training: 0.41621191380375727 | validation: 0.3623861387255946]
	TIME [epoch: 34.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4462378790177052		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.4462378790177052 | validation: 0.5226393187705023]
	TIME [epoch: 34.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36527097034062755		[learning rate: 0.0030576]
	Learning Rate: 0.00305763
	LOSS [training: 0.36527097034062755 | validation: 0.388601819060502]
	TIME [epoch: 34.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869331339501015		[learning rate: 0.0030504]
	Learning Rate: 0.00305042
	LOSS [training: 0.3869331339501015 | validation: 0.6463124666929255]
	TIME [epoch: 34.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5437952755221899		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.5437952755221899 | validation: 0.5153206405552306]
	TIME [epoch: 34.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139358035328186		[learning rate: 0.003036]
	Learning Rate: 0.00303604
	LOSS [training: 0.5139358035328186 | validation: 1.3776308504791384]
	TIME [epoch: 34.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546923565041027		[learning rate: 0.0030289]
	Learning Rate: 0.00302888
	LOSS [training: 1.1546923565041027 | validation: 1.4617237625046744]
	TIME [epoch: 34.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104305026620723		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 1.104305026620723 | validation: 0.5735395879593235]
	TIME [epoch: 34.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46499353750553596		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.46499353750553596 | validation: 0.6003843589536768]
	TIME [epoch: 34.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.482020848822785		[learning rate: 0.0030075]
	Learning Rate: 0.0030075
	LOSS [training: 0.482020848822785 | validation: 0.3152627946696712]
	TIME [epoch: 34.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957227638191393		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.3957227638191393 | validation: 0.38780738262806025]
	TIME [epoch: 34.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970396345727602		[learning rate: 0.0029933]
	Learning Rate: 0.00299332
	LOSS [training: 0.6970396345727602 | validation: 0.6584559668903996]
	TIME [epoch: 34.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44881685979524494		[learning rate: 0.0029863]
	Learning Rate: 0.00298626
	LOSS [training: 0.44881685979524494 | validation: 0.5075565045972028]
	TIME [epoch: 34.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971992088436409		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.4971992088436409 | validation: 0.4321933621402566]
	TIME [epoch: 34.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48314699359373714		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.48314699359373714 | validation: 0.3568142299537174]
	TIME [epoch: 34.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536336558457427		[learning rate: 0.0029652]
	Learning Rate: 0.00296518
	LOSS [training: 0.3536336558457427 | validation: 0.39537186781768835]
	TIME [epoch: 34.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42374734222804356		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.42374734222804356 | validation: 0.3397413272502401]
	TIME [epoch: 34.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153989818276809		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.4153989818276809 | validation: 0.6720289365960662]
	TIME [epoch: 34.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718451353207576		[learning rate: 0.0029442]
	Learning Rate: 0.00294425
	LOSS [training: 0.718451353207576 | validation: 0.8350839988040918]
	TIME [epoch: 34.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5539913506742399		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.5539913506742399 | validation: 0.36776870107252996]
	TIME [epoch: 34.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3738468143959693		[learning rate: 0.0029304]
	Learning Rate: 0.00293037
	LOSS [training: 0.3738468143959693 | validation: 0.46997187117541855]
	TIME [epoch: 34.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033730594555561		[learning rate: 0.0029235]
	Learning Rate: 0.00292346
	LOSS [training: 0.4033730594555561 | validation: 0.5968024096688798]
	TIME [epoch: 34.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958046274205362		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.3958046274205362 | validation: 0.4873326769276919]
	TIME [epoch: 34.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468290019928113		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.4468290019928113 | validation: 0.8590084352380991]
	TIME [epoch: 34.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.670624625557322		[learning rate: 0.0029028]
	Learning Rate: 0.00290282
	LOSS [training: 0.670624625557322 | validation: 0.5639231215378011]
	TIME [epoch: 34.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4558228973557564		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.4558228973557564 | validation: 0.8064081720132957]
	TIME [epoch: 34.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43203194733738437		[learning rate: 0.0028891]
	Learning Rate: 0.00288914
	LOSS [training: 0.43203194733738437 | validation: 0.30434268414202925]
	TIME [epoch: 34.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221730917703188		[learning rate: 0.0028823]
	Learning Rate: 0.00288233
	LOSS [training: 0.3221730917703188 | validation: 0.7446867304788658]
	TIME [epoch: 34.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449318682931676		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.449318682931676 | validation: 0.34208287103491714]
	TIME [epoch: 34.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253679218766021		[learning rate: 0.0028687]
	Learning Rate: 0.00286875
	LOSS [training: 0.5253679218766021 | validation: 0.7228124924359306]
	TIME [epoch: 34.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495536463227693		[learning rate: 0.002862]
	Learning Rate: 0.00286198
	LOSS [training: 0.4495536463227693 | validation: 0.40771786217363304]
	TIME [epoch: 34.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4305924559889026		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.4305924559889026 | validation: 0.4130815775230886]
	TIME [epoch: 34.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613659896794994		[learning rate: 0.0028485]
	Learning Rate: 0.00284849
	LOSS [training: 0.5613659896794994 | validation: 0.7958392069142723]
	TIME [epoch: 34.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9535493995170672		[learning rate: 0.0028418]
	Learning Rate: 0.00284178
	LOSS [training: 0.9535493995170672 | validation: 0.5651812567419453]
	TIME [epoch: 34.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.546404070806539		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.546404070806539 | validation: 0.4207739180359912]
	TIME [epoch: 34.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984308079391728		[learning rate: 0.0028284]
	Learning Rate: 0.00282838
	LOSS [training: 0.3984308079391728 | validation: 0.8036417109453233]
	TIME [epoch: 34.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5291185661222177		[learning rate: 0.0028217]
	Learning Rate: 0.00282171
	LOSS [training: 0.5291185661222177 | validation: 0.706615267552343]
	TIME [epoch: 34.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097041138492475		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 1.097041138492475 | validation: 0.7250138566339887]
	TIME [epoch: 34.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577820019858349		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.6577820019858349 | validation: 0.3854027638047359]
	TIME [epoch: 34.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363963091226136		[learning rate: 0.0028018]
	Learning Rate: 0.00280179
	LOSS [training: 0.3363963091226136 | validation: 0.5239471914061231]
	TIME [epoch: 34.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39949946118866136		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.39949946118866136 | validation: 0.4195429346925908]
	TIME [epoch: 34.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42875261670276094		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.42875261670276094 | validation: 0.2643325497006359]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535704246239028		[learning rate: 0.002782]
	Learning Rate: 0.00278201
	LOSS [training: 0.4535704246239028 | validation: 0.33694662807279296]
	TIME [epoch: 34.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42843097014282583		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.42843097014282583 | validation: 0.8057498676219166]
	TIME [epoch: 34.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809853359372831		[learning rate: 0.0027689]
	Learning Rate: 0.0027689
	LOSS [training: 0.5809853359372831 | validation: 0.8187755513213215]
	TIME [epoch: 34.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662812771323782		[learning rate: 0.0027624]
	Learning Rate: 0.00276237
	LOSS [training: 0.5662812771323782 | validation: 0.3714377776230655]
	TIME [epoch: 34.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307985461771058		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.3307985461771058 | validation: 0.5303536689577997]
	TIME [epoch: 34.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4211506462092509		[learning rate: 0.0027494]
	Learning Rate: 0.00274936
	LOSS [training: 0.4211506462092509 | validation: 0.8934196346750598]
	TIME [epoch: 34.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494129538838255		[learning rate: 0.0027429]
	Learning Rate: 0.00274287
	LOSS [training: 0.494129538838255 | validation: 0.4283306937647521]
	TIME [epoch: 34.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824392180846991		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.6824392180846991 | validation: 0.5658685427988355]
	TIME [epoch: 34.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4863678619037295		[learning rate: 0.0027299]
	Learning Rate: 0.00272994
	LOSS [training: 0.4863678619037295 | validation: 0.4070336961660408]
	TIME [epoch: 34.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783094052875039		[learning rate: 0.0027235]
	Learning Rate: 0.00272351
	LOSS [training: 0.3783094052875039 | validation: 0.383851366347689]
	TIME [epoch: 34.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234101420962032		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.5234101420962032 | validation: 0.5536041750186567]
	TIME [epoch: 34.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37775045893612047		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.37775045893612047 | validation: 0.4231821633712368]
	TIME [epoch: 34.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4195224641804748		[learning rate: 0.0027043]
	Learning Rate: 0.00270428
	LOSS [training: 0.4195224641804748 | validation: 0.7774155804701044]
	TIME [epoch: 34.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6197756037490492		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.6197756037490492 | validation: 0.4313702704492889]
	TIME [epoch: 34.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35400098744791886		[learning rate: 0.0026915]
	Learning Rate: 0.00269153
	LOSS [training: 0.35400098744791886 | validation: 0.3246021065849902]
	TIME [epoch: 34.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297887656059224		[learning rate: 0.0026852]
	Learning Rate: 0.00268519
	LOSS [training: 0.3297887656059224 | validation: 0.35979175827581455]
	TIME [epoch: 34.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364500004414112		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.3364500004414112 | validation: 0.3632983991718911]
	TIME [epoch: 34.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892475307511508		[learning rate: 0.0026725]
	Learning Rate: 0.00267253
	LOSS [training: 0.3892475307511508 | validation: 0.6605995054648185]
	TIME [epoch: 34.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41341744769437927		[learning rate: 0.0026662]
	Learning Rate: 0.00266623
	LOSS [training: 0.41341744769437927 | validation: 1.1441710879848515]
	TIME [epoch: 34.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7784083886337794		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.7784083886337794 | validation: 0.7325346258390808]
	TIME [epoch: 34.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46433821406982634		[learning rate: 0.0026537]
	Learning Rate: 0.00265367
	LOSS [training: 0.46433821406982634 | validation: 0.34673069509266224]
	TIME [epoch: 34.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37853378985650793		[learning rate: 0.0026474]
	Learning Rate: 0.00264741
	LOSS [training: 0.37853378985650793 | validation: 0.5729986179428109]
	TIME [epoch: 34.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839820353498566		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.4839820353498566 | validation: 0.3900920225542248]
	TIME [epoch: 34.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4339755254235784		[learning rate: 0.0026349]
	Learning Rate: 0.00263493
	LOSS [training: 0.4339755254235784 | validation: 0.3546660737957059]
	TIME [epoch: 34.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361447564642816		[learning rate: 0.0026287]
	Learning Rate: 0.00262872
	LOSS [training: 0.361447564642816 | validation: 0.3822774566525545]
	TIME [epoch: 34.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271293492664753		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.3271293492664753 | validation: 0.5449763219966397]
	TIME [epoch: 34.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47106553042817434		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.47106553042817434 | validation: 0.6929156420996416]
	TIME [epoch: 34.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369990440746515		[learning rate: 0.0026102]
	Learning Rate: 0.00261016
	LOSS [training: 0.5369990440746515 | validation: 0.31566859387415286]
	TIME [epoch: 34.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30632999643408243		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.30632999643408243 | validation: 0.4866447573358423]
	TIME [epoch: 34.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547963584152006		[learning rate: 0.0025979]
	Learning Rate: 0.00259786
	LOSS [training: 0.3547963584152006 | validation: 0.44726393243804113]
	TIME [epoch: 34.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278604416794676		[learning rate: 0.0025917]
	Learning Rate: 0.00259173
	LOSS [training: 0.3278604416794676 | validation: 0.5546859666362568]
	TIME [epoch: 34.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43146945973791795		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.43146945973791795 | validation: 0.8718931807390122]
	TIME [epoch: 34.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467282941042058		[learning rate: 0.0025795]
	Learning Rate: 0.00257952
	LOSS [training: 0.4467282941042058 | validation: 0.3814293317813805]
	TIME [epoch: 34.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42608959214459696		[learning rate: 0.0025734]
	Learning Rate: 0.00257343
	LOSS [training: 0.42608959214459696 | validation: 0.4605453048189025]
	TIME [epoch: 34.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977113889234245		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2977113889234245 | validation: 0.3555342187347901]
	TIME [epoch: 34.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822064990653056		[learning rate: 0.0025613]
	Learning Rate: 0.00256131
	LOSS [training: 0.2822064990653056 | validation: 0.365909161081266]
	TIME [epoch: 34.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36588671605937306		[learning rate: 0.0025553]
	Learning Rate: 0.00255526
	LOSS [training: 0.36588671605937306 | validation: 0.5659040900212848]
	TIME [epoch: 34.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482337839612262		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.3482337839612262 | validation: 0.2982107908737103]
	TIME [epoch: 34.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207900956894335		[learning rate: 0.0025432]
	Learning Rate: 0.00254322
	LOSS [training: 0.3207900956894335 | validation: 0.3810795941759194]
	TIME [epoch: 34.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1829669355571966		[learning rate: 0.0025372]
	Learning Rate: 0.00253722
	LOSS [training: 1.1829669355571966 | validation: 1.1339593314000727]
	TIME [epoch: 34.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9777325892144269		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.9777325892144269 | validation: 1.0388813725493575]
	TIME [epoch: 34.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661021596581541		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.6661021596581541 | validation: 0.3380549071903598]
	TIME [epoch: 34.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39410697248213616		[learning rate: 0.0025193]
	Learning Rate: 0.00251931
	LOSS [training: 0.39410697248213616 | validation: 0.38978469348054956]
	TIME [epoch: 34.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024345473112138		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.4024345473112138 | validation: 0.40113625504875905]
	TIME [epoch: 34.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4887195356259667		[learning rate: 0.0025074]
	Learning Rate: 0.00250744
	LOSS [training: 0.4887195356259667 | validation: 0.8159358359488353]
	TIME [epoch: 34.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753133968185123		[learning rate: 0.0025015]
	Learning Rate: 0.00250153
	LOSS [training: 0.6753133968185123 | validation: 0.516966150723899]
	TIME [epoch: 34.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374675847262813		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.6374675847262813 | validation: 0.42819964918385545]
	TIME [epoch: 34.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32345978298469574		[learning rate: 0.0024897]
	Learning Rate: 0.00248974
	LOSS [training: 0.32345978298469574 | validation: 0.2535204218375037]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049819810127663		[learning rate: 0.0024839]
	Learning Rate: 0.00248387
	LOSS [training: 0.3049819810127663 | validation: 0.3569205148284231]
	TIME [epoch: 34.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100585475771013		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.3100585475771013 | validation: 0.3165583059807475]
	TIME [epoch: 34.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32584824471110835		[learning rate: 0.0024722]
	Learning Rate: 0.00247216
	LOSS [training: 0.32584824471110835 | validation: 0.8048971774558707]
	TIME [epoch: 34.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971795665641084		[learning rate: 0.0024663]
	Learning Rate: 0.00246633
	LOSS [training: 0.5971795665641084 | validation: 0.7322166305809883]
	TIME [epoch: 34.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.574142266820508		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.574142266820508 | validation: 0.3120445449029391]
	TIME [epoch: 34.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26451965443393255		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.26451965443393255 | validation: 0.4055110748741404]
	TIME [epoch: 34.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3780160559838784		[learning rate: 0.0024489]
	Learning Rate: 0.00244892
	LOSS [training: 0.3780160559838784 | validation: 0.25213161769143005]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_646.pth
	Model improved!!!
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26833656560462404		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.26833656560462404 | validation: 0.2986517612887828]
	TIME [epoch: 34.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9179597895794253		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.9179597895794253 | validation: 0.6653653366515999]
	TIME [epoch: 34.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5444804268113254		[learning rate: 0.0024316]
	Learning Rate: 0.00243163
	LOSS [training: 0.5444804268113254 | validation: 0.23844336580425296]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26877598368834177		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.26877598368834177 | validation: 0.2900607733699834]
	TIME [epoch: 34.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362802469819257		[learning rate: 0.0024202]
	Learning Rate: 0.00242017
	LOSS [training: 0.3362802469819257 | validation: 0.3348739588736417]
	TIME [epoch: 34.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802101498532772		[learning rate: 0.0024145]
	Learning Rate: 0.00241446
	LOSS [training: 0.3802101498532772 | validation: 0.3769670598132577]
	TIME [epoch: 34.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096031294869794		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.4096031294869794 | validation: 0.3167026472401732]
	TIME [epoch: 34.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628662567563711		[learning rate: 0.0024031]
	Learning Rate: 0.00240309
	LOSS [training: 0.2628662567563711 | validation: 0.6642349711881403]
	TIME [epoch: 34.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247638844668736		[learning rate: 0.0023974]
	Learning Rate: 0.00239742
	LOSS [training: 0.5247638844668736 | validation: 0.3922481665751979]
	TIME [epoch: 34.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559869150866507		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.3559869150866507 | validation: 0.6563853056767335]
	TIME [epoch: 34.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528535461806321		[learning rate: 0.0023861]
	Learning Rate: 0.00238612
	LOSS [training: 0.4528535461806321 | validation: 0.2999681072260114]
	TIME [epoch: 34.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778780526424091		[learning rate: 0.0023805]
	Learning Rate: 0.00238049
	LOSS [training: 0.2778780526424091 | validation: 0.226229194445764]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3214681234920197		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.3214681234920197 | validation: 0.42964864936227654]
	TIME [epoch: 34.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35033560636054184		[learning rate: 0.0023693]
	Learning Rate: 0.00236927
	LOSS [training: 0.35033560636054184 | validation: 0.34302844867319865]
	TIME [epoch: 34.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42372693054846927		[learning rate: 0.0023637]
	Learning Rate: 0.00236369
	LOSS [training: 0.42372693054846927 | validation: 0.3437677776645791]
	TIME [epoch: 34.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31622637833868195		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.31622637833868195 | validation: 0.395166481677794]
	TIME [epoch: 34.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.623631068611417		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.623631068611417 | validation: 0.6685111249672404]
	TIME [epoch: 34.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532053385643549		[learning rate: 0.002347]
	Learning Rate: 0.002347
	LOSS [training: 0.532053385643549 | validation: 0.5274520957291645]
	TIME [epoch: 34.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608003676752116		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.4608003676752116 | validation: 0.4530974763179882]
	TIME [epoch: 34.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067270795745969		[learning rate: 0.0023359]
	Learning Rate: 0.00233594
	LOSS [training: 0.4067270795745969 | validation: 0.4092836939404775]
	TIME [epoch: 34.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913769725540123		[learning rate: 0.0023304]
	Learning Rate: 0.00233043
	LOSS [training: 0.3913769725540123 | validation: 0.3911241374169811]
	TIME [epoch: 34.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32732590164255226		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.32732590164255226 | validation: 0.2844791005584377]
	TIME [epoch: 34.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44288422581850656		[learning rate: 0.0023194]
	Learning Rate: 0.00231945
	LOSS [training: 0.44288422581850656 | validation: 0.5318803450041361]
	TIME [epoch: 34.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805617255883228		[learning rate: 0.002314]
	Learning Rate: 0.00231398
	LOSS [training: 0.3805617255883228 | validation: 0.3310539381287819]
	TIME [epoch: 34.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32453101000956697		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.32453101000956697 | validation: 0.34888919051002476]
	TIME [epoch: 34.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40579563898851256		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.40579563898851256 | validation: 0.3947354607014185]
	TIME [epoch: 34.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343712109691996		[learning rate: 0.0022976]
	Learning Rate: 0.00229764
	LOSS [training: 0.3343712109691996 | validation: 0.7298529135468861]
	TIME [epoch: 34.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45233436456647325		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.45233436456647325 | validation: 0.35854174850157106]
	TIME [epoch: 34.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328674855568322		[learning rate: 0.0022868]
	Learning Rate: 0.00228681
	LOSS [training: 0.3328674855568322 | validation: 0.2865227453738911]
	TIME [epoch: 34.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34312571195489067		[learning rate: 0.0022814]
	Learning Rate: 0.00228142
	LOSS [training: 0.34312571195489067 | validation: 0.3992284953947979]
	TIME [epoch: 34.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41645942474411857		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.41645942474411857 | validation: 0.6691324228271609]
	TIME [epoch: 34.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167826486686302		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.5167826486686302 | validation: 0.4660627658894424]
	TIME [epoch: 34.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3762879496107087		[learning rate: 0.0022653]
	Learning Rate: 0.00226531
	LOSS [training: 0.3762879496107087 | validation: 0.41196133769065113]
	TIME [epoch: 34.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354784155012557		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.3354784155012557 | validation: 0.3956907432484792]
	TIME [epoch: 34.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528156965531779		[learning rate: 0.0022546]
	Learning Rate: 0.00225464
	LOSS [training: 0.3528156965531779 | validation: 0.3098341986947388]
	TIME [epoch: 34.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212043069799517		[learning rate: 0.0022493]
	Learning Rate: 0.00224932
	LOSS [training: 0.3212043069799517 | validation: 0.3679089538448057]
	TIME [epoch: 34.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128168898766043		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.3128168898766043 | validation: 0.21867400920330998]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801011092451924		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.2801011092451924 | validation: 0.3989897894735079]
	TIME [epoch: 34.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556495118865623		[learning rate: 0.0022334]
	Learning Rate: 0.00223344
	LOSS [training: 0.6556495118865623 | validation: 0.9438762316947619]
	TIME [epoch: 34.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536481953302006		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.6536481953302006 | validation: 0.7335482378663734]
	TIME [epoch: 34.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5981402422729987		[learning rate: 0.0022229]
	Learning Rate: 0.00222292
	LOSS [training: 0.5981402422729987 | validation: 0.7187268813128747]
	TIME [epoch: 34.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091442992375106		[learning rate: 0.0022177]
	Learning Rate: 0.00221767
	LOSS [training: 0.5091442992375106 | validation: 0.6668088512701553]
	TIME [epoch: 34.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4851962651711812		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.4851962651711812 | validation: 0.5285925837532176]
	TIME [epoch: 34.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4712714130771002		[learning rate: 0.0022072]
	Learning Rate: 0.00220722
	LOSS [training: 0.4712714130771002 | validation: 0.5988139660205654]
	TIME [epoch: 34.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5367541114653926		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.5367541114653926 | validation: 0.6065561594253845]
	TIME [epoch: 34.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865285254728766		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.4865285254728766 | validation: 0.5209293978289736]
	TIME [epoch: 34.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4994874322033054		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.4994874322033054 | validation: 0.46425855716033093]
	TIME [epoch: 34.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753913054167292		[learning rate: 0.0021865]
	Learning Rate: 0.00218647
	LOSS [training: 0.4753913054167292 | validation: 0.5751998784444905]
	TIME [epoch: 34.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411293794805588		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.5411293794805588 | validation: 0.5355035799805868]
	TIME [epoch: 34.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4180097924525308		[learning rate: 0.0021762]
	Learning Rate: 0.00217617
	LOSS [training: 0.4180097924525308 | validation: 0.3077322544613416]
	TIME [epoch: 34.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2805998467958404		[learning rate: 0.002171]
	Learning Rate: 0.00217103
	LOSS [training: 0.2805998467958404 | validation: 0.2983774550824285]
	TIME [epoch: 34.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30509211782368434		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.30509211782368434 | validation: 0.2779973840602451]
	TIME [epoch: 34.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4706259664742802		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.4706259664742802 | validation: 0.453911690936577]
	TIME [epoch: 34.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38459421491141066		[learning rate: 0.0021557]
	Learning Rate: 0.00215571
	LOSS [training: 0.38459421491141066 | validation: 0.5357621200488984]
	TIME [epoch: 34.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4184161841434211		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.4184161841434211 | validation: 0.4639324571909456]
	TIME [epoch: 34.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36277780173189944		[learning rate: 0.0021455]
	Learning Rate: 0.00214555
	LOSS [training: 0.36277780173189944 | validation: 0.3081332023786538]
	TIME [epoch: 34.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921371061016903		[learning rate: 0.0021405]
	Learning Rate: 0.00214049
	LOSS [training: 0.2921371061016903 | validation: 0.3170236147279192]
	TIME [epoch: 34.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332783119239572		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.3332783119239572 | validation: 0.23896895299471807]
	TIME [epoch: 34.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47338423761003157		[learning rate: 0.0021304]
	Learning Rate: 0.0021304
	LOSS [training: 0.47338423761003157 | validation: 0.3645442518528049]
	TIME [epoch: 34.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117658300817632		[learning rate: 0.0021254]
	Learning Rate: 0.00212538
	LOSS [training: 0.3117658300817632 | validation: 0.2749524638259562]
	TIME [epoch: 34.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286609666390501		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.286609666390501 | validation: 0.2737894407153687]
	TIME [epoch: 34.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308955566160215		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.308955566160215 | validation: 0.26466539838716696]
	TIME [epoch: 34.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049301752008213		[learning rate: 0.0021104]
	Learning Rate: 0.00211037
	LOSS [training: 0.3049301752008213 | validation: 0.4597316862127664]
	TIME [epoch: 34.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39280730999355085		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.39280730999355085 | validation: 0.2513855401550807]
	TIME [epoch: 34.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309112336279012		[learning rate: 0.0021004]
	Learning Rate: 0.00210043
	LOSS [training: 0.309112336279012 | validation: 0.40493890530208376]
	TIME [epoch: 34.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178004045084055		[learning rate: 0.0020955]
	Learning Rate: 0.00209547
	LOSS [training: 0.3178004045084055 | validation: 0.45844925592197366]
	TIME [epoch: 34.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394797405579961		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.394797405579961 | validation: 0.2421779371577415]
	TIME [epoch: 34.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346428326088657		[learning rate: 0.0020856]
	Learning Rate: 0.0020856
	LOSS [training: 0.3346428326088657 | validation: 0.5141260344774305]
	TIME [epoch: 34.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843246620118982		[learning rate: 0.0020807]
	Learning Rate: 0.00208068
	LOSS [training: 0.3843246620118982 | validation: 0.3066711354222436]
	TIME [epoch: 34.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674706497934284		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.2674706497934284 | validation: 0.3686084580647271]
	TIME [epoch: 34.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35326579971194083		[learning rate: 0.0020709]
	Learning Rate: 0.00207087
	LOSS [training: 0.35326579971194083 | validation: 0.44222189740715134]
	TIME [epoch: 34.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700487847455542		[learning rate: 0.002066]
	Learning Rate: 0.00206599
	LOSS [training: 0.3700487847455542 | validation: 0.2832990867672961]
	TIME [epoch: 34.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926702710878738		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.2926702710878738 | validation: 0.42562718122423304]
	TIME [epoch: 34.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565943390595138		[learning rate: 0.0020563]
	Learning Rate: 0.00205626
	LOSS [training: 0.3565943390595138 | validation: 0.7345682326337193]
	TIME [epoch: 34.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041917714363894		[learning rate: 0.0020514]
	Learning Rate: 0.0020514
	LOSS [training: 0.6041917714363894 | validation: 0.35054276741914575]
	TIME [epoch: 34.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422996595638611		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.422996595638611 | validation: 0.8675670856285913]
	TIME [epoch: 34.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013840479384867		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.7013840479384867 | validation: 0.6214495211571202]
	TIME [epoch: 34.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131044053378899		[learning rate: 0.0020369]
	Learning Rate: 0.00203692
	LOSS [training: 0.5131044053378899 | validation: 0.2781613913068172]
	TIME [epoch: 34.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27925714634123106		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.27925714634123106 | validation: 0.22574284415562396]
	TIME [epoch: 34.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423487922112607		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.2423487922112607 | validation: 0.2284386870540524]
	TIME [epoch: 34.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590840916509411		[learning rate: 0.0020225]
	Learning Rate: 0.00202254
	LOSS [training: 0.2590840916509411 | validation: 0.30898030285640044]
	TIME [epoch: 34.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821182862102728		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2821182862102728 | validation: 0.27016230937617186]
	TIME [epoch: 34.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136355889877648		[learning rate: 0.002013]
	Learning Rate: 0.00201301
	LOSS [training: 0.5136355889877648 | validation: 1.9960347615253942]
	TIME [epoch: 34.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192985867430676		[learning rate: 0.0020083]
	Learning Rate: 0.00200826
	LOSS [training: 1.192985867430676 | validation: 1.0190764993686021]
	TIME [epoch: 34.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42364922851994025		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.42364922851994025 | validation: 0.25149684184272525]
	TIME [epoch: 34.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828078066217261		[learning rate: 0.0019988]
	Learning Rate: 0.0019988
	LOSS [training: 0.2828078066217261 | validation: 0.1862067108429734]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931311441127402		[learning rate: 0.0019941]
	Learning Rate: 0.00199408
	LOSS [training: 0.2931311441127402 | validation: 0.27416888727643185]
	TIME [epoch: 34.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745640876330288		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.2745640876330288 | validation: 0.2532640712357521]
	TIME [epoch: 34.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760466671494715		[learning rate: 0.0019847]
	Learning Rate: 0.00198469
	LOSS [training: 0.8760466671494715 | validation: 1.3170779472791148]
	TIME [epoch: 34.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799736231617062		[learning rate: 0.00198]
	Learning Rate: 0.00198001
	LOSS [training: 0.799736231617062 | validation: 0.4676733521132541]
	TIME [epoch: 34.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47020741292408597		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.47020741292408597 | validation: 0.3879912651772529]
	TIME [epoch: 34.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44983145016157455		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.44983145016157455 | validation: 0.304930780020907]
	TIME [epoch: 34.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985884591986297		[learning rate: 0.001966]
	Learning Rate: 0.00196603
	LOSS [training: 0.2985884591986297 | validation: 0.26479536538357384]
	TIME [epoch: 34.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194084700442309		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.7194084700442309 | validation: 0.6737120829555958]
	TIME [epoch: 34.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7643187428073048		[learning rate: 0.0019568]
	Learning Rate: 0.00195676
	LOSS [training: 0.7643187428073048 | validation: 0.6185795124351434]
	TIME [epoch: 34.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626683230467462		[learning rate: 0.0019521]
	Learning Rate: 0.00195215
	LOSS [training: 0.5626683230467462 | validation: 0.42765145305755703]
	TIME [epoch: 34.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4774824290739324		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.4774824290739324 | validation: 0.3472600126688604]
	TIME [epoch: 34.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27373425716519173		[learning rate: 0.0019429]
	Learning Rate: 0.00194295
	LOSS [training: 0.27373425716519173 | validation: 0.2988839464807227]
	TIME [epoch: 34.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2735679692446775		[learning rate: 0.0019384]
	Learning Rate: 0.00193837
	LOSS [training: 0.2735679692446775 | validation: 0.19043751046589613]
	TIME [epoch: 34.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475627050049611		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.3475627050049611 | validation: 0.344517393457744]
	TIME [epoch: 34.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29415318468526414		[learning rate: 0.0019292]
	Learning Rate: 0.00192923
	LOSS [training: 0.29415318468526414 | validation: 0.23728137391751933]
	TIME [epoch: 34.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27184508284705944		[learning rate: 0.0019247]
	Learning Rate: 0.00192468
	LOSS [training: 0.27184508284705944 | validation: 0.27921080800498954]
	TIME [epoch: 34.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27350176568572127		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.27350176568572127 | validation: 0.25630880444601944]
	TIME [epoch: 34.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27101753621186386		[learning rate: 0.0019156]
	Learning Rate: 0.00191561
	LOSS [training: 0.27101753621186386 | validation: 0.2806491718575514]
	TIME [epoch: 34.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29305589354768885		[learning rate: 0.0019111]
	Learning Rate: 0.00191109
	LOSS [training: 0.29305589354768885 | validation: 0.4538815661422414]
	TIME [epoch: 34.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31905618494387467		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.31905618494387467 | validation: 0.21202823099220064]
	TIME [epoch: 34.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22014002996050555		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.22014002996050555 | validation: 1.0163975045448608]
	TIME [epoch: 34.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8422086555557656		[learning rate: 0.0018976]
	Learning Rate: 0.0018976
	LOSS [training: 0.8422086555557656 | validation: 0.47676167381746776]
	TIME [epoch: 34.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081969522489164		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.4081969522489164 | validation: 0.39789529719262107]
	TIME [epoch: 34.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005987064492982		[learning rate: 0.0018887]
	Learning Rate: 0.00188866
	LOSS [training: 0.3005987064492982 | validation: 0.26182299346580334]
	TIME [epoch: 34.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26454518929204857		[learning rate: 0.0018842]
	Learning Rate: 0.00188421
	LOSS [training: 0.26454518929204857 | validation: 0.33178994729325395]
	TIME [epoch: 34.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28011777753868367		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.28011777753868367 | validation: 0.2792908156426643]
	TIME [epoch: 34.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497196735797325		[learning rate: 0.0018753]
	Learning Rate: 0.00187533
	LOSS [training: 0.3497196735797325 | validation: 0.3062502761215471]
	TIME [epoch: 34.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3210370812763075		[learning rate: 0.0018709]
	Learning Rate: 0.0018709
	LOSS [training: 0.3210370812763075 | validation: 0.2762961668561595]
	TIME [epoch: 34.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23010989476617744		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.23010989476617744 | validation: 0.320135290130913]
	TIME [epoch: 34.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31046461802226116		[learning rate: 0.0018621]
	Learning Rate: 0.00186209
	LOSS [training: 0.31046461802226116 | validation: 0.31223282433695315]
	TIME [epoch: 34.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3192212064413702		[learning rate: 0.0018577]
	Learning Rate: 0.00185769
	LOSS [training: 0.3192212064413702 | validation: 0.24398331220873218]
	TIME [epoch: 34.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229266838409065		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.3229266838409065 | validation: 0.2483176460694757]
	TIME [epoch: 34.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172136321831031		[learning rate: 0.0018489]
	Learning Rate: 0.00184894
	LOSS [training: 0.3172136321831031 | validation: 0.22992205472413046]
	TIME [epoch: 34.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24088419902529706		[learning rate: 0.0018446]
	Learning Rate: 0.00184458
	LOSS [training: 0.24088419902529706 | validation: 0.44473599344721654]
	TIME [epoch: 34.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37343120172260597		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.37343120172260597 | validation: 0.26086593729227836]
	TIME [epoch: 34.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179295740065781		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.5179295740065781 | validation: 0.2347513253581811]
	TIME [epoch: 34.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665091603847999		[learning rate: 0.0018316]
	Learning Rate: 0.00183156
	LOSS [training: 0.2665091603847999 | validation: 0.2790358033363727]
	TIME [epoch: 34.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2488213958724505		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.2488213958724505 | validation: 0.35491296170778164]
	TIME [epoch: 34.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49994401927573756		[learning rate: 0.0018229]
	Learning Rate: 0.00182293
	LOSS [training: 0.49994401927573756 | validation: 0.3726645001588038]
	TIME [epoch: 34.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4101560951403932		[learning rate: 0.0018186]
	Learning Rate: 0.00181863
	LOSS [training: 0.4101560951403932 | validation: 0.3697893950311584]
	TIME [epoch: 34.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172854814208993		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.3172854814208993 | validation: 0.27890249257709704]
	TIME [epoch: 34.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30837882866474564		[learning rate: 0.0018101]
	Learning Rate: 0.00181006
	LOSS [training: 0.30837882866474564 | validation: 0.21073348941608872]
	TIME [epoch: 34.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22169319240228502		[learning rate: 0.0018058]
	Learning Rate: 0.00180579
	LOSS [training: 0.22169319240228502 | validation: 0.3614675317914323]
	TIME [epoch: 34.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24050685365847202		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24050685365847202 | validation: 0.27468088351093345]
	TIME [epoch: 34.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23332641112117666		[learning rate: 0.0017973]
	Learning Rate: 0.00179728
	LOSS [training: 0.23332641112117666 | validation: 0.3106575902643517]
	TIME [epoch: 34.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23716672377437426		[learning rate: 0.001793]
	Learning Rate: 0.00179304
	LOSS [training: 0.23716672377437426 | validation: 0.23707323882883585]
	TIME [epoch: 34.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25094944447410333		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.25094944447410333 | validation: 0.3319945364870101]
	TIME [epoch: 34.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308657767872102		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.308657767872102 | validation: 0.35535823655375015]
	TIME [epoch: 34.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41421845278400354		[learning rate: 0.0017804]
	Learning Rate: 0.00178038
	LOSS [training: 0.41421845278400354 | validation: 0.8763588233978703]
	TIME [epoch: 34.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5603015149924289		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.5603015149924289 | validation: 0.3469128243843952]
	TIME [epoch: 34.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29854122357248786		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.29854122357248786 | validation: 0.19196947042008772]
	TIME [epoch: 34.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572248516974963		[learning rate: 0.0017678]
	Learning Rate: 0.00176781
	LOSS [training: 0.2572248516974963 | validation: 0.17852761870647244]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20673213239783225		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.20673213239783225 | validation: 0.24388016196153284]
	TIME [epoch: 34.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20983907811483854		[learning rate: 0.0017595]
	Learning Rate: 0.00175948
	LOSS [training: 0.20983907811483854 | validation: 0.19937667168261858]
	TIME [epoch: 34.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20011163731896567		[learning rate: 0.0017553]
	Learning Rate: 0.00175533
	LOSS [training: 0.20011163731896567 | validation: 0.2257183342144134]
	TIME [epoch: 34.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927116605297079		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2927116605297079 | validation: 0.4628372170663033]
	TIME [epoch: 34.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35968511282813787		[learning rate: 0.0017471]
	Learning Rate: 0.00174706
	LOSS [training: 0.35968511282813787 | validation: 0.33645425037642984]
	TIME [epoch: 34.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25251292050200846		[learning rate: 0.0017429]
	Learning Rate: 0.00174294
	LOSS [training: 0.25251292050200846 | validation: 0.6326255015433018]
	TIME [epoch: 34.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41563955286782117		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.41563955286782117 | validation: 0.4739607467293345]
	TIME [epoch: 34.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4932560628822529		[learning rate: 0.0017347]
	Learning Rate: 0.00173473
	LOSS [training: 0.4932560628822529 | validation: 0.48465400455245533]
	TIME [epoch: 34.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872851122634263		[learning rate: 0.0017306]
	Learning Rate: 0.00173063
	LOSS [training: 0.3872851122634263 | validation: 0.31988505551491964]
	TIME [epoch: 34.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28780543054500096		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.28780543054500096 | validation: 0.3633976406069035]
	TIME [epoch: 34.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33224264494473765		[learning rate: 0.0017225]
	Learning Rate: 0.00172248
	LOSS [training: 0.33224264494473765 | validation: 0.23094647102919458]
	TIME [epoch: 34.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27411111899784807		[learning rate: 0.0017184]
	Learning Rate: 0.00171842
	LOSS [training: 0.27411111899784807 | validation: 0.3861667118982026]
	TIME [epoch: 34.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601370511654817		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.3601370511654817 | validation: 0.3301920288768674]
	TIME [epoch: 34.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24532042768740697		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.24532042768740697 | validation: 0.2098171435438143]
	TIME [epoch: 34.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30905361607828863		[learning rate: 0.0017063]
	Learning Rate: 0.00170628
	LOSS [training: 0.30905361607828863 | validation: 0.4478396232600411]
	TIME [epoch: 34.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992609167453485		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.3992609167453485 | validation: 0.3012297938095734]
	TIME [epoch: 34.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644559286989677		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.2644559286989677 | validation: 0.27231418175853983]
	TIME [epoch: 34.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2491193288593058		[learning rate: 0.0016942]
	Learning Rate: 0.00169424
	LOSS [training: 0.2491193288593058 | validation: 0.25947582058442964]
	TIME [epoch: 34.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263188313383261		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.263188313383261 | validation: 0.18238237254258705]
	TIME [epoch: 34.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972651729157216		[learning rate: 0.0016863]
	Learning Rate: 0.00168625
	LOSS [training: 0.1972651729157216 | validation: 0.26550600101994076]
	TIME [epoch: 34.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344852938968613		[learning rate: 0.0016823]
	Learning Rate: 0.00168228
	LOSS [training: 0.3344852938968613 | validation: 0.592045284944966]
	TIME [epoch: 34.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46061931197797845		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.46061931197797845 | validation: 0.4387067403991687]
	TIME [epoch: 34.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48956892181520295		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.48956892181520295 | validation: 0.8321922312319942]
	TIME [epoch: 34.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205042210756921		[learning rate: 0.0016704]
	Learning Rate: 0.0016704
	LOSS [training: 0.6205042210756921 | validation: 0.6580799828759456]
	TIME [epoch: 34.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586375752777762		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.5586375752777762 | validation: 0.6403226236421404]
	TIME [epoch: 34.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854777545211055		[learning rate: 0.0016625]
	Learning Rate: 0.00166253
	LOSS [training: 0.5854777545211055 | validation: 0.8184495579131824]
	TIME [epoch: 34.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161069775479497		[learning rate: 0.0016586]
	Learning Rate: 0.00165861
	LOSS [training: 0.6161069775479497 | validation: 0.672007834060548]
	TIME [epoch: 34.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504903356302692		[learning rate: 0.0016547]
	Learning Rate: 0.0016547
	LOSS [training: 0.504903356302692 | validation: 0.5212001839025866]
	TIME [epoch: 34.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4266483372604107		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.4266483372604107 | validation: 0.5043239529726788]
	TIME [epoch: 34.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41279911982947387		[learning rate: 0.0016469]
	Learning Rate: 0.0016469
	LOSS [training: 0.41279911982947387 | validation: 0.44959412639494073]
	TIME [epoch: 34.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4322441239573859		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.4322441239573859 | validation: 0.5124775161053572]
	TIME [epoch: 34.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3838956659210968		[learning rate: 0.0016391]
	Learning Rate: 0.00163914
	LOSS [training: 0.3838956659210968 | validation: 0.4494873552185564]
	TIME [epoch: 34.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559558681476254		[learning rate: 0.0016353]
	Learning Rate: 0.00163527
	LOSS [training: 0.3559558681476254 | validation: 0.38519025042947497]
	TIME [epoch: 34.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321238433294248		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.3321238433294248 | validation: 0.3026313432059513]
	TIME [epoch: 34.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500234904740996		[learning rate: 0.0016276]
	Learning Rate: 0.00162757
	LOSS [training: 0.2500234904740996 | validation: 0.5053884838274252]
	TIME [epoch: 34.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3208414063901654		[learning rate: 0.0016237]
	Learning Rate: 0.00162373
	LOSS [training: 0.3208414063901654 | validation: 0.2802435494219794]
	TIME [epoch: 34.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24944897857227172		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24944897857227172 | validation: 0.18328122253050874]
	TIME [epoch: 34.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22296997669107627		[learning rate: 0.0016161]
	Learning Rate: 0.00161608
	LOSS [training: 0.22296997669107627 | validation: 0.2797128729148876]
	TIME [epoch: 34.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24856476359176183		[learning rate: 0.0016123]
	Learning Rate: 0.00161226
	LOSS [training: 0.24856476359176183 | validation: 0.2969301611285022]
	TIME [epoch: 34.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21471818606851933		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.21471818606851933 | validation: 0.18785610824725063]
	TIME [epoch: 34.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926858622895931		[learning rate: 0.0016047]
	Learning Rate: 0.00160467
	LOSS [training: 0.1926858622895931 | validation: 0.19350332991972613]
	TIME [epoch: 34.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26680311349634034		[learning rate: 0.0016009]
	Learning Rate: 0.00160088
	LOSS [training: 0.26680311349634034 | validation: 0.42776858357200365]
	TIME [epoch: 34.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32941250378467885		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.32941250378467885 | validation: 0.234066315908838]
	TIME [epoch: 34.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20110078774771964		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.20110078774771964 | validation: 0.16779279295778077]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21428347632594846		[learning rate: 0.0015896]
	Learning Rate: 0.00158958
	LOSS [training: 0.21428347632594846 | validation: 0.25464770854689905]
	TIME [epoch: 34.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24274376343239687		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.24274376343239687 | validation: 0.27826424609317085]
	TIME [epoch: 34.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311887530867734		[learning rate: 0.0015821]
	Learning Rate: 0.00158209
	LOSS [training: 0.2311887530867734 | validation: 0.16549932163191455]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286661500046697		[learning rate: 0.0015784]
	Learning Rate: 0.00157836
	LOSS [training: 0.286661500046697 | validation: 0.29079169178845754]
	TIME [epoch: 34.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25117641368209115		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.25117641368209115 | validation: 0.3399596000618588]
	TIME [epoch: 34.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650257102049554		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.2650257102049554 | validation: 0.19246870594763285]
	TIME [epoch: 34.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30178609155565506		[learning rate: 0.0015672]
	Learning Rate: 0.00156721
	LOSS [training: 0.30178609155565506 | validation: 0.3395002446674074]
	TIME [epoch: 34.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696761449332778		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.2696761449332778 | validation: 0.351223146154067]
	TIME [epoch: 34.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33400719933911427		[learning rate: 0.0015598]
	Learning Rate: 0.00155983
	LOSS [training: 0.33400719933911427 | validation: 0.221380675348949]
	TIME [epoch: 34.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23918414960148807		[learning rate: 0.0015561]
	Learning Rate: 0.00155615
	LOSS [training: 0.23918414960148807 | validation: 0.29115601235414734]
	TIME [epoch: 34.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605371541381772		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.2605371541381772 | validation: 0.1725724106187581]
	TIME [epoch: 34.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458727453299358		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.2458727453299358 | validation: 0.23755529532747022]
	TIME [epoch: 34.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245424638367111		[learning rate: 0.0015452]
	Learning Rate: 0.00154516
	LOSS [training: 0.2245424638367111 | validation: 0.23036854120917255]
	TIME [epoch: 34.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22771471119205028		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.22771471119205028 | validation: 0.21469415132230568]
	TIME [epoch: 34.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944238832152606		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1944238832152606 | validation: 0.23039134437232378]
	TIME [epoch: 34.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30478007184520706		[learning rate: 0.0015343]
	Learning Rate: 0.00153425
	LOSS [training: 0.30478007184520706 | validation: 0.22383683838386578]
	TIME [epoch: 34.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21675860327754232		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.21675860327754232 | validation: 0.20023268042812872]
	TIME [epoch: 34.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910994580587838		[learning rate: 0.001527]
	Learning Rate: 0.00152703
	LOSS [training: 0.1910994580587838 | validation: 0.2066390161809778]
	TIME [epoch: 34.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193536080809372		[learning rate: 0.0015234]
	Learning Rate: 0.00152342
	LOSS [training: 0.193536080809372 | validation: 0.24311945516942274]
	TIME [epoch: 34.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23826377184276243		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.23826377184276243 | validation: 0.21902719939726006]
	TIME [epoch: 34.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280423342808679		[learning rate: 0.0015162]
	Learning Rate: 0.00151624
	LOSS [training: 0.2280423342808679 | validation: 0.24938721901703878]
	TIME [epoch: 34.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23550829382552124		[learning rate: 0.0015127]
	Learning Rate: 0.00151267
	LOSS [training: 0.23550829382552124 | validation: 0.1361362236941647]
	TIME [epoch: 34.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18431267893224781		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.18431267893224781 | validation: 0.19410153962215834]
	TIME [epoch: 34.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26759291941844454		[learning rate: 0.0015055]
	Learning Rate: 0.00150554
	LOSS [training: 0.26759291941844454 | validation: 0.5904443733887061]
	TIME [epoch: 34.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34606961126496066		[learning rate: 0.001502]
	Learning Rate: 0.00150199
	LOSS [training: 0.34606961126496066 | validation: 0.1962986651612834]
	TIME [epoch: 34.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21473648490413988		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.21473648490413988 | validation: 0.2775252835130906]
	TIME [epoch: 34.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653539174854206		[learning rate: 0.0014949]
	Learning Rate: 0.00149491
	LOSS [training: 0.2653539174854206 | validation: 0.36181163662945337]
	TIME [epoch: 34.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173431042012357		[learning rate: 0.0014914]
	Learning Rate: 0.00149139
	LOSS [training: 0.3173431042012357 | validation: 0.26960532294227746]
	TIME [epoch: 34.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19973546581495077		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.19973546581495077 | validation: 0.41921255399470114]
	TIME [epoch: 34.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182564852214757		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 1.0182564852214757 | validation: 0.7390282919511801]
	TIME [epoch: 34.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737648021619704		[learning rate: 0.0014809]
	Learning Rate: 0.00148086
	LOSS [training: 0.6737648021619704 | validation: 0.4768137254349665]
	TIME [epoch: 34.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624118992359736		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.5624118992359736 | validation: 0.4701835735360608]
	TIME [epoch: 34.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5432369093238604		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.5432369093238604 | validation: 0.5959230048922859]
	TIME [epoch: 34.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552955662915019		[learning rate: 0.0014704]
	Learning Rate: 0.0014704
	LOSS [training: 0.5552955662915019 | validation: 0.3537792314160043]
	TIME [epoch: 34.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44713233446436607		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.44713233446436607 | validation: 0.38263554646797693]
	TIME [epoch: 34.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4145105898448971		[learning rate: 0.0014635]
	Learning Rate: 0.00146347
	LOSS [training: 0.4145105898448971 | validation: 0.41697153732270087]
	TIME [epoch: 34.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33123686015536463		[learning rate: 0.00146]
	Learning Rate: 0.00146002
	LOSS [training: 0.33123686015536463 | validation: 0.2846982784135512]
	TIME [epoch: 34.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24697116947639086		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24697116947639086 | validation: 0.3078911608426689]
	TIME [epoch: 34.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29145618202619356		[learning rate: 0.0014531]
	Learning Rate: 0.00145314
	LOSS [training: 0.29145618202619356 | validation: 0.2960015688924986]
	TIME [epoch: 34.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689162517995716		[learning rate: 0.0014497]
	Learning Rate: 0.00144971
	LOSS [training: 0.2689162517995716 | validation: 0.2639521946994346]
	TIME [epoch: 34.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614749995747931		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.2614749995747931 | validation: 0.1555193114518093]
	TIME [epoch: 34.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22231095964255143		[learning rate: 0.0014429]
	Learning Rate: 0.00144288
	LOSS [training: 0.22231095964255143 | validation: 0.19425084061600917]
	TIME [epoch: 34.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19583434666936891		[learning rate: 0.0014395]
	Learning Rate: 0.00143948
	LOSS [training: 0.19583434666936891 | validation: 0.18384293348180258]
	TIME [epoch: 34.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24570091718463727		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.24570091718463727 | validation: 0.32856418142263594]
	TIME [epoch: 34.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23229528512075157		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.23229528512075157 | validation: 0.20950322388685766]
	TIME [epoch: 34.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24795829210706025		[learning rate: 0.0014293]
	Learning Rate: 0.00142932
	LOSS [training: 0.24795829210706025 | validation: 0.26402647202883067]
	TIME [epoch: 34.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21236509700004247		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.21236509700004247 | validation: 0.19360993188740439]
	TIME [epoch: 34.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18947026825201252		[learning rate: 0.0014226]
	Learning Rate: 0.00142258
	LOSS [training: 0.18947026825201252 | validation: 0.1631872795278153]
	TIME [epoch: 34.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19963972016011525		[learning rate: 0.0014192]
	Learning Rate: 0.00141923
	LOSS [training: 0.19963972016011525 | validation: 0.24975019907004195]
	TIME [epoch: 34.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30854502752930485		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.30854502752930485 | validation: 0.3306898858066778]
	TIME [epoch: 34.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26306202060021694		[learning rate: 0.0014125]
	Learning Rate: 0.00141254
	LOSS [training: 0.26306202060021694 | validation: 0.18360807563170917]
	TIME [epoch: 34.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.237684111534795		[learning rate: 0.0014092]
	Learning Rate: 0.00140921
	LOSS [training: 0.237684111534795 | validation: 0.2946799033367036]
	TIME [epoch: 34.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27661664172079203		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.27661664172079203 | validation: 0.22172688045132077]
	TIME [epoch: 34.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18512002431801292		[learning rate: 0.0014026]
	Learning Rate: 0.00140257
	LOSS [training: 0.18512002431801292 | validation: 0.18965739573542006]
	TIME [epoch: 34.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875292672021594		[learning rate: 0.0013993]
	Learning Rate: 0.00139926
	LOSS [training: 0.1875292672021594 | validation: 0.5798715074411309]
	TIME [epoch: 34.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307931286553003		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.4307931286553003 | validation: 0.2296127124070284]
	TIME [epoch: 34.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23162144272936538		[learning rate: 0.0013927]
	Learning Rate: 0.00139266
	LOSS [training: 0.23162144272936538 | validation: 0.32689406411960553]
	TIME [epoch: 34.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22930380601328276		[learning rate: 0.0013894]
	Learning Rate: 0.00138938
	LOSS [training: 0.22930380601328276 | validation: 0.2634150696853834]
	TIME [epoch: 34.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21860181703407966		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.21860181703407966 | validation: 0.2260014228955853]
	TIME [epoch: 34.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813604081542405		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.2813604081542405 | validation: 0.258481981470317]
	TIME [epoch: 34.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2460827643752024		[learning rate: 0.0013796]
	Learning Rate: 0.00137957
	LOSS [training: 0.2460827643752024 | validation: 0.275237158451764]
	TIME [epoch: 34.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24731215377804128		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.24731215377804128 | validation: 0.2381406549281814]
	TIME [epoch: 34.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23286329355006385		[learning rate: 0.0013731]
	Learning Rate: 0.00137307
	LOSS [training: 0.23286329355006385 | validation: 0.2351913980236572]
	TIME [epoch: 34.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112258545681113		[learning rate: 0.0013698]
	Learning Rate: 0.00136983
	LOSS [training: 0.2112258545681113 | validation: 0.22094812072033232]
	TIME [epoch: 34.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25750668468532484		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.25750668468532484 | validation: 0.22743782571413496]
	TIME [epoch: 34.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22671628631573795		[learning rate: 0.0013634]
	Learning Rate: 0.00136338
	LOSS [training: 0.22671628631573795 | validation: 0.2562872793856111]
	TIME [epoch: 34.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2187388180328523		[learning rate: 0.0013602]
	Learning Rate: 0.00136016
	LOSS [training: 0.2187388180328523 | validation: 0.24197806902100788]
	TIME [epoch: 34.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18726720197945262		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.18726720197945262 | validation: 0.21577657325362165]
	TIME [epoch: 34.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2057752736284814		[learning rate: 0.0013538]
	Learning Rate: 0.00135375
	LOSS [training: 0.2057752736284814 | validation: 0.3073123973309803]
	TIME [epoch: 34.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240943628875439		[learning rate: 0.0013506]
	Learning Rate: 0.00135056
	LOSS [training: 0.2240943628875439 | validation: 0.24426039550727682]
	TIME [epoch: 34.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20755460762431513		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.20755460762431513 | validation: 0.17033100799422915]
	TIME [epoch: 34.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101962295907187		[learning rate: 0.0013442]
	Learning Rate: 0.00134419
	LOSS [training: 0.2101962295907187 | validation: 0.18620072550072786]
	TIME [epoch: 34.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684620804411542		[learning rate: 0.001341]
	Learning Rate: 0.00134102
	LOSS [training: 0.21684620804411542 | validation: 0.17534599090647868]
	TIME [epoch: 34.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647905420487204		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.1647905420487204 | validation: 0.14946369939964843]
	TIME [epoch: 34.7 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19915867340604654		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.19915867340604654 | validation: 0.13555402396177338]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_903.pth
	Model improved!!!
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18379892207266357		[learning rate: 0.0013316]
	Learning Rate: 0.00133155
	LOSS [training: 0.18379892207266357 | validation: 0.1493868752701177]
	TIME [epoch: 34.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659663640775557		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.1659663640775557 | validation: 0.18193389724954995]
	TIME [epoch: 34.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20328150981380363		[learning rate: 0.0013253]
	Learning Rate: 0.00132528
	LOSS [training: 0.20328150981380363 | validation: 0.3002824412752403]
	TIME [epoch: 34.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23130897764568262		[learning rate: 0.0013222]
	Learning Rate: 0.00132215
	LOSS [training: 0.23130897764568262 | validation: 0.21853219163859783]
	TIME [epoch: 34.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21122714832968964		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.21122714832968964 | validation: 0.2432296744265619]
	TIME [epoch: 34.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280252895226069		[learning rate: 0.0013159]
	Learning Rate: 0.00131592
	LOSS [training: 0.5280252895226069 | validation: 0.4697822368102211]
	TIME [epoch: 34.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32933499413100564		[learning rate: 0.0013128]
	Learning Rate: 0.00131282
	LOSS [training: 0.32933499413100564 | validation: 0.29610562051125716]
	TIME [epoch: 34.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074453935598373		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.3074453935598373 | validation: 0.1680039988175474]
	TIME [epoch: 34.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812518507994146		[learning rate: 0.0013066]
	Learning Rate: 0.00130663
	LOSS [training: 0.1812518507994146 | validation: 0.156386222939376]
	TIME [epoch: 34.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17298738357853918		[learning rate: 0.0013036]
	Learning Rate: 0.00130355
	LOSS [training: 0.17298738357853918 | validation: 0.2182625458753632]
	TIME [epoch: 34.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20222009581288483		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.20222009581288483 | validation: 0.15106170785191478]
	TIME [epoch: 34.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16607829196992738		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.16607829196992738 | validation: 0.18467280880259446]
	TIME [epoch: 34.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18724268219177986		[learning rate: 0.0012943]
	Learning Rate: 0.00129435
	LOSS [training: 0.18724268219177986 | validation: 0.18823591279610266]
	TIME [epoch: 34.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20366739674410417		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.20366739674410417 | validation: 0.24545208151169756]
	TIME [epoch: 34.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886723614498637		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.20886723614498637 | validation: 0.16678417963284214]
	TIME [epoch: 34.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677963366722365		[learning rate: 0.0012852]
	Learning Rate: 0.00128521
	LOSS [training: 0.16677963366722365 | validation: 0.1438631914578941]
	TIME [epoch: 34.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678709908282976		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.1678709908282976 | validation: 0.47769320032252816]
	TIME [epoch: 34.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157969464456277		[learning rate: 0.0012792]
	Learning Rate: 0.00127915
	LOSS [training: 0.6157969464456277 | validation: 0.7688988700315897]
	TIME [epoch: 34.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430629656078222		[learning rate: 0.0012761]
	Learning Rate: 0.00127614
	LOSS [training: 0.5430629656078222 | validation: 0.41341129256609954]
	TIME [epoch: 34.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36224201758707597		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.36224201758707597 | validation: 0.374255766828979]
	TIME [epoch: 34.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31222505352986957		[learning rate: 0.0012701]
	Learning Rate: 0.00127012
	LOSS [training: 0.31222505352986957 | validation: 0.2969062100168515]
	TIME [epoch: 34.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943625128701133		[learning rate: 0.0012671]
	Learning Rate: 0.00126713
	LOSS [training: 0.2943625128701133 | validation: 0.35106978994812066]
	TIME [epoch: 34.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268655078442255		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.268655078442255 | validation: 0.2622792285411909]
	TIME [epoch: 34.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24882547726035356		[learning rate: 0.0012612]
	Learning Rate: 0.00126116
	LOSS [training: 0.24882547726035356 | validation: 0.4246073205878375]
	TIME [epoch: 34.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828541463170625		[learning rate: 0.0012582]
	Learning Rate: 0.00125818
	LOSS [training: 0.2828541463170625 | validation: 0.28272712333980077]
	TIME [epoch: 34.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24956878561685295		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.24956878561685295 | validation: 0.28267306494191313]
	TIME [epoch: 34.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20068973524800943		[learning rate: 0.0012523]
	Learning Rate: 0.00125225
	LOSS [training: 0.20068973524800943 | validation: 0.22238985316875254]
	TIME [epoch: 34.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165792669685853		[learning rate: 0.0012493]
	Learning Rate: 0.0012493
	LOSS [training: 0.2165792669685853 | validation: 0.1909386250521264]
	TIME [epoch: 34.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125381820759326		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.2125381820759326 | validation: 0.250247065038843]
	TIME [epoch: 34.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24309860345216933		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.24309860345216933 | validation: 0.18844606032546934]
	TIME [epoch: 34.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22338119547755475		[learning rate: 0.0012405]
	Learning Rate: 0.00124048
	LOSS [training: 0.22338119547755475 | validation: 0.664516083226144]
	TIME [epoch: 34.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131594355928831		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.5131594355928831 | validation: 0.34603492581497663]
	TIME [epoch: 34.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290265122734488		[learning rate: 0.0012346]
	Learning Rate: 0.00123463
	LOSS [training: 0.290265122734488 | validation: 0.25975579989884184]
	TIME [epoch: 34.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35642312038766105		[learning rate: 0.0012317]
	Learning Rate: 0.00123172
	LOSS [training: 0.35642312038766105 | validation: 0.4185411463155545]
	TIME [epoch: 34.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702645383909388		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.3702645383909388 | validation: 0.4866157794301291]
	TIME [epoch: 34.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387653861122334		[learning rate: 0.0012259]
	Learning Rate: 0.00122592
	LOSS [training: 0.4387653861122334 | validation: 0.5581232414760029]
	TIME [epoch: 34.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49184245327738385		[learning rate: 0.001223]
	Learning Rate: 0.00122303
	LOSS [training: 0.49184245327738385 | validation: 0.4143979806758975]
	TIME [epoch: 34.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38223756847856327		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.38223756847856327 | validation: 0.37852471598955933]
	TIME [epoch: 34.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373441048389775		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.3373441048389775 | validation: 0.37327495467404376]
	TIME [epoch: 34.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385519143044328		[learning rate: 0.0012144]
	Learning Rate: 0.00121439
	LOSS [training: 0.3385519143044328 | validation: 0.34209633896936475]
	TIME [epoch: 34.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30288700397949897		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.30288700397949897 | validation: 0.34790058091340714]
	TIME [epoch: 34.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2942878830591803		[learning rate: 0.0012087]
	Learning Rate: 0.00120867
	LOSS [training: 0.2942878830591803 | validation: 0.6900674408487876]
	TIME [epoch: 34.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141079917402378		[learning rate: 0.0012058]
	Learning Rate: 0.00120582
	LOSS [training: 0.4141079917402378 | validation: 0.22630451820019623]
	TIME [epoch: 34.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199918923407873		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.2199918923407873 | validation: 0.2777665983973956]
	TIME [epoch: 34.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25179149932925304		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.25179149932925304 | validation: 0.1700549827518269]
	TIME [epoch: 34.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18170038412933248		[learning rate: 0.0011973]
	Learning Rate: 0.00119731
	LOSS [training: 0.18170038412933248 | validation: 0.19736715257243553]
	TIME [epoch: 34.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19517784790016174		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.19517784790016174 | validation: 0.25511636077823735]
	TIME [epoch: 34.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22949552302717577		[learning rate: 0.0011917]
	Learning Rate: 0.00119166
	LOSS [training: 0.22949552302717577 | validation: 0.20997713255939088]
	TIME [epoch: 34.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2160728882110084		[learning rate: 0.0011889]
	Learning Rate: 0.00118885
	LOSS [training: 0.2160728882110084 | validation: 0.24149973975940103]
	TIME [epoch: 34.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19862446836800074		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.19862446836800074 | validation: 0.2619421114013748]
	TIME [epoch: 34.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441081508645756		[learning rate: 0.0011833]
	Learning Rate: 0.00118325
	LOSS [training: 0.2441081508645756 | validation: 0.16320608461115046]
	TIME [epoch: 34.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32052807259732613		[learning rate: 0.0011805]
	Learning Rate: 0.00118046
	LOSS [training: 0.32052807259732613 | validation: 0.22793534913270475]
	TIME [epoch: 34.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235104651751855		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.19235104651751855 | validation: 0.15711470134480596]
	TIME [epoch: 34.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17816545970575992		[learning rate: 0.0011749]
	Learning Rate: 0.0011749
	LOSS [training: 0.17816545970575992 | validation: 0.16482243593154125]
	TIME [epoch: 34.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20413760203466924		[learning rate: 0.0011721]
	Learning Rate: 0.00117213
	LOSS [training: 0.20413760203466924 | validation: 0.16696020930236313]
	TIME [epoch: 34.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15948982270332843		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.15948982270332843 | validation: 0.20906466077320407]
	TIME [epoch: 34.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957144456008724		[learning rate: 0.0011666]
	Learning Rate: 0.0011666
	LOSS [training: 0.1957144456008724 | validation: 0.4875398888683074]
	TIME [epoch: 34.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35179508688683286		[learning rate: 0.0011639]
	Learning Rate: 0.00116385
	LOSS [training: 0.35179508688683286 | validation: 0.3981841244678436]
	TIME [epoch: 34.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24560161813537942		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.24560161813537942 | validation: 0.18183662408854084]
	TIME [epoch: 34.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17372027125765882		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.17372027125765882 | validation: 0.3364400902527108]
	TIME [epoch: 34.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545796365940877		[learning rate: 0.0011556]
	Learning Rate: 0.00115563
	LOSS [training: 0.2545796365940877 | validation: 0.2619239265848224]
	TIME [epoch: 34.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23789878195335462		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.23789878195335462 | validation: 0.19029810877752695]
	TIME [epoch: 34.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23558406302960544		[learning rate: 0.0011502]
	Learning Rate: 0.00115019
	LOSS [training: 0.23558406302960544 | validation: 0.21847042290380037]
	TIME [epoch: 34.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18421433726699604		[learning rate: 0.0011475]
	Learning Rate: 0.00114748
	LOSS [training: 0.18421433726699604 | validation: 0.20641656722978596]
	TIME [epoch: 34.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580945311994318		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.2580945311994318 | validation: 0.2167243713625524]
	TIME [epoch: 34.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22329700979981904		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.22329700979981904 | validation: 0.2484752397249409]
	TIME [epoch: 34.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2483568735490236		[learning rate: 0.0011394]
	Learning Rate: 0.00113937
	LOSS [training: 0.2483568735490236 | validation: 0.16527065276087033]
	TIME [epoch: 34.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21861098221440856		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.21861098221440856 | validation: 0.14443912351895483]
	TIME [epoch: 34.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16547015368447854		[learning rate: 0.001134]
	Learning Rate: 0.00113401
	LOSS [training: 0.16547015368447854 | validation: 0.14472432472632088]
	TIME [epoch: 34.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19771217451998063		[learning rate: 0.0011313]
	Learning Rate: 0.00113133
	LOSS [training: 0.19771217451998063 | validation: 0.12359366897022858]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_973.pth
	Model improved!!!
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19155538302571853		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.19155538302571853 | validation: 0.13211928303485537]
	TIME [epoch: 34.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176333357509982		[learning rate: 0.001126]
	Learning Rate: 0.001126
	LOSS [training: 0.2176333357509982 | validation: 0.14591648862500042]
	TIME [epoch: 34.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20714335370975123		[learning rate: 0.0011233]
	Learning Rate: 0.00112334
	LOSS [training: 0.20714335370975123 | validation: 0.2828926669643183]
	TIME [epoch: 34.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27573055395558593		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.27573055395558593 | validation: 0.28566229264674226]
	TIME [epoch: 34.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22777564551561205		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.22777564551561205 | validation: 0.17029959916359722]
	TIME [epoch: 34.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17374701721127578		[learning rate: 0.0011154]
	Learning Rate: 0.00111541
	LOSS [training: 0.17374701721127578 | validation: 0.2503914314478684]
	TIME [epoch: 34.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25731819125007577		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.25731819125007577 | validation: 0.15373879855873065]
	TIME [epoch: 34.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1998567914335989		[learning rate: 0.0011102]
	Learning Rate: 0.00111016
	LOSS [training: 0.1998567914335989 | validation: 0.24953211512413576]
	TIME [epoch: 34.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404110340248672		[learning rate: 0.0011075]
	Learning Rate: 0.00110754
	LOSS [training: 0.2404110340248672 | validation: 0.22092487266066127]
	TIME [epoch: 34.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20188653828996117		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.20188653828996117 | validation: 0.13821178359583286]
	TIME [epoch: 34.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23703278999892652		[learning rate: 0.0011023]
	Learning Rate: 0.00110232
	LOSS [training: 0.23703278999892652 | validation: 0.20184216300821606]
	TIME [epoch: 34.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21958613366261484		[learning rate: 0.0010997]
	Learning Rate: 0.00109972
	LOSS [training: 0.21958613366261484 | validation: 0.2007695397553379]
	TIME [epoch: 34.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457645492032393		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.2457645492032393 | validation: 0.22508203112440828]
	TIME [epoch: 34.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032137206688346		[learning rate: 0.0010945]
	Learning Rate: 0.00109454
	LOSS [training: 0.22032137206688346 | validation: 0.16375600692614697]
	TIME [epoch: 34.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2213052312267595		[learning rate: 0.001092]
	Learning Rate: 0.00109196
	LOSS [training: 0.2213052312267595 | validation: 0.2519380314067748]
	TIME [epoch: 34.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22281830688091844		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.22281830688091844 | validation: 0.26031316750901656]
	TIME [epoch: 34.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23529554400130973		[learning rate: 0.0010868]
	Learning Rate: 0.00108681
	LOSS [training: 0.23529554400130973 | validation: 0.305194520031802]
	TIME [epoch: 34.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20996992320066488		[learning rate: 0.0010842]
	Learning Rate: 0.00108425
	LOSS [training: 0.20996992320066488 | validation: 0.15233205032024408]
	TIME [epoch: 34.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712145487708578		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.1712145487708578 | validation: 0.20926567161150436]
	TIME [epoch: 34.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19677146367629383		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.19677146367629383 | validation: 0.16978593709010442]
	TIME [epoch: 34.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640937056560176		[learning rate: 0.0010766]
	Learning Rate: 0.00107659
	LOSS [training: 0.13640937056560176 | validation: 0.24595583373055668]
	TIME [epoch: 34.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808877446340053		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.2808877446340053 | validation: 0.2296898180446585]
	TIME [epoch: 34.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24598469814900442		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.24598469814900442 | validation: 0.5469383907279902]
	TIME [epoch: 34.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27201240426540296		[learning rate: 0.001069]
	Learning Rate: 0.00106899
	LOSS [training: 0.27201240426540296 | validation: 0.19740862630763922]
	TIME [epoch: 34.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16933390486911856		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.16933390486911856 | validation: 0.16332494924474705]
	TIME [epoch: 34.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18907860223559647		[learning rate: 0.001064]
	Learning Rate: 0.00106395
	LOSS [training: 0.18907860223559647 | validation: 0.2816674005993727]
	TIME [epoch: 34.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24917603040745778		[learning rate: 0.0010614]
	Learning Rate: 0.00106144
	LOSS [training: 0.24917603040745778 | validation: 0.26017523862002534]
	TIME [epoch: 34.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27103463039826886		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.27103463039826886 | validation: 0.22819184949419036]
	TIME [epoch: 167 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22407413565135506		[learning rate: 0.0010564]
	Learning Rate: 0.00105644
	LOSS [training: 0.22407413565135506 | validation: 0.17014127988603256]
	TIME [epoch: 74.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24807573421874196		[learning rate: 0.001054]
	Learning Rate: 0.00105395
	LOSS [training: 0.24807573421874196 | validation: 0.23429785749197682]
	TIME [epoch: 74.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023618052589549		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.2023618052589549 | validation: 0.19999773338629145]
	TIME [epoch: 74.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17807696035371604		[learning rate: 0.001049]
	Learning Rate: 0.00104898
	LOSS [training: 0.17807696035371604 | validation: 0.16241472158303902]
	TIME [epoch: 74.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16412450930512068		[learning rate: 0.0010465]
	Learning Rate: 0.00104651
	LOSS [training: 0.16412450930512068 | validation: 0.250319978664022]
	TIME [epoch: 74.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16795325421962304		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.16795325421962304 | validation: 0.23204183492634284]
	TIME [epoch: 74.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20846678120913473		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.20846678120913473 | validation: 0.1923966376943677]
	TIME [epoch: 74.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975546076212441		[learning rate: 0.0010391]
	Learning Rate: 0.00103912
	LOSS [training: 0.2975546076212441 | validation: 0.2660653345049827]
	TIME [epoch: 74.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20099135227583326		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.20099135227583326 | validation: 0.17857382151396334]
	TIME [epoch: 74.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2361188063730167		[learning rate: 0.0010342]
	Learning Rate: 0.00103423
	LOSS [training: 0.2361188063730167 | validation: 0.27686189705009095]
	TIME [epoch: 74.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1850933047511556		[learning rate: 0.0010318]
	Learning Rate: 0.00103179
	LOSS [training: 0.1850933047511556 | validation: 0.28085543214093767]
	TIME [epoch: 74.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516700134405139		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.2516700134405139 | validation: 0.26881827448596585]
	TIME [epoch: 74.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20291390995039268		[learning rate: 0.0010269]
	Learning Rate: 0.00102692
	LOSS [training: 0.20291390995039268 | validation: 0.15867765197238265]
	TIME [epoch: 74.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17286669540614757		[learning rate: 0.0010245]
	Learning Rate: 0.0010245
	LOSS [training: 0.17286669540614757 | validation: 0.15706671044077303]
	TIME [epoch: 74.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17187824326396212		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.17187824326396212 | validation: 0.16164207404458528]
	TIME [epoch: 74.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18241715139067394		[learning rate: 0.0010197]
	Learning Rate: 0.00101967
	LOSS [training: 0.18241715139067394 | validation: 0.29440294132195227]
	TIME [epoch: 74.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291342469833321		[learning rate: 0.0010173]
	Learning Rate: 0.00101727
	LOSS [training: 0.291342469833321 | validation: 0.246687304324559]
	TIME [epoch: 74.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21727015164537528		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.21727015164537528 | validation: 0.21339014128152423]
	TIME [epoch: 74.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19045816374853602		[learning rate: 0.0010125]
	Learning Rate: 0.00101248
	LOSS [training: 0.19045816374853602 | validation: 0.15285951257149583]
	TIME [epoch: 74.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14852214696012103		[learning rate: 0.0010101]
	Learning Rate: 0.00101009
	LOSS [training: 0.14852214696012103 | validation: 0.1854436304980912]
	TIME [epoch: 74.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16217370391815963		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.16217370391815963 | validation: 0.1335697356744845]
	TIME [epoch: 74.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413116502679548		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1413116502679548 | validation: 0.4346458890922259]
	TIME [epoch: 74.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808010837022173		[learning rate: 0.001003]
	Learning Rate: 0.00100296
	LOSS [training: 0.2808010837022173 | validation: 0.22946205189693386]
	TIME [epoch: 74.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16389202803324399		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.16389202803324399 | validation: 0.18693686215786703]
	TIME [epoch: 74.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17624866703683734		[learning rate: 0.00099823]
	Learning Rate: 0.000998231
	LOSS [training: 0.17624866703683734 | validation: 0.15490283110307074]
	TIME [epoch: 74.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16052796862834176		[learning rate: 0.00099588]
	Learning Rate: 0.000995876
	LOSS [training: 0.16052796862834176 | validation: 0.21027647083035483]
	TIME [epoch: 74.4 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564368976134258		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.1564368976134258 | validation: 0.16827477720360468]
	TIME [epoch: 74.4 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293989907769073		[learning rate: 0.00099118]
	Learning Rate: 0.000991183
	LOSS [training: 0.15293989907769073 | validation: 0.1366051104233531]
	TIME [epoch: 74.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711407941933789		[learning rate: 0.00098885]
	Learning Rate: 0.000988845
	LOSS [training: 0.1711407941933789 | validation: 0.3473621330380353]
	TIME [epoch: 74.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26508493711870945		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.26508493711870945 | validation: 0.19659295890670198]
	TIME [epoch: 74.4 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713601467587741		[learning rate: 0.00098419]
	Learning Rate: 0.000984185
	LOSS [training: 0.1713601467587741 | validation: 0.21230919888201838]
	TIME [epoch: 74.4 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15157530417847967		[learning rate: 0.00098186]
	Learning Rate: 0.000981864
	LOSS [training: 0.15157530417847967 | validation: 0.1868057760332651]
	TIME [epoch: 74.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18342771456120335		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.18342771456120335 | validation: 0.1700760342318654]
	TIME [epoch: 74.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30371733427661113		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.30371733427661113 | validation: 0.2315888102231592]
	TIME [epoch: 74.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674954284950488		[learning rate: 0.00097493]
	Learning Rate: 0.000974932
	LOSS [training: 0.1674954284950488 | validation: 0.1653150480474554]
	TIME [epoch: 74.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771486822290794		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.20771486822290794 | validation: 0.38887611039738385]
	TIME [epoch: 74.4 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265866502403785		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.265866502403785 | validation: 0.19018745868887182]
	TIME [epoch: 74.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903278269825886		[learning rate: 0.00096805]
	Learning Rate: 0.000968049
	LOSS [training: 0.13903278269825886 | validation: 0.15930259501386412]
	TIME [epoch: 74.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337996642803607		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.1337996642803607 | validation: 0.17078289583214223]
	TIME [epoch: 74.4 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15018462940839736		[learning rate: 0.00096349]
	Learning Rate: 0.000963488
	LOSS [training: 0.15018462940839736 | validation: 0.1528142908131023]
	TIME [epoch: 74.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351593698723482		[learning rate: 0.00096121]
	Learning Rate: 0.000961215
	LOSS [training: 0.13351593698723482 | validation: 0.204533074011866]
	TIME [epoch: 74.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15756495812671434		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.15756495812671434 | validation: 0.11661974623287175]
	TIME [epoch: 74.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1043.pth
	Model improved!!!
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417669197368288		[learning rate: 0.00095669]
	Learning Rate: 0.000956686
	LOSS [training: 0.1417669197368288 | validation: 0.10976001032192018]
	TIME [epoch: 74.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1044.pth
	Model improved!!!
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13386588252439258		[learning rate: 0.00095443]
	Learning Rate: 0.000954429
	LOSS [training: 0.13386588252439258 | validation: 0.12697322634460134]
	TIME [epoch: 74.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171805660893245		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.12171805660893245 | validation: 0.14335513119558765]
	TIME [epoch: 74.4 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13819687296419592		[learning rate: 0.00094993]
	Learning Rate: 0.000949932
	LOSS [training: 0.13819687296419592 | validation: 0.15125804444040383]
	TIME [epoch: 74.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13892153695464476		[learning rate: 0.00094769]
	Learning Rate: 0.000947691
	LOSS [training: 0.13892153695464476 | validation: 0.16523039508828163]
	TIME [epoch: 74.4 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18194977016331862		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.18194977016331862 | validation: 0.14693338787467072]
	TIME [epoch: 74.4 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12187131597864224		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.12187131597864224 | validation: 0.10050175722269145]
	TIME [epoch: 74.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1050.pth
	Model improved!!!
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706963054459768		[learning rate: 0.000941]
	Learning Rate: 0.000941
	LOSS [training: 0.1706963054459768 | validation: 0.36258653076460295]
	TIME [epoch: 74.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572273651390104		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.2572273651390104 | validation: 0.1760427987416675]
	TIME [epoch: 74.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634400407897935		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.1634400407897935 | validation: 0.108495708154705]
	TIME [epoch: 74.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965577873706033		[learning rate: 0.00093436]
	Learning Rate: 0.000934357
	LOSS [training: 0.15965577873706033 | validation: 0.16267114445574687]
	TIME [epoch: 74.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357301752097601		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.1357301752097601 | validation: 0.17855395089102724]
	TIME [epoch: 74.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17581503277780486		[learning rate: 0.00092995]
	Learning Rate: 0.000929954
	LOSS [training: 0.17581503277780486 | validation: 0.1996271429617344]
	TIME [epoch: 74.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20355896042097385		[learning rate: 0.00092776]
	Learning Rate: 0.000927761
	LOSS [training: 0.20355896042097385 | validation: 0.21925993561672338]
	TIME [epoch: 74.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199563883533266		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.2199563883533266 | validation: 0.18742462372029284]
	TIME [epoch: 74.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18660686067290463		[learning rate: 0.00092339]
	Learning Rate: 0.000923389
	LOSS [training: 0.18660686067290463 | validation: 0.15678459852359028]
	TIME [epoch: 74.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12703916050312852		[learning rate: 0.00092121]
	Learning Rate: 0.000921211
	LOSS [training: 0.12703916050312852 | validation: 0.22106371901649874]
	TIME [epoch: 74.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568259666535149		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.2568259666535149 | validation: 0.4486649651749615]
	TIME [epoch: 74.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45132231199350054		[learning rate: 0.00091687]
	Learning Rate: 0.00091687
	LOSS [training: 0.45132231199350054 | validation: 0.305995424466857]
	TIME [epoch: 74.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31946022457318396		[learning rate: 0.00091471]
	Learning Rate: 0.000914707
	LOSS [training: 0.31946022457318396 | validation: 0.31488390841281355]
	TIME [epoch: 74.4 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27836622793474414		[learning rate: 0.00091255]
	Learning Rate: 0.00091255
	LOSS [training: 0.27836622793474414 | validation: 0.23709922680202863]
	TIME [epoch: 74.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22609896505115218		[learning rate: 0.0009104]
	Learning Rate: 0.000910397
	LOSS [training: 0.22609896505115218 | validation: 0.39969313562168074]
	TIME [epoch: 74.4 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492042009854386		[learning rate: 0.00090825]
	Learning Rate: 0.00090825
	LOSS [training: 0.3492042009854386 | validation: 0.33510833502586407]
	TIME [epoch: 74.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299344602851068		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.299344602851068 | validation: 0.28567281871846917]
	TIME [epoch: 74.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26074896654431057		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.26074896654431057 | validation: 0.2898422810017858]
	TIME [epoch: 74.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22989574339227453		[learning rate: 0.00090184]
	Learning Rate: 0.000901837
	LOSS [training: 0.22989574339227453 | validation: 0.19613203836793286]
	TIME [epoch: 74.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19223629262622752		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.19223629262622752 | validation: 0.19838832652424948]
	TIME [epoch: 74.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17694200210149869		[learning rate: 0.00089759]
	Learning Rate: 0.000897588
	LOSS [training: 0.17694200210149869 | validation: 0.1874893764937637]
	TIME [epoch: 74.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17933107655629416		[learning rate: 0.00089547]
	Learning Rate: 0.00089547
	LOSS [training: 0.17933107655629416 | validation: 0.1501940098307971]
	TIME [epoch: 74.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347869630661203		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.14347869630661203 | validation: 0.16849873072716856]
	TIME [epoch: 74.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13588155601049948		[learning rate: 0.00089125]
	Learning Rate: 0.000891251
	LOSS [training: 0.13588155601049948 | validation: 0.16797599308508765]
	TIME [epoch: 74.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16074416630584715		[learning rate: 0.00088915]
	Learning Rate: 0.000889149
	LOSS [training: 0.16074416630584715 | validation: 0.15182648593634823]
	TIME [epoch: 74.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198461156136735		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.2198461156136735 | validation: 0.21985660387936773]
	TIME [epoch: 74.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17526190636790398		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.17526190636790398 | validation: 0.12838681860987966]
	TIME [epoch: 74.2 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961312498422762		[learning rate: 0.00088287]
	Learning Rate: 0.000882871
	LOSS [training: 0.13961312498422762 | validation: 0.22414370078472456]
	TIME [epoch: 74.2 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21532862899885652		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.21532862899885652 | validation: 0.1446468375381418]
	TIME [epoch: 74.2 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295630046211264		[learning rate: 0.00087871]
	Learning Rate: 0.000878711
	LOSS [training: 0.1295630046211264 | validation: 0.1755086894124675]
	TIME [epoch: 74.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062521733127798		[learning rate: 0.00087664]
	Learning Rate: 0.000876639
	LOSS [training: 0.15062521733127798 | validation: 0.17410863763305295]
	TIME [epoch: 74.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560536200532867		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.1560536200532867 | validation: 0.18240379579479313]
	TIME [epoch: 74.2 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484835383520404		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.1484835383520404 | validation: 0.145917149656602]
	TIME [epoch: 74.2 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497459582796434		[learning rate: 0.00087045]
	Learning Rate: 0.00087045
	LOSS [training: 0.1497459582796434 | validation: 0.1679741348710967]
	TIME [epoch: 74.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191254859347299		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.191254859347299 | validation: 0.19315613717033364]
	TIME [epoch: 74.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19291982997948606		[learning rate: 0.00086635]
	Learning Rate: 0.000866348
	LOSS [training: 0.19291982997948606 | validation: 0.15541906796907412]
	TIME [epoch: 74.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16619687345223447		[learning rate: 0.0008643]
	Learning Rate: 0.000864304
	LOSS [training: 0.16619687345223447 | validation: 0.16104570881746985]
	TIME [epoch: 74.2 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1836965608844825		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.1836965608844825 | validation: 0.11423061842829346]
	TIME [epoch: 74.2 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20575802898027643		[learning rate: 0.00086023]
	Learning Rate: 0.000860232
	LOSS [training: 0.20575802898027643 | validation: 0.48453685324152446]
	TIME [epoch: 74.2 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29386453129882056		[learning rate: 0.0008582]
	Learning Rate: 0.000858202
	LOSS [training: 0.29386453129882056 | validation: 0.16002047559749233]
	TIME [epoch: 74.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15414251835297338		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.15414251835297338 | validation: 0.17554437808920476]
	TIME [epoch: 74.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376629072931077		[learning rate: 0.00085416]
	Learning Rate: 0.000854159
	LOSS [training: 0.1376629072931077 | validation: 0.09496410477870253]
	TIME [epoch: 74.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1092.pth
	Model improved!!!
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16967592900776612		[learning rate: 0.00085214]
	Learning Rate: 0.000852144
	LOSS [training: 0.16967592900776612 | validation: 0.126965972650731]
	TIME [epoch: 74.2 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292940281752814		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.1292940281752814 | validation: 0.11478072370369666]
	TIME [epoch: 74.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700596661246548		[learning rate: 0.00084813]
	Learning Rate: 0.000848128
	LOSS [training: 0.11700596661246548 | validation: 0.14238116203396683]
	TIME [epoch: 74.2 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13825213932683814		[learning rate: 0.00084613]
	Learning Rate: 0.000846128
	LOSS [training: 0.13825213932683814 | validation: 0.08909452955153108]
	TIME [epoch: 74.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1096.pth
	Model improved!!!
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397194727569467		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.1397194727569467 | validation: 0.1451167400848402]
	TIME [epoch: 74.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249785118548277		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.13249785118548277 | validation: 0.15623075910640982]
	TIME [epoch: 74.2 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13446945231183516		[learning rate: 0.00084015]
	Learning Rate: 0.000840154
	LOSS [training: 0.13446945231183516 | validation: 0.12357494622778302]
	TIME [epoch: 74.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925805803732082		[learning rate: 0.00083817]
	Learning Rate: 0.000838173
	LOSS [training: 0.12925805803732082 | validation: 0.15789859727928357]
	TIME [epoch: 74.2 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16200183557210035		[learning rate: 0.0008362]
	Learning Rate: 0.000836195
	LOSS [training: 0.16200183557210035 | validation: 0.1426347341533512]
	TIME [epoch: 74.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18656418056942284		[learning rate: 0.00083422]
	Learning Rate: 0.000834223
	LOSS [training: 0.18656418056942284 | validation: 0.22663765809540526]
	TIME [epoch: 74.2 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23015717699674704		[learning rate: 0.00083226]
	Learning Rate: 0.000832255
	LOSS [training: 0.23015717699674704 | validation: 0.16565859500380714]
	TIME [epoch: 74.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344789720383176		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.1344789720383176 | validation: 0.1282122376028694]
	TIME [epoch: 74.2 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18483338042350544		[learning rate: 0.00082833]
	Learning Rate: 0.000828333
	LOSS [training: 0.18483338042350544 | validation: 0.209369262779522]
	TIME [epoch: 74.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14681387924019076		[learning rate: 0.00082638]
	Learning Rate: 0.00082638
	LOSS [training: 0.14681387924019076 | validation: 0.14024661976850766]
	TIME [epoch: 74.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13758853761005102		[learning rate: 0.00082443]
	Learning Rate: 0.00082443
	LOSS [training: 0.13758853761005102 | validation: 0.13669035219378567]
	TIME [epoch: 74.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18655866577498903		[learning rate: 0.00082249]
	Learning Rate: 0.000822485
	LOSS [training: 0.18655866577498903 | validation: 0.2790330303210719]
	TIME [epoch: 74.2 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055189307968266		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.20055189307968266 | validation: 0.1952574649480219]
	TIME [epoch: 74.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16813097182282488		[learning rate: 0.00081861]
	Learning Rate: 0.00081861
	LOSS [training: 0.16813097182282488 | validation: 0.17084602955441222]
	TIME [epoch: 74.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15772404021526792		[learning rate: 0.00081668]
	Learning Rate: 0.000816679
	LOSS [training: 0.15772404021526792 | validation: 0.15822759577771056]
	TIME [epoch: 74.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614949773545568		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.1614949773545568 | validation: 0.14205865835198267]
	TIME [epoch: 74.2 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276346048907309		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1276346048907309 | validation: 0.12696717487381137]
	TIME [epoch: 74.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766820326107496		[learning rate: 0.00081091]
	Learning Rate: 0.000810913
	LOSS [training: 0.13766820326107496 | validation: 0.22015174105141117]
	TIME [epoch: 74.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21459041991993116		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.21459041991993116 | validation: 0.13574766145346517]
	TIME [epoch: 74.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19703880209622515		[learning rate: 0.00080709]
	Learning Rate: 0.000807092
	LOSS [training: 0.19703880209622515 | validation: 0.16804932239670417]
	TIME [epoch: 74.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16895560397242024		[learning rate: 0.00080519]
	Learning Rate: 0.000805188
	LOSS [training: 0.16895560397242024 | validation: 0.212644325468332]
	TIME [epoch: 74.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22636941818986622		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.22636941818986622 | validation: 0.19347163106532245]
	TIME [epoch: 74.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16599888864482162		[learning rate: 0.00080139]
	Learning Rate: 0.000801394
	LOSS [training: 0.16599888864482162 | validation: 0.2658717065616642]
	TIME [epoch: 74.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952448706053147		[learning rate: 0.0007995]
	Learning Rate: 0.000799504
	LOSS [training: 0.2952448706053147 | validation: 0.2501043438550836]
	TIME [epoch: 74.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21775190865106386		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.21775190865106386 | validation: 0.16593046892902058]
	TIME [epoch: 74.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498762669445077		[learning rate: 0.00079574]
	Learning Rate: 0.000795736
	LOSS [training: 0.1498762669445077 | validation: 0.1385349612946224]
	TIME [epoch: 74.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12409569812648426		[learning rate: 0.00079386]
	Learning Rate: 0.000793859
	LOSS [training: 0.12409569812648426 | validation: 0.13529528351502662]
	TIME [epoch: 74.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204801263861524		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.12204801263861524 | validation: 0.11064208872419484]
	TIME [epoch: 74.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2318043932776366		[learning rate: 0.00079012]
	Learning Rate: 0.000790119
	LOSS [training: 0.2318043932776366 | validation: 0.3216760474449295]
	TIME [epoch: 74.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736942363839364		[learning rate: 0.00078826]
	Learning Rate: 0.000788255
	LOSS [training: 0.1736942363839364 | validation: 0.1329389014550919]
	TIME [epoch: 74.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327691748482086		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.1327691748482086 | validation: 0.12529235305200895]
	TIME [epoch: 74.3 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11895434186058884		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.11895434186058884 | validation: 0.1436358354265655]
	TIME [epoch: 74.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11796327262359661		[learning rate: 0.00078269]
	Learning Rate: 0.00078269
	LOSS [training: 0.11796327262359661 | validation: 0.15591721851964135]
	TIME [epoch: 74.2 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11965399158982065		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.11965399158982065 | validation: 0.12109464237478064]
	TIME [epoch: 74.2 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099944431893344		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.1099944431893344 | validation: 0.11533845998238479]
	TIME [epoch: 74.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693404225370478		[learning rate: 0.00077716]
	Learning Rate: 0.000777164
	LOSS [training: 0.12693404225370478 | validation: 0.10288775063443945]
	TIME [epoch: 74.2 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10879766285292819		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.10879766285292819 | validation: 0.13072583030498128]
	TIME [epoch: 74.3 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998134334054552		[learning rate: 0.0007735]
	Learning Rate: 0.000773502
	LOSS [training: 0.13998134334054552 | validation: 0.12452228771471054]
	TIME [epoch: 74.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11306216216787948		[learning rate: 0.00077168]
	Learning Rate: 0.000771678
	LOSS [training: 0.11306216216787948 | validation: 0.15214774171855988]
	TIME [epoch: 74.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840832218784209		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.1840832218784209 | validation: 0.14116541619088824]
	TIME [epoch: 74.3 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212956831371656		[learning rate: 0.00076804]
	Learning Rate: 0.000768041
	LOSS [training: 0.13212956831371656 | validation: 0.11934897576138463]
	TIME [epoch: 74.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11905464223862752		[learning rate: 0.00076623]
	Learning Rate: 0.00076623
	LOSS [training: 0.11905464223862752 | validation: 0.12052658278737532]
	TIME [epoch: 74.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236318275937617		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.1236318275937617 | validation: 0.11273066172600985]
	TIME [epoch: 74.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11290657727513838		[learning rate: 0.00076262]
	Learning Rate: 0.000762619
	LOSS [training: 0.11290657727513838 | validation: 0.12031161768333126]
	TIME [epoch: 74.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969957230704057		[learning rate: 0.00076082]
	Learning Rate: 0.00076082
	LOSS [training: 0.12969957230704057 | validation: 0.13036368234577794]
	TIME [epoch: 74.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045899306664335		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.13045899306664335 | validation: 0.15906615767438886]
	TIME [epoch: 74.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250006869319943		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.12250006869319943 | validation: 0.12202384798754945]
	TIME [epoch: 74.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13020319351080653		[learning rate: 0.00075545]
	Learning Rate: 0.000755449
	LOSS [training: 0.13020319351080653 | validation: 0.13239297266344624]
	TIME [epoch: 74.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14390902577861048		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.14390902577861048 | validation: 0.11833557956192689]
	TIME [epoch: 74.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489145395139986		[learning rate: 0.00075189]
	Learning Rate: 0.000751889
	LOSS [training: 0.1489145395139986 | validation: 0.12840297399760664]
	TIME [epoch: 74.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900342511450093		[learning rate: 0.00075012]
	Learning Rate: 0.000750116
	LOSS [training: 0.14900342511450093 | validation: 0.1140182926883894]
	TIME [epoch: 74.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624278520111181		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.11624278520111181 | validation: 0.17183711374655258]
	TIME [epoch: 74.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319657117450027		[learning rate: 0.00074658]
	Learning Rate: 0.000746581
	LOSS [training: 0.1319657117450027 | validation: 0.11867194288870322]
	TIME [epoch: 74.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552962960008446		[learning rate: 0.00074482]
	Learning Rate: 0.00074482
	LOSS [training: 0.1552962960008446 | validation: 0.2539603444648368]
	TIME [epoch: 74.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17719902372103818		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.17719902372103818 | validation: 0.18899393102092907]
	TIME [epoch: 74.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351204174389214		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.1351204174389214 | validation: 0.13758086336045955]
	TIME [epoch: 74.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21833415939179457		[learning rate: 0.00073956]
	Learning Rate: 0.000739562
	LOSS [training: 0.21833415939179457 | validation: 0.249624237434611]
	TIME [epoch: 74.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176796763519321		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.176796763519321 | validation: 0.1622992495831519]
	TIME [epoch: 74.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15007958710462382		[learning rate: 0.00073608]
	Learning Rate: 0.000736077
	LOSS [training: 0.15007958710462382 | validation: 0.13526941348759028]
	TIME [epoch: 74.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181966438958075		[learning rate: 0.00073434]
	Learning Rate: 0.000734341
	LOSS [training: 0.1181966438958075 | validation: 0.14065446575726284]
	TIME [epoch: 74.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398456442262826		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.12398456442262826 | validation: 0.15040789802644783]
	TIME [epoch: 74.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474247931107075		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1474247931107075 | validation: 0.1695645942155991]
	TIME [epoch: 74.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13915148758955703		[learning rate: 0.00072916]
	Learning Rate: 0.000729156
	LOSS [training: 0.13915148758955703 | validation: 0.2030206154114616]
	TIME [epoch: 74.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478862553397589		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.16478862553397589 | validation: 0.15813522719783146]
	TIME [epoch: 74.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131114518590801		[learning rate: 0.00072572]
	Learning Rate: 0.00072572
	LOSS [training: 0.131114518590801 | validation: 0.15522205894335592]
	TIME [epoch: 74.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11998543113204377		[learning rate: 0.00072401]
	Learning Rate: 0.000724008
	LOSS [training: 0.11998543113204377 | validation: 0.15199729827329417]
	TIME [epoch: 74.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11689947192061632		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.11689947192061632 | validation: 0.15888519423095648]
	TIME [epoch: 74.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11670594376195706		[learning rate: 0.0007206]
	Learning Rate: 0.000720597
	LOSS [training: 0.11670594376195706 | validation: 0.14451847270642376]
	TIME [epoch: 74.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11671600537446958		[learning rate: 0.0007189]
	Learning Rate: 0.000718897
	LOSS [training: 0.11671600537446958 | validation: 0.13550478745124292]
	TIME [epoch: 74.4 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13937840642315344		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.13937840642315344 | validation: 0.18370034734449034]
	TIME [epoch: 74.4 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21256761902473434		[learning rate: 0.00071551]
	Learning Rate: 0.00071551
	LOSS [training: 0.21256761902473434 | validation: 0.2710661843843106]
	TIME [epoch: 74.4 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796832476958996		[learning rate: 0.00071382]
	Learning Rate: 0.000713822
	LOSS [training: 0.1796832476958996 | validation: 0.1496261497997185]
	TIME [epoch: 74.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258546245242189		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.1258546245242189 | validation: 0.09913117951152606]
	TIME [epoch: 74.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386768105285601		[learning rate: 0.00071046]
	Learning Rate: 0.000710458
	LOSS [training: 0.1386768105285601 | validation: 0.27823939518193697]
	TIME [epoch: 74.4 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19058658370455062		[learning rate: 0.00070878]
	Learning Rate: 0.000708782
	LOSS [training: 0.19058658370455062 | validation: 0.11440690711923049]
	TIME [epoch: 74.3 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10010265769095064		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.10010265769095064 | validation: 0.11443552501785684]
	TIME [epoch: 74.4 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10607196917156783		[learning rate: 0.00070544]
	Learning Rate: 0.000705443
	LOSS [training: 0.10607196917156783 | validation: 0.1292598346040296]
	TIME [epoch: 74.4 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973472431430015		[learning rate: 0.00070378]
	Learning Rate: 0.000703778
	LOSS [training: 0.10973472431430015 | validation: 0.10921249547267925]
	TIME [epoch: 74.4 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19176122754821406		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.19176122754821406 | validation: 0.22386787470163183]
	TIME [epoch: 74.4 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938278824202353		[learning rate: 0.00070046]
	Learning Rate: 0.000700462
	LOSS [training: 0.1938278824202353 | validation: 0.16310687122238632]
	TIME [epoch: 74.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554896591733183		[learning rate: 0.00069881]
	Learning Rate: 0.00069881
	LOSS [training: 0.15554896591733183 | validation: 0.24922166997301098]
	TIME [epoch: 74.4 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21154789165767926		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.21154789165767926 | validation: 0.21393574527351678]
	TIME [epoch: 74.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16858807959947347		[learning rate: 0.00069552]
	Learning Rate: 0.000695517
	LOSS [training: 0.16858807959947347 | validation: 0.2151832450404953]
	TIME [epoch: 74.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20679058306762724		[learning rate: 0.00069388]
	Learning Rate: 0.000693876
	LOSS [training: 0.20679058306762724 | validation: 0.24791045685747373]
	TIME [epoch: 74.4 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913640102544103		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.19913640102544103 | validation: 0.2340398248874808]
	TIME [epoch: 74.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954935977346694		[learning rate: 0.00069061]
	Learning Rate: 0.000690607
	LOSS [training: 0.1954935977346694 | validation: 0.18861158166944086]
	TIME [epoch: 74.4 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16741813730011945		[learning rate: 0.00068898]
	Learning Rate: 0.000688978
	LOSS [training: 0.16741813730011945 | validation: 0.19516020822451305]
	TIME [epoch: 74.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665738355735187		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.1665738355735187 | validation: 0.17078636912092304]
	TIME [epoch: 74.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13145028772391215		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.13145028772391215 | validation: 0.19098643888971922]
	TIME [epoch: 74.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525509450101516		[learning rate: 0.00068411]
	Learning Rate: 0.000684114
	LOSS [training: 0.1525509450101516 | validation: 0.15228502063967359]
	TIME [epoch: 74.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984339093432531		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.1984339093432531 | validation: 0.2729838010933816]
	TIME [epoch: 74.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108066963861766		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.15108066963861766 | validation: 0.145544520945664]
	TIME [epoch: 74.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392993359876305		[learning rate: 0.00067928]
	Learning Rate: 0.000679284
	LOSS [training: 0.1392993359876305 | validation: 0.13475865441514956]
	TIME [epoch: 74.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670665894940922		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.1670665894940922 | validation: 0.16620329715719367]
	TIME [epoch: 74.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15641212418738637		[learning rate: 0.00067608]
	Learning Rate: 0.000676083
	LOSS [training: 0.15641212418738637 | validation: 0.19802104488359196]
	TIME [epoch: 74.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16957735097465673		[learning rate: 0.00067449]
	Learning Rate: 0.000674488
	LOSS [training: 0.16957735097465673 | validation: 0.1487718036016109]
	TIME [epoch: 74.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12590863612409822		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.12590863612409822 | validation: 0.15148504279011787]
	TIME [epoch: 74.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383526495604505		[learning rate: 0.00067131]
	Learning Rate: 0.00067131
	LOSS [training: 0.1383526495604505 | validation: 0.1999851949955861]
	TIME [epoch: 74.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17688559538824536		[learning rate: 0.00066973]
	Learning Rate: 0.000669726
	LOSS [training: 0.17688559538824536 | validation: 0.17035691262987324]
	TIME [epoch: 74.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351927454225234		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.1351927454225234 | validation: 0.2730529241419627]
	TIME [epoch: 74.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859983540151415		[learning rate: 0.00066657]
	Learning Rate: 0.000666571
	LOSS [training: 0.1859983540151415 | validation: 0.1495362786823266]
	TIME [epoch: 74.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240705_042608/states/model_phi1_1a_v_kl2_1197.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 38930.598 seconds.
