Args:
Namespace(name='model_phi2_1a_v1', outdir='out/model_training/model_phi2_1a_v1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1996200260

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.284817885086081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.284817885086081 | validation: 7.895045981639003]
	TIME [epoch: 102 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.67280283421942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.67280283421942 | validation: 6.9243809457081476]
	TIME [epoch: 6.87 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.228275417037999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.228275417037999 | validation: 6.2896060633641895]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.500468452524013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.500468452524013 | validation: 5.757605715591538]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636308707684799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.636308707684799 | validation: 5.461090507158843]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.113617397828259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.113617397828259 | validation: 4.946937469300568]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596403846575038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596403846575038 | validation: 4.735194802141461]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.387156021733249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.387156021733249 | validation: 4.589554177625218]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.272033241625886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.272033241625886 | validation: 4.110785306633177]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8783943164603167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8783943164603167 | validation: 3.4411667861706166]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7159874210819743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7159874210819743 | validation: 3.65444451923187]
	TIME [epoch: 6.77 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3766321556112584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3766321556112584 | validation: 3.1196681480559576]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0414726273228467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0414726273228467 | validation: 2.800586057206652]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829973007046888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.829973007046888 | validation: 2.2850166597569594]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.026616430002856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.026616430002856 | validation: 2.161378887277146]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3161114452112392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3161114452112392 | validation: 2.197589474321193]
	TIME [epoch: 6.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420209806304996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.420209806304996 | validation: 1.4258216658395946]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.91963127828315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.91963127828315 | validation: 1.399303702464786]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.889048593698174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.889048593698174 | validation: 1.2738564887009949]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9036359916143306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9036359916143306 | validation: 1.914767951447982]
	TIME [epoch: 6.77 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8666842503409076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8666842503409076 | validation: 1.1656296030062534]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8505531228283287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8505531228283287 | validation: 1.1439926353371248]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.85261659027177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.85261659027177 | validation: 1.1301530598811755]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6484712434157895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6484712434157895 | validation: 1.3315929337377423]
	TIME [epoch: 6.76 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9282203736178758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9282203736178758 | validation: 1.2815428970845792]
	TIME [epoch: 6.76 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6953618864904172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6953618864904172 | validation: 1.0946655801406835]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6347312825944211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6347312825944211 | validation: 1.0665029343149082]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6615494443055217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6615494443055217 | validation: 1.1865003241837258]
	TIME [epoch: 6.82 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5190720743694792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5190720743694792 | validation: 1.0656963595135573]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6578881617368142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6578881617368142 | validation: 1.1745994921334486]
	TIME [epoch: 6.76 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5001893473183914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5001893473183914 | validation: 1.1609210652463895]
	TIME [epoch: 6.77 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5132675560210758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5132675560210758 | validation: 1.0354607065487555]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4824561548110502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4824561548110502 | validation: 0.9010134423312435]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4379073247581124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4379073247581124 | validation: 0.894593370960115]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4222013584228639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4222013584228639 | validation: 0.8560718117630335]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4406954376406107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4406954376406107 | validation: 1.0572419858682132]
	TIME [epoch: 6.77 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3467291381969693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3467291381969693 | validation: 0.7968200572972275]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3536154885481453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3536154885481453 | validation: 1.3737916388810105]
	TIME [epoch: 6.76 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3986607235842643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3986607235842643 | validation: 0.7815547185410431]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4007217189502243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4007217189502243 | validation: 0.9037059908424687]
	TIME [epoch: 6.77 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3054929408790787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3054929408790787 | validation: 0.8016128274521239]
	TIME [epoch: 6.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.379248135884349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.379248135884349 | validation: 1.0811553132319713]
	TIME [epoch: 6.78 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3567882684598853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3567882684598853 | validation: 0.8411589411696758]
	TIME [epoch: 6.77 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2621368617849997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2621368617849997 | validation: 0.7973929064534406]
	TIME [epoch: 6.77 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3803837731966082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3803837731966082 | validation: 0.7545789007093604]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2126602938245088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2126602938245088 | validation: 1.3423118920971806]
	TIME [epoch: 6.77 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3682605889124557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3682605889124557 | validation: 0.8506804994517321]
	TIME [epoch: 6.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2290841182763883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2290841182763883 | validation: 0.8881278304730599]
	TIME [epoch: 6.81 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2145506860228577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2145506860228577 | validation: 0.9143111568300322]
	TIME [epoch: 6.77 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3304784835723555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3304784835723555 | validation: 0.89903637344658]
	TIME [epoch: 6.76 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2802681610361473		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.2802681610361473 | validation: 0.7980515145998605]
	TIME [epoch: 6.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2521850816783235		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.2521850816783235 | validation: 0.7984228554524129]
	TIME [epoch: 6.76 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2621989843208508		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.2621989843208508 | validation: 0.9322308786424586]
	TIME [epoch: 6.76 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2909670941032636		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.2909670941032636 | validation: 0.8343265895165826]
	TIME [epoch: 6.77 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1830640337037042		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.1830640337037042 | validation: 0.7715663049101102]
	TIME [epoch: 6.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212640130021926		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.212640130021926 | validation: 0.9678521483299005]
	TIME [epoch: 6.76 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341306268480991		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.341306268480991 | validation: 0.8055044843905604]
	TIME [epoch: 6.76 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1958125189666662		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.1958125189666662 | validation: 0.7120982609184736]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226656633895658		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.226656633895658 | validation: 0.7490119953009143]
	TIME [epoch: 6.77 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1781336139685803		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.1781336139685803 | validation: 1.0045331493078016]
	TIME [epoch: 6.76 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381645347554027		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.2381645347554027 | validation: 0.8400448188244869]
	TIME [epoch: 6.78 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2177948914888577		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.2177948914888577 | validation: 1.0742959768811595]
	TIME [epoch: 6.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2634187415392597		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.2634187415392597 | validation: 1.1448023137999592]
	TIME [epoch: 6.77 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4290312506092462		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.4290312506092462 | validation: 0.945477020068263]
	TIME [epoch: 6.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2803671896455031		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.2803671896455031 | validation: 0.7764189624071427]
	TIME [epoch: 6.77 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2420033522630365		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.2420033522630365 | validation: 0.7504789613925883]
	TIME [epoch: 6.77 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2097512756390423		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.2097512756390423 | validation: 0.8518256937289044]
	TIME [epoch: 6.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2856197888131182		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.2856197888131182 | validation: 0.7672499035059488]
	TIME [epoch: 6.81 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.213085775326712		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.213085775326712 | validation: 0.7627085591793824]
	TIME [epoch: 6.78 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2004272872785995		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.2004272872785995 | validation: 0.8422689452779688]
	TIME [epoch: 6.76 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1948924692180944		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.1948924692180944 | validation: 1.3612099093390482]
	TIME [epoch: 6.77 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3440193325970458		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.3440193325970458 | validation: 0.7911179995682768]
	TIME [epoch: 6.76 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178810398391382		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.178810398391382 | validation: 0.8202050789732869]
	TIME [epoch: 6.76 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635871185293563		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.1635871185293563 | validation: 0.8480475102592289]
	TIME [epoch: 6.76 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1832782931750785		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.1832782931750785 | validation: 0.7152458125034901]
	TIME [epoch: 6.81 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1502078010101096		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.1502078010101096 | validation: 0.908187602482341]
	TIME [epoch: 6.77 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2509433313171712		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.2509433313171712 | validation: 0.7085342196692104]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1719869982553177		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.1719869982553177 | validation: 0.7535204267712053]
	TIME [epoch: 6.76 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1654503370553169		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.1654503370553169 | validation: 0.6836434392900379]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154139032159952		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.154139032159952 | validation: 0.7700531481492219]
	TIME [epoch: 6.76 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196251370209683		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.196251370209683 | validation: 0.7065567087841592]
	TIME [epoch: 6.77 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1065453679355124		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.1065453679355124 | validation: 0.7072482906106206]
	TIME [epoch: 6.81 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495907989313365		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.1495907989313365 | validation: 0.8292380515993976]
	TIME [epoch: 6.77 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2750421093129645		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.2750421093129645 | validation: 0.8372492175717345]
	TIME [epoch: 6.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1334439332693362		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.1334439332693362 | validation: 0.6902211974158413]
	TIME [epoch: 6.76 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.09394366085261		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.09394366085261 | validation: 0.6713518969008965]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1067962920117966		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.1067962920117966 | validation: 0.7076373402706266]
	TIME [epoch: 6.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1041296878010034		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.1041296878010034 | validation: 0.6684595625074934]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1505670087774666		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.1505670087774666 | validation: 0.7506400070824522]
	TIME [epoch: 6.79 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098576716265617		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.098576716265617 | validation: 0.635218363276397]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1056816674443337		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.1056816674443337 | validation: 0.7119775994805299]
	TIME [epoch: 6.78 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355092376541271		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.1355092376541271 | validation: 0.6740245803705651]
	TIME [epoch: 6.78 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1743354059238018		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.1743354059238018 | validation: 0.6935997887579815]
	TIME [epoch: 6.77 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0765294663065132		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.0765294663065132 | validation: 0.612410647635885]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0862081697693298		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.0862081697693298 | validation: 0.676044516639805]
	TIME [epoch: 6.83 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07666221349962		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.07666221349962 | validation: 0.6738851033289066]
	TIME [epoch: 6.79 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842039532749497		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.0842039532749497 | validation: 0.638693719366094]
	TIME [epoch: 6.78 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0804719378941874		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.0804719378941874 | validation: 0.699594403760316]
	TIME [epoch: 6.78 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1175724696380118		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1175724696380118 | validation: 0.7550913496277263]
	TIME [epoch: 6.78 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705822778948535		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.0705822778948535 | validation: 0.7239241009235591]
	TIME [epoch: 6.78 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0870444563371127		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.0870444563371127 | validation: 0.814550557880469]
	TIME [epoch: 6.79 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0922381568517046		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.0922381568517046 | validation: 0.6263486298377311]
	TIME [epoch: 6.82 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0074753008654382		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.0074753008654382 | validation: 0.5892331215804667]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886034122413988		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.8886034122413988 | validation: 0.7336572831893133]
	TIME [epoch: 6.78 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8403247789956819		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.8403247789956819 | validation: 0.6947762601257814]
	TIME [epoch: 6.77 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192022616118223		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7192022616118223 | validation: 0.6031640123397833]
	TIME [epoch: 6.78 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126073850942798		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.7126073850942798 | validation: 0.5548137583198529]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088173598871909		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.7088173598871909 | validation: 0.6052639915061799]
	TIME [epoch: 6.79 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697740636956725		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.697740636956725 | validation: 0.538217182557536]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6586678129805891		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.6586678129805891 | validation: 0.5403364371729897]
	TIME [epoch: 6.78 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5863286600045877		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5863286600045877 | validation: 0.5309193983156414]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434062949271601		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.5434062949271601 | validation: 0.4585295301064232]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.657897607703		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.657897607703 | validation: 0.45047723888331576]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656823299960771		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5656823299960771 | validation: 0.4943080677862989]
	TIME [epoch: 6.77 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576855045124255		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5576855045124255 | validation: 0.4346135448726325]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163112297185366		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5163112297185366 | validation: 0.4613398943422403]
	TIME [epoch: 6.78 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49343273452589476		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.49343273452589476 | validation: 0.42147488107406406]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172664368718289		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5172664368718289 | validation: 0.5302528692998016]
	TIME [epoch: 6.77 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49956786441411216		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.49956786441411216 | validation: 0.3950371013971551]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507842419354332		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5507842419354332 | validation: 0.6090643914952509]
	TIME [epoch: 6.77 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204326241662987		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.5204326241662987 | validation: 0.44680977336222333]
	TIME [epoch: 6.78 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44104820607739803		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.44104820607739803 | validation: 0.37687466071437353]
	TIME [epoch: 6.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447390856171288		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.4447390856171288 | validation: 0.3543696575574016]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419438061489157		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4419438061489157 | validation: 0.3828702283840236]
	TIME [epoch: 6.78 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4670971613259822		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4670971613259822 | validation: 0.44735045865169626]
	TIME [epoch: 6.78 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083694254195925		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5083694254195925 | validation: 0.700890693104375]
	TIME [epoch: 6.78 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069294583541364		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.6069294583541364 | validation: 0.4438904319371042]
	TIME [epoch: 6.78 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503345093240369		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.503345093240369 | validation: 0.36804762653779977]
	TIME [epoch: 6.82 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39265314859428335		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.39265314859428335 | validation: 0.3848839276789999]
	TIME [epoch: 6.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3995164185046424		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.3995164185046424 | validation: 0.4111616795630823]
	TIME [epoch: 6.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273474577884297		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5273474577884297 | validation: 0.3405400746387781]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47663563611886794		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.47663563611886794 | validation: 0.5338195774825141]
	TIME [epoch: 6.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113014467969221		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5113014467969221 | validation: 0.4049144363994309]
	TIME [epoch: 6.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309572679155207		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4309572679155207 | validation: 0.36086899181881693]
	TIME [epoch: 6.77 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4329279106215971		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4329279106215971 | validation: 0.2990559047873458]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35391991584418897		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.35391991584418897 | validation: 0.4176404362446914]
	TIME [epoch: 6.78 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49757721924059445		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.49757721924059445 | validation: 0.3778756124137905]
	TIME [epoch: 6.77 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597839274451798		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.4597839274451798 | validation: 0.3829109701108794]
	TIME [epoch: 6.77 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490782269278363		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4490782269278363 | validation: 0.3287131114403897]
	TIME [epoch: 6.77 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297423287076708		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3297423287076708 | validation: 0.3826625423135278]
	TIME [epoch: 6.77 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41188620280091565		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.41188620280091565 | validation: 0.3310542466570907]
	TIME [epoch: 6.79 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709140748233759		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3709140748233759 | validation: 0.35606173928529705]
	TIME [epoch: 6.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418662188794328		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3418662188794328 | validation: 0.3654122286946608]
	TIME [epoch: 6.76 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798538187074196		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3798538187074196 | validation: 0.4163701546916252]
	TIME [epoch: 6.77 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3949257232962289		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3949257232962289 | validation: 0.3532491701010461]
	TIME [epoch: 6.77 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47357623247173697		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.47357623247173697 | validation: 0.46990069284019587]
	TIME [epoch: 6.77 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49117569776706227		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.49117569776706227 | validation: 0.40682970314521516]
	TIME [epoch: 6.77 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36056016205139774		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.36056016205139774 | validation: 0.33831209286526875]
	TIME [epoch: 6.79 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39616276099572706		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.39616276099572706 | validation: 0.28956364005462154]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710470183293416		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.3710470183293416 | validation: 0.3831389131457805]
	TIME [epoch: 6.76 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643956946534095		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4643956946534095 | validation: 0.2721337223208488]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356787115846428		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3356787115846428 | validation: 0.31773163553242434]
	TIME [epoch: 6.77 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196105858004138		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3196105858004138 | validation: 0.3782752295519794]
	TIME [epoch: 6.77 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338339731908589		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.338339731908589 | validation: 0.44689083860792733]
	TIME [epoch: 6.77 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42227985450608174		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.42227985450608174 | validation: 0.35022829887421314]
	TIME [epoch: 6.82 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34347546650592486		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.34347546650592486 | validation: 0.30855335345962154]
	TIME [epoch: 6.78 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721979930684222		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3721979930684222 | validation: 0.25473056208592487]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527706517557313		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3527706517557313 | validation: 0.3043012383707393]
	TIME [epoch: 6.76 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34308168958066576		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.34308168958066576 | validation: 0.2666043192913271]
	TIME [epoch: 6.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32672506825505554		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.32672506825505554 | validation: 0.3535131541215852]
	TIME [epoch: 6.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33731894718477784		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.33731894718477784 | validation: 0.30090874874017015]
	TIME [epoch: 6.77 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32433562835561747		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.32433562835561747 | validation: 0.3173659783097309]
	TIME [epoch: 6.81 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691321430508761		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.5691321430508761 | validation: 0.3010450679590956]
	TIME [epoch: 6.76 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29364012282788515		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.29364012282788515 | validation: 0.343205546452514]
	TIME [epoch: 6.76 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872896447776861		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.3872896447776861 | validation: 0.32519532582894073]
	TIME [epoch: 6.77 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32777625408003297		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.32777625408003297 | validation: 0.3209611172489004]
	TIME [epoch: 6.76 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897347142033681		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.2897347142033681 | validation: 0.3300956357154874]
	TIME [epoch: 6.76 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41732329536141305		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.41732329536141305 | validation: 0.3936715942897291]
	TIME [epoch: 6.78 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30433965718827993		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.30433965718827993 | validation: 0.25949843784504]
	TIME [epoch: 6.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46610324338372744		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.46610324338372744 | validation: 0.2574075426815645]
	TIME [epoch: 6.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27702173016158227		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.27702173016158227 | validation: 0.24063887940891082]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440985673976643		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.4440985673976643 | validation: 0.2715021082796363]
	TIME [epoch: 6.76 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296479206339331		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.296479206339331 | validation: 0.6276352373112557]
	TIME [epoch: 6.76 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7765259250172876		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.7765259250172876 | validation: 0.7059255822254098]
	TIME [epoch: 6.76 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44285904296114714		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.44285904296114714 | validation: 0.3147932649446149]
	TIME [epoch: 6.79 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288421816217289		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.288421816217289 | validation: 0.3295362414779114]
	TIME [epoch: 6.78 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804304645959333		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.2804304645959333 | validation: 0.23314979149442755]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740067926301995		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.2740067926301995 | validation: 0.2897202164002778]
	TIME [epoch: 6.76 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28100460275878836		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.28100460275878836 | validation: 0.27263598932424427]
	TIME [epoch: 6.76 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26968481684426804		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.26968481684426804 | validation: 0.8687767018844765]
	TIME [epoch: 6.75 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504394519587539		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4504394519587539 | validation: 0.3206398133980657]
	TIME [epoch: 6.76 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31579492453720254		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.31579492453720254 | validation: 0.2790946475091559]
	TIME [epoch: 6.79 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25172764640753376		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.25172764640753376 | validation: 0.24787784978723804]
	TIME [epoch: 6.77 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40617480241035975		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.40617480241035975 | validation: 0.3729231459361566]
	TIME [epoch: 6.76 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28195157717552344		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.28195157717552344 | validation: 0.32487958717839893]
	TIME [epoch: 6.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23802971422273433		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.23802971422273433 | validation: 0.26117986656714504]
	TIME [epoch: 6.76 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918025314566136		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.2918025314566136 | validation: 0.26226845723068776]
	TIME [epoch: 6.76 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401369421331464		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2401369421331464 | validation: 0.23384857242213852]
	TIME [epoch: 6.76 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27809841256002393		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.27809841256002393 | validation: 0.2172354530657874]
	TIME [epoch: 6.81 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592582584953984		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.3592582584953984 | validation: 0.3471796161567205]
	TIME [epoch: 6.77 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035008503997537		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3035008503997537 | validation: 0.28847221406163687]
	TIME [epoch: 6.76 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074068917835682		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3074068917835682 | validation: 0.36648787887828727]
	TIME [epoch: 6.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27472831535563313		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.27472831535563313 | validation: 0.22948520019951374]
	TIME [epoch: 6.77 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091714063212101		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.3091714063212101 | validation: 0.3267083651102495]
	TIME [epoch: 6.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29006915774990316		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.29006915774990316 | validation: 0.6086314945729138]
	TIME [epoch: 6.77 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47220404398351856		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.47220404398351856 | validation: 0.24350247594619773]
	TIME [epoch: 6.79 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24323708614880704		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24323708614880704 | validation: 0.25495296965648473]
	TIME [epoch: 6.75 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26369028791408194		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.26369028791408194 | validation: 0.2238832228740709]
	TIME [epoch: 6.75 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143993949092531		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3143993949092531 | validation: 0.23877353303951357]
	TIME [epoch: 6.75 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39838638738737325		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.39838638738737325 | validation: 0.25751031022349746]
	TIME [epoch: 6.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22556831872524155		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.22556831872524155 | validation: 0.27137157892815666]
	TIME [epoch: 6.76 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23002577381884404		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.23002577381884404 | validation: 0.42538820290574436]
	TIME [epoch: 6.77 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329755468654105		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.3329755468654105 | validation: 0.3317935597812025]
	TIME [epoch: 6.79 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285216292534249		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.285216292534249 | validation: 0.3370152018582673]
	TIME [epoch: 6.75 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28013664707332636		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.28013664707332636 | validation: 0.179190817485377]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716668517227749		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3716668517227749 | validation: 1.3333305731564593]
	TIME [epoch: 6.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323934632756364		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.323934632756364 | validation: 1.0452060080626673]
	TIME [epoch: 6.75 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9320739046915645		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9320739046915645 | validation: 0.9125453255675952]
	TIME [epoch: 6.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7650999905944817		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.7650999905944817 | validation: 0.8768168369161412]
	TIME [epoch: 6.78 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592539126379432		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7592539126379432 | validation: 0.8682960898073093]
	TIME [epoch: 6.76 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833834039315024		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7833834039315024 | validation: 0.8591101321807444]
	TIME [epoch: 6.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484217031599428		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7484217031599428 | validation: 0.9029954878686892]
	TIME [epoch: 6.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834419974610533		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7834419974610533 | validation: 0.8873356287434053]
	TIME [epoch: 6.75 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389984945519089		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7389984945519089 | validation: 0.9813209373053251]
	TIME [epoch: 6.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8332478136700916		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8332478136700916 | validation: 0.8848879027185136]
	TIME [epoch: 6.75 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520176613011365		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7520176613011365 | validation: 0.9082573546528052]
	TIME [epoch: 6.79 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738500321592815		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.738500321592815 | validation: 0.8561733386487886]
	TIME [epoch: 6.76 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677773070998305		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7677773070998305 | validation: 0.86324569299372]
	TIME [epoch: 6.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195962930476448		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.7195962930476448 | validation: 0.8805765162468107]
	TIME [epoch: 6.75 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733468447490392		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.733468447490392 | validation: 0.4209639572655631]
	TIME [epoch: 6.74 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36977917421183026		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.36977917421183026 | validation: 0.3272273077713909]
	TIME [epoch: 6.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132071332619234		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3132071332619234 | validation: 0.2680473938912452]
	TIME [epoch: 6.74 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241178131846126		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.4241178131846126 | validation: 0.32363295569501094]
	TIME [epoch: 6.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3923519487592315		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3923519487592315 | validation: 0.21368209216138068]
	TIME [epoch: 6.77 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23915698801558144		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.23915698801558144 | validation: 0.2038742082963015]
	TIME [epoch: 6.75 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746949358026696		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2746949358026696 | validation: 0.19281854253794378]
	TIME [epoch: 6.75 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2810634897373449		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2810634897373449 | validation: 0.24912594663700866]
	TIME [epoch: 6.75 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40122319395215367		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.40122319395215367 | validation: 0.3057477968471628]
	TIME [epoch: 6.74 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918833302302215		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.2918833302302215 | validation: 0.2644512204410827]
	TIME [epoch: 6.75 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655604410146522		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.2655604410146522 | validation: 0.21959025719198635]
	TIME [epoch: 6.79 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28198744777487067		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.28198744777487067 | validation: 0.2505099473692407]
	TIME [epoch: 6.75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018774088847316		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.23018774088847316 | validation: 0.21499023136522044]
	TIME [epoch: 6.75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20986873327043107		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.20986873327043107 | validation: 0.2629029586135643]
	TIME [epoch: 6.75 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22004657846432363		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.22004657846432363 | validation: 0.260581007047108]
	TIME [epoch: 6.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23019417140053516		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.23019417140053516 | validation: 0.19835440459435755]
	TIME [epoch: 6.74 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23276700997984867		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.23276700997984867 | validation: 0.24735792452505795]
	TIME [epoch: 6.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693233683448395		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2693233683448395 | validation: 0.15857400706149447]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27497981219770207		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.27497981219770207 | validation: 0.2617952326439811]
	TIME [epoch: 6.77 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573475558496711		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.2573475558496711 | validation: 0.5404742508162932]
	TIME [epoch: 6.76 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47068741277705345		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.47068741277705345 | validation: 0.48643108771501486]
	TIME [epoch: 6.77 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572802571641048		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3572802571641048 | validation: 0.29615437556346336]
	TIME [epoch: 6.77 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704143304070293		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2704143304070293 | validation: 0.1939557341515158]
	TIME [epoch: 6.77 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19251207540656756		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.19251207540656756 | validation: 0.2806296862743848]
	TIME [epoch: 6.81 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24273013514539146		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.24273013514539146 | validation: 0.21364180200642013]
	TIME [epoch: 6.78 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20264034748630483		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.20264034748630483 | validation: 0.18269001304081933]
	TIME [epoch: 6.77 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260495204300614		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.260495204300614 | validation: 0.16910057211698618]
	TIME [epoch: 6.77 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21881693006656838		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.21881693006656838 | validation: 0.21981359867586792]
	TIME [epoch: 6.77 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23486444731695244		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.23486444731695244 | validation: 0.26215552933502984]
	TIME [epoch: 6.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23069902001636486		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.23069902001636486 | validation: 0.23182930205020807]
	TIME [epoch: 6.77 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664438391708827		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2664438391708827 | validation: 0.1611958193755627]
	TIME [epoch: 6.81 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624159908119261		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2624159908119261 | validation: 0.16351013963238453]
	TIME [epoch: 6.78 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237726926935298		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5237726926935298 | validation: 1.0155514300049688]
	TIME [epoch: 6.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9402452802312704		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.9402452802312704 | validation: 0.9388409205758035]
	TIME [epoch: 6.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962630838297835		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7962630838297835 | validation: 0.8995848751038868]
	TIME [epoch: 6.77 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485081433082161		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7485081433082161 | validation: 0.9101478210817431]
	TIME [epoch: 6.77 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487217286268062		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7487217286268062 | validation: 0.7854137616941796]
	TIME [epoch: 6.77 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189883781209969		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.5189883781209969 | validation: 0.29317947571777464]
	TIME [epoch: 6.82 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907598803669378		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.2907598803669378 | validation: 0.21752131119923301]
	TIME [epoch: 6.78 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266343387788382		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2266343387788382 | validation: 0.17779182862761983]
	TIME [epoch: 6.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855662512978018		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2855662512978018 | validation: 0.28180217864294754]
	TIME [epoch: 6.76 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533249463314042		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2533249463314042 | validation: 0.17042140753124874]
	TIME [epoch: 6.76 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428664506799941		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2428664506799941 | validation: 0.3427027553654166]
	TIME [epoch: 6.76 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724105420912019		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.724105420912019 | validation: 0.46301499905853793]
	TIME [epoch: 6.77 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33133023423965097		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.33133023423965097 | validation: 0.22280353627668384]
	TIME [epoch: 6.81 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955695470049875		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1955695470049875 | validation: 0.16417579904982382]
	TIME [epoch: 6.77 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22379799519416516		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.22379799519416516 | validation: 0.13965466813164015]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16603655316379196		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.16603655316379196 | validation: 0.15534351213235295]
	TIME [epoch: 6.77 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16406343648321361		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.16406343648321361 | validation: 0.14048429693577563]
	TIME [epoch: 6.77 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16414171884942075		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.16414171884942075 | validation: 0.4212518753527503]
	TIME [epoch: 6.77 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929979612359592		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.2929979612359592 | validation: 0.2232116506284964]
	TIME [epoch: 6.78 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26926789358296044		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.26926789358296044 | validation: 0.15019622476451167]
	TIME [epoch: 6.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31292882149458917		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.31292882149458917 | validation: 0.1844100182908558]
	TIME [epoch: 6.77 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283991173433278		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2283991173433278 | validation: 0.3320075932009806]
	TIME [epoch: 6.77 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34858424399051574		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.34858424399051574 | validation: 0.15770745411733247]
	TIME [epoch: 6.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25401692225776473		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.25401692225776473 | validation: 0.141084553631256]
	TIME [epoch: 6.77 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24630439758271477		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.24630439758271477 | validation: 0.22473110622180176]
	TIME [epoch: 6.77 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21153621407027476		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.21153621407027476 | validation: 0.270535150636129]
	TIME [epoch: 6.81 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21599669781464947		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.21599669781464947 | validation: 0.1944997722618647]
	TIME [epoch: 6.78 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558579156708982		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2558579156708982 | validation: 0.21503718570818203]
	TIME [epoch: 6.77 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26630223019173405		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.26630223019173405 | validation: 0.49818760607759727]
	TIME [epoch: 6.77 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32873732622366775		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.32873732622366775 | validation: 0.33264321104620964]
	TIME [epoch: 6.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035115631080427		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3035115631080427 | validation: 0.3166206242604895]
	TIME [epoch: 6.76 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29242208252138535		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.29242208252138535 | validation: 0.15925880314807955]
	TIME [epoch: 6.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3162973555864586		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.3162973555864586 | validation: 0.16280290526202812]
	TIME [epoch: 6.81 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42044427212127466		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.42044427212127466 | validation: 0.1940898000067732]
	TIME [epoch: 6.78 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2479736642804442		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.2479736642804442 | validation: 0.2780400100387135]
	TIME [epoch: 6.76 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754980508671714		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2754980508671714 | validation: 0.15650476913175865]
	TIME [epoch: 6.76 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342719338060107		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.2342719338060107 | validation: 0.16567091198587164]
	TIME [epoch: 6.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598441195644017		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5598441195644017 | validation: 0.571242666809823]
	TIME [epoch: 6.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516045958056264		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5516045958056264 | validation: 0.3746382077122832]
	TIME [epoch: 6.77 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26437280654535045		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.26437280654535045 | validation: 0.22664116941595203]
	TIME [epoch: 6.81 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49873745518252954		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.49873745518252954 | validation: 0.2496480346608166]
	TIME [epoch: 6.77 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23216005663521827		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.23216005663521827 | validation: 0.18195171324070897]
	TIME [epoch: 6.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27645558965806233		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.27645558965806233 | validation: 0.5502549142707199]
	TIME [epoch: 6.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35649260588415677		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.35649260588415677 | validation: 0.21025858567423267]
	TIME [epoch: 6.77 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21124404685364992		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.21124404685364992 | validation: 0.17986128785729852]
	TIME [epoch: 6.77 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803777769939415		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.1803777769939415 | validation: 0.1718555893979182]
	TIME [epoch: 6.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24539146247226146		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.24539146247226146 | validation: 0.2694862738851978]
	TIME [epoch: 6.81 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274697350944949		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3274697350944949 | validation: 0.2947997896501835]
	TIME [epoch: 6.77 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29831190313404043		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.29831190313404043 | validation: 0.18514052112499918]
	TIME [epoch: 6.77 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21758230588949345		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.21758230588949345 | validation: 0.16824842034519272]
	TIME [epoch: 6.77 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23317497051886432		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.23317497051886432 | validation: 0.14391795486917586]
	TIME [epoch: 6.77 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22750117073509213		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.22750117073509213 | validation: 0.2014033200397909]
	TIME [epoch: 6.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926701110065145		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.1926701110065145 | validation: 0.3885525110635206]
	TIME [epoch: 6.79 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254289669042075		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3254289669042075 | validation: 0.22135640459685324]
	TIME [epoch: 6.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297884624895382		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2297884624895382 | validation: 0.16077344438451158]
	TIME [epoch: 6.77 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251521193981903		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.2251521193981903 | validation: 0.18272365255415773]
	TIME [epoch: 6.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33765111267953146		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.33765111267953146 | validation: 0.24829599899156057]
	TIME [epoch: 6.77 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34999567313853563		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.34999567313853563 | validation: 0.1617032429382097]
	TIME [epoch: 6.77 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27405837574029174		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.27405837574029174 | validation: 0.2804089057102971]
	TIME [epoch: 6.78 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45188843919478794		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.45188843919478794 | validation: 0.202644188231359]
	TIME [epoch: 6.81 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932479477810025		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.2932479477810025 | validation: 0.28903265677557644]
	TIME [epoch: 6.79 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22363704763669429		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.22363704763669429 | validation: 0.1601067677453484]
	TIME [epoch: 6.78 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22583405272800844		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.22583405272800844 | validation: 0.4290995423646228]
	TIME [epoch: 6.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30693177784513814		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.30693177784513814 | validation: 0.17644013932932232]
	TIME [epoch: 6.77 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20231776454938927		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.20231776454938927 | validation: 0.15691292366491497]
	TIME [epoch: 6.77 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807097485736816		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3807097485736816 | validation: 0.23764822195262758]
	TIME [epoch: 6.78 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265047295558531		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.265047295558531 | validation: 0.16827431785419023]
	TIME [epoch: 6.81 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35306732661588813		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.35306732661588813 | validation: 0.2649089108717795]
	TIME [epoch: 6.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22253290363790437		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.22253290363790437 | validation: 0.1849873375862752]
	TIME [epoch: 6.78 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25554649257153206		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.25554649257153206 | validation: 0.21262234901082105]
	TIME [epoch: 6.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255467585606652		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2255467585606652 | validation: 0.17584826501384376]
	TIME [epoch: 6.77 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2276694276027243		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2276694276027243 | validation: 0.1708726801545965]
	TIME [epoch: 6.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28397822546450513		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.28397822546450513 | validation: 0.1871715355100137]
	TIME [epoch: 6.77 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17787240930862047		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.17787240930862047 | validation: 0.15234346366781076]
	TIME [epoch: 6.81 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16059468701177382		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.16059468701177382 | validation: 0.1821377151971772]
	TIME [epoch: 6.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19167544738130932		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.19167544738130932 | validation: 0.2247447367639706]
	TIME [epoch: 6.77 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296778003898413		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.16296778003898413 | validation: 0.15689515323374081]
	TIME [epoch: 6.77 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16383448362716435		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.16383448362716435 | validation: 0.17521835820731693]
	TIME [epoch: 6.77 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637300029153811		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.3637300029153811 | validation: 0.1344152471955537]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24679959146070757		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.24679959146070757 | validation: 0.30974717758636355]
	TIME [epoch: 6.79 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29876879687107455		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.29876879687107455 | validation: 0.44843327580766235]
	TIME [epoch: 6.79 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719524173634721		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2719524173634721 | validation: 0.17499608721223528]
	TIME [epoch: 6.77 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18185772199375916		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.18185772199375916 | validation: 0.20131891681130581]
	TIME [epoch: 6.76 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17471463158166167		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.17471463158166167 | validation: 0.13155119452455913]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16232306590609763		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.16232306590609763 | validation: 0.20592082456851302]
	TIME [epoch: 6.76 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24224411510016555		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.24224411510016555 | validation: 0.17080862140457115]
	TIME [epoch: 6.76 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795885261098965		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.2795885261098965 | validation: 0.1665835416003847]
	TIME [epoch: 6.78 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20676143428563468		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.20676143428563468 | validation: 0.19515358078109174]
	TIME [epoch: 6.79 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20717120984550763		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.20717120984550763 | validation: 0.14265708105517863]
	TIME [epoch: 6.76 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167186561206764		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.167186561206764 | validation: 0.1557953822051039]
	TIME [epoch: 6.76 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581320266993273		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.1581320266993273 | validation: 0.30037559371950273]
	TIME [epoch: 6.76 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916456103561444		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2916456103561444 | validation: 0.4446118979730605]
	TIME [epoch: 6.76 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29868659164480965		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.29868659164480965 | validation: 0.23264435451073004]
	TIME [epoch: 6.76 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1893098525124332		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1893098525124332 | validation: 0.15940558848519526]
	TIME [epoch: 6.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965882751124907		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.15965882751124907 | validation: 0.19617447516315284]
	TIME [epoch: 6.78 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25646307835857207		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.25646307835857207 | validation: 0.20689964304721722]
	TIME [epoch: 6.76 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747566022259035		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.1747566022259035 | validation: 0.44149770721168335]
	TIME [epoch: 6.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874464300375096		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.874464300375096 | validation: 0.9449920968275761]
	TIME [epoch: 6.76 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061774683952234		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7061774683952234 | validation: 0.3641782746087754]
	TIME [epoch: 6.76 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24343127497981096		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.24343127497981096 | validation: 0.19610708356580736]
	TIME [epoch: 6.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320281908540768		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.19320281908540768 | validation: 0.25238395724595086]
	TIME [epoch: 6.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209301636172948		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.2209301636172948 | validation: 0.1873814621561531]
	TIME [epoch: 6.77 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20881457424424565		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.20881457424424565 | validation: 0.14477861404889472]
	TIME [epoch: 6.76 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20181223323808511		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.20181223323808511 | validation: 0.20397669936211152]
	TIME [epoch: 6.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23539634903484408		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.23539634903484408 | validation: 0.18830920442095744]
	TIME [epoch: 6.76 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119559854967977		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2119559854967977 | validation: 0.12732165032505072]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343454614718313		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.15343454614718313 | validation: 0.15149078269077956]
	TIME [epoch: 6.76 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571916569373927		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2571916569373927 | validation: 0.22867605736510865]
	TIME [epoch: 6.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2027183803330203		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.2027183803330203 | validation: 0.1624410225602544]
	TIME [epoch: 6.76 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189859287840539		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.189859287840539 | validation: 0.14280710763964755]
	TIME [epoch: 6.76 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881696194163455		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.15881696194163455 | validation: 0.1473638071919448]
	TIME [epoch: 6.76 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15017569069652617		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.15017569069652617 | validation: 0.141989193765084]
	TIME [epoch: 6.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18510887918122362		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.18510887918122362 | validation: 0.1375169857800743]
	TIME [epoch: 6.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15755643252139453		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.15755643252139453 | validation: 0.18454437109556476]
	TIME [epoch: 6.78 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20123760101859728		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.20123760101859728 | validation: 0.21561173859278493]
	TIME [epoch: 6.79 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16959707612207714		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.16959707612207714 | validation: 0.1189663430236873]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389417374471852		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.1389417374471852 | validation: 0.20223922582586812]
	TIME [epoch: 6.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19447234145837552		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.19447234145837552 | validation: 0.12148008267158728]
	TIME [epoch: 6.75 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15543408732496103		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.15543408732496103 | validation: 0.16146924435456467]
	TIME [epoch: 6.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017013551984376		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2017013551984376 | validation: 0.29503675838156695]
	TIME [epoch: 6.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22059618995871294		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.22059618995871294 | validation: 0.15153016697640825]
	TIME [epoch: 6.79 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15279960058254344		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.15279960058254344 | validation: 0.2744092564730783]
	TIME [epoch: 6.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22298563828223952		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.22298563828223952 | validation: 0.27016480651775715]
	TIME [epoch: 6.76 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21826556654089552		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.21826556654089552 | validation: 0.17130218912694223]
	TIME [epoch: 6.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623981039627836		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.1623981039627836 | validation: 0.11871444961691499]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13919857472607677		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.13919857472607677 | validation: 0.17563226685115327]
	TIME [epoch: 6.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594362187236037		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1594362187236037 | validation: 0.12783726594382722]
	TIME [epoch: 6.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775880616043287		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.2775880616043287 | validation: 0.15565666476261214]
	TIME [epoch: 6.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24752206170871402		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.24752206170871402 | validation: 0.1710580326316834]
	TIME [epoch: 6.77 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2115226533664495		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2115226533664495 | validation: 0.24021537816102453]
	TIME [epoch: 6.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2136537617051239		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.2136537617051239 | validation: 0.215565170198408]
	TIME [epoch: 6.75 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2085781008825635		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.2085781008825635 | validation: 0.35400285687744815]
	TIME [epoch: 6.75 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24354728446365326		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.24354728446365326 | validation: 0.3064177619662096]
	TIME [epoch: 6.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22104054212691587		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.22104054212691587 | validation: 0.19928077865316035]
	TIME [epoch: 6.76 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347349349727001		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2347349349727001 | validation: 0.16011698969304078]
	TIME [epoch: 6.79 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18443720256501764		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.18443720256501764 | validation: 0.17306791986614933]
	TIME [epoch: 6.76 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625988353493115		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.1625988353493115 | validation: 0.1692755235851731]
	TIME [epoch: 6.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16801392718009572		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.16801392718009572 | validation: 0.21602001751231398]
	TIME [epoch: 6.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19249173684207116		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.19249173684207116 | validation: 0.1654382469276264]
	TIME [epoch: 6.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22205154134369232		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.22205154134369232 | validation: 0.18752109302165526]
	TIME [epoch: 6.75 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15042264131758573		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.15042264131758573 | validation: 0.12268855752769392]
	TIME [epoch: 6.76 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16284261488679325		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.16284261488679325 | validation: 0.12709072466431312]
	TIME [epoch: 6.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13620377023159974		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.13620377023159974 | validation: 0.1562260825329211]
	TIME [epoch: 6.76 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22921150844058655		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.22921150844058655 | validation: 0.1425528065179104]
	TIME [epoch: 6.76 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745598886641068		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.2745598886641068 | validation: 0.1330577558027132]
	TIME [epoch: 6.76 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34092509152964856		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.34092509152964856 | validation: 0.3172278036258184]
	TIME [epoch: 6.76 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466250175226759		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2466250175226759 | validation: 0.14215527575343764]
	TIME [epoch: 6.76 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13764982489952504		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.13764982489952504 | validation: 0.21487430892341747]
	TIME [epoch: 6.77 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17147689006704384		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.17147689006704384 | validation: 0.11747114088517335]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17776620862273942		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.17776620862273942 | validation: 0.1548332528440246]
	TIME [epoch: 6.76 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23704000832125058		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.23704000832125058 | validation: 0.26954102869612145]
	TIME [epoch: 6.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19666571932072446		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.19666571932072446 | validation: 0.20349353673192783]
	TIME [epoch: 6.75 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525952623676082		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2525952623676082 | validation: 0.14446242607926515]
	TIME [epoch: 6.75 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16708546995716056		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16708546995716056 | validation: 0.24982160348090193]
	TIME [epoch: 6.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17360764329038517		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.17360764329038517 | validation: 0.12060612361220896]
	TIME [epoch: 6.79 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492843627416217		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.1492843627416217 | validation: 0.12019411900834961]
	TIME [epoch: 6.78 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20796055087965842		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.20796055087965842 | validation: 0.1386436759887296]
	TIME [epoch: 6.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17840810833212445		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.17840810833212445 | validation: 0.17693945789517704]
	TIME [epoch: 6.76 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190845049678582		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16190845049678582 | validation: 0.13946391093500704]
	TIME [epoch: 6.76 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17850259462321746		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.17850259462321746 | validation: 0.18465129517395892]
	TIME [epoch: 6.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15435110282135342		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.15435110282135342 | validation: 0.11156491362961912]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21366661815796043		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.21366661815796043 | validation: 0.1984983453643176]
	TIME [epoch: 6.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416560983462406		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.13416560983462406 | validation: 0.12218190201534178]
	TIME [epoch: 6.77 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259201264727065		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.18259201264727065 | validation: 0.2626493489372993]
	TIME [epoch: 6.76 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198414879991411		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2198414879991411 | validation: 0.3021957501870512]
	TIME [epoch: 6.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24218133210260712		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.24218133210260712 | validation: 0.25200350203218447]
	TIME [epoch: 6.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433553887653916		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2433553887653916 | validation: 0.189856161219294]
	TIME [epoch: 6.76 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758779343461206		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.1758779343461206 | validation: 0.12216745272683908]
	TIME [epoch: 6.76 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13664357000078212		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.13664357000078212 | validation: 0.12924029284901156]
	TIME [epoch: 6.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484618650790054		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.1484618650790054 | validation: 0.36655384641248295]
	TIME [epoch: 6.76 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31907147142749037		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.31907147142749037 | validation: 0.4825229732723197]
	TIME [epoch: 6.76 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43791277190995426		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.43791277190995426 | validation: 0.14732337427424777]
	TIME [epoch: 6.76 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4366092464024016		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4366092464024016 | validation: 0.9518286972995358]
	TIME [epoch: 6.75 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074766905376156		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8074766905376156 | validation: 0.7068304769548877]
	TIME [epoch: 6.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319143178279063		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6319143178279063 | validation: 0.5164414603014645]
	TIME [epoch: 6.77 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36239956707522103		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.36239956707522103 | validation: 0.15586570053916576]
	TIME [epoch: 6.79 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508745164235868		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.1508745164235868 | validation: 0.13855057912931076]
	TIME [epoch: 6.76 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14340045171415952		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.14340045171415952 | validation: 0.1204839077017975]
	TIME [epoch: 6.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13716426346777963		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.13716426346777963 | validation: 0.18007206693735353]
	TIME [epoch: 6.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33974476585745683		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.33974476585745683 | validation: 0.32167805600465404]
	TIME [epoch: 6.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533019921668327		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2533019921668327 | validation: 0.16955696344907956]
	TIME [epoch: 6.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14257801800557005		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.14257801800557005 | validation: 0.15852627453880025]
	TIME [epoch: 6.78 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18020389243159723		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.18020389243159723 | validation: 0.1365500412137236]
	TIME [epoch: 6.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520022971515882		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1520022971515882 | validation: 0.2124227548496068]
	TIME [epoch: 6.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16601317455991782		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.16601317455991782 | validation: 0.11307658765664341]
	TIME [epoch: 6.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562413534937891		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1562413534937891 | validation: 0.1485713921997572]
	TIME [epoch: 6.76 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15202577368002107		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.15202577368002107 | validation: 0.10356294596550036]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608965814867795		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.12608965814867795 | validation: 0.10105288124064932]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15719737605354625		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.15719737605354625 | validation: 0.10848192776614994]
	TIME [epoch: 6.79 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753583982485894		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.1753583982485894 | validation: 0.28047894820283137]
	TIME [epoch: 6.76 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.258473172252092		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.258473172252092 | validation: 0.142283122818315]
	TIME [epoch: 6.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862115405133315		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1862115405133315 | validation: 0.1827887715488889]
	TIME [epoch: 6.74 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23430403961691104		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.23430403961691104 | validation: 0.16464639879481463]
	TIME [epoch: 6.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790843263591373		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.2790843263591373 | validation: 0.15520895638946774]
	TIME [epoch: 6.75 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695377146659414		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.15695377146659414 | validation: 0.19075988086084605]
	TIME [epoch: 6.75 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780281071598463		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.2780281071598463 | validation: 0.14061704184279017]
	TIME [epoch: 6.79 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389186339673922		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.1389186339673922 | validation: 0.16710409604644855]
	TIME [epoch: 6.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18794891014689694		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.18794891014689694 | validation: 0.1114360932797778]
	TIME [epoch: 6.75 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797930310558559		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.2797930310558559 | validation: 0.18564399354463662]
	TIME [epoch: 6.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475947720586531		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.1475947720586531 | validation: 0.11775704838661062]
	TIME [epoch: 6.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724227615051382		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.13724227615051382 | validation: 0.1124790999298435]
	TIME [epoch: 6.75 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087476726951132		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.12087476726951132 | validation: 0.12134269087084046]
	TIME [epoch: 6.76 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12569862441672952		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.12569862441672952 | validation: 0.14605292196556782]
	TIME [epoch: 6.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24809723359139985		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.24809723359139985 | validation: 0.2460667278867752]
	TIME [epoch: 6.76 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21964464150783		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.21964464150783 | validation: 0.39312415850275695]
	TIME [epoch: 6.75 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6772732280890229		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.6772732280890229 | validation: 0.5785088074200093]
	TIME [epoch: 6.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29167076894851673		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.29167076894851673 | validation: 0.19870760127530626]
	TIME [epoch: 6.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4384673171531358		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.4384673171531358 | validation: 0.5040580962397514]
	TIME [epoch: 6.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27156043716224626		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.27156043716224626 | validation: 0.14974368852240394]
	TIME [epoch: 6.77 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16630652648277117		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.16630652648277117 | validation: 0.13641874766647955]
	TIME [epoch: 6.79 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364207364717875		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.15364207364717875 | validation: 0.22024110255028548]
	TIME [epoch: 6.76 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.214174015067289		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.214174015067289 | validation: 0.227667447692258]
	TIME [epoch: 6.75 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20380978027982904		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.20380978027982904 | validation: 0.27458494862525384]
	TIME [epoch: 6.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173554321681298		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2173554321681298 | validation: 0.25585209718886637]
	TIME [epoch: 6.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397348849956786		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2397348849956786 | validation: 0.13890344199570945]
	TIME [epoch: 6.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20685588493665263		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.20685588493665263 | validation: 0.14934516108896567]
	TIME [epoch: 6.77 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17656457773165293		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.17656457773165293 | validation: 0.11694844082122322]
	TIME [epoch: 6.79 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240223242557377		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.12240223242557377 | validation: 0.0961795289302032]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13924426493392955		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.13924426493392955 | validation: 0.1447905672358204]
	TIME [epoch: 6.78 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670130940140406		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.1670130940140406 | validation: 0.11813417779454459]
	TIME [epoch: 6.77 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12975401808570092		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.12975401808570092 | validation: 0.13868184153065255]
	TIME [epoch: 6.77 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16686051607042332		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.16686051607042332 | validation: 0.5826032284997973]
	TIME [epoch: 6.77 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121117919424279		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4121117919424279 | validation: 0.14318904753702394]
	TIME [epoch: 6.82 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13701422157966123		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.13701422157966123 | validation: 0.1273037066684452]
	TIME [epoch: 6.78 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16732781808649086		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.16732781808649086 | validation: 0.12565976294967063]
	TIME [epoch: 6.77 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580857603870024		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.12580857603870024 | validation: 0.12538227980040084]
	TIME [epoch: 6.77 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12823011593831923		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.12823011593831923 | validation: 0.16316203125637616]
	TIME [epoch: 6.77 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555940224683248		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1555940224683248 | validation: 0.1402731020427313]
	TIME [epoch: 6.77 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28710452576909484		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.28710452576909484 | validation: 0.38061342790486274]
	TIME [epoch: 6.77 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21810999430840738		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.21810999430840738 | validation: 0.15191542979499628]
	TIME [epoch: 6.81 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17464223141308813		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.17464223141308813 | validation: 0.1900287316890709]
	TIME [epoch: 6.76 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17741976069147844		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.17741976069147844 | validation: 0.1093148820439653]
	TIME [epoch: 6.76 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286310358990778		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1286310358990778 | validation: 0.21826768426217474]
	TIME [epoch: 6.76 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545629946390817		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.14545629946390817 | validation: 0.1389630477412941]
	TIME [epoch: 6.76 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355613979512792		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.1355613979512792 | validation: 0.11854622155440091]
	TIME [epoch: 6.76 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15083273517783433		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.15083273517783433 | validation: 0.13614808835880465]
	TIME [epoch: 6.77 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615704519103477		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.19615704519103477 | validation: 0.1514457773417861]
	TIME [epoch: 6.81 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18258459289261803		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.18258459289261803 | validation: 0.28369892690116616]
	TIME [epoch: 6.77 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22886021690083277		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.22886021690083277 | validation: 0.2025759298893292]
	TIME [epoch: 6.77 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19222774347389612		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.19222774347389612 | validation: 0.30770202179933237]
	TIME [epoch: 6.76 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100431310249496		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2100431310249496 | validation: 0.116883890207956]
	TIME [epoch: 6.76 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1776341900045506		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1776341900045506 | validation: 0.14115732213851742]
	TIME [epoch: 6.76 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15594674224372276		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.15594674224372276 | validation: 0.28055578186021124]
	TIME [epoch: 6.78 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22799107685580772		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.22799107685580772 | validation: 0.15625259149192328]
	TIME [epoch: 6.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979466196517285		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.13979466196517285 | validation: 0.1699321147374543]
	TIME [epoch: 6.77 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24960386942404628		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.24960386942404628 | validation: 0.1853192855170656]
	TIME [epoch: 6.76 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727207451247683		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.1727207451247683 | validation: 0.2409258213125794]
	TIME [epoch: 6.76 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793234610245527		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1793234610245527 | validation: 0.14352215342683214]
	TIME [epoch: 6.76 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17764568205787118		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.17764568205787118 | validation: 0.18324102834529793]
	TIME [epoch: 6.76 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18377879651810164		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.18377879651810164 | validation: 0.16080921659389513]
	TIME [epoch: 6.81 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690129461742838		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.1690129461742838 | validation: 0.1299470569111912]
	TIME [epoch: 6.78 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13855313375861375		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.13855313375861375 | validation: 0.12943084322190312]
	TIME [epoch: 6.77 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18627313534076984		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.18627313534076984 | validation: 0.18589000330976352]
	TIME [epoch: 6.77 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16551095453453898		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16551095453453898 | validation: 0.13338078091143826]
	TIME [epoch: 6.77 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503110315673127		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1503110315673127 | validation: 0.11632251736430972]
	TIME [epoch: 6.77 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12038507238073079		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.12038507238073079 | validation: 0.14286949659315157]
	TIME [epoch: 6.77 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111309985592193		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.19111309985592193 | validation: 0.20967222918183442]
	TIME [epoch: 6.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30259042776933354		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.30259042776933354 | validation: 0.26242497740168347]
	TIME [epoch: 6.78 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774592360742318		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1774592360742318 | validation: 0.1782893064085234]
	TIME [epoch: 6.77 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17102153053122637		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.17102153053122637 | validation: 0.19497410781061947]
	TIME [epoch: 6.77 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917153007614062		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.1917153007614062 | validation: 0.12361807764897026]
	TIME [epoch: 6.77 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689635166573697		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.13689635166573697 | validation: 0.14683396935540394]
	TIME [epoch: 6.77 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17995046284069044		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.17995046284069044 | validation: 0.22063579770844033]
	TIME [epoch: 6.78 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24572334592436124		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.24572334592436124 | validation: 0.2973734301739095]
	TIME [epoch: 6.81 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555292365476634		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.2555292365476634 | validation: 0.17948097995964393]
	TIME [epoch: 6.78 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21927747523216973		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.21927747523216973 | validation: 0.35310761662488466]
	TIME [epoch: 6.77 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24346225989585518		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.24346225989585518 | validation: 0.1399786721624193]
	TIME [epoch: 6.78 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14057341297562295		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.14057341297562295 | validation: 0.12735237011513184]
	TIME [epoch: 6.78 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311827150076758		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.12311827150076758 | validation: 0.11408693304201384]
	TIME [epoch: 6.78 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394281367751357		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1394281367751357 | validation: 0.11455695290251655]
	TIME [epoch: 6.79 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431621384040579		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.1431621384040579 | validation: 0.11943081998064733]
	TIME [epoch: 6.82 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646523040036107		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.1646523040036107 | validation: 0.10459965585974296]
	TIME [epoch: 6.78 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14685351327348373		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.14685351327348373 | validation: 0.15167792487576318]
	TIME [epoch: 6.78 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615931107767044		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1615931107767044 | validation: 0.2812610273967671]
	TIME [epoch: 6.78 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25154161032912614		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.25154161032912614 | validation: 0.12319699092416238]
	TIME [epoch: 6.78 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16380285993177776		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.16380285993177776 | validation: 0.30715314328640764]
	TIME [epoch: 6.78 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22948344022908718		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.22948344022908718 | validation: 0.1311655648865288]
	TIME [epoch: 6.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13808096374120513		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13808096374120513 | validation: 0.12741597976941405]
	TIME [epoch: 6.82 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350061409626141		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1350061409626141 | validation: 0.22026221030070692]
	TIME [epoch: 6.78 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211380457519301		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2211380457519301 | validation: 0.11835202876230784]
	TIME [epoch: 6.78 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456531298055006		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.12456531298055006 | validation: 0.12243795002573199]
	TIME [epoch: 6.77 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220505262140255		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.11220505262140255 | validation: 0.10669465175405635]
	TIME [epoch: 6.78 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371953895324833		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.15371953895324833 | validation: 0.10499346144868248]
	TIME [epoch: 6.78 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218241305317134		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1218241305317134 | validation: 0.23478930243212137]
	TIME [epoch: 6.82 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577229225173287		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1577229225173287 | validation: 0.15319095748833378]
	TIME [epoch: 6.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15063460267628143		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.15063460267628143 | validation: 0.18814571410871986]
	TIME [epoch: 6.78 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612086659724607		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2612086659724607 | validation: 0.2269499644003316]
	TIME [epoch: 6.78 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20959167959133618		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.20959167959133618 | validation: 0.13439327872894882]
	TIME [epoch: 6.79 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361076649724851		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1361076649724851 | validation: 0.11383352238925687]
	TIME [epoch: 6.78 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126148595823249		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.1126148595823249 | validation: 0.11159607696577772]
	TIME [epoch: 6.78 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535273469593153		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.11535273469593153 | validation: 0.10244661373462055]
	TIME [epoch: 6.83 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17580586503724277		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.17580586503724277 | validation: 0.1103458827683796]
	TIME [epoch: 6.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12029300545086094		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.12029300545086094 | validation: 0.10282665501054411]
	TIME [epoch: 6.79 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536045784943062		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.12536045784943062 | validation: 0.27971751076398554]
	TIME [epoch: 6.78 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26588321157552763		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.26588321157552763 | validation: 0.12639889964831574]
	TIME [epoch: 6.78 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123904418482753		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.15123904418482753 | validation: 0.10227011896565735]
	TIME [epoch: 6.78 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16888056617234679		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.16888056617234679 | validation: 0.3454421562265032]
	TIME [epoch: 6.79 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029994953654404		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3029994953654404 | validation: 0.12591761632033743]
	TIME [epoch: 6.83 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18925117265053953		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.18925117265053953 | validation: 0.11668732096750854]
	TIME [epoch: 6.78 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16115267393584742		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.16115267393584742 | validation: 0.12841102477241587]
	TIME [epoch: 6.78 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11725307595301897		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.11725307595301897 | validation: 0.10317285030945786]
	TIME [epoch: 6.78 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763775207442555		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1763775207442555 | validation: 0.28326334577535756]
	TIME [epoch: 6.78 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23253586041015412		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.23253586041015412 | validation: 0.1910798870334728]
	TIME [epoch: 6.78 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614324656056883		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1614324656056883 | validation: 0.1195260338725331]
	TIME [epoch: 6.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362843184245421		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1362843184245421 | validation: 0.08555590611657674]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10187832570067065		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.10187832570067065 | validation: 0.11335325821661152]
	TIME [epoch: 6.79 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162815848318684		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.12162815848318684 | validation: 0.09189262575164683]
	TIME [epoch: 6.79 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13393989034637374		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.13393989034637374 | validation: 0.09995119819905535]
	TIME [epoch: 6.78 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261653511924592		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1261653511924592 | validation: 0.10893134042250223]
	TIME [epoch: 6.78 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573634423195945		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.12573634423195945 | validation: 0.11225512740499904]
	TIME [epoch: 6.78 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16780199151083336		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.16780199151083336 | validation: 0.11121292811483952]
	TIME [epoch: 6.81 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137148035276746		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.137148035276746 | validation: 0.33524600343506805]
	TIME [epoch: 6.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4953076652749955		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4953076652749955 | validation: 0.2911186700672021]
	TIME [epoch: 6.78 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666390163448408		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.2666390163448408 | validation: 0.13593829824720294]
	TIME [epoch: 6.78 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13811248438058735		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.13811248438058735 | validation: 0.11087768687135433]
	TIME [epoch: 6.78 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144322329831698		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.144322329831698 | validation: 0.10499862661561951]
	TIME [epoch: 6.78 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11600895674955952		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.11600895674955952 | validation: 0.1752938286820942]
	TIME [epoch: 6.78 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541593621499686		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.1541593621499686 | validation: 0.10873873633385188]
	TIME [epoch: 6.82 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029151666652823		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1029151666652823 | validation: 0.11450934725911216]
	TIME [epoch: 6.79 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672176484431543		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1672176484431543 | validation: 0.10581858525216609]
	TIME [epoch: 6.78 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14039881541347451		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.14039881541347451 | validation: 0.11299759118412732]
	TIME [epoch: 6.78 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623993561321451		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.10623993561321451 | validation: 0.09401059553126506]
	TIME [epoch: 6.79 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15857238506961055		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.15857238506961055 | validation: 0.11287293088765227]
	TIME [epoch: 6.78 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11588910330586305		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.11588910330586305 | validation: 0.09240406898057651]
	TIME [epoch: 6.79 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13031635544519266		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.13031635544519266 | validation: 0.09344311849956559]
	TIME [epoch: 6.82 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0937250469552595		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0937250469552595 | validation: 0.0896068310903699]
	TIME [epoch: 6.79 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231338009549526		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.1231338009549526 | validation: 0.1694180267130621]
	TIME [epoch: 6.78 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20423812096023417		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.20423812096023417 | validation: 0.09926288626910577]
	TIME [epoch: 6.78 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063168611772352		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2063168611772352 | validation: 0.19129006643324922]
	TIME [epoch: 6.78 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557568293592372		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1557568293592372 | validation: 0.11053280878149449]
	TIME [epoch: 6.78 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09746296622796514		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09746296622796514 | validation: 0.08440408636975912]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080411721079571		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.10080411721079571 | validation: 0.09613089187022864]
	TIME [epoch: 6.82 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274637592281626		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.12274637592281626 | validation: 0.12175645010222774]
	TIME [epoch: 6.77 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759263337493726		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1759263337493726 | validation: 0.13698225644742465]
	TIME [epoch: 6.77 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785535770533653		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.11785535770533653 | validation: 0.12675024918949596]
	TIME [epoch: 6.77 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13001609304358178		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.13001609304358178 | validation: 0.1474925069371179]
	TIME [epoch: 6.77 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15838814011392724		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.15838814011392724 | validation: 0.1795762972375357]
	TIME [epoch: 6.77 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19720148923128172		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.19720148923128172 | validation: 0.14538263194485113]
	TIME [epoch: 6.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11797892239671876		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.11797892239671876 | validation: 0.10641330157426343]
	TIME [epoch: 6.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805843966137471		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.1805843966137471 | validation: 0.10114014907333588]
	TIME [epoch: 6.78 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490928763153529		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.1490928763153529 | validation: 0.2385243448604675]
	TIME [epoch: 6.77 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20005683040749492		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.20005683040749492 | validation: 0.09357543120945058]
	TIME [epoch: 6.77 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388422676065484		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1388422676065484 | validation: 0.16785846891490389]
	TIME [epoch: 6.77 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088398353310926		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2088398353310926 | validation: 0.18884371813490072]
	TIME [epoch: 6.77 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911792095693868		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2911792095693868 | validation: 0.3562882311044816]
	TIME [epoch: 6.81 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25231886891553285		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.25231886891553285 | validation: 0.10643942375788339]
	TIME [epoch: 6.78 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140005553946748		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.140005553946748 | validation: 0.11099464554055356]
	TIME [epoch: 6.77 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13765459212468178		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.13765459212468178 | validation: 0.15274001151421057]
	TIME [epoch: 6.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13274095908404138		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.13274095908404138 | validation: 0.09149805634453069]
	TIME [epoch: 6.77 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521207756715202		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10521207756715202 | validation: 0.10362771752052072]
	TIME [epoch: 6.77 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620747273338597		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.14620747273338597 | validation: 0.1040450607653591]
	TIME [epoch: 6.77 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287479012975007		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.11287479012975007 | validation: 0.17792652733828995]
	TIME [epoch: 6.81 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435365341075728		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.1435365341075728 | validation: 0.1675674327279832]
	TIME [epoch: 6.78 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21789931415060515		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.21789931415060515 | validation: 0.19913722044124282]
	TIME [epoch: 6.76 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184861494051332		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.184861494051332 | validation: 0.3591660879724701]
	TIME [epoch: 6.77 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092022633858409		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3092022633858409 | validation: 0.26841748067881455]
	TIME [epoch: 6.76 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20952884869426347		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.20952884869426347 | validation: 0.11257947724141033]
	TIME [epoch: 6.77 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114936009008439		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.1114936009008439 | validation: 0.18268329326781907]
	TIME [epoch: 6.77 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17623120615327328		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.17623120615327328 | validation: 0.14019398797627503]
	TIME [epoch: 6.81 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17280820466765495		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.17280820466765495 | validation: 0.2047677521024266]
	TIME [epoch: 6.77 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923839296775576		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.14923839296775576 | validation: 0.10939872881588847]
	TIME [epoch: 6.77 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092935158538631		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.12092935158538631 | validation: 0.1009562367592141]
	TIME [epoch: 6.77 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18761968113320232		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.18761968113320232 | validation: 0.29192112730917485]
	TIME [epoch: 6.77 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21269762849498475		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.21269762849498475 | validation: 0.12979817240320057]
	TIME [epoch: 6.78 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10637747161689717		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10637747161689717 | validation: 0.08736279146021608]
	TIME [epoch: 6.79 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841606078500368		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10841606078500368 | validation: 0.13536921114225164]
	TIME [epoch: 6.81 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073468836932673		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.11073468836932673 | validation: 0.09014920963034587]
	TIME [epoch: 6.77 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12275926201558596		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.12275926201558596 | validation: 0.09065960338359687]
	TIME [epoch: 6.76 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674119194323		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.10674119194323 | validation: 0.12066742489035184]
	TIME [epoch: 6.76 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200413706985047		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.10200413706985047 | validation: 0.08264288640447828]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10161258764577855		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.10161258764577855 | validation: 0.09102866583883462]
	TIME [epoch: 6.76 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934134416297693		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.10934134416297693 | validation: 0.1557211741276824]
	TIME [epoch: 6.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266506898206761		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.1266506898206761 | validation: 0.11641013947911757]
	TIME [epoch: 6.78 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12181949365382494		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.12181949365382494 | validation: 0.08901058623765014]
	TIME [epoch: 6.75 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625340262541415		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.10625340262541415 | validation: 0.08192060430701248]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546121338843606		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.09546121338843606 | validation: 0.09206905841906082]
	TIME [epoch: 6.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09431429852089117		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.09431429852089117 | validation: 0.12066346695754503]
	TIME [epoch: 6.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16176012047411714		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.16176012047411714 | validation: 0.07493535522126092]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980330091094138		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.0980330091094138 | validation: 0.12652102814401395]
	TIME [epoch: 6.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770114676036876		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.13770114676036876 | validation: 0.13102622096908645]
	TIME [epoch: 6.76 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019458143264626		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.12019458143264626 | validation: 0.07120721643946204]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10074123719363881		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.10074123719363881 | validation: 0.07466425955507817]
	TIME [epoch: 6.75 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033872464685653		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.10033872464685653 | validation: 0.07608564825163919]
	TIME [epoch: 6.75 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902171466410758		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.11902171466410758 | validation: 0.10968781584272727]
	TIME [epoch: 6.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114401903987189		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.114401903987189 | validation: 0.07414736325940136]
	TIME [epoch: 6.76 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08377605617055572		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.08377605617055572 | validation: 0.07509218517163649]
	TIME [epoch: 6.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276238742914306		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08276238742914306 | validation: 0.09406057892784606]
	TIME [epoch: 6.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039061498065329		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.09039061498065329 | validation: 0.08448150307041906]
	TIME [epoch: 6.75 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09617582175518768		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09617582175518768 | validation: 0.13715682981295102]
	TIME [epoch: 6.75 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344074897912035		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.14344074897912035 | validation: 0.2660584483510027]
	TIME [epoch: 6.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165542334786811		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2165542334786811 | validation: 0.10125347068366367]
	TIME [epoch: 6.75 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09702801535690984		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.09702801535690984 | validation: 0.10892502431648607]
	TIME [epoch: 6.77 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854261220261776		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.08854261220261776 | validation: 0.07466071532914198]
	TIME [epoch: 6.79 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17616903591576316		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.17616903591576316 | validation: 0.08845093147823062]
	TIME [epoch: 6.75 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452584614253828		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.09452584614253828 | validation: 0.07998903393688103]
	TIME [epoch: 6.75 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09269233194012083		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.09269233194012083 | validation: 0.08351768358640053]
	TIME [epoch: 6.76 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674737362943411		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.10674737362943411 | validation: 0.08355795396565763]
	TIME [epoch: 6.75 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975858644871738		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09975858644871738 | validation: 0.22865639939049368]
	TIME [epoch: 6.75 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17741176132865236		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.17741176132865236 | validation: 0.08570056008772495]
	TIME [epoch: 6.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462673108115931		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.08462673108115931 | validation: 0.08590481665396894]
	TIME [epoch: 6.77 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091723515137155		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.091723515137155 | validation: 0.07424438782048211]
	TIME [epoch: 6.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971515429946579		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0971515429946579 | validation: 0.06788646419191605]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340444204995055		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.09340444204995055 | validation: 0.10107128866643417]
	TIME [epoch: 6.75 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09608590452047074		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.09608590452047074 | validation: 0.08475207570702661]
	TIME [epoch: 6.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08887148242642968		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.08887148242642968 | validation: 0.09507710079587962]
	TIME [epoch: 6.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08985952898351532		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.08985952898351532 | validation: 0.07565992167933172]
	TIME [epoch: 6.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124304373278692		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.09124304373278692 | validation: 0.07834809624739635]
	TIME [epoch: 6.76 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13102835548639352		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.13102835548639352 | validation: 0.19145243284797764]
	TIME [epoch: 6.75 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16804302224415013		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.16804302224415013 | validation: 0.07092542899685736]
	TIME [epoch: 6.75 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475951817590238		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.08475951817590238 | validation: 0.08177877916854755]
	TIME [epoch: 6.76 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442447151798941		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.09442447151798941 | validation: 0.0968974634096686]
	TIME [epoch: 6.75 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09604659970969293		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.09604659970969293 | validation: 0.07480279656608356]
	TIME [epoch: 6.76 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368525060007494		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.08368525060007494 | validation: 0.12149100661364738]
	TIME [epoch: 6.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10286110325099718		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10286110325099718 | validation: 0.09172769952206672]
	TIME [epoch: 6.77 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09838016842980463		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.09838016842980463 | validation: 0.14284461587654002]
	TIME [epoch: 6.76 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777953650328223		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.10777953650328223 | validation: 0.10203787225336106]
	TIME [epoch: 6.76 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09858732315448501		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.09858732315448501 | validation: 0.0742529462944714]
	TIME [epoch: 6.75 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221505414981125		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.10221505414981125 | validation: 0.06442796103330094]
	TIME [epoch: 6.74 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08700839880840217		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08700839880840217 | validation: 0.07295032119818155]
	TIME [epoch: 6.77 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360795954384315		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.08360795954384315 | validation: 0.0844595247888531]
	TIME [epoch: 6.78 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11272152741989191		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.11272152741989191 | validation: 0.13725691689309782]
	TIME [epoch: 6.75 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748637720925105		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.10748637720925105 | validation: 0.06809458477198566]
	TIME [epoch: 6.75 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093038646106363		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.09093038646106363 | validation: 0.09209820014262614]
	TIME [epoch: 6.75 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09343550613459228		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09343550613459228 | validation: 0.08698090164316546]
	TIME [epoch: 6.75 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952089102410653		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07952089102410653 | validation: 0.07186610693640601]
	TIME [epoch: 6.75 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09465182232865733		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.09465182232865733 | validation: 0.11162548057380561]
	TIME [epoch: 6.77 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10661338561928704		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.10661338561928704 | validation: 0.07944141726172567]
	TIME [epoch: 6.78 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985868591225608		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.12985868591225608 | validation: 0.08713416895335216]
	TIME [epoch: 6.76 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824433241028748		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08824433241028748 | validation: 0.10522476771215142]
	TIME [epoch: 6.76 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23515317643319955		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.23515317643319955 | validation: 0.25165895925418574]
	TIME [epoch: 6.75 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23724822942968687		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.23724822942968687 | validation: 0.0799933836110568]
	TIME [epoch: 6.76 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294025917058515		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.07294025917058515 | validation: 0.08780367176639103]
	TIME [epoch: 6.75 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08099462316947123		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.08099462316947123 | validation: 0.08714929817098171]
	TIME [epoch: 6.79 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14505675068577878		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.14505675068577878 | validation: 0.09449570954595327]
	TIME [epoch: 6.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10289658852455824		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.10289658852455824 | validation: 0.13512048325095516]
	TIME [epoch: 6.75 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267708535773656		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.13267708535773656 | validation: 0.11164073191051516]
	TIME [epoch: 6.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403261534518229		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.1403261534518229 | validation: 0.1912284299438806]
	TIME [epoch: 6.75 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15067586089289547		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.15067586089289547 | validation: 0.09837099897387994]
	TIME [epoch: 6.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468547676816651		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.11468547676816651 | validation: 0.09275648679724811]
	TIME [epoch: 6.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102996878437962		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09102996878437962 | validation: 0.06730698687293335]
	TIME [epoch: 6.79 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921837625494375		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.08921837625494375 | validation: 0.05306176619048862]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_692.pth
	Model improved!!!
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273970656586622		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.07273970656586622 | validation: 0.06891839263384059]
	TIME [epoch: 6.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307474546460386		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.1307474546460386 | validation: 0.12104712328274207]
	TIME [epoch: 6.76 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16041155268263824		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.16041155268263824 | validation: 0.12036151302763709]
	TIME [epoch: 6.75 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10897742299576012		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.10897742299576012 | validation: 0.0730534814231181]
	TIME [epoch: 6.76 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14436843198011418		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14436843198011418 | validation: 0.0942815711490006]
	TIME [epoch: 6.76 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185906357777505		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1185906357777505 | validation: 0.1796151384036871]
	TIME [epoch: 6.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15386283631915731		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.15386283631915731 | validation: 0.15244249162551207]
	TIME [epoch: 6.76 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1794492988018625		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1794492988018625 | validation: 0.11043508945003039]
	TIME [epoch: 6.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665770255426726		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10665770255426726 | validation: 0.12311108647470914]
	TIME [epoch: 6.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755435962974817		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.17755435962974817 | validation: 0.13228794198980104]
	TIME [epoch: 6.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636523921456508		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.1636523921456508 | validation: 0.1794207439746984]
	TIME [epoch: 6.76 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291635053972121		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1291635053972121 | validation: 0.07658842889293757]
	TIME [epoch: 6.77 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09169264510677597		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09169264510677597 | validation: 0.07372313191586374]
	TIME [epoch: 6.78 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759163912949609		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.11759163912949609 | validation: 0.11370231420327903]
	TIME [epoch: 6.76 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468451879206674		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.12468451879206674 | validation: 0.09377369832922956]
	TIME [epoch: 6.76 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12134296409317066		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.12134296409317066 | validation: 0.0784822173505002]
	TIME [epoch: 6.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435294016965346		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.11435294016965346 | validation: 0.06480063222868154]
	TIME [epoch: 6.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610305393751509		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.09610305393751509 | validation: 0.10001095266259899]
	TIME [epoch: 6.75 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12199611799650399		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.12199611799650399 | validation: 0.06036139987760573]
	TIME [epoch: 6.77 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09146522230673716		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.09146522230673716 | validation: 0.09588059168002638]
	TIME [epoch: 6.79 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11705992936401682		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.11705992936401682 | validation: 0.07171950566625665]
	TIME [epoch: 6.76 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921768840268555		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.0921768840268555 | validation: 0.19393632428173002]
	TIME [epoch: 6.75 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.325647666840286		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.325647666840286 | validation: 0.3913809357407833]
	TIME [epoch: 6.76 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30461971231788787		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.30461971231788787 | validation: 0.15191937741710798]
	TIME [epoch: 6.76 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169140026051409		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.11169140026051409 | validation: 0.06697375579814373]
	TIME [epoch: 6.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08496276776652534		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.08496276776652534 | validation: 0.07704411255807819]
	TIME [epoch: 6.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08328195121515962		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.08328195121515962 | validation: 0.07572426701976467]
	TIME [epoch: 6.77 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003346798966486		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.10003346798966486 | validation: 0.11501307620741458]
	TIME [epoch: 6.76 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08477933102827638		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.08477933102827638 | validation: 0.0832332085936458]
	TIME [epoch: 6.76 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13437835347565608		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.13437835347565608 | validation: 0.12083615375768032]
	TIME [epoch: 6.76 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252710721643019		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.09252710721643019 | validation: 0.07216061809267908]
	TIME [epoch: 6.76 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07927820085699967		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07927820085699967 | validation: 0.0677841413144393]
	TIME [epoch: 6.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678103057699662		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07678103057699662 | validation: 0.07490463949096939]
	TIME [epoch: 6.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954093731700266		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.0954093731700266 | validation: 0.07195730284210312]
	TIME [epoch: 6.76 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668787986153792		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.08668787986153792 | validation: 0.0692160955113088]
	TIME [epoch: 6.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395858973884712		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.08395858973884712 | validation: 0.06774324812443347]
	TIME [epoch: 6.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07012986560607778		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.07012986560607778 | validation: 0.06899373701944966]
	TIME [epoch: 6.76 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121723675060187		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08121723675060187 | validation: 0.06130260483017948]
	TIME [epoch: 6.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07737339634279959		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07737339634279959 | validation: 0.04751287742935478]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07167369607591001		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.07167369607591001 | validation: 0.07465227431907939]
	TIME [epoch: 6.82 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12334566861042155		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.12334566861042155 | validation: 0.12309444451569801]
	TIME [epoch: 6.77 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391269009750708		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1391269009750708 | validation: 0.0628095938614806]
	TIME [epoch: 6.77 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08468816044441971		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08468816044441971 | validation: 0.09299376648796512]
	TIME [epoch: 6.77 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274328901501653		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.10274328901501653 | validation: 0.10967879897660684]
	TIME [epoch: 6.77 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08699502878427728		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.08699502878427728 | validation: 0.08310647472350374]
	TIME [epoch: 6.77 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000279665862906		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.09000279665862906 | validation: 0.07550367585670081]
	TIME [epoch: 6.79 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219388909529574		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.1219388909529574 | validation: 0.19828578124052554]
	TIME [epoch: 6.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559589956920492		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15559589956920492 | validation: 0.0836147863294652]
	TIME [epoch: 6.77 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809131664014462		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.0809131664014462 | validation: 0.11497426580781621]
	TIME [epoch: 6.76 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104966838662815		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.09104966838662815 | validation: 0.08519311879405839]
	TIME [epoch: 6.76 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855883473364715		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.07855883473364715 | validation: 0.09343671003723317]
	TIME [epoch: 6.76 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07865879289490557		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.07865879289490557 | validation: 0.06796126636106234]
	TIME [epoch: 6.76 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750197786800675		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.0750197786800675 | validation: 0.07366391235247582]
	TIME [epoch: 6.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895213267177647		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0895213267177647 | validation: 0.11112220611601362]
	TIME [epoch: 6.78 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09380282114435773		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.09380282114435773 | validation: 0.065152735540291]
	TIME [epoch: 6.76 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07177557401230476		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.07177557401230476 | validation: 0.08539418498283197]
	TIME [epoch: 6.76 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09140104854894854		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.09140104854894854 | validation: 0.08141193442605735]
	TIME [epoch: 6.76 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07451247193856834		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.07451247193856834 | validation: 0.06217938006317164]
	TIME [epoch: 6.76 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06781834922730907		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.06781834922730907 | validation: 0.08827665073279876]
	TIME [epoch: 6.77 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718149964998234		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.09718149964998234 | validation: 0.0847708163562523]
	TIME [epoch: 6.81 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481036432536181		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.07481036432536181 | validation: 0.07346150419508174]
	TIME [epoch: 6.79 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15583639807376579		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.15583639807376579 | validation: 0.13808716161731727]
	TIME [epoch: 6.77 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15367765421637578		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15367765421637578 | validation: 0.07687163836118481]
	TIME [epoch: 6.77 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10882140996751627		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10882140996751627 | validation: 0.11630689513601508]
	TIME [epoch: 6.77 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201724807217493		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.1201724807217493 | validation: 0.09444268006345743]
	TIME [epoch: 6.77 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321389432754718		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.11321389432754718 | validation: 0.071449259710201]
	TIME [epoch: 6.77 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243427177002097		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08243427177002097 | validation: 0.07251799792198246]
	TIME [epoch: 6.81 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981206514776837		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.07981206514776837 | validation: 0.07422200607350649]
	TIME [epoch: 6.78 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481194322587081		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07481194322587081 | validation: 0.11388767774542272]
	TIME [epoch: 6.77 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801736811400924		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.12801736811400924 | validation: 0.0787818522939721]
	TIME [epoch: 6.77 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07347200451851643		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07347200451851643 | validation: 0.059927555658361935]
	TIME [epoch: 6.77 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941694035613076		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.08941694035613076 | validation: 0.07027941817047262]
	TIME [epoch: 6.78 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09292207094455125		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.09292207094455125 | validation: 0.07673484541614344]
	TIME [epoch: 6.78 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018309896603429		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08018309896603429 | validation: 0.07753092775605383]
	TIME [epoch: 6.82 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877723076871683		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0877723076871683 | validation: 0.060709181320659264]
	TIME [epoch: 6.78 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262782829446159		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.09262782829446159 | validation: 0.09307134790316332]
	TIME [epoch: 6.78 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153976899274074		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.08153976899274074 | validation: 0.06602810841420327]
	TIME [epoch: 6.78 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911415577623385		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.06911415577623385 | validation: 0.07744433438552031]
	TIME [epoch: 6.78 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719201846434783		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.0719201846434783 | validation: 0.05806798328270732]
	TIME [epoch: 6.78 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015586994183995		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.07015586994183995 | validation: 0.05841590016570354]
	TIME [epoch: 6.79 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0754152852300013		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0754152852300013 | validation: 0.07456252558405427]
	TIME [epoch: 6.81 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15998137562233763		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.15998137562233763 | validation: 0.09586735510777553]
	TIME [epoch: 6.78 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09901090735424607		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09901090735424607 | validation: 0.07582769531392496]
	TIME [epoch: 6.78 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230316484683187		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.11230316484683187 | validation: 0.09079373957233627]
	TIME [epoch: 6.78 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979814822813647		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.13979814822813647 | validation: 0.07425461665630595]
	TIME [epoch: 6.78 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931347154221772		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.08931347154221772 | validation: 0.07774164463619723]
	TIME [epoch: 6.77 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078112484978517		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.08078112484978517 | validation: 0.11509566275103039]
	TIME [epoch: 6.82 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633449481040774		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.10633449481040774 | validation: 0.06900698743915556]
	TIME [epoch: 6.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09554835084199338		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.09554835084199338 | validation: 0.0737152282876217]
	TIME [epoch: 6.78 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509681829495907		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.07509681829495907 | validation: 0.11751838625541064]
	TIME [epoch: 6.78 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1166327873962274		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1166327873962274 | validation: 0.08501080497773893]
	TIME [epoch: 6.77 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619062425324552		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09619062425324552 | validation: 0.09550023254970044]
	TIME [epoch: 6.78 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09430382682101998		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09430382682101998 | validation: 0.08096898690535241]
	TIME [epoch: 6.78 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0806059502435057		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0806059502435057 | validation: 0.06247388577967934]
	TIME [epoch: 6.83 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736114784559848		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.0736114784559848 | validation: 0.06561445127919525]
	TIME [epoch: 6.79 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07787926853250468		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.07787926853250468 | validation: 0.06496637371181585]
	TIME [epoch: 6.78 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745534813051913		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.07745534813051913 | validation: 0.08552464464660384]
	TIME [epoch: 6.78 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0807818334234443		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0807818334234443 | validation: 0.06407990112500186]
	TIME [epoch: 6.78 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12166522776050376		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.12166522776050376 | validation: 0.169443073325459]
	TIME [epoch: 6.78 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17498065108119992		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.17498065108119992 | validation: 0.15792394974944282]
	TIME [epoch: 6.78 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14701188342740662		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.14701188342740662 | validation: 0.119230420555803]
	TIME [epoch: 6.82 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935936533690632		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.0935936533690632 | validation: 0.06209064479670116]
	TIME [epoch: 6.79 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07411233690698515		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07411233690698515 | validation: 0.06493184806118724]
	TIME [epoch: 6.77 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782079060026648		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.07782079060026648 | validation: 0.06121777761960898]
	TIME [epoch: 6.78 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09182782835572431		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.09182782835572431 | validation: 0.06776084787417702]
	TIME [epoch: 6.77 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200876307990157		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.08200876307990157 | validation: 0.07065515605305756]
	TIME [epoch: 6.77 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695367385632357		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07695367385632357 | validation: 0.1242788744110889]
	TIME [epoch: 6.78 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758958232331868		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.12758958232331868 | validation: 0.09823737563872924]
	TIME [epoch: 6.83 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575044438185914		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.08575044438185914 | validation: 0.13844823770383238]
	TIME [epoch: 6.78 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329072259376702		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.1329072259376702 | validation: 0.1185119179069655]
	TIME [epoch: 6.78 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09301247500278167		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.09301247500278167 | validation: 0.07654986140978981]
	TIME [epoch: 6.78 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09571159399142322		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.09571159399142322 | validation: 0.06837269798961261]
	TIME [epoch: 6.78 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028121204561563		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.08028121204561563 | validation: 0.06581673606895838]
	TIME [epoch: 6.78 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09537518925297243		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.09537518925297243 | validation: 0.06019535211655144]
	TIME [epoch: 6.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628765867590328		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.09628765867590328 | validation: 0.1470590667401675]
	TIME [epoch: 6.81 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504802636274583		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1504802636274583 | validation: 0.1416168500371484]
	TIME [epoch: 6.78 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003126411484859		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1003126411484859 | validation: 0.07159987505454239]
	TIME [epoch: 6.77 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605365956260133		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08605365956260133 | validation: 0.09581117364681463]
	TIME [epoch: 6.77 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09295094436979509		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.09295094436979509 | validation: 0.06614561147670198]
	TIME [epoch: 6.77 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313528204981806		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.08313528204981806 | validation: 0.1085400020356642]
	TIME [epoch: 6.77 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080067471463342		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.08080067471463342 | validation: 0.07466031000873702]
	TIME [epoch: 6.81 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602305377979156		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06602305377979156 | validation: 0.06844635041521349]
	TIME [epoch: 6.78 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900573795749944		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.06900573795749944 | validation: 0.06647178483765573]
	TIME [epoch: 6.78 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07558232309388191		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.07558232309388191 | validation: 0.07707042096984464]
	TIME [epoch: 6.77 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804640580915117		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.08804640580915117 | validation: 0.14740624672319128]
	TIME [epoch: 6.77 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679836835404507		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.1679836835404507 | validation: 0.14848903170698835]
	TIME [epoch: 6.77 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11425204297282165		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.11425204297282165 | validation: 0.06576202837014372]
	TIME [epoch: 6.77 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796794290282899		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07796794290282899 | validation: 0.06513338597978294]
	TIME [epoch: 6.82 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09207667641501989		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.09207667641501989 | validation: 0.05865781360179689]
	TIME [epoch: 6.79 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07282423943583671		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07282423943583671 | validation: 0.06067738462242059]
	TIME [epoch: 6.77 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086925378026734		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.1086925378026734 | validation: 0.10998394730775152]
	TIME [epoch: 6.77 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108884204788598		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.09108884204788598 | validation: 0.06488125777539133]
	TIME [epoch: 6.77 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065766791787996		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.065766791787996 | validation: 0.07318659795919974]
	TIME [epoch: 6.77 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508451877426331		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.07508451877426331 | validation: 0.05871712995774908]
	TIME [epoch: 6.78 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095055539172985		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.095055539172985 | validation: 0.09482119193091754]
	TIME [epoch: 6.81 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097306349896297		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.097306349896297 | validation: 0.05434415715455708]
	TIME [epoch: 6.78 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420851694686838		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.07420851694686838 | validation: 0.07919095754566696]
	TIME [epoch: 6.77 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547080086800777		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09547080086800777 | validation: 0.1500768973037558]
	TIME [epoch: 6.77 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966970090320597		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0966970090320597 | validation: 0.07336170095022412]
	TIME [epoch: 6.78 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128549044693884		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.08128549044693884 | validation: 0.11638182066319877]
	TIME [epoch: 6.77 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826551999160478		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.09826551999160478 | validation: 0.10293831589125305]
	TIME [epoch: 6.79 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700322057392888		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.12700322057392888 | validation: 0.07679241275630545]
	TIME [epoch: 6.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0752021611792758		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0752021611792758 | validation: 0.06343927244886738]
	TIME [epoch: 6.77 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163402329615712		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.07163402329615712 | validation: 0.056559107487636595]
	TIME [epoch: 6.77 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816916273092083		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.06816916273092083 | validation: 0.06473094312522523]
	TIME [epoch: 6.77 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794442470958075		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0794442470958075 | validation: 0.06349199855098583]
	TIME [epoch: 6.77 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761428543941575		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.06761428543941575 | validation: 0.06777894987918819]
	TIME [epoch: 6.78 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320536747457744		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.07320536747457744 | validation: 0.05710047059248909]
	TIME [epoch: 6.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515699841685257		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.09515699841685257 | validation: 0.12065334199033576]
	TIME [epoch: 6.81 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392061579578788		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.12392061579578788 | validation: 0.07154478904110528]
	TIME [epoch: 6.77 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740843645459304		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.07740843645459304 | validation: 0.07001001832067193]
	TIME [epoch: 6.77 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639981076781406		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.0639981076781406 | validation: 0.057388109750130936]
	TIME [epoch: 6.77 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163686188816203		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07163686188816203 | validation: 0.07423493651343856]
	TIME [epoch: 6.76 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12535586595834977		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.12535586595834977 | validation: 0.13460303844838228]
	TIME [epoch: 6.77 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902922191304475		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.09902922191304475 | validation: 0.06438686582031172]
	TIME [epoch: 6.81 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917046418504089		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0917046418504089 | validation: 0.10003508279503517]
	TIME [epoch: 6.78 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274659266906531		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.11274659266906531 | validation: 0.09395935765888752]
	TIME [epoch: 6.77 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926626660327044		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08926626660327044 | validation: 0.0921922351020075]
	TIME [epoch: 6.77 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13418724128414755		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13418724128414755 | validation: 0.16220335683711962]
	TIME [epoch: 6.77 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372173803341782		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1372173803341782 | validation: 0.11394236575132843]
	TIME [epoch: 6.77 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348115190728153		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.11348115190728153 | validation: 0.1308614104361552]
	TIME [epoch: 6.77 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13066428418138815		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.13066428418138815 | validation: 0.09325348726958314]
	TIME [epoch: 6.81 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08882902244023055		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08882902244023055 | validation: 0.0953613099503982]
	TIME [epoch: 6.78 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09877342308444856		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.09877342308444856 | validation: 0.11427425768907296]
	TIME [epoch: 6.77 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09173488152291087		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.09173488152291087 | validation: 0.062159870674999715]
	TIME [epoch: 6.77 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366703258014387		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07366703258014387 | validation: 0.06360395595789478]
	TIME [epoch: 6.77 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294987304200978		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.10294987304200978 | validation: 0.09066341841631466]
	TIME [epoch: 6.77 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10212493649433727		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.10212493649433727 | validation: 0.06700108155216106]
	TIME [epoch: 6.77 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07149692228591135		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.07149692228591135 | validation: 0.06264578625567269]
	TIME [epoch: 6.81 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761082745985932		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.0761082745985932 | validation: 0.06815876931758291]
	TIME [epoch: 6.77 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167110744669571		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08167110744669571 | validation: 0.0792374075067383]
	TIME [epoch: 6.77 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783025344771418		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.0783025344771418 | validation: 0.08089167972271037]
	TIME [epoch: 6.77 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13131939724119507		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.13131939724119507 | validation: 0.08983107520682887]
	TIME [epoch: 6.77 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953699183423253		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.08953699183423253 | validation: 0.05429869060679646]
	TIME [epoch: 6.77 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701873700616982		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.07701873700616982 | validation: 0.07385201636832217]
	TIME [epoch: 6.79 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252268458309133		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.07252268458309133 | validation: 0.08053423464182219]
	TIME [epoch: 6.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08265212577572846		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.08265212577572846 | validation: 0.07625001683324335]
	TIME [epoch: 6.76 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07231184737244792		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07231184737244792 | validation: 0.07660710259647897]
	TIME [epoch: 6.76 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983112987539201		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.06983112987539201 | validation: 0.05600714516161911]
	TIME [epoch: 6.76 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803499831334035		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.06803499831334035 | validation: 0.0693625221023485]
	TIME [epoch: 6.76 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452444137516968		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.07452444137516968 | validation: 0.06828877983654759]
	TIME [epoch: 6.77 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09683702198682936		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.09683702198682936 | validation: 0.21473488730066453]
	TIME [epoch: 6.79 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2575732118396441		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.2575732118396441 | validation: 0.33968468931497897]
	TIME [epoch: 6.79 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967377697539389		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2967377697539389 | validation: 0.21387757690485643]
	TIME [epoch: 6.77 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619821925222835		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1619821925222835 | validation: 0.08297585922397102]
	TIME [epoch: 6.76 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07512875966788894		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.07512875966788894 | validation: 0.07478223087471847]
	TIME [epoch: 6.77 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717558350444851		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0717558350444851 | validation: 0.0710609697729884]
	TIME [epoch: 6.76 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017393900220116		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.07017393900220116 | validation: 0.06416448637812869]
	TIME [epoch: 6.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06833547440024854		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.06833547440024854 | validation: 0.06189490718120268]
	TIME [epoch: 6.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06883015569104992		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.06883015569104992 | validation: 0.07449759897381875]
	TIME [epoch: 6.78 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12772879458313569		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.12772879458313569 | validation: 0.07603950399633733]
	TIME [epoch: 6.76 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888582364085885		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0888582364085885 | validation: 0.05833604275701403]
	TIME [epoch: 6.76 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646307139046827		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0646307139046827 | validation: 0.08233718021427276]
	TIME [epoch: 6.76 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326854405202703		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.09326854405202703 | validation: 0.14724737652541586]
	TIME [epoch: 6.76 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631115687741225		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.14631115687741225 | validation: 0.09776434392297287]
	TIME [epoch: 6.76 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753508606967043		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0753508606967043 | validation: 0.055636602960123224]
	TIME [epoch: 6.81 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651721185043439		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0651721185043439 | validation: 0.06643518521553138]
	TIME [epoch: 6.77 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570606451493861		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.07570606451493861 | validation: 0.07890357981540677]
	TIME [epoch: 6.77 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07154129907803411		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.07154129907803411 | validation: 0.06688582740227893]
	TIME [epoch: 6.77 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06705938108455455		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.06705938108455455 | validation: 0.06185889371764263]
	TIME [epoch: 6.77 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07586006439272663		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.07586006439272663 | validation: 0.08877676780311157]
	TIME [epoch: 6.77 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07848108171665735		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.07848108171665735 | validation: 0.07389365752807481]
	TIME [epoch: 6.78 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270188068653326		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.07270188068653326 | validation: 0.06099567531754341]
	TIME [epoch: 6.81 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886416467778701		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.07886416467778701 | validation: 0.06515064794842149]
	TIME [epoch: 6.77 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692047610496146		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.06692047610496146 | validation: 0.057979679049355526]
	TIME [epoch: 6.77 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332889186772633		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.06332889186772633 | validation: 0.05810353674835518]
	TIME [epoch: 6.77 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06927196460130985		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.06927196460130985 | validation: 0.05526908608943048]
	TIME [epoch: 6.77 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655196041885053		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0655196041885053 | validation: 0.06184655630560071]
	TIME [epoch: 6.77 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059654373851799		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.08059654373851799 | validation: 0.06342812941399355]
	TIME [epoch: 6.79 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002157102234747		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.1002157102234747 | validation: 0.07656436023454007]
	TIME [epoch: 6.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11606079280539346		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.11606079280539346 | validation: 0.07480766850431457]
	TIME [epoch: 6.77 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600627192580704		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.08600627192580704 | validation: 0.05170650571561773]
	TIME [epoch: 6.77 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07097642793036008		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.07097642793036008 | validation: 0.09022281606080289]
	TIME [epoch: 6.77 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07647218737431227		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.07647218737431227 | validation: 0.0729538918336684]
	TIME [epoch: 6.77 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06857116576406962		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06857116576406962 | validation: 0.07772674218741168]
	TIME [epoch: 6.76 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109305644153807		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.1109305644153807 | validation: 0.13937612982055647]
	TIME [epoch: 6.81 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281599341422172		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11281599341422172 | validation: 0.08356753602428273]
	TIME [epoch: 6.78 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306342592020348		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.06306342592020348 | validation: 0.06312217776803856]
	TIME [epoch: 6.77 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764557282361496		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.0764557282361496 | validation: 0.060466718512255435]
	TIME [epoch: 6.77 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516015497284677		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.06516015497284677 | validation: 0.06650311113064623]
	TIME [epoch: 6.77 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917985714055136		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.06917985714055136 | validation: 0.05706975978687692]
	TIME [epoch: 6.77 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816173847284689		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.06816173847284689 | validation: 0.052731668018757206]
	TIME [epoch: 6.77 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018741219626662		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.06018741219626662 | validation: 0.05983803573534414]
	TIME [epoch: 6.81 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805271850022243		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.0805271850022243 | validation: 0.07550696603679007]
	TIME [epoch: 6.78 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012710467674889		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09012710467674889 | validation: 0.06686317571867749]
	TIME [epoch: 6.76 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07589165858849695		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.07589165858849695 | validation: 0.07042696992471376]
	TIME [epoch: 6.77 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329607772752357		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.07329607772752357 | validation: 0.06357436301769098]
	TIME [epoch: 6.77 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657233436669062		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08657233436669062 | validation: 0.05712395502162693]
	TIME [epoch: 6.78 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421230987164067		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07421230987164067 | validation: 0.08436938491893348]
	TIME [epoch: 6.78 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859470285674372		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.07859470285674372 | validation: 0.11046461695720915]
	TIME [epoch: 6.82 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747901179221962		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0747901179221962 | validation: 0.0519404687673154]
	TIME [epoch: 6.78 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06683067156774025		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.06683067156774025 | validation: 0.05775527139734497]
	TIME [epoch: 6.77 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531552513717425		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.10531552513717425 | validation: 0.07179098261230632]
	TIME [epoch: 6.78 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172562076086088		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.1172562076086088 | validation: 0.08143292944366019]
	TIME [epoch: 6.78 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09539886182423916		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.09539886182423916 | validation: 0.05067921241427596]
	TIME [epoch: 6.78 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06760674687356351		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.06760674687356351 | validation: 0.08054696469689074]
	TIME [epoch: 6.78 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09155894417222726		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.09155894417222726 | validation: 0.060806282528967456]
	TIME [epoch: 6.81 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06147300192297238		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.06147300192297238 | validation: 0.06284369755134797]
	TIME [epoch: 6.77 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300414739090499		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.06300414739090499 | validation: 0.06046615868985286]
	TIME [epoch: 6.76 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651115869906211		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0651115869906211 | validation: 0.061668096123560515]
	TIME [epoch: 6.76 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06663735233533619		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.06663735233533619 | validation: 0.062023525983968784]
	TIME [epoch: 6.76 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874706778922774		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07874706778922774 | validation: 0.05890109176953409]
	TIME [epoch: 6.77 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06596504502435369		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.06596504502435369 | validation: 0.05967334856833545]
	TIME [epoch: 6.78 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07175715550452791		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.07175715550452791 | validation: 0.0778374790207236]
	TIME [epoch: 6.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0744128085841252		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0744128085841252 | validation: 0.06255984460294126]
	TIME [epoch: 6.77 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313978055547445		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.06313978055547445 | validation: 0.051657774470634396]
	TIME [epoch: 6.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008797525695592		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.06008797525695592 | validation: 0.06425780335593076]
	TIME [epoch: 6.77 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06342156406274865		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.06342156406274865 | validation: 0.07067705773913988]
	TIME [epoch: 6.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720385700477877		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.06720385700477877 | validation: 0.05900383744852286]
	TIME [epoch: 6.76 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711563079868232		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06711563079868232 | validation: 0.06554507872106383]
	TIME [epoch: 6.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06405811709422617		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.06405811709422617 | validation: 0.0744363780750378]
	TIME [epoch: 6.78 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07404775798837535		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.07404775798837535 | validation: 0.04950400828357401]
	TIME [epoch: 6.76 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07024494181300028		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.07024494181300028 | validation: 0.06922726256003395]
	TIME [epoch: 6.76 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07649439451948904		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.07649439451948904 | validation: 0.06548954495414276]
	TIME [epoch: 6.76 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768615179580397		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0768615179580397 | validation: 0.0589688517702418]
	TIME [epoch: 6.76 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346829982536893		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.07346829982536893 | validation: 0.06307328086289425]
	TIME [epoch: 6.76 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181115277985171		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.07181115277985171 | validation: 0.059030657164702044]
	TIME [epoch: 6.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706489520224115		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.06706489520224115 | validation: 0.06638418494036456]
	TIME [epoch: 6.77 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059136228444898895		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.059136228444898895 | validation: 0.050313464568565225]
	TIME [epoch: 6.76 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796232602072319		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.06796232602072319 | validation: 0.06685450852568302]
	TIME [epoch: 6.76 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07166059217422205		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.07166059217422205 | validation: 0.07833763347958513]
	TIME [epoch: 6.76 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274609272663285		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.10274609272663285 | validation: 0.05185261623994032]
	TIME [epoch: 6.76 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625842178651792		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0625842178651792 | validation: 0.07597745017926019]
	TIME [epoch: 6.77 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880679686651067		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.06880679686651067 | validation: 0.07373400387313064]
	TIME [epoch: 6.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06524054717032718		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.06524054717032718 | validation: 0.058713589909224345]
	TIME [epoch: 6.77 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266737564654995		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.06266737564654995 | validation: 0.05670281910698796]
	TIME [epoch: 6.76 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094075558911535		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07094075558911535 | validation: 0.06121956525167104]
	TIME [epoch: 6.76 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609203144155323		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.07609203144155323 | validation: 0.06161753646637606]
	TIME [epoch: 6.76 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542949967576031		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.06542949967576031 | validation: 0.06899382138496382]
	TIME [epoch: 6.76 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717463481105711		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.0717463481105711 | validation: 0.07374707024764282]
	TIME [epoch: 6.77 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439222533220302		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.10439222533220302 | validation: 0.10258448133715581]
	TIME [epoch: 6.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137094205722882		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.11137094205722882 | validation: 0.08404704567834262]
	TIME [epoch: 6.76 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135357407037382		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08135357407037382 | validation: 0.062353046486669575]
	TIME [epoch: 6.76 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809663014231888		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.06809663014231888 | validation: 0.05281282793812317]
	TIME [epoch: 6.76 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926031955602852		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.06926031955602852 | validation: 0.09211419903678364]
	TIME [epoch: 6.76 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08381304921649341		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08381304921649341 | validation: 0.06860252899329217]
	TIME [epoch: 6.76 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07547160322254451		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.07547160322254451 | validation: 0.09933884881021246]
	TIME [epoch: 6.78 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986590497552226		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0986590497552226 | validation: 0.08866116696738247]
	TIME [epoch: 6.79 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08334270009574768		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.08334270009574768 | validation: 0.08738593799877753]
	TIME [epoch: 6.76 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968987629542289		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07968987629542289 | validation: 0.06727464232120897]
	TIME [epoch: 6.76 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681906486633192		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0681906486633192 | validation: 0.06644337166174755]
	TIME [epoch: 6.76 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753886852652653		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0753886852652653 | validation: 0.07197706182513497]
	TIME [epoch: 6.78 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305689049701329		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08305689049701329 | validation: 0.06976283564407336]
	TIME [epoch: 6.77 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686244248192855		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.06686244248192855 | validation: 0.057118529044446066]
	TIME [epoch: 6.81 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045470403620075		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.06045470403620075 | validation: 0.05214419248761991]
	TIME [epoch: 6.79 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06126191686720682		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.06126191686720682 | validation: 0.06262041972430947]
	TIME [epoch: 6.78 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06930982673634542		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06930982673634542 | validation: 0.06333536576315257]
	TIME [epoch: 6.79 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176285501107196		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.08176285501107196 | validation: 0.05994208763591587]
	TIME [epoch: 6.78 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392616904762679		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.07392616904762679 | validation: 0.06002255163963914]
	TIME [epoch: 6.78 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060982885525339384		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.060982885525339384 | validation: 0.059392931422536946]
	TIME [epoch: 6.78 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366760430620086		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.06366760430620086 | validation: 0.0523844693519615]
	TIME [epoch: 6.83 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059241174059357436		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.059241174059357436 | validation: 0.06511738057826633]
	TIME [epoch: 6.79 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346911154487753		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.06346911154487753 | validation: 0.05690868784119976]
	TIME [epoch: 6.78 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05504507090287434		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.05504507090287434 | validation: 0.054486427056015654]
	TIME [epoch: 6.78 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060547532254557376		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.060547532254557376 | validation: 0.0420325130310656]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0588026282886948		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.0588026282886948 | validation: 0.041588459836860034]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_988.pth
	Model improved!!!
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06132687675259872		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06132687675259872 | validation: 0.05267530980862423]
	TIME [epoch: 6.77 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304413050509923		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06304413050509923 | validation: 0.05890193937162473]
	TIME [epoch: 6.81 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324939126434099		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07324939126434099 | validation: 0.06610895337707531]
	TIME [epoch: 6.77 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07497025014682053		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07497025014682053 | validation: 0.05525653999502416]
	TIME [epoch: 6.77 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726119466787035		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06726119466787035 | validation: 0.05195033007441568]
	TIME [epoch: 6.76 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615589600903612		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.06615589600903612 | validation: 0.06109802930507156]
	TIME [epoch: 6.77 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737461715000517		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0737461715000517 | validation: 0.03929044963288674]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_995.pth
	Model improved!!!
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614256274574722		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.06614256274574722 | validation: 0.07053325415523816]
	TIME [epoch: 6.78 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941003722343788		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0941003722343788 | validation: 0.09970274952429412]
	TIME [epoch: 6.79 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08224886301445274		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.08224886301445274 | validation: 0.0634313797382847]
	TIME [epoch: 6.77 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252004535324842		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.08252004535324842 | validation: 0.08767767966389053]
	TIME [epoch: 6.77 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831064495312968		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08831064495312968 | validation: 0.07700328219760393]
	TIME [epoch: 6.77 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08933827362933697		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.08933827362933697 | validation: 0.08189397277405647]
	TIME [epoch: 6.76 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07269817631087601		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.07269817631087601 | validation: 0.057135281492557095]
	TIME [epoch: 6.75 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061804207586955054		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.061804207586955054 | validation: 0.04663225769515385]
	TIME [epoch: 6.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059716620331918796		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.059716620331918796 | validation: 0.06143763010343818]
	TIME [epoch: 6.77 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903685444347395		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.05903685444347395 | validation: 0.0643876868119084]
	TIME [epoch: 6.76 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748609540945474		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.06748609540945474 | validation: 0.05106380246081478]
	TIME [epoch: 6.77 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613197353340503		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.06613197353340503 | validation: 0.05277395790252963]
	TIME [epoch: 6.77 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474935237544627		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.05474935237544627 | validation: 0.0560929335749513]
	TIME [epoch: 6.76 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060233282458458125		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.060233282458458125 | validation: 0.0649954363164706]
	TIME [epoch: 6.78 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800144165376448		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0800144165376448 | validation: 0.08505477853141472]
	TIME [epoch: 6.82 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09265140029245546		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.09265140029245546 | validation: 0.09321385516034944]
	TIME [epoch: 6.77 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547320876822594		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.08547320876822594 | validation: 0.09339111162581779]
	TIME [epoch: 6.76 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1082757250251632		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.1082757250251632 | validation: 0.10803827354353551]
	TIME [epoch: 6.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08464277302649954		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08464277302649954 | validation: 0.05255906825163999]
	TIME [epoch: 6.77 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081954244976091		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.06081954244976091 | validation: 0.06097529196994721]
	TIME [epoch: 6.75 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06770808664472208		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.06770808664472208 | validation: 0.05796790445494587]
	TIME [epoch: 6.77 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07861075793190853		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07861075793190853 | validation: 0.03645359019588204]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_1017.pth
	Model improved!!!
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06084282945587763		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.06084282945587763 | validation: 0.047695918973544214]
	TIME [epoch: 6.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887606106035679		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.06887606106035679 | validation: 0.07483234301300448]
	TIME [epoch: 6.75 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953517171408293		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0953517171408293 | validation: 0.08067079670846805]
	TIME [epoch: 6.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977652036864198		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0977652036864198 | validation: 0.09477839095263962]
	TIME [epoch: 6.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080862311785133		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.1080862311785133 | validation: 0.05982000644804629]
	TIME [epoch: 6.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990847646887154		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08990847646887154 | validation: 0.056153326856811125]
	TIME [epoch: 6.78 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363486594179446		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.08363486594179446 | validation: 0.058492165820134265]
	TIME [epoch: 6.78 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764766381476899		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0764766381476899 | validation: 0.06301922638576607]
	TIME [epoch: 6.75 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480057496748821		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.07480057496748821 | validation: 0.048309920418654784]
	TIME [epoch: 6.75 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069251719436168		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.06069251719436168 | validation: 0.060652820701280294]
	TIME [epoch: 6.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07558562310280573		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.07558562310280573 | validation: 0.07684095837632303]
	TIME [epoch: 6.74 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09559468222031578		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.09559468222031578 | validation: 0.05581299175089948]
	TIME [epoch: 6.74 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.075933346119477		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.075933346119477 | validation: 0.05127885063099115]
	TIME [epoch: 6.79 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999131213465697		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.06999131213465697 | validation: 0.0651326292681461]
	TIME [epoch: 6.77 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467507048279765		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.06467507048279765 | validation: 0.05097729278855728]
	TIME [epoch: 6.75 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708159851751441		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.06708159851751441 | validation: 0.05089926113342805]
	TIME [epoch: 6.76 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06022160796803348		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06022160796803348 | validation: 0.05750945602854039]
	TIME [epoch: 6.76 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06064190488291986		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06064190488291986 | validation: 0.05825246901026819]
	TIME [epoch: 6.76 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07417947648745127		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.07417947648745127 | validation: 0.054960645818655465]
	TIME [epoch: 6.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085614170842006		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.07085614170842006 | validation: 0.045745224658139134]
	TIME [epoch: 6.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453470103505193		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.06453470103505193 | validation: 0.05332451698819331]
	TIME [epoch: 6.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420010106667211		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.06420010106667211 | validation: 0.04273466038231044]
	TIME [epoch: 6.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063789740102346		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.063789740102346 | validation: 0.06643578193878827]
	TIME [epoch: 6.76 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059958129465218196		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.059958129465218196 | validation: 0.05699846454485792]
	TIME [epoch: 6.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06240867959447786		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.06240867959447786 | validation: 0.05373079748124362]
	TIME [epoch: 6.76 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188641404730906		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.06188641404730906 | validation: 0.0532585948806399]
	TIME [epoch: 6.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06857880118152934		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06857880118152934 | validation: 0.062214766429009805]
	TIME [epoch: 6.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161218969746577		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.07161218969746577 | validation: 0.06068503834053244]
	TIME [epoch: 6.76 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06929392382898943		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.06929392382898943 | validation: 0.05340378162737834]
	TIME [epoch: 6.76 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07301165559553915		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07301165559553915 | validation: 0.055923927905000774]
	TIME [epoch: 6.76 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078143835174869		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.06078143835174869 | validation: 0.05236920914514892]
	TIME [epoch: 6.76 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0769564280783306		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0769564280783306 | validation: 0.06116622624135638]
	TIME [epoch: 6.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353752866405717		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.06353752866405717 | validation: 0.05686112613290263]
	TIME [epoch: 6.77 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572783740640913		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.06572783740640913 | validation: 0.06309030394295496]
	TIME [epoch: 6.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544815749389248		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.06544815749389248 | validation: 0.06171101332718705]
	TIME [epoch: 6.76 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07275936725714689		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.07275936725714689 | validation: 0.05299600625490462]
	TIME [epoch: 6.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334646352851655		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.07334646352851655 | validation: 0.04775169274543643]
	TIME [epoch: 6.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06639786903051642		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.06639786903051642 | validation: 0.07466077465915973]
	TIME [epoch: 6.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687260168414709		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.0687260168414709 | validation: 0.06039071858453955]
	TIME [epoch: 6.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07292813740762923		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07292813740762923 | validation: 0.05148241145369518]
	TIME [epoch: 6.76 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06347871342861411		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.06347871342861411 | validation: 0.05261458314123191]
	TIME [epoch: 6.77 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626306855510449		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0626306855510449 | validation: 0.05980101628810315]
	TIME [epoch: 6.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06643058391543886		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.06643058391543886 | validation: 0.06326437714224374]
	TIME [epoch: 6.74 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07072503129982047		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.07072503129982047 | validation: 0.08433153313765898]
	TIME [epoch: 6.74 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07465462357171908		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.07465462357171908 | validation: 0.07669628487342957]
	TIME [epoch: 6.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08246498766785304		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08246498766785304 | validation: 0.07456684140701476]
	TIME [epoch: 6.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577233868375442		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.08577233868375442 | validation: 0.07123033520213361]
	TIME [epoch: 6.76 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892726203802242		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.06892726203802242 | validation: 0.06082696796879629]
	TIME [epoch: 6.76 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06418544708393759		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.06418544708393759 | validation: 0.061616296337052276]
	TIME [epoch: 6.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727098841266911		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.06727098841266911 | validation: 0.0489937146067321]
	TIME [epoch: 6.75 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06861261360463959		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06861261360463959 | validation: 0.04857919365526876]
	TIME [epoch: 6.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067190654354572		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.067190654354572 | validation: 0.04759656663283745]
	TIME [epoch: 6.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892167088921168		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08892167088921168 | validation: 0.06681719538202405]
	TIME [epoch: 6.74 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08614450394170393		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.08614450394170393 | validation: 0.04759426718041232]
	TIME [epoch: 6.78 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724794162305451		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.07724794162305451 | validation: 0.054732097009724506]
	TIME [epoch: 6.76 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07496538739441122		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07496538739441122 | validation: 0.0484959238683135]
	TIME [epoch: 6.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07157505311247025		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07157505311247025 | validation: 0.058561960081692795]
	TIME [epoch: 6.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331891867459839		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.06331891867459839 | validation: 0.04874915921720028]
	TIME [epoch: 6.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06838783070755526		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.06838783070755526 | validation: 0.059758228244818204]
	TIME [epoch: 6.74 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909802351175081		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07909802351175081 | validation: 0.05100211967024028]
	TIME [epoch: 6.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06503249077618894		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.06503249077618894 | validation: 0.04258481295866952]
	TIME [epoch: 6.78 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07959893123632951		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07959893123632951 | validation: 0.05233561780812243]
	TIME [epoch: 6.75 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08271564759320828		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.08271564759320828 | validation: 0.063738017558421]
	TIME [epoch: 6.74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08411228535381518		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.08411228535381518 | validation: 0.059861268675254396]
	TIME [epoch: 6.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07457111476891853		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.07457111476891853 | validation: 0.046690275683718536]
	TIME [epoch: 6.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05684391186354256		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.05684391186354256 | validation: 0.05468988371245925]
	TIME [epoch: 6.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061613672687653824		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.061613672687653824 | validation: 0.05091595068403268]
	TIME [epoch: 6.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640648065500697		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0640648065500697 | validation: 0.061755906544443684]
	TIME [epoch: 6.79 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604088975167802		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.08604088975167802 | validation: 0.07981247592856021]
	TIME [epoch: 6.75 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816171174956739		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0816171174956739 | validation: 0.07625564373581253]
	TIME [epoch: 6.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08187200483650829		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08187200483650829 | validation: 0.08235051770502508]
	TIME [epoch: 6.75 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569952966500344		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.08569952966500344 | validation: 0.0686815501257684]
	TIME [epoch: 6.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08088160920394236		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.08088160920394236 | validation: 0.07398656241911193]
	TIME [epoch: 6.74 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07356304345096741		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.07356304345096741 | validation: 0.05682350546778808]
	TIME [epoch: 6.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05930263274283622		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.05930263274283622 | validation: 0.06047259694646457]
	TIME [epoch: 6.78 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631074567845786		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0631074567845786 | validation: 0.06393713322937154]
	TIME [epoch: 6.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646792661633735		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.06646792661633735 | validation: 0.05732724276705186]
	TIME [epoch: 6.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229672004030743		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.07229672004030743 | validation: 0.09476222669678008]
	TIME [epoch: 6.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09557439829231348		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.09557439829231348 | validation: 0.06555559092636348]
	TIME [epoch: 6.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06776738744965953		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.06776738744965953 | validation: 0.04843939927235215]
	TIME [epoch: 6.74 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873549476854664		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05873549476854664 | validation: 0.045852290925011745]
	TIME [epoch: 6.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062282399851952136		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.062282399851952136 | validation: 0.05154131893115946]
	TIME [epoch: 6.78 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640802728304776		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.06640802728304776 | validation: 0.06338760093472406]
	TIME [epoch: 6.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05853555896879758		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.05853555896879758 | validation: 0.054112678036043485]
	TIME [epoch: 6.75 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05878176460009644		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.05878176460009644 | validation: 0.05148422179047671]
	TIME [epoch: 6.74 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331820507799256		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.06331820507799256 | validation: 0.054077361374914666]
	TIME [epoch: 6.74 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011857488355183		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.06011857488355183 | validation: 0.061344716140733446]
	TIME [epoch: 6.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263342282194997		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.06263342282194997 | validation: 0.06201054066119226]
	TIME [epoch: 6.78 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0690819985603275		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0690819985603275 | validation: 0.04914042193417989]
	TIME [epoch: 6.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05992557292744134		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.05992557292744134 | validation: 0.060816021607636966]
	TIME [epoch: 6.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572669094656435		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.06572669094656435 | validation: 0.05630205391357308]
	TIME [epoch: 6.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055621779990659086		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.055621779990659086 | validation: 0.06015864447087855]
	TIME [epoch: 6.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850677795430241		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.05850677795430241 | validation: 0.05939660684083785]
	TIME [epoch: 6.74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06445645085330308		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06445645085330308 | validation: 0.059605925617892824]
	TIME [epoch: 6.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711826403218195		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.06711826403218195 | validation: 0.04530442771652556]
	TIME [epoch: 6.78 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06004673985409469		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.06004673985409469 | validation: 0.0515794657616906]
	TIME [epoch: 6.75 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012296497043072		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.06012296497043072 | validation: 0.054291273262043034]
	TIME [epoch: 6.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06238365156353789		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.06238365156353789 | validation: 0.06227664137749589]
	TIME [epoch: 6.73 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611185353072425		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.06611185353072425 | validation: 0.05466835848055783]
	TIME [epoch: 6.73 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617039887591281		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0617039887591281 | validation: 0.05741500441432686]
	TIME [epoch: 6.73 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323367141952103		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.06323367141952103 | validation: 0.05936306327538435]
	TIME [epoch: 6.73 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558166538410576		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.06558166538410576 | validation: 0.05201427453027106]
	TIME [epoch: 6.78 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059580127795935606		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.059580127795935606 | validation: 0.04796480351796723]
	TIME [epoch: 6.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641694864547626		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06641694864547626 | validation: 0.06188411472016242]
	TIME [epoch: 6.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0682615272919008		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0682615272919008 | validation: 0.06069577467787196]
	TIME [epoch: 6.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690954503214742		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.07690954503214742 | validation: 0.05349718780608544]
	TIME [epoch: 6.73 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117328530621528		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.07117328530621528 | validation: 0.054819932048430386]
	TIME [epoch: 6.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07608391763872445		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.07608391763872445 | validation: 0.06847068117038588]
	TIME [epoch: 6.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599541526552186		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.09599541526552186 | validation: 0.06199037053746652]
	TIME [epoch: 6.78 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920052169241105		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07920052169241105 | validation: 0.05815875911126465]
	TIME [epoch: 6.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07249009469856472		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.07249009469856472 | validation: 0.047289525958452656]
	TIME [epoch: 6.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644870837638102		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0644870837638102 | validation: 0.056479266430284156]
	TIME [epoch: 6.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029508201711601		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.06029508201711601 | validation: 0.046225488820852006]
	TIME [epoch: 6.74 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468823247204915		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.06468823247204915 | validation: 0.05417515481757032]
	TIME [epoch: 6.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967461537039545		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.07967461537039545 | validation: 0.0669830894316091]
	TIME [epoch: 6.75 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08083578116440171		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08083578116440171 | validation: 0.0513381293370305]
	TIME [epoch: 6.77 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07387942638008164		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07387942638008164 | validation: 0.039214863784144925]
	TIME [epoch: 6.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06533967185541847		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.06533967185541847 | validation: 0.056191655380194765]
	TIME [epoch: 6.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652401740274291		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.06652401740274291 | validation: 0.05281087359527392]
	TIME [epoch: 6.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421030714422578		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.06421030714422578 | validation: 0.058253748080456344]
	TIME [epoch: 6.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293213474964085		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.06293213474964085 | validation: 0.055018438590629465]
	TIME [epoch: 6.74 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412917349053679		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.06412917349053679 | validation: 0.06301434555049196]
	TIME [epoch: 6.77 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566067220190969		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.06566067220190969 | validation: 0.06888516768371383]
	TIME [epoch: 6.77 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675363051048113		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07675363051048113 | validation: 0.07501529568052998]
	TIME [epoch: 6.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07568870806116458		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07568870806116458 | validation: 0.06424411313792211]
	TIME [epoch: 6.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463683415093126		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.06463683415093126 | validation: 0.056773320214426076]
	TIME [epoch: 6.74 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745105773539468		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.05745105773539468 | validation: 0.053775098242190233]
	TIME [epoch: 6.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268241534388415		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.06268241534388415 | validation: 0.056159233151782145]
	TIME [epoch: 6.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749691208105892		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.06749691208105892 | validation: 0.044641139073677547]
	TIME [epoch: 6.78 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06065324484884671		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.06065324484884671 | validation: 0.054130522614279385]
	TIME [epoch: 6.75 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05814624087304515		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.05814624087304515 | validation: 0.05147235252340736]
	TIME [epoch: 6.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059046243837879236		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.059046243837879236 | validation: 0.0646723419393555]
	TIME [epoch: 6.73 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479897977258382		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.06479897977258382 | validation: 0.06098948110597246]
	TIME [epoch: 6.74 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065317389529552		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.065317389529552 | validation: 0.050097240107688394]
	TIME [epoch: 6.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057563980441743844		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.057563980441743844 | validation: 0.05759281517066851]
	TIME [epoch: 6.73 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340917988674565		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.08340917988674565 | validation: 0.0826217788564412]
	TIME [epoch: 6.78 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09759468266142754		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.09759468266142754 | validation: 0.1075126944276566]
	TIME [epoch: 6.75 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471572625641284		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.10471572625641284 | validation: 0.09200688491042974]
	TIME [epoch: 6.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621120051825129		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.08621120051825129 | validation: 0.08266160313810705]
	TIME [epoch: 6.73 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018111226352767		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.08018111226352767 | validation: 0.06240901576465324]
	TIME [epoch: 6.73 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502237353464875		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.06502237353464875 | validation: 0.05710313669050805]
	TIME [epoch: 6.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637254527725009		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.0637254527725009 | validation: 0.06689704102128788]
	TIME [epoch: 6.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297305587376791		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07297305587376791 | validation: 0.07698433687552686]
	TIME [epoch: 6.79 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703223120256739		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.09703223120256739 | validation: 0.09865406315593633]
	TIME [epoch: 6.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033849066038422		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.1033849066038422 | validation: 0.09691483184957328]
	TIME [epoch: 6.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059281001566942		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08059281001566942 | validation: 0.062366806402400915]
	TIME [epoch: 6.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022051449662317		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.07022051449662317 | validation: 0.06542942405006537]
	TIME [epoch: 6.74 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150703082644974		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.07150703082644974 | validation: 0.08104362400419651]
	TIME [epoch: 6.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911009669432731		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.07911009669432731 | validation: 0.07569108778693692]
	TIME [epoch: 6.76 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835586480900081		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.07835586480900081 | validation: 0.08207099302584507]
	TIME [epoch: 6.77 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07586212482252602		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.07586212482252602 | validation: 0.07310481961659543]
	TIME [epoch: 6.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704932010514433		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.06704932010514433 | validation: 0.05833803620986692]
	TIME [epoch: 6.74 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059698895825315706		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.059698895825315706 | validation: 0.05109584445040646]
	TIME [epoch: 6.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061717313353153294		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.061717313353153294 | validation: 0.059046506873164144]
	TIME [epoch: 6.74 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05777127791210007		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.05777127791210007 | validation: 0.0559539411722471]
	TIME [epoch: 6.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150830578101349		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.06150830578101349 | validation: 0.05733822604348603]
	TIME [epoch: 6.77 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719919539307638		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.0719919539307638 | validation: 0.05554232938801644]
	TIME [epoch: 6.78 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663455651554536		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0663455651554536 | validation: 0.06073438259282566]
	TIME [epoch: 6.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071247515288548		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.06071247515288548 | validation: 0.0516092175371026]
	TIME [epoch: 6.74 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05630627063986095		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.05630627063986095 | validation: 0.04630200486006196]
	TIME [epoch: 6.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05859901592149599		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.05859901592149599 | validation: 0.060568400406265675]
	TIME [epoch: 6.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043067538930967		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06043067538930967 | validation: 0.05790292581110841]
	TIME [epoch: 6.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06393539996109666		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.06393539996109666 | validation: 0.07397984313768816]
	TIME [epoch: 6.78 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0660993986817837		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0660993986817837 | validation: 0.046602683480934604]
	TIME [epoch: 6.76 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058555043606661805		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.058555043606661805 | validation: 0.04533104412554599]
	TIME [epoch: 6.74 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836153733055312		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.05836153733055312 | validation: 0.05803747622181232]
	TIME [epoch: 6.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0593730896999615		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0593730896999615 | validation: 0.052592233231061464]
	TIME [epoch: 6.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634249151256377		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0634249151256377 | validation: 0.06097842090340724]
	TIME [epoch: 6.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06102705021281922		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.06102705021281922 | validation: 0.05945867076402707]
	TIME [epoch: 6.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307191754320131		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06307191754320131 | validation: 0.048555319309438454]
	TIME [epoch: 6.78 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882991486955998		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.05882991486955998 | validation: 0.0516713285886838]
	TIME [epoch: 6.76 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059718779066634906		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.059718779066634906 | validation: 0.05372366505183074]
	TIME [epoch: 6.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053775032761320965		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.053775032761320965 | validation: 0.05857108182430977]
	TIME [epoch: 6.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056409919646489504		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.056409919646489504 | validation: 0.056687876259839225]
	TIME [epoch: 6.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353481271465068		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06353481271465068 | validation: 0.05601407574153654]
	TIME [epoch: 6.75 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05586818599258815		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.05586818599258815 | validation: 0.04722128188107651]
	TIME [epoch: 6.75 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243993418917457		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.06243993418917457 | validation: 0.05353032144448404]
	TIME [epoch: 6.78 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060779423784555385		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.060779423784555385 | validation: 0.05979971121475036]
	TIME [epoch: 6.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990293393106245		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.05990293393106245 | validation: 0.0628936570231828]
	TIME [epoch: 6.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06074998910134384		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.06074998910134384 | validation: 0.05535432010677194]
	TIME [epoch: 6.74 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950225783369058		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.05950225783369058 | validation: 0.04808337813849415]
	TIME [epoch: 6.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059782175419529196		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.059782175419529196 | validation: 0.047458264861385956]
	TIME [epoch: 6.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688753905506313		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07688753905506313 | validation: 0.05003728695211371]
	TIME [epoch: 6.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07009654404988956		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.07009654404988956 | validation: 0.05270889334476965]
	TIME [epoch: 6.78 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06535260043862322		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.06535260043862322 | validation: 0.062213510033000824]
	TIME [epoch: 6.74 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574642113530133		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0574642113530133 | validation: 0.055912036820904606]
	TIME [epoch: 6.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06121360855009278		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.06121360855009278 | validation: 0.05947208900789834]
	TIME [epoch: 6.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501755446755049		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.06501755446755049 | validation: 0.04401906851132975]
	TIME [epoch: 6.74 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652720756247243		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.07652720756247243 | validation: 0.061187514671708076]
	TIME [epoch: 6.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07974281878086026		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07974281878086026 | validation: 0.05815547579993135]
	TIME [epoch: 6.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07084512115174729		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.07084512115174729 | validation: 0.0550196218547178]
	TIME [epoch: 6.78 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575546823356661		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.06575546823356661 | validation: 0.053848074077088526]
	TIME [epoch: 6.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06624844197281594		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.06624844197281594 | validation: 0.058589410588825476]
	TIME [epoch: 6.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671188785649045		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06671188785649045 | validation: 0.054223930736174056]
	TIME [epoch: 6.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768791665440202		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.06768791665440202 | validation: 0.056776769676125244]
	TIME [epoch: 6.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344383783924369		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.06344383783924369 | validation: 0.04445071649015868]
	TIME [epoch: 6.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06182604449469792		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06182604449469792 | validation: 0.04904474600093943]
	TIME [epoch: 6.77 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645667019852012		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.0645667019852012 | validation: 0.053888793541973325]
	TIME [epoch: 6.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07046865564446941		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.07046865564446941 | validation: 0.05049099952986749]
	TIME [epoch: 6.74 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367531965980706		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06367531965980706 | validation: 0.060017162284996935]
	TIME [epoch: 6.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058454709234070784		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.058454709234070784 | validation: 0.05650450683544854]
	TIME [epoch: 6.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135347758354194		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.06135347758354194 | validation: 0.06129337102548811]
	TIME [epoch: 6.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997530182732278		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06997530182732278 | validation: 0.05966182404654252]
	TIME [epoch: 6.74 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675174016610825		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0675174016610825 | validation: 0.06942279326938387]
	TIME [epoch: 6.79 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07353494410068563		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.07353494410068563 | validation: 0.07626312937631867]
	TIME [epoch: 6.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663568911051115		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0663568911051115 | validation: 0.058338698149607085]
	TIME [epoch: 6.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530452740390368		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.05530452740390368 | validation: 0.05380223421383809]
	TIME [epoch: 6.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880437815662583		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.05880437815662583 | validation: 0.049568382234005066]
	TIME [epoch: 6.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057239688631923163		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.057239688631923163 | validation: 0.05755045461603901]
	TIME [epoch: 6.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008120886307212		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.07008120886307212 | validation: 0.05437111860630913]
	TIME [epoch: 6.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06580288185432603		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06580288185432603 | validation: 0.061205811393362564]
	TIME [epoch: 6.79 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06178263740846851		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06178263740846851 | validation: 0.046952577865845446]
	TIME [epoch: 6.76 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476465410556934		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.05476465410556934 | validation: 0.04624487551869716]
	TIME [epoch: 6.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308253964730326		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06308253964730326 | validation: 0.05155944071942967]
	TIME [epoch: 6.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286068989224153		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.06286068989224153 | validation: 0.04963660168979521]
	TIME [epoch: 6.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407090559347409		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06407090559347409 | validation: 0.061426206775222154]
	TIME [epoch: 6.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0678942832586387		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.0678942832586387 | validation: 0.04935625900887011]
	TIME [epoch: 6.75 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07088091640070303		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.07088091640070303 | validation: 0.04830746787708454]
	TIME [epoch: 6.78 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071904437228501		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.06071904437228501 | validation: 0.055936364039184214]
	TIME [epoch: 6.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06194383663364825		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.06194383663364825 | validation: 0.0568220913586316]
	TIME [epoch: 6.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318624417014565		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.06318624417014565 | validation: 0.04913538609607593]
	TIME [epoch: 6.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757618437318884		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.06757618437318884 | validation: 0.058154819638124675]
	TIME [epoch: 6.73 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086739084215755		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.07086739084215755 | validation: 0.05059980777717748]
	TIME [epoch: 6.73 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262208503951232		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.06262208503951232 | validation: 0.05632924203749223]
	TIME [epoch: 6.75 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059308013356409964		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.059308013356409964 | validation: 0.05735365732413861]
	TIME [epoch: 6.76 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06570286407054748		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.06570286407054748 | validation: 0.05383476742850183]
	TIME [epoch: 6.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920904561392545		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.06920904561392545 | validation: 0.0646708892915692]
	TIME [epoch: 6.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341170083749143		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.07341170083749143 | validation: 0.04939499660011901]
	TIME [epoch: 6.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412494836978205		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06412494836978205 | validation: 0.04588482838620843]
	TIME [epoch: 6.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06001749313546813		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06001749313546813 | validation: 0.05308993527262812]
	TIME [epoch: 6.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656974947832385		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0656974947832385 | validation: 0.05027186970481985]
	TIME [epoch: 6.75 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06866272357898559		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06866272357898559 | validation: 0.05738234276185127]
	TIME [epoch: 6.76 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06495501258876275		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06495501258876275 | validation: 0.05456967947374187]
	TIME [epoch: 6.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678369154185773		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.07678369154185773 | validation: 0.05978109290201477]
	TIME [epoch: 6.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445196933062688		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.07445196933062688 | validation: 0.052881705848203196]
	TIME [epoch: 6.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726099174616774		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.0726099174616774 | validation: 0.051985949894575764]
	TIME [epoch: 6.73 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455478522809403		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.07455478522809403 | validation: 0.0577350024179967]
	TIME [epoch: 6.73 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441493967974389		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.07441493967974389 | validation: 0.046345278989996005]
	TIME [epoch: 6.77 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819337680918225		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.06819337680918225 | validation: 0.05022699982044808]
	TIME [epoch: 6.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06070470109581569		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.06070470109581569 | validation: 0.05132010952922848]
	TIME [epoch: 6.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06219218927604117		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06219218927604117 | validation: 0.056718333326665794]
	TIME [epoch: 6.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743161845413559		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.05743161845413559 | validation: 0.04909800383482034]
	TIME [epoch: 6.73 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05955296447390714		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.05955296447390714 | validation: 0.06265550457963925]
	TIME [epoch: 6.73 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054559388590480706		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.054559388590480706 | validation: 0.0490836488042217]
	TIME [epoch: 6.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053440870866721994		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.053440870866721994 | validation: 0.05042723738066236]
	TIME [epoch: 6.77 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05693372456765308		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.05693372456765308 | validation: 0.05367784748383131]
	TIME [epoch: 6.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557961084920744		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.05557961084920744 | validation: 0.04269915762448001]
	TIME [epoch: 6.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116385410402716		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.06116385410402716 | validation: 0.05511166252726729]
	TIME [epoch: 6.73 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06041102505644727		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.06041102505644727 | validation: 0.05506170148174471]
	TIME [epoch: 6.73 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06491894772999593		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.06491894772999593 | validation: 0.060443568130594386]
	TIME [epoch: 6.73 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060072357489307344		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.060072357489307344 | validation: 0.05411638365519081]
	TIME [epoch: 6.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060125617086961805		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.060125617086961805 | validation: 0.04896213388236491]
	TIME [epoch: 6.77 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056985298118701226		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.056985298118701226 | validation: 0.0430909039837703]
	TIME [epoch: 6.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05838096247410808		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.05838096247410808 | validation: 0.050777524999926237]
	TIME [epoch: 6.73 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058164554878955665		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.058164554878955665 | validation: 0.05279378757347816]
	TIME [epoch: 6.73 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745954016602842		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.05745954016602842 | validation: 0.05986226017130725]
	TIME [epoch: 6.73 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05849120116244794		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.05849120116244794 | validation: 0.05831037274149754]
	TIME [epoch: 6.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059514194856029025		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.059514194856029025 | validation: 0.0504922030521856]
	TIME [epoch: 6.73 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05965034127511369		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.05965034127511369 | validation: 0.0583334612815143]
	TIME [epoch: 6.77 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06252634834253819		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.06252634834253819 | validation: 0.05235830106520464]
	TIME [epoch: 6.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056415457261526816		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.056415457261526816 | validation: 0.05040791857767124]
	TIME [epoch: 6.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055708372664063435		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.055708372664063435 | validation: 0.04944796287176882]
	TIME [epoch: 6.73 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055909308693595644		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.055909308693595644 | validation: 0.05672757946360604]
	TIME [epoch: 6.74 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528685308235349		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05528685308235349 | validation: 0.05764133231838911]
	TIME [epoch: 6.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06060661798255012		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.06060661798255012 | validation: 0.04902925166055021]
	TIME [epoch: 6.75 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068039108044691		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06068039108044691 | validation: 0.04551743616128093]
	TIME [epoch: 6.76 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05502990690958197		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.05502990690958197 | validation: 0.057895862409677895]
	TIME [epoch: 6.73 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078225582165878		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.06078225582165878 | validation: 0.058398880131364565]
	TIME [epoch: 6.73 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06036365766267607		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.06036365766267607 | validation: 0.0612933197790724]
	TIME [epoch: 6.73 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129176587171428		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.06129176587171428 | validation: 0.043921033375177124]
	TIME [epoch: 6.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060639766907732776		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.060639766907732776 | validation: 0.0549636393151262]
	TIME [epoch: 6.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05737567078348034		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.05737567078348034 | validation: 0.05228325160961905]
	TIME [epoch: 6.77 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0674498839585004		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.0674498839585004 | validation: 0.05997167841842549]
	TIME [epoch: 6.75 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06713432129493287		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06713432129493287 | validation: 0.06567423192059296]
	TIME [epoch: 6.73 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306843742401705		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06306843742401705 | validation: 0.05678119996500741]
	TIME [epoch: 6.73 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07236169840112706		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.07236169840112706 | validation: 0.07462495145389247]
	TIME [epoch: 6.73 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08405849818004044		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.08405849818004044 | validation: 0.0852018583554967]
	TIME [epoch: 6.73 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762662771517888		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.09762662771517888 | validation: 0.07873162659531252]
	TIME [epoch: 6.73 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776324263364463		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.08776324263364463 | validation: 0.07114141267757665]
	TIME [epoch: 6.77 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06948666965795765		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.06948666965795765 | validation: 0.05621790593574567]
	TIME [epoch: 6.75 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444981292252645		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.06444981292252645 | validation: 0.062012618870305444]
	TIME [epoch: 6.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07010040973940486		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.07010040973940486 | validation: 0.06098364452462647]
	TIME [epoch: 6.74 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584287136276584		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06584287136276584 | validation: 0.0663460486713292]
	TIME [epoch: 6.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316542016170038		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.06316542016170038 | validation: 0.05569897722984097]
	TIME [epoch: 6.73 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060669756255837426		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.060669756255837426 | validation: 0.052381022661281154]
	TIME [epoch: 6.73 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891010563479298		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.05891010563479298 | validation: 0.04507843505414141]
	TIME [epoch: 6.77 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05547019155173281		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.05547019155173281 | validation: 0.05500578523149714]
	TIME [epoch: 6.74 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157828661860536		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06157828661860536 | validation: 0.0661872188549167]
	TIME [epoch: 6.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0730530260725061		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0730530260725061 | validation: 0.07279445383766993]
	TIME [epoch: 6.73 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804782856985226		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0804782856985226 | validation: 0.07926962692078468]
	TIME [epoch: 6.73 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07844745418356007		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.07844745418356007 | validation: 0.07582793620721867]
	TIME [epoch: 6.73 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349838726572924		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.07349838726572924 | validation: 0.06812323623356664]
	TIME [epoch: 6.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07424678349366012		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.07424678349366012 | validation: 0.06338383018455704]
	TIME [epoch: 6.77 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349415528723609		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.07349415528723609 | validation: 0.07121161700608208]
	TIME [epoch: 6.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06940458959304166		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.06940458959304166 | validation: 0.06327291279405022]
	TIME [epoch: 6.73 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585447237165315		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.06585447237165315 | validation: 0.06310186368842033]
	TIME [epoch: 6.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662110701713646		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06662110701713646 | validation: 0.051891835607097744]
	TIME [epoch: 6.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0643226930580889		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.0643226930580889 | validation: 0.07010196176251043]
	TIME [epoch: 6.73 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725736564471471		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.06725736564471471 | validation: 0.05822632155905233]
	TIME [epoch: 6.75 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890436544675485		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.06890436544675485 | validation: 0.061173809602260314]
	TIME [epoch: 6.76 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05962830385080514		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05962830385080514 | validation: 0.05526990040122684]
	TIME [epoch: 6.73 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060867896012187284		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.060867896012187284 | validation: 0.06509436797235903]
	TIME [epoch: 6.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05703211582256935		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.05703211582256935 | validation: 0.04501030284483175]
	TIME [epoch: 6.73 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324506827483833		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.06324506827483833 | validation: 0.059609930345469936]
	TIME [epoch: 6.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790264210256846		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.05790264210256846 | validation: 0.04701262419947822]
	TIME [epoch: 6.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059755397780213694		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.059755397780213694 | validation: 0.05815462050887512]
	TIME [epoch: 6.75 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06091888427123862		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06091888427123862 | validation: 0.04982228058657087]
	TIME [epoch: 6.76 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914478408576525		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.05914478408576525 | validation: 0.06045659386857769]
	TIME [epoch: 6.74 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658667576092173		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.05658667576092173 | validation: 0.060316672282225224]
	TIME [epoch: 6.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05849866684199895		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.05849866684199895 | validation: 0.04600222349907797]
	TIME [epoch: 6.73 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058880276083670226		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.058880276083670226 | validation: 0.04928180957493959]
	TIME [epoch: 6.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058270677290972635		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.058270677290972635 | validation: 0.05048967103909812]
	TIME [epoch: 6.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045443812484022		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06045443812484022 | validation: 0.0522523841856713]
	TIME [epoch: 6.77 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570135892385838		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05570135892385838 | validation: 0.04592792592982292]
	TIME [epoch: 6.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991444206777255		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.05991444206777255 | validation: 0.05131873269186705]
	TIME [epoch: 6.73 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854855549803878		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.05854855549803878 | validation: 0.04545899325681436]
	TIME [epoch: 6.73 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06296122829190383		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06296122829190383 | validation: 0.04956550456616095]
	TIME [epoch: 6.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06497941897786813		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.06497941897786813 | validation: 0.04472129117412792]
	TIME [epoch: 6.73 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201165835777146		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.06201165835777146 | validation: 0.051473792610293834]
	TIME [epoch: 6.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059857307425223		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.059857307425223 | validation: 0.0467119793866633]
	TIME [epoch: 6.78 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05615096106091512		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.05615096106091512 | validation: 0.04901687867614303]
	TIME [epoch: 6.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506722204022439		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06506722204022439 | validation: 0.05961197193340086]
	TIME [epoch: 6.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06989692339788449		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06989692339788449 | validation: 0.05341950928161347]
	TIME [epoch: 6.73 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07223131231969514		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.07223131231969514 | validation: 0.06075294537834376]
	TIME [epoch: 6.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317121124565977		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.08317121124565977 | validation: 0.06262846716263012]
	TIME [epoch: 6.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838371410692664		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.0838371410692664 | validation: 0.05988481077311492]
	TIME [epoch: 6.73 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099089883198273		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.07099089883198273 | validation: 0.05907136916634803]
	TIME [epoch: 6.77 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843756438256294		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.07843756438256294 | validation: 0.05791447229914713]
	TIME [epoch: 6.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07255264087665085		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.07255264087665085 | validation: 0.06786002737103972]
	TIME [epoch: 6.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127221780922167		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08127221780922167 | validation: 0.05612041536133655]
	TIME [epoch: 6.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07084298764420288		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.07084298764420288 | validation: 0.05156193468593144]
	TIME [epoch: 6.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06656162577223232		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.06656162577223232 | validation: 0.051890304255492535]
	TIME [epoch: 6.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865818525170521		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.06865818525170521 | validation: 0.05276469535045848]
	TIME [epoch: 6.74 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925422526123844		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.06925422526123844 | validation: 0.04942190591220975]
	TIME [epoch: 6.77 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07893491362866085		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.07893491362866085 | validation: 0.05797275716419374]
	TIME [epoch: 6.74 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399011403903079		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.07399011403903079 | validation: 0.05896580682656599]
	TIME [epoch: 6.74 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0685845022072652		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.0685845022072652 | validation: 0.05725110881737322]
	TIME [epoch: 6.73 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05862193172549755		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05862193172549755 | validation: 0.048581068288299015]
	TIME [epoch: 6.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05970563323031851		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.05970563323031851 | validation: 0.04289434694081448]
	TIME [epoch: 6.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399631200438298		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.06399631200438298 | validation: 0.05313093230962475]
	TIME [epoch: 6.75 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102607508949522		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.07102607508949522 | validation: 0.051669403843387196]
	TIME [epoch: 6.77 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06488600851126128		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.06488600851126128 | validation: 0.04986860535834985]
	TIME [epoch: 6.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06163096440364214		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06163096440364214 | validation: 0.03378260917283635]
	TIME [epoch: 6.73 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_1360.pth
	Model improved!!!
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518105526180752		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.05518105526180752 | validation: 0.05214293222939907]
	TIME [epoch: 6.74 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057449542309289586		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.057449542309289586 | validation: 0.059558505562838614]
	TIME [epoch: 6.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05736133162057374		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.05736133162057374 | validation: 0.05419966835169127]
	TIME [epoch: 6.73 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272498855701521		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.06272498855701521 | validation: 0.048854614582532284]
	TIME [epoch: 6.77 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903307582322027		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.05903307582322027 | validation: 0.04851642025388813]
	TIME [epoch: 6.74 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053760597429976735		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.053760597429976735 | validation: 0.054619162922581024]
	TIME [epoch: 6.73 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366210938574517		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.06366210938574517 | validation: 0.05559808408365005]
	TIME [epoch: 6.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093978072499219		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.06093978072499219 | validation: 0.049149440849164144]
	TIME [epoch: 6.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290513697480195		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.06290513697480195 | validation: 0.04143844280606375]
	TIME [epoch: 6.73 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565806096225212		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.05565806096225212 | validation: 0.04806754059878318]
	TIME [epoch: 6.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05688056834753685		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.05688056834753685 | validation: 0.04748736376810758]
	TIME [epoch: 6.78 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05500677524814718		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.05500677524814718 | validation: 0.03982847206311711]
	TIME [epoch: 6.74 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06014283851674415		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.06014283851674415 | validation: 0.05422333480016085]
	TIME [epoch: 6.73 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939075077942357		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.05939075077942357 | validation: 0.05056099818770614]
	TIME [epoch: 6.73 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05945452448004265		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.05945452448004265 | validation: 0.05369945816737233]
	TIME [epoch: 6.73 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592934647381949		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.05592934647381949 | validation: 0.06155795530412313]
	TIME [epoch: 6.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05986624186614691		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.05986624186614691 | validation: 0.050883256598752084]
	TIME [epoch: 6.73 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891693634385199		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.05891693634385199 | validation: 0.054043711557503496]
	TIME [epoch: 6.77 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054279386853688		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.06054279386853688 | validation: 0.05050062663694756]
	TIME [epoch: 6.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057606444938267005		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.057606444938267005 | validation: 0.05277664595385076]
	TIME [epoch: 6.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608956067043895		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.0608956067043895 | validation: 0.06339521840149238]
	TIME [epoch: 6.73 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056653553643927136		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.056653553643927136 | validation: 0.055222312398443295]
	TIME [epoch: 6.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396418773084134		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05396418773084134 | validation: 0.05353557944814059]
	TIME [epoch: 6.73 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05479588750525538		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.05479588750525538 | validation: 0.04867255935529202]
	TIME [epoch: 6.74 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053622491416421746		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.053622491416421746 | validation: 0.06049849851532541]
	TIME [epoch: 6.77 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056614484399535765		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.056614484399535765 | validation: 0.04237873250872583]
	TIME [epoch: 6.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05572489787392739		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05572489787392739 | validation: 0.04702690121759799]
	TIME [epoch: 6.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056245872641475084		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.056245872641475084 | validation: 0.04358392943916486]
	TIME [epoch: 6.73 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057688267397340114		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.057688267397340114 | validation: 0.04782623441134243]
	TIME [epoch: 6.73 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614224309588082		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.06614224309588082 | validation: 0.04372435178679546]
	TIME [epoch: 6.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642696706359963		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.0642696706359963 | validation: 0.057823513684929925]
	TIME [epoch: 6.75 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056961946048132255		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.056961946048132255 | validation: 0.04846315023872971]
	TIME [epoch: 6.76 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05575910262927533		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.05575910262927533 | validation: 0.0512491182176743]
	TIME [epoch: 6.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056974655693501214		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.056974655693501214 | validation: 0.050411430901087316]
	TIME [epoch: 6.73 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123993636061951		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06123993636061951 | validation: 0.04949387913694097]
	TIME [epoch: 6.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060091146722031544		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.060091146722031544 | validation: 0.060026172356178104]
	TIME [epoch: 6.73 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612865505585058		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0612865505585058 | validation: 0.04256822500745156]
	TIME [epoch: 6.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05408069233463929		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.05408069233463929 | validation: 0.055977616094382454]
	TIME [epoch: 6.76 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06134225890596213		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.06134225890596213 | validation: 0.05495840247165124]
	TIME [epoch: 6.75 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604506355069543		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.0604506355069543 | validation: 0.056039942058819056]
	TIME [epoch: 6.74 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542037510264104		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06542037510264104 | validation: 0.05045720214973429]
	TIME [epoch: 6.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06200804688426828		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.06200804688426828 | validation: 0.048984138566942996]
	TIME [epoch: 6.73 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784349688019432		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.05784349688019432 | validation: 0.047005564284590386]
	TIME [epoch: 6.73 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520832125986016		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.05520832125986016 | validation: 0.03955589172281532]
	TIME [epoch: 6.73 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661930597275391		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.05661930597275391 | validation: 0.04503971870752082]
	TIME [epoch: 6.77 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725881276525252		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.05725881276525252 | validation: 0.03939470605995515]
	TIME [epoch: 6.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056595850830570504		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.056595850830570504 | validation: 0.049342915083040555]
	TIME [epoch: 6.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05593342034595375		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05593342034595375 | validation: 0.04779080755840056]
	TIME [epoch: 6.72 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057781487415113464		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.057781487415113464 | validation: 0.055174960142697994]
	TIME [epoch: 6.73 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06062023326232967		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.06062023326232967 | validation: 0.060273122209462585]
	TIME [epoch: 6.72 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05667410782620926		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.05667410782620926 | validation: 0.06109801246068353]
	TIME [epoch: 6.72 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093664577350021		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.06093664577350021 | validation: 0.060156799728068755]
	TIME [epoch: 6.77 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05555240421753062		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.05555240421753062 | validation: 0.061472758634585734]
	TIME [epoch: 6.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974928575203641		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.05974928575203641 | validation: 0.05238115120014172]
	TIME [epoch: 6.72 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639022456886346		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.05639022456886346 | validation: 0.046232168002471374]
	TIME [epoch: 6.73 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733032601398849		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.05733032601398849 | validation: 0.04259077640601797]
	TIME [epoch: 6.72 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05488841171813863		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.05488841171813863 | validation: 0.04768499714514516]
	TIME [epoch: 6.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928180158044588		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.05928180158044588 | validation: 0.0465406727932926]
	TIME [epoch: 6.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918952352586117		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.05918952352586117 | validation: 0.04500515176220618]
	TIME [epoch: 6.77 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05885486345343497		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.05885486345343497 | validation: 0.05130935590156894]
	TIME [epoch: 6.73 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055680380506395497		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.055680380506395497 | validation: 0.05531790932658743]
	TIME [epoch: 6.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265771241892007		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06265771241892007 | validation: 0.050398422719300354]
	TIME [epoch: 6.73 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05472243746847491		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.05472243746847491 | validation: 0.043579785493413195]
	TIME [epoch: 6.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0567179880660149		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0567179880660149 | validation: 0.04063956058199075]
	TIME [epoch: 6.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664142577374526		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.05664142577374526 | validation: 0.055049118891437904]
	TIME [epoch: 6.73 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0603282326372464		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.0603282326372464 | validation: 0.046455081068230805]
	TIME [epoch: 6.77 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054448324609628895		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.054448324609628895 | validation: 0.053256853374863244]
	TIME [epoch: 6.73 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061046421456468436		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.061046421456468436 | validation: 0.04675579517853409]
	TIME [epoch: 6.72 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06041440065417185		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06041440065417185 | validation: 0.05718381053525616]
	TIME [epoch: 6.73 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054182169670395255		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.054182169670395255 | validation: 0.048155236156980134]
	TIME [epoch: 6.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055203263716195695		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.055203263716195695 | validation: 0.02956729361299367]
	TIME [epoch: 6.73 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134646/states/model_phi2_1a_v1_1431.pth
	Model improved!!!
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05367440306670537		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.05367440306670537 | validation: 0.05302300964227337]
	TIME [epoch: 6.75 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05380216598153372		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.05380216598153372 | validation: 0.05669791874195876]
	TIME [epoch: 6.75 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056652140915280556		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.056652140915280556 | validation: 0.04684775989551771]
	TIME [epoch: 6.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056768223434985075		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.056768223434985075 | validation: 0.05140791446769835]
	TIME [epoch: 6.72 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059353519055521095		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.059353519055521095 | validation: 0.054579144810900045]
	TIME [epoch: 6.72 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484699056764597		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06484699056764597 | validation: 0.05906427094731539]
	TIME [epoch: 6.72 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835500197069207		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.05835500197069207 | validation: 0.0490325423758239]
	TIME [epoch: 6.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636988018357915		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.05636988018357915 | validation: 0.04793390031242445]
	TIME [epoch: 6.76 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05811529749028644		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.05811529749028644 | validation: 0.04003713026293075]
	TIME [epoch: 6.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340853713583276		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.06340853713583276 | validation: 0.04199296653899241]
	TIME [epoch: 6.73 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06236309310392387		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.06236309310392387 | validation: 0.04740405835595207]
	TIME [epoch: 6.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998676330595201		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.05998676330595201 | validation: 0.04792938265722385]
	TIME [epoch: 6.73 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330589611093436		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.06330589611093436 | validation: 0.05245039370897327]
	TIME [epoch: 6.73 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06348767933039295		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.06348767933039295 | validation: 0.04892041202074408]
	TIME [epoch: 6.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269444893425509		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.06269444893425509 | validation: 0.04309450252912674]
	TIME [epoch: 6.77 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05587715363429761		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.05587715363429761 | validation: 0.052396174671677315]
	TIME [epoch: 6.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059726724215820544		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.059726724215820544 | validation: 0.04838728346181244]
	TIME [epoch: 6.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600440198004153		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.05600440198004153 | validation: 0.05376353076004264]
	TIME [epoch: 6.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054917242576984604		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.054917242576984604 | validation: 0.05203227994434004]
	TIME [epoch: 6.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05872533396693069		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.05872533396693069 | validation: 0.03957522546219072]
	TIME [epoch: 6.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054782832219470945		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.054782832219470945 | validation: 0.05096979976122637]
	TIME [epoch: 6.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0546753144364411		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.0546753144364411 | validation: 0.04989089935165931]
	TIME [epoch: 6.76 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060273567737016906		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.060273567737016906 | validation: 0.05292058566372297]
	TIME [epoch: 6.73 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057317176901829206		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.057317176901829206 | validation: 0.04903080862229729]
	TIME [epoch: 6.73 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058744849170386707		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.058744849170386707 | validation: 0.05455423578177541]
	TIME [epoch: 6.73 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057644153843879		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.057644153843879 | validation: 0.04777435124663851]
	TIME [epoch: 6.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072878058847552		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.06072878058847552 | validation: 0.04855305065538844]
	TIME [epoch: 6.73 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891707591598582		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.05891707591598582 | validation: 0.04962381413899085]
	TIME [epoch: 6.73 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05419474231957651		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.05419474231957651 | validation: 0.05018162753302524]
	TIME [epoch: 6.77 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732963115971836		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.05732963115971836 | validation: 0.04453367667828095]
	TIME [epoch: 6.73 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058377816211787635		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.058377816211787635 | validation: 0.05393202831728962]
	TIME [epoch: 6.73 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05824373781971466		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.05824373781971466 | validation: 0.041856780820352796]
	TIME [epoch: 6.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729059601638111		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.05729059601638111 | validation: 0.05008296291133918]
	TIME [epoch: 6.72 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055194269560434		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.055194269560434 | validation: 0.049138707795895145]
	TIME [epoch: 6.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448818669311297		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.05448818669311297 | validation: 0.04324642508416046]
	TIME [epoch: 6.75 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058059029606082065		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.058059029606082065 | validation: 0.0430238971945889]
	TIME [epoch: 6.76 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056226405854990946		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.056226405854990946 | validation: 0.05065547619965962]
	TIME [epoch: 6.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529970331233559		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.0529970331233559 | validation: 0.05418370171901167]
	TIME [epoch: 6.73 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05209258465371411		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.05209258465371411 | validation: 0.04985175485853246]
	TIME [epoch: 6.73 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801586507431229		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.05801586507431229 | validation: 0.04006407655325002]
	TIME [epoch: 6.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059507117531092016		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.059507117531092016 | validation: 0.05512867187833499]
	TIME [epoch: 6.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05410044236668193		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.05410044236668193 | validation: 0.042550235709483394]
	TIME [epoch: 6.75 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852341613430774		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.05852341613430774 | validation: 0.05023075247437844]
	TIME [epoch: 6.75 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898425354552777		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.05898425354552777 | validation: 0.04480647413099649]
	TIME [epoch: 6.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057311362288104434		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.057311362288104434 | validation: 0.05010737248555811]
	TIME [epoch: 6.73 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05391996674038405		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.05391996674038405 | validation: 0.03850744817637623]
	TIME [epoch: 6.73 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056955585207435405		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.056955585207435405 | validation: 0.05044182950335842]
	TIME [epoch: 6.72 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932541575057232		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.05932541575057232 | validation: 0.04520483301854778]
	TIME [epoch: 6.72 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057796833061940556		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.057796833061940556 | validation: 0.054285840328254176]
	TIME [epoch: 6.76 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05265510840682018		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.05265510840682018 | validation: 0.04061360033645391]
	TIME [epoch: 6.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056727225223217534		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.056727225223217534 | validation: 0.05471175486581475]
	TIME [epoch: 6.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06003829339272385		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.06003829339272385 | validation: 0.04424649690571552]
	TIME [epoch: 6.72 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495004326632863		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.05495004326632863 | validation: 0.0481241444317548]
	TIME [epoch: 6.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057719050308145885		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.057719050308145885 | validation: 0.04426968739785227]
	TIME [epoch: 6.72 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056443039214655724		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.056443039214655724 | validation: 0.042489625680646716]
	TIME [epoch: 6.73 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591302680910879		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05591302680910879 | validation: 0.0483451326694389]
	TIME [epoch: 6.77 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06042152005898831		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.06042152005898831 | validation: 0.047531101168594374]
	TIME [epoch: 6.73 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05894008197675363		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.05894008197675363 | validation: 0.044660325741107496]
	TIME [epoch: 6.72 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058797551511776076		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.058797551511776076 | validation: 0.04882958216851012]
	TIME [epoch: 6.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05829334235536794		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.05829334235536794 | validation: 0.053433642402836934]
	TIME [epoch: 6.73 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545518511091089		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.0545518511091089 | validation: 0.044688073694938095]
	TIME [epoch: 6.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603358412940699		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.05603358412940699 | validation: 0.052428281983607605]
	TIME [epoch: 6.74 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471014548068668		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.05471014548068668 | validation: 0.05081914400118395]
	TIME [epoch: 6.77 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000910997722987		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.06000910997722987 | validation: 0.04961715112740363]
	TIME [epoch: 6.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05272108727290918		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05272108727290918 | validation: 0.051707127533080835]
	TIME [epoch: 6.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670029277275336		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.05670029277275336 | validation: 0.059973100169799023]
	TIME [epoch: 6.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589072090763131		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.05589072090763131 | validation: 0.04073962889937807]
	TIME [epoch: 6.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590555111641546		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.05590555111641546 | validation: 0.05872051733256867]
	TIME [epoch: 6.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0587730423618153		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0587730423618153 | validation: 0.039147345851157554]
	TIME [epoch: 6.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609174463466993		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.05609174463466993 | validation: 0.044425286916051396]
	TIME [epoch: 6.75 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055107466582099675		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.055107466582099675 | validation: 0.048487603821709926]
	TIME [epoch: 6.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054990643112742585		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.054990643112742585 | validation: 0.04680431762244247]
	TIME [epoch: 6.73 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058306964460515164		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.058306964460515164 | validation: 0.04502482232072363]
	TIME [epoch: 6.73 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029233958931591		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.06029233958931591 | validation: 0.04992494800595653]
	TIME [epoch: 6.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796665226877151		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.05796665226877151 | validation: 0.054118708055266945]
	TIME [epoch: 6.73 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564300403544198		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.05564300403544198 | validation: 0.062375334583023065]
	TIME [epoch: 6.74 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05385465282250332		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.05385465282250332 | validation: 0.05631977631574836]
	TIME [epoch: 6.76 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05050754101619322		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.05050754101619322 | validation: 0.05391721387989407]
	TIME [epoch: 6.73 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456491210414603		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.05456491210414603 | validation: 0.04496719335350723]
	TIME [epoch: 6.73 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05799430574272359		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.05799430574272359 | validation: 0.0534905083382825]
	TIME [epoch: 6.73 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05741731763437846		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05741731763437846 | validation: 0.050381157545309335]
	TIME [epoch: 6.73 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055241412230737544		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.055241412230737544 | validation: 0.06451414563476238]
	TIME [epoch: 6.73 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05727446426642896		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.05727446426642896 | validation: 0.05776080473827817]
	TIME [epoch: 6.76 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537201930363579		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.05537201930363579 | validation: 0.04284920248807213]
	TIME [epoch: 6.74 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060941727588853065		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.060941727588853065 | validation: 0.045534843514969794]
	TIME [epoch: 6.72 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05482134720434403		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.05482134720434403 | validation: 0.048280135910111356]
	TIME [epoch: 6.73 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222262346640963		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.05222262346640963 | validation: 0.049036354593157375]
	TIME [epoch: 6.72 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158644417653321		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.05158644417653321 | validation: 0.04978947115949629]
	TIME [epoch: 6.73 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818846151519218		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.05818846151519218 | validation: 0.06219507751104801]
	TIME [epoch: 6.72 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05426572444889525		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.05426572444889525 | validation: 0.05803108269652833]
	TIME [epoch: 6.77 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844819780500288		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.05844819780500288 | validation: 0.05434384286900157]
	TIME [epoch: 6.74 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05168127869101401		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.05168127869101401 | validation: 0.03660923613787242]
	TIME [epoch: 6.72 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057229423838631735		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.057229423838631735 | validation: 0.0390527381658576]
	TIME [epoch: 6.72 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05682718023092671		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.05682718023092671 | validation: 0.053408082811639945]
	TIME [epoch: 6.72 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05638460551731435		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.05638460551731435 | validation: 0.03839217322023183]
	TIME [epoch: 6.72 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061397857959338456		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.061397857959338456 | validation: 0.04508092694427076]
	TIME [epoch: 6.72 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05641751582669914		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.05641751582669914 | validation: 0.0463077544198338]
	TIME [epoch: 6.77 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055729633942882925		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.055729633942882925 | validation: 0.04983442846212283]
	TIME [epoch: 6.73 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055455949295131646		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.055455949295131646 | validation: 0.052479165298199244]
	TIME [epoch: 6.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404058785685002		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.05404058785685002 | validation: 0.05628453510979209]
	TIME [epoch: 6.73 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054741823579756155		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.054741823579756155 | validation: 0.0476077497233531]
	TIME [epoch: 6.72 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561942570947553		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0561942570947553 | validation: 0.049962402804779225]
	TIME [epoch: 6.72 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0591476331673455		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.0591476331673455 | validation: 0.05506047243229514]
	TIME [epoch: 6.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05696050750072934		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.05696050750072934 | validation: 0.04643680015991407]
	TIME [epoch: 6.77 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055453841609106005		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.055453841609106005 | validation: 0.042018848207121005]
	TIME [epoch: 6.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053627410321703914		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.053627410321703914 | validation: 0.04701367730796713]
	TIME [epoch: 6.72 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495729423376051		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.05495729423376051 | validation: 0.057662044824843744]
	TIME [epoch: 6.72 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832292734188409		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.05832292734188409 | validation: 0.046739120878069695]
	TIME [epoch: 6.73 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771135633866852		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.05771135633866852 | validation: 0.04135293400868517]
	TIME [epoch: 6.72 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579772762689115		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.05579772762689115 | validation: 0.04785112410551581]
	TIME [epoch: 6.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05965570271910452		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.05965570271910452 | validation: 0.045917112265716514]
	TIME [epoch: 6.76 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603701714893659		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.05603701714893659 | validation: 0.05188786793846318]
	TIME [epoch: 6.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05587602509101919		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.05587602509101919 | validation: 0.05019383742225144]
	TIME [epoch: 6.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896061034164034		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.05896061034164034 | validation: 0.05198283653387281]
	TIME [epoch: 6.73 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056378071066343106		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.056378071066343106 | validation: 0.056097698911389604]
	TIME [epoch: 6.73 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057083993497039624		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.057083993497039624 | validation: 0.05741226744970997]
	TIME [epoch: 6.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548321999329213		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0548321999329213 | validation: 0.04333133607024332]
	TIME [epoch: 6.75 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058178320902453666		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.058178320902453666 | validation: 0.05306916252235383]
	TIME [epoch: 6.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0578139252210156		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.0578139252210156 | validation: 0.0517063236528886]
	TIME [epoch: 6.73 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053317760321284935		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.053317760321284935 | validation: 0.04997578941790691]
	TIME [epoch: 6.72 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058324857167003086		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.058324857167003086 | validation: 0.0503088139695473]
	TIME [epoch: 6.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061253880902338784		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.061253880902338784 | validation: 0.060728821629036756]
	TIME [epoch: 6.73 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057953975779352615		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.057953975779352615 | validation: 0.06359778625866447]
	TIME [epoch: 6.72 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0589101792948693		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.0589101792948693 | validation: 0.04224063424296181]
	TIME [epoch: 6.76 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913886438512225		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.05913886438512225 | validation: 0.05615459009064154]
	TIME [epoch: 6.74 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034729620879131		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06034729620879131 | validation: 0.05350256797570851]
	TIME [epoch: 6.72 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726314953743113		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05726314953743113 | validation: 0.059362353255248995]
	TIME [epoch: 6.72 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538174501137473		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.05538174501137473 | validation: 0.04229043592208359]
	TIME [epoch: 6.73 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054206620341830686		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.054206620341830686 | validation: 0.0458370208290543]
	TIME [epoch: 6.72 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0541833435499796		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.0541833435499796 | validation: 0.05750407740009841]
	TIME [epoch: 6.72 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05826137511966213		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.05826137511966213 | validation: 0.052288575408148665]
	TIME [epoch: 6.77 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627712941075404		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.05627712941075404 | validation: 0.05154979371027444]
	TIME [epoch: 6.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483854962046464		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.05483854962046464 | validation: 0.05629044424137179]
	TIME [epoch: 6.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714747632212961		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.05714747632212961 | validation: 0.05152573000058293]
	TIME [epoch: 6.73 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05819643743234468		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.05819643743234468 | validation: 0.05401800664929844]
	TIME [epoch: 6.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544978162165151		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.0544978162165151 | validation: 0.055739973273525104]
	TIME [epoch: 6.72 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056412720063501905		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.056412720063501905 | validation: 0.06350885239790229]
	TIME [epoch: 6.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057357229253203475		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.057357229253203475 | validation: 0.05611531472190123]
	TIME [epoch: 6.76 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05704179674679212		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.05704179674679212 | validation: 0.048704750289534304]
	TIME [epoch: 6.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627340381457742		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.05627340381457742 | validation: 0.0517726342999308]
	TIME [epoch: 6.72 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056055147760065774		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.056055147760065774 | validation: 0.05899732882141345]
	TIME [epoch: 6.73 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680511799290257		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.05680511799290257 | validation: 0.04872128949044417]
	TIME [epoch: 6.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055800597620908506		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.055800597620908506 | validation: 0.05830150379284056]
	TIME [epoch: 6.72 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572597791507805		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.0572597791507805 | validation: 0.05933383354464167]
	TIME [epoch: 6.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059339409371569604		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.059339409371569604 | validation: 0.05778551538733924]
	TIME [epoch: 6.76 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060204026219451576		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.060204026219451576 | validation: 0.05634204318547782]
	TIME [epoch: 6.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06137116860168791		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.06137116860168791 | validation: 0.04573180313393532]
	TIME [epoch: 6.72 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06181617196338336		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.06181617196338336 | validation: 0.06429045875630966]
	TIME [epoch: 6.72 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06209847005042486		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.06209847005042486 | validation: 0.059176246038562225]
	TIME [epoch: 6.72 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058978343064349736		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.058978343064349736 | validation: 0.0541800627672678]
	TIME [epoch: 6.72 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060334320653324634		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.060334320653324634 | validation: 0.04061000442289059]
	TIME [epoch: 6.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05980664916073379		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05980664916073379 | validation: 0.04946590562467444]
	TIME [epoch: 6.75 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329769570724103		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.05329769570724103 | validation: 0.05725208560009827]
	TIME [epoch: 6.73 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489813837236308		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.05489813837236308 | validation: 0.054433303131463995]
	TIME [epoch: 6.72 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363959272736851		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.05363959272736851 | validation: 0.04300250137015267]
	TIME [epoch: 6.72 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054620033630790016		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.054620033630790016 | validation: 0.050208257280954]
	TIME [epoch: 6.72 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057516018417280296		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.057516018417280296 | validation: 0.04709955346226356]
	TIME [epoch: 6.72 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057713783503776504		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.057713783503776504 | validation: 0.056210079345831394]
	TIME [epoch: 6.76 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05721958795464427		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.05721958795464427 | validation: 0.05199747684724543]
	TIME [epoch: 6.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05257689728916656		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.05257689728916656 | validation: 0.04386231937546847]
	TIME [epoch: 6.72 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059951740794906686		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.059951740794906686 | validation: 0.04542435562623001]
	TIME [epoch: 6.72 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820954333549612		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.05820954333549612 | validation: 0.04131153306811643]
	TIME [epoch: 6.72 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654912228206313		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.05654912228206313 | validation: 0.04860475415535592]
	TIME [epoch: 6.72 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054900050676350315		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.054900050676350315 | validation: 0.04706527240570672]
	TIME [epoch: 6.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556227783173486		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.05556227783173486 | validation: 0.04066927370271438]
	TIME [epoch: 6.76 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605764677301994		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.05605764677301994 | validation: 0.05277518400901657]
	TIME [epoch: 6.74 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05766469197803829		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.05766469197803829 | validation: 0.03698734152726019]
	TIME [epoch: 6.72 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206290984335872		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.05206290984335872 | validation: 0.05245336888208544]
	TIME [epoch: 6.72 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724717647831693		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.05724717647831693 | validation: 0.05255261308890981]
	TIME [epoch: 6.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059668146333345724		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.059668146333345724 | validation: 0.04309863014733305]
	TIME [epoch: 6.72 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05977526045787208		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.05977526045787208 | validation: 0.04764203567867986]
	TIME [epoch: 6.72 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729213197664408		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.05729213197664408 | validation: 0.05510057109177015]
	TIME [epoch: 6.77 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057600086479277945		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.057600086479277945 | validation: 0.047766669571562295]
	TIME [epoch: 6.73 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05634731842589687		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.05634731842589687 | validation: 0.039967337701368136]
	TIME [epoch: 6.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632750453683953		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.05632750453683953 | validation: 0.05602261124115164]
	TIME [epoch: 6.73 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057187611941075564		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.057187611941075564 | validation: 0.050699856809758095]
	TIME [epoch: 6.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05722351849716796		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.05722351849716796 | validation: 0.050923679009950006]
	TIME [epoch: 6.72 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052387186215706885		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.052387186215706885 | validation: 0.05695951047314693]
	TIME [epoch: 6.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053829388765769176		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.053829388765769176 | validation: 0.03771198873160303]
	TIME [epoch: 6.76 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055694791308783284		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.055694791308783284 | validation: 0.039871827170073565]
	TIME [epoch: 6.73 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05450956155416507		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.05450956155416507 | validation: 0.047957702248640786]
	TIME [epoch: 6.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05436237700327323		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.05436237700327323 | validation: 0.04848723526873758]
	TIME [epoch: 6.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590097136640826		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05590097136640826 | validation: 0.04892320681409541]
	TIME [epoch: 6.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764781914206597		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.05764781914206597 | validation: 0.04624003439731099]
	TIME [epoch: 6.72 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05877166832625822		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05877166832625822 | validation: 0.04792996724626266]
	TIME [epoch: 6.74 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569256440912159		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05569256440912159 | validation: 0.049174344173706135]
	TIME [epoch: 6.75 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006991089344314		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.06006991089344314 | validation: 0.04466998398303632]
	TIME [epoch: 6.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448590383755388		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.05448590383755388 | validation: 0.04313677737563842]
	TIME [epoch: 6.72 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054634617189200624		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.054634617189200624 | validation: 0.04347017460705274]
	TIME [epoch: 6.72 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549974465859775		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.0549974465859775 | validation: 0.04363013608342253]
	TIME [epoch: 6.72 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956510677232143		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.04956510677232143 | validation: 0.0510531968956613]
	TIME [epoch: 6.72 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683679429529646		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.05683679429529646 | validation: 0.03917555316028788]
	TIME [epoch: 6.74 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405221608065695		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05405221608065695 | validation: 0.052408192728066]
	TIME [epoch: 6.75 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552043748141207		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.0552043748141207 | validation: 0.05185373442536574]
	TIME [epoch: 6.73 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05550433244386674		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.05550433244386674 | validation: 0.05442330855861642]
	TIME [epoch: 6.73 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680930008156712		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.05680930008156712 | validation: 0.052368192159366084]
	TIME [epoch: 6.72 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492725050759749		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.05492725050759749 | validation: 0.042191386730471445]
	TIME [epoch: 6.72 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432563185734378		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05432563185734378 | validation: 0.05924994049581548]
	TIME [epoch: 6.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054304452565221706		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.054304452565221706 | validation: 0.047644761892175355]
	TIME [epoch: 6.76 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05701328540090152		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.05701328540090152 | validation: 0.041133621053318185]
	TIME [epoch: 6.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053571517305590004		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.053571517305590004 | validation: 0.060620138628604645]
	TIME [epoch: 6.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535183347267436		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.05535183347267436 | validation: 0.05291170464525801]
	TIME [epoch: 6.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053451835470447955		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.053451835470447955 | validation: 0.05196636778253004]
	TIME [epoch: 6.73 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054756338307306696		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.054756338307306696 | validation: 0.05522692934524437]
	TIME [epoch: 6.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05403677048722319		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.05403677048722319 | validation: 0.04419143743998686]
	TIME [epoch: 6.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461681695419088		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05461681695419088 | validation: 0.04700293469331106]
	TIME [epoch: 6.77 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05615481749743027		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.05615481749743027 | validation: 0.0410238929547768]
	TIME [epoch: 6.73 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05851026393484787		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.05851026393484787 | validation: 0.04281817012055527]
	TIME [epoch: 6.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059826243790012584		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.059826243790012584 | validation: 0.051487062934386436]
	TIME [epoch: 6.72 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603052194723372		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.05603052194723372 | validation: 0.05635759571866702]
	TIME [epoch: 6.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057092918803465495		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.057092918803465495 | validation: 0.052177532432047286]
	TIME [epoch: 6.72 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0559864732189808		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.0559864732189808 | validation: 0.04226034354032272]
	TIME [epoch: 6.73 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05710375758369941		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.05710375758369941 | validation: 0.03503157819190129]
	TIME [epoch: 6.76 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056280604741844875		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.056280604741844875 | validation: 0.052042640510075164]
	TIME [epoch: 6.73 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836595735388852		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.05836595735388852 | validation: 0.03985821569259638]
	TIME [epoch: 6.72 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702141497961871		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.05702141497961871 | validation: 0.04710988894971398]
	TIME [epoch: 6.72 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058542636047107285		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.058542636047107285 | validation: 0.04584690576826947]
	TIME [epoch: 6.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591017032966649		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.05591017032966649 | validation: 0.0434813467110169]
	TIME [epoch: 6.72 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052965837633323465		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.052965837633323465 | validation: 0.04910133207240221]
	TIME [epoch: 6.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05741080009190527		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.05741080009190527 | validation: 0.05883217437315306]
	TIME [epoch: 6.77 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250460544334843		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.05250460544334843 | validation: 0.04884292715676751]
	TIME [epoch: 6.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053618707020330926		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.053618707020330926 | validation: 0.04551096713450696]
	TIME [epoch: 6.73 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05481014134147398		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05481014134147398 | validation: 0.0466060378694078]
	TIME [epoch: 6.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059204905908512045		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.059204905908512045 | validation: 0.04703298662745653]
	TIME [epoch: 6.72 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055049768278593696		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.055049768278593696 | validation: 0.05525031717167331]
	TIME [epoch: 6.72 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052345572853631644		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.052345572853631644 | validation: 0.05451816851470024]
	TIME [epoch: 6.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051664791717461606		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.051664791717461606 | validation: 0.050698200546395754]
	TIME [epoch: 6.75 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055875306376533006		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.055875306376533006 | validation: 0.040059189459885264]
	TIME [epoch: 6.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05397856002915732		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05397856002915732 | validation: 0.048833226085186476]
	TIME [epoch: 6.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458181514684117		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05458181514684117 | validation: 0.05512136224342451]
	TIME [epoch: 6.72 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05682287647104155		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.05682287647104155 | validation: 0.047027745300506955]
	TIME [epoch: 6.72 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057430445729593924		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.057430445729593924 | validation: 0.047945324167965514]
	TIME [epoch: 6.72 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551651115710198		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.0551651115710198 | validation: 0.05762765874320683]
	TIME [epoch: 6.75 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540662561729166		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0540662561729166 | validation: 0.058923905835696525]
	TIME [epoch: 6.75 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051471774063769876		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.051471774063769876 | validation: 0.05409329304715951]
	TIME [epoch: 6.72 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054077010019514336		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.054077010019514336 | validation: 0.04321759810590524]
	TIME [epoch: 6.72 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379147894238365		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.05379147894238365 | validation: 0.05526600471202425]
	TIME [epoch: 6.73 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05552188372482038		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.05552188372482038 | validation: 0.043602173694297267]
	TIME [epoch: 6.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05327118802304273		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.05327118802304273 | validation: 0.0557481148291619]
	TIME [epoch: 6.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05370916422210138		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.05370916422210138 | validation: 0.05553904380856786]
	TIME [epoch: 6.76 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05413926687635877		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.05413926687635877 | validation: 0.05366788728756085]
	TIME [epoch: 6.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647804371607801		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.05647804371607801 | validation: 0.05073848985410438]
	TIME [epoch: 6.72 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459821637207447		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.05459821637207447 | validation: 0.05527062933111192]
	TIME [epoch: 6.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055610364629272546		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.055610364629272546 | validation: 0.055486507038005374]
	TIME [epoch: 6.72 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060569620405871404		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.060569620405871404 | validation: 0.058857872454236126]
	TIME [epoch: 6.73 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891088201819006		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.05891088201819006 | validation: 0.046983183196231376]
	TIME [epoch: 6.72 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675868146607188		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.05675868146607188 | validation: 0.04665873835726016]
	TIME [epoch: 6.77 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0559751626034104		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0559751626034104 | validation: 0.04652453804836492]
	TIME [epoch: 6.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05482407484337301		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.05482407484337301 | validation: 0.058894259924421724]
	TIME [epoch: 6.72 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528887932486229		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.0528887932486229 | validation: 0.06519071584774094]
	TIME [epoch: 6.72 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795353208220887		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.05795353208220887 | validation: 0.05770715086510704]
	TIME [epoch: 6.72 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05339580114798961		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.05339580114798961 | validation: 0.05432241274287743]
	TIME [epoch: 6.72 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714902797635075		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.05714902797635075 | validation: 0.05144676032799292]
	TIME [epoch: 6.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689307337108372		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.05689307337108372 | validation: 0.04404366116288293]
	TIME [epoch: 6.76 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05514032575380591		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.05514032575380591 | validation: 0.05168191242262009]
	TIME [epoch: 6.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05369293272614767		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.05369293272614767 | validation: 0.06154949403790987]
	TIME [epoch: 6.73 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05524345985736079		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.05524345985736079 | validation: 0.05190569606540413]
	TIME [epoch: 6.73 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773121186921579		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.05773121186921579 | validation: 0.06883999780045885]
	TIME [epoch: 6.72 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928237463109463		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.05928237463109463 | validation: 0.05073657796362323]
	TIME [epoch: 6.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05577483166675186		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.05577483166675186 | validation: 0.0486779404495148]
	TIME [epoch: 6.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055960932298265015		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.055960932298265015 | validation: 0.0636000999781428]
	TIME [epoch: 6.76 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073224136686023		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.06073224136686023 | validation: 0.05689176193723672]
	TIME [epoch: 6.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474868158034986		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.05474868158034986 | validation: 0.050173172200348615]
	TIME [epoch: 6.73 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055738582270126236		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.055738582270126236 | validation: 0.05496576958366796]
	TIME [epoch: 6.72 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05855871335398942		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.05855871335398942 | validation: 0.049218003055217716]
	TIME [epoch: 6.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420907057627446		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.05420907057627446 | validation: 0.04885707464780763]
	TIME [epoch: 6.72 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055896041401174004		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.055896041401174004 | validation: 0.05649346456106697]
	TIME [epoch: 6.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05395920508027292		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.05395920508027292 | validation: 0.05818662090526123]
	TIME [epoch: 6.75 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968704970155769		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.05968704970155769 | validation: 0.0465857883921848]
	TIME [epoch: 6.73 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05321250346268419		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.05321250346268419 | validation: 0.05165544968229449]
	TIME [epoch: 6.72 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05686108882731147		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.05686108882731147 | validation: 0.044742532081316136]
	TIME [epoch: 6.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05462420234461974		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.05462420234461974 | validation: 0.05615039582509351]
	TIME [epoch: 6.73 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458807436115619		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.05458807436115619 | validation: 0.05907774131133642]
	TIME [epoch: 6.73 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493486639663646		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.05493486639663646 | validation: 0.050435569145131476]
	TIME [epoch: 6.77 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545002408215252		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.05545002408215252 | validation: 0.040023852499192984]
	TIME [epoch: 6.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05439520386434525		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.05439520386434525 | validation: 0.057833588743901376]
	TIME [epoch: 6.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880513642001974		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.05880513642001974 | validation: 0.04727993355127329]
	TIME [epoch: 6.72 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05567818077577012		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.05567818077577012 | validation: 0.06027721263850658]
	TIME [epoch: 6.72 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569153463575566		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0569153463575566 | validation: 0.056202735821199556]
	TIME [epoch: 6.72 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716247258987847		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.05716247258987847 | validation: 0.05935320974625503]
	TIME [epoch: 6.73 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05297800971499745		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.05297800971499745 | validation: 0.052707612708306595]
	TIME [epoch: 6.77 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642098010753162		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.05642098010753162 | validation: 0.05943357156755444]
	TIME [epoch: 6.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900593446136505		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.05900593446136505 | validation: 0.0572691292896195]
	TIME [epoch: 6.73 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716601076184454		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.05716601076184454 | validation: 0.04633199433885993]
	TIME [epoch: 6.72 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060118745310698204		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.060118745310698204 | validation: 0.04813618271049106]
	TIME [epoch: 6.72 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06025386626838852		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.06025386626838852 | validation: 0.054637121391409846]
	TIME [epoch: 6.72 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057502911588089144		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.057502911588089144 | validation: 0.05476048943006627]
	TIME [epoch: 6.72 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05825323188410537		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.05825323188410537 | validation: 0.0452999141357602]
	TIME [epoch: 6.76 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060897744124701225		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.060897744124701225 | validation: 0.06033766069864097]
	TIME [epoch: 6.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613656913341951		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.0613656913341951 | validation: 0.058573892217640845]
	TIME [epoch: 6.72 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699787843622901		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.05699787843622901 | validation: 0.0565467426293393]
	TIME [epoch: 6.73 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412367885147967		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.05412367885147967 | validation: 0.048564598270432094]
	TIME [epoch: 6.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05434221584006199		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.05434221584006199 | validation: 0.05344358360314226]
	TIME [epoch: 6.72 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371304578180573		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.05371304578180573 | validation: 0.053455166207946506]
	TIME [epoch: 6.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762352912127624		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.05762352912127624 | validation: 0.05230185002231454]
	TIME [epoch: 6.76 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05296172090955779		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.05296172090955779 | validation: 0.04772319076726827]
	TIME [epoch: 6.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056868371924132216		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.056868371924132216 | validation: 0.05108849812616889]
	TIME [epoch: 6.72 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058875565583630544		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.058875565583630544 | validation: 0.05341041995540828]
	TIME [epoch: 6.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758295922586809		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.05758295922586809 | validation: 0.05021024356147542]
	TIME [epoch: 6.72 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05685310454636359		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.05685310454636359 | validation: 0.05123223319435656]
	TIME [epoch: 6.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633276980267571		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.05633276980267571 | validation: 0.04772116491864088]
	TIME [epoch: 6.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456622750111992		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.05456622750111992 | validation: 0.054085339376199415]
	TIME [epoch: 6.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307192212509808		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.05307192212509808 | validation: 0.050424808860318096]
	TIME [epoch: 6.72 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0495899086970745		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.0495899086970745 | validation: 0.03844186657991809]
	TIME [epoch: 6.72 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412510507499666		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.05412510507499666 | validation: 0.03736569453993226]
	TIME [epoch: 6.72 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600540417968739		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.05600540417968739 | validation: 0.04835152054819834]
	TIME [epoch: 6.72 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05381367154838483		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.05381367154838483 | validation: 0.05433354554283202]
	TIME [epoch: 6.72 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492541378678913		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.05492541378678913 | validation: 0.0360985953468902]
	TIME [epoch: 6.75 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054798425306657766		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.054798425306657766 | validation: 0.05144474108467044]
	TIME [epoch: 6.75 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797208432821928		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05797208432821928 | validation: 0.05455596724280347]
	TIME [epoch: 6.73 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05200667372196382		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.05200667372196382 | validation: 0.05357812935581986]
	TIME [epoch: 6.72 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058307029102951616		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.058307029102951616 | validation: 0.05590592217560026]
	TIME [epoch: 6.72 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050679853147673794		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.050679853147673794 | validation: 0.055016990195894205]
	TIME [epoch: 6.72 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052593910783878435		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.052593910783878435 | validation: 0.05147848775478963]
	TIME [epoch: 6.72 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055021727101018804		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.055021727101018804 | validation: 0.05468330694275674]
	TIME [epoch: 6.76 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05209172026081613		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.05209172026081613 | validation: 0.05108099969380446]
	TIME [epoch: 6.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05553805934666768		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.05553805934666768 | validation: 0.04002442287357023]
	TIME [epoch: 6.72 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051586591095571496		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.051586591095571496 | validation: 0.049784127561856364]
	TIME [epoch: 6.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368808264257766		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.05368808264257766 | validation: 0.0470423775503889]
	TIME [epoch: 6.72 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056206989691778654		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.056206989691778654 | validation: 0.05258039870198636]
	TIME [epoch: 6.72 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702359952871514		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.05702359952871514 | validation: 0.05351151552766213]
	TIME [epoch: 6.72 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236742259986397		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.05236742259986397 | validation: 0.04987850302053223]
	TIME [epoch: 6.76 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516617618434858		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.05516617618434858 | validation: 0.05460508842351508]
	TIME [epoch: 6.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565770497614797		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.05565770497614797 | validation: 0.04699019543477925]
	TIME [epoch: 6.72 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348882611007998		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.05348882611007998 | validation: 0.05227966244816202]
	TIME [epoch: 6.72 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05598122791418836		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.05598122791418836 | validation: 0.05073123704718664]
	TIME [epoch: 6.72 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346950820952223		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.05346950820952223 | validation: 0.04685304639781365]
	TIME [epoch: 6.72 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05457282955661477		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.05457282955661477 | validation: 0.05214723712175198]
	TIME [epoch: 6.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05503560526602889		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.05503560526602889 | validation: 0.05383945785160775]
	TIME [epoch: 6.76 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057246843993299365		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.057246843993299365 | validation: 0.05342960368246724]
	TIME [epoch: 6.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057616699738684905		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.057616699738684905 | validation: 0.05409123723924909]
	TIME [epoch: 6.72 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053243145287883924		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.053243145287883924 | validation: 0.042319474539249675]
	TIME [epoch: 6.72 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05693631446270927		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.05693631446270927 | validation: 0.03956373088581077]
	TIME [epoch: 6.72 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052770592933391536		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.052770592933391536 | validation: 0.05139987292494476]
	TIME [epoch: 6.72 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05395550066237744		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.05395550066237744 | validation: 0.042654924127954866]
	TIME [epoch: 6.73 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528394641329345		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.0528394641329345 | validation: 0.057907070727026194]
	TIME [epoch: 6.76 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725292991629041		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.05725292991629041 | validation: 0.04575209218727043]
	TIME [epoch: 6.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053045192998975754		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.053045192998975754 | validation: 0.05268836562619921]
	TIME [epoch: 6.72 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747113830151643		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.05747113830151643 | validation: 0.050636881224984734]
	TIME [epoch: 6.72 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532904447465242		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05532904447465242 | validation: 0.03990173095645305]
	TIME [epoch: 6.72 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512433010961351		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.05512433010961351 | validation: 0.04734873901450748]
	TIME [epoch: 6.72 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773872093372971		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.05773872093372971 | validation: 0.044898420534234554]
	TIME [epoch: 6.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053928210908113394		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.053928210908113394 | validation: 0.05381897303979853]
	TIME [epoch: 6.76 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052894460320572614		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.052894460320572614 | validation: 0.05572636863320082]
	TIME [epoch: 6.73 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648718522203585		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.05648718522203585 | validation: 0.050668978470268494]
	TIME [epoch: 6.72 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059779861812266015		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.059779861812266015 | validation: 0.049601607671104844]
	TIME [epoch: 6.72 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055409374198801514		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.055409374198801514 | validation: 0.05671344560696578]
	TIME [epoch: 6.72 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057309281656977885		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.057309281656977885 | validation: 0.057813325319146444]
	TIME [epoch: 6.72 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05310013148563939		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.05310013148563939 | validation: 0.05579978145766414]
	TIME [epoch: 6.76 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060259870379427385		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.060259870379427385 | validation: 0.0582622436308097]
	TIME [epoch: 6.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05507201406020128		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.05507201406020128 | validation: 0.04909898978584655]
	TIME [epoch: 6.72 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05653517697259229		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.05653517697259229 | validation: 0.06047454127287161]
	TIME [epoch: 6.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494697854350729		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.05494697854350729 | validation: 0.05969428948673481]
	TIME [epoch: 6.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574661855613406		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.05574661855613406 | validation: 0.051473945360401306]
	TIME [epoch: 6.72 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612514229901433		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.05612514229901433 | validation: 0.048904491800390124]
	TIME [epoch: 6.72 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334933991652314		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.05334933991652314 | validation: 0.053286354238348155]
	TIME [epoch: 6.76 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055357015747335675		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.055357015747335675 | validation: 0.05116980250722577]
	TIME [epoch: 6.73 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05134998571791419		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.05134998571791419 | validation: 0.049679423862187475]
	TIME [epoch: 6.72 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344839433992614		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.05344839433992614 | validation: 0.05397745239042191]
	TIME [epoch: 6.72 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882987664631806		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.05882987664631806 | validation: 0.06652140779399715]
	TIME [epoch: 6.72 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051703504233981984		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.051703504233981984 | validation: 0.04918303144567669]
	TIME [epoch: 6.72 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529085359754696		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.05529085359754696 | validation: 0.049801055392350926]
	TIME [epoch: 6.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203438650874133		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.05203438650874133 | validation: 0.04654731612033289]
	TIME [epoch: 6.77 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031732970697173		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.05031732970697173 | validation: 0.05726829790809984]
	TIME [epoch: 6.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05358565458346233		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.05358565458346233 | validation: 0.044444177124471226]
	TIME [epoch: 6.72 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677943650489458		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.05677943650489458 | validation: 0.049299831160640115]
	TIME [epoch: 6.72 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051713750125542975		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.051713750125542975 | validation: 0.05511745261677705]
	TIME [epoch: 6.72 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056202707522387714		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.056202707522387714 | validation: 0.047804712613345506]
	TIME [epoch: 6.72 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052311490025870794		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.052311490025870794 | validation: 0.04495268109182443]
	TIME [epoch: 6.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844562692872337		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.05844562692872337 | validation: 0.051612332689971584]
	TIME [epoch: 6.76 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05995258306601996		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.05995258306601996 | validation: 0.05029822489776947]
	TIME [epoch: 6.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557004679825309		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.05557004679825309 | validation: 0.03850686692477691]
	TIME [epoch: 6.72 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05187771134205075		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.05187771134205075 | validation: 0.044914128657949026]
	TIME [epoch: 6.72 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056619813381266905		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.056619813381266905 | validation: 0.0396246348792509]
	TIME [epoch: 6.72 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05454201043054292		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.05454201043054292 | validation: 0.05523540234868436]
	TIME [epoch: 6.72 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622802067236491		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.05622802067236491 | validation: 0.051796124633278776]
	TIME [epoch: 6.74 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987164550063911		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.05987164550063911 | validation: 0.05608965464287305]
	TIME [epoch: 6.75 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053577694727725785		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.053577694727725785 | validation: 0.049377241703191604]
	TIME [epoch: 6.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05301120382067639		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.05301120382067639 | validation: 0.04639703987129962]
	TIME [epoch: 6.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06239338670946018		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.06239338670946018 | validation: 0.042885499551663105]
	TIME [epoch: 6.73 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059647594354167464		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.059647594354167464 | validation: 0.05549937532217629]
	TIME [epoch: 6.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055897304893821595		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.055897304893821595 | validation: 0.044903648996734866]
	TIME [epoch: 6.72 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452591074500976		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.05452591074500976 | validation: 0.05072181661406672]
	TIME [epoch: 6.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05737297828164391		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.05737297828164391 | validation: 0.05147135542747654]
	TIME [epoch: 6.74 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531073739729179		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.05531073739729179 | validation: 0.044345298019246734]
	TIME [epoch: 6.72 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056487612545290514		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.056487612545290514 | validation: 0.054707757926042225]
	TIME [epoch: 6.72 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057760670330346355		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.057760670330346355 | validation: 0.04696362337717985]
	TIME [epoch: 6.72 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05665338080437697		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.05665338080437697 | validation: 0.04417948095319403]
	TIME [epoch: 6.72 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05638563885070918		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.05638563885070918 | validation: 0.04529473478117811]
	TIME [epoch: 6.72 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05266108821060745		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.05266108821060745 | validation: 0.04202172447384991]
	TIME [epoch: 6.76 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05701350314496181		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.05701350314496181 | validation: 0.04783938277567168]
	TIME [epoch: 6.74 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676383162822196		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.05676383162822196 | validation: 0.04328710512877211]
	TIME [epoch: 6.73 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420353645268894		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.05420353645268894 | validation: 0.054239726480561315]
	TIME [epoch: 6.72 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564687705664726		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.0564687705664726 | validation: 0.034262771231567596]
	TIME [epoch: 6.72 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735898938815945		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.05735898938815945 | validation: 0.05025883437096594]
	TIME [epoch: 6.72 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055883249250758944		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.055883249250758944 | validation: 0.05426798232750098]
	TIME [epoch: 6.72 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05602840504892287		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.05602840504892287 | validation: 0.0523345315062268]
	TIME [epoch: 6.77 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05397130262974371		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.05397130262974371 | validation: 0.053144425162686595]
	TIME [epoch: 6.74 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760110143658248		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.05760110143658248 | validation: 0.04743114409765495]
	TIME [epoch: 6.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069888454241207		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.05069888454241207 | validation: 0.04703754122340836]
	TIME [epoch: 6.72 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05224042661381635		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.05224042661381635 | validation: 0.05679828940137944]
	TIME [epoch: 6.72 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058164015431343266		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.058164015431343266 | validation: 0.04821752929566618]
	TIME [epoch: 6.72 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055175504483354815		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.055175504483354815 | validation: 0.04184851906413467]
	TIME [epoch: 6.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055965556039551265		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.055965556039551265 | validation: 0.0555624116474429]
	TIME [epoch: 6.76 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05577086697525644		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.05577086697525644 | validation: 0.051020078330123286]
	TIME [epoch: 6.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527249109069922		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0527249109069922 | validation: 0.05862891924355261]
	TIME [epoch: 6.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057124589555619776		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.057124589555619776 | validation: 0.04839161273724994]
	TIME [epoch: 6.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05667106280969673		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.05667106280969673 | validation: 0.042501455151208345]
	TIME [epoch: 6.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051602109160968704		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.051602109160968704 | validation: 0.04791049734435483]
	TIME [epoch: 6.73 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05370958042131391		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.05370958042131391 | validation: 0.041523367032340476]
	TIME [epoch: 6.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506513408663516		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.05506513408663516 | validation: 0.04820300091944307]
	TIME [epoch: 6.76 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054087399362545155		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.054087399362545155 | validation: 0.05352042370561726]
	TIME [epoch: 6.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054074139082946455		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.054074139082946455 | validation: 0.04677729578439962]
	TIME [epoch: 6.72 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057959561497319		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.057959561497319 | validation: 0.05901244358425095]
	TIME [epoch: 6.72 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827740372693389		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05827740372693389 | validation: 0.038172143991323466]
	TIME [epoch: 6.72 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642755071236031		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.05642755071236031 | validation: 0.05384759829075186]
	TIME [epoch: 6.73 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055526338337744445		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.055526338337744445 | validation: 0.05070272843379074]
	TIME [epoch: 6.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05243053382253986		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.05243053382253986 | validation: 0.05366844482998553]
	TIME [epoch: 6.75 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470599243854772		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.05470599243854772 | validation: 0.04726433237125073]
	TIME [epoch: 6.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240332565569455		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.05240332565569455 | validation: 0.05202854570202825]
	TIME [epoch: 6.72 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0546846535998701		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0546846535998701 | validation: 0.05450121924406367]
	TIME [epoch: 6.72 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456310584097174		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.05456310584097174 | validation: 0.04652069313012121]
	TIME [epoch: 6.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054735161239051894		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.054735161239051894 | validation: 0.04896997356323329]
	TIME [epoch: 6.72 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492814457935351		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05492814457935351 | validation: 0.040435488037070734]
	TIME [epoch: 6.76 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784568875490481		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.05784568875490481 | validation: 0.05051513404886909]
	TIME [epoch: 6.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058507509317853645		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.058507509317853645 | validation: 0.041946367369137726]
	TIME [epoch: 6.72 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0536574587998726		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0536574587998726 | validation: 0.05788324518464681]
	TIME [epoch: 6.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05386039879724095		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.05386039879724095 | validation: 0.05037449392582868]
	TIME [epoch: 6.72 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648803352971605		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.05648803352971605 | validation: 0.05683899855005598]
	TIME [epoch: 6.72 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666819677784449		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.05666819677784449 | validation: 0.05322119988299527]
	TIME [epoch: 6.72 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516525379732249		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.05516525379732249 | validation: 0.04142905039362781]
	TIME [epoch: 6.76 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719372974376732		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.05719372974376732 | validation: 0.043255826666655395]
	TIME [epoch: 6.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055316067464879146		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.055316067464879146 | validation: 0.06199118724036158]
	TIME [epoch: 6.72 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049656315370443856		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.049656315370443856 | validation: 0.05543353884552336]
	TIME [epoch: 6.72 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053655163447487		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.053655163447487 | validation: 0.054446460815105735]
	TIME [epoch: 6.72 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131412574334989		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.05131412574334989 | validation: 0.046727818081916325]
	TIME [epoch: 6.72 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05524302184762946		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.05524302184762946 | validation: 0.052355816643259445]
	TIME [epoch: 6.72 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055417460439824456		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.055417460439824456 | validation: 0.049501380574745346]
	TIME [epoch: 6.76 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762948224502264		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.05762948224502264 | validation: 0.046500775957988724]
	TIME [epoch: 6.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715948168566162		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.05715948168566162 | validation: 0.054791065698288996]
	TIME [epoch: 6.73 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459277991385521		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.05459277991385521 | validation: 0.050947663062239384]
	TIME [epoch: 6.72 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05606247056861027		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.05606247056861027 | validation: 0.05813722418054665]
	TIME [epoch: 6.72 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794863896876887		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.05794863896876887 | validation: 0.058486667843242995]
	TIME [epoch: 6.72 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053407257185873025		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.053407257185873025 | validation: 0.055581096724179616]
	TIME [epoch: 6.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607397543986856		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.05607397543986856 | validation: 0.04909001688796147]
	TIME [epoch: 6.76 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05977004248928971		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.05977004248928971 | validation: 0.046240181232452465]
	TIME [epoch: 6.73 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320170713889483		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.05320170713889483 | validation: 0.05237594885346211]
	TIME [epoch: 6.72 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058234654973226836		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.058234654973226836 | validation: 0.0632748235203745]
	TIME [epoch: 6.72 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689952991651263		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.05689952991651263 | validation: 0.04417003390909223]
	TIME [epoch: 6.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060965977750441484		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.060965977750441484 | validation: 0.05184560346182161]
	TIME [epoch: 6.72 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05219981064282631		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.05219981064282631 | validation: 0.046125576304762536]
	TIME [epoch: 6.74 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0506069800623326		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.0506069800623326 | validation: 0.05491868830625485]
	TIME [epoch: 6.76 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058832958033878044		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.058832958033878044 | validation: 0.05342647436564063]
	TIME [epoch: 6.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570144857566413		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.0570144857566413 | validation: 0.058412365641010267]
	TIME [epoch: 6.72 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054668283145021895		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.054668283145021895 | validation: 0.052730171946863406]
	TIME [epoch: 6.72 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058463861472903854		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.058463861472903854 | validation: 0.05154175643505929]
	TIME [epoch: 6.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05177376312259989		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05177376312259989 | validation: 0.05819153645774597]
	TIME [epoch: 6.72 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05214135720852472		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.05214135720852472 | validation: 0.053726977484425724]
	TIME [epoch: 6.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092308085935088		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.05092308085935088 | validation: 0.047113406658278144]
	TIME [epoch: 6.75 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057919488989084444		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.057919488989084444 | validation: 0.048281737772246536]
	TIME [epoch: 6.72 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055633274642757274		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.055633274642757274 | validation: 0.04291610652327203]
	TIME [epoch: 6.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057669060561430174		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.057669060561430174 | validation: 0.049078877278184926]
	TIME [epoch: 6.72 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762689025839317		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.05762689025839317 | validation: 0.056477005296914184]
	TIME [epoch: 6.72 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636501420807955		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.05636501420807955 | validation: 0.04291273302973827]
	TIME [epoch: 6.72 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05276530630262376		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.05276530630262376 | validation: 0.04713053200940929]
	TIME [epoch: 6.76 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056669627144303986		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.056669627144303986 | validation: 0.057443705963508354]
	TIME [epoch: 6.74 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05070676609121644		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.05070676609121644 | validation: 0.052099315599564835]
	TIME [epoch: 6.73 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05500368549260486		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.05500368549260486 | validation: 0.04102308546549299]
	TIME [epoch: 6.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575217056681634		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.0575217056681634 | validation: 0.047899331338798486]
	TIME [epoch: 6.73 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055123330412225474		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.055123330412225474 | validation: 0.03430095535623971]
	TIME [epoch: 6.73 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05652123535597471		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.05652123535597471 | validation: 0.06128108906887865]
	TIME [epoch: 6.72 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05503747639450357		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.05503747639450357 | validation: 0.057600822904613436]
	TIME [epoch: 6.77 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060013015839785445		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.060013015839785445 | validation: 0.041277190285431]
	TIME [epoch: 6.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057790018521669845		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.057790018521669845 | validation: 0.05420280691777307]
	TIME [epoch: 6.72 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597171402685889		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.05597171402685889 | validation: 0.05747867196494523]
	TIME [epoch: 6.72 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05672035258764806		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.05672035258764806 | validation: 0.048809586269660823]
	TIME [epoch: 6.73 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05539910966465408		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.05539910966465408 | validation: 0.053023154579147386]
	TIME [epoch: 6.73 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052057362968822414		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.052057362968822414 | validation: 0.05337252620849787]
	TIME [epoch: 6.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059710346767007545		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.059710346767007545 | validation: 0.05009479667873211]
	TIME [epoch: 6.77 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05077933073877031		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.05077933073877031 | validation: 0.04595221011898301]
	TIME [epoch: 6.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540833419259726		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.0540833419259726 | validation: 0.05261783770796407]
	TIME [epoch: 6.73 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607443403548132		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.05607443403548132 | validation: 0.05609148301699403]
	TIME [epoch: 6.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535384909193433		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.05535384909193433 | validation: 0.056280397040842534]
	TIME [epoch: 6.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051994984625854807		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.051994984625854807 | validation: 0.05329556950448363]
	TIME [epoch: 6.73 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053151206915732205		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.053151206915732205 | validation: 0.04964290492773314]
	TIME [epoch: 6.74 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483827484438883		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.05483827484438883 | validation: 0.03900247000935778]
	TIME [epoch: 6.76 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445115775178613		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.05445115775178613 | validation: 0.049364456675828755]
	TIME [epoch: 6.73 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05541856124779573		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.05541856124779573 | validation: 0.04603746245190984]
	TIME [epoch: 6.72 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051682137215950746		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.051682137215950746 | validation: 0.0437236160323371]
	TIME [epoch: 6.72 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633101861051623		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.05633101861051623 | validation: 0.047949518064168396]
	TIME [epoch: 6.72 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592383776755669		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0592383776755669 | validation: 0.04724111617515488]
	TIME [epoch: 6.72 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05586282245474789		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.05586282245474789 | validation: 0.04789422626821506]
	TIME [epoch: 6.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052709869088850274		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.052709869088850274 | validation: 0.041382499042412216]
	TIME [epoch: 6.76 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054379657222042126		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.054379657222042126 | validation: 0.04960282766052414]
	TIME [epoch: 6.73 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05294209805547832		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05294209805547832 | validation: 0.04564822878084399]
	TIME [epoch: 6.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051221002988041525		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.051221002988041525 | validation: 0.04585341162879308]
	TIME [epoch: 6.72 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052728039340901964		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.052728039340901964 | validation: 0.03873676710222378]
	TIME [epoch: 6.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817350123572808		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.05817350123572808 | validation: 0.04367603317626646]
	TIME [epoch: 6.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914406954067245		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.04914406954067245 | validation: 0.05117591627236556]
	TIME [epoch: 6.76 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053791484954667575		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.053791484954667575 | validation: 0.03766871448554139]
	TIME [epoch: 6.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544425911971573		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.0544425911971573 | validation: 0.0407697286233496]
	TIME [epoch: 6.72 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053699461901816396		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.053699461901816396 | validation: 0.0551598664321164]
	TIME [epoch: 6.72 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222021766151835		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05222021766151835 | validation: 0.04514624338126966]
	TIME [epoch: 6.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05376354124425094		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.05376354124425094 | validation: 0.04316164201133956]
	TIME [epoch: 6.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054096881781616264		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.054096881781616264 | validation: 0.031918934853782575]
	TIME [epoch: 6.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057633704924434696		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.057633704924434696 | validation: 0.05375383012830087]
	TIME [epoch: 6.77 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059687087420172105		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.059687087420172105 | validation: 0.04762296390765286]
	TIME [epoch: 6.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05311984036268496		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.05311984036268496 | validation: 0.04908449064846944]
	TIME [epoch: 6.73 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719410825511109		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.05719410825511109 | validation: 0.057927677899909914]
	TIME [epoch: 6.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051745802811465895		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.051745802811465895 | validation: 0.05079807603962874]
	TIME [epoch: 6.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055237981566159944		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.055237981566159944 | validation: 0.056889169681876676]
	TIME [epoch: 6.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05585162297109866		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.05585162297109866 | validation: 0.04934040244406809]
	TIME [epoch: 6.73 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786772724188133		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.05786772724188133 | validation: 0.042274023940988344]
	TIME [epoch: 6.77 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440692263662544		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.05440692263662544 | validation: 0.049186127810012734]
	TIME [epoch: 6.73 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054711901979823195		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.054711901979823195 | validation: 0.05192700608877852]
	TIME [epoch: 6.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379516150800081		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.05379516150800081 | validation: 0.03733312913715883]
	TIME [epoch: 6.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05144980579049856		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.05144980579049856 | validation: 0.046276814731942]
	TIME [epoch: 6.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702193854559267		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.05702193854559267 | validation: 0.04682786904608674]
	TIME [epoch: 6.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055096114937281754		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.055096114937281754 | validation: 0.04717161845928121]
	TIME [epoch: 6.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05313280885094521		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.05313280885094521 | validation: 0.04961612965742976]
	TIME [epoch: 6.77 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346922608807869		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.05346922608807869 | validation: 0.04142402215096337]
	TIME [epoch: 6.73 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052341134537649305		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.052341134537649305 | validation: 0.058388818426150124]
	TIME [epoch: 6.73 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051678200501059805		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.051678200501059805 | validation: 0.03771314578554191]
	TIME [epoch: 6.73 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05381814409563083		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.05381814409563083 | validation: 0.05756385349232651]
	TIME [epoch: 6.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057031611381384045		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.057031611381384045 | validation: 0.03925644057799736]
	TIME [epoch: 6.73 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053521363454498073		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.053521363454498073 | validation: 0.04738433325456411]
	TIME [epoch: 6.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053997833827024444		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.053997833827024444 | validation: 0.05471403994269012]
	TIME [epoch: 6.76 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05397620974135818		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.05397620974135818 | validation: 0.0453416040533702]
	TIME [epoch: 6.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05576357256221888		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.05576357256221888 | validation: 0.052018633051492874]
	TIME [epoch: 6.72 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055638284692787934		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.055638284692787934 | validation: 0.038099911673505175]
	TIME [epoch: 6.73 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059074484980721854		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.059074484980721854 | validation: 0.05090690079302245]
	TIME [epoch: 6.72 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520102797148048		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.05520102797148048 | validation: 0.04528631239652804]
	TIME [epoch: 6.73 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05317691513799725		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.05317691513799725 | validation: 0.047777850104902944]
	TIME [epoch: 6.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054122344783213955		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.054122344783213955 | validation: 0.05843265827865556]
	TIME [epoch: 6.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517831206902172		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.05517831206902172 | validation: 0.0552034053867691]
	TIME [epoch: 6.72 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542986397313543		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.0542986397313543 | validation: 0.05599819358191212]
	TIME [epoch: 6.73 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057144584775314596		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.057144584775314596 | validation: 0.046831899431949146]
	TIME [epoch: 6.73 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789910718307409		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.05789910718307409 | validation: 0.0484692440940494]
	TIME [epoch: 6.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521849933377696		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.05521849933377696 | validation: 0.04684622356476434]
	TIME [epoch: 6.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058019710815319675		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.058019710815319675 | validation: 0.04754002224322122]
	TIME [epoch: 6.77 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05361493098436919		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.05361493098436919 | validation: 0.0405620947504483]
	TIME [epoch: 6.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558629689938901		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.05558629689938901 | validation: 0.04616838932901315]
	TIME [epoch: 6.73 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530630339036838		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.05530630339036838 | validation: 0.045491693570048584]
	TIME [epoch: 6.73 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318488113365133		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05318488113365133 | validation: 0.043300556282916375]
	TIME [epoch: 6.73 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655513320623217		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.05655513320623217 | validation: 0.04919217242436863]
	TIME [epoch: 6.72 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05805343040346197		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.05805343040346197 | validation: 0.039265873652855686]
	TIME [epoch: 6.73 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334163608644245		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05334163608644245 | validation: 0.03843996216278553]
	TIME [epoch: 6.76 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05668329216510638		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.05668329216510638 | validation: 0.05461956099797308]
	TIME [epoch: 6.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307725864701421		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.05307725864701421 | validation: 0.042553403862578]
	TIME [epoch: 6.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607809371977723		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.05607809371977723 | validation: 0.046144178037822906]
	TIME [epoch: 6.72 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236107253085481		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.05236107253085481 | validation: 0.041160733578297394]
	TIME [epoch: 6.72 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431485920732103		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.05431485920732103 | validation: 0.046081249919003045]
	TIME [epoch: 6.72 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521096583111239		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.05521096583111239 | validation: 0.043072315942236844]
	TIME [epoch: 6.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564400466131432		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.0564400466131432 | validation: 0.04900084049516236]
	TIME [epoch: 6.77 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05616105658161478		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.05616105658161478 | validation: 0.05103026481049501]
	TIME [epoch: 6.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057778238727877074		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.057778238727877074 | validation: 0.048711569441225566]
	TIME [epoch: 6.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058294599693168164		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.058294599693168164 | validation: 0.045284848645031864]
	TIME [epoch: 6.73 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392012812583519		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.05392012812583519 | validation: 0.038034430177990006]
	TIME [epoch: 6.73 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949463064093488		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.05949463064093488 | validation: 0.03986679032189282]
	TIME [epoch: 6.72 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053483874247578556		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.053483874247578556 | validation: 0.043550826059654116]
	TIME [epoch: 6.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662019910351615		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.05662019910351615 | validation: 0.04637810135461304]
	TIME [epoch: 6.76 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758139696489652		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.05758139696489652 | validation: 0.04459380823074112]
	TIME [epoch: 6.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495496074843725		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.05495496074843725 | validation: 0.040316592525389744]
	TIME [epoch: 6.72 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430773319265051		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.05430773319265051 | validation: 0.049051835731454635]
	TIME [epoch: 6.73 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057142843072834806		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.057142843072834806 | validation: 0.03864504801227046]
	TIME [epoch: 6.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399641986124426		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.05399641986124426 | validation: 0.04986595518678463]
	TIME [epoch: 6.72 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05374430129394326		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.05374430129394326 | validation: 0.047771584356213564]
	TIME [epoch: 6.76 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555933631386408		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.0555933631386408 | validation: 0.044368962483124934]
	TIME [epoch: 6.74 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707934936758717		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.05707934936758717 | validation: 0.05176822495723992]
	TIME [epoch: 6.72 sec]
Finished training in 13726.287 seconds.
