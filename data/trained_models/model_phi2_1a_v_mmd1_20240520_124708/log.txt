Args:
Namespace(name='model_phi2_1a_v_mmd1', outdir='out/model_training/model_phi2_1a_v_mmd1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1868044729

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6592011720957207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6592011720957207 | validation: 2.5385377361120183]
	TIME [epoch: 104 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.188005260997893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.188005260997893 | validation: 2.2955097834712497]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8971196377298558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8971196377298558 | validation: 2.0295739706646345]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7467072412311244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7467072412311244 | validation: 1.4473079746851072]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3309029385106483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3309029385106483 | validation: 1.261964990288367]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284005423474825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0284005423474825 | validation: 1.1716670005184495]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610805438891862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0610805438891862 | validation: 0.526052174778638]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571028588195785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6571028588195785 | validation: 0.6815775558848238]
	TIME [epoch: 8.39 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030013708524758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6030013708524758 | validation: 0.29587188563328876]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35082624606185886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35082624606185886 | validation: 0.20771649805707365]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106185918158077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4106185918158077 | validation: 0.18971296537376015]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827997721940613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2827997721940613 | validation: 0.1888382211312964]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37894809660122064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37894809660122064 | validation: 0.20248509621300168]
	TIME [epoch: 8.39 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960328016546883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2960328016546883 | validation: 0.20213005490230232]
	TIME [epoch: 8.34 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35175734437725975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35175734437725975 | validation: 0.19817317128040182]
	TIME [epoch: 8.34 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992690054092053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2992690054092053 | validation: 0.29994048065730344]
	TIME [epoch: 8.34 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365098663667174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3365098663667174 | validation: 0.20687788620279385]
	TIME [epoch: 8.34 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35792623586948635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35792623586948635 | validation: 0.20529457645605356]
	TIME [epoch: 8.37 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980294997162823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2980294997162823 | validation: 0.20464960865616866]
	TIME [epoch: 8.35 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35461538862438524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35461538862438524 | validation: 0.16310033079936348]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27443165781173917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27443165781173917 | validation: 0.18093674211012606]
	TIME [epoch: 8.34 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34937228665354136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34937228665354136 | validation: 0.19918777163005555]
	TIME [epoch: 8.34 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040650210059979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3040650210059979 | validation: 0.17784156472590487]
	TIME [epoch: 8.38 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31844264970292324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31844264970292324 | validation: 0.19352087791725442]
	TIME [epoch: 8.35 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033177773660621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3033177773660621 | validation: 0.17531372315062654]
	TIME [epoch: 8.33 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.298616694746417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.298616694746417 | validation: 0.21114685202523414]
	TIME [epoch: 8.33 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141487394613345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3141487394613345 | validation: 0.25265682432700914]
	TIME [epoch: 8.33 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32030529436504557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32030529436504557 | validation: 0.1654614225620857]
	TIME [epoch: 8.36 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29030205063061054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29030205063061054 | validation: 0.24260368812164457]
	TIME [epoch: 8.34 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33280535571080966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33280535571080966 | validation: 0.17615985510391508]
	TIME [epoch: 8.33 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28391571387143233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28391571387143233 | validation: 0.21961913032976427]
	TIME [epoch: 8.33 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32278921595930066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32278921595930066 | validation: 0.16101255882856697]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30226616818214136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30226616818214136 | validation: 0.1982886199776931]
	TIME [epoch: 8.38 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29325702022031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29325702022031 | validation: 0.18711514674173996]
	TIME [epoch: 8.35 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308287878571512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.308287878571512 | validation: 0.1853891175732061]
	TIME [epoch: 8.33 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29635891813201287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29635891813201287 | validation: 0.17953136204510142]
	TIME [epoch: 8.33 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289846584705536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.289846584705536 | validation: 0.18166927070902084]
	TIME [epoch: 8.33 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29561655348100446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29561655348100446 | validation: 0.24915415300789184]
	TIME [epoch: 8.35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3076495072425152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3076495072425152 | validation: 0.17133809147097231]
	TIME [epoch: 8.37 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29593061587666225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29593061587666225 | validation: 0.1916457168561284]
	TIME [epoch: 8.33 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30537782924007684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30537782924007684 | validation: 0.1776025805865431]
	TIME [epoch: 8.33 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28222993966954535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28222993966954535 | validation: 0.15206665887621196]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741918690013647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2741918690013647 | validation: 0.196478194262563]
	TIME [epoch: 8.36 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34271620533456276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34271620533456276 | validation: 0.1653204504626267]
	TIME [epoch: 8.37 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27527363915525627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27527363915525627 | validation: 0.1722141152696986]
	TIME [epoch: 8.33 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30121729245955586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30121729245955586 | validation: 0.15761767786165715]
	TIME [epoch: 8.33 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695789664272209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2695789664272209 | validation: 0.15746173366866947]
	TIME [epoch: 8.33 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31680360314067296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31680360314067296 | validation: 0.1624619488040896]
	TIME [epoch: 8.34 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842127260493692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2842127260493692 | validation: 0.20614205745282954]
	TIME [epoch: 8.38 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807788434796836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2807788434796836 | validation: 0.16838711160193157]
	TIME [epoch: 8.34 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29046550156340895		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.29046550156340895 | validation: 0.16586312497591837]
	TIME [epoch: 8.33 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27548212020158575		[learning rate: 0.0099588]
	Learning Rate: 0.00995876
	LOSS [training: 0.27548212020158575 | validation: 0.19053490737506065]
	TIME [epoch: 8.33 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003128481304688		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3003128481304688 | validation: 0.17721091602163705]
	TIME [epoch: 8.34 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27932382295179237		[learning rate: 0.0099118]
	Learning Rate: 0.00991183
	LOSS [training: 0.27932382295179237 | validation: 0.14858542050870363]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800416949185545		[learning rate: 0.0098884]
	Learning Rate: 0.00988845
	LOSS [training: 0.2800416949185545 | validation: 0.18715592319168117]
	TIME [epoch: 8.44 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957912974791211		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.2957912974791211 | validation: 0.16838147531514736]
	TIME [epoch: 8.34 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26638406684679017		[learning rate: 0.0098419]
	Learning Rate: 0.00984185
	LOSS [training: 0.26638406684679017 | validation: 0.15398540691249163]
	TIME [epoch: 8.33 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27409720503322943		[learning rate: 0.0098186]
	Learning Rate: 0.00981864
	LOSS [training: 0.27409720503322943 | validation: 0.1531958342442537]
	TIME [epoch: 8.33 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25314868734642854		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.25314868734642854 | validation: 0.18562898468631775]
	TIME [epoch: 8.38 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25895483767997146		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 0.25895483767997146 | validation: 0.18125072642397216]
	TIME [epoch: 8.32 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23625166873979608		[learning rate: 0.0097493]
	Learning Rate: 0.00974932
	LOSS [training: 0.23625166873979608 | validation: 0.15123072938809184]
	TIME [epoch: 8.29 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381264419087212		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.2381264419087212 | validation: 0.16696789562317335]
	TIME [epoch: 8.31 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22982960631186006		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.22982960631186006 | validation: 0.16151584137178265]
	TIME [epoch: 8.32 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24674852954536186		[learning rate: 0.0096805]
	Learning Rate: 0.00968049
	LOSS [training: 0.24674852954536186 | validation: 0.17004333836945773]
	TIME [epoch: 8.36 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23530046311144637		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.23530046311144637 | validation: 0.1523673362376267]
	TIME [epoch: 8.33 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23466290043477064		[learning rate: 0.0096349]
	Learning Rate: 0.00963488
	LOSS [training: 0.23466290043477064 | validation: 0.14886407217964884]
	TIME [epoch: 8.33 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290318882653871		[learning rate: 0.0096121]
	Learning Rate: 0.00961215
	LOSS [training: 0.2290318882653871 | validation: 0.17479993766507224]
	TIME [epoch: 8.33 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22858334910746947		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.22858334910746947 | validation: 0.17922770580300745]
	TIME [epoch: 8.33 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23007267925156144		[learning rate: 0.0095669]
	Learning Rate: 0.00956686
	LOSS [training: 0.23007267925156144 | validation: 0.1393371955876591]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21863564478822273		[learning rate: 0.0095443]
	Learning Rate: 0.00954429
	LOSS [training: 0.21863564478822273 | validation: 0.16920641114378668]
	TIME [epoch: 8.46 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349726760682971		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2349726760682971 | validation: 0.17824681502020412]
	TIME [epoch: 8.34 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23966507583999294		[learning rate: 0.0094993]
	Learning Rate: 0.00949931
	LOSS [training: 0.23966507583999294 | validation: 0.17604330611926117]
	TIME [epoch: 8.34 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23139389274476502		[learning rate: 0.0094769]
	Learning Rate: 0.00947691
	LOSS [training: 0.23139389274476502 | validation: 0.17389130306196426]
	TIME [epoch: 8.31 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22434072965272964		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.22434072965272964 | validation: 0.14869553321530596]
	TIME [epoch: 8.34 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21367260283337108		[learning rate: 0.0094323]
	Learning Rate: 0.00943225
	LOSS [training: 0.21367260283337108 | validation: 0.1656151929417608]
	TIME [epoch: 8.32 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22550398543511282		[learning rate: 0.00941]
	Learning Rate: 0.00941
	LOSS [training: 0.22550398543511282 | validation: 0.19380566450726106]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21822304300351456		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.21822304300351456 | validation: 0.17196138890075255]
	TIME [epoch: 8.32 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19840456616045482		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.19840456616045482 | validation: 0.23432808077895223]
	TIME [epoch: 8.31 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2224476770726897		[learning rate: 0.0093436]
	Learning Rate: 0.00934357
	LOSS [training: 0.2224476770726897 | validation: 0.16496541766937686]
	TIME [epoch: 8.35 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21390451211152967		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.21390451211152967 | validation: 0.14514858341428602]
	TIME [epoch: 8.34 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21322389389534913		[learning rate: 0.0092995]
	Learning Rate: 0.00929954
	LOSS [training: 0.21322389389534913 | validation: 0.13731360261903916]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077437078381727		[learning rate: 0.0092776]
	Learning Rate: 0.00927761
	LOSS [training: 0.2077437078381727 | validation: 0.1364292814316091]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17495976026604412		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.17495976026604412 | validation: 0.1487095595783722]
	TIME [epoch: 8.35 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18519512692140075		[learning rate: 0.0092339]
	Learning Rate: 0.00923389
	LOSS [training: 0.18519512692140075 | validation: 0.18247472620530014]
	TIME [epoch: 8.38 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409292021531565		[learning rate: 0.0092121]
	Learning Rate: 0.00921211
	LOSS [training: 0.2409292021531565 | validation: 0.14147474507540597]
	TIME [epoch: 8.34 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830525779255363		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.1830525779255363 | validation: 0.11026761551996203]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16375306401669165		[learning rate: 0.0091687]
	Learning Rate: 0.0091687
	LOSS [training: 0.16375306401669165 | validation: 0.11888389501890076]
	TIME [epoch: 8.34 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18818027440874047		[learning rate: 0.0091471]
	Learning Rate: 0.00914707
	LOSS [training: 0.18818027440874047 | validation: 0.09864232309978826]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220464714463734		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.13220464714463734 | validation: 0.1476710683636061]
	TIME [epoch: 8.38 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20050993841227127		[learning rate: 0.009104]
	Learning Rate: 0.00910397
	LOSS [training: 0.20050993841227127 | validation: 0.17470270857618603]
	TIME [epoch: 8.35 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22904129786037392		[learning rate: 0.0090825]
	Learning Rate: 0.00908249
	LOSS [training: 0.22904129786037392 | validation: 0.18102460540833681]
	TIME [epoch: 8.34 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14960434807051254		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.14960434807051254 | validation: 0.11296534934619205]
	TIME [epoch: 8.33 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115619089221728		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.19115619089221728 | validation: 0.09970335231164229]
	TIME [epoch: 8.34 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15701295976813748		[learning rate: 0.0090184]
	Learning Rate: 0.00901837
	LOSS [training: 0.15701295976813748 | validation: 0.1355387902633413]
	TIME [epoch: 8.37 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13326782692878447		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.13326782692878447 | validation: 0.08611213823046707]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15726960361303213		[learning rate: 0.0089759]
	Learning Rate: 0.00897588
	LOSS [training: 0.15726960361303213 | validation: 0.12364085692570802]
	TIME [epoch: 8.34 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847616887859114		[learning rate: 0.0089547]
	Learning Rate: 0.0089547
	LOSS [training: 0.15847616887859114 | validation: 0.14295468224206764]
	TIME [epoch: 8.34 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365121963823616		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.1365121963823616 | validation: 0.08850750414737922]
	TIME [epoch: 8.34 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15766264855368167		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.15766264855368167 | validation: 0.30339514117631616]
	TIME [epoch: 8.36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970515509026203		[learning rate: 0.0088915]
	Learning Rate: 0.00889149
	LOSS [training: 0.1970515509026203 | validation: 0.09176505914395516]
	TIME [epoch: 8.36 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14950756011984967		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.14950756011984967 | validation: 0.09102722581029779]
	TIME [epoch: 8.34 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14424523033709408		[learning rate: 0.0088496]
	Learning Rate: 0.00884959
	LOSS [training: 0.14424523033709408 | validation: 0.08415833549802205]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17975189817516868		[learning rate: 0.0088287]
	Learning Rate: 0.00882871
	LOSS [training: 0.17975189817516868 | validation: 0.09992477237817614]
	TIME [epoch: 8.34 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11614572228124953		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.11614572228124953 | validation: 0.08770307949234595]
	TIME [epoch: 8.37 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16326604409481127		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.16326604409481127 | validation: 0.09428244288736642]
	TIME [epoch: 8.36 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19353199077960145		[learning rate: 0.0087664]
	Learning Rate: 0.00876638
	LOSS [training: 0.19353199077960145 | validation: 0.13506221077946765]
	TIME [epoch: 8.34 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18097771148015246		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.18097771148015246 | validation: 0.09242362305987481]
	TIME [epoch: 8.34 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679572655810179		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.11679572655810179 | validation: 0.12309211634399098]
	TIME [epoch: 8.32 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026070018250334		[learning rate: 0.0087045]
	Learning Rate: 0.00870449
	LOSS [training: 0.12026070018250334 | validation: 0.09704020048526407]
	TIME [epoch: 8.27 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613539947479446		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.12613539947479446 | validation: 0.13122781706032105]
	TIME [epoch: 8.31 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19439304443444314		[learning rate: 0.0086635]
	Learning Rate: 0.00866348
	LOSS [training: 0.19439304443444314 | validation: 0.08167952445957001]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11554490444946183		[learning rate: 0.008643]
	Learning Rate: 0.00864304
	LOSS [training: 0.11554490444946183 | validation: 0.0840967984689357]
	TIME [epoch: 8.42 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983587756240883		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.10983587756240883 | validation: 0.064454102699726]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12492883535032404		[learning rate: 0.0086023]
	Learning Rate: 0.00860232
	LOSS [training: 0.12492883535032404 | validation: 0.1548582584464584]
	TIME [epoch: 8.46 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16896564787297158		[learning rate: 0.008582]
	Learning Rate: 0.00858202
	LOSS [training: 0.16896564787297158 | validation: 0.09166958949753513]
	TIME [epoch: 8.31 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134327758046105		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.134327758046105 | validation: 0.07119488870481541]
	TIME [epoch: 8.32 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197661101620971		[learning rate: 0.0085416]
	Learning Rate: 0.00854158
	LOSS [training: 0.12197661101620971 | validation: 0.11754910752553652]
	TIME [epoch: 8.31 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339153645075997		[learning rate: 0.0085214]
	Learning Rate: 0.00852144
	LOSS [training: 0.14339153645075997 | validation: 0.12842335291333778]
	TIME [epoch: 8.35 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15661462992356343		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.15661462992356343 | validation: 0.11495786923109057]
	TIME [epoch: 8.32 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09973180884575578		[learning rate: 0.0084813]
	Learning Rate: 0.00848128
	LOSS [training: 0.09973180884575578 | validation: 0.08151768698880284]
	TIME [epoch: 8.37 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12255532847427104		[learning rate: 0.0084613]
	Learning Rate: 0.00846128
	LOSS [training: 0.12255532847427104 | validation: 0.11788928132825291]
	TIME [epoch: 8.33 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08471892937155212		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.08471892937155212 | validation: 0.13440658610794426]
	TIME [epoch: 8.31 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011679308978284		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.10011679308978284 | validation: 0.07686790666488846]
	TIME [epoch: 8.33 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062791583556496		[learning rate: 0.0084015]
	Learning Rate: 0.00840154
	LOSS [training: 0.10062791583556496 | validation: 0.0689423456524764]
	TIME [epoch: 8.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11892628444293962		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.11892628444293962 | validation: 0.05532549508739949]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650907903654258		[learning rate: 0.008362]
	Learning Rate: 0.00836195
	LOSS [training: 0.10650907903654258 | validation: 0.053822858809619484]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11557702241974158		[learning rate: 0.0083422]
	Learning Rate: 0.00834223
	LOSS [training: 0.11557702241974158 | validation: 0.06619032091455611]
	TIME [epoch: 8.34 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08746457740540615		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.08746457740540615 | validation: 0.04873641113854915]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06456020492538678		[learning rate: 0.0083029]
	Learning Rate: 0.00830292
	LOSS [training: 0.06456020492538678 | validation: 0.15977614386249253]
	TIME [epoch: 8.34 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11650505048731467		[learning rate: 0.0082833]
	Learning Rate: 0.00828333
	LOSS [training: 0.11650505048731467 | validation: 0.050298660614027116]
	TIME [epoch: 8.38 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052415858990139		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.08052415858990139 | validation: 0.04127698411818646]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08629741155051883		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.08629741155051883 | validation: 0.06293566322147552]
	TIME [epoch: 8.34 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06861182806304475		[learning rate: 0.0082249]
	Learning Rate: 0.00822485
	LOSS [training: 0.06861182806304475 | validation: 0.10548848068810121]
	TIME [epoch: 8.34 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771082835510204		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.08771082835510204 | validation: 0.2658316579785318]
	TIME [epoch: 8.34 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15648260118411844		[learning rate: 0.0081861]
	Learning Rate: 0.0081861
	LOSS [training: 0.15648260118411844 | validation: 0.22947168700882675]
	TIME [epoch: 8.39 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634440686609909		[learning rate: 0.0081668]
	Learning Rate: 0.00816679
	LOSS [training: 0.11634440686609909 | validation: 0.04590428441725222]
	TIME [epoch: 8.34 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856380832784101		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.06856380832784101 | validation: 0.07279677755847236]
	TIME [epoch: 8.34 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662882427473187		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.0662882427473187 | validation: 0.037326454724820754]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09959140739918013		[learning rate: 0.0081091]
	Learning Rate: 0.00810913
	LOSS [training: 0.09959140739918013 | validation: 0.04205252976317312]
	TIME [epoch: 8.35 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008686058988851		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.07008686058988851 | validation: 0.045863453051324325]
	TIME [epoch: 8.38 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068063450769022		[learning rate: 0.0080709]
	Learning Rate: 0.00807092
	LOSS [training: 0.07068063450769022 | validation: 0.047654303817051644]
	TIME [epoch: 8.34 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07996556719052497		[learning rate: 0.0080519]
	Learning Rate: 0.00805188
	LOSS [training: 0.07996556719052497 | validation: 0.06185628586411394]
	TIME [epoch: 8.34 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07345593548456991		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.07345593548456991 | validation: 0.037751061305408756]
	TIME [epoch: 8.34 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996302153702263		[learning rate: 0.0080139]
	Learning Rate: 0.00801394
	LOSS [training: 0.06996302153702263 | validation: 0.03750028887433366]
	TIME [epoch: 8.34 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06921543037845954		[learning rate: 0.007995]
	Learning Rate: 0.00799504
	LOSS [training: 0.06921543037845954 | validation: 0.1338600922030989]
	TIME [epoch: 8.37 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441430226365564		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.07441430226365564 | validation: 0.08013121575164274]
	TIME [epoch: 8.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164685948291221		[learning rate: 0.0079574]
	Learning Rate: 0.00795736
	LOSS [training: 0.05164685948291221 | validation: 0.05527658391045795]
	TIME [epoch: 8.34 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340368401828264		[learning rate: 0.0079386]
	Learning Rate: 0.00793859
	LOSS [training: 0.06340368401828264 | validation: 0.060790216466627536]
	TIME [epoch: 8.32 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845907651632739		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.06845907651632739 | validation: 0.04085280463872497]
	TIME [epoch: 8.31 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157748408695132		[learning rate: 0.0079012]
	Learning Rate: 0.00790119
	LOSS [training: 0.06157748408695132 | validation: 0.03334919416380324]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06569991416244453		[learning rate: 0.0078825]
	Learning Rate: 0.00788255
	LOSS [training: 0.06569991416244453 | validation: 0.05766512717135096]
	TIME [epoch: 8.45 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04029066288517265		[learning rate: 0.007864]
	Learning Rate: 0.00786396
	LOSS [training: 0.04029066288517265 | validation: 0.022369855342636386]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06115706323991365		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.06115706323991365 | validation: 0.06387046966755303]
	TIME [epoch: 8.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05547579537326619		[learning rate: 0.0078269]
	Learning Rate: 0.0078269
	LOSS [training: 0.05547579537326619 | validation: 0.07063550558031964]
	TIME [epoch: 8.33 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887502573418647		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.06887502573418647 | validation: 0.031252750251532554]
	TIME [epoch: 8.36 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037566096814150615		[learning rate: 0.00779]
	Learning Rate: 0.00779002
	LOSS [training: 0.037566096814150615 | validation: 0.12198798912756154]
	TIME [epoch: 8.33 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07503671967285738		[learning rate: 0.0077716]
	Learning Rate: 0.00777164
	LOSS [training: 0.07503671967285738 | validation: 0.07199579477410722]
	TIME [epoch: 8.32 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632926572770388		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.0632926572770388 | validation: 0.04544061687038221]
	TIME [epoch: 8.33 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058403536560898306		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.058403536560898306 | validation: 0.0608734656892224]
	TIME [epoch: 8.33 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071668778249639		[learning rate: 0.0077168]
	Learning Rate: 0.00771678
	LOSS [training: 0.06071668778249639 | validation: 0.031245877583542914]
	TIME [epoch: 8.38 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0481152637447575		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.0481152637447575 | validation: 0.055670185514440834]
	TIME [epoch: 8.34 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050481796796353375		[learning rate: 0.0076804]
	Learning Rate: 0.00768041
	LOSS [training: 0.050481796796353375 | validation: 0.02640594295803363]
	TIME [epoch: 8.33 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187281102869599		[learning rate: 0.0076623]
	Learning Rate: 0.0076623
	LOSS [training: 0.06187281102869599 | validation: 0.0550552871335749]
	TIME [epoch: 8.33 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494443212083651		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.04494443212083651 | validation: 0.03680155786399576]
	TIME [epoch: 8.31 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439463919521172		[learning rate: 0.0076262]
	Learning Rate: 0.00762619
	LOSS [training: 0.07439463919521172 | validation: 0.039557593948739346]
	TIME [epoch: 8.35 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0558181998233902		[learning rate: 0.0076082]
	Learning Rate: 0.0076082
	LOSS [training: 0.0558181998233902 | validation: 0.053519208224789644]
	TIME [epoch: 8.34 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873974298556505		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.05873974298556505 | validation: 0.03718404476659799]
	TIME [epoch: 8.32 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026667206322701965		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.026667206322701965 | validation: 0.021255817969936808]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243869380296779		[learning rate: 0.0075545]
	Learning Rate: 0.00755449
	LOSS [training: 0.06243869380296779 | validation: 0.06315354802403542]
	TIME [epoch: 8.34 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06616634699064407		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.06616634699064407 | validation: 0.06623035635726836]
	TIME [epoch: 8.37 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900567495123582		[learning rate: 0.0075189]
	Learning Rate: 0.00751889
	LOSS [training: 0.06900567495123582 | validation: 0.06810493559348679]
	TIME [epoch: 8.35 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042871825485505645		[learning rate: 0.0075012]
	Learning Rate: 0.00750116
	LOSS [training: 0.042871825485505645 | validation: 0.02593675482909505]
	TIME [epoch: 8.33 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04860214267261055		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.04860214267261055 | validation: 0.06150026909830894]
	TIME [epoch: 8.33 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053458479613410145		[learning rate: 0.0074658]
	Learning Rate: 0.00746581
	LOSS [training: 0.053458479613410145 | validation: 0.07890559342552686]
	TIME [epoch: 8.33 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06208708894889803		[learning rate: 0.0074482]
	Learning Rate: 0.0074482
	LOSS [training: 0.06208708894889803 | validation: 0.021235970386852654]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03784301297278854		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.03784301297278854 | validation: 0.044684292354732175]
	TIME [epoch: 8.36 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06053899235801585		[learning rate: 0.0074131]
	Learning Rate: 0.0074131
	LOSS [training: 0.06053899235801585 | validation: 0.024343674989606205]
	TIME [epoch: 8.33 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041849735858528726		[learning rate: 0.0073956]
	Learning Rate: 0.00739562
	LOSS [training: 0.041849735858528726 | validation: 0.02347650526301549]
	TIME [epoch: 8.33 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040404005291365286		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.040404005291365286 | validation: 0.025688035998846875]
	TIME [epoch: 8.33 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051479840293287546		[learning rate: 0.0073608]
	Learning Rate: 0.00736077
	LOSS [training: 0.051479840293287546 | validation: 0.03065092588342813]
	TIME [epoch: 8.35 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026637020372880255		[learning rate: 0.0073434]
	Learning Rate: 0.0073434
	LOSS [training: 0.026637020372880255 | validation: 0.025055124758116665]
	TIME [epoch: 8.36 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306652873712722		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.06306652873712722 | validation: 0.02883693749296022]
	TIME [epoch: 8.33 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04807432746686194		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.04807432746686194 | validation: 0.03752987694470462]
	TIME [epoch: 8.33 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405257084678611		[learning rate: 0.0072916]
	Learning Rate: 0.00729156
	LOSS [training: 0.05405257084678611 | validation: 0.0337287366416023]
	TIME [epoch: 8.33 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04790661300413026		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.04790661300413026 | validation: 0.02022895789506455]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024275751875722874		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.024275751875722874 | validation: 0.02513165158330165]
	TIME [epoch: 8.48 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059356705164313545		[learning rate: 0.0072401]
	Learning Rate: 0.00724008
	LOSS [training: 0.059356705164313545 | validation: 0.05122269724170442]
	TIME [epoch: 8.33 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558764161319081		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.04558764161319081 | validation: 0.02578118827663353]
	TIME [epoch: 8.33 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040492216675067506		[learning rate: 0.007206]
	Learning Rate: 0.00720597
	LOSS [training: 0.040492216675067506 | validation: 0.021425608068766727]
	TIME [epoch: 8.34 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04526565598746855		[learning rate: 0.007189]
	Learning Rate: 0.00718897
	LOSS [training: 0.04526565598746855 | validation: 0.05035234809526441]
	TIME [epoch: 8.34 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06605778203046826		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.06605778203046826 | validation: 0.023010168296117916]
	TIME [epoch: 8.38 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011687132676375		[learning rate: 0.0071551]
	Learning Rate: 0.00715509
	LOSS [training: 0.05011687132676375 | validation: 0.10832235928468481]
	TIME [epoch: 8.33 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054321187909152		[learning rate: 0.0071382]
	Learning Rate: 0.00713822
	LOSS [training: 0.06054321187909152 | validation: 0.027403344510963615]
	TIME [epoch: 8.33 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358492311546493		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.03358492311546493 | validation: 0.029044025221190196]
	TIME [epoch: 8.33 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03073059204989581		[learning rate: 0.0071046]
	Learning Rate: 0.00710458
	LOSS [training: 0.03073059204989581 | validation: 0.021493614588211217]
	TIME [epoch: 8.34 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045283848988759444		[learning rate: 0.0070878]
	Learning Rate: 0.00708782
	LOSS [training: 0.045283848988759444 | validation: 0.059089203018685754]
	TIME [epoch: 8.37 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118676603282116		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.10118676603282116 | validation: 0.04357513816233678]
	TIME [epoch: 8.34 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0466145618505864		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.0466145618505864 | validation: 0.02242129914259223]
	TIME [epoch: 8.34 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038243000603898444		[learning rate: 0.0070378]
	Learning Rate: 0.00703778
	LOSS [training: 0.038243000603898444 | validation: 0.024496044110955992]
	TIME [epoch: 8.34 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028322898760268164		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.028322898760268164 | validation: 0.01751294912688579]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03564874014767856		[learning rate: 0.0070046]
	Learning Rate: 0.00700462
	LOSS [training: 0.03564874014767856 | validation: 0.08703063149843011]
	TIME [epoch: 8.38 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06391095186262427		[learning rate: 0.0069881]
	Learning Rate: 0.0069881
	LOSS [training: 0.06391095186262427 | validation: 0.046721714260728596]
	TIME [epoch: 8.34 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042395260905526796		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.042395260905526796 | validation: 0.01847074274330053]
	TIME [epoch: 8.34 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026432993687498976		[learning rate: 0.0069552]
	Learning Rate: 0.00695517
	LOSS [training: 0.026432993687498976 | validation: 0.02029186977446426]
	TIME [epoch: 8.34 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05180956399660892		[learning rate: 0.0069388]
	Learning Rate: 0.00693876
	LOSS [training: 0.05180956399660892 | validation: 0.02544559590863173]
	TIME [epoch: 8.35 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028092947571998393		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.028092947571998393 | validation: 0.02457005692689214]
	TIME [epoch: 8.38 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713971227840021		[learning rate: 0.0069061]
	Learning Rate: 0.00690607
	LOSS [training: 0.03713971227840021 | validation: 0.021731459290943514]
	TIME [epoch: 8.33 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027000422890654394		[learning rate: 0.0068898]
	Learning Rate: 0.00688978
	LOSS [training: 0.027000422890654394 | validation: 0.05227436996582774]
	TIME [epoch: 8.34 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858725914731497		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.05858725914731497 | validation: 0.0221848333452674]
	TIME [epoch: 8.34 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081431075157461		[learning rate: 0.0068573]
	Learning Rate: 0.00685731
	LOSS [training: 0.06081431075157461 | validation: 0.03682235983678423]
	TIME [epoch: 8.34 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07461277060419666		[learning rate: 0.0068411]
	Learning Rate: 0.00684114
	LOSS [training: 0.07461277060419666 | validation: 0.042035397577228024]
	TIME [epoch: 8.38 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043849299996197404		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.043849299996197404 | validation: 0.018110171288334954]
	TIME [epoch: 8.34 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024265902367343613		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.024265902367343613 | validation: 0.06808364597885222]
	TIME [epoch: 8.34 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590510208790998		[learning rate: 0.0067928]
	Learning Rate: 0.00679284
	LOSS [training: 0.05590510208790998 | validation: 0.01756933957575635]
	TIME [epoch: 8.34 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027175013660132058		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.027175013660132058 | validation: 0.022805411710317827]
	TIME [epoch: 8.34 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028932312866612915		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.028932312866612915 | validation: 0.027479015308003306]
	TIME [epoch: 8.39 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080683008902078		[learning rate: 0.0067449]
	Learning Rate: 0.00674488
	LOSS [training: 0.04080683008902078 | validation: 0.03963987924300626]
	TIME [epoch: 8.35 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029898038397647146		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.029898038397647146 | validation: 0.024257418994184647]
	TIME [epoch: 8.33 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02954495777578614		[learning rate: 0.0067131]
	Learning Rate: 0.0067131
	LOSS [training: 0.02954495777578614 | validation: 0.014729781651509665]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08066526920300879		[learning rate: 0.0066973]
	Learning Rate: 0.00669726
	LOSS [training: 0.08066526920300879 | validation: 0.04862183022711758]
	TIME [epoch: 8.33 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774669384589782		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.04774669384589782 | validation: 0.025059324154912396]
	TIME [epoch: 8.37 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02762196544667461		[learning rate: 0.0066657]
	Learning Rate: 0.00666571
	LOSS [training: 0.02762196544667461 | validation: 0.025122166892745594]
	TIME [epoch: 8.35 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032613813000628294		[learning rate: 0.00665]
	Learning Rate: 0.00664998
	LOSS [training: 0.032613813000628294 | validation: 0.04024858742542275]
	TIME [epoch: 8.33 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156113845713928		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.03156113845713928 | validation: 0.025117827294875578]
	TIME [epoch: 8.33 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820824703756764		[learning rate: 0.0066186]
	Learning Rate: 0.00661865
	LOSS [training: 0.04820824703756764 | validation: 0.031633235700608164]
	TIME [epoch: 8.33 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025734804913731868		[learning rate: 0.006603]
	Learning Rate: 0.00660304
	LOSS [training: 0.025734804913731868 | validation: 0.023225853723267537]
	TIME [epoch: 8.37 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13410388475708687		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.13410388475708687 | validation: 0.04260293766001721]
	TIME [epoch: 8.35 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04082504138421361		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.04082504138421361 | validation: 0.024683835381387752]
	TIME [epoch: 8.33 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03348729478511904		[learning rate: 0.0065564]
	Learning Rate: 0.00655642
	LOSS [training: 0.03348729478511904 | validation: 0.018127126859611258]
	TIME [epoch: 8.34 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030773243196775407		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.030773243196775407 | validation: 0.06860203501826712]
	TIME [epoch: 8.34 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838564712035926		[learning rate: 0.0065255]
	Learning Rate: 0.00652552
	LOSS [training: 0.03838564712035926 | validation: 0.02611328214723231]
	TIME [epoch: 8.36 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019916032610189448		[learning rate: 0.0065101]
	Learning Rate: 0.00651013
	LOSS [training: 0.019916032610189448 | validation: 0.018355128822875738]
	TIME [epoch: 8.36 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06053432284063463		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.06053432284063463 | validation: 0.034588685676839315]
	TIME [epoch: 8.34 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037224683929744054		[learning rate: 0.0064795]
	Learning Rate: 0.00647945
	LOSS [training: 0.037224683929744054 | validation: 0.02309394693186141]
	TIME [epoch: 8.34 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03395361983218993		[learning rate: 0.0064642]
	Learning Rate: 0.00646417
	LOSS [training: 0.03395361983218993 | validation: 0.025644860001592752]
	TIME [epoch: 8.34 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02158943875612935		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.02158943875612935 | validation: 0.019442602333044134]
	TIME [epoch: 8.35 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020870393316231778		[learning rate: 0.0064337]
	Learning Rate: 0.00643371
	LOSS [training: 0.020870393316231778 | validation: 0.021238471004277913]
	TIME [epoch: 8.38 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033146222714793706		[learning rate: 0.0064185]
	Learning Rate: 0.00641853
	LOSS [training: 0.033146222714793706 | validation: 0.1192191948334206]
	TIME [epoch: 8.34 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15091942031851877		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.15091942031851877 | validation: 0.040822633478986944]
	TIME [epoch: 8.34 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03347864728263799		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.03347864728263799 | validation: 0.01887391433141188]
	TIME [epoch: 8.34 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023827896524512043		[learning rate: 0.0063732]
	Learning Rate: 0.00637322
	LOSS [training: 0.023827896524512043 | validation: 0.020877712505852346]
	TIME [epoch: 8.35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019155081220514802		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.019155081220514802 | validation: 0.015611221786133736]
	TIME [epoch: 8.39 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02825467786759904		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.02825467786759904 | validation: 0.019587150703679335]
	TIME [epoch: 8.34 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03084176438714046		[learning rate: 0.0063282]
	Learning Rate: 0.00632823
	LOSS [training: 0.03084176438714046 | validation: 0.04406536101311511]
	TIME [epoch: 8.34 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033904275335235164		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.033904275335235164 | validation: 0.017744654035123823]
	TIME [epoch: 8.34 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018981652109982008		[learning rate: 0.0062984]
	Learning Rate: 0.00629841
	LOSS [training: 0.018981652109982008 | validation: 0.18631859466849837]
	TIME [epoch: 8.34 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861819239071387		[learning rate: 0.0062836]
	Learning Rate: 0.00628355
	LOSS [training: 0.0861819239071387 | validation: 0.03668424669140525]
	TIME [epoch: 8.38 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211239877321278		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.0211239877321278 | validation: 0.015011924163257553]
	TIME [epoch: 8.34 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596780830183717		[learning rate: 0.0062539]
	Learning Rate: 0.00625394
	LOSS [training: 0.03596780830183717 | validation: 0.028240483696874506]
	TIME [epoch: 8.34 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022579655463759306		[learning rate: 0.0062392]
	Learning Rate: 0.00623919
	LOSS [training: 0.022579655463759306 | validation: 0.018105165971066414]
	TIME [epoch: 8.33 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025279907156589523		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.025279907156589523 | validation: 0.017377851459030334]
	TIME [epoch: 8.34 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919061119456853		[learning rate: 0.0062098]
	Learning Rate: 0.00620979
	LOSS [training: 0.03919061119456853 | validation: 0.025544227713867856]
	TIME [epoch: 8.38 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142273782085374		[learning rate: 0.0061951]
	Learning Rate: 0.00619514
	LOSS [training: 0.04142273782085374 | validation: 0.023306398155720352]
	TIME [epoch: 8.35 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018603730405722878		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.018603730405722878 | validation: 0.013282524977186273]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382049757377517		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.06382049757377517 | validation: 0.11778140695141671]
	TIME [epoch: 8.33 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237758165937315		[learning rate: 0.0061514]
	Learning Rate: 0.00615141
	LOSS [training: 0.07237758165937315 | validation: 0.026107810929215294]
	TIME [epoch: 8.33 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02124071412885088		[learning rate: 0.0061369]
	Learning Rate: 0.0061369
	LOSS [training: 0.02124071412885088 | validation: 0.015105377071422642]
	TIME [epoch: 8.37 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021828487979851287		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.021828487979851287 | validation: 0.013727272205829021]
	TIME [epoch: 8.34 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02702241110897552		[learning rate: 0.006108]
	Learning Rate: 0.00610798
	LOSS [training: 0.02702241110897552 | validation: 0.022926069718779148]
	TIME [epoch: 8.33 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043653423535756034		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.043653423535756034 | validation: 0.04030332022744554]
	TIME [epoch: 8.34 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942085131189862		[learning rate: 0.0060792]
	Learning Rate: 0.0060792
	LOSS [training: 0.02942085131189862 | validation: 0.013691564406722905]
	TIME [epoch: 8.34 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013966769590015872		[learning rate: 0.0060649]
	Learning Rate: 0.00606486
	LOSS [training: 0.013966769590015872 | validation: 0.015267806606363907]
	TIME [epoch: 8.38 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030575235112436927		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.030575235112436927 | validation: 0.04215320997661527]
	TIME [epoch: 8.35 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040771694407958824		[learning rate: 0.0060363]
	Learning Rate: 0.00603628
	LOSS [training: 0.040771694407958824 | validation: 0.015326851582544529]
	TIME [epoch: 8.33 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0285473536702581		[learning rate: 0.006022]
	Learning Rate: 0.00602204
	LOSS [training: 0.0285473536702581 | validation: 0.018435525034397604]
	TIME [epoch: 8.33 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037717165256179366		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.037717165256179366 | validation: 0.015694150443711426]
	TIME [epoch: 8.33 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026020791650417114		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.026020791650417114 | validation: 0.014497361631973803]
	TIME [epoch: 8.37 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09220159451496199		[learning rate: 0.0059795]
	Learning Rate: 0.00597952
	LOSS [training: 0.09220159451496199 | validation: 0.04845596255651433]
	TIME [epoch: 8.34 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046986960188799394		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.046986960188799394 | validation: 0.021649984364296732]
	TIME [epoch: 8.33 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026158140358447213		[learning rate: 0.0059513]
	Learning Rate: 0.00595135
	LOSS [training: 0.026158140358447213 | validation: 0.0169095969981382]
	TIME [epoch: 8.33 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024860604298843698		[learning rate: 0.0059373]
	Learning Rate: 0.00593731
	LOSS [training: 0.024860604298843698 | validation: 0.014369241578359794]
	TIME [epoch: 8.33 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016610961600464928		[learning rate: 0.0059233]
	Learning Rate: 0.00592331
	LOSS [training: 0.016610961600464928 | validation: 0.017338282864106887]
	TIME [epoch: 8.36 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026675018180272535		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.026675018180272535 | validation: 0.032807058997644155]
	TIME [epoch: 8.36 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094535241939772		[learning rate: 0.0058954]
	Learning Rate: 0.00589539
	LOSS [training: 0.03094535241939772 | validation: 0.025620780057997537]
	TIME [epoch: 8.33 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02355322243634744		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.02355322243634744 | validation: 0.024963035262441112]
	TIME [epoch: 8.34 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022668127787234583		[learning rate: 0.0058676]
	Learning Rate: 0.00586761
	LOSS [training: 0.022668127787234583 | validation: 0.027336444781766035]
	TIME [epoch: 8.33 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117243622016685		[learning rate: 0.0058538]
	Learning Rate: 0.00585377
	LOSS [training: 0.05117243622016685 | validation: 0.10782937831575086]
	TIME [epoch: 8.36 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621316737735176		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.05621316737735176 | validation: 0.02553634017564941]
	TIME [epoch: 8.36 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018092668934337183		[learning rate: 0.0058262]
	Learning Rate: 0.00582619
	LOSS [training: 0.018092668934337183 | validation: 0.014408576699137936]
	TIME [epoch: 8.34 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016556940478841466		[learning rate: 0.0058124]
	Learning Rate: 0.00581245
	LOSS [training: 0.016556940478841466 | validation: 0.023068538779360086]
	TIME [epoch: 8.33 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02100634964433878		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.02100634964433878 | validation: 0.022246645012181248]
	TIME [epoch: 8.34 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019142408469952906		[learning rate: 0.0057851]
	Learning Rate: 0.00578506
	LOSS [training: 0.019142408469952906 | validation: 0.017845768099386806]
	TIME [epoch: 8.34 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04322196684496092		[learning rate: 0.0057714]
	Learning Rate: 0.00577141
	LOSS [training: 0.04322196684496092 | validation: 0.08473870601437306]
	TIME [epoch: 8.38 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820344867108038		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.04820344867108038 | validation: 0.02222104362293226]
	TIME [epoch: 8.33 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020001545680925298		[learning rate: 0.0057442]
	Learning Rate: 0.00574422
	LOSS [training: 0.020001545680925298 | validation: 0.020812619729985757]
	TIME [epoch: 8.33 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019101217267550263		[learning rate: 0.0057307]
	Learning Rate: 0.00573067
	LOSS [training: 0.019101217267550263 | validation: 0.011708574237094514]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015836841636860007		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.015836841636860007 | validation: 0.03999809522109189]
	TIME [epoch: 8.34 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060911837121767884		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.060911837121767884 | validation: 0.046059132842644374]
	TIME [epoch: 8.38 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034733096899973		[learning rate: 0.0056902]
	Learning Rate: 0.00569021
	LOSS [training: 0.034733096899973 | validation: 0.01868879614703685]
	TIME [epoch: 8.34 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029765908086737763		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.029765908086737763 | validation: 0.04374224550520332]
	TIME [epoch: 8.34 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380114205556842		[learning rate: 0.0056634]
	Learning Rate: 0.0056634
	LOSS [training: 0.03380114205556842 | validation: 0.013798157077133078]
	TIME [epoch: 8.33 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02665116221830866		[learning rate: 0.00565]
	Learning Rate: 0.00565004
	LOSS [training: 0.02665116221830866 | validation: 0.01694064913581022]
	TIME [epoch: 8.34 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024899823774062815		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.024899823774062815 | validation: 0.049981933954998205]
	TIME [epoch: 8.39 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713420109056872		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.03713420109056872 | validation: 0.01989146921785138]
	TIME [epoch: 8.34 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01999072630240256		[learning rate: 0.0056101]
	Learning Rate: 0.00561015
	LOSS [training: 0.01999072630240256 | validation: 0.08279305582325808]
	TIME [epoch: 8.33 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345951348565766		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.04345951348565766 | validation: 0.019557581655413787]
	TIME [epoch: 8.34 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0195936883109408		[learning rate: 0.0055837]
	Learning Rate: 0.00558371
	LOSS [training: 0.0195936883109408 | validation: 0.021351660686034238]
	TIME [epoch: 8.34 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027762821209823978		[learning rate: 0.0055705]
	Learning Rate: 0.00557054
	LOSS [training: 0.027762821209823978 | validation: 0.057635400236314374]
	TIME [epoch: 8.38 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04215139880658273		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.04215139880658273 | validation: 0.01894213966142763]
	TIME [epoch: 8.34 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01862898149495485		[learning rate: 0.0055443]
	Learning Rate: 0.00554429
	LOSS [training: 0.01862898149495485 | validation: 0.013942184010673575]
	TIME [epoch: 8.34 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01364459698054351		[learning rate: 0.0055312]
	Learning Rate: 0.00553121
	LOSS [training: 0.01364459698054351 | validation: 0.013790680047481262]
	TIME [epoch: 8.34 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03866666196240219		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.03866666196240219 | validation: 0.05907515936355759]
	TIME [epoch: 8.34 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241494988708003		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.04241494988708003 | validation: 0.018089969403985485]
	TIME [epoch: 8.38 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015912558387773147		[learning rate: 0.0054922]
	Learning Rate: 0.00549216
	LOSS [training: 0.015912558387773147 | validation: 0.2296995685248659]
	TIME [epoch: 8.35 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265708067280381		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.1265708067280381 | validation: 0.036746828388369956]
	TIME [epoch: 8.34 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124564352771707		[learning rate: 0.0054663]
	Learning Rate: 0.00546629
	LOSS [training: 0.03124564352771707 | validation: 0.015991263275905877]
	TIME [epoch: 8.34 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02120661470409141		[learning rate: 0.0054534]
	Learning Rate: 0.00545339
	LOSS [training: 0.02120661470409141 | validation: 0.019481562702464907]
	TIME [epoch: 8.35 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01475072765789456		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.01475072765789456 | validation: 0.011638855415687648]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017967993598506364		[learning rate: 0.0054277]
	Learning Rate: 0.00542769
	LOSS [training: 0.017967993598506364 | validation: 0.024296121254566032]
	TIME [epoch: 8.35 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029669266262973747		[learning rate: 0.0054149]
	Learning Rate: 0.00541489
	LOSS [training: 0.029669266262973747 | validation: 0.01404345830059955]
	TIME [epoch: 8.34 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02108891772662211		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.02108891772662211 | validation: 0.021134361167275503]
	TIME [epoch: 8.33 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046256212308600886		[learning rate: 0.0053894]
	Learning Rate: 0.00538938
	LOSS [training: 0.046256212308600886 | validation: 0.03953816578267713]
	TIME [epoch: 8.34 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034344081797765845		[learning rate: 0.0053767]
	Learning Rate: 0.00537666
	LOSS [training: 0.034344081797765845 | validation: 0.034066235014075]
	TIME [epoch: 8.37 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025809149178976882		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.025809149178976882 | validation: 0.014787553221759675]
	TIME [epoch: 8.34 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02256917357157813		[learning rate: 0.0053513]
	Learning Rate: 0.00535133
	LOSS [training: 0.02256917357157813 | validation: 0.012563305787049]
	TIME [epoch: 8.33 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03911224989776872		[learning rate: 0.0053387]
	Learning Rate: 0.00533871
	LOSS [training: 0.03911224989776872 | validation: 0.020704246037959284]
	TIME [epoch: 8.34 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020424566052296197		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.020424566052296197 | validation: 0.011001631216505579]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012220850653965373		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.012220850653965373 | validation: 0.016225132183038102]
	TIME [epoch: 8.38 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019850710805508015		[learning rate: 0.005301]
	Learning Rate: 0.00530101
	LOSS [training: 0.019850710805508015 | validation: 0.037460932351256845]
	TIME [epoch: 8.35 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020613651858530403		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.020613651858530403 | validation: 0.011222122942762643]
	TIME [epoch: 8.33 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029962984311807994		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.029962984311807994 | validation: 0.07932478801575285]
	TIME [epoch: 8.33 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683914808728385		[learning rate: 0.0052636]
	Learning Rate: 0.00526359
	LOSS [training: 0.04683914808728385 | validation: 0.019081712216620493]
	TIME [epoch: 8.33 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01618360963837742		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.01618360963837742 | validation: 0.009311481900124648]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016427862650444866		[learning rate: 0.0052388]
	Learning Rate: 0.00523879
	LOSS [training: 0.016427862650444866 | validation: 0.042362048597235386]
	TIME [epoch: 8.34 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02472317944563846		[learning rate: 0.0052264]
	Learning Rate: 0.00522643
	LOSS [training: 0.02472317944563846 | validation: 0.014176513710467565]
	TIME [epoch: 8.33 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01658857729762222		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.01658857729762222 | validation: 0.021317613496081564]
	TIME [epoch: 8.33 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019522566123458422		[learning rate: 0.0052018]
	Learning Rate: 0.0052018
	LOSS [training: 0.019522566123458422 | validation: 0.009986242802318837]
	TIME [epoch: 8.33 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015410738068164506		[learning rate: 0.0051895]
	Learning Rate: 0.00518953
	LOSS [training: 0.015410738068164506 | validation: 0.015167492028955107]
	TIME [epoch: 8.36 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025210413437012247		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.025210413437012247 | validation: 0.016374540055419547]
	TIME [epoch: 8.35 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018849642462287968		[learning rate: 0.0051651]
	Learning Rate: 0.00516508
	LOSS [training: 0.018849642462287968 | validation: 0.03047279429348952]
	TIME [epoch: 8.33 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01808617224106329		[learning rate: 0.0051529]
	Learning Rate: 0.00515289
	LOSS [training: 0.01808617224106329 | validation: 0.01129855205379899]
	TIME [epoch: 8.33 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02315242769743453		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.02315242769743453 | validation: 0.016319601313655334]
	TIME [epoch: 8.33 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020558424170567077		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.020558424170567077 | validation: 0.03120364829157786]
	TIME [epoch: 8.35 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314701597787189		[learning rate: 0.0051165]
	Learning Rate: 0.00511652
	LOSS [training: 0.02314701597787189 | validation: 0.01854298742796985]
	TIME [epoch: 8.35 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01826383037987568		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.01826383037987568 | validation: 0.014850967324149412]
	TIME [epoch: 8.33 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028670009386988698		[learning rate: 0.0050924]
	Learning Rate: 0.00509241
	LOSS [training: 0.028670009386988698 | validation: 0.016403806476027925]
	TIME [epoch: 8.33 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018484805947937367		[learning rate: 0.0050804]
	Learning Rate: 0.00508039
	LOSS [training: 0.018484805947937367 | validation: 0.018532437298850162]
	TIME [epoch: 8.34 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043709794281503664		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.043709794281503664 | validation: 0.0380525089722545]
	TIME [epoch: 8.34 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03112134016561316		[learning rate: 0.0050565]
	Learning Rate: 0.00505645
	LOSS [training: 0.03112134016561316 | validation: 0.015027102992628692]
	TIME [epoch: 8.37 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01565135429003634		[learning rate: 0.0050445]
	Learning Rate: 0.00504453
	LOSS [training: 0.01565135429003634 | validation: 0.010936333716609509]
	TIME [epoch: 8.33 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011996538953924427		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.011996538953924427 | validation: 0.01902485963253728]
	TIME [epoch: 8.33 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026415602469058507		[learning rate: 0.0050208]
	Learning Rate: 0.00502076
	LOSS [training: 0.026415602469058507 | validation: 0.012699552221436722]
	TIME [epoch: 8.33 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03617964530752367		[learning rate: 0.0050089]
	Learning Rate: 0.00500891
	LOSS [training: 0.03617964530752367 | validation: 0.021694231604744568]
	TIME [epoch: 8.34 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017390965924668277		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.017390965924668277 | validation: 0.015028991705751898]
	TIME [epoch: 8.37 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011901477740800224		[learning rate: 0.0049853]
	Learning Rate: 0.00498531
	LOSS [training: 0.011901477740800224 | validation: 0.025614165657936457]
	TIME [epoch: 8.33 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605176652268047		[learning rate: 0.0049736]
	Learning Rate: 0.00497355
	LOSS [training: 0.03605176652268047 | validation: 0.05840650917401134]
	TIME [epoch: 8.33 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039901946205781816		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.039901946205781816 | validation: 0.01569217322309413]
	TIME [epoch: 8.33 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710450167338058		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.01710450167338058 | validation: 0.016211898365007114]
	TIME [epoch: 8.33 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021917070426407153		[learning rate: 0.0049384]
	Learning Rate: 0.00493844
	LOSS [training: 0.021917070426407153 | validation: 0.01597790665835648]
	TIME [epoch: 8.38 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016254335509148947		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.016254335509148947 | validation: 0.009132540070638859]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009301833830886461		[learning rate: 0.0049152]
	Learning Rate: 0.00491517
	LOSS [training: 0.009301833830886461 | validation: 0.01681546703203011]
	TIME [epoch: 8.33 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021793554311608163		[learning rate: 0.0049036]
	Learning Rate: 0.00490357
	LOSS [training: 0.021793554311608163 | validation: 0.016320533321285337]
	TIME [epoch: 8.33 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864671418095132		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.02864671418095132 | validation: 0.03689030629887589]
	TIME [epoch: 8.33 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510127402347096		[learning rate: 0.0048805]
	Learning Rate: 0.00488047
	LOSS [training: 0.03510127402347096 | validation: 0.015627608973704542]
	TIME [epoch: 8.38 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015218828012584729		[learning rate: 0.004869]
	Learning Rate: 0.00486896
	LOSS [training: 0.015218828012584729 | validation: 0.011606271366541698]
	TIME [epoch: 8.33 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011675479916358714		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.011675479916358714 | validation: 0.01070810080752717]
	TIME [epoch: 8.33 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01570053958783304		[learning rate: 0.004846]
	Learning Rate: 0.00484601
	LOSS [training: 0.01570053958783304 | validation: 0.011119925942966576]
	TIME [epoch: 8.33 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0245028336476481		[learning rate: 0.0048346]
	Learning Rate: 0.00483458
	LOSS [training: 0.0245028336476481 | validation: 0.023439047732447024]
	TIME [epoch: 8.33 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030785004013779017		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.030785004013779017 | validation: 0.013100127328702447]
	TIME [epoch: 8.37 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01251943517779831		[learning rate: 0.0048118]
	Learning Rate: 0.0048118
	LOSS [training: 0.01251943517779831 | validation: 0.008505803469691223]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008475184658525575		[learning rate: 0.0048005]
	Learning Rate: 0.00480045
	LOSS [training: 0.008475184658525575 | validation: 0.01416044858292249]
	TIME [epoch: 8.33 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06104335944157144		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.06104335944157144 | validation: 0.020797711769337]
	TIME [epoch: 8.33 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022757492931359685		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.022757492931359685 | validation: 0.010997283196425338]
	TIME [epoch: 8.33 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01121137876939982		[learning rate: 0.0047666]
	Learning Rate: 0.00476656
	LOSS [training: 0.01121137876939982 | validation: 0.02057546366852117]
	TIME [epoch: 8.38 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029747045169450696		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.029747045169450696 | validation: 0.01029695303960057]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051243353317366		[learning rate: 0.0047441]
	Learning Rate: 0.0047441
	LOSS [training: 0.04051243353317366 | validation: 0.015833334908324087]
	TIME [epoch: 8.33 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01513986378713225		[learning rate: 0.0047329]
	Learning Rate: 0.00473291
	LOSS [training: 0.01513986378713225 | validation: 0.01274824525875392]
	TIME [epoch: 8.34 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009808821916524959		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.009808821916524959 | validation: 0.015592617482588493]
	TIME [epoch: 8.33 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017942701914481867		[learning rate: 0.0047106]
	Learning Rate: 0.00471061
	LOSS [training: 0.017942701914481867 | validation: 0.00940097319060862]
	TIME [epoch: 8.37 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012198002652298616		[learning rate: 0.0046995]
	Learning Rate: 0.0046995
	LOSS [training: 0.012198002652298616 | validation: 0.006544397066263417]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015079293671437843		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.015079293671437843 | validation: 0.015086776005986083]
	TIME [epoch: 8.34 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016472948526355558		[learning rate: 0.0046774]
	Learning Rate: 0.00467735
	LOSS [training: 0.016472948526355558 | validation: 0.009791755207971342]
	TIME [epoch: 8.35 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015257982696901174		[learning rate: 0.0046663]
	Learning Rate: 0.00466632
	LOSS [training: 0.015257982696901174 | validation: 0.012433252947194745]
	TIME [epoch: 8.34 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027941481997517226		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.027941481997517226 | validation: 0.032729205872280634]
	TIME [epoch: 8.38 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021411120913671068		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.021411120913671068 | validation: 0.013882501878773278]
	TIME [epoch: 8.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013757221549288556		[learning rate: 0.0046334]
	Learning Rate: 0.00463338
	LOSS [training: 0.013757221549288556 | validation: 0.016843071977726103]
	TIME [epoch: 8.34 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01540504990575486		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.01540504990575486 | validation: 0.0064841991474205865]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011933926712885732		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.011933926712885732 | validation: 0.00936105194145348]
	TIME [epoch: 8.34 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00963014958314829		[learning rate: 0.0046007]
	Learning Rate: 0.00460066
	LOSS [training: 0.00963014958314829 | validation: 0.02296713801483814]
	TIME [epoch: 8.38 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353785882210124		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.03353785882210124 | validation: 0.03473875266670694]
	TIME [epoch: 8.36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033667314307773887		[learning rate: 0.004579]
	Learning Rate: 0.00457899
	LOSS [training: 0.033667314307773887 | validation: 0.015372079296774178]
	TIME [epoch: 8.34 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027685753405384223		[learning rate: 0.0045682]
	Learning Rate: 0.00456818
	LOSS [training: 0.027685753405384223 | validation: 0.015336413777335143]
	TIME [epoch: 8.34 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652952697785817		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.01652952697785817 | validation: 0.016258748206132122]
	TIME [epoch: 8.34 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014950609201842593		[learning rate: 0.0045467]
	Learning Rate: 0.00454666
	LOSS [training: 0.014950609201842593 | validation: 0.009521746126782533]
	TIME [epoch: 8.36 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008581505282773034		[learning rate: 0.0045359]
	Learning Rate: 0.00453593
	LOSS [training: 0.008581505282773034 | validation: 0.008944495304324153]
	TIME [epoch: 8.38 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008379795683942594		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.008379795683942594 | validation: 0.011823251341349837]
	TIME [epoch: 8.34 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016301513573077936		[learning rate: 0.0045146]
	Learning Rate: 0.00451456
	LOSS [training: 0.016301513573077936 | validation: 0.007613603611992205]
	TIME [epoch: 8.35 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013571648945268713		[learning rate: 0.0045039]
	Learning Rate: 0.00450391
	LOSS [training: 0.013571648945268713 | validation: 0.059807693966583864]
	TIME [epoch: 8.34 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03444453372913561		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.03444453372913561 | validation: 0.027557845540778617]
	TIME [epoch: 8.35 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014552622107918863		[learning rate: 0.0044827]
	Learning Rate: 0.00448269
	LOSS [training: 0.014552622107918863 | validation: 0.00909766351870804]
	TIME [epoch: 8.39 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008057894135293881		[learning rate: 0.0044721]
	Learning Rate: 0.00447211
	LOSS [training: 0.008057894135293881 | validation: 0.013365538787313964]
	TIME [epoch: 8.34 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014875009164824546		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.014875009164824546 | validation: 0.012427338935558531]
	TIME [epoch: 8.34 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00908719137385278		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.00908719137385278 | validation: 0.011196778864230882]
	TIME [epoch: 8.34 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042694184994671085		[learning rate: 0.0044405]
	Learning Rate: 0.00444054
	LOSS [training: 0.042694184994671085 | validation: 0.01640689238153062]
	TIME [epoch: 8.35 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01288498860880236		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.01288498860880236 | validation: 0.007996368088575874]
	TIME [epoch: 8.39 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010909390844421328		[learning rate: 0.0044196]
	Learning Rate: 0.00441962
	LOSS [training: 0.010909390844421328 | validation: 0.023634723294013428]
	TIME [epoch: 8.35 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014457175860853416		[learning rate: 0.0044092]
	Learning Rate: 0.00440919
	LOSS [training: 0.014457175860853416 | validation: 0.01229083783472542]
	TIME [epoch: 8.34 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01747160974604639		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.01747160974604639 | validation: 0.009838270478067295]
	TIME [epoch: 8.34 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030133337585579886		[learning rate: 0.0043884]
	Learning Rate: 0.00438841
	LOSS [training: 0.030133337585579886 | validation: 0.006578312728550687]
	TIME [epoch: 8.35 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020132091471455005		[learning rate: 0.0043781]
	Learning Rate: 0.00437806
	LOSS [training: 0.020132091471455005 | validation: 0.020096429188774065]
	TIME [epoch: 8.39 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013177436816137342		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.013177436816137342 | validation: 0.014000639954728654]
	TIME [epoch: 8.34 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014869205111386737		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.014869205111386737 | validation: 0.009111272369678975]
	TIME [epoch: 8.34 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011091385592149974		[learning rate: 0.0043472]
	Learning Rate: 0.00434715
	LOSS [training: 0.011091385592149974 | validation: 0.00814919775009681]
	TIME [epoch: 8.34 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011578002782301039		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.011578002782301039 | validation: 0.03306994324968007]
	TIME [epoch: 8.34 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574807329314107		[learning rate: 0.0043267]
	Learning Rate: 0.00432667
	LOSS [training: 0.03574807329314107 | validation: 0.060093998917847585]
	TIME [epoch: 8.39 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090017406956569		[learning rate: 0.0043165]
	Learning Rate: 0.00431646
	LOSS [training: 0.03090017406956569 | validation: 0.11326550086952128]
	TIME [epoch: 8.35 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765994245709598		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.08765994245709598 | validation: 0.027898344091956954]
	TIME [epoch: 8.34 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019017740378100754		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.019017740378100754 | validation: 0.008349950731047896]
	TIME [epoch: 8.34 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011250043759902972		[learning rate: 0.004286]
	Learning Rate: 0.00428599
	LOSS [training: 0.011250043759902972 | validation: 0.013599110747243359]
	TIME [epoch: 8.34 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00994601266729803		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.00994601266729803 | validation: 0.006744223597009665]
	TIME [epoch: 8.39 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006765068361638611		[learning rate: 0.0042658]
	Learning Rate: 0.0042658
	LOSS [training: 0.006765068361638611 | validation: 0.004359336417402519]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007919989887441808		[learning rate: 0.0042557]
	Learning Rate: 0.00425573
	LOSS [training: 0.007919989887441808 | validation: 0.008470536013772262]
	TIME [epoch: 8.34 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021380174638406003		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.021380174638406003 | validation: 0.009031296879248312]
	TIME [epoch: 8.34 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0208633582356572		[learning rate: 0.0042357]
	Learning Rate: 0.00423568
	LOSS [training: 0.0208633582356572 | validation: 0.016632255722637018]
	TIME [epoch: 8.34 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016336349821282556		[learning rate: 0.0042257]
	Learning Rate: 0.00422569
	LOSS [training: 0.016336349821282556 | validation: 0.012717991444704608]
	TIME [epoch: 8.38 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00856802815151602		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.00856802815151602 | validation: 0.02319265897481606]
	TIME [epoch: 8.34 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722308378666395		[learning rate: 0.0042058]
	Learning Rate: 0.00420578
	LOSS [training: 0.07722308378666395 | validation: 0.07529444200455582]
	TIME [epoch: 8.34 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04392659994538478		[learning rate: 0.0041959]
	Learning Rate: 0.00419585
	LOSS [training: 0.04392659994538478 | validation: 0.01539856124180742]
	TIME [epoch: 8.34 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016145553943442734		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.016145553943442734 | validation: 0.00859512061889777]
	TIME [epoch: 8.33 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007403706975344162		[learning rate: 0.0041761]
	Learning Rate: 0.00417608
	LOSS [training: 0.007403706975344162 | validation: 0.00567418057706429]
	TIME [epoch: 8.37 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013607290958826984		[learning rate: 0.0041662]
	Learning Rate: 0.00416623
	LOSS [training: 0.013607290958826984 | validation: 0.013266563451657429]
	TIME [epoch: 8.35 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018849503998621488		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.018849503998621488 | validation: 0.010341914948753462]
	TIME [epoch: 8.34 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014760095032201681		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.014760095032201681 | validation: 0.013564054580781923]
	TIME [epoch: 8.33 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031758441597371394		[learning rate: 0.0041368]
	Learning Rate: 0.00413682
	LOSS [training: 0.031758441597371394 | validation: 0.0161809720019757]
	TIME [epoch: 8.34 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009202913716915314		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.009202913716915314 | validation: 0.006197170651298744]
	TIME [epoch: 8.37 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009147526583530671		[learning rate: 0.0041173]
	Learning Rate: 0.00411733
	LOSS [training: 0.009147526583530671 | validation: 0.01663354020228014]
	TIME [epoch: 8.35 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040441732505392305		[learning rate: 0.0041076]
	Learning Rate: 0.00410762
	LOSS [training: 0.040441732505392305 | validation: 0.015658852473981456]
	TIME [epoch: 8.33 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017728866942586595		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.017728866942586595 | validation: 0.025365425872060362]
	TIME [epoch: 8.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01667013077642806		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.01667013077642806 | validation: 0.011390870470922205]
	TIME [epoch: 8.34 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015536234699894031		[learning rate: 0.0040786]
	Learning Rate: 0.00407862
	LOSS [training: 0.015536234699894031 | validation: 0.024369416453268063]
	TIME [epoch: 8.35 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01767032592646304		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.01767032592646304 | validation: 0.007386068649960064]
	TIME [epoch: 8.35 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009872365290244715		[learning rate: 0.0040594]
	Learning Rate: 0.0040594
	LOSS [training: 0.009872365290244715 | validation: 0.010561554134885265]
	TIME [epoch: 8.32 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218483578503849		[learning rate: 0.0040498]
	Learning Rate: 0.00404982
	LOSS [training: 0.03218483578503849 | validation: 0.016373466251501434]
	TIME [epoch: 8.32 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021444124009161764		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.021444124009161764 | validation: 0.007825860085444053]
	TIME [epoch: 8.33 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01807378424596774		[learning rate: 0.0040307]
	Learning Rate: 0.00403074
	LOSS [training: 0.01807378424596774 | validation: 0.00970251596400977]
	TIME [epoch: 8.36 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008475939521944309		[learning rate: 0.0040212]
	Learning Rate: 0.00402123
	LOSS [training: 0.008475939521944309 | validation: 0.009485903198863804]
	TIME [epoch: 8.37 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007586352065852755		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.007586352065852755 | validation: 0.0038273741028369266]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01629462599956804		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.01629462599956804 | validation: 0.010115137608640605]
	TIME [epoch: 8.34 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008009828674272128		[learning rate: 0.0039928]
	Learning Rate: 0.00399284
	LOSS [training: 0.008009828674272128 | validation: 0.011881217166010608]
	TIME [epoch: 8.34 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021152681922066055		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.021152681922066055 | validation: 0.015459510133190711]
	TIME [epoch: 8.34 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014383132570672797		[learning rate: 0.003974]
	Learning Rate: 0.00397403
	LOSS [training: 0.014383132570672797 | validation: 0.007547720859220517]
	TIME [epoch: 8.39 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056751332328698854		[learning rate: 0.0039647]
	Learning Rate: 0.00396465
	LOSS [training: 0.056751332328698854 | validation: 0.09505193308544815]
	TIME [epoch: 8.34 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10782828192344801		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.10782828192344801 | validation: 0.01421184722352257]
	TIME [epoch: 8.34 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016742790684900505		[learning rate: 0.003946]
	Learning Rate: 0.00394597
	LOSS [training: 0.016742790684900505 | validation: 0.008345776294763624]
	TIME [epoch: 8.33 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015727624737565365		[learning rate: 0.0039367]
	Learning Rate: 0.00393666
	LOSS [training: 0.015727624737565365 | validation: 0.01886387042735602]
	TIME [epoch: 8.34 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023205397701809724		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.023205397701809724 | validation: 0.008122102244909491]
	TIME [epoch: 8.38 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008142929930282348		[learning rate: 0.0039181]
	Learning Rate: 0.00391811
	LOSS [training: 0.008142929930282348 | validation: 0.004614856453477982]
	TIME [epoch: 8.33 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004671043621245904		[learning rate: 0.0039089]
	Learning Rate: 0.00390887
	LOSS [training: 0.004671043621245904 | validation: 0.0024990815654295185]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034408684098785145		[learning rate: 0.0038996]
	Learning Rate: 0.00389965
	LOSS [training: 0.0034408684098785145 | validation: 0.004897258804188991]
	TIME [epoch: 8.33 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024737778259539267		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.024737778259539267 | validation: 0.03711359713639033]
	TIME [epoch: 8.34 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023051813410128505		[learning rate: 0.0038813]
	Learning Rate: 0.00388127
	LOSS [training: 0.023051813410128505 | validation: 0.00975792881330688]
	TIME [epoch: 8.38 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009357966303152727		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.009357966303152727 | validation: 0.008944241495692515]
	TIME [epoch: 8.33 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945331753814508		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.07945331753814508 | validation: 0.035129509001961115]
	TIME [epoch: 8.33 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025586240576899125		[learning rate: 0.0038539]
	Learning Rate: 0.00385387
	LOSS [training: 0.025586240576899125 | validation: 0.006915856712140847]
	TIME [epoch: 8.33 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006145533599379763		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.006145533599379763 | validation: 0.004200678669199355]
	TIME [epoch: 8.33 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010242498821371643		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.010242498821371643 | validation: 0.014621493384892503]
	TIME [epoch: 8.38 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007348982338632774		[learning rate: 0.0038267]
	Learning Rate: 0.00382667
	LOSS [training: 0.007348982338632774 | validation: 0.005486723978014403]
	TIME [epoch: 8.33 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009003395249081654		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.009003395249081654 | validation: 0.008379388714923561]
	TIME [epoch: 8.24 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024875330311386654		[learning rate: 0.0038086]
	Learning Rate: 0.00380863
	LOSS [training: 0.024875330311386654 | validation: 0.03186165036694475]
	TIME [epoch: 8.31 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01475361033782611		[learning rate: 0.0037996]
	Learning Rate: 0.00379965
	LOSS [training: 0.01475361033782611 | validation: 0.007076611028101144]
	TIME [epoch: 8.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007934910146048293		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.007934910146048293 | validation: 0.005355148969799797]
	TIME [epoch: 8.37 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011789666421293837		[learning rate: 0.0037817]
	Learning Rate: 0.00378175
	LOSS [training: 0.011789666421293837 | validation: 0.00593872340158366]
	TIME [epoch: 8.34 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005925599384031132		[learning rate: 0.0037728]
	Learning Rate: 0.00377283
	LOSS [training: 0.005925599384031132 | validation: 0.003921860683360664]
	TIME [epoch: 8.33 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00649699004981035		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.00649699004981035 | validation: 0.007237357758258741]
	TIME [epoch: 8.32 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037314855786260905		[learning rate: 0.003755]
	Learning Rate: 0.00375505
	LOSS [training: 0.037314855786260905 | validation: 0.010016041391098518]
	TIME [epoch: 8.34 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009088488006532051		[learning rate: 0.0037462]
	Learning Rate: 0.00374619
	LOSS [training: 0.009088488006532051 | validation: 0.005753986942055141]
	TIME [epoch: 8.37 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004588334510735184		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.004588334510735184 | validation: 0.01960111905200234]
	TIME [epoch: 8.35 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016149854647316428		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.016149854647316428 | validation: 0.0071954156246393204]
	TIME [epoch: 8.33 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006410776264898346		[learning rate: 0.0037197]
	Learning Rate: 0.00371974
	LOSS [training: 0.006410776264898346 | validation: 0.006873124065281951]
	TIME [epoch: 8.33 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009795252233214174		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.009795252233214174 | validation: 0.007289956175881755]
	TIME [epoch: 8.33 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008889668680309585		[learning rate: 0.0037022]
	Learning Rate: 0.00370221
	LOSS [training: 0.008889668680309585 | validation: 0.00524334961037807]
	TIME [epoch: 8.36 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010395382339655927		[learning rate: 0.0036935]
	Learning Rate: 0.00369348
	LOSS [training: 0.010395382339655927 | validation: 0.009251966472051105]
	TIME [epoch: 8.33 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01265042702595083		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.01265042702595083 | validation: 0.006332605468421739]
	TIME [epoch: 8.31 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004067411685619304		[learning rate: 0.0036761]
	Learning Rate: 0.00367608
	LOSS [training: 0.004067411685619304 | validation: 0.03026587013710192]
	TIME [epoch: 8.33 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025525057187332886		[learning rate: 0.0036674]
	Learning Rate: 0.00366741
	LOSS [training: 0.025525057187332886 | validation: 0.007519257326117147]
	TIME [epoch: 8.31 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008879716726664027		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.008879716726664027 | validation: 0.004122635864946945]
	TIME [epoch: 8.36 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04452763863773622		[learning rate: 0.0036501]
	Learning Rate: 0.00365012
	LOSS [training: 0.04452763863773622 | validation: 0.018014093599700493]
	TIME [epoch: 8.36 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017970064400723643		[learning rate: 0.0036415]
	Learning Rate: 0.00364151
	LOSS [training: 0.017970064400723643 | validation: 0.008730680225839225]
	TIME [epoch: 8.33 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008453227772640955		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.008453227772640955 | validation: 0.011562582270140806]
	TIME [epoch: 8.33 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008152941286608695		[learning rate: 0.0036244]
	Learning Rate: 0.00362436
	LOSS [training: 0.008152941286608695 | validation: 0.004979063889459892]
	TIME [epoch: 8.34 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008039438576073428		[learning rate: 0.0036158]
	Learning Rate: 0.00361581
	LOSS [training: 0.008039438576073428 | validation: 0.005942843776042295]
	TIME [epoch: 8.35 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006148985036003253		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.006148985036003253 | validation: 0.01091655535032578]
	TIME [epoch: 8.35 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012637283089634783		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.012637283089634783 | validation: 0.010307673908829751]
	TIME [epoch: 8.32 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0131404686943206		[learning rate: 0.0035903]
	Learning Rate: 0.00359028
	LOSS [training: 0.0131404686943206 | validation: 0.015733581598866855]
	TIME [epoch: 8.32 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015148142566931146		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.015148142566931146 | validation: 0.022296644083182424]
	TIME [epoch: 8.33 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040704982432127876		[learning rate: 0.0035734]
	Learning Rate: 0.00357336
	LOSS [training: 0.040704982432127876 | validation: 0.014877904259926545]
	TIME [epoch: 8.34 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007861903329361571		[learning rate: 0.0035649]
	Learning Rate: 0.00356493
	LOSS [training: 0.007861903329361571 | validation: 0.007524107735567467]
	TIME [epoch: 8.37 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00556394067706016		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.00556394067706016 | validation: 0.003146957247712176]
	TIME [epoch: 8.34 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007374610036194353		[learning rate: 0.0035481]
	Learning Rate: 0.00354813
	LOSS [training: 0.007374610036194353 | validation: 0.012314738547561658]
	TIME [epoch: 8.33 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009470529388612812		[learning rate: 0.0035398]
	Learning Rate: 0.00353976
	LOSS [training: 0.009470529388612812 | validation: 0.009312267217136242]
	TIME [epoch: 8.33 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00937101787425977		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.00937101787425977 | validation: 0.009893464998442642]
	TIME [epoch: 8.34 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01525630602034683		[learning rate: 0.0035231]
	Learning Rate: 0.00352308
	LOSS [training: 0.01525630602034683 | validation: 0.01122319721855949]
	TIME [epoch: 8.39 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008296343280334718		[learning rate: 0.0035148]
	Learning Rate: 0.00351477
	LOSS [training: 0.008296343280334718 | validation: 0.0044597430284432455]
	TIME [epoch: 8.34 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00787067969157925		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.00787067969157925 | validation: 0.0053773037681857745]
	TIME [epoch: 8.34 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006574793750297214		[learning rate: 0.0034982]
	Learning Rate: 0.00349821
	LOSS [training: 0.006574793750297214 | validation: 0.0074172701477964835]
	TIME [epoch: 8.33 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005093622263002785		[learning rate: 0.00349]
	Learning Rate: 0.00348996
	LOSS [training: 0.005093622263002785 | validation: 0.00647264833041434]
	TIME [epoch: 8.34 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393464442253287		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.03393464442253287 | validation: 0.008194645997683296]
	TIME [epoch: 8.39 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006723108755652954		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.006723108755652954 | validation: 0.00553962447802198]
	TIME [epoch: 8.29 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006416443665758365		[learning rate: 0.0034653]
	Learning Rate: 0.00346532
	LOSS [training: 0.006416443665758365 | validation: 0.003426020301323068]
	TIME [epoch: 8.32 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005743603324698471		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.005743603324698471 | validation: 0.004460754483049524]
	TIME [epoch: 8.33 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006292853934340755		[learning rate: 0.003449]
	Learning Rate: 0.00344899
	LOSS [training: 0.006292853934340755 | validation: 0.030871012071443993]
	TIME [epoch: 8.33 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653553755655942		[learning rate: 0.0034409]
	Learning Rate: 0.00344086
	LOSS [training: 0.01653553755655942 | validation: 0.011191848836795571]
	TIME [epoch: 8.48 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030488094724806587		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.030488094724806587 | validation: 0.02949654132684467]
	TIME [epoch: 8.34 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011598853011161814		[learning rate: 0.0034246]
	Learning Rate: 0.00342464
	LOSS [training: 0.011598853011161814 | validation: 0.0037764502835952118]
	TIME [epoch: 8.32 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007064913482249316		[learning rate: 0.0034166]
	Learning Rate: 0.00341657
	LOSS [training: 0.007064913482249316 | validation: 0.014118183001140646]
	TIME [epoch: 8.33 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009762759142597626		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.009762759142597626 | validation: 0.008746466440415716]
	TIME [epoch: 8.32 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00968699760813928		[learning rate: 0.0034005]
	Learning Rate: 0.00340047
	LOSS [training: 0.00968699760813928 | validation: 0.0036516002960889945]
	TIME [epoch: 8.39 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004541019695628393		[learning rate: 0.0033924]
	Learning Rate: 0.00339244
	LOSS [training: 0.004541019695628393 | validation: 0.0028895301740772183]
	TIME [epoch: 8.34 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046130462083891054		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.0046130462083891054 | validation: 0.004522303414042664]
	TIME [epoch: 8.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018949124062361947		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.018949124062361947 | validation: 0.009809404428190043]
	TIME [epoch: 8.33 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006612332570188437		[learning rate: 0.0033685]
	Learning Rate: 0.0033685
	LOSS [training: 0.006612332570188437 | validation: 0.00486502088163665]
	TIME [epoch: 8.33 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009915153360006722		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.009915153360006722 | validation: 0.0043156788833890935]
	TIME [epoch: 8.35 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009662180931360773		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.009662180931360773 | validation: 0.017894381164880416]
	TIME [epoch: 8.35 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013517050657366494		[learning rate: 0.0033447]
	Learning Rate: 0.00334471
	LOSS [training: 0.013517050657366494 | validation: 0.005766718818422792]
	TIME [epoch: 8.32 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00579465609454382		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.00579465609454382 | validation: 0.0038250360816315804]
	TIME [epoch: 8.33 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004269104990360462		[learning rate: 0.003329]
	Learning Rate: 0.00332895
	LOSS [training: 0.004269104990360462 | validation: 0.004675313548764536]
	TIME [epoch: 8.33 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008328710862742804		[learning rate: 0.0033211]
	Learning Rate: 0.0033211
	LOSS [training: 0.008328710862742804 | validation: 0.0037779312602741486]
	TIME [epoch: 8.36 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004040016284817148		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.004040016284817148 | validation: 0.02690009836647069]
	TIME [epoch: 8.36 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02186063646713114		[learning rate: 0.0033055]
	Learning Rate: 0.00330545
	LOSS [training: 0.02186063646713114 | validation: 0.01696690107015956]
	TIME [epoch: 8.33 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320148048787566		[learning rate: 0.0032977]
	Learning Rate: 0.00329765
	LOSS [training: 0.026320148048787566 | validation: 0.012698292168859253]
	TIME [epoch: 8.33 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008434570393363698		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.008434570393363698 | validation: 0.0049723729965024015]
	TIME [epoch: 8.33 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056566704707663625		[learning rate: 0.0032821]
	Learning Rate: 0.00328212
	LOSS [training: 0.0056566704707663625 | validation: 0.006568159445405228]
	TIME [epoch: 8.36 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005987456038223661		[learning rate: 0.0032744]
	Learning Rate: 0.00327437
	LOSS [training: 0.005987456038223661 | validation: 0.010956366801038044]
	TIME [epoch: 8.37 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008831746657822525		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.008831746657822525 | validation: 0.007856842588377756]
	TIME [epoch: 8.31 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019037477225727923		[learning rate: 0.0032589]
	Learning Rate: 0.00325894
	LOSS [training: 0.019037477225727923 | validation: 0.025709635392926776]
	TIME [epoch: 8.32 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01678564165206621		[learning rate: 0.0032513]
	Learning Rate: 0.00325126
	LOSS [training: 0.01678564165206621 | validation: 0.006993427074615492]
	TIME [epoch: 8.33 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010445605948152702		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.010445605948152702 | validation: 0.006928003338359832]
	TIME [epoch: 8.32 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037870977739990134		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.0037870977739990134 | validation: 0.002755662531790585]
	TIME [epoch: 8.38 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016403346077813415		[learning rate: 0.0032283]
	Learning Rate: 0.0032283
	LOSS [training: 0.016403346077813415 | validation: 0.02297514765338274]
	TIME [epoch: 8.34 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01604571342509651		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.01604571342509651 | validation: 0.006685218782018125]
	TIME [epoch: 8.32 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007119432799440269		[learning rate: 0.0032131]
	Learning Rate: 0.00321309
	LOSS [training: 0.007119432799440269 | validation: 0.003901920521219771]
	TIME [epoch: 8.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006127877102591175		[learning rate: 0.0032055]
	Learning Rate: 0.00320551
	LOSS [training: 0.006127877102591175 | validation: 0.00652195589886603]
	TIME [epoch: 8.32 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016064082213429164		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.016064082213429164 | validation: 0.014517378543009385]
	TIME [epoch: 8.37 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015078879232491455		[learning rate: 0.0031904]
	Learning Rate: 0.00319041
	LOSS [training: 0.015078879232491455 | validation: 0.0072432166851924985]
	TIME [epoch: 8.33 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006978328299567927		[learning rate: 0.0031829]
	Learning Rate: 0.00318288
	LOSS [training: 0.006978328299567927 | validation: 0.004544450705584787]
	TIME [epoch: 8.34 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005889407870675626		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.005889407870675626 | validation: 0.005428344796635346]
	TIME [epoch: 8.33 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006716540241822932		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.006716540241822932 | validation: 0.03700734841441643]
	TIME [epoch: 8.43 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022349788252426707		[learning rate: 0.0031604]
	Learning Rate: 0.00316041
	LOSS [training: 0.022349788252426707 | validation: 0.0042481338094308195]
	TIME [epoch: 8.39 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005012242705014776		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.005012242705014776 | validation: 0.008926941571816447]
	TIME [epoch: 8.34 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011951614471560727		[learning rate: 0.0031455]
	Learning Rate: 0.00314552
	LOSS [training: 0.011951614471560727 | validation: 0.006461332632456374]
	TIME [epoch: 8.34 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006130996248793392		[learning rate: 0.0031381]
	Learning Rate: 0.0031381
	LOSS [training: 0.006130996248793392 | validation: 0.008184498026629947]
	TIME [epoch: 8.34 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634299193235169		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.03634299193235169 | validation: 0.008863476713072985]
	TIME [epoch: 8.33 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010574411686530089		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.010574411686530089 | validation: 0.028319075844987086]
	TIME [epoch: 8.38 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01923680524162297		[learning rate: 0.0031159]
	Learning Rate: 0.00311594
	LOSS [training: 0.01923680524162297 | validation: 0.00532097661763726]
	TIME [epoch: 8.34 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051015641486049776		[learning rate: 0.0031086]
	Learning Rate: 0.0031086
	LOSS [training: 0.0051015641486049776 | validation: 0.01473352796504477]
	TIME [epoch: 8.34 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007311337284441403		[learning rate: 0.0031013]
	Learning Rate: 0.00310126
	LOSS [training: 0.007311337284441403 | validation: 0.006894060654844944]
	TIME [epoch: 8.33 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013233826053775561		[learning rate: 0.0030939]
	Learning Rate: 0.00309395
	LOSS [training: 0.013233826053775561 | validation: 0.004164258328848458]
	TIME [epoch: 8.34 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004456215934703711		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.004456215934703711 | validation: 0.018285617389809286]
	TIME [epoch: 8.35 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010816958029053289		[learning rate: 0.0030794]
	Learning Rate: 0.00307937
	LOSS [training: 0.010816958029053289 | validation: 0.0022673847846399497]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004466421292549395		[learning rate: 0.0030721]
	Learning Rate: 0.0030721
	LOSS [training: 0.004466421292549395 | validation: 0.004579672608006294]
	TIME [epoch: 8.43 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02052678038002336		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.02052678038002336 | validation: 0.01159383335723449]
	TIME [epoch: 8.34 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008426466113282842		[learning rate: 0.0030576]
	Learning Rate: 0.00305763
	LOSS [training: 0.008426466113282842 | validation: 0.003917114671348187]
	TIME [epoch: 8.32 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038638263423288887		[learning rate: 0.0030504]
	Learning Rate: 0.00305042
	LOSS [training: 0.0038638263423288887 | validation: 0.004897134215362388]
	TIME [epoch: 8.37 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959411665191458		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.05959411665191458 | validation: 0.015908627378857558]
	TIME [epoch: 8.33 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01511818690278941		[learning rate: 0.003036]
	Learning Rate: 0.00303604
	LOSS [training: 0.01511818690278941 | validation: 0.0071177129692841104]
	TIME [epoch: 8.32 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007163012935490315		[learning rate: 0.0030289]
	Learning Rate: 0.00302888
	LOSS [training: 0.007163012935490315 | validation: 0.00442314011512159]
	TIME [epoch: 8.32 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004792735010159354		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.004792735010159354 | validation: 0.003304820392577835]
	TIME [epoch: 8.34 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033879877417425947		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.0033879877417425947 | validation: 0.004137992701982333]
	TIME [epoch: 8.38 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049633894627935105		[learning rate: 0.0030075]
	Learning Rate: 0.0030075
	LOSS [training: 0.0049633894627935105 | validation: 0.007159205588705475]
	TIME [epoch: 8.36 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018613184199293347		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.018613184199293347 | validation: 0.024618554766076654]
	TIME [epoch: 8.34 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012782662466258782		[learning rate: 0.0029933]
	Learning Rate: 0.00299332
	LOSS [training: 0.012782662466258782 | validation: 0.005037709279887824]
	TIME [epoch: 8.34 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034972691718867708		[learning rate: 0.0029863]
	Learning Rate: 0.00298626
	LOSS [training: 0.0034972691718867708 | validation: 0.003634338144419388]
	TIME [epoch: 8.35 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008424305130518246		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.008424305130518246 | validation: 0.005085223553089855]
	TIME [epoch: 8.34 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008236908733322728		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.008236908733322728 | validation: 0.00436051632893122]
	TIME [epoch: 8.34 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019333543431073116		[learning rate: 0.0029652]
	Learning Rate: 0.00296518
	LOSS [training: 0.019333543431073116 | validation: 0.011211603127292042]
	TIME [epoch: 8.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00778682168590011		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.00778682168590011 | validation: 0.003110688643478304]
	TIME [epoch: 8.32 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024178547881798817		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.0024178547881798817 | validation: 0.003504298304181]
	TIME [epoch: 8.31 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034675229638290546		[learning rate: 0.0029442]
	Learning Rate: 0.00294425
	LOSS [training: 0.0034675229638290546 | validation: 0.0023338313746952156]
	TIME [epoch: 8.36 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060100448292613184		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.0060100448292613184 | validation: 0.0041422561804924166]
	TIME [epoch: 8.36 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005682151904879125		[learning rate: 0.0029304]
	Learning Rate: 0.00293037
	LOSS [training: 0.005682151904879125 | validation: 0.016066763047633027]
	TIME [epoch: 8.29 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001100484200193		[learning rate: 0.0029235]
	Learning Rate: 0.00292346
	LOSS [training: 0.02001100484200193 | validation: 0.011322003389865673]
	TIME [epoch: 8.31 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01349244671772139		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.01349244671772139 | validation: 0.008421166929444475]
	TIME [epoch: 8.32 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006821095567228886		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.006821095567228886 | validation: 0.034873711608142816]
	TIME [epoch: 8.33 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022042130871400972		[learning rate: 0.0029028]
	Learning Rate: 0.00290282
	LOSS [training: 0.022042130871400972 | validation: 0.006523482905400446]
	TIME [epoch: 8.38 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01962664674183137		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.01962664674183137 | validation: 0.0055984605713047565]
	TIME [epoch: 8.34 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00615565319800801		[learning rate: 0.0028891]
	Learning Rate: 0.00288914
	LOSS [training: 0.00615565319800801 | validation: 0.0057433845473736245]
	TIME [epoch: 8.34 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004802519176970004		[learning rate: 0.0028823]
	Learning Rate: 0.00288233
	LOSS [training: 0.004802519176970004 | validation: 0.0051025181416637835]
	TIME [epoch: 8.34 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004396773559268584		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.004396773559268584 | validation: 0.002813299227279957]
	TIME [epoch: 8.34 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037985313677941983		[learning rate: 0.0028687]
	Learning Rate: 0.00286875
	LOSS [training: 0.0037985313677941983 | validation: 0.00952667005857022]
	TIME [epoch: 8.39 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012869860896507589		[learning rate: 0.002862]
	Learning Rate: 0.00286198
	LOSS [training: 0.012869860896507589 | validation: 0.013757121104948446]
	TIME [epoch: 8.35 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008563039268008043		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.008563039268008043 | validation: 0.004192606531435882]
	TIME [epoch: 8.34 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004799068657420661		[learning rate: 0.0028485]
	Learning Rate: 0.00284849
	LOSS [training: 0.004799068657420661 | validation: 0.003993512910659297]
	TIME [epoch: 8.33 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004692676910778636		[learning rate: 0.0028418]
	Learning Rate: 0.00284178
	LOSS [training: 0.004692676910778636 | validation: 0.009070809830370627]
	TIME [epoch: 8.34 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005407117707517202		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.005407117707517202 | validation: 0.005095162305137833]
	TIME [epoch: 8.39 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010920679703732212		[learning rate: 0.0028284]
	Learning Rate: 0.00282838
	LOSS [training: 0.010920679703732212 | validation: 0.006571548543237271]
	TIME [epoch: 8.34 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009634376752878582		[learning rate: 0.0028217]
	Learning Rate: 0.00282171
	LOSS [training: 0.009634376752878582 | validation: 0.004796785436387574]
	TIME [epoch: 8.34 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007788932460595524		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.007788932460595524 | validation: 0.005653807278576612]
	TIME [epoch: 8.34 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004529014004380924		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.004529014004380924 | validation: 0.004530939243510276]
	TIME [epoch: 8.34 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010342738318755398		[learning rate: 0.0028018]
	Learning Rate: 0.00280179
	LOSS [training: 0.010342738318755398 | validation: 0.010608082539855204]
	TIME [epoch: 8.38 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009894920169898501		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.009894920169898501 | validation: 0.0073684412227699525]
	TIME [epoch: 8.32 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006194315621169981		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.006194315621169981 | validation: 0.003460636168217083]
	TIME [epoch: 8.32 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003201510655418525		[learning rate: 0.002782]
	Learning Rate: 0.00278201
	LOSS [training: 0.003201510655418525 | validation: 0.0018364056938222515]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009875544476591594		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.009875544476591594 | validation: 0.015328304332591735]
	TIME [epoch: 8.44 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011656710921425026		[learning rate: 0.0027689]
	Learning Rate: 0.0027689
	LOSS [training: 0.011656710921425026 | validation: 0.0027513298367149337]
	TIME [epoch: 8.38 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004137486607994664		[learning rate: 0.0027624]
	Learning Rate: 0.00276237
	LOSS [training: 0.004137486607994664 | validation: 0.009620248478317028]
	TIME [epoch: 8.35 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073168076606921146		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.0073168076606921146 | validation: 0.002349095571192619]
	TIME [epoch: 8.34 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004034586946687014		[learning rate: 0.0027494]
	Learning Rate: 0.00274936
	LOSS [training: 0.004034586946687014 | validation: 0.002879546383068872]
	TIME [epoch: 8.34 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006190178744715472		[learning rate: 0.0027429]
	Learning Rate: 0.00274287
	LOSS [training: 0.006190178744715472 | validation: 0.014120894677209372]
	TIME [epoch: 8.34 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008983221139853472		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.008983221139853472 | validation: 0.013440419735290783]
	TIME [epoch: 8.39 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009704693800497283		[learning rate: 0.0027299]
	Learning Rate: 0.00272994
	LOSS [training: 0.009704693800497283 | validation: 0.005200361211013544]
	TIME [epoch: 8.36 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003970034680122947		[learning rate: 0.0027235]
	Learning Rate: 0.00272351
	LOSS [training: 0.003970034680122947 | validation: 0.0035667733100132387]
	TIME [epoch: 8.34 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007819138582673418		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.007819138582673418 | validation: 0.005929856214446041]
	TIME [epoch: 8.34 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036745228201664005		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.0036745228201664005 | validation: 0.0025974331362402414]
	TIME [epoch: 8.33 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049487217227289805		[learning rate: 0.0027043]
	Learning Rate: 0.00270428
	LOSS [training: 0.0049487217227289805 | validation: 0.016040551406860164]
	TIME [epoch: 8.38 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009942932626974115		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.009942932626974115 | validation: 0.006845768775576078]
	TIME [epoch: 8.35 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007763073215469235		[learning rate: 0.0026915]
	Learning Rate: 0.00269153
	LOSS [training: 0.007763073215469235 | validation: 0.0041940177825588254]
	TIME [epoch: 8.34 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02646027903304905		[learning rate: 0.0026852]
	Learning Rate: 0.00268519
	LOSS [training: 0.02646027903304905 | validation: 0.03808049674402861]
	TIME [epoch: 8.32 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023560403191148303		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.023560403191148303 | validation: 0.005228664401315911]
	TIME [epoch: 8.32 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003942911364246467		[learning rate: 0.0026725]
	Learning Rate: 0.00267253
	LOSS [training: 0.003942911364246467 | validation: 0.002724337173465861]
	TIME [epoch: 8.36 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050729473212509		[learning rate: 0.0026662]
	Learning Rate: 0.00266623
	LOSS [training: 0.0050729473212509 | validation: 0.0023189478897705823]
	TIME [epoch: 8.35 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011654747129573647		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.011654747129573647 | validation: 0.005321497074134533]
	TIME [epoch: 8.34 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005397733611640773		[learning rate: 0.0026537]
	Learning Rate: 0.00265367
	LOSS [training: 0.005397733611640773 | validation: 0.0021965896458097816]
	TIME [epoch: 8.34 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003996300281643603		[learning rate: 0.0026474]
	Learning Rate: 0.00264741
	LOSS [training: 0.003996300281643603 | validation: 0.0028373517173683853]
	TIME [epoch: 8.33 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031294328197760336		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.0031294328197760336 | validation: 0.008672256520534438]
	TIME [epoch: 8.35 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00838470191987017		[learning rate: 0.0026349]
	Learning Rate: 0.00263493
	LOSS [training: 0.00838470191987017 | validation: 0.01743664845584743]
	TIME [epoch: 8.37 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017315907705030914		[learning rate: 0.0026287]
	Learning Rate: 0.00262872
	LOSS [training: 0.017315907705030914 | validation: 0.004926266372146239]
	TIME [epoch: 8.33 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536641572465597		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.02536641572465597 | validation: 0.012262316324489375]
	TIME [epoch: 8.33 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006279301006409485		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.006279301006409485 | validation: 0.0026699055608182557]
	TIME [epoch: 8.34 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038043954383622765		[learning rate: 0.0026102]
	Learning Rate: 0.00261016
	LOSS [training: 0.0038043954383622765 | validation: 0.0025634197809520287]
	TIME [epoch: 8.34 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003484258196825738		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.003484258196825738 | validation: 0.0033208891787869623]
	TIME [epoch: 8.36 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005033980538348901		[learning rate: 0.0025979]
	Learning Rate: 0.00259786
	LOSS [training: 0.005033980538348901 | validation: 0.03491262113068215]
	TIME [epoch: 8.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016177473343908014		[learning rate: 0.0025917]
	Learning Rate: 0.00259173
	LOSS [training: 0.016177473343908014 | validation: 0.002423858395623818]
	TIME [epoch: 8.31 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003729516885250054		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.003729516885250054 | validation: 0.0023244132601348906]
	TIME [epoch: 8.29 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023877536707679016		[learning rate: 0.0025795]
	Learning Rate: 0.00257952
	LOSS [training: 0.0023877536707679016 | validation: 0.0032437409011625436]
	TIME [epoch: 8.32 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003997671713360059		[learning rate: 0.0025734]
	Learning Rate: 0.00257343
	LOSS [training: 0.003997671713360059 | validation: 0.004349457514157285]
	TIME [epoch: 8.38 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009201408897147517		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.009201408897147517 | validation: 0.005983097901460391]
	TIME [epoch: 8.33 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004291339522700228		[learning rate: 0.0025613]
	Learning Rate: 0.00256131
	LOSS [training: 0.004291339522700228 | validation: 0.0029811922903699275]
	TIME [epoch: 8.34 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006876447852292338		[learning rate: 0.0025553]
	Learning Rate: 0.00255526
	LOSS [training: 0.006876447852292338 | validation: 0.008692219515421205]
	TIME [epoch: 8.33 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018006634992130316		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.018006634992130316 | validation: 0.007272838431655824]
	TIME [epoch: 8.32 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059414148076184035		[learning rate: 0.0025432]
	Learning Rate: 0.00254322
	LOSS [training: 0.0059414148076184035 | validation: 0.0025134426259579984]
	TIME [epoch: 8.35 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005174608211136767		[learning rate: 0.0025372]
	Learning Rate: 0.00253722
	LOSS [training: 0.005174608211136767 | validation: 0.004864429809397]
	TIME [epoch: 8.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027293017222810613		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.0027293017222810613 | validation: 0.002018437776933468]
	TIME [epoch: 8.31 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028263241534365055		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.0028263241534365055 | validation: 0.006294412924588194]
	TIME [epoch: 8.31 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007348884314133405		[learning rate: 0.0025193]
	Learning Rate: 0.00251931
	LOSS [training: 0.007348884314133405 | validation: 0.00249540596638543]
	TIME [epoch: 8.33 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004623029130348094		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.004623029130348094 | validation: 0.0035076378687377745]
	TIME [epoch: 8.38 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006452232536801481		[learning rate: 0.0025074]
	Learning Rate: 0.00250744
	LOSS [training: 0.006452232536801481 | validation: 0.006385186715535743]
	TIME [epoch: 8.34 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005274839308377671		[learning rate: 0.0025015]
	Learning Rate: 0.00250153
	LOSS [training: 0.005274839308377671 | validation: 0.003701657137812766]
	TIME [epoch: 8.33 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010474564131813895		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.010474564131813895 | validation: 0.01805932888730595]
	TIME [epoch: 8.33 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017071127301748958		[learning rate: 0.0024897]
	Learning Rate: 0.00248974
	LOSS [training: 0.017071127301748958 | validation: 0.005496502901800162]
	TIME [epoch: 8.33 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030977780606439792		[learning rate: 0.0024839]
	Learning Rate: 0.00248387
	LOSS [training: 0.0030977780606439792 | validation: 0.03875880285948066]
	TIME [epoch: 8.37 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031219373024572037		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.031219373024572037 | validation: 0.00525444996833454]
	TIME [epoch: 8.36 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052647469192644		[learning rate: 0.0024722]
	Learning Rate: 0.00247216
	LOSS [training: 0.0052647469192644 | validation: 0.00572151302154012]
	TIME [epoch: 8.33 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030292697965163063		[learning rate: 0.0024663]
	Learning Rate: 0.00246633
	LOSS [training: 0.0030292697965163063 | validation: 0.0017131339790163662]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004637665450643896		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.004637665450643896 | validation: 0.0029145563521867477]
	TIME [epoch: 8.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027199755487258333		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.0027199755487258333 | validation: 0.0019145550992301658]
	TIME [epoch: 8.37 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002356735567039756		[learning rate: 0.0024489]
	Learning Rate: 0.00244892
	LOSS [training: 0.002356735567039756 | validation: 0.010904607087923603]
	TIME [epoch: 8.35 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00786506027817815		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.00786506027817815 | validation: 0.018020401783312323]
	TIME [epoch: 8.33 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01191847916761084		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.01191847916761084 | validation: 0.00225913620987099]
	TIME [epoch: 8.33 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024993866693514342		[learning rate: 0.0024316]
	Learning Rate: 0.00243163
	LOSS [training: 0.0024993866693514342 | validation: 0.002066233843176334]
	TIME [epoch: 8.33 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005495244729174408		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.005495244729174408 | validation: 0.003707374257673396]
	TIME [epoch: 8.37 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006228309969971365		[learning rate: 0.0024202]
	Learning Rate: 0.00242017
	LOSS [training: 0.006228309969971365 | validation: 0.006554508425034344]
	TIME [epoch: 8.35 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005995505311869349		[learning rate: 0.0024145]
	Learning Rate: 0.00241446
	LOSS [training: 0.005995505311869349 | validation: 0.002309467817691007]
	TIME [epoch: 8.33 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018125324691227514		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.018125324691227514 | validation: 0.006602285778265681]
	TIME [epoch: 8.33 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048754680280842806		[learning rate: 0.0024031]
	Learning Rate: 0.00240309
	LOSS [training: 0.0048754680280842806 | validation: 0.0025040024757351413]
	TIME [epoch: 8.34 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020902486978502614		[learning rate: 0.0023974]
	Learning Rate: 0.00239742
	LOSS [training: 0.0020902486978502614 | validation: 0.005164017687142114]
	TIME [epoch: 8.35 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005295205089187653		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.005295205089187653 | validation: 0.0053917330524503]
	TIME [epoch: 8.37 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003767512308420075		[learning rate: 0.0023861]
	Learning Rate: 0.00238612
	LOSS [training: 0.003767512308420075 | validation: 0.0022169734801979796]
	TIME [epoch: 8.33 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026040566036633376		[learning rate: 0.0023805]
	Learning Rate: 0.00238049
	LOSS [training: 0.0026040566036633376 | validation: 0.005555887153934658]
	TIME [epoch: 8.33 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009051641326882383		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.009051641326882383 | validation: 0.006436069100991846]
	TIME [epoch: 8.33 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028913057909330858		[learning rate: 0.0023693]
	Learning Rate: 0.00236927
	LOSS [training: 0.0028913057909330858 | validation: 0.008236247118431716]
	TIME [epoch: 8.35 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008853321415999002		[learning rate: 0.0023637]
	Learning Rate: 0.00236369
	LOSS [training: 0.008853321415999002 | validation: 0.0023893323586043555]
	TIME [epoch: 8.38 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004274922929741772		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.004274922929741772 | validation: 0.0033838785349598233]
	TIME [epoch: 8.31 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018832691379425744		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.0018832691379425744 | validation: 0.002504886692553416]
	TIME [epoch: 8.31 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004592215830333663		[learning rate: 0.002347]
	Learning Rate: 0.002347
	LOSS [training: 0.004592215830333663 | validation: 0.015701762401735132]
	TIME [epoch: 8.34 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012961285935519986		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.012961285935519986 | validation: 0.02712967012812094]
	TIME [epoch: 8.33 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03425721649238914		[learning rate: 0.0023359]
	Learning Rate: 0.00233594
	LOSS [training: 0.03425721649238914 | validation: 0.03490143295661409]
	TIME [epoch: 8.36 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016708115937734497		[learning rate: 0.0023304]
	Learning Rate: 0.00233043
	LOSS [training: 0.016708115937734497 | validation: 0.004367421989750964]
	TIME [epoch: 8.34 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032313512850435156		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.0032313512850435156 | validation: 0.002617164796975713]
	TIME [epoch: 8.34 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004509409367368823		[learning rate: 0.0023194]
	Learning Rate: 0.00231945
	LOSS [training: 0.004509409367368823 | validation: 0.007659405980959548]
	TIME [epoch: 8.33 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003368171181645678		[learning rate: 0.002314]
	Learning Rate: 0.00231398
	LOSS [training: 0.003368171181645678 | validation: 0.0014904549954512607]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025338679258820923		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.0025338679258820923 | validation: 0.0027628510366707612]
	TIME [epoch: 8.49 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005848944309562518		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.005848944309562518 | validation: 0.0054214301214751265]
	TIME [epoch: 8.34 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013442953914124697		[learning rate: 0.0022976]
	Learning Rate: 0.00229764
	LOSS [training: 0.013442953914124697 | validation: 0.0029452737339500288]
	TIME [epoch: 8.33 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028331588694105138		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.0028331588694105138 | validation: 0.0011464960303457744]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002611581386338163		[learning rate: 0.0022868]
	Learning Rate: 0.00228681
	LOSS [training: 0.002611581386338163 | validation: 0.002740810556193681]
	TIME [epoch: 8.43 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005137839371075021		[learning rate: 0.0022814]
	Learning Rate: 0.00228142
	LOSS [training: 0.005137839371075021 | validation: 0.005166094374489082]
	TIME [epoch: 8.37 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004608659657045785		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.004608659657045785 | validation: 0.009446225164753698]
	TIME [epoch: 8.33 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007899045175272809		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.007899045175272809 | validation: 0.003864979788115434]
	TIME [epoch: 8.33 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011534655266573038		[learning rate: 0.0022653]
	Learning Rate: 0.00226531
	LOSS [training: 0.011534655266573038 | validation: 0.0034949825175736218]
	TIME [epoch: 8.32 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004424315643074314		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.004424315643074314 | validation: 0.0020343874941915543]
	TIME [epoch: 8.32 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019925998761251345		[learning rate: 0.0022546]
	Learning Rate: 0.00225464
	LOSS [training: 0.0019925998761251345 | validation: 0.002793122993853572]
	TIME [epoch: 8.39 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002782776477893691		[learning rate: 0.0022493]
	Learning Rate: 0.00224932
	LOSS [training: 0.002782776477893691 | validation: 0.008889227947532129]
	TIME [epoch: 8.34 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006843136698514782		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.006843136698514782 | validation: 0.0028785219658379914]
	TIME [epoch: 8.34 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018709851880720693		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.0018709851880720693 | validation: 0.0031929649927587606]
	TIME [epoch: 8.33 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011364432650868425		[learning rate: 0.0022334]
	Learning Rate: 0.00223344
	LOSS [training: 0.0011364432650868425 | validation: 0.008896429644249759]
	TIME [epoch: 8.32 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008753318558107643		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.008753318558107643 | validation: 0.0032949703796419324]
	TIME [epoch: 8.37 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030085742719508568		[learning rate: 0.0022229]
	Learning Rate: 0.00222292
	LOSS [training: 0.0030085742719508568 | validation: 0.004101775041471619]
	TIME [epoch: 8.33 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054828837699793		[learning rate: 0.0022177]
	Learning Rate: 0.00221767
	LOSS [training: 0.0054828837699793 | validation: 0.002918490593299564]
	TIME [epoch: 8.32 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026788056895274736		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.0026788056895274736 | validation: 0.0019182200304385503]
	TIME [epoch: 8.32 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048115027412916405		[learning rate: 0.0022072]
	Learning Rate: 0.00220722
	LOSS [training: 0.0048115027412916405 | validation: 0.004628269970130004]
	TIME [epoch: 8.32 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034797499655799995		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.0034797499655799995 | validation: 0.002598435700090395]
	TIME [epoch: 8.37 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019634148828269544		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.019634148828269544 | validation: 0.0043445450394723265]
	TIME [epoch: 8.34 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006006660506753974		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.006006660506753974 | validation: 0.00623095374929925]
	TIME [epoch: 8.34 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010833024931427881		[learning rate: 0.0021865]
	Learning Rate: 0.00218647
	LOSS [training: 0.010833024931427881 | validation: 0.009354348185796977]
	TIME [epoch: 8.31 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031148411038494565		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.0031148411038494565 | validation: 0.002180534910255488]
	TIME [epoch: 8.32 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014003682464350936		[learning rate: 0.0021762]
	Learning Rate: 0.00217617
	LOSS [training: 0.0014003682464350936 | validation: 0.0013739048554543302]
	TIME [epoch: 8.36 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002937594605855311		[learning rate: 0.002171]
	Learning Rate: 0.00217103
	LOSS [training: 0.002937594605855311 | validation: 0.0021270359893659804]
	TIME [epoch: 8.33 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001662023130486793		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.001662023130486793 | validation: 0.0011132850124064486]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008159110502927952		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.008159110502927952 | validation: 0.03004523496740933]
	TIME [epoch: 8.44 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021440658489193878		[learning rate: 0.0021557]
	Learning Rate: 0.00215571
	LOSS [training: 0.021440658489193878 | validation: 0.012126469412158707]
	TIME [epoch: 8.63 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005552918630594196		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.005552918630594196 | validation: 0.001403086338808869]
	TIME [epoch: 8.38 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019028151182988997		[learning rate: 0.0021455]
	Learning Rate: 0.00214555
	LOSS [training: 0.0019028151182988997 | validation: 0.0011373997146986938]
	TIME [epoch: 8.43 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037309473997856487		[learning rate: 0.0021405]
	Learning Rate: 0.00214049
	LOSS [training: 0.0037309473997856487 | validation: 0.0019812597520593857]
	TIME [epoch: 8.34 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059944278487011156		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.0059944278487011156 | validation: 0.003056455322569495]
	TIME [epoch: 8.34 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008082280845755373		[learning rate: 0.0021304]
	Learning Rate: 0.0021304
	LOSS [training: 0.008082280845755373 | validation: 0.002306758219819143]
	TIME [epoch: 8.34 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003481716909459201		[learning rate: 0.0021254]
	Learning Rate: 0.00212538
	LOSS [training: 0.003481716909459201 | validation: 0.0018466406235405452]
	TIME [epoch: 8.34 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019949036651055988		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.0019949036651055988 | validation: 0.0043420291540840275]
	TIME [epoch: 8.39 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020939742757145234		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.0020939742757145234 | validation: 0.001931603204509972]
	TIME [epoch: 8.34 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01916343174263286		[learning rate: 0.0021104]
	Learning Rate: 0.00211037
	LOSS [training: 0.01916343174263286 | validation: 0.0034517878951208255]
	TIME [epoch: 8.34 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002710740393076007		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.002710740393076007 | validation: 0.0017285172341165267]
	TIME [epoch: 8.34 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464051891734422		[learning rate: 0.0021004]
	Learning Rate: 0.00210043
	LOSS [training: 0.01464051891734422 | validation: 0.007765984932146065]
	TIME [epoch: 8.34 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014657972554430958		[learning rate: 0.0020955]
	Learning Rate: 0.00209547
	LOSS [training: 0.014657972554430958 | validation: 0.006089576643026234]
	TIME [epoch: 8.38 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004901584676205527		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.004901584676205527 | validation: 0.002411398205916914]
	TIME [epoch: 8.32 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006662042486721805		[learning rate: 0.0020856]
	Learning Rate: 0.0020856
	LOSS [training: 0.006662042486721805 | validation: 0.003609024080363011]
	TIME [epoch: 8.32 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033225034055927066		[learning rate: 0.0020807]
	Learning Rate: 0.00208068
	LOSS [training: 0.0033225034055927066 | validation: 0.0020970740458257377]
	TIME [epoch: 8.34 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001755363768505482		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.001755363768505482 | validation: 0.004318858139721423]
	TIME [epoch: 8.34 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033607801293560778		[learning rate: 0.0020709]
	Learning Rate: 0.00207087
	LOSS [training: 0.0033607801293560778 | validation: 0.0007533910840511001]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014588094248357132		[learning rate: 0.002066]
	Learning Rate: 0.00206599
	LOSS [training: 0.0014588094248357132 | validation: 0.0011411305287085023]
	TIME [epoch: 8.41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048408797969696086		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.0048408797969696086 | validation: 0.0015065385482867638]
	TIME [epoch: 8.35 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015278847006433868		[learning rate: 0.0020563]
	Learning Rate: 0.00205626
	LOSS [training: 0.0015278847006433868 | validation: 0.0052858617446732]
	TIME [epoch: 8.32 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003537753692658048		[learning rate: 0.0020514]
	Learning Rate: 0.0020514
	LOSS [training: 0.003537753692658048 | validation: 0.009422224744790346]
	TIME [epoch: 8.34 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008877373115388516		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.008877373115388516 | validation: 0.004221657029565152]
	TIME [epoch: 8.39 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002423463883158022		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.002423463883158022 | validation: 0.001114313246505286]
	TIME [epoch: 8.35 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019480897815286467		[learning rate: 0.0020369]
	Learning Rate: 0.00203692
	LOSS [training: 0.019480897815286467 | validation: 0.022988414861559066]
	TIME [epoch: 8.34 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01005612343653934		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.01005612343653934 | validation: 0.002990081296784859]
	TIME [epoch: 8.34 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031963702014281836		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.0031963702014281836 | validation: 0.006335578830313906]
	TIME [epoch: 8.34 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004880208915028925		[learning rate: 0.0020225]
	Learning Rate: 0.00202254
	LOSS [training: 0.004880208915028925 | validation: 0.003278685164166679]
	TIME [epoch: 8.39 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003915552643003105		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.003915552643003105 | validation: 0.0033758433003105593]
	TIME [epoch: 8.35 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004066548332292619		[learning rate: 0.002013]
	Learning Rate: 0.00201301
	LOSS [training: 0.004066548332292619 | validation: 0.0004439090709598971]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_729.pth
	Model improved!!!
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008221839999551124		[learning rate: 0.0020083]
	Learning Rate: 0.00200826
	LOSS [training: 0.0008221839999551124 | validation: 0.002796863817656102]
	TIME [epoch: 8.45 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010917534280231703		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.0010917534280231703 | validation: 0.0038922411115576193]
	TIME [epoch: 8.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004964725794190373		[learning rate: 0.0019988]
	Learning Rate: 0.0019988
	LOSS [training: 0.004964725794190373 | validation: 0.0019388460943557263]
	TIME [epoch: 8.35 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003168826591347723		[learning rate: 0.0019941]
	Learning Rate: 0.00199408
	LOSS [training: 0.003168826591347723 | validation: 0.003044058816722996]
	TIME [epoch: 8.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029877875980779175		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.0029877875980779175 | validation: 0.005599626580935496]
	TIME [epoch: 8.33 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003852005696992536		[learning rate: 0.0019847]
	Learning Rate: 0.00198469
	LOSS [training: 0.003852005696992536 | validation: 0.0031819002634961976]
	TIME [epoch: 8.33 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023744117455070934		[learning rate: 0.00198]
	Learning Rate: 0.00198001
	LOSS [training: 0.0023744117455070934 | validation: 0.007797894700608183]
	TIME [epoch: 8.32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006152212972247782		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.006152212972247782 | validation: 0.0010790956598786222]
	TIME [epoch: 8.36 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004446727776520767		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.004446727776520767 | validation: 0.0025894007594543106]
	TIME [epoch: 8.34 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029466063743013734		[learning rate: 0.001966]
	Learning Rate: 0.00196603
	LOSS [training: 0.0029466063743013734 | validation: 0.0026169738637687964]
	TIME [epoch: 8.32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005854839167179375		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.005854839167179375 | validation: 0.0014352682893404869]
	TIME [epoch: 8.31 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020348411345492083		[learning rate: 0.0019568]
	Learning Rate: 0.00195676
	LOSS [training: 0.020348411345492083 | validation: 0.007095658390828681]
	TIME [epoch: 8.33 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004729502901294176		[learning rate: 0.0019521]
	Learning Rate: 0.00195215
	LOSS [training: 0.004729502901294176 | validation: 0.0029927386952403896]
	TIME [epoch: 8.36 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004809242710931866		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.004809242710931866 | validation: 0.0010427472891151224]
	TIME [epoch: 8.37 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017586068025337498		[learning rate: 0.0019429]
	Learning Rate: 0.00194295
	LOSS [training: 0.0017586068025337498 | validation: 0.0014639968058411017]
	TIME [epoch: 8.34 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023985017143812433		[learning rate: 0.0019384]
	Learning Rate: 0.00193837
	LOSS [training: 0.0023985017143812433 | validation: 0.000437843907951768]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002887235725117369		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.002887235725117369 | validation: 0.003029747906437069]
	TIME [epoch: 8.45 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020770273594096036		[learning rate: 0.0019292]
	Learning Rate: 0.00192923
	LOSS [training: 0.0020770273594096036 | validation: 0.0033128625383274466]
	TIME [epoch: 8.36 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020430703920450623		[learning rate: 0.0019247]
	Learning Rate: 0.00192468
	LOSS [training: 0.0020430703920450623 | validation: 0.003941304688721967]
	TIME [epoch: 8.36 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036297833670549604		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.0036297833670549604 | validation: 0.003369963546005719]
	TIME [epoch: 8.33 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032998509347167905		[learning rate: 0.0019156]
	Learning Rate: 0.00191561
	LOSS [training: 0.0032998509347167905 | validation: 0.010247948864796602]
	TIME [epoch: 8.33 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007854219729151228		[learning rate: 0.0019111]
	Learning Rate: 0.00191109
	LOSS [training: 0.007854219729151228 | validation: 0.002074696941065312]
	TIME [epoch: 8.33 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003184720274127889		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.003184720274127889 | validation: 0.0021709024363435136]
	TIME [epoch: 8.35 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001127128489303182		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.001127128489303182 | validation: 0.0005136336072425314]
	TIME [epoch: 8.37 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029038798254439136		[learning rate: 0.0018976]
	Learning Rate: 0.0018976
	LOSS [training: 0.0029038798254439136 | validation: 0.0015721817228031509]
	TIME [epoch: 8.33 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005494535253190364		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.005494535253190364 | validation: 0.008301928866798706]
	TIME [epoch: 8.33 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005478265775350483		[learning rate: 0.0018887]
	Learning Rate: 0.00188866
	LOSS [training: 0.005478265775350483 | validation: 0.0009876260634827858]
	TIME [epoch: 8.31 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020163255899040963		[learning rate: 0.0018842]
	Learning Rate: 0.00188421
	LOSS [training: 0.0020163255899040963 | validation: 0.00294278085044568]
	TIME [epoch: 8.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022715291137372466		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.0022715291137372466 | validation: 0.0033496439491833433]
	TIME [epoch: 8.34 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004291156933252932		[learning rate: 0.0018753]
	Learning Rate: 0.00187533
	LOSS [training: 0.004291156933252932 | validation: 0.0014480872655016192]
	TIME [epoch: 8.33 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016605352300327948		[learning rate: 0.0018709]
	Learning Rate: 0.0018709
	LOSS [training: 0.0016605352300327948 | validation: 0.0061791793180449375]
	TIME [epoch: 8.31 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0091668627209711		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.0091668627209711 | validation: 0.004827736634999594]
	TIME [epoch: 8.32 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004958586996731493		[learning rate: 0.0018621]
	Learning Rate: 0.00186209
	LOSS [training: 0.004958586996731493 | validation: 0.0022092861327712315]
	TIME [epoch: 8.33 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017874344368476913		[learning rate: 0.0018577]
	Learning Rate: 0.00185769
	LOSS [training: 0.0017874344368476913 | validation: 0.006983214120598406]
	TIME [epoch: 8.37 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005062729488453061		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.005062729488453061 | validation: 0.0031418743359197714]
	TIME [epoch: 8.33 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023674420274298266		[learning rate: 0.0018489]
	Learning Rate: 0.00184894
	LOSS [training: 0.0023674420274298266 | validation: 0.0016517060356873474]
	TIME [epoch: 8.25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002362095026245041		[learning rate: 0.0018446]
	Learning Rate: 0.00184458
	LOSS [training: 0.002362095026245041 | validation: 0.0024012936479494186]
	TIME [epoch: 8.33 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003362407100302509		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.003362407100302509 | validation: 0.0033765612699160983]
	TIME [epoch: 8.33 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002810129099764335		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.002810129099764335 | validation: 0.001957973419741472]
	TIME [epoch: 8.38 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030128516616054297		[learning rate: 0.0018316]
	Learning Rate: 0.00183156
	LOSS [training: 0.0030128516616054297 | validation: 0.0026189602105291614]
	TIME [epoch: 8.33 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023804613321388958		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.0023804613321388958 | validation: 0.003357089111556996]
	TIME [epoch: 8.33 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01743381745726744		[learning rate: 0.0018229]
	Learning Rate: 0.00182293
	LOSS [training: 0.01743381745726744 | validation: 0.03813167851038037]
	TIME [epoch: 8.33 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019951582234287127		[learning rate: 0.0018186]
	Learning Rate: 0.00181863
	LOSS [training: 0.019951582234287127 | validation: 0.006669347366573751]
	TIME [epoch: 8.31 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005389484045903224		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.005389484045903224 | validation: 0.00245775336413514]
	TIME [epoch: 8.36 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005485326419232603		[learning rate: 0.0018101]
	Learning Rate: 0.00181006
	LOSS [training: 0.005485326419232603 | validation: 0.008974540608288954]
	TIME [epoch: 8.33 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004838981139776245		[learning rate: 0.0018058]
	Learning Rate: 0.00180579
	LOSS [training: 0.004838981139776245 | validation: 0.0014802219266463663]
	TIME [epoch: 8.31 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018439846883769719		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.0018439846883769719 | validation: 0.003331369129542735]
	TIME [epoch: 8.33 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014534257647380124		[learning rate: 0.0017973]
	Learning Rate: 0.00179728
	LOSS [training: 0.0014534257647380124 | validation: 0.0028341942681899654]
	TIME [epoch: 8.33 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018768174759000902		[learning rate: 0.001793]
	Learning Rate: 0.00179304
	LOSS [training: 0.018768174759000902 | validation: 0.0028806522851155757]
	TIME [epoch: 8.37 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068916799796338996		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.0068916799796338996 | validation: 0.003793054419288499]
	TIME [epoch: 8.35 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002264879501378848		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.002264879501378848 | validation: 0.0029084334681193113]
	TIME [epoch: 8.33 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003440196076159032		[learning rate: 0.0017804]
	Learning Rate: 0.00178038
	LOSS [training: 0.003440196076159032 | validation: 0.0033715797869588223]
	TIME [epoch: 8.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011057191997437311		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.0011057191997437311 | validation: 0.0018937634238032999]
	TIME [epoch: 8.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028349456436986826		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.0028349456436986826 | validation: 0.0012457612905321153]
	TIME [epoch: 8.34 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014963368718866814		[learning rate: 0.0017678]
	Learning Rate: 0.00176781
	LOSS [training: 0.0014963368718866814 | validation: 0.0018683608398262041]
	TIME [epoch: 8.32 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01379116443073069		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.01379116443073069 | validation: 0.0021002372777897812]
	TIME [epoch: 8.32 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003158821343723542		[learning rate: 0.0017595]
	Learning Rate: 0.00175948
	LOSS [training: 0.003158821343723542 | validation: 0.0012165863299123916]
	TIME [epoch: 8.29 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006770473721092505		[learning rate: 0.0017553]
	Learning Rate: 0.00175533
	LOSS [training: 0.0006770473721092505 | validation: 0.0026694439126596936]
	TIME [epoch: 8.31 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005635685040789045		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.005635685040789045 | validation: 0.006438965497127677]
	TIME [epoch: 8.34 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002886118916956787		[learning rate: 0.0017471]
	Learning Rate: 0.00174706
	LOSS [training: 0.002886118916956787 | validation: 0.0016934843890763418]
	TIME [epoch: 8.38 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018098771567158925		[learning rate: 0.0017429]
	Learning Rate: 0.00174294
	LOSS [training: 0.0018098771567158925 | validation: 0.002025596199856653]
	TIME [epoch: 8.33 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021296816421906405		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.0021296816421906405 | validation: 0.001768016634525426]
	TIME [epoch: 8.33 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024150221803526436		[learning rate: 0.0017347]
	Learning Rate: 0.00173473
	LOSS [training: 0.0024150221803526436 | validation: 0.005190709271943805]
	TIME [epoch: 8.33 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003684815842167174		[learning rate: 0.0017306]
	Learning Rate: 0.00173063
	LOSS [training: 0.003684815842167174 | validation: 0.010467292676796169]
	TIME [epoch: 8.34 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007714055106119042		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.007714055106119042 | validation: 0.02072148164679629]
	TIME [epoch: 8.38 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033366837929784454		[learning rate: 0.0017225]
	Learning Rate: 0.00172248
	LOSS [training: 0.033366837929784454 | validation: 0.005957268968127682]
	TIME [epoch: 8.33 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004286200832542959		[learning rate: 0.0017184]
	Learning Rate: 0.00171842
	LOSS [training: 0.004286200832542959 | validation: 0.004678990752875313]
	TIME [epoch: 8.33 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00341364342359093		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.00341364342359093 | validation: 0.002441853823467169]
	TIME [epoch: 8.33 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002148404662723537		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.002148404662723537 | validation: 0.001214856167656758]
	TIME [epoch: 8.34 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007834016795584699		[learning rate: 0.0017063]
	Learning Rate: 0.00170628
	LOSS [training: 0.0007834016795584699 | validation: 0.0008434871982791092]
	TIME [epoch: 8.38 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011354434971569763		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.0011354434971569763 | validation: 0.0006712299231430845]
	TIME [epoch: 8.33 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016661912782639887		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.0016661912782639887 | validation: 0.0013497388242710339]
	TIME [epoch: 8.32 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002033187344416627		[learning rate: 0.0016942]
	Learning Rate: 0.00169424
	LOSS [training: 0.002033187344416627 | validation: 0.0005059106567497729]
	TIME [epoch: 8.43 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012677543620565957		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.0012677543620565957 | validation: 0.00373370966287316]
	TIME [epoch: 8.33 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002641172642145179		[learning rate: 0.0016863]
	Learning Rate: 0.00168625
	LOSS [training: 0.002641172642145179 | validation: 0.0019481863781830248]
	TIME [epoch: 8.37 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021043745882481186		[learning rate: 0.0016823]
	Learning Rate: 0.00168228
	LOSS [training: 0.0021043745882481186 | validation: 0.0018442158760538483]
	TIME [epoch: 8.34 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006291240531565584		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.0006291240531565584 | validation: 0.0026779649281387374]
	TIME [epoch: 8.32 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037070205121285875		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.0037070205121285875 | validation: 0.0019075456653649657]
	TIME [epoch: 8.33 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016424542850412669		[learning rate: 0.0016704]
	Learning Rate: 0.0016704
	LOSS [training: 0.0016424542850412669 | validation: 0.0005781321435920681]
	TIME [epoch: 8.33 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00372304932917053		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.00372304932917053 | validation: 0.0009736431003530522]
	TIME [epoch: 8.38 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003331264155255142		[learning rate: 0.0016625]
	Learning Rate: 0.00166253
	LOSS [training: 0.003331264155255142 | validation: 0.0023950105661212063]
	TIME [epoch: 8.33 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015042895890092904		[learning rate: 0.0016586]
	Learning Rate: 0.00165861
	LOSS [training: 0.0015042895890092904 | validation: 0.0013158547835231196]
	TIME [epoch: 8.32 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00226811440879938		[learning rate: 0.0016547]
	Learning Rate: 0.0016547
	LOSS [training: 0.00226811440879938 | validation: 0.0023207641290113666]
	TIME [epoch: 8.33 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020473543193321175		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.0020473543193321175 | validation: 0.00044657184503882254]
	TIME [epoch: 8.33 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00413105099792104		[learning rate: 0.0016469]
	Learning Rate: 0.0016469
	LOSS [training: 0.00413105099792104 | validation: 0.0021247309190552217]
	TIME [epoch: 8.37 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002402222241920041		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.002402222241920041 | validation: 0.0024971473504015558]
	TIME [epoch: 8.34 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017535791466818116		[learning rate: 0.0016391]
	Learning Rate: 0.00163914
	LOSS [training: 0.0017535791466818116 | validation: 0.003889481858573844]
	TIME [epoch: 8.32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013671505259073515		[learning rate: 0.0016353]
	Learning Rate: 0.00163527
	LOSS [training: 0.013671505259073515 | validation: 0.0042899129932362935]
	TIME [epoch: 8.31 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037941121377147087		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.0037941121377147087 | validation: 0.0012494628879172116]
	TIME [epoch: 8.33 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019472264718084216		[learning rate: 0.0016276]
	Learning Rate: 0.00162757
	LOSS [training: 0.0019472264718084216 | validation: 0.0007788124694502296]
	TIME [epoch: 8.37 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033066078773700924		[learning rate: 0.0016237]
	Learning Rate: 0.00162373
	LOSS [training: 0.0033066078773700924 | validation: 0.0015345307278030206]
	TIME [epoch: 8.34 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010796769502268576		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.0010796769502268576 | validation: 0.0007540441206284033]
	TIME [epoch: 8.33 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001646761143220568		[learning rate: 0.0016161]
	Learning Rate: 0.00161608
	LOSS [training: 0.001646761143220568 | validation: 0.0018944051627484244]
	TIME [epoch: 8.33 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011813292209173942		[learning rate: 0.0016123]
	Learning Rate: 0.00161226
	LOSS [training: 0.0011813292209173942 | validation: 0.011009137148307938]
	TIME [epoch: 8.33 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008468939945835169		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.008468939945835169 | validation: 0.0017102796156834989]
	TIME [epoch: 8.37 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022603701427129667		[learning rate: 0.0016047]
	Learning Rate: 0.00160467
	LOSS [training: 0.0022603701427129667 | validation: 0.00436824617393307]
	TIME [epoch: 8.34 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017518960442658674		[learning rate: 0.0016009]
	Learning Rate: 0.00160088
	LOSS [training: 0.0017518960442658674 | validation: 0.00029696311855687745]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006881578705376879		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.006881578705376879 | validation: 0.001572016720229351]
	TIME [epoch: 8.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004598968024207518		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.004598968024207518 | validation: 0.006592591856478494]
	TIME [epoch: 8.33 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004393515950877075		[learning rate: 0.0015896]
	Learning Rate: 0.00158958
	LOSS [training: 0.004393515950877075 | validation: 0.0013870058059381701]
	TIME [epoch: 8.37 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00194829411973395		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.00194829411973395 | validation: 0.00185330383482912]
	TIME [epoch: 8.34 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010242284485799816		[learning rate: 0.0015821]
	Learning Rate: 0.00158209
	LOSS [training: 0.0010242284485799816 | validation: 0.0020207382602086274]
	TIME [epoch: 8.33 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010377891209624089		[learning rate: 0.0015784]
	Learning Rate: 0.00157836
	LOSS [training: 0.010377891209624089 | validation: 0.00557928031969437]
	TIME [epoch: 8.33 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002715326754740989		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.002715326754740989 | validation: 0.0004491677105826559]
	TIME [epoch: 8.34 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007962457809059482		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.007962457809059482 | validation: 0.004683217316822155]
	TIME [epoch: 8.37 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027076539709315834		[learning rate: 0.0015672]
	Learning Rate: 0.00156721
	LOSS [training: 0.0027076539709315834 | validation: 0.0004851444351381806]
	TIME [epoch: 8.36 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004978232875057282		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.0004978232875057282 | validation: 0.0016559968586276864]
	TIME [epoch: 8.34 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014654587961709178		[learning rate: 0.0015598]
	Learning Rate: 0.00155983
	LOSS [training: 0.0014654587961709178 | validation: 0.0016993989361530324]
	TIME [epoch: 8.34 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010885640452849162		[learning rate: 0.0015561]
	Learning Rate: 0.00155615
	LOSS [training: 0.0010885640452849162 | validation: 0.004979276600346432]
	TIME [epoch: 8.33 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004562140480812466		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.004562140480812466 | validation: 0.0017105677714462462]
	TIME [epoch: 8.35 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008958325483546092		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.0008958325483546092 | validation: 0.0011334643266687583]
	TIME [epoch: 8.37 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017496345021693078		[learning rate: 0.0015452]
	Learning Rate: 0.00154516
	LOSS [training: 0.0017496345021693078 | validation: 0.0003120607959495594]
	TIME [epoch: 8.33 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022161157640178965		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.0022161157640178965 | validation: 0.0016243078809983018]
	TIME [epoch: 8.34 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033753819885930566		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.0033753819885930566 | validation: 0.009119810088066286]
	TIME [epoch: 8.33 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005874099557222081		[learning rate: 0.0015343]
	Learning Rate: 0.00153425
	LOSS [training: 0.005874099557222081 | validation: 0.0007607036331780948]
	TIME [epoch: 8.32 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011494809205272209		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.0011494809205272209 | validation: 0.001886049588313234]
	TIME [epoch: 8.36 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015405127697872792		[learning rate: 0.001527]
	Learning Rate: 0.00152703
	LOSS [training: 0.0015405127697872792 | validation: 0.0015974652608560498]
	TIME [epoch: 8.33 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013246506362943405		[learning rate: 0.0015234]
	Learning Rate: 0.00152342
	LOSS [training: 0.0013246506362943405 | validation: 0.00914219610105382]
	TIME [epoch: 8.32 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005973940795287634		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.005973940795287634 | validation: 0.0021382936652745727]
	TIME [epoch: 8.32 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017391041108502565		[learning rate: 0.0015162]
	Learning Rate: 0.00151624
	LOSS [training: 0.0017391041108502565 | validation: 0.0010024115995660298]
	TIME [epoch: 8.34 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020003831603221476		[learning rate: 0.0015127]
	Learning Rate: 0.00151267
	LOSS [training: 0.0020003831603221476 | validation: 0.0008347933140122517]
	TIME [epoch: 8.38 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001169086105031639		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.001169086105031639 | validation: 0.0008995148421880033]
	TIME [epoch: 8.34 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00269551573025182		[learning rate: 0.0015055]
	Learning Rate: 0.00150554
	LOSS [training: 0.00269551573025182 | validation: 0.0012935170780554762]
	TIME [epoch: 8.33 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010529520138475746		[learning rate: 0.001502]
	Learning Rate: 0.00150199
	LOSS [training: 0.0010529520138475746 | validation: 0.0013050748564365584]
	TIME [epoch: 8.36 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008460974531516268		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.008460974531516268 | validation: 0.005793563726377772]
	TIME [epoch: 8.33 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012829956196263556		[learning rate: 0.0014949]
	Learning Rate: 0.00149491
	LOSS [training: 0.012829956196263556 | validation: 0.0011094313614750167]
	TIME [epoch: 8.39 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017537679523852328		[learning rate: 0.0014914]
	Learning Rate: 0.00149139
	LOSS [training: 0.0017537679523852328 | validation: 0.001880896530184838]
	TIME [epoch: 8.34 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021520268207364415		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.0021520268207364415 | validation: 0.0008086679285252605]
	TIME [epoch: 8.33 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030395968144001206		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.0030395968144001206 | validation: 0.0011378625766402212]
	TIME [epoch: 8.33 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017499468232698204		[learning rate: 0.0014809]
	Learning Rate: 0.00148086
	LOSS [training: 0.0017499468232698204 | validation: 0.0006798093749138227]
	TIME [epoch: 8.33 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011715823511322023		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.0011715823511322023 | validation: 0.003983477402344723]
	TIME [epoch: 8.37 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015881384217565529		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.0015881384217565529 | validation: 0.0007779681860921329]
	TIME [epoch: 8.33 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010142078190855264		[learning rate: 0.0014704]
	Learning Rate: 0.0014704
	LOSS [training: 0.0010142078190855264 | validation: 3.285402672100846e-05]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_862.pth
	Model improved!!!
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004139871480754342		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.004139871480754342 | validation: 0.0028537269977497153]
	TIME [epoch: 8.41 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005755669611100653		[learning rate: 0.0014635]
	Learning Rate: 0.00146347
	LOSS [training: 0.005755669611100653 | validation: 0.007273633955221617]
	TIME [epoch: 8.34 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004017817059671003		[learning rate: 0.00146]
	Learning Rate: 0.00146002
	LOSS [training: 0.004017817059671003 | validation: 0.001834024987263622]
	TIME [epoch: 8.39 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006677641779948591		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.0006677641779948591 | validation: 0.00027175839445990895]
	TIME [epoch: 8.35 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001396580780795316		[learning rate: 0.0014531]
	Learning Rate: 0.00145314
	LOSS [training: 0.001396580780795316 | validation: 0.0021046570772752793]
	TIME [epoch: 8.34 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013855234455793172		[learning rate: 0.0014497]
	Learning Rate: 0.00144971
	LOSS [training: 0.0013855234455793172 | validation: 0.0016071408847789966]
	TIME [epoch: 8.34 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016274394225303222		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.0016274394225303222 | validation: 0.004686069727242585]
	TIME [epoch: 8.34 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008643316520275508		[learning rate: 0.0014429]
	Learning Rate: 0.00144288
	LOSS [training: 0.008643316520275508 | validation: 0.0030645416230729097]
	TIME [epoch: 8.36 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015421178612233452		[learning rate: 0.0014395]
	Learning Rate: 0.00143948
	LOSS [training: 0.0015421178612233452 | validation: 0.0007031013118131577]
	TIME [epoch: 8.38 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007576657164898939		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.0007576657164898939 | validation: 0.0008374116372295206]
	TIME [epoch: 8.34 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007424256173402073		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.0007424256173402073 | validation: 0.003189115961551109]
	TIME [epoch: 8.34 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014697456603708563		[learning rate: 0.0014293]
	Learning Rate: 0.00142932
	LOSS [training: 0.0014697456603708563 | validation: 0.0009198564746310329]
	TIME [epoch: 8.34 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009848137296946367		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.0009848137296946367 | validation: 3.026056207879613e-05]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_875.pth
	Model improved!!!
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013953249130768896		[learning rate: 0.0014226]
	Learning Rate: 0.00142258
	LOSS [training: 0.0013953249130768896 | validation: 0.001349270661178975]
	TIME [epoch: 8.46 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010582473546711113		[learning rate: 0.0014192]
	Learning Rate: 0.00141923
	LOSS [training: 0.0010582473546711113 | validation: 0.003344794877600802]
	TIME [epoch: 8.33 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007043342691640535		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.007043342691640535 | validation: 0.005754109632486598]
	TIME [epoch: 8.33 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044194003167855		[learning rate: 0.0014125]
	Learning Rate: 0.00141254
	LOSS [training: 0.0044194003167855 | validation: 0.0026538155338246424]
	TIME [epoch: 8.34 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017931521089510302		[learning rate: 0.0014092]
	Learning Rate: 0.00140921
	LOSS [training: 0.0017931521089510302 | validation: -2.0495464345656584e-05]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_880.pth
	Model improved!!!
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002442182810215874		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.002442182810215874 | validation: 0.0011937381793550475]
	TIME [epoch: 8.48 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002013072565324528		[learning rate: 0.0014026]
	Learning Rate: 0.00140257
	LOSS [training: 0.002013072565324528 | validation: 0.0018760498662919632]
	TIME [epoch: 8.33 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043559237438034427		[learning rate: 0.0013993]
	Learning Rate: 0.00139926
	LOSS [training: 0.00043559237438034427 | validation: -2.7482722702763416e-05]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017265166342548932		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.0017265166342548932 | validation: 0.0017129144282762763]
	TIME [epoch: 8.42 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001981881334733213		[learning rate: 0.0013927]
	Learning Rate: 0.00139266
	LOSS [training: 0.001981881334733213 | validation: 0.0020761317482720565]
	TIME [epoch: 8.34 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011190407318758036		[learning rate: 0.0013894]
	Learning Rate: 0.00138938
	LOSS [training: 0.0011190407318758036 | validation: 0.0011777598238535295]
	TIME [epoch: 8.38 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015776351339110172		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.0015776351339110172 | validation: 0.0012849758141395351]
	TIME [epoch: 8.33 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004265460269477061		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.004265460269477061 | validation: 0.0015111025360910852]
	TIME [epoch: 8.33 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010441083352158603		[learning rate: 0.0013796]
	Learning Rate: 0.00137957
	LOSS [training: 0.0010441083352158603 | validation: 0.012427874941857472]
	TIME [epoch: 8.33 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016511292364929223		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.016511292364929223 | validation: 0.0011471715670515088]
	TIME [epoch: 8.34 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017298267770995716		[learning rate: 0.0013731]
	Learning Rate: 0.00137307
	LOSS [training: 0.0017298267770995716 | validation: 0.0006705340867532934]
	TIME [epoch: 8.38 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001163289321014327		[learning rate: 0.0013698]
	Learning Rate: 0.00136983
	LOSS [training: 0.001163289321014327 | validation: 0.00353668666370194]
	TIME [epoch: 8.33 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025575575979639754		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.0025575575979639754 | validation: 0.001417640972168191]
	TIME [epoch: 8.33 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001126268907664373		[learning rate: 0.0013634]
	Learning Rate: 0.00136338
	LOSS [training: 0.001126268907664373 | validation: 0.0005225418762349818]
	TIME [epoch: 8.33 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001214132598121241		[learning rate: 0.0013602]
	Learning Rate: 0.00136016
	LOSS [training: 0.001214132598121241 | validation: 0.0015121193700780222]
	TIME [epoch: 8.34 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027256522058071025		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.0027256522058071025 | validation: 0.0025916834838520626]
	TIME [epoch: 8.37 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004109657751056331		[learning rate: 0.0013538]
	Learning Rate: 0.00135375
	LOSS [training: 0.004109657751056331 | validation: 0.002737315580074244]
	TIME [epoch: 8.34 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012688170402286151		[learning rate: 0.0013506]
	Learning Rate: 0.00135056
	LOSS [training: 0.0012688170402286151 | validation: 0.0017972437647315333]
	TIME [epoch: 8.33 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012875024593370224		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.00012875024593370224 | validation: 0.0006770474007160883]
	TIME [epoch: 8.33 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014152389398133644		[learning rate: 0.0013442]
	Learning Rate: 0.00134419
	LOSS [training: 0.0014152389398133644 | validation: 0.0012538295885031773]
	TIME [epoch: 8.33 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.158982269025869e-05		[learning rate: 0.001341]
	Learning Rate: 0.00134102
	LOSS [training: 3.158982269025869e-05 | validation: 0.0017266725554889789]
	TIME [epoch: 8.38 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016725835956128688		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.0016725835956128688 | validation: 0.0013914744673544127]
	TIME [epoch: 8.43 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003263163203265678		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.003263163203265678 | validation: 0.005430035059685994]
	TIME [epoch: 8.33 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036854032487976555		[learning rate: 0.0013316]
	Learning Rate: 0.00133155
	LOSS [training: 0.0036854032487976555 | validation: 0.0013644631965926586]
	TIME [epoch: 8.33 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017536701433786548		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.0017536701433786548 | validation: 0.002539005233737231]
	TIME [epoch: 8.32 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004515652383249905		[learning rate: 0.0013253]
	Learning Rate: 0.00132528
	LOSS [training: 0.004515652383249905 | validation: 0.000987099757691552]
	TIME [epoch: 8.39 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027244074675653552		[learning rate: 0.0013222]
	Learning Rate: 0.00132215
	LOSS [training: 0.0027244074675653552 | validation: 0.003847425105151847]
	TIME [epoch: 8.34 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002877396246014894		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.002877396246014894 | validation: 0.001833101189057312]
	TIME [epoch: 8.33 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001333099378449291		[learning rate: 0.0013159]
	Learning Rate: 0.00131592
	LOSS [training: 0.001333099378449291 | validation: 0.0011198395801822567]
	TIME [epoch: 8.34 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002998455633335881		[learning rate: 0.0013128]
	Learning Rate: 0.00131282
	LOSS [training: 0.002998455633335881 | validation: 0.00418558848018482]
	TIME [epoch: 8.33 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003729499155424738		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.003729499155424738 | validation: 0.0013712511080778507]
	TIME [epoch: 8.37 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015157719577264727		[learning rate: 0.0013066]
	Learning Rate: 0.00130663
	LOSS [training: 0.0015157719577264727 | validation: 0.0023921031819239148]
	TIME [epoch: 8.34 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012175400158863647		[learning rate: 0.0013036]
	Learning Rate: 0.00130355
	LOSS [training: 0.0012175400158863647 | validation: 0.0010062189519311994]
	TIME [epoch: 8.32 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020839056973094103		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.0020839056973094103 | validation: 0.004266956259400553]
	TIME [epoch: 8.33 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026851968835092084		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.0026851968835092084 | validation: 0.0037942804154888396]
	TIME [epoch: 8.33 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032135087505518693		[learning rate: 0.0012943]
	Learning Rate: 0.00129435
	LOSS [training: 0.0032135087505518693 | validation: 0.0030697767607577647]
	TIME [epoch: 8.36 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021955356954006283		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.0021955356954006283 | validation: 0.0034036400193276388]
	TIME [epoch: 8.34 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023869261305242474		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.0023869261305242474 | validation: 0.0017827281268305618]
	TIME [epoch: 8.33 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018918861873444867		[learning rate: 0.0012852]
	Learning Rate: 0.00128521
	LOSS [training: 0.0018918861873444867 | validation: 0.00013018611787569157]
	TIME [epoch: 8.33 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001984721553085825		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.001984721553085825 | validation: 0.0014489475698525626]
	TIME [epoch: 8.32 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005018554970491319		[learning rate: 0.0012792]
	Learning Rate: 0.00127915
	LOSS [training: 0.0005018554970491319 | validation: 0.0029256951170486406]
	TIME [epoch: 8.37 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00345034930043456		[learning rate: 0.0012761]
	Learning Rate: 0.00127614
	LOSS [training: 0.00345034930043456 | validation: 0.0008109312765931014]
	TIME [epoch: 8.34 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004808774236964936		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.004808774236964936 | validation: 0.01025485259194299]
	TIME [epoch: 8.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035468591658166767		[learning rate: 0.0012701]
	Learning Rate: 0.00127012
	LOSS [training: 0.0035468591658166767 | validation: 0.0005044672442977931]
	TIME [epoch: 8.33 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000294470446141849		[learning rate: 0.0012671]
	Learning Rate: 0.00126713
	LOSS [training: 0.000294470446141849 | validation: 0.0008652199014185636]
	TIME [epoch: 8.33 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022103080219143824		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.00022103080219143824 | validation: 0.0026205621313322046]
	TIME [epoch: 8.34 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019968905338598963		[learning rate: 0.0012612]
	Learning Rate: 0.00126116
	LOSS [training: 0.0019968905338598963 | validation: 0.0030126777431167652]
	TIME [epoch: 8.36 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010350986409879655		[learning rate: 0.0012582]
	Learning Rate: 0.00125818
	LOSS [training: 0.0010350986409879655 | validation: 0.0036809589232563657]
	TIME [epoch: 8.32 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021943985480107247		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.0021943985480107247 | validation: 0.0008683339792963429]
	TIME [epoch: 8.33 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013789732621231842		[learning rate: 0.0012523]
	Learning Rate: 0.00125225
	LOSS [training: 0.0013789732621231842 | validation: 0.007081964494821616]
	TIME [epoch: 8.33 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005573340043417355		[learning rate: 0.0012493]
	Learning Rate: 0.0012493
	LOSS [training: 0.005573340043417355 | validation: 0.0021415128131763604]
	TIME [epoch: 8.34 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002547344353965389		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.002547344353965389 | validation: 0.0006905129802594594]
	TIME [epoch: 8.37 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004269249592840855		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.0004269249592840855 | validation: 0.004868822541905806]
	TIME [epoch: 8.32 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046257178660351695		[learning rate: 0.0012405]
	Learning Rate: 0.00124048
	LOSS [training: 0.0046257178660351695 | validation: 0.0006966460990328259]
	TIME [epoch: 8.32 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009840163586907619		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.0009840163586907619 | validation: 7.294139226088879e-05]
	TIME [epoch: 8.33 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023725798541067906		[learning rate: 0.0012346]
	Learning Rate: 0.00123463
	LOSS [training: 0.0023725798541067906 | validation: 0.00339980847824081]
	TIME [epoch: 8.33 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016198280511562873		[learning rate: 0.0012317]
	Learning Rate: 0.00123172
	LOSS [training: 0.0016198280511562873 | validation: 0.0008986431692065064]
	TIME [epoch: 8.37 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005713058103508713		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.0005713058103508713 | validation: 0.0036819455761631426]
	TIME [epoch: 8.33 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019164809408019924		[learning rate: 0.0012259]
	Learning Rate: 0.00122592
	LOSS [training: 0.0019164809408019924 | validation: 0.0017687862291417148]
	TIME [epoch: 8.32 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011638964976681857		[learning rate: 0.001223]
	Learning Rate: 0.00122303
	LOSS [training: 0.0011638964976681857 | validation: 0.0004007360088470193]
	TIME [epoch: 8.32 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006852387459145004		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.0006852387459145004 | validation: 0.0021477761288381915]
	TIME [epoch: 8.33 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017884437401688349		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.0017884437401688349 | validation: 0.0020773652163010286]
	TIME [epoch: 8.38 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010653947350853638		[learning rate: 0.0012144]
	Learning Rate: 0.00121439
	LOSS [training: 0.0010653947350853638 | validation: 0.00035619486952935065]
	TIME [epoch: 8.33 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007710169668801663		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.0007710169668801663 | validation: 0.0022657800604466267]
	TIME [epoch: 8.33 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01103227679266281		[learning rate: 0.0012087]
	Learning Rate: 0.00120867
	LOSS [training: 0.01103227679266281 | validation: 0.0035500229014104236]
	TIME [epoch: 8.33 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001910593546306184		[learning rate: 0.0012058]
	Learning Rate: 0.00120582
	LOSS [training: 0.001910593546306184 | validation: 0.0008145673304285106]
	TIME [epoch: 8.33 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009034226539616847		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.0009034226539616847 | validation: 0.0002633993195010223]
	TIME [epoch: 8.38 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007302443573166133		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.0007302443573166133 | validation: 0.0013347163906967875]
	TIME [epoch: 8.33 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001614319013003878		[learning rate: 0.0011973]
	Learning Rate: 0.00119731
	LOSS [training: 0.001614319013003878 | validation: 0.0010771074211872477]
	TIME [epoch: 8.32 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001775309597277105		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.001775309597277105 | validation: 0.0016525111415234615]
	TIME [epoch: 8.32 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006648989723000056		[learning rate: 0.0011917]
	Learning Rate: 0.00119166
	LOSS [training: 0.0006648989723000056 | validation: 0.000639831380508947]
	TIME [epoch: 8.33 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017551889303863517		[learning rate: 0.0011889]
	Learning Rate: 0.00118885
	LOSS [training: 0.0017551889303863517 | validation: 0.003175335572158608]
	TIME [epoch: 8.37 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025383791136754873		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.0025383791136754873 | validation: 0.0034399454605355184]
	TIME [epoch: 8.34 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002945591215022918		[learning rate: 0.0011833]
	Learning Rate: 0.00118325
	LOSS [training: 0.002945591215022918 | validation: 0.0028953656228115545]
	TIME [epoch: 8.33 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014374292711767617		[learning rate: 0.0011805]
	Learning Rate: 0.00118046
	LOSS [training: 0.0014374292711767617 | validation: 0.0009669406142156301]
	TIME [epoch: 8.33 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020390045909718515		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.00020390045909718515 | validation: 0.0002885995460326804]
	TIME [epoch: 8.33 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.115612725503515e-05		[learning rate: 0.0011749]
	Learning Rate: 0.0011749
	LOSS [training: 6.115612725503515e-05 | validation: 0.0006540833839405544]
	TIME [epoch: 8.37 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010189634405882884		[learning rate: 0.0011721]
	Learning Rate: 0.00117213
	LOSS [training: 0.0010189634405882884 | validation: 0.00046521443852632016]
	TIME [epoch: 8.35 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005232290525384045		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.0005232290525384045 | validation: 0.0007271678061650255]
	TIME [epoch: 8.33 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007562330004096684		[learning rate: 0.0011666]
	Learning Rate: 0.0011666
	LOSS [training: 0.0007562330004096684 | validation: 0.008053761012289922]
	TIME [epoch: 8.32 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057293344305980485		[learning rate: 0.0011639]
	Learning Rate: 0.00116385
	LOSS [training: 0.0057293344305980485 | validation: 0.0024595613659834543]
	TIME [epoch: 8.33 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010431571753535707		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.010431571753535707 | validation: 0.01564453851836574]
	TIME [epoch: 8.37 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010551884180972658		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.010551884180972658 | validation: 0.002082845301127745]
	TIME [epoch: 8.34 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026542520538380765		[learning rate: 0.0011556]
	Learning Rate: 0.00115563
	LOSS [training: 0.0026542520538380765 | validation: 0.0015309505756793272]
	TIME [epoch: 8.33 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009312266388404784		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.0009312266388404784 | validation: 0.0015122141972740684]
	TIME [epoch: 8.32 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006603456629858153		[learning rate: 0.0011502]
	Learning Rate: 0.00115019
	LOSS [training: 0.0006603456629858153 | validation: 0.0019381692225102966]
	TIME [epoch: 8.31 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013382800516794798		[learning rate: 0.0011475]
	Learning Rate: 0.00114748
	LOSS [training: 0.0013382800516794798 | validation: 0.0019634552870824344]
	TIME [epoch: 8.34 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003760608865414769		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.0003760608865414769 | validation: 0.00047428739555021877]
	TIME [epoch: 8.37 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.605648758276341e-05		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: -5.605648758276341e-05 | validation: 0.0009202884564460559]
	TIME [epoch: 8.33 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003507813140264725		[learning rate: 0.0011394]
	Learning Rate: 0.00113937
	LOSS [training: 0.003507813140264725 | validation: 0.001715356020498231]
	TIME [epoch: 8.32 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019769622697346227		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.0019769622697346227 | validation: 0.00043779921597599447]
	TIME [epoch: 8.33 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012276694561304483		[learning rate: 0.001134]
	Learning Rate: 0.00113401
	LOSS [training: 0.0012276694561304483 | validation: 0.0006599160904154426]
	TIME [epoch: 8.33 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.904848563763919e-05		[learning rate: 0.0011313]
	Learning Rate: 0.00113133
	LOSS [training: 2.904848563763919e-05 | validation: 0.006126689331271418]
	TIME [epoch: 8.38 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004910153179868839		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.004910153179868839 | validation: 0.0013247411036339165]
	TIME [epoch: 8.33 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012741768494042073		[learning rate: 0.001126]
	Learning Rate: 0.001126
	LOSS [training: 0.0012741768494042073 | validation: 0.0017302477528370669]
	TIME [epoch: 8.33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009231279665240464		[learning rate: 0.0011233]
	Learning Rate: 0.00112334
	LOSS [training: 0.0009231279665240464 | validation: 0.0018338799696401603]
	TIME [epoch: 8.33 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007391398837704912		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.0007391398837704912 | validation: 0.00038636816368245745]
	TIME [epoch: 8.33 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005974332648484619		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.0005974332648484619 | validation: 0.0005599975382351312]
	TIME [epoch: 8.37 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016516201043317658		[learning rate: 0.0011154]
	Learning Rate: 0.00111541
	LOSS [training: 0.0016516201043317658 | validation: 0.005795422454945024]
	TIME [epoch: 8.33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035369194568406434		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.0035369194568406434 | validation: 0.000644529697067175]
	TIME [epoch: 8.32 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.28404570061949e-05		[learning rate: 0.0011102]
	Learning Rate: 0.00111016
	LOSS [training: 6.28404570061949e-05 | validation: 0.0003048418561143605]
	TIME [epoch: 8.33 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042411653642319405		[learning rate: 0.0011075]
	Learning Rate: 0.00110754
	LOSS [training: 0.00042411653642319405 | validation: 0.002255014669351807]
	TIME [epoch: 8.33 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003686804632113476		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.003686804632113476 | validation: 0.0013736130654559316]
	TIME [epoch: 8.38 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011797222349759502		[learning rate: 0.0011023]
	Learning Rate: 0.00110232
	LOSS [training: 0.0011797222349759502 | validation: 0.0022407321515770613]
	TIME [epoch: 8.32 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001794921815161364		[learning rate: 0.0010997]
	Learning Rate: 0.00109972
	LOSS [training: 0.001794921815161364 | validation: 0.0046903598769514]
	TIME [epoch: 8.33 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002511683402018257		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.002511683402018257 | validation: 0.0014103869788913833]
	TIME [epoch: 8.33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014502239946837625		[learning rate: 0.0010945]
	Learning Rate: 0.00109454
	LOSS [training: 0.0014502239946837625 | validation: 0.0006155226594825875]
	TIME [epoch: 8.33 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002232047986651958		[learning rate: 0.001092]
	Learning Rate: 0.00109196
	LOSS [training: 0.002232047986651958 | validation: -0.0007082755772739659]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_988.pth
	Model improved!!!
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012985401985190028		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.00012985401985190028 | validation: -4.755010969179725e-05]
	TIME [epoch: 8.41 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001579501496673798		[learning rate: 0.0010868]
	Learning Rate: 0.00108681
	LOSS [training: 0.001579501496673798 | validation: 0.00974540913172122]
	TIME [epoch: 8.33 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00362814966622871		[learning rate: 0.0010842]
	Learning Rate: 0.00108425
	LOSS [training: 0.00362814966622871 | validation: 0.000541170612421055]
	TIME [epoch: 8.33 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003872604441153771		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.003872604441153771 | validation: 0.000900122099758534]
	TIME [epoch: 8.33 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000768803012879732		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.000768803012879732 | validation: 0.000723438032356511]
	TIME [epoch: 8.39 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001124167761236438		[learning rate: 0.0010766]
	Learning Rate: 0.00107659
	LOSS [training: 0.001124167761236438 | validation: 0.00032489268251473024]
	TIME [epoch: 8.33 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014455637663334513		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.0014455637663334513 | validation: 0.001431038442109935]
	TIME [epoch: 8.34 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000864614980302769		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.000864614980302769 | validation: 0.001452900057431417]
	TIME [epoch: 8.33 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008539134462977853		[learning rate: 0.001069]
	Learning Rate: 0.00106899
	LOSS [training: 0.0008539134462977853 | validation: 0.0016846932423219127]
	TIME [epoch: 8.33 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027146107175383266		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.0027146107175383266 | validation: 0.004200726423007275]
	TIME [epoch: 8.37 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024020233033879915		[learning rate: 0.001064]
	Learning Rate: 0.00106395
	LOSS [training: 0.0024020233033879915 | validation: 0.0008840544256448354]
	TIME [epoch: 8.34 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007682938353120729		[learning rate: 0.0010614]
	Learning Rate: 0.00106144
	LOSS [training: 0.007682938353120729 | validation: 0.0005375904233808275]
	TIME [epoch: 8.33 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002176363705474209		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.002176363705474209 | validation: 0.003920466290453102]
	TIME [epoch: 8.33 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016602367174039167		[learning rate: 0.0010564]
	Learning Rate: 0.00105644
	LOSS [training: 0.0016602367174039167 | validation: 0.0004487638243351983]
	TIME [epoch: 8.41 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011626303012653779		[learning rate: 0.001054]
	Learning Rate: 0.00105395
	LOSS [training: 0.0011626303012653779 | validation: 0.0017473922171965986]
	TIME [epoch: 8.38 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002938985831031968		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.0002938985831031968 | validation: 9.984321753118097e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.860062092779425e-06		[learning rate: 0.001049]
	Learning Rate: 0.00104898
	LOSS [training: 8.860062092779425e-06 | validation: 0.0007601226041094695]
	TIME [epoch: 8.34 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015778355311702168		[learning rate: 0.0010465]
	Learning Rate: 0.00104651
	LOSS [training: 0.0015778355311702168 | validation: 0.0010699271672452832]
	TIME [epoch: 8.34 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023152573051716235		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.0023152573051716235 | validation: 0.00653999457776999]
	TIME [epoch: 8.34 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015376248105069307		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.0015376248105069307 | validation: 0.002569355193342061]
	TIME [epoch: 8.35 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006750028186230188		[learning rate: 0.0010391]
	Learning Rate: 0.00103912
	LOSS [training: 0.0006750028186230188 | validation: 0.0003107471706036815]
	TIME [epoch: 8.38 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021356855924816454		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.0021356855924816454 | validation: 0.0031643281051029867]
	TIME [epoch: 8.34 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002099058572697996		[learning rate: 0.0010342]
	Learning Rate: 0.00103423
	LOSS [training: 0.002099058572697996 | validation: 0.0006475429926635261]
	TIME [epoch: 8.34 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006459977136806658		[learning rate: 0.0010318]
	Learning Rate: 0.00103179
	LOSS [training: 0.0006459977136806658 | validation: 0.0007623891228564022]
	TIME [epoch: 8.34 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011517083932796306		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.0011517083932796306 | validation: 0.000252227002947051]
	TIME [epoch: 8.35 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006091541417204119		[learning rate: 0.0010269]
	Learning Rate: 0.00102692
	LOSS [training: 0.0006091541417204119 | validation: 0.0006448780301382562]
	TIME [epoch: 8.38 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016132332308173723		[learning rate: 0.0010245]
	Learning Rate: 0.0010245
	LOSS [training: 0.00016132332308173723 | validation: 0.0008255095264516083]
	TIME [epoch: 8.35 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010834792785687003		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.0010834792785687003 | validation: 0.003038159132945324]
	TIME [epoch: 8.32 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006099356660532196		[learning rate: 0.0010197]
	Learning Rate: 0.00101967
	LOSS [training: 0.0006099356660532196 | validation: -1.781919113449823e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028990736511879697		[learning rate: 0.0010173]
	Learning Rate: 0.00101727
	LOSS [training: 0.0028990736511879697 | validation: 0.005537750835984305]
	TIME [epoch: 8.34 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002217769686122818		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.002217769686122818 | validation: 0.001255339004474572]
	TIME [epoch: 8.39 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.5818363394103806e-05		[learning rate: 0.0010125]
	Learning Rate: 0.00101248
	LOSS [training: -1.5818363394103806e-05 | validation: 0.0005064473995682834]
	TIME [epoch: 8.34 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00519284878162376		[learning rate: 0.0010101]
	Learning Rate: 0.00101009
	LOSS [training: 0.00519284878162376 | validation: 0.0005280702226615284]
	TIME [epoch: 8.34 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001304204285329087		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.001304204285329087 | validation: 0.0011650506381864175]
	TIME [epoch: 8.34 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.5732487272392294e-05		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: -1.5732487272392294e-05 | validation: 0.0008510965470741331]
	TIME [epoch: 8.34 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003746408482731185		[learning rate: 0.001003]
	Learning Rate: 0.00100296
	LOSS [training: 0.0003746408482731185 | validation: 0.002096411589842032]
	TIME [epoch: 8.39 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016833855393223011		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.0016833855393223011 | validation: -0.0003175099521992815]
	TIME [epoch: 8.34 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001633643437808286		[learning rate: 0.00099823]
	Learning Rate: 0.000998231
	LOSS [training: 0.001633643437808286 | validation: 0.0003939420061875909]
	TIME [epoch: 8.34 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014733827177827628		[learning rate: 0.00099588]
	Learning Rate: 0.000995876
	LOSS [training: 0.0014733827177827628 | validation: 0.0010227424318095268]
	TIME [epoch: 8.34 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027849306887950775		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.0027849306887950775 | validation: 0.0024854189944921064]
	TIME [epoch: 8.32 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001699134867062		[learning rate: 0.00099118]
	Learning Rate: 0.000991183
	LOSS [training: 0.001699134867062 | validation: 0.0005043423217644181]
	TIME [epoch: 8.33 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016278080739321943		[learning rate: 0.00098885]
	Learning Rate: 0.000988845
	LOSS [training: 0.0016278080739321943 | validation: 0.002522024832878267]
	TIME [epoch: 8.31 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024152288828072463		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.0024152288828072463 | validation: 0.0018354625395841147]
	TIME [epoch: 8.31 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005850116564118402		[learning rate: 0.00098419]
	Learning Rate: 0.000984185
	LOSS [training: 0.0005850116564118402 | validation: -0.00025072130970711464]
	TIME [epoch: 8.34 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004432234357413545		[learning rate: 0.00098186]
	Learning Rate: 0.000981864
	LOSS [training: 0.0004432234357413545 | validation: 0.0004937733013681749]
	TIME [epoch: 8.34 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006821696265699304		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.0006821696265699304 | validation: 0.004340122544060845]
	TIME [epoch: 8.38 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022458348064305863		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.0022458348064305863 | validation: 0.0005027098821586305]
	TIME [epoch: 8.35 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023801042837315145		[learning rate: 0.00097493]
	Learning Rate: 0.000974932
	LOSS [training: 0.0023801042837315145 | validation: 0.0016769703054278905]
	TIME [epoch: 8.34 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011224111031021022		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.0011224111031021022 | validation: 0.0005812026848313216]
	TIME [epoch: 8.34 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011363705465910177		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.011363705465910177 | validation: 0.012842212539116205]
	TIME [epoch: 8.34 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008377522006503725		[learning rate: 0.00096805]
	Learning Rate: 0.000968049
	LOSS [training: 0.008377522006503725 | validation: 0.0006424335820040477]
	TIME [epoch: 8.38 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004067299797566368		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.0004067299797566368 | validation: 0.0004030382601468241]
	TIME [epoch: 8.36 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950124752926911e-05		[learning rate: 0.00096349]
	Learning Rate: 0.000963488
	LOSS [training: 4.950124752926911e-05 | validation: 0.0011078470905527852]
	TIME [epoch: 8.33 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006096551202953321		[learning rate: 0.00096121]
	Learning Rate: 0.000961215
	LOSS [training: 0.0006096551202953321 | validation: 0.0010605201171654608]
	TIME [epoch: 8.34 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000564750173688943		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.000564750173688943 | validation: 0.0017339464055615287]
	TIME [epoch: 8.34 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00113046546689637		[learning rate: 0.00095669]
	Learning Rate: 0.000956686
	LOSS [training: 0.00113046546689637 | validation: 0.00029326573418779136]
	TIME [epoch: 8.36 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002999217632585529		[learning rate: 0.00095443]
	Learning Rate: 0.000954429
	LOSS [training: 0.002999217632585529 | validation: 0.0014886973876338302]
	TIME [epoch: 8.38 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00118351249542318		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.00118351249542318 | validation: 0.0002581403571240286]
	TIME [epoch: 8.34 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004911870167880453		[learning rate: 0.00094993]
	Learning Rate: 0.000949932
	LOSS [training: 0.0004911870167880453 | validation: 4.333140220928565e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007100551632445782		[learning rate: 0.00094769]
	Learning Rate: 0.000947691
	LOSS [training: 0.0007100551632445782 | validation: 0.00013500019467945276]
	TIME [epoch: 8.34 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018234528412711286		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.0018234528412711286 | validation: 0.007055726604587554]
	TIME [epoch: 8.34 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038768163846168656		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.0038768163846168656 | validation: 0.0007872893529883508]
	TIME [epoch: 8.38 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002880289347359351		[learning rate: 0.000941]
	Learning Rate: 0.000941
	LOSS [training: 0.0002880289347359351 | validation: 0.001171546252340225]
	TIME [epoch: 8.34 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012235777301825347		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.0012235777301825347 | validation: 0.00013609359744335455]
	TIME [epoch: 8.34 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004953877324984468		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.0004953877324984468 | validation: 0.00012717149882435707]
	TIME [epoch: 8.34 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013763157293148085		[learning rate: 0.00093436]
	Learning Rate: 0.000934357
	LOSS [training: 0.0013763157293148085 | validation: 0.0050540466920870825]
	TIME [epoch: 8.34 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003052738001782394		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.003052738001782394 | validation: 0.001121418173060134]
	TIME [epoch: 8.39 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003775397958856911		[learning rate: 0.00092995]
	Learning Rate: 0.000929954
	LOSS [training: 0.003775397958856911 | validation: 0.002012936999359201]
	TIME [epoch: 8.34 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001988601030100071		[learning rate: 0.00092776]
	Learning Rate: 0.000927761
	LOSS [training: 0.001988601030100071 | validation: 0.002533982735378772]
	TIME [epoch: 8.34 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015064289994693575		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.0015064289994693575 | validation: 0.0006316423328254985]
	TIME [epoch: 8.33 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004072859509191371		[learning rate: 0.00092339]
	Learning Rate: 0.000923389
	LOSS [training: 0.0004072859509191371 | validation: 0.0004630554487276988]
	TIME [epoch: 8.34 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003725286052683621		[learning rate: 0.00092121]
	Learning Rate: 0.000921211
	LOSS [training: -0.0003725286052683621 | validation: 0.0009034927826746313]
	TIME [epoch: 8.37 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001294539123669789		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.0001294539123669789 | validation: 6.071888493736283e-06]
	TIME [epoch: 8.32 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038824769429638334		[learning rate: 0.00091687]
	Learning Rate: 0.00091687
	LOSS [training: 0.00038824769429638334 | validation: -0.00019746231524803723]
	TIME [epoch: 8.34 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008160658043926547		[learning rate: 0.00091471]
	Learning Rate: 0.000914707
	LOSS [training: 0.0008160658043926547 | validation: 0.00012898471607903514]
	TIME [epoch: 8.34 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012720790645268378		[learning rate: 0.00091255]
	Learning Rate: 0.00091255
	LOSS [training: 0.0012720790645268378 | validation: 0.001179562319973558]
	TIME [epoch: 8.34 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019238242633805797		[learning rate: 0.0009104]
	Learning Rate: 0.000910397
	LOSS [training: 0.0019238242633805797 | validation: 0.0008018722650260522]
	TIME [epoch: 8.39 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008785589800566877		[learning rate: 0.00090825]
	Learning Rate: 0.00090825
	LOSS [training: 0.0008785589800566877 | validation: 0.0006087262436286265]
	TIME [epoch: 8.34 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005260481580260816		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: -0.0005260481580260816 | validation: 0.001078195628495556]
	TIME [epoch: 8.34 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002136095133332945		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.002136095133332945 | validation: 0.0017454500302475143]
	TIME [epoch: 8.34 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020295570085975146		[learning rate: 0.00090184]
	Learning Rate: 0.000901837
	LOSS [training: 0.0020295570085975146 | validation: 0.0013044674103516458]
	TIME [epoch: 8.34 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017313881471374185		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.00017313881471374185 | validation: 0.0007335648133385483]
	TIME [epoch: 8.39 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003293913734233187		[learning rate: 0.00089759]
	Learning Rate: 0.000897588
	LOSS [training: 0.0003293913734233187 | validation: 7.324609330282117e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021528794183155853		[learning rate: 0.00089547]
	Learning Rate: 0.00089547
	LOSS [training: -0.00021528794183155853 | validation: 0.0004155291302095572]
	TIME [epoch: 8.34 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032283252083363664		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.00032283252083363664 | validation: 0.0004515243400772406]
	TIME [epoch: 8.34 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010042118012746726		[learning rate: 0.00089125]
	Learning Rate: 0.000891251
	LOSS [training: 0.00010042118012746726 | validation: 0.0005972651637578465]
	TIME [epoch: 8.34 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000624402609059566		[learning rate: 0.00088915]
	Learning Rate: 0.000889149
	LOSS [training: 0.000624402609059566 | validation: 0.0013876010572114526]
	TIME [epoch: 8.38 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024784534324580245		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.0024784534324580245 | validation: 0.0014933618376552062]
	TIME [epoch: 8.35 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023632630679707076		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.0023632630679707076 | validation: 0.001032086258407324]
	TIME [epoch: 8.34 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007975684981764464		[learning rate: 0.00088287]
	Learning Rate: 0.000882871
	LOSS [training: 0.0007975684981764464 | validation: 0.0008536369421240249]
	TIME [epoch: 8.34 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016730079799431546		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.0016730079799431546 | validation: 0.002548964127973877]
	TIME [epoch: 8.34 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017794868704299421		[learning rate: 0.00087871]
	Learning Rate: 0.000878711
	LOSS [training: 0.0017794868704299421 | validation: 0.000928618923098027]
	TIME [epoch: 8.37 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.8768335889883824e-05		[learning rate: 0.00087664]
	Learning Rate: 0.000876639
	LOSS [training: -3.8768335889883824e-05 | validation: 0.00037296580047030495]
	TIME [epoch: 8.35 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019558510946116616		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.0019558510946116616 | validation: 0.001182013183110814]
	TIME [epoch: 8.34 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015892124205330019		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.0015892124205330019 | validation: 0.0002548572050702447]
	TIME [epoch: 8.33 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004928652313533661		[learning rate: 0.00087045]
	Learning Rate: 0.00087045
	LOSS [training: 0.0004928652313533661 | validation: -0.0002402145173537176]
	TIME [epoch: 8.34 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019665147045975774		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.00019665147045975774 | validation: -0.0003050808591628034]
	TIME [epoch: 8.36 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031878435915387744		[learning rate: 0.00086635]
	Learning Rate: 0.000866348
	LOSS [training: 0.00031878435915387744 | validation: 0.00041621593277440817]
	TIME [epoch: 8.37 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001884339385393035		[learning rate: 0.0008643]
	Learning Rate: 0.000864304
	LOSS [training: -0.0001884339385393035 | validation: -0.00010843648843938248]
	TIME [epoch: 8.34 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007117387958418082		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.0007117387958418082 | validation: 0.002388862300962175]
	TIME [epoch: 8.34 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028545023156809615		[learning rate: 0.00086023]
	Learning Rate: 0.000860232
	LOSS [training: 0.0028545023156809615 | validation: 0.0024860433479461054]
	TIME [epoch: 8.34 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010428142242571124		[learning rate: 0.0008582]
	Learning Rate: 0.000858202
	LOSS [training: 0.0010428142242571124 | validation: 0.0015877102582838951]
	TIME [epoch: 8.35 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.371447832093828e-05		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 9.371447832093828e-05 | validation: 0.0018064357003261939]
	TIME [epoch: 8.37 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012228786625872055		[learning rate: 0.00085416]
	Learning Rate: 0.000854159
	LOSS [training: 0.0012228786625872055 | validation: 0.00014764570707332327]
	TIME [epoch: 8.34 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.20520252892242e-06		[learning rate: 0.00085214]
	Learning Rate: 0.000852144
	LOSS [training: -5.20520252892242e-06 | validation: 0.0011615514853381321]
	TIME [epoch: 8.33 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00446484034091643		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.00446484034091643 | validation: 0.0013286179670055614]
	TIME [epoch: 8.34 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007536371132268261		[learning rate: 0.00084813]
	Learning Rate: 0.000848128
	LOSS [training: 0.0007536371132268261 | validation: 0.0002969718601056136]
	TIME [epoch: 8.34 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00046877887042785614		[learning rate: 0.00084613]
	Learning Rate: 0.000846128
	LOSS [training: 0.00046877887042785614 | validation: 0.0024844238180251315]
	TIME [epoch: 8.38 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001545968460926357		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.001545968460926357 | validation: 0.001339247124697142]
	TIME [epoch: 8.33 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003684373669117987		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.0003684373669117987 | validation: 0.00018170251750627606]
	TIME [epoch: 8.33 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004470123598072735		[learning rate: 0.00084015]
	Learning Rate: 0.000840154
	LOSS [training: 0.0004470123598072735 | validation: 0.00047562255952817003]
	TIME [epoch: 8.34 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032059244552771674		[learning rate: 0.00083817]
	Learning Rate: 0.000838173
	LOSS [training: 0.00032059244552771674 | validation: 0.003392677392272692]
	TIME [epoch: 8.34 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017911368821415324		[learning rate: 0.0008362]
	Learning Rate: 0.000836195
	LOSS [training: 0.0017911368821415324 | validation: 0.0014463988959800295]
	TIME [epoch: 8.38 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011120170685024898		[learning rate: 0.00083422]
	Learning Rate: 0.000834223
	LOSS [training: 0.0011120170685024898 | validation: -0.00028255894477597287]
	TIME [epoch: 8.41 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012930897940266496		[learning rate: 0.00083226]
	Learning Rate: 0.000832255
	LOSS [training: 0.0012930897940266496 | validation: 0.0010323646141125833]
	TIME [epoch: 8.33 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018823920435186365		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.00018823920435186365 | validation: 0.00013728846879499073]
	TIME [epoch: 8.33 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011834372081885738		[learning rate: 0.00082833]
	Learning Rate: 0.000828333
	LOSS [training: 0.00011834372081885738 | validation: -0.0001967537588550803]
	TIME [epoch: 8.34 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010752806806939709		[learning rate: 0.00082638]
	Learning Rate: 0.00082638
	LOSS [training: 0.0010752806806939709 | validation: 0.0004522588799842628]
	TIME [epoch: 8.37 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005181586155131683		[learning rate: 0.00082443]
	Learning Rate: 0.00082443
	LOSS [training: 0.0005181586155131683 | validation: 0.0008105302736888139]
	TIME [epoch: 8.33 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.854723070451566e-05		[learning rate: 0.00082249]
	Learning Rate: 0.000822485
	LOSS [training: -8.854723070451566e-05 | validation: 0.0010953315071640152]
	TIME [epoch: 8.33 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028184354579255876		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: -0.00028184354579255876 | validation: 0.0013622125281015074]
	TIME [epoch: 8.34 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043601136247005477		[learning rate: 0.00081861]
	Learning Rate: 0.00081861
	LOSS [training: 0.00043601136247005477 | validation: 0.0014491028477148565]
	TIME [epoch: 8.33 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001363324028879654		[learning rate: 0.00081668]
	Learning Rate: 0.000816679
	LOSS [training: 0.001363324028879654 | validation: 8.836317981486629e-05]
	TIME [epoch: 8.38 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.051217917704978e-05		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 4.051217917704978e-05 | validation: -0.00030723112973671853]
	TIME [epoch: 8.33 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014564371779543788		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.0014564371779543788 | validation: 9.63069303044963e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023471301832021066		[learning rate: 0.00081091]
	Learning Rate: 0.000810913
	LOSS [training: 0.00023471301832021066 | validation: 0.005209935676442755]
	TIME [epoch: 8.34 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006196288562079663		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.006196288562079663 | validation: 0.0006819783612919022]
	TIME [epoch: 8.34 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002264701008198415		[learning rate: 0.00080709]
	Learning Rate: 0.000807092
	LOSS [training: 0.002264701008198415 | validation: 0.0008024786173334224]
	TIME [epoch: 8.38 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034986897819353387		[learning rate: 0.00080519]
	Learning Rate: 0.000805188
	LOSS [training: 0.0034986897819353387 | validation: 0.0019754805882966943]
	TIME [epoch: 8.34 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007793731545535437		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.0007793731545535437 | validation: -0.0004336566867891358]
	TIME [epoch: 8.32 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020565753643100472		[learning rate: 0.00080139]
	Learning Rate: 0.000801394
	LOSS [training: -0.00020565753643100472 | validation: 0.00048619138798552936]
	TIME [epoch: 8.33 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015729967909309313		[learning rate: 0.0007995]
	Learning Rate: 0.000799504
	LOSS [training: 0.00015729967909309313 | validation: 0.0012373350510086296]
	TIME [epoch: 8.33 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018770803194911466		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: -0.00018770803194911466 | validation: 0.0007630997702353595]
	TIME [epoch: 8.38 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032470916317826014		[learning rate: 0.00079574]
	Learning Rate: 0.000795736
	LOSS [training: 0.00032470916317826014 | validation: 0.00040977526972869557]
	TIME [epoch: 8.35 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042308871460792634		[learning rate: 0.00079386]
	Learning Rate: 0.000793859
	LOSS [training: 0.00042308871460792634 | validation: 0.0003326997464878034]
	TIME [epoch: 8.33 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004886189635960053		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: -0.0004886189635960053 | validation: -0.00020713497568312803]
	TIME [epoch: 8.34 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004075812797765839		[learning rate: 0.00079012]
	Learning Rate: 0.000790119
	LOSS [training: -0.0004075812797765839 | validation: -3.021085075544317e-06]
	TIME [epoch: 8.34 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018564486248907734		[learning rate: 0.00078826]
	Learning Rate: 0.000788255
	LOSS [training: 0.0018564486248907734 | validation: 0.0015991828173608788]
	TIME [epoch: 8.37 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000987111532162167		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.000987111532162167 | validation: 0.00115994401879607]
	TIME [epoch: 8.35 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043424086461779047		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.00043424086461779047 | validation: -0.000326939988737684]
	TIME [epoch: 8.33 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00030516232295563526		[learning rate: 0.00078269]
	Learning Rate: 0.00078269
	LOSS [training: -0.00030516232295563526 | validation: 0.0003698767882912466]
	TIME [epoch: 8.34 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4126422905542896e-05		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 1.4126422905542896e-05 | validation: -0.0005119998087372704]
	TIME [epoch: 8.33 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026868944277164044		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.00026868944277164044 | validation: -0.00011488474543372407]
	TIME [epoch: 8.36 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010684367439267657		[learning rate: 0.00077716]
	Learning Rate: 0.000777164
	LOSS [training: 0.00010684367439267657 | validation: 0.00022944885312084295]
	TIME [epoch: 8.36 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003189644015072592		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.0003189644015072592 | validation: 0.0009448389428047115]
	TIME [epoch: 8.33 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001061249950861241		[learning rate: 0.0007735]
	Learning Rate: 0.000773502
	LOSS [training: 0.001061249950861241 | validation: 0.0009583675069046427]
	TIME [epoch: 8.33 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001374464097148683		[learning rate: 0.00077168]
	Learning Rate: 0.000771678
	LOSS [training: 0.001374464097148683 | validation: 0.002049029326463042]
	TIME [epoch: 8.33 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004271412402252155		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.0004271412402252155 | validation: -0.00041834516348995533]
	TIME [epoch: 8.35 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003151970025105961		[learning rate: 0.00076804]
	Learning Rate: 0.000768041
	LOSS [training: -0.0003151970025105961 | validation: 0.002223472843431831]
	TIME [epoch: 8.36 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008409159507133246		[learning rate: 0.00076623]
	Learning Rate: 0.00076623
	LOSS [training: 0.0008409159507133246 | validation: 1.4947419632616596e-06]
	TIME [epoch: 8.33 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009894090017623898		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.0009894090017623898 | validation: 0.00032519321295815837]
	TIME [epoch: 8.33 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019846034249294117		[learning rate: 0.00076262]
	Learning Rate: 0.000762619
	LOSS [training: 0.0019846034249294117 | validation: 0.0005728519803495523]
	TIME [epoch: 8.33 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013832446722940328		[learning rate: 0.00076082]
	Learning Rate: 0.00076082
	LOSS [training: 0.00013832446722940328 | validation: -0.0005845357066379001]
	TIME [epoch: 8.34 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001294334598385298		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.0001294334598385298 | validation: 0.0004907867342711501]
	TIME [epoch: 8.37 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010722927280642173		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.010722927280642173 | validation: 0.0036275943718799943]
	TIME [epoch: 8.33 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011011374073928674		[learning rate: 0.00075545]
	Learning Rate: 0.000755449
	LOSS [training: 0.0011011374073928674 | validation: 0.000680211608902448]
	TIME [epoch: 8.33 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9646747744378946e-05		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 4.9646747744378946e-05 | validation: 0.0012884790376129257]
	TIME [epoch: 8.33 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009008560292428826		[learning rate: 0.00075189]
	Learning Rate: 0.000751889
	LOSS [training: 0.0009008560292428826 | validation: 0.000962481561334947]
	TIME [epoch: 8.34 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022943727062392247		[learning rate: 0.00075012]
	Learning Rate: 0.000750116
	LOSS [training: 0.00022943727062392247 | validation: 0.00036636084165432825]
	TIME [epoch: 8.38 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025554158828344976		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.00025554158828344976 | validation: -0.0004568124144691086]
	TIME [epoch: 8.33 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.727721682531232e-05		[learning rate: 0.00074658]
	Learning Rate: 0.000746581
	LOSS [training: -5.727721682531232e-05 | validation: 0.0014767805403839533]
	TIME [epoch: 8.33 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.601526449081273e-05		[learning rate: 0.00074482]
	Learning Rate: 0.00074482
	LOSS [training: -3.601526449081273e-05 | validation: -0.00010735174238209752]
	TIME [epoch: 8.33 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024412222201137726		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.00024412222201137726 | validation: 0.0010603416306241105]
	TIME [epoch: 8.33 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025911374279887927		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.0025911374279887927 | validation: 0.008904232995196461]
	TIME [epoch: 8.38 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007060611241897793		[learning rate: 0.00073956]
	Learning Rate: 0.000739562
	LOSS [training: 0.007060611241897793 | validation: 0.0011496060943457535]
	TIME [epoch: 8.33 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002579186656547299		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.0002579186656547299 | validation: 5.561631965409484e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.108077940115292e-05		[learning rate: 0.00073608]
	Learning Rate: 0.000736077
	LOSS [training: -1.108077940115292e-05 | validation: 0.0009033143663680595]
	TIME [epoch: 8.33 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012532481456640544		[learning rate: 0.00073434]
	Learning Rate: 0.000734341
	LOSS [training: -0.00012532481456640544 | validation: 0.00011214552148113997]
	TIME [epoch: 8.33 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003519099323713577		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: -0.0003519099323713577 | validation: 0.0003672094135851904]
	TIME [epoch: 8.38 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.909532931793504e-05		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 4.909532931793504e-05 | validation: 0.0001792081612071934]
	TIME [epoch: 8.33 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009669638446823586		[learning rate: 0.00072916]
	Learning Rate: 0.000729156
	LOSS [training: 0.0009669638446823586 | validation: 0.0002318306812929296]
	TIME [epoch: 8.33 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006181324456883328		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.0006181324456883328 | validation: 0.0005192332808356253]
	TIME [epoch: 8.33 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012514489221051289		[learning rate: 0.00072572]
	Learning Rate: 0.00072572
	LOSS [training: 0.0012514489221051289 | validation: 0.0009352800891625188]
	TIME [epoch: 8.33 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015803999560168843		[learning rate: 0.00072401]
	Learning Rate: 0.000724008
	LOSS [training: 0.0015803999560168843 | validation: -0.000271042536901469]
	TIME [epoch: 8.38 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003379703499294446		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.0003379703499294446 | validation: -0.00014168365156830244]
	TIME [epoch: 8.34 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004490824523725219		[learning rate: 0.0007206]
	Learning Rate: 0.000720597
	LOSS [training: 0.0004490824523725219 | validation: 0.00025491820159038124]
	TIME [epoch: 8.33 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005718220861018782		[learning rate: 0.0007189]
	Learning Rate: 0.000718897
	LOSS [training: 0.0005718220861018782 | validation: 0.0008936832821160824]
	TIME [epoch: 8.33 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010579979908185405		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.0010579979908185405 | validation: 0.00679873871452741]
	TIME [epoch: 8.33 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003921816236305841		[learning rate: 0.00071551]
	Learning Rate: 0.00071551
	LOSS [training: 0.003921816236305841 | validation: 0.001175070744339409]
	TIME [epoch: 8.37 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000177011657787713		[learning rate: 0.00071382]
	Learning Rate: 0.000713822
	LOSS [training: -0.000177011657787713 | validation: 0.00033877852326308133]
	TIME [epoch: 8.34 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008661875699543618		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.0008661875699543618 | validation: 0.004103343943616132]
	TIME [epoch: 8.33 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026521519148857606		[learning rate: 0.00071046]
	Learning Rate: 0.000710458
	LOSS [training: 0.0026521519148857606 | validation: 0.0002385117759340454]
	TIME [epoch: 8.33 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003794738580216544		[learning rate: 0.00070878]
	Learning Rate: 0.000708782
	LOSS [training: 0.0003794738580216544 | validation: 0.0003437270478870262]
	TIME [epoch: 8.33 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008751409387079405		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.0008751409387079405 | validation: 0.0029007239587029825]
	TIME [epoch: 8.37 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008525449695637015		[learning rate: 0.00070544]
	Learning Rate: 0.000705443
	LOSS [training: 0.0008525449695637015 | validation: 0.0006362296725181396]
	TIME [epoch: 8.35 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010010732375700202		[learning rate: 0.00070378]
	Learning Rate: 0.000703778
	LOSS [training: -0.00010010732375700202 | validation: 0.0013828714326184622]
	TIME [epoch: 8.33 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007660972875827742		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.0007660972875827742 | validation: 0.005861948023786495]
	TIME [epoch: 8.33 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002166560760600623		[learning rate: 0.00070046]
	Learning Rate: 0.000700462
	LOSS [training: 0.002166560760600623 | validation: 0.0007343749607881601]
	TIME [epoch: 8.33 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018807339284662405		[learning rate: 0.00069881]
	Learning Rate: 0.00069881
	LOSS [training: 0.00018807339284662405 | validation: 0.00013547083101240847]
	TIME [epoch: 8.35 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018693822591913859		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.00018693822591913859 | validation: 0.00042568690328138994]
	TIME [epoch: 8.37 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002903300734001941		[learning rate: 0.00069552]
	Learning Rate: 0.000695517
	LOSS [training: -0.0002903300734001941 | validation: 0.0004941360353761314]
	TIME [epoch: 8.33 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006261870695839082		[learning rate: 0.00069388]
	Learning Rate: 0.000693876
	LOSS [training: -0.0006261870695839082 | validation: 0.0006764763393940099]
	TIME [epoch: 8.33 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016157279355780113		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.0016157279355780113 | validation: 0.00041925508357608447]
	TIME [epoch: 8.33 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003064998977964259		[learning rate: 0.00069061]
	Learning Rate: 0.000690607
	LOSS [training: 0.0003064998977964259 | validation: 4.6972841178977e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026608116749544343		[learning rate: 0.00068898]
	Learning Rate: 0.000688978
	LOSS [training: 0.0026608116749544343 | validation: 0.002300283260716433]
	TIME [epoch: 8.38 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000611293314640452		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.000611293314640452 | validation: -0.0001874877109501023]
	TIME [epoch: 8.33 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000446615996125068		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.000446615996125068 | validation: 0.0005427107605117634]
	TIME [epoch: 8.34 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055707807112175475		[learning rate: 0.00068411]
	Learning Rate: 0.000684114
	LOSS [training: 0.0055707807112175475 | validation: 0.0022867844104986984]
	TIME [epoch: 8.34 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004740608045806629		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.0004740608045806629 | validation: 0.0007194610265499582]
	TIME [epoch: 8.34 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009378729310121293		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.0009378729310121293 | validation: 8.123914604645676e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001202385169603309		[learning rate: 0.00067928]
	Learning Rate: 0.000679284
	LOSS [training: 0.001202385169603309 | validation: 0.00010098623031830952]
	TIME [epoch: 8.34 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005754442875449759		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.0005754442875449759 | validation: 0.001247274198213844]
	TIME [epoch: 8.33 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010282683707425308		[learning rate: 0.00067608]
	Learning Rate: 0.000676083
	LOSS [training: 0.0010282683707425308 | validation: 0.0016183859138087999]
	TIME [epoch: 8.33 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006824777746003564		[learning rate: 0.00067449]
	Learning Rate: 0.000674488
	LOSS [training: 0.0006824777746003564 | validation: 0.00030590932175912313]
	TIME [epoch: 8.34 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009758060230401582		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.0009758060230401582 | validation: 0.004107619075477829]
	TIME [epoch: 8.38 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003086432481765655		[learning rate: 0.00067131]
	Learning Rate: 0.00067131
	LOSS [training: 0.003086432481765655 | validation: 0.003467041718512162]
	TIME [epoch: 8.34 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017955876934163122		[learning rate: 0.00066973]
	Learning Rate: 0.000669726
	LOSS [training: 0.0017955876934163122 | validation: -0.00034931264085486457]
	TIME [epoch: 8.33 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006139620943249672		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: -0.0006139620943249672 | validation: 0.00018183201703291906]
	TIME [epoch: 8.33 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000197688195004682		[learning rate: 0.00066657]
	Learning Rate: 0.000666571
	LOSS [training: -0.000197688195004682 | validation: -0.00017997944596655557]
	TIME [epoch: 8.33 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015005361927120453		[learning rate: 0.000665]
	Learning Rate: 0.000664998
	LOSS [training: -0.00015005361927120453 | validation: 0.00017000323258006264]
	TIME [epoch: 8.38 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002370862413497079		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.002370862413497079 | validation: 0.0020412255025054715]
	TIME [epoch: 8.34 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016908701423823391		[learning rate: 0.00066186]
	Learning Rate: 0.000661865
	LOSS [training: 0.0016908701423823391 | validation: -0.00018733803227404168]
	TIME [epoch: 8.33 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1823330784326086e-05		[learning rate: 0.0006603]
	Learning Rate: 0.000660304
	LOSS [training: 5.1823330784326086e-05 | validation: 0.0012897701603497942]
	TIME [epoch: 8.33 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004138349036058642		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: -0.0004138349036058642 | validation: -0.0004298340243394993]
	TIME [epoch: 8.33 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038784855850088485		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.00038784855850088485 | validation: 0.0009345480061522134]
	TIME [epoch: 8.39 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019699178687159228		[learning rate: 0.00065564]
	Learning Rate: 0.000655642
	LOSS [training: 0.00019699178687159228 | validation: 0.0013604153171634498]
	TIME [epoch: 8.34 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002803263170589683		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.0002803263170589683 | validation: 0.001629867932878252]
	TIME [epoch: 8.33 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.809301545913016e-05		[learning rate: 0.00065255]
	Learning Rate: 0.000652552
	LOSS [training: 9.809301545913016e-05 | validation: 0.000891308108254218]
	TIME [epoch: 8.33 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005502117998354559		[learning rate: 0.00065101]
	Learning Rate: 0.000651013
	LOSS [training: 0.0005502117998354559 | validation: 0.0011182809654101096]
	TIME [epoch: 8.33 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.5968303912795368e-05		[learning rate: 0.00064948]
	Learning Rate: 0.000649478
	LOSS [training: -1.5968303912795368e-05 | validation: 0.00016857809869502647]
	TIME [epoch: 8.37 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024560854546440292		[learning rate: 0.00064795]
	Learning Rate: 0.000647945
	LOSS [training: 0.0024560854546440292 | validation: 0.001229464287145305]
	TIME [epoch: 8.34 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00062926998076998		[learning rate: 0.00064642]
	Learning Rate: 0.000646417
	LOSS [training: 0.00062926998076998 | validation: 0.000651714824227347]
	TIME [epoch: 8.33 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024856799736073486		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.0024856799736073486 | validation: 0.006546512450981704]
	TIME [epoch: 8.33 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035965122933150724		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.0035965122933150724 | validation: 0.0005469674717399333]
	TIME [epoch: 8.33 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008767685585176986		[learning rate: 0.00064185]
	Learning Rate: 0.000641854
	LOSS [training: 0.0008767685585176986 | validation: 0.0008446924911440657]
	TIME [epoch: 8.37 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011434857304509016		[learning rate: 0.00064034]
	Learning Rate: 0.00064034
	LOSS [training: -0.00011434857304509016 | validation: -0.0008160691866055516]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_1214.pth
	Model improved!!!
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009023872036552751		[learning rate: 0.00063883]
	Learning Rate: 0.000638829
	LOSS [training: 0.0009023872036552751 | validation: 0.000845819323326761]
	TIME [epoch: 8.34 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006184552919283595		[learning rate: 0.00063732]
	Learning Rate: 0.000637322
	LOSS [training: 0.0006184552919283595 | validation: 0.00029624239849942714]
	TIME [epoch: 8.32 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002872445904897312		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: -0.0002872445904897312 | validation: 0.00042624536624044575]
	TIME [epoch: 8.33 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010773434337191475		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.0010773434337191475 | validation: 0.0012578286535401342]
	TIME [epoch: 8.37 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004119229203450236		[learning rate: 0.00063282]
	Learning Rate: 0.000632823
	LOSS [training: 0.0004119229203450236 | validation: -0.0001280570442409071]
	TIME [epoch: 8.34 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003812039629484778		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: -0.0003812039629484778 | validation: 0.0005271233308819729]
	TIME [epoch: 8.33 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003634208046775476		[learning rate: 0.00062984]
	Learning Rate: 0.000629841
	LOSS [training: -0.0003634208046775476 | validation: 0.00010516282790942279]
	TIME [epoch: 8.33 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033919052660050464		[learning rate: 0.00062836]
	Learning Rate: 0.000628355
	LOSS [training: 0.00033919052660050464 | validation: 0.00011602044456957694]
	TIME [epoch: 8.32 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036033674253807877		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.00036033674253807877 | validation: 0.0012267982925195625]
	TIME [epoch: 8.37 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020850673255715612		[learning rate: 0.00062539]
	Learning Rate: 0.000625394
	LOSS [training: 0.00020850673255715612 | validation: -0.0002967049676282918]
	TIME [epoch: 8.34 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.339012024242897e-05		[learning rate: 0.00062392]
	Learning Rate: 0.000623919
	LOSS [training: -9.339012024242897e-05 | validation: 0.0009744293505563669]
	TIME [epoch: 8.33 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003603905102021787		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.0003603905102021787 | validation: 6.0583973693306714e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042750500990266447		[learning rate: 0.00062098]
	Learning Rate: 0.000620979
	LOSS [training: 0.00042750500990266447 | validation: 0.0011138256311932393]
	TIME [epoch: 8.32 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00045362035259471933		[learning rate: 0.00061951]
	Learning Rate: 0.000619514
	LOSS [training: 0.00045362035259471933 | validation: 0.00024784186216464344]
	TIME [epoch: 8.36 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.225396864667606e-05		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 2.225396864667606e-05 | validation: 0.00039541596532302977]
	TIME [epoch: 8.36 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442061254364957e-05		[learning rate: 0.0006166]
	Learning Rate: 0.000616595
	LOSS [training: 1.2442061254364957e-05 | validation: 0.00020293955667280097]
	TIME [epoch: 8.33 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005449397566549302		[learning rate: 0.00061514]
	Learning Rate: 0.000615141
	LOSS [training: -0.0005449397566549302 | validation: 0.00010592257642069126]
	TIME [epoch: 8.32 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038086715795241635		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.00038086715795241635 | validation: 0.0007046019559640185]
	TIME [epoch: 8.32 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006947265731350718		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.0006947265731350718 | validation: 0.0013924157537113287]
	TIME [epoch: 8.34 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.513431491189127e-05		[learning rate: 0.0006108]
	Learning Rate: 0.000610798
	LOSS [training: 6.513431491189127e-05 | validation: -0.00010421185721203366]
	TIME [epoch: 8.36 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010006607340754333		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.0010006607340754333 | validation: 0.0007978878274479971]
	TIME [epoch: 8.32 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005133178420185624		[learning rate: 0.00060792]
	Learning Rate: 0.00060792
	LOSS [training: 0.005133178420185624 | validation: 0.0042057840519892946]
	TIME [epoch: 8.32 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014280249329426406		[learning rate: 0.00060649]
	Learning Rate: 0.000606486
	LOSS [training: 0.0014280249329426406 | validation: 0.0007348863540695442]
	TIME [epoch: 8.32 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041171224543937624		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.00041171224543937624 | validation: -0.0004771858227516553]
	TIME [epoch: 8.33 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.555034251565825e-05		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 5.555034251565825e-05 | validation: -0.00021421400315329198]
	TIME [epoch: 8.37 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.326240229905844e-05		[learning rate: 0.0006022]
	Learning Rate: 0.000602204
	LOSS [training: 5.326240229905844e-05 | validation: 0.0002856388692056356]
	TIME [epoch: 8.33 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007310443994565092		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.0007310443994565092 | validation: 0.0002518965723722291]
	TIME [epoch: 8.33 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004409486957358746		[learning rate: 0.00059937]
	Learning Rate: 0.000599366
	LOSS [training: -0.0004409486957358746 | validation: 0.002190076734557042]
	TIME [epoch: 8.33 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006742549715950039		[learning rate: 0.00059795]
	Learning Rate: 0.000597953
	LOSS [training: 0.0006742549715950039 | validation: -0.00034802303026008815]
	TIME [epoch: 8.34 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.934435802000308e-05		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 9.934435802000308e-05 | validation: 0.0008914352733071236]
	TIME [epoch: 8.38 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008217791834919922		[learning rate: 0.00059513]
	Learning Rate: 0.000595135
	LOSS [training: 0.0008217791834919922 | validation: 0.0011418134202520144]
	TIME [epoch: 8.33 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032122446522500246		[learning rate: 0.00059373]
	Learning Rate: 0.000593731
	LOSS [training: -0.00032122446522500246 | validation: 0.0005546092876714259]
	TIME [epoch: 8.33 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001994727489109256		[learning rate: 0.00059233]
	Learning Rate: 0.000592331
	LOSS [training: -0.0001994727489109256 | validation: 0.0005425699540523356]
	TIME [epoch: 8.33 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015614813835750362		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: -0.00015614813835750362 | validation: 0.0015695340451929286]
	TIME [epoch: 8.33 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028529180432618656		[learning rate: 0.00058954]
	Learning Rate: 0.000589539
	LOSS [training: 0.00028529180432618656 | validation: -0.00026787971488952784]
	TIME [epoch: 8.38 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.732397394869774e-05		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 6.732397394869774e-05 | validation: -0.00043960805894785216]
	TIME [epoch: 8.33 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000331538301372629		[learning rate: 0.00058676]
	Learning Rate: 0.000586761
	LOSS [training: -0.000331538301372629 | validation: 2.2251290336784604e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004650914085522617		[learning rate: 0.00058538]
	Learning Rate: 0.000585377
	LOSS [training: -0.0004650914085522617 | validation: -0.00029433596494912045]
	TIME [epoch: 8.33 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006605842348213098		[learning rate: 0.000584]
	Learning Rate: 0.000583997
	LOSS [training: 0.0006605842348213098 | validation: -1.6508422268004673e-06]
	TIME [epoch: 8.32 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023289273708145222		[learning rate: 0.00058262]
	Learning Rate: 0.000582619
	LOSS [training: 0.00023289273708145222 | validation: 0.0008982958327301889]
	TIME [epoch: 8.37 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011785379063064903		[learning rate: 0.00058124]
	Learning Rate: 0.000581245
	LOSS [training: 0.0011785379063064903 | validation: 3.577676334476766e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002769822577980192		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.0002769822577980192 | validation: 0.002023957684751662]
	TIME [epoch: 8.33 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006785168111992495		[learning rate: 0.00057851]
	Learning Rate: 0.000578506
	LOSS [training: 0.0006785168111992495 | validation: 0.0001880883268261227]
	TIME [epoch: 8.32 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019562648533484129		[learning rate: 0.00057714]
	Learning Rate: 0.000577141
	LOSS [training: -0.00019562648533484129 | validation: -0.0002153961275658052]
	TIME [epoch: 8.33 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00042770134463130624		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: -0.00042770134463130624 | validation: 0.0002871394375400849]
	TIME [epoch: 8.37 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.203974376147085e-05		[learning rate: 0.00057442]
	Learning Rate: 0.000574422
	LOSS [training: 9.203974376147085e-05 | validation: 0.0007372667219694731]
	TIME [epoch: 8.34 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000624135455467486		[learning rate: 0.00057307]
	Learning Rate: 0.000573067
	LOSS [training: 0.000624135455467486 | validation: -0.0003894885495922207]
	TIME [epoch: 8.33 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000135125905892032		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: -0.000135125905892032 | validation: -1.1496424142116231e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047398655619185193		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.00047398655619185193 | validation: -0.00013409399130838475]
	TIME [epoch: 8.33 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008594744198569202		[learning rate: 0.00056902]
	Learning Rate: 0.000569021
	LOSS [training: 0.0008594744198569202 | validation: 0.0008073713116050323]
	TIME [epoch: 8.37 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010102139146133781		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.00010102139146133781 | validation: 0.00019318532037628655]
	TIME [epoch: 8.34 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023849733106131904		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.00023849733106131904 | validation: 0.0002387833402882556]
	TIME [epoch: 8.33 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.8689642566170205e-05		[learning rate: 0.000565]
	Learning Rate: 0.000565004
	LOSS [training: -1.8689642566170205e-05 | validation: 0.00022552793585838417]
	TIME [epoch: 8.33 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044505939180314866		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: -0.00044505939180314866 | validation: 2.004693938345971e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004020822829278404		[learning rate: 0.00056234]
	Learning Rate: 0.000562341
	LOSS [training: 0.0004020822829278404 | validation: -0.00041728087057668666]
	TIME [epoch: 8.35 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010306495946892321		[learning rate: 0.00056101]
	Learning Rate: 0.000561015
	LOSS [training: -0.0010306495946892321 | validation: -0.00013271418061722737]
	TIME [epoch: 8.36 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003451360422657097		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: -0.0003451360422657097 | validation: 0.00047424070748601114]
	TIME [epoch: 8.33 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.233315191548334e-05		[learning rate: 0.00055837]
	Learning Rate: 0.000558371
	LOSS [training: 9.233315191548334e-05 | validation: 0.000338050904078532]
	TIME [epoch: 8.33 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003922976068105937		[learning rate: 0.00055705]
	Learning Rate: 0.000557054
	LOSS [training: 0.003922976068105937 | validation: -0.00019089330490694814]
	TIME [epoch: 8.32 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.963756990063907e-05		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 8.963756990063907e-05 | validation: -0.00014415241224675148]
	TIME [epoch: 8.34 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.493920771077715e-05		[learning rate: 0.00055443]
	Learning Rate: 0.000554429
	LOSS [training: -9.493920771077715e-05 | validation: 0.0005872949299763727]
	TIME [epoch: 8.37 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001281250526468989		[learning rate: 0.00055312]
	Learning Rate: 0.000553121
	LOSS [training: 0.0001281250526468989 | validation: 4.552272179154883e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.448309937014687e-05		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: -8.448309937014687e-05 | validation: -0.0002578883471962352]
	TIME [epoch: 8.33 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025806709911181376		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: -0.00025806709911181376 | validation: -1.4060245973832974e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017337509349140256		[learning rate: 0.00054922]
	Learning Rate: 0.000549216
	LOSS [training: 0.0017337509349140256 | validation: 0.0032175054262080435]
	TIME [epoch: 8.33 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002373289792639223		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.002373289792639223 | validation: -0.0005349966732657947]
	TIME [epoch: 8.37 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042282989914791807		[learning rate: 0.00054663]
	Learning Rate: 0.000546629
	LOSS [training: 0.00042282989914791807 | validation: 0.003623011434022331]
	TIME [epoch: 8.32 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005557952195706567		[learning rate: 0.00054534]
	Learning Rate: 0.000545339
	LOSS [training: 0.005557952195706567 | validation: 0.0008569571634838571]
	TIME [epoch: 8.32 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006063489144850449		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.0006063489144850449 | validation: 3.2348242861703454e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.173173482120477e-05		[learning rate: 0.00054277]
	Learning Rate: 0.000542769
	LOSS [training: -9.173173482120477e-05 | validation: 0.00015696628527366976]
	TIME [epoch: 8.33 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004943821040935297		[learning rate: 0.00054149]
	Learning Rate: 0.000541489
	LOSS [training: -0.0004943821040935297 | validation: -0.0002664272238444356]
	TIME [epoch: 8.37 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025462501014548636		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: -0.00025462501014548636 | validation: -0.0006866264789901115]
	TIME [epoch: 8.33 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005783879846708846		[learning rate: 0.00053894]
	Learning Rate: 0.000538938
	LOSS [training: 0.0005783879846708846 | validation: 0.000396638589363604]
	TIME [epoch: 8.32 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00013563727950086492		[learning rate: 0.00053767]
	Learning Rate: 0.000537666
	LOSS [training: -0.00013563727950086492 | validation: -0.0012426325843721963]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_1288.pth
	Model improved!!!
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014868194845501552		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.00014868194845501552 | validation: -0.0003224140902822206]
	TIME [epoch: 8.33 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008282821646640855		[learning rate: 0.00053513]
	Learning Rate: 0.000535133
	LOSS [training: -0.0008282821646640855 | validation: 0.00023396118188901527]
	TIME [epoch: 8.37 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029588742376151656		[learning rate: 0.00053387]
	Learning Rate: 0.00053387
	LOSS [training: 0.0029588742376151656 | validation: 0.0050169928667698]
	TIME [epoch: 8.33 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004133346430795405		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.004133346430795405 | validation: 0.0013403323298232434]
	TIME [epoch: 8.33 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011906297341707407		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: -0.00011906297341707407 | validation: 0.00017556485981843294]
	TIME [epoch: 8.32 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004188092375998605		[learning rate: 0.0005301]
	Learning Rate: 0.000530101
	LOSS [training: -0.0004188092375998605 | validation: 0.0001553678408806247]
	TIME [epoch: 8.33 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015575646290504628		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: -0.00015575646290504628 | validation: 0.00017081557402189018]
	TIME [epoch: 8.38 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005113431926705489		[learning rate: 0.0005276]
	Learning Rate: 0.000527603
	LOSS [training: -0.0005113431926705489 | validation: -0.00012182916615007456]
	TIME [epoch: 8.33 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004444190085503828		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: -0.0004444190085503828 | validation: 0.0012128585621063901]
	TIME [epoch: 8.33 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021966057587683262		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: -0.00021966057587683262 | validation: 0.0009358784580973448]
	TIME [epoch: 8.32 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.854065339697146e-05		[learning rate: 0.00052388]
	Learning Rate: 0.000523879
	LOSS [training: 5.854065339697146e-05 | validation: 0.00037732307420411274]
	TIME [epoch: 8.33 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006831581353133147		[learning rate: 0.00052264]
	Learning Rate: 0.000522643
	LOSS [training: 0.0006831581353133147 | validation: 0.00010481992175407883]
	TIME [epoch: 8.37 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015382563258173264		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: -0.00015382563258173264 | validation: -0.000280679378410293]
	TIME [epoch: 8.33 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4232862604258266e-05		[learning rate: 0.00052018]
	Learning Rate: 0.00052018
	LOSS [training: 3.4232862604258266e-05 | validation: 0.00040409955080358053]
	TIME [epoch: 8.33 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018636119125703822		[learning rate: 0.00051895]
	Learning Rate: 0.000518953
	LOSS [training: 0.0018636119125703822 | validation: 0.00022564154656043998]
	TIME [epoch: 8.32 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007896568228161873		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: -0.0007896568228161873 | validation: 0.00023723392686700383]
	TIME [epoch: 8.32 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.143834132840408e-05		[learning rate: 0.00051651]
	Learning Rate: 0.000516508
	LOSS [training: 3.143834132840408e-05 | validation: -0.0001292636794516371]
	TIME [epoch: 8.37 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.60854288398898e-05		[learning rate: 0.00051529]
	Learning Rate: 0.000515289
	LOSS [training: 9.60854288398898e-05 | validation: -0.00013907250579209894]
	TIME [epoch: 8.33 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.505977072502801e-05		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: 9.505977072502801e-05 | validation: 0.00042531136611228116]
	TIME [epoch: 8.32 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.041870207591945e-05		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: -4.041870207591945e-05 | validation: 0.0004363828977026767]
	TIME [epoch: 8.33 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012332333335410173		[learning rate: 0.00051165]
	Learning Rate: 0.000511652
	LOSS [training: -0.00012332333335410173 | validation: 9.869700032343642e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010425237796112555		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: -0.00010425237796112555 | validation: 0.0008077887567506999]
	TIME [epoch: 8.37 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003378436372345164		[learning rate: 0.00050924]
	Learning Rate: 0.000509241
	LOSS [training: -0.0003378436372345164 | validation: 0.00010807073373877385]
	TIME [epoch: 8.34 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003975357257165502		[learning rate: 0.00050804]
	Learning Rate: 0.000508039
	LOSS [training: -0.0003975357257165502 | validation: -0.0005583417131573923]
	TIME [epoch: 8.32 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8038414368402037e-06		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 1.8038414368402037e-06 | validation: 0.0011958509568882926]
	TIME [epoch: 8.33 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003543579006122353		[learning rate: 0.00050565]
	Learning Rate: 0.000505646
	LOSS [training: 0.0003543579006122353 | validation: -0.0005279626292486582]
	TIME [epoch: 8.33 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010864511599887793		[learning rate: 0.00050445]
	Learning Rate: 0.000504453
	LOSS [training: -0.00010864511599887793 | validation: 0.00028773110691862505]
	TIME [epoch: 8.37 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017632038634009394		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: -0.00017632038634009394 | validation: 0.0013682712864170306]
	TIME [epoch: 8.34 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.941248437578108e-05		[learning rate: 0.00050208]
	Learning Rate: 0.000502076
	LOSS [training: 8.941248437578108e-05 | validation: 0.0006531093832475774]
	TIME [epoch: 8.33 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003735978824001878		[learning rate: 0.00050089]
	Learning Rate: 0.000500891
	LOSS [training: 0.0003735978824001878 | validation: 0.0021515263288170708]
	TIME [epoch: 8.33 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008963661028899658		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: 0.0008963661028899658 | validation: 0.00045361799549682757]
	TIME [epoch: 8.32 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020452332197306867		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: -0.00020452332197306867 | validation: 0.00023241645034092828]
	TIME [epoch: 8.35 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032992607277719906		[learning rate: 0.00049736]
	Learning Rate: 0.000497355
	LOSS [training: -0.00032992607277719906 | validation: 0.0001566519096872989]
	TIME [epoch: 8.35 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.829228140002266e-05		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: -4.829228140002266e-05 | validation: -0.0004608838266235069]
	TIME [epoch: 8.33 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003673946478731145		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: -0.0003673946478731145 | validation: -0.0003872908290609094]
	TIME [epoch: 8.32 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041148393025506013		[learning rate: 0.00049384]
	Learning Rate: 0.000493844
	LOSS [training: -0.00041148393025506013 | validation: -5.412647245257629e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006589891726858901		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.0006589891726858901 | validation: -0.00017938772643286214]
	TIME [epoch: 8.35 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004838842083177237		[learning rate: 0.00049152]
	Learning Rate: 0.000491517
	LOSS [training: 0.0004838842083177237 | validation: 0.0002818634330367744]
	TIME [epoch: 8.36 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047172296624456195		[learning rate: 0.00049036]
	Learning Rate: 0.000490358
	LOSS [training: 0.00047172296624456195 | validation: 0.001128261412233966]
	TIME [epoch: 8.32 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000624649773110254		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: 0.000624649773110254 | validation: -0.0001979383688745768]
	TIME [epoch: 8.32 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014950045443067907		[learning rate: 0.00048805]
	Learning Rate: 0.000488047
	LOSS [training: 0.00014950045443067907 | validation: -0.000801211368835831]
	TIME [epoch: 8.33 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032827605288566694		[learning rate: 0.0004869]
	Learning Rate: 0.000486896
	LOSS [training: -0.00032827605288566694 | validation: 0.0003170702671327943]
	TIME [epoch: 8.34 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00031702112347274604		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: -0.00031702112347274604 | validation: 0.00010829741663528837]
	TIME [epoch: 8.37 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003941148134017096		[learning rate: 0.0004846]
	Learning Rate: 0.000484601
	LOSS [training: 0.0003941148134017096 | validation: 5.699765169401921e-06]
	TIME [epoch: 8.32 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003446562007048532		[learning rate: 0.00048346]
	Learning Rate: 0.000483458
	LOSS [training: -0.0003446562007048532 | validation: 0.0010971314420665404]
	TIME [epoch: 8.32 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004164698065251429		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: 0.0004164698065251429 | validation: 0.00101744175284477]
	TIME [epoch: 8.33 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6655611683217067e-05		[learning rate: 0.00048118]
	Learning Rate: 0.00048118
	LOSS [training: 1.6655611683217067e-05 | validation: -0.0003098476830877073]
	TIME [epoch: 8.34 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001516000445680101		[learning rate: 0.00048005]
	Learning Rate: 0.000480045
	LOSS [training: 0.0001516000445680101 | validation: -0.00039699725745696]
	TIME [epoch: 8.36 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002992374207514686		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: -0.0002992374207514686 | validation: 0.0017195829543113236]
	TIME [epoch: 8.32 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003259516899923161		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.003259516899923161 | validation: 0.0016393467217084158]
	TIME [epoch: 8.32 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001354851868851974		[learning rate: 0.00047666]
	Learning Rate: 0.000476656
	LOSS [training: 0.001354851868851974 | validation: 0.0008524748192249763]
	TIME [epoch: 8.33 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010633428185556549		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: 0.00010633428185556549 | validation: 0.0001356369195236411]
	TIME [epoch: 8.33 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.48972159361223e-05		[learning rate: 0.00047441]
	Learning Rate: 0.00047441
	LOSS [training: 6.48972159361223e-05 | validation: 0.0004051124706140938]
	TIME [epoch: 8.38 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002239143876985772		[learning rate: 0.00047329]
	Learning Rate: 0.000473291
	LOSS [training: -0.0002239143876985772 | validation: 0.0007888238533963223]
	TIME [epoch: 8.33 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025734714364254475		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: -0.00025734714364254475 | validation: -0.00012595232841781055]
	TIME [epoch: 8.33 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005729546264888071		[learning rate: 0.00047106]
	Learning Rate: 0.000471061
	LOSS [training: -0.0005729546264888071 | validation: -0.00044796458495603724]
	TIME [epoch: 8.32 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023990460473410804		[learning rate: 0.00046995]
	Learning Rate: 0.00046995
	LOSS [training: -0.00023990460473410804 | validation: 0.0005149213750711654]
	TIME [epoch: 8.33 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004660966227961214		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: -0.0004660966227961214 | validation: 0.00022479211696156389]
	TIME [epoch: 8.37 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005443169245692472		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: -0.0005443169245692472 | validation: 0.0013154942239121655]
	TIME [epoch: 8.33 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003035596987584277		[learning rate: 0.00046663]
	Learning Rate: 0.000466632
	LOSS [training: 0.003035596987584277 | validation: -0.0001313892712644691]
	TIME [epoch: 8.32 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00044908627655160704		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: -0.00044908627655160704 | validation: -1.3233670288837374e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006068852118676883		[learning rate: 0.00046443]
	Learning Rate: 0.000464433
	LOSS [training: -0.0006068852118676883 | validation: -5.394629621941551e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003800502096753484		[learning rate: 0.00046334]
	Learning Rate: 0.000463338
	LOSS [training: 0.0003800502096753484 | validation: 0.0008377412652366791]
	TIME [epoch: 8.37 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000303868607984316		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: 0.000303868607984316 | validation: 0.0002879196820446621]
	TIME [epoch: 8.33 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001411376975780183		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.0001411376975780183 | validation: -0.00021541348133860886]
	TIME [epoch: 8.32 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: -2.36981339692388e-05		[learning rate: 0.00046007]
	Learning Rate: 0.000460066
	LOSS [training: -2.36981339692388e-05 | validation: 0.000622777340659031]
	TIME [epoch: 8.33 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008563823416634951		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: 0.0008563823416634951 | validation: 0.0004115632070239843]
	TIME [epoch: 8.33 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004914573279826288		[learning rate: 0.0004579]
	Learning Rate: 0.000457898
	LOSS [training: 0.0004914573279826288 | validation: 2.141009450935935e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023092538336037395		[learning rate: 0.00045682]
	Learning Rate: 0.000456818
	LOSS [training: -0.00023092538336037395 | validation: 0.0005379173472652483]
	TIME [epoch: 8.34 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037125792318851865		[learning rate: 0.00045574]
	Learning Rate: 0.000455741
	LOSS [training: 0.0037125792318851865 | validation: 0.004669518476547701]
	TIME [epoch: 8.33 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004743782346537224		[learning rate: 0.00045467]
	Learning Rate: 0.000454666
	LOSS [training: 0.004743782346537224 | validation: 0.0023347038745544003]
	TIME [epoch: 8.33 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010257716850085557		[learning rate: 0.00045359]
	Learning Rate: 0.000453593
	LOSS [training: 0.0010257716850085557 | validation: 0.0006000395418470719]
	TIME [epoch: 8.33 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.276232371060453e-05		[learning rate: 0.00045252]
	Learning Rate: 0.000452523
	LOSS [training: -6.276232371060453e-05 | validation: -0.0005220675292772725]
	TIME [epoch: 8.36 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027073271285050864		[learning rate: 0.00045146]
	Learning Rate: 0.000451456
	LOSS [training: -0.00027073271285050864 | validation: -4.430025335792687e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045037341611698723		[learning rate: 0.00045039]
	Learning Rate: 0.000450391
	LOSS [training: -0.00045037341611698723 | validation: -0.0005127079010730066]
	TIME [epoch: 8.32 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004296169211131897		[learning rate: 0.00044933]
	Learning Rate: 0.000449329
	LOSS [training: -0.0004296169211131897 | validation: 0.0014285182926915218]
	TIME [epoch: 8.33 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030067917263951324		[learning rate: 0.00044827]
	Learning Rate: 0.000448269
	LOSS [training: 0.00030067917263951324 | validation: -0.00021994591224208367]
	TIME [epoch: 8.33 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001594097805979935		[learning rate: 0.00044721]
	Learning Rate: 0.000447211
	LOSS [training: -0.0001594097805979935 | validation: -0.0005223734006439167]
	TIME [epoch: 8.35 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00014079079827721762		[learning rate: 0.00044616]
	Learning Rate: 0.000446157
	LOSS [training: -0.00014079079827721762 | validation: 0.00012645351315627675]
	TIME [epoch: 8.36 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007097501759502321		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.0007097501759502321 | validation: -0.0005075002053181996]
	TIME [epoch: 8.32 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001877227419635048		[learning rate: 0.00044405]
	Learning Rate: 0.000444054
	LOSS [training: -0.0001877227419635048 | validation: -0.0001954740733363094]
	TIME [epoch: 8.32 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.160899623328663e-05		[learning rate: 0.00044301]
	Learning Rate: 0.000443007
	LOSS [training: 5.160899623328663e-05 | validation: -0.0009309567405701302]
	TIME [epoch: 8.33 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003219660313063475		[learning rate: 0.00044196]
	Learning Rate: 0.000441962
	LOSS [training: -0.0003219660313063475 | validation: 0.0005310271972459427]
	TIME [epoch: 8.34 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005776050918361906		[learning rate: 0.00044092]
	Learning Rate: 0.000440919
	LOSS [training: -0.0005776050918361906 | validation: 0.0009546814614552805]
	TIME [epoch: 8.37 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037126182445947477		[learning rate: 0.00043988]
	Learning Rate: 0.000439879
	LOSS [training: -0.00037126182445947477 | validation: 0.0008245729643597154]
	TIME [epoch: 8.32 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009241310089738037		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.0009241310089738037 | validation: -0.0002070016433501216]
	TIME [epoch: 8.33 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005687744825988919		[learning rate: 0.00043781]
	Learning Rate: 0.000437806
	LOSS [training: -0.0005687744825988919 | validation: 0.0008726923299375305]
	TIME [epoch: 8.33 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015459963051357045		[learning rate: 0.00043677]
	Learning Rate: 0.000436774
	LOSS [training: 0.0015459963051357045 | validation: -0.00016126878682763926]
	TIME [epoch: 8.33 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023553437124566677		[learning rate: 0.00043574]
	Learning Rate: 0.000435743
	LOSS [training: -0.00023553437124566677 | validation: 0.00023451686571034002]
	TIME [epoch: 8.37 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002306969078990513		[learning rate: 0.00043472]
	Learning Rate: 0.000434715
	LOSS [training: -0.0002306969078990513 | validation: -0.00018102661052200108]
	TIME [epoch: 8.33 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.120352404963689e-06		[learning rate: 0.00043369]
	Learning Rate: 0.00043369
	LOSS [training: -5.120352404963689e-06 | validation: -0.00012067051860886348]
	TIME [epoch: 8.32 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018517494535507994		[learning rate: 0.00043267]
	Learning Rate: 0.000432667
	LOSS [training: 0.00018517494535507994 | validation: -0.0007037096569598273]
	TIME [epoch: 8.33 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002660296184559514		[learning rate: 0.00043165]
	Learning Rate: 0.000431647
	LOSS [training: -0.0002660296184559514 | validation: -0.0005833186894677223]
	TIME [epoch: 8.32 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011617111213604995		[learning rate: 0.00043063]
	Learning Rate: 0.000430628
	LOSS [training: -0.0011617111213604995 | validation: 0.00016980286207363046]
	TIME [epoch: 8.37 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012513415990508326		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: -0.00012513415990508326 | validation: 6.55006254722903e-06]
	TIME [epoch: 8.33 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006639636908384533		[learning rate: 0.0004286]
	Learning Rate: 0.000428599
	LOSS [training: -0.0006639636908384533 | validation: -0.0005603591187106818]
	TIME [epoch: 8.33 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002134445946336156		[learning rate: 0.00042759]
	Learning Rate: 0.000427588
	LOSS [training: -0.0002134445946336156 | validation: 0.0005485578024913083]
	TIME [epoch: 8.33 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000283159540111686		[learning rate: 0.00042658]
	Learning Rate: 0.000426579
	LOSS [training: 0.000283159540111686 | validation: 0.0011537642971126676]
	TIME [epoch: 8.33 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003408572142041031		[learning rate: 0.00042557]
	Learning Rate: 0.000425573
	LOSS [training: 0.0003408572142041031 | validation: 0.00041273044056618026]
	TIME [epoch: 8.37 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.960851727528161e-05		[learning rate: 0.00042457]
	Learning Rate: 0.000424569
	LOSS [training: -8.960851727528161e-05 | validation: 0.0004992925230336125]
	TIME [epoch: 8.33 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.255073294046854e-06		[learning rate: 0.00042357]
	Learning Rate: 0.000423568
	LOSS [training: -7.255073294046854e-06 | validation: 0.0017485092102247522]
	TIME [epoch: 8.31 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010102380348492594		[learning rate: 0.00042257]
	Learning Rate: 0.000422569
	LOSS [training: 0.0010102380348492594 | validation: 0.00034306986407726204]
	TIME [epoch: 8.33 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003394331173238066		[learning rate: 0.00042157]
	Learning Rate: 0.000421572
	LOSS [training: 0.0003394331173238066 | validation: -0.0008940194352948558]
	TIME [epoch: 8.33 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002647081028189775		[learning rate: 0.00042058]
	Learning Rate: 0.000420578
	LOSS [training: -0.0002647081028189775 | validation: -0.0009430830256430527]
	TIME [epoch: 8.37 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.126162581141938e-05		[learning rate: 0.00041959]
	Learning Rate: 0.000419586
	LOSS [training: 5.126162581141938e-05 | validation: 0.00018338951284207106]
	TIME [epoch: 8.34 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020189059966939916		[learning rate: 0.0004186]
	Learning Rate: 0.000418596
	LOSS [training: -0.00020189059966939916 | validation: -0.00012305188463724505]
	TIME [epoch: 8.32 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035844074325823064		[learning rate: 0.00041761]
	Learning Rate: 0.000417608
	LOSS [training: -0.00035844074325823064 | validation: -0.0003620052857614775]
	TIME [epoch: 8.32 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004319097259350182		[learning rate: 0.00041662]
	Learning Rate: 0.000416623
	LOSS [training: -0.0004319097259350182 | validation: 0.00013626806767993527]
	TIME [epoch: 8.33 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003770302253936251		[learning rate: 0.00041564]
	Learning Rate: 0.000415641
	LOSS [training: 0.0003770302253936251 | validation: -0.0003000558881108142]
	TIME [epoch: 8.37 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.988068930905774e-05		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 7.988068930905774e-05 | validation: -0.0002748092480367306]
	TIME [epoch: 8.34 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032955613988200355		[learning rate: 0.00041368]
	Learning Rate: 0.000413682
	LOSS [training: -0.00032955613988200355 | validation: 0.0011599971327433765]
	TIME [epoch: 8.34 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00281803791126577		[learning rate: 0.00041271]
	Learning Rate: 0.000412706
	LOSS [training: 0.00281803791126577 | validation: 0.0015620757360755352]
	TIME [epoch: 8.33 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002571344338847426		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.002571344338847426 | validation: 7.222739309111325e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029265250342613977		[learning rate: 0.00041076]
	Learning Rate: 0.000410761
	LOSS [training: -0.00029265250342613977 | validation: 0.0004290858593562809]
	TIME [epoch: 8.37 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001640310317364954		[learning rate: 0.00040979]
	Learning Rate: 0.000409793
	LOSS [training: 0.001640310317364954 | validation: 0.0005206698284813078]
	TIME [epoch: 8.34 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010763116839137379		[learning rate: 0.00040883]
	Learning Rate: 0.000408826
	LOSS [training: 0.0010763116839137379 | validation: -0.00020798238392489223]
	TIME [epoch: 8.33 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.881417291710194e-05		[learning rate: 0.00040786]
	Learning Rate: 0.000407862
	LOSS [training: -9.881417291710194e-05 | validation: -0.0005989553422441868]
	TIME [epoch: 8.33 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.297032632633373e-05		[learning rate: 0.0004069]
	Learning Rate: 0.0004069
	LOSS [training: -6.297032632633373e-05 | validation: -0.0010656330143662487]
	TIME [epoch: 8.33 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008998485554030339		[learning rate: 0.00040594]
	Learning Rate: 0.00040594
	LOSS [training: -0.0008998485554030339 | validation: -0.000512579726036139]
	TIME [epoch: 8.34 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005673993745018988		[learning rate: 0.00040498]
	Learning Rate: 0.000404982
	LOSS [training: -0.0005673993745018988 | validation: 8.6156529447718e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003486348492660536		[learning rate: 0.00040403]
	Learning Rate: 0.000404027
	LOSS [training: -0.0003486348492660536 | validation: -0.00040741000180235745]
	TIME [epoch: 8.33 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000300178414784918		[learning rate: 0.00040307]
	Learning Rate: 0.000403074
	LOSS [training: -0.000300178414784918 | validation: -0.0004621634196280624]
	TIME [epoch: 8.33 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005032256288592927		[learning rate: 0.00040212]
	Learning Rate: 0.000402123
	LOSS [training: -0.0005032256288592927 | validation: -0.0008867136850041648]
	TIME [epoch: 8.33 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007631185774822921		[learning rate: 0.00040117]
	Learning Rate: 0.000401175
	LOSS [training: -0.0007631185774822921 | validation: 0.0006755081717131821]
	TIME [epoch: 8.33 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.619984324212518e-05		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 9.619984324212518e-05 | validation: -0.0005169908112516218]
	TIME [epoch: 8.38 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007699177834456912		[learning rate: 0.00039928]
	Learning Rate: 0.000399284
	LOSS [training: -0.0007699177834456912 | validation: -0.0002180616986085666]
	TIME [epoch: 8.33 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0331934219539406e-05		[learning rate: 0.00039834]
	Learning Rate: 0.000398342
	LOSS [training: 4.0331934219539406e-05 | validation: -0.0001218996971130033]
	TIME [epoch: 8.33 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029233449084196874		[learning rate: 0.0003974]
	Learning Rate: 0.000397403
	LOSS [training: -0.00029233449084196874 | validation: -0.0003381008438709415]
	TIME [epoch: 8.33 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000388486234032005		[learning rate: 0.00039647]
	Learning Rate: 0.000396465
	LOSS [training: -0.000388486234032005 | validation: 0.0007732075772806156]
	TIME [epoch: 8.32 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019143092271113214		[learning rate: 0.00039553]
	Learning Rate: 0.00039553
	LOSS [training: -0.00019143092271113214 | validation: 0.0008443000003509717]
	TIME [epoch: 8.38 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.57002408238949e-05		[learning rate: 0.0003946]
	Learning Rate: 0.000394597
	LOSS [training: -3.57002408238949e-05 | validation: -0.000729539954526043]
	TIME [epoch: 8.33 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005180947001741956		[learning rate: 0.00039367]
	Learning Rate: 0.000393666
	LOSS [training: -0.0005180947001741956 | validation: 0.00028711066944443476]
	TIME [epoch: 8.33 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000540698085016861		[learning rate: 0.00039274]
	Learning Rate: 0.000392738
	LOSS [training: -0.000540698085016861 | validation: 3.8787276798014014e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: -3.517350871086021e-05		[learning rate: 0.00039181]
	Learning Rate: 0.000391811
	LOSS [training: -3.517350871086021e-05 | validation: 0.0005039304515745085]
	TIME [epoch: 8.33 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006201634240856289		[learning rate: 0.00039089]
	Learning Rate: 0.000390887
	LOSS [training: -0.0006201634240856289 | validation: -0.0005036078363841354]
	TIME [epoch: 8.38 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007524300594997546		[learning rate: 0.00038997]
	Learning Rate: 0.000389965
	LOSS [training: -0.0007524300594997546 | validation: -0.0006926439672872782]
	TIME [epoch: 8.34 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007188668633185129		[learning rate: 0.00038905]
	Learning Rate: 0.000389045
	LOSS [training: -0.0007188668633185129 | validation: -9.714933898891288e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00048203941756200355		[learning rate: 0.00038813]
	Learning Rate: 0.000388127
	LOSS [training: -0.00048203941756200355 | validation: 0.00017800642424381995]
	TIME [epoch: 8.33 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7167643945463148e-05		[learning rate: 0.00038721]
	Learning Rate: 0.000387212
	LOSS [training: 2.7167643945463148e-05 | validation: 0.0008433376894900273]
	TIME [epoch: 8.33 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008080765333221062		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.0008080765333221062 | validation: 0.000207557031865087]
	TIME [epoch: 8.38 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3926740595453956e-05		[learning rate: 0.00038539]
	Learning Rate: 0.000385387
	LOSS [training: 1.3926740595453956e-05 | validation: -0.0005861716625078417]
	TIME [epoch: 8.35 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000218968731801741		[learning rate: 0.00038448]
	Learning Rate: 0.000384478
	LOSS [training: 0.000218968731801741 | validation: 0.0005777992665096975]
	TIME [epoch: 8.33 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.866201313755948e-05		[learning rate: 0.00038357]
	Learning Rate: 0.000383571
	LOSS [training: -1.866201313755948e-05 | validation: -0.000758480219156962]
	TIME [epoch: 8.33 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003822316163559041		[learning rate: 0.00038267]
	Learning Rate: 0.000382667
	LOSS [training: -0.0003822316163559041 | validation: 0.0015263237086193648]
	TIME [epoch: 8.33 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002647583774557733		[learning rate: 0.00038176]
	Learning Rate: 0.000381764
	LOSS [training: 0.002647583774557733 | validation: -0.000384639950452835]
	TIME [epoch: 8.37 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007386236762295695		[learning rate: 0.00038086]
	Learning Rate: 0.000380863
	LOSS [training: 0.0007386236762295695 | validation: 0.0011773838571743213]
	TIME [epoch: 8.34 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009657235346016543		[learning rate: 0.00037997]
	Learning Rate: 0.000379965
	LOSS [training: 0.0009657235346016543 | validation: 0.0003995154843323423]
	TIME [epoch: 8.33 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027124524218897795		[learning rate: 0.00037907]
	Learning Rate: 0.000379069
	LOSS [training: -0.00027124524218897795 | validation: -0.0004104645269883097]
	TIME [epoch: 8.33 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.58023444943199e-05		[learning rate: 0.00037817]
	Learning Rate: 0.000378175
	LOSS [training: -7.58023444943199e-05 | validation: -9.7798592889891e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000324965853690854		[learning rate: 0.00037728]
	Learning Rate: 0.000377283
	LOSS [training: -0.000324965853690854 | validation: -0.0008420421677649643]
	TIME [epoch: 8.35 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00217490691379119		[learning rate: 0.00037639]
	Learning Rate: 0.000376393
	LOSS [training: 0.00217490691379119 | validation: 0.0024697112875092866]
	TIME [epoch: 8.36 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010106408406167064		[learning rate: 0.0003755]
	Learning Rate: 0.000375505
	LOSS [training: 0.0010106408406167064 | validation: 0.0003967488552415706]
	TIME [epoch: 8.33 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.319324864787923e-05		[learning rate: 0.00037462]
	Learning Rate: 0.000374619
	LOSS [training: -4.319324864787923e-05 | validation: -9.406641698401553e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00033790697990150376		[learning rate: 0.00037374]
	Learning Rate: 0.000373735
	LOSS [training: -0.00033790697990150376 | validation: -2.13627414121875e-06]
	TIME [epoch: 8.34 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003578935528212637		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: -0.0003578935528212637 | validation: 0.0026410198192601585]
	TIME [epoch: 8.35 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004808961827338479		[learning rate: 0.00037197]
	Learning Rate: 0.000371974
	LOSS [training: 0.0004808961827338479 | validation: -0.00021889828670148902]
	TIME [epoch: 8.37 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002995005716016512		[learning rate: 0.0003711]
	Learning Rate: 0.000371097
	LOSS [training: 0.0002995005716016512 | validation: -0.0003999897435866853]
	TIME [epoch: 8.33 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.082740127296018e-05		[learning rate: 0.00037022]
	Learning Rate: 0.000370221
	LOSS [training: -8.082740127296018e-05 | validation: 7.197584676595038e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007978895430102236		[learning rate: 0.00036935]
	Learning Rate: 0.000369348
	LOSS [training: -0.0007978895430102236 | validation: 0.0005745069634809194]
	TIME [epoch: 8.33 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003046920752874267		[learning rate: 0.00036848]
	Learning Rate: 0.000368477
	LOSS [training: 0.0003046920752874267 | validation: 0.0013219292348172283]
	TIME [epoch: 8.34 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001965581162945729		[learning rate: 0.00036761]
	Learning Rate: 0.000367608
	LOSS [training: 0.0001965581162945729 | validation: -0.00038078116063170733]
	TIME [epoch: 8.38 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028356282960853975		[learning rate: 0.00036674]
	Learning Rate: 0.000366741
	LOSS [training: 0.00028356282960853975 | validation: -0.00044044060196326515]
	TIME [epoch: 8.33 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006939525503734207		[learning rate: 0.00036588]
	Learning Rate: 0.000365876
	LOSS [training: 0.0006939525503734207 | validation: 0.00042142260534110143]
	TIME [epoch: 8.33 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008051956110129337		[learning rate: 0.00036501]
	Learning Rate: 0.000365012
	LOSS [training: -0.0008051956110129337 | validation: 0.0007127805408457268]
	TIME [epoch: 8.33 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040564432782811945		[learning rate: 0.00036415]
	Learning Rate: 0.000364152
	LOSS [training: -0.00040564432782811945 | validation: -0.00017362001100086654]
	TIME [epoch: 8.34 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006812573446522916		[learning rate: 0.00036329]
	Learning Rate: 0.000363293
	LOSS [training: -0.0006812573446522916 | validation: 5.266519523950652e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005429445254568268		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: -0.0005429445254568268 | validation: 0.0010114364114956536]
	TIME [epoch: 8.33 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008239203153505		[learning rate: 0.00036158]
	Learning Rate: 0.000361581
	LOSS [training: -0.0008239203153505 | validation: -0.0005501226277377076]
	TIME [epoch: 8.33 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004954495077909336		[learning rate: 0.00036073]
	Learning Rate: 0.000360728
	LOSS [training: -0.0004954495077909336 | validation: 0.00025726561412904483]
	TIME [epoch: 8.33 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7066444546170083e-05		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 5.7066444546170083e-05 | validation: -8.330670678771269e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005811886623369962		[learning rate: 0.00035903]
	Learning Rate: 0.000359028
	LOSS [training: 0.0005811886623369962 | validation: 0.001141037788262384]
	TIME [epoch: 8.38 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016494674792502662		[learning rate: 0.00035818]
	Learning Rate: 0.000358181
	LOSS [training: 0.00016494674792502662 | validation: -1.7991889672305035e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003443760322964242		[learning rate: 0.00035734]
	Learning Rate: 0.000357336
	LOSS [training: -0.0003443760322964242 | validation: -0.0004965560683343382]
	TIME [epoch: 8.33 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006540397319664631		[learning rate: 0.00035649]
	Learning Rate: 0.000356493
	LOSS [training: -0.0006540397319664631 | validation: -0.0004701929279440979]
	TIME [epoch: 8.33 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018794400308755078		[learning rate: 0.00035565]
	Learning Rate: 0.000355652
	LOSS [training: -0.00018794400308755078 | validation: 0.0011128257245162016]
	TIME [epoch: 8.33 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002231128879539359		[learning rate: 0.00035481]
	Learning Rate: 0.000354813
	LOSS [training: 0.0002231128879539359 | validation: -0.0008622943196084775]
	TIME [epoch: 8.38 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005826818957555817		[learning rate: 0.00035398]
	Learning Rate: 0.000353976
	LOSS [training: -0.0005826818957555817 | validation: 0.0006269787954092099]
	TIME [epoch: 8.34 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009509553023703043		[learning rate: 0.00035314]
	Learning Rate: 0.000353141
	LOSS [training: -0.0009509553023703043 | validation: 0.0003471542399555969]
	TIME [epoch: 8.33 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006943848427785476		[learning rate: 0.00035231]
	Learning Rate: 0.000352309
	LOSS [training: -0.0006943848427785476 | validation: -3.382250590723368e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039392532416249296		[learning rate: 0.00035148]
	Learning Rate: 0.000351477
	LOSS [training: -0.00039392532416249296 | validation: -6.483118746635741e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000673735274717028		[learning rate: 0.00035065]
	Learning Rate: 0.000350648
	LOSS [training: -0.000673735274717028 | validation: -0.0005853016170987195]
	TIME [epoch: 8.38 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002749727314839088		[learning rate: 0.00034982]
	Learning Rate: 0.000349821
	LOSS [training: -0.0002749727314839088 | validation: -0.000833090522363603]
	TIME [epoch: 8.35 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.272885109906419e-05		[learning rate: 0.000349]
	Learning Rate: 0.000348996
	LOSS [training: -4.272885109906419e-05 | validation: 0.0003883990460060782]
	TIME [epoch: 8.34 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004571562810123772		[learning rate: 0.00034817]
	Learning Rate: 0.000348173
	LOSS [training: 0.0004571562810123772 | validation: 0.0007188433736768327]
	TIME [epoch: 8.33 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003950383990368056		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.0003950383990368056 | validation: -0.0001275190561579831]
	TIME [epoch: 8.34 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005711566355727354		[learning rate: 0.00034653]
	Learning Rate: 0.000346532
	LOSS [training: -0.0005711566355727354 | validation: 0.0014060919987468501]
	TIME [epoch: 8.37 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016040993074024359		[learning rate: 0.00034571]
	Learning Rate: 0.000345715
	LOSS [training: 0.00016040993074024359 | validation: 0.0006783207622524307]
	TIME [epoch: 8.35 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039800880746800505		[learning rate: 0.0003449]
	Learning Rate: 0.000344899
	LOSS [training: -0.00039800880746800505 | validation: 0.0012119535073302301]
	TIME [epoch: 8.33 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012202276786743152		[learning rate: 0.00034409]
	Learning Rate: 0.000344086
	LOSS [training: 0.00012202276786743152 | validation: -0.0005623593142868822]
	TIME [epoch: 8.33 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005627922736304019		[learning rate: 0.00034327]
	Learning Rate: 0.000343274
	LOSS [training: 0.0005627922736304019 | validation: 0.0005871555258490585]
	TIME [epoch: 8.33 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003844009451122925		[learning rate: 0.00034246]
	Learning Rate: 0.000342464
	LOSS [training: 0.0003844009451122925 | validation: 0.00019771035309404985]
	TIME [epoch: 8.38 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018988524344781864		[learning rate: 0.00034166]
	Learning Rate: 0.000341657
	LOSS [training: -0.00018988524344781864 | validation: 0.0005845257592509583]
	TIME [epoch: 8.35 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00011723689561332471		[learning rate: 0.00034085]
	Learning Rate: 0.000340851
	LOSS [training: -0.00011723689561332471 | validation: -0.0005943166824756414]
	TIME [epoch: 8.33 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015884019408733409		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: -0.00015884019408733409 | validation: -0.00023582146100348744]
	TIME [epoch: 8.34 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029871989905876117		[learning rate: 0.00033924]
	Learning Rate: 0.000339245
	LOSS [training: -0.00029871989905876117 | validation: -0.0002237930029242401]
	TIME [epoch: 8.34 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037281349317891177		[learning rate: 0.00033844]
	Learning Rate: 0.000338444
	LOSS [training: -0.00037281349317891177 | validation: -0.000719492005048433]
	TIME [epoch: 8.35 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003261572343257515		[learning rate: 0.00033765]
	Learning Rate: 0.000337646
	LOSS [training: -0.0003261572343257515 | validation: -0.0002972105982362408]
	TIME [epoch: 8.37 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003813314429757251		[learning rate: 0.00033685]
	Learning Rate: 0.00033685
	LOSS [training: 0.0003813314429757251 | validation: 0.0007237584676208596]
	TIME [epoch: 8.33 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011554794506937502		[learning rate: 0.00033605]
	Learning Rate: 0.000336055
	LOSS [training: 0.0011554794506937502 | validation: 0.000623077699226052]
	TIME [epoch: 8.34 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012084330344225646		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.00012084330344225646 | validation: -0.0011586297118090472]
	TIME [epoch: 8.33 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006863893114296778		[learning rate: 0.00033447]
	Learning Rate: 0.000334471
	LOSS [training: -0.0006863893114296778 | validation: -0.0001312095438055252]
	TIME [epoch: 8.35 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005603176644056376		[learning rate: 0.00033368]
	Learning Rate: 0.000333682
	LOSS [training: -0.0005603176644056376 | validation: -0.00036889290090083994]
	TIME [epoch: 8.37 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004049198031279886		[learning rate: 0.0003329]
	Learning Rate: 0.000332895
	LOSS [training: -0.0004049198031279886 | validation: 0.001354007993706384]
	TIME [epoch: 8.33 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006879915063997749		[learning rate: 0.00033211]
	Learning Rate: 0.00033211
	LOSS [training: 0.0006879915063997749 | validation: 0.004138137779366438]
	TIME [epoch: 8.33 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004839938523361258		[learning rate: 0.00033133]
	Learning Rate: 0.000331327
	LOSS [training: 0.004839938523361258 | validation: 0.0026407825627114165]
	TIME [epoch: 8.33 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017697018951183866		[learning rate: 0.00033055]
	Learning Rate: 0.000330545
	LOSS [training: 0.0017697018951183866 | validation: 0.00026516987621624333]
	TIME [epoch: 8.34 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006906199129120502		[learning rate: 0.00032977]
	Learning Rate: 0.000329765
	LOSS [training: -0.0006906199129120502 | validation: -0.0008003337299094606]
	TIME [epoch: 8.38 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006221673077574377		[learning rate: 0.00032899]
	Learning Rate: 0.000328988
	LOSS [training: -0.0006221673077574377 | validation: -0.00030515412497499295]
	TIME [epoch: 8.33 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003574729424558836		[learning rate: 0.00032821]
	Learning Rate: 0.000328212
	LOSS [training: -0.0003574729424558836 | validation: -0.00033263165759402693]
	TIME [epoch: 8.33 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005822854293851248		[learning rate: 0.00032744]
	Learning Rate: 0.000327437
	LOSS [training: -0.0005822854293851248 | validation: -0.00046203658083575767]
	TIME [epoch: 8.33 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008631747245302639		[learning rate: 0.00032666]
	Learning Rate: 0.000326665
	LOSS [training: -0.0008631747245302639 | validation: 0.00031434369293070177]
	TIME [epoch: 8.34 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004255602182139271		[learning rate: 0.00032589]
	Learning Rate: 0.000325894
	LOSS [training: -0.0004255602182139271 | validation: -0.00030438211137787883]
	TIME [epoch: 8.38 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006589939253690898		[learning rate: 0.00032513]
	Learning Rate: 0.000325126
	LOSS [training: -0.0006589939253690898 | validation: -0.0004163394788165755]
	TIME [epoch: 8.33 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004451079335903716		[learning rate: 0.00032436]
	Learning Rate: 0.000324359
	LOSS [training: -0.0004451079335903716 | validation: -0.0004388987739860717]
	TIME [epoch: 8.33 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008505609572433269		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: -0.0008505609572433269 | validation: 0.00013683316004528388]
	TIME [epoch: 8.33 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006752862719891769		[learning rate: 0.00032283]
	Learning Rate: 0.00032283
	LOSS [training: -0.0006752862719891769 | validation: 0.000256077822873912]
	TIME [epoch: 8.33 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040691484600746073		[learning rate: 0.00032207]
	Learning Rate: 0.000322069
	LOSS [training: -0.00040691484600746073 | validation: -0.00048448728184263156]
	TIME [epoch: 8.38 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005295806846993392		[learning rate: 0.00032131]
	Learning Rate: 0.000321309
	LOSS [training: -0.0005295806846993392 | validation: -0.00039546409053347015]
	TIME [epoch: 8.33 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000609354682042824		[learning rate: 0.00032055]
	Learning Rate: 0.000320551
	LOSS [training: -0.000609354682042824 | validation: 0.00028271290546043955]
	TIME [epoch: 8.33 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005448615445866722		[learning rate: 0.0003198]
	Learning Rate: 0.000319795
	LOSS [training: -0.0005448615445866722 | validation: -0.0008476583379572617]
	TIME [epoch: 8.33 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008255271552984327		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: -0.0008255271552984327 | validation: 0.0008963406920212708]
	TIME [epoch: 8.33 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000840176981282502		[learning rate: 0.00031829]
	Learning Rate: 0.000318288
	LOSS [training: 0.000840176981282502 | validation: 0.0005783165669082755]
	TIME [epoch: 8.38 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005275774310968205		[learning rate: 0.00031754]
	Learning Rate: 0.000317537
	LOSS [training: 0.0005275774310968205 | validation: 0.001550633960112148]
	TIME [epoch: 8.33 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010065051937895971		[learning rate: 0.00031679]
	Learning Rate: 0.000316788
	LOSS [training: -0.00010065051937895971 | validation: 0.00030297197143649117]
	TIME [epoch: 8.33 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003314891801459607		[learning rate: 0.00031604]
	Learning Rate: 0.000316041
	LOSS [training: -0.0003314891801459607 | validation: -3.352714415355649e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.887061100281983e-05		[learning rate: 0.0003153]
	Learning Rate: 0.000315296
	LOSS [training: 4.887061100281983e-05 | validation: 2.9085231103491267e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00012450605591163332		[learning rate: 0.00031455]
	Learning Rate: 0.000314552
	LOSS [training: -0.00012450605591163332 | validation: 0.000266978971540889]
	TIME [epoch: 8.38 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003743726756043373		[learning rate: 0.00031381]
	Learning Rate: 0.00031381
	LOSS [training: -0.0003743726756043373 | validation: 5.777316547632206e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142013327109105e-05		[learning rate: 0.00031307]
	Learning Rate: 0.00031307
	LOSS [training: 2.142013327109105e-05 | validation: -0.0005225698393501617]
	TIME [epoch: 8.33 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028884751949022645		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: -0.00028884751949022645 | validation: -0.0001292328289277993]
	TIME [epoch: 8.33 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040867323867385674		[learning rate: 0.00031159]
	Learning Rate: 0.000311594
	LOSS [training: -0.00040867323867385674 | validation: -8.338000258288191e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007622196453548931		[learning rate: 0.00031086]
	Learning Rate: 0.00031086
	LOSS [training: -0.0007622196453548931 | validation: -0.0008059652432500055]
	TIME [epoch: 8.37 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039795567436789385		[learning rate: 0.00031013]
	Learning Rate: 0.000310126
	LOSS [training: -0.00039795567436789385 | validation: -0.0008809767808915058]
	TIME [epoch: 8.35 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041392905082764716		[learning rate: 0.00030939]
	Learning Rate: 0.000309395
	LOSS [training: -0.00041392905082764716 | validation: -0.00017258134803999647]
	TIME [epoch: 8.33 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003128833668682696		[learning rate: 0.00030866]
	Learning Rate: 0.000308665
	LOSS [training: -0.0003128833668682696 | validation: -0.0006319025818975357]
	TIME [epoch: 8.33 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004992546686378096		[learning rate: 0.00030794]
	Learning Rate: 0.000307937
	LOSS [training: -0.0004992546686378096 | validation: -0.0010542363054956505]
	TIME [epoch: 8.33 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002442941963674823		[learning rate: 0.00030721]
	Learning Rate: 0.00030721
	LOSS [training: -0.0002442941963674823 | validation: -0.0004224580882743747]
	TIME [epoch: 8.38 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6058055166685674e-06		[learning rate: 0.00030649]
	Learning Rate: 0.000306486
	LOSS [training: 1.6058055166685674e-06 | validation: 0.0021813098203688408]
	TIME [epoch: 8.34 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024496547433960516		[learning rate: 0.00030576]
	Learning Rate: 0.000305763
	LOSS [training: 0.0024496547433960516 | validation: -0.0001053583286295949]
	TIME [epoch: 8.33 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034410092669591246		[learning rate: 0.00030504]
	Learning Rate: 0.000305042
	LOSS [training: -0.00034410092669591246 | validation: -0.0005483605169060452]
	TIME [epoch: 8.33 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020221182527777916		[learning rate: 0.00030432]
	Learning Rate: 0.000304322
	LOSS [training: -0.00020221182527777916 | validation: -0.0006220972355924404]
	TIME [epoch: 8.33 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005124617973165256		[learning rate: 0.0003036]
	Learning Rate: 0.000303604
	LOSS [training: 0.0005124617973165256 | validation: 0.0004904144171230032]
	TIME [epoch: 8.35 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.666405547333621e-05		[learning rate: 0.00030289]
	Learning Rate: 0.000302888
	LOSS [training: 7.666405547333621e-05 | validation: 0.0005096331939035993]
	TIME [epoch: 8.36 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00024350092982965556		[learning rate: 0.00030217]
	Learning Rate: 0.000302174
	LOSS [training: -0.00024350092982965556 | validation: -0.0006498856023929021]
	TIME [epoch: 8.33 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005373565055215971		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: -0.0005373565055215971 | validation: -7.531481237448291e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005447763306621581		[learning rate: 0.00030075]
	Learning Rate: 0.00030075
	LOSS [training: -0.0005447763306621581 | validation: 0.0006322711727287329]
	TIME [epoch: 8.32 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.885713491267386e-05		[learning rate: 0.00030004]
	Learning Rate: 0.00030004
	LOSS [training: 1.885713491267386e-05 | validation: -0.00037393505825530937]
	TIME [epoch: 8.35 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003165264991979424		[learning rate: 0.00029933]
	Learning Rate: 0.000299332
	LOSS [training: -0.0003165264991979424 | validation: 0.0010421641815846524]
	TIME [epoch: 8.36 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032607069592979765		[learning rate: 0.00029863]
	Learning Rate: 0.000298626
	LOSS [training: -0.00032607069592979765 | validation: -0.0007079637186872358]
	TIME [epoch: 8.33 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008817705279099187		[learning rate: 0.00029792]
	Learning Rate: 0.000297922
	LOSS [training: -0.0008817705279099187 | validation: 0.0001826957583397566]
	TIME [epoch: 8.33 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021271335467457542		[learning rate: 0.00029722]
	Learning Rate: 0.000297219
	LOSS [training: -0.00021271335467457542 | validation: 0.00014494747349827407]
	TIME [epoch: 8.32 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005783524281089556		[learning rate: 0.00029652]
	Learning Rate: 0.000296518
	LOSS [training: -0.0005783524281089556 | validation: -0.00034698552080675207]
	TIME [epoch: 8.34 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006739402827057495		[learning rate: 0.00029582]
	Learning Rate: 0.000295819
	LOSS [training: -0.0006739402827057495 | validation: -0.0002961573576005141]
	TIME [epoch: 8.37 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.490162164042901e-05		[learning rate: 0.00029512]
	Learning Rate: 0.000295121
	LOSS [training: -6.490162164042901e-05 | validation: 0.0003756177420485667]
	TIME [epoch: 8.33 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1491339866421168e-05		[learning rate: 0.00029442]
	Learning Rate: 0.000294425
	LOSS [training: 2.1491339866421168e-05 | validation: -0.0005222978838555918]
	TIME [epoch: 8.33 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006957953444514105		[learning rate: 0.00029373]
	Learning Rate: 0.00029373
	LOSS [training: -0.0006957953444514105 | validation: -0.0007268923060204125]
	TIME [epoch: 8.33 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003896799225798526		[learning rate: 0.00029304]
	Learning Rate: 0.000293037
	LOSS [training: -0.0003896799225798526 | validation: -0.000856524666143359]
	TIME [epoch: 8.33 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00030301281137031297		[learning rate: 0.00029235]
	Learning Rate: 0.000292346
	LOSS [training: -0.00030301281137031297 | validation: 0.001414127581555653]
	TIME [epoch: 8.38 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007537146649563793		[learning rate: 0.00029166]
	Learning Rate: 0.000291657
	LOSS [training: 0.0007537146649563793 | validation: -0.00032769450963460666]
	TIME [epoch: 8.33 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004888425751062857		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: -0.0004888425751062857 | validation: -0.0003363241807606299]
	TIME [epoch: 8.33 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004715181864050357		[learning rate: 0.00029028]
	Learning Rate: 0.000290282
	LOSS [training: -0.0004715181864050357 | validation: 0.0006032457627526084]
	TIME [epoch: 8.33 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021420405496465312		[learning rate: 0.0002896]
	Learning Rate: 0.000289598
	LOSS [training: -0.00021420405496465312 | validation: 0.0002628915061474211]
	TIME [epoch: 8.33 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003284880932615284		[learning rate: 0.00028891]
	Learning Rate: 0.000288914
	LOSS [training: -0.0003284880932615284 | validation: 0.00038483771759126876]
	TIME [epoch: 8.37 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00036462617302235724		[learning rate: 0.00028823]
	Learning Rate: 0.000288233
	LOSS [training: -0.00036462617302235724 | validation: 0.0012568917945719226]
	TIME [epoch: 8.32 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021833895711836427		[learning rate: 0.00028755]
	Learning Rate: 0.000287553
	LOSS [training: -0.00021833895711836427 | validation: -0.0006322466482358045]
	TIME [epoch: 8.33 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006857644599932757		[learning rate: 0.00028687]
	Learning Rate: 0.000286875
	LOSS [training: -0.0006857644599932757 | validation: -0.00018245959958779732]
	TIME [epoch: 8.32 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010469981954379487		[learning rate: 0.0002862]
	Learning Rate: 0.000286198
	LOSS [training: -0.0010469981954379487 | validation: 0.0006173101897683582]
	TIME [epoch: 8.32 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.866745381665072e-05		[learning rate: 0.00028552]
	Learning Rate: 0.000285523
	LOSS [training: 3.866745381665072e-05 | validation: -0.0006316310141393804]
	TIME [epoch: 8.38 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000561336979000464		[learning rate: 0.00028485]
	Learning Rate: 0.000284849
	LOSS [training: -0.000561336979000464 | validation: -0.0005338078366373331]
	TIME [epoch: 8.33 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005824444868563227		[learning rate: 0.00028418]
	Learning Rate: 0.000284178
	LOSS [training: -0.0005824444868563227 | validation: -0.0008614580494590194]
	TIME [epoch: 8.32 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002966742761884693		[learning rate: 0.00028351]
	Learning Rate: 0.000283507
	LOSS [training: -0.0002966742761884693 | validation: 0.00065127478030844]
	TIME [epoch: 8.33 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000577159489681155		[learning rate: 0.00028284]
	Learning Rate: 0.000282839
	LOSS [training: -0.000577159489681155 | validation: 0.0008059674731689444]
	TIME [epoch: 8.33 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005166406177377971		[learning rate: 0.00028217]
	Learning Rate: 0.000282171
	LOSS [training: 0.0005166406177377971 | validation: -0.0004928691812691906]
	TIME [epoch: 8.38 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005712631867081824		[learning rate: 0.00028151]
	Learning Rate: 0.000281506
	LOSS [training: -0.0005712631867081824 | validation: 0.00012241845440462033]
	TIME [epoch: 8.34 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045666663080057095		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: -0.00045666663080057095 | validation: -0.0008763284640718192]
	TIME [epoch: 8.33 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008127566564960225		[learning rate: 0.00028018]
	Learning Rate: 0.000280179
	LOSS [training: -0.0008127566564960225 | validation: 0.00046391026886537863]
	TIME [epoch: 8.34 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026550162914434417		[learning rate: 0.00027952]
	Learning Rate: 0.000279518
	LOSS [training: 0.00026550162914434417 | validation: -0.00010733878096636976]
	TIME [epoch: 8.33 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.342369677103352e-05		[learning rate: 0.00027886]
	Learning Rate: 0.000278859
	LOSS [training: -5.342369677103352e-05 | validation: -0.0006372058282284469]
	TIME [epoch: 8.36 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007650871907479671		[learning rate: 0.0002782]
	Learning Rate: 0.000278201
	LOSS [training: -0.0007650871907479671 | validation: -0.0011457615883460135]
	TIME [epoch: 8.34 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004423389557980633		[learning rate: 0.00027755]
	Learning Rate: 0.000277545
	LOSS [training: -0.0004423389557980633 | validation: -0.0005134101133076716]
	TIME [epoch: 8.33 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005021398627893614		[learning rate: 0.00027689]
	Learning Rate: 0.00027689
	LOSS [training: -0.0005021398627893614 | validation: -1.5835930124497456e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005566382796631305		[learning rate: 0.00027624]
	Learning Rate: 0.000276237
	LOSS [training: 0.0005566382796631305 | validation: 0.00012000854451471899]
	TIME [epoch: 8.33 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008731575240049619		[learning rate: 0.00027559]
	Learning Rate: 0.000275586
	LOSS [training: -0.0008731575240049619 | validation: -0.0007822415801483995]
	TIME [epoch: 8.37 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017449735136649934		[learning rate: 0.00027494]
	Learning Rate: 0.000274935
	LOSS [training: -0.00017449735136649934 | validation: -0.0013440448519879235]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_1572.pth
	Model improved!!!
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037418622396072565		[learning rate: 0.00027429]
	Learning Rate: 0.000274287
	LOSS [training: -0.00037418622396072565 | validation: -0.00014271163067708237]
	TIME [epoch: 8.31 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004984812761133909		[learning rate: 0.00027364]
	Learning Rate: 0.00027364
	LOSS [training: -0.0004984812761133909 | validation: -0.00031310052677689404]
	TIME [epoch: 8.32 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043835330024769937		[learning rate: 0.00027299]
	Learning Rate: 0.000272994
	LOSS [training: -0.00043835330024769937 | validation: -0.00021243890392703382]
	TIME [epoch: 8.32 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019360005527077284		[learning rate: 0.00027235]
	Learning Rate: 0.000272351
	LOSS [training: -0.00019360005527077284 | validation: -0.0004495591477651764]
	TIME [epoch: 8.35 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043224353118980104		[learning rate: 0.00027171]
	Learning Rate: 0.000271708
	LOSS [training: -0.00043224353118980104 | validation: -0.0002513284005839256]
	TIME [epoch: 8.33 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027396903549894053		[learning rate: 0.00027107]
	Learning Rate: 0.000271067
	LOSS [training: -0.00027396903549894053 | validation: 0.00011807904890863207]
	TIME [epoch: 8.32 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025933799442833053		[learning rate: 0.00027043]
	Learning Rate: 0.000270428
	LOSS [training: 0.00025933799442833053 | validation: -0.0001212090375619117]
	TIME [epoch: 8.32 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020215998495155916		[learning rate: 0.00026979]
	Learning Rate: 0.00026979
	LOSS [training: -0.00020215998495155916 | validation: -0.0003467695555560879]
	TIME [epoch: 8.31 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005600193802246846		[learning rate: 0.00026915]
	Learning Rate: 0.000269154
	LOSS [training: -0.0005600193802246846 | validation: -0.00026645277150200023]
	TIME [epoch: 8.34 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005471912305155722		[learning rate: 0.00026852]
	Learning Rate: 0.000268519
	LOSS [training: -0.0005471912305155722 | validation: -7.844323775541007e-06]
	TIME [epoch: 8.36 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010786443887760837		[learning rate: 0.00026789]
	Learning Rate: 0.000267885
	LOSS [training: -0.0010786443887760837 | validation: 0.0002328821937332286]
	TIME [epoch: 8.32 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007536161274628871		[learning rate: 0.00026725]
	Learning Rate: 0.000267253
	LOSS [training: -0.0007536161274628871 | validation: -0.00011329644117280413]
	TIME [epoch: 8.33 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.779938999109606e-05		[learning rate: 0.00026662]
	Learning Rate: 0.000266623
	LOSS [training: -6.779938999109606e-05 | validation: 0.0009028169423103952]
	TIME [epoch: 8.33 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000271319195517411		[learning rate: 0.00026599]
	Learning Rate: 0.000265994
	LOSS [training: 0.000271319195517411 | validation: -0.0004730308748414696]
	TIME [epoch: 8.34 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018557453850531736		[learning rate: 0.00026537]
	Learning Rate: 0.000265367
	LOSS [training: -0.00018557453850531736 | validation: -0.00011846695176060696]
	TIME [epoch: 8.36 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004764147901034286		[learning rate: 0.00026474]
	Learning Rate: 0.000264741
	LOSS [training: -0.0004764147901034286 | validation: 1.2232474015403834e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00013336032520825137		[learning rate: 0.00026412]
	Learning Rate: 0.000264116
	LOSS [training: -0.00013336032520825137 | validation: 0.0006876402730333725]
	TIME [epoch: 8.32 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008189369961933477		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: -0.0008189369961933477 | validation: -0.00027630390548777275]
	TIME [epoch: 8.32 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008006959455076792		[learning rate: 0.00026287]
	Learning Rate: 0.000262872
	LOSS [training: -0.0008006959455076792 | validation: 0.0002944073459573202]
	TIME [epoch: 8.33 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045920793965795826		[learning rate: 0.00026225]
	Learning Rate: 0.000262252
	LOSS [training: -0.00045920793965795826 | validation: -0.0004960944471803987]
	TIME [epoch: 8.37 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029522662703590117		[learning rate: 0.00026163]
	Learning Rate: 0.000261633
	LOSS [training: -0.00029522662703590117 | validation: 0.0015212853488499648]
	TIME [epoch: 8.32 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001240549388141303		[learning rate: 0.00026102]
	Learning Rate: 0.000261016
	LOSS [training: 0.001240549388141303 | validation: 0.0012200155791193467]
	TIME [epoch: 8.32 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006068803259057581		[learning rate: 0.0002604]
	Learning Rate: 0.0002604
	LOSS [training: 0.0006068803259057581 | validation: 0.0006424389048557942]
	TIME [epoch: 8.32 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223981658923325e-05		[learning rate: 0.00025979]
	Learning Rate: 0.000259786
	LOSS [training: 3.223981658923325e-05 | validation: 0.0002335612145152011]
	TIME [epoch: 8.33 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005637980865320868		[learning rate: 0.00025917]
	Learning Rate: 0.000259173
	LOSS [training: -0.0005637980865320868 | validation: 0.0002538625462985755]
	TIME [epoch: 8.37 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006044618574710525		[learning rate: 0.00025856]
	Learning Rate: 0.000258562
	LOSS [training: -0.0006044618574710525 | validation: -0.000530592927371825]
	TIME [epoch: 8.32 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005276749412126407		[learning rate: 0.00025795]
	Learning Rate: 0.000257952
	LOSS [training: -0.0005276749412126407 | validation: 0.0002053986682933262]
	TIME [epoch: 8.33 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007007638582827329		[learning rate: 0.00025734]
	Learning Rate: 0.000257343
	LOSS [training: -0.0007007638582827329 | validation: -6.596104993648001e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003237258990441298		[learning rate: 0.00025674]
	Learning Rate: 0.000256736
	LOSS [training: -0.0003237258990441298 | validation: 3.288697950049762e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017488619080291914		[learning rate: 0.00025613]
	Learning Rate: 0.000256131
	LOSS [training: 0.00017488619080291914 | validation: -3.531398541022665e-05]
	TIME [epoch: 8.38 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.754877832587144e-05		[learning rate: 0.00025553]
	Learning Rate: 0.000255527
	LOSS [training: -6.754877832587144e-05 | validation: -0.0006556666781766584]
	TIME [epoch: 8.33 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003821844918425794		[learning rate: 0.00025492]
	Learning Rate: 0.000254924
	LOSS [training: -0.0003821844918425794 | validation: 0.00021162207839493785]
	TIME [epoch: 8.32 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005109049386986193		[learning rate: 0.00025432]
	Learning Rate: 0.000254322
	LOSS [training: -0.0005109049386986193 | validation: -0.0004906810829942092]
	TIME [epoch: 8.32 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003777339604288792		[learning rate: 0.00025372]
	Learning Rate: 0.000253723
	LOSS [training: -0.0003777339604288792 | validation: -9.084996028625714e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028069994001157707		[learning rate: 0.00025312]
	Learning Rate: 0.000253124
	LOSS [training: -0.00028069994001157707 | validation: -0.0006233648340159244]
	TIME [epoch: 8.38 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005365114963777581		[learning rate: 0.00025253]
	Learning Rate: 0.000252527
	LOSS [training: -0.0005365114963777581 | validation: -0.0003213948635498691]
	TIME [epoch: 8.33 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006572003816204095		[learning rate: 0.00025193]
	Learning Rate: 0.000251931
	LOSS [training: -0.0006572003816204095 | validation: -0.00014560406455454357]
	TIME [epoch: 8.32 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004007677169426645		[learning rate: 0.00025134]
	Learning Rate: 0.000251337
	LOSS [training: -0.0004007677169426645 | validation: 0.0007821686459755726]
	TIME [epoch: 8.33 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003408599701971724		[learning rate: 0.00025074]
	Learning Rate: 0.000250744
	LOSS [training: -0.0003408599701971724 | validation: 5.792656381090433e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018939591960062942		[learning rate: 0.00025015]
	Learning Rate: 0.000250153
	LOSS [training: -0.00018939591960062942 | validation: 0.00047516154906314997]
	TIME [epoch: 8.37 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00018681964500561079		[learning rate: 0.00024956]
	Learning Rate: 0.000249563
	LOSS [training: -0.00018681964500561079 | validation: 0.001311724550866178]
	TIME [epoch: 8.34 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027354460680620996		[learning rate: 0.00024897]
	Learning Rate: 0.000248974
	LOSS [training: 0.00027354460680620996 | validation: 0.0004838687311498311]
	TIME [epoch: 8.33 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.133135435758064e-05		[learning rate: 0.00024839]
	Learning Rate: 0.000248387
	LOSS [training: -7.133135435758064e-05 | validation: 0.0005888025872647229]
	TIME [epoch: 8.33 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014894336460901986		[learning rate: 0.0002478]
	Learning Rate: 0.000247801
	LOSS [training: 0.0014894336460901986 | validation: 0.001676669203444814]
	TIME [epoch: 8.32 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008151235169838078		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.0008151235169838078 | validation: -0.00032703131905520346]
	TIME [epoch: 8.37 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003699798323161647		[learning rate: 0.00024663]
	Learning Rate: 0.000246633
	LOSS [training: -0.0003699798323161647 | validation: 0.00015456946664376938]
	TIME [epoch: 8.33 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002234828244347855		[learning rate: 0.00024605]
	Learning Rate: 0.000246051
	LOSS [training: -0.0002234828244347855 | validation: -0.00032293666108641354]
	TIME [epoch: 8.33 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046362500487595273		[learning rate: 0.00024547]
	Learning Rate: 0.000245471
	LOSS [training: -0.00046362500487595273 | validation: 3.573954155797932e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000208196738762646		[learning rate: 0.00024489]
	Learning Rate: 0.000244892
	LOSS [training: -0.000208196738762646 | validation: -0.00046372211968002475]
	TIME [epoch: 8.33 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007891562415581146		[learning rate: 0.00024431]
	Learning Rate: 0.000244314
	LOSS [training: -0.0007891562415581146 | validation: 0.000808527171628251]
	TIME [epoch: 8.37 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008707495627050646		[learning rate: 0.00024374]
	Learning Rate: 0.000243738
	LOSS [training: -0.0008707495627050646 | validation: -0.00041037558458830326]
	TIME [epoch: 8.34 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008262197801754397		[learning rate: 0.00024316]
	Learning Rate: 0.000243163
	LOSS [training: -0.0008262197801754397 | validation: -0.000874014144461797]
	TIME [epoch: 8.33 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00064834821943277		[learning rate: 0.00024259]
	Learning Rate: 0.000242589
	LOSS [training: -0.00064834821943277 | validation: -0.0004749155916190744]
	TIME [epoch: 8.32 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008513313965954934		[learning rate: 0.00024202]
	Learning Rate: 0.000242017
	LOSS [training: -0.0008513313965954934 | validation: -0.0005599603285393058]
	TIME [epoch: 8.33 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020892675022608033		[learning rate: 0.00024145]
	Learning Rate: 0.000241446
	LOSS [training: -0.00020892675022608033 | validation: -0.0004336463430491948]
	TIME [epoch: 8.35 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004895758037940591		[learning rate: 0.00024088]
	Learning Rate: 0.000240877
	LOSS [training: -0.0004895758037940591 | validation: 0.0004284636467491376]
	TIME [epoch: 8.35 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00033413599544881967		[learning rate: 0.00024031]
	Learning Rate: 0.000240309
	LOSS [training: -0.00033413599544881967 | validation: 0.00010349724148773064]
	TIME [epoch: 8.32 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005919993570690172		[learning rate: 0.00023974]
	Learning Rate: 0.000239742
	LOSS [training: -0.0005919993570690172 | validation: 0.00100783356148251]
	TIME [epoch: 8.32 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016037831841507145		[learning rate: 0.00023918]
	Learning Rate: 0.000239176
	LOSS [training: 0.0016037831841507145 | validation: 0.0004190354315210319]
	TIME [epoch: 8.32 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048113918032337483		[learning rate: 0.00023861]
	Learning Rate: 0.000238612
	LOSS [training: 0.00048113918032337483 | validation: -0.00041993546911245485]
	TIME [epoch: 8.34 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004006745896933835		[learning rate: 0.00023805]
	Learning Rate: 0.000238049
	LOSS [training: -0.0004006745896933835 | validation: -0.0009673073388311147]
	TIME [epoch: 8.36 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005281377663823151		[learning rate: 0.00023749]
	Learning Rate: 0.000237488
	LOSS [training: -0.0005281377663823151 | validation: 0.0004881805190202879]
	TIME [epoch: 8.32 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003654539736243547		[learning rate: 0.00023693]
	Learning Rate: 0.000236927
	LOSS [training: -0.0003654539736243547 | validation: -0.00021143942066447836]
	TIME [epoch: 8.32 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000795350060049867		[learning rate: 0.00023637]
	Learning Rate: 0.000236369
	LOSS [training: -0.000795350060049867 | validation: -0.00014801459854999965]
	TIME [epoch: 8.32 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015739875091949098		[learning rate: 0.00023581]
	Learning Rate: 0.000235811
	LOSS [training: -0.00015739875091949098 | validation: 0.0003504781601044451]
	TIME [epoch: 8.33 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003244330806477136		[learning rate: 0.00023525]
	Learning Rate: 0.000235255
	LOSS [training: -0.0003244330806477136 | validation: -0.0011083490942984206]
	TIME [epoch: 8.37 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006071184735524515		[learning rate: 0.0002347]
	Learning Rate: 0.0002347
	LOSS [training: -0.0006071184735524515 | validation: -5.0666069283236584e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008414025068893027		[learning rate: 0.00023415]
	Learning Rate: 0.000234146
	LOSS [training: -0.0008414025068893027 | validation: -4.112333194440643e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005012510001939339		[learning rate: 0.00023359]
	Learning Rate: 0.000233594
	LOSS [training: -0.0005012510001939339 | validation: -2.233835608156599e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005989995889161428		[learning rate: 0.00023304]
	Learning Rate: 0.000233043
	LOSS [training: -0.0005989995889161428 | validation: 0.00037941756923224235]
	TIME [epoch: 8.34 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.9406788232488904e-05		[learning rate: 0.00023249]
	Learning Rate: 0.000232493
	LOSS [training: -4.9406788232488904e-05 | validation: -0.0003901681896602987]
	TIME [epoch: 8.37 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004931434406250828		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: -0.0004931434406250828 | validation: 6.850098061378374e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005488738960042676		[learning rate: 0.0002314]
	Learning Rate: 0.000231398
	LOSS [training: -0.0005488738960042676 | validation: 0.0005225524118914797]
	TIME [epoch: 8.32 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006235495841873164		[learning rate: 0.00023085]
	Learning Rate: 0.000230852
	LOSS [training: -0.0006235495841873164 | validation: -0.00023768183044635996]
	TIME [epoch: 8.32 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007439031603697311		[learning rate: 0.00023031]
	Learning Rate: 0.000230307
	LOSS [training: -0.0007439031603697311 | validation: -0.0006578660520876807]
	TIME [epoch: 8.33 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005137366845421245		[learning rate: 0.00022976]
	Learning Rate: 0.000229764
	LOSS [training: -0.0005137366845421245 | validation: -0.00015926634113787853]
	TIME [epoch: 8.38 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006646138021783174		[learning rate: 0.00022922]
	Learning Rate: 0.000229222
	LOSS [training: -0.0006646138021783174 | validation: -0.00027913253192956417]
	TIME [epoch: 8.33 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008856982221014221		[learning rate: 0.00022868]
	Learning Rate: 0.000228681
	LOSS [training: -0.0008856982221014221 | validation: 0.00012753710897457494]
	TIME [epoch: 8.33 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008856348811857933		[learning rate: 0.00022814]
	Learning Rate: 0.000228142
	LOSS [training: -0.0008856348811857933 | validation: 0.00010008118003487445]
	TIME [epoch: 8.32 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008079124424970409		[learning rate: 0.0002276]
	Learning Rate: 0.000227604
	LOSS [training: -0.0008079124424970409 | validation: 3.631680314766859e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00022096160897439819		[learning rate: 0.00022707]
	Learning Rate: 0.000227067
	LOSS [training: -0.00022096160897439819 | validation: -0.0007583896074977304]
	TIME [epoch: 8.38 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000451730290116011		[learning rate: 0.00022653]
	Learning Rate: 0.000226531
	LOSS [training: -0.000451730290116011 | validation: -0.00047776540663411104]
	TIME [epoch: 8.33 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006557693734870045		[learning rate: 0.000226]
	Learning Rate: 0.000225997
	LOSS [training: -0.0006557693734870045 | validation: -0.0006631404352324077]
	TIME [epoch: 8.33 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003743936930351052		[learning rate: 0.00022546]
	Learning Rate: 0.000225464
	LOSS [training: -0.0003743936930351052 | validation: -0.0004583957274100019]
	TIME [epoch: 8.33 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016161911601363906		[learning rate: 0.00022493]
	Learning Rate: 0.000224932
	LOSS [training: 0.0016161911601363906 | validation: 0.0011749033629386725]
	TIME [epoch: 8.34 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041119270211094296		[learning rate: 0.0002244]
	Learning Rate: 0.000224401
	LOSS [training: 0.00041119270211094296 | validation: -0.0005125180123720515]
	TIME [epoch: 8.38 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006367686245081271		[learning rate: 0.00022387]
	Learning Rate: 0.000223872
	LOSS [training: -0.0006367686245081271 | validation: 0.001105886487865647]
	TIME [epoch: 8.35 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006112508849375715		[learning rate: 0.00022334]
	Learning Rate: 0.000223344
	LOSS [training: -0.0006112508849375715 | validation: -0.001175899671835472]
	TIME [epoch: 8.32 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006177847645463714		[learning rate: 0.00022282]
	Learning Rate: 0.000222817
	LOSS [training: -0.0006177847645463714 | validation: -0.00112812063380971]
	TIME [epoch: 8.33 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006341700340935048		[learning rate: 0.00022229]
	Learning Rate: 0.000222292
	LOSS [training: -0.0006341700340935048 | validation: -0.0008740228407706359]
	TIME [epoch: 8.33 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026541411184376407		[learning rate: 0.00022177]
	Learning Rate: 0.000221767
	LOSS [training: 0.00026541411184376407 | validation: 5.7827357272385965e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006622520671319316		[learning rate: 0.00022124]
	Learning Rate: 0.000221244
	LOSS [training: -0.0006622520671319316 | validation: -0.0004988646975299886]
	TIME [epoch: 8.34 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013367294192576332		[learning rate: 0.00022072]
	Learning Rate: 0.000220722
	LOSS [training: 0.0013367294192576332 | validation: 0.0008133150796406206]
	TIME [epoch: 8.33 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010195808938661644		[learning rate: 0.0002202]
	Learning Rate: 0.000220202
	LOSS [training: 0.0010195808938661644 | validation: 0.001098802529454586]
	TIME [epoch: 8.34 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017942794735090772		[learning rate: 0.00021968]
	Learning Rate: 0.000219682
	LOSS [training: -0.00017942794735090772 | validation: -3.480635387366433e-06]
	TIME [epoch: 8.33 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00017379143627639816		[learning rate: 0.00021916]
	Learning Rate: 0.000219164
	LOSS [training: -0.00017379143627639816 | validation: -0.000782510357030259]
	TIME [epoch: 8.37 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006629653756036411		[learning rate: 0.00021865]
	Learning Rate: 0.000218647
	LOSS [training: -0.0006629653756036411 | validation: 0.00025985468358942135]
	TIME [epoch: 8.34 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007566994509729697		[learning rate: 0.00021813]
	Learning Rate: 0.000218131
	LOSS [training: -0.0007566994509729697 | validation: -0.000562181783929589]
	TIME [epoch: 8.32 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008498971895250312		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: -0.0008498971895250312 | validation: -0.0003724587956188343]
	TIME [epoch: 8.33 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000523240609354442		[learning rate: 0.0002171]
	Learning Rate: 0.000217103
	LOSS [training: -0.000523240609354442 | validation: -8.307626393199906e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009171642955562009		[learning rate: 0.00021659]
	Learning Rate: 0.000216591
	LOSS [training: -0.0009171642955562009 | validation: -7.808614912240629e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004766388883061057		[learning rate: 0.00021608]
	Learning Rate: 0.00021608
	LOSS [training: -0.0004766388883061057 | validation: -0.00024057515625413738]
	TIME [epoch: 8.35 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00033232605367054016		[learning rate: 0.00021557]
	Learning Rate: 0.000215571
	LOSS [training: -0.00033232605367054016 | validation: -5.9615199142366284e-06]
	TIME [epoch: 8.32 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043785418177541406		[learning rate: 0.00021506]
	Learning Rate: 0.000215062
	LOSS [training: -0.00043785418177541406 | validation: -0.0008800570409159328]
	TIME [epoch: 8.33 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00032485497408535417		[learning rate: 0.00021455]
	Learning Rate: 0.000214555
	LOSS [training: -0.00032485497408535417 | validation: -0.0008851583265048375]
	TIME [epoch: 8.33 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007375120072660145		[learning rate: 0.00021405]
	Learning Rate: 0.000214049
	LOSS [training: -0.0007375120072660145 | validation: -0.0002113053515802945]
	TIME [epoch: 8.34 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007429669623929245		[learning rate: 0.00021354]
	Learning Rate: 0.000213544
	LOSS [training: -0.0007429669623929245 | validation: -0.0001890984559864113]
	TIME [epoch: 8.37 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008069360053920246		[learning rate: 0.00021304]
	Learning Rate: 0.00021304
	LOSS [training: -0.0008069360053920246 | validation: -0.0002139247885613269]
	TIME [epoch: 8.32 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00020058598515383964		[learning rate: 0.00021254]
	Learning Rate: 0.000212538
	LOSS [training: -0.00020058598515383964 | validation: -0.00040678915114014425]
	TIME [epoch: 8.33 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004396914619156991		[learning rate: 0.00021204]
	Learning Rate: 0.000212036
	LOSS [training: -0.0004396914619156991 | validation: -0.0005874617004261191]
	TIME [epoch: 8.32 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.73044700318269e-05		[learning rate: 0.00021154]
	Learning Rate: 0.000211536
	LOSS [training: -8.73044700318269e-05 | validation: 0.0009140019825733617]
	TIME [epoch: 8.33 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001092872609602784		[learning rate: 0.00021104]
	Learning Rate: 0.000211037
	LOSS [training: -0.0001092872609602784 | validation: -0.00010141208990107665]
	TIME [epoch: 8.37 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005101810494300452		[learning rate: 0.00021054]
	Learning Rate: 0.000210539
	LOSS [training: 0.0005101810494300452 | validation: 0.0008378734710860569]
	TIME [epoch: 8.33 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001415333828346673		[learning rate: 0.00021004]
	Learning Rate: 0.000210043
	LOSS [training: 0.001415333828346673 | validation: -0.0004943887446335276]
	TIME [epoch: 8.33 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040655890313170165		[learning rate: 0.00020955]
	Learning Rate: 0.000209547
	LOSS [training: -0.00040655890313170165 | validation: -0.0006536001953570945]
	TIME [epoch: 8.33 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006877506914128065		[learning rate: 0.00020905]
	Learning Rate: 0.000209053
	LOSS [training: -0.0006877506914128065 | validation: -0.00036110859862136245]
	TIME [epoch: 8.33 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006098265212905037		[learning rate: 0.00020856]
	Learning Rate: 0.00020856
	LOSS [training: -0.0006098265212905037 | validation: -0.0005446263412438514]
	TIME [epoch: 8.37 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006531390336354335		[learning rate: 0.00020807]
	Learning Rate: 0.000208068
	LOSS [training: -0.0006531390336354335 | validation: -0.00015542240019598497]
	TIME [epoch: 8.32 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010440539775277262		[learning rate: 0.00020758]
	Learning Rate: 0.000207577
	LOSS [training: -0.0010440539775277262 | validation: -0.001169909409018872]
	TIME [epoch: 8.32 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005388077705213914		[learning rate: 0.00020709]
	Learning Rate: 0.000207087
	LOSS [training: -0.0005388077705213914 | validation: -0.00053048170061914]
	TIME [epoch: 8.32 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000541928140066501		[learning rate: 0.0002066]
	Learning Rate: 0.000206599
	LOSS [training: -0.000541928140066501 | validation: -5.382365198740356e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003627085300878135		[learning rate: 0.00020611]
	Learning Rate: 0.000206112
	LOSS [training: 0.0003627085300878135 | validation: 7.995928955876065e-05]
	TIME [epoch: 8.39 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020332142393286758		[learning rate: 0.00020563]
	Learning Rate: 0.000205625
	LOSS [training: 0.00020332142393286758 | validation: -0.0010235527173738266]
	TIME [epoch: 8.33 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00025413286260345244		[learning rate: 0.00020514]
	Learning Rate: 0.00020514
	LOSS [training: -0.00025413286260345244 | validation: -0.00017355671684491237]
	TIME [epoch: 8.33 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006010415674446187		[learning rate: 0.00020466]
	Learning Rate: 0.000204657
	LOSS [training: -0.0006010415674446187 | validation: 3.007778195797964e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007563095326135558		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: -0.0007563095326135558 | validation: -7.005248260453235e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019450894831528242		[learning rate: 0.00020369]
	Learning Rate: 0.000203692
	LOSS [training: -0.00019450894831528242 | validation: -0.0002342997605960111]
	TIME [epoch: 8.38 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000851369316655477		[learning rate: 0.00020321]
	Learning Rate: 0.000203212
	LOSS [training: -0.000851369316655477 | validation: 0.0007252007677746252]
	TIME [epoch: 8.34 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005942550254950415		[learning rate: 0.00020273]
	Learning Rate: 0.000202732
	LOSS [training: 0.0005942550254950415 | validation: -0.0005800560931934071]
	TIME [epoch: 8.34 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003848657696381006		[learning rate: 0.00020225]
	Learning Rate: 0.000202254
	LOSS [training: -0.0003848657696381006 | validation: -0.00018491284800366658]
	TIME [epoch: 8.33 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007286415224240594		[learning rate: 0.00020178]
	Learning Rate: 0.000201777
	LOSS [training: -0.0007286415224240594 | validation: 0.000509964080516888]
	TIME [epoch: 8.32 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003555579221282248		[learning rate: 0.0002013]
	Learning Rate: 0.000201301
	LOSS [training: 0.0003555579221282248 | validation: -0.0005908016112287889]
	TIME [epoch: 8.38 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000685680225085646		[learning rate: 0.00020083]
	Learning Rate: 0.000200826
	LOSS [training: -0.000685680225085646 | validation: -0.000612630120481592]
	TIME [epoch: 8.34 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008062434916744367		[learning rate: 0.00020035]
	Learning Rate: 0.000200353
	LOSS [training: -0.0008062434916744367 | validation: -0.0008075412562412515]
	TIME [epoch: 8.33 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003726870005028078		[learning rate: 0.00019988]
	Learning Rate: 0.00019988
	LOSS [training: -0.0003726870005028078 | validation: -0.00022866049893461373]
	TIME [epoch: 8.33 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006445423640833378		[learning rate: 0.00019941]
	Learning Rate: 0.000199408
	LOSS [training: -0.0006445423640833378 | validation: 0.00038100114371620415]
	TIME [epoch: 8.33 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010602412975947194		[learning rate: 0.00019894]
	Learning Rate: 0.000198938
	LOSS [training: -0.00010602412975947194 | validation: -0.00046436186324240187]
	TIME [epoch: 8.37 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003745743610051442		[learning rate: 0.00019847]
	Learning Rate: 0.000198469
	LOSS [training: -0.0003745743610051442 | validation: -5.418849298540439e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005638867576704638		[learning rate: 0.000198]
	Learning Rate: 0.000198001
	LOSS [training: 0.0005638867576704638 | validation: -0.0003901062641183928]
	TIME [epoch: 8.33 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004757299122248411		[learning rate: 0.00019753]
	Learning Rate: 0.000197534
	LOSS [training: -0.0004757299122248411 | validation: -0.00016346894193455515]
	TIME [epoch: 8.33 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006803222488431754		[learning rate: 0.00019707]
	Learning Rate: 0.000197068
	LOSS [training: 0.0006803222488431754 | validation: -3.294816719562511e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00010863848503269557		[learning rate: 0.0001966]
	Learning Rate: 0.000196603
	LOSS [training: -0.00010863848503269557 | validation: 0.0001165571921544113]
	TIME [epoch: 8.37 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005769220341963568		[learning rate: 0.00019614]
	Learning Rate: 0.000196139
	LOSS [training: -0.0005769220341963568 | validation: -0.00034335585245159493]
	TIME [epoch: 8.35 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046313508684652074		[learning rate: 0.00019568]
	Learning Rate: 0.000195676
	LOSS [training: -0.00046313508684652074 | validation: -0.00037140134491466664]
	TIME [epoch: 8.32 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005744497970087205		[learning rate: 0.00019521]
	Learning Rate: 0.000195215
	LOSS [training: -0.0005744497970087205 | validation: 0.0006074536434588724]
	TIME [epoch: 8.32 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009848171264885941		[learning rate: 0.00019475]
	Learning Rate: 0.000194754
	LOSS [training: -0.0009848171264885941 | validation: 0.001023495440403743]
	TIME [epoch: 8.32 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008263176514601273		[learning rate: 0.00019429]
	Learning Rate: 0.000194295
	LOSS [training: -0.0008263176514601273 | validation: -0.00043972622431865375]
	TIME [epoch: 8.37 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006037344335093886		[learning rate: 0.00019384]
	Learning Rate: 0.000193837
	LOSS [training: -0.0006037344335093886 | validation: -0.00013749933792764368]
	TIME [epoch: 8.34 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006485769063972428		[learning rate: 0.00019338]
	Learning Rate: 0.000193379
	LOSS [training: -0.0006485769063972428 | validation: 0.0004363512625502221]
	TIME [epoch: 8.33 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001000272324926025		[learning rate: 0.00019292]
	Learning Rate: 0.000192923
	LOSS [training: -0.001000272324926025 | validation: 0.0001296959722795301]
	TIME [epoch: 8.32 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047741883079844573		[learning rate: 0.00019247]
	Learning Rate: 0.000192468
	LOSS [training: -0.00047741883079844573 | validation: -0.0006144965090557397]
	TIME [epoch: 8.33 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006905618725222933		[learning rate: 0.00019201]
	Learning Rate: 0.000192014
	LOSS [training: -0.0006905618725222933 | validation: -0.0004817167707405688]
	TIME [epoch: 8.34 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.840263910168123e-05		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 7.840263910168123e-05 | validation: -8.849033080257087e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008648544089924139		[learning rate: 0.00019111]
	Learning Rate: 0.000191109
	LOSS [training: -0.0008648544089924139 | validation: 2.211425972373915e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001033135375680021		[learning rate: 0.00019066]
	Learning Rate: 0.000190659
	LOSS [training: -0.001033135375680021 | validation: -0.00031165407829420876]
	TIME [epoch: 8.34 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004505439371821875		[learning rate: 0.00019021]
	Learning Rate: 0.000190209
	LOSS [training: -0.0004505439371821875 | validation: -0.00037176270725600705]
	TIME [epoch: 8.33 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005911960695479956		[learning rate: 0.00018976]
	Learning Rate: 0.00018976
	LOSS [training: -0.0005911960695479956 | validation: 0.00018016073671268137]
	TIME [epoch: 8.34 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047392537231892985		[learning rate: 0.00018931]
	Learning Rate: 0.000189313
	LOSS [training: -0.00047392537231892985 | validation: -0.0008252139297148289]
	TIME [epoch: 8.38 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007805254102176103		[learning rate: 0.00018887]
	Learning Rate: 0.000188866
	LOSS [training: -0.0007805254102176103 | validation: -0.0008764219005965676]
	TIME [epoch: 8.32 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000526656209052077		[learning rate: 0.00018842]
	Learning Rate: 0.00018842
	LOSS [training: -0.000526656209052077 | validation: -0.0003707888723275681]
	TIME [epoch: 8.32 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00015444235380010097		[learning rate: 0.00018798]
	Learning Rate: 0.000187976
	LOSS [training: -0.00015444235380010097 | validation: -0.0006389529770335152]
	TIME [epoch: 8.33 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000578484664496187		[learning rate: 0.00018753]
	Learning Rate: 0.000187533
	LOSS [training: -0.000578484664496187 | validation: -0.00044617302082188145]
	TIME [epoch: 8.33 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004932936067842842		[learning rate: 0.00018709]
	Learning Rate: 0.00018709
	LOSS [training: -0.0004932936067842842 | validation: 0.00035428050578081654]
	TIME [epoch: 8.37 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003900322338608631		[learning rate: 0.00018665]
	Learning Rate: 0.000186649
	LOSS [training: 0.0003900322338608631 | validation: -0.000128367358247949]
	TIME [epoch: 8.33 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000633473603433209		[learning rate: 0.00018621]
	Learning Rate: 0.000186209
	LOSS [training: -0.000633473603433209 | validation: -0.0012068168381550602]
	TIME [epoch: 8.32 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011032503688746772		[learning rate: 0.00018577]
	Learning Rate: 0.000185769
	LOSS [training: -0.0011032503688746772 | validation: -0.000662835840473222]
	TIME [epoch: 8.32 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005997033428310368		[learning rate: 0.00018533]
	Learning Rate: 0.000185331
	LOSS [training: -0.0005997033428310368 | validation: -0.0010763228878807691]
	TIME [epoch: 8.33 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000511997247441357		[learning rate: 0.00018489]
	Learning Rate: 0.000184894
	LOSS [training: -0.000511997247441357 | validation: -0.000578450200013521]
	TIME [epoch: 8.38 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005306965635853145		[learning rate: 0.00018446]
	Learning Rate: 0.000184458
	LOSS [training: -0.0005306965635853145 | validation: -0.0007453070772340279]
	TIME [epoch: 8.33 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009252044592481796		[learning rate: 0.00018402]
	Learning Rate: 0.000184023
	LOSS [training: -0.0009252044592481796 | validation: 0.0007029638634257038]
	TIME [epoch: 8.32 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003393672884930512		[learning rate: 0.00018359]
	Learning Rate: 0.000183589
	LOSS [training: -0.0003393672884930512 | validation: -0.00062758918661772]
	TIME [epoch: 8.33 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004388970453970731		[learning rate: 0.00018316]
	Learning Rate: 0.000183156
	LOSS [training: -0.0004388970453970731 | validation: -0.0006619653991493113]
	TIME [epoch: 8.32 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004564483444343181		[learning rate: 0.00018272]
	Learning Rate: 0.000182724
	LOSS [training: -0.0004564483444343181 | validation: -0.0003599364973597617]
	TIME [epoch: 8.38 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045795723711509887		[learning rate: 0.00018229]
	Learning Rate: 0.000182293
	LOSS [training: -0.00045795723711509887 | validation: -0.0005174858638932607]
	TIME [epoch: 8.33 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008592151738684071		[learning rate: 0.00018186]
	Learning Rate: 0.000181863
	LOSS [training: -0.0008592151738684071 | validation: -0.00039975387477733464]
	TIME [epoch: 8.32 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005960191860623616		[learning rate: 0.00018143]
	Learning Rate: 0.000181434
	LOSS [training: -0.0005960191860623616 | validation: 0.0007884828189743357]
	TIME [epoch: 8.32 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009264440868225561		[learning rate: 0.00018101]
	Learning Rate: 0.000181006
	LOSS [training: -0.0009264440868225561 | validation: -0.0007090840630165576]
	TIME [epoch: 8.33 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000534449903132084		[learning rate: 0.00018058]
	Learning Rate: 0.000180579
	LOSS [training: -0.000534449903132084 | validation: -0.00030313045429926653]
	TIME [epoch: 8.37 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007279573820214895		[learning rate: 0.00018015]
	Learning Rate: 0.000180153
	LOSS [training: -0.0007279573820214895 | validation: -0.0006006724045210915]
	TIME [epoch: 8.33 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029124121633497806		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: -0.00029124121633497806 | validation: 0.0006172021765959951]
	TIME [epoch: 8.33 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013544886661269914		[learning rate: 0.0001793]
	Learning Rate: 0.000179304
	LOSS [training: 0.00013544886661269914 | validation: 0.0006803684621334942]
	TIME [epoch: 8.32 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.4466268996949285e-05		[learning rate: 0.00017888]
	Learning Rate: 0.000178881
	LOSS [training: -4.4466268996949285e-05 | validation: 0.0002833235304089285]
	TIME [epoch: 8.33 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007459185570928911		[learning rate: 0.00017846]
	Learning Rate: 0.000178459
	LOSS [training: -0.0007459185570928911 | validation: 0.00034927523488677227]
	TIME [epoch: 8.37 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010098729775115446		[learning rate: 0.00017804]
	Learning Rate: 0.000178038
	LOSS [training: -0.0010098729775115446 | validation: 0.0002824966812284466]
	TIME [epoch: 8.34 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034481316051837173		[learning rate: 0.00017762]
	Learning Rate: 0.000177618
	LOSS [training: 0.00034481316051837173 | validation: -0.0004047524542050387]
	TIME [epoch: 8.33 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00036387979833988937		[learning rate: 0.0001772]
	Learning Rate: 0.000177199
	LOSS [training: -0.00036387979833988937 | validation: -0.0007539712425588556]
	TIME [epoch: 8.33 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005790415090225873		[learning rate: 0.00017678]
	Learning Rate: 0.000176781
	LOSS [training: -0.0005790415090225873 | validation: -0.0009737928675851882]
	TIME [epoch: 8.33 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005851935746321531		[learning rate: 0.00017636]
	Learning Rate: 0.000176364
	LOSS [training: -0.0005851935746321531 | validation: -0.000392473928386162]
	TIME [epoch: 8.37 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007592195407819074		[learning rate: 0.00017595]
	Learning Rate: 0.000175948
	LOSS [training: -0.0007592195407819074 | validation: -9.96865869247041e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008135071026241052		[learning rate: 0.00017553]
	Learning Rate: 0.000175533
	LOSS [training: -0.0008135071026241052 | validation: -0.0003566239082312448]
	TIME [epoch: 8.33 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002781085559624843		[learning rate: 0.00017512]
	Learning Rate: 0.000175119
	LOSS [training: 0.0002781085559624843 | validation: -0.0001308808624389495]
	TIME [epoch: 8.32 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002526882662263306		[learning rate: 0.00017471]
	Learning Rate: 0.000174706
	LOSS [training: -0.0002526882662263306 | validation: 0.0005044345297454682]
	TIME [epoch: 8.33 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005105916748120186		[learning rate: 0.00017429]
	Learning Rate: 0.000174294
	LOSS [training: -0.0005105916748120186 | validation: -0.0009211389272486407]
	TIME [epoch: 8.36 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008254528140606236		[learning rate: 0.00017388]
	Learning Rate: 0.000173883
	LOSS [training: -0.0008254528140606236 | validation: -0.0006714657327478198]
	TIME [epoch: 8.34 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005253931054481236		[learning rate: 0.00017347]
	Learning Rate: 0.000173473
	LOSS [training: -0.0005253931054481236 | validation: -0.00044342532588342377]
	TIME [epoch: 8.33 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005786724064043525		[learning rate: 0.00017306]
	Learning Rate: 0.000173063
	LOSS [training: -0.0005786724064043525 | validation: -0.00032444373751247557]
	TIME [epoch: 8.33 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005309469594305847		[learning rate: 0.00017266]
	Learning Rate: 0.000172655
	LOSS [training: -0.0005309469594305847 | validation: -0.00025922895446399874]
	TIME [epoch: 8.32 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005991110505135917		[learning rate: 0.00017225]
	Learning Rate: 0.000172248
	LOSS [training: -0.0005991110505135917 | validation: -0.0008903542944493174]
	TIME [epoch: 8.35 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037391425884774704		[learning rate: 0.00017184]
	Learning Rate: 0.000171842
	LOSS [training: -0.00037391425884774704 | validation: -0.0009467869518073848]
	TIME [epoch: 8.36 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007337149799625811		[learning rate: 0.00017144]
	Learning Rate: 0.000171436
	LOSS [training: -0.0007337149799625811 | validation: -0.00036412196211631546]
	TIME [epoch: 8.33 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041753416274372497		[learning rate: 0.00017103]
	Learning Rate: 0.000171032
	LOSS [training: -0.00041753416274372497 | validation: -0.00040440528525296897]
	TIME [epoch: 8.33 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047525191047037454		[learning rate: 0.00017063]
	Learning Rate: 0.000170628
	LOSS [training: -0.00047525191047037454 | validation: -6.357227030949497e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015187989100920137		[learning rate: 0.00017023]
	Learning Rate: 0.000170226
	LOSS [training: 0.0015187989100920137 | validation: 0.0013069192769194883]
	TIME [epoch: 8.34 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039341377147137724		[learning rate: 0.00016982]
	Learning Rate: 0.000169824
	LOSS [training: -0.00039341377147137724 | validation: -0.00023669724336511066]
	TIME [epoch: 8.38 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003589827218352446		[learning rate: 0.00016942]
	Learning Rate: 0.000169424
	LOSS [training: -0.0003589827218352446 | validation: -0.0008110714364819787]
	TIME [epoch: 8.33 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004672993975884443		[learning rate: 0.00016902]
	Learning Rate: 0.000169024
	LOSS [training: -0.0004672993975884443 | validation: -0.0010011725563395144]
	TIME [epoch: 8.33 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004952367315643996		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: -0.0004952367315643996 | validation: 0.0012350998907171805]
	TIME [epoch: 8.33 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009870765341195853		[learning rate: 0.00016823]
	Learning Rate: 0.000168228
	LOSS [training: -0.0009870765341195853 | validation: 0.000501488761665824]
	TIME [epoch: 8.34 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000720180596644626		[learning rate: 0.00016783]
	Learning Rate: 0.000167831
	LOSS [training: -0.000720180596644626 | validation: 0.0008574249921243925]
	TIME [epoch: 8.38 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017094922119345135		[learning rate: 0.00016743]
	Learning Rate: 0.000167435
	LOSS [training: 0.00017094922119345135 | validation: 0.00026474881680103526]
	TIME [epoch: 8.33 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001584638618603529		[learning rate: 0.00016704]
	Learning Rate: 0.00016704
	LOSS [training: 0.001584638618603529 | validation: -0.00046484995014133283]
	TIME [epoch: 8.33 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004892133685974153		[learning rate: 0.00016665]
	Learning Rate: 0.000166646
	LOSS [training: 0.0004892133685974153 | validation: -0.00086695074909108]
	TIME [epoch: 8.33 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001836750220625263		[learning rate: 0.00016625]
	Learning Rate: 0.000166253
	LOSS [training: -0.0001836750220625263 | validation: -0.0009743921172331285]
	TIME [epoch: 8.33 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: -6.605221126714601e-05		[learning rate: 0.00016586]
	Learning Rate: 0.000165861
	LOSS [training: -6.605221126714601e-05 | validation: -0.0011191353315547024]
	TIME [epoch: 8.37 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004444080764046778		[learning rate: 0.00016547]
	Learning Rate: 0.00016547
	LOSS [training: -0.0004444080764046778 | validation: -0.00015648270935205225]
	TIME [epoch: 8.32 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00047548526907587485		[learning rate: 0.00016508]
	Learning Rate: 0.000165079
	LOSS [training: -0.00047548526907587485 | validation: -0.0005477703041582642]
	TIME [epoch: 8.33 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006937876309615038		[learning rate: 0.00016469]
	Learning Rate: 0.00016469
	LOSS [training: -0.0006937876309615038 | validation: -0.0001758887702636498]
	TIME [epoch: 8.32 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00045561461586139293		[learning rate: 0.0001643]
	Learning Rate: 0.000164301
	LOSS [training: -0.00045561461586139293 | validation: -4.805361090756489e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003889001718689897		[learning rate: 0.00016391]
	Learning Rate: 0.000163914
	LOSS [training: -0.0003889001718689897 | validation: -0.000905043531174941]
	TIME [epoch: 8.38 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005877679288822022		[learning rate: 0.00016353]
	Learning Rate: 0.000163527
	LOSS [training: -0.0005877679288822022 | validation: -0.001046923327906042]
	TIME [epoch: 8.33 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004493965154046014		[learning rate: 0.00016314]
	Learning Rate: 0.000163141
	LOSS [training: -0.0004493965154046014 | validation: 0.00022891118929036037]
	TIME [epoch: 8.33 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00027954001722635825		[learning rate: 0.00016276]
	Learning Rate: 0.000162757
	LOSS [training: -0.00027954001722635825 | validation: -0.0009458717555020861]
	TIME [epoch: 8.33 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007439008769441708		[learning rate: 0.00016237]
	Learning Rate: 0.000162373
	LOSS [training: -0.0007439008769441708 | validation: 4.802753388677148e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.568407963411844e-05		[learning rate: 0.00016199]
	Learning Rate: 0.00016199
	LOSS [training: 4.568407963411844e-05 | validation: 0.0007337052828858601]
	TIME [epoch: 8.37 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005594567147901481		[learning rate: 0.00016161]
	Learning Rate: 0.000161608
	LOSS [training: 0.0005594567147901481 | validation: 0.00047109345589235475]
	TIME [epoch: 8.33 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003732003350475632		[learning rate: 0.00016123]
	Learning Rate: 0.000161226
	LOSS [training: -0.0003732003350475632 | validation: -0.0005307563212240716]
	TIME [epoch: 8.32 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004896009115561584		[learning rate: 0.00016085]
	Learning Rate: 0.000160846
	LOSS [training: -0.0004896009115561584 | validation: 9.3179436711543e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004250488175462641		[learning rate: 0.00016047]
	Learning Rate: 0.000160467
	LOSS [training: -0.0004250488175462641 | validation: 0.00022886075009185403]
	TIME [epoch: 8.33 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004020992781652686		[learning rate: 0.00016009]
	Learning Rate: 0.000160088
	LOSS [training: -0.0004020992781652686 | validation: -0.0001619284281410751]
	TIME [epoch: 8.37 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001626722870323549		[learning rate: 0.00015971]
	Learning Rate: 0.00015971
	LOSS [training: -0.0001626722870323549 | validation: 0.0004601985484982194]
	TIME [epoch: 8.64 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008404123517211112		[learning rate: 0.00015933]
	Learning Rate: 0.000159334
	LOSS [training: -0.0008404123517211112 | validation: -0.00014140287382795113]
	TIME [epoch: 8.33 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005151068065485848		[learning rate: 0.00015896]
	Learning Rate: 0.000158958
	LOSS [training: -0.0005151068065485848 | validation: -0.00019561231268507841]
	TIME [epoch: 8.33 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005134111966266681		[learning rate: 0.00015858]
	Learning Rate: 0.000158583
	LOSS [training: -0.0005134111966266681 | validation: -0.00022384803457546946]
	TIME [epoch: 8.33 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006300605056486294		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: -0.0006300605056486294 | validation: -7.812076520765786e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010548152794841276		[learning rate: 0.00015784]
	Learning Rate: 0.000157836
	LOSS [training: -0.0010548152794841276 | validation: -0.0008355642323719628]
	TIME [epoch: 8.37 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040240804240658723		[learning rate: 0.00015746]
	Learning Rate: 0.000157463
	LOSS [training: -0.00040240804240658723 | validation: -0.0006524955853515868]
	TIME [epoch: 8.34 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00029466265595040327		[learning rate: 0.00015709]
	Learning Rate: 0.000157092
	LOSS [training: -0.00029466265595040327 | validation: -0.0007977110129104421]
	TIME [epoch: 8.33 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007587207440367908		[learning rate: 0.00015672]
	Learning Rate: 0.000156721
	LOSS [training: -0.0007587207440367908 | validation: 0.00039885853682147853]
	TIME [epoch: 8.33 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007859426998086688		[learning rate: 0.00015635]
	Learning Rate: 0.000156352
	LOSS [training: -0.0007859426998086688 | validation: -0.0004357401008505342]
	TIME [epoch: 8.34 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006571170469976598		[learning rate: 0.00015598]
	Learning Rate: 0.000155983
	LOSS [training: -0.0006571170469976598 | validation: -0.0008752874993214048]
	TIME [epoch: 8.39 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.651311540469297e-06		[learning rate: 0.00015561]
	Learning Rate: 0.000155615
	LOSS [training: -7.651311540469297e-06 | validation: -0.0005835894932146087]
	TIME [epoch: 8.34 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006313914625819454		[learning rate: 0.00015525]
	Learning Rate: 0.000155248
	LOSS [training: -0.0006313914625819454 | validation: -0.0004973632255387304]
	TIME [epoch: 8.34 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006800660016669117		[learning rate: 0.00015488]
	Learning Rate: 0.000154882
	LOSS [training: -0.0006800660016669117 | validation: 1.4668169658261577e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005530699789970452		[learning rate: 0.00015452]
	Learning Rate: 0.000154516
	LOSS [training: -0.0005530699789970452 | validation: 5.673909452239956e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000676055926751485		[learning rate: 0.00015415]
	Learning Rate: 0.000154152
	LOSS [training: -0.000676055926751485 | validation: -0.00013542797298625063]
	TIME [epoch: 8.38 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000626197966690287		[learning rate: 0.00015379]
	Learning Rate: 0.000153788
	LOSS [training: -0.000626197966690287 | validation: -0.0008806676723158819]
	TIME [epoch: 8.34 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000606903939487996		[learning rate: 0.00015343]
	Learning Rate: 0.000153425
	LOSS [training: -0.000606903939487996 | validation: 6.910213574861545e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002558143227544636		[learning rate: 0.00015306]
	Learning Rate: 0.000153064
	LOSS [training: -0.0002558143227544636 | validation: -0.00016254742541928734]
	TIME [epoch: 8.34 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006174288099398806		[learning rate: 0.0001527]
	Learning Rate: 0.000152703
	LOSS [training: -0.0006174288099398806 | validation: -0.0006524218313943711]
	TIME [epoch: 8.34 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009332358936246819		[learning rate: 0.00015234]
	Learning Rate: 0.000152342
	LOSS [training: -0.0009332358936246819 | validation: -0.0008888293976585602]
	TIME [epoch: 8.39 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007907226523274468		[learning rate: 0.00015198]
	Learning Rate: 0.000151983
	LOSS [training: -0.0007907226523274468 | validation: -3.01823925109499e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006392729047531168		[learning rate: 0.00015162]
	Learning Rate: 0.000151624
	LOSS [training: -0.0006392729047531168 | validation: 0.0004243601491181646]
	TIME [epoch: 8.34 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000532712955853583		[learning rate: 0.00015127]
	Learning Rate: 0.000151267
	LOSS [training: -0.000532712955853583 | validation: -0.0009872842808877245]
	TIME [epoch: 8.34 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004963756561617783		[learning rate: 0.00015091]
	Learning Rate: 0.00015091
	LOSS [training: -0.0004963756561617783 | validation: 0.0004656420596341202]
	TIME [epoch: 8.34 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009861977658866304		[learning rate: 0.00015055]
	Learning Rate: 0.000150554
	LOSS [training: -0.0009861977658866304 | validation: -0.00018384755385598118]
	TIME [epoch: 8.39 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000424810737490789		[learning rate: 0.0001502]
	Learning Rate: 0.000150199
	LOSS [training: -0.000424810737490789 | validation: 8.476439665564239e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003932435562382348		[learning rate: 0.00014984]
	Learning Rate: 0.000149845
	LOSS [training: -0.0003932435562382348 | validation: -0.0015177589332223908]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20240520_124708/states/model_phi2_1a_v_mmd1_1829.pth
	Model improved!!!
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007097396999031281		[learning rate: 0.00014949]
	Learning Rate: 0.000149491
	LOSS [training: -0.0007097396999031281 | validation: 0.0005933946239819297]
	TIME [epoch: 8.34 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007170287754024085		[learning rate: 0.00014914]
	Learning Rate: 0.000149139
	LOSS [training: -0.0007170287754024085 | validation: 0.00011867604428938129]
	TIME [epoch: 8.33 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00037935359139622764		[learning rate: 0.00014879]
	Learning Rate: 0.000148787
	LOSS [training: -0.00037935359139622764 | validation: 0.00035722621999038885]
	TIME [epoch: 8.38 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006101395761266273		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: -0.0006101395761266273 | validation: -0.0004507985670187993]
	TIME [epoch: 8.34 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007722712511079629		[learning rate: 0.00014809]
	Learning Rate: 0.000148086
	LOSS [training: -0.0007722712511079629 | validation: -0.00013034296247189215]
	TIME [epoch: 8.34 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000771525263107465		[learning rate: 0.00014774]
	Learning Rate: 0.000147736
	LOSS [training: -0.000771525263107465 | validation: -0.0002462234581280453]
	TIME [epoch: 8.34 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.265351318107255e-05		[learning rate: 0.00014739]
	Learning Rate: 0.000147388
	LOSS [training: 1.265351318107255e-05 | validation: 6.184271336491065e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007870311656021881		[learning rate: 0.00014704]
	Learning Rate: 0.00014704
	LOSS [training: -0.0007870311656021881 | validation: -0.0007130291923528937]
	TIME [epoch: 8.38 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00035870190528866685		[learning rate: 0.00014669]
	Learning Rate: 0.000146693
	LOSS [training: -0.00035870190528866685 | validation: -0.00030975495126345676]
	TIME [epoch: 8.34 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006033263919011672		[learning rate: 0.00014635]
	Learning Rate: 0.000146347
	LOSS [training: -0.0006033263919011672 | validation: -0.0004273683859409632]
	TIME [epoch: 8.33 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00019575355090290558		[learning rate: 0.000146]
	Learning Rate: 0.000146002
	LOSS [training: -0.00019575355090290558 | validation: -0.0012008787083695582]
	TIME [epoch: 8.34 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005114832958973054		[learning rate: 0.00014566]
	Learning Rate: 0.000145658
	LOSS [training: -0.0005114832958973054 | validation: -0.00037564718677823893]
	TIME [epoch: 8.34 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046369412830349766		[learning rate: 0.00014531]
	Learning Rate: 0.000145314
	LOSS [training: -0.00046369412830349766 | validation: -0.0006669856985913176]
	TIME [epoch: 8.38 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005755318888646544		[learning rate: 0.00014497]
	Learning Rate: 0.000144971
	LOSS [training: -0.0005755318888646544 | validation: 1.9518739028745262e-06]
	TIME [epoch: 8.35 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006785170939961969		[learning rate: 0.00014463]
	Learning Rate: 0.000144629
	LOSS [training: -0.0006785170939961969 | validation: -0.0006925751511554227]
	TIME [epoch: 8.33 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006148646728730682		[learning rate: 0.00014429]
	Learning Rate: 0.000144288
	LOSS [training: -0.0006148646728730682 | validation: -0.0007604286634738657]
	TIME [epoch: 8.33 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007704905692012694		[learning rate: 0.00014395]
	Learning Rate: 0.000143948
	LOSS [training: -0.0007704905692012694 | validation: -0.0012933634474004885]
	TIME [epoch: 8.34 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004374462730254971		[learning rate: 0.00014361]
	Learning Rate: 0.000143608
	LOSS [training: -0.0004374462730254971 | validation: -0.0005845455448405401]
	TIME [epoch: 8.37 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00023881022489583283		[learning rate: 0.00014327]
	Learning Rate: 0.00014327
	LOSS [training: -0.00023881022489583283 | validation: -0.0003657854119969271]
	TIME [epoch: 8.35 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003410983553568434		[learning rate: 0.00014293]
	Learning Rate: 0.000142932
	LOSS [training: -0.0003410983553568434 | validation: -0.00046406448921867765]
	TIME [epoch: 8.33 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004313719835517947		[learning rate: 0.00014259]
	Learning Rate: 0.000142594
	LOSS [training: -0.0004313719835517947 | validation: 6.399629974982002e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003222464151641202		[learning rate: 0.00014226]
	Learning Rate: 0.000142258
	LOSS [training: -0.0003222464151641202 | validation: -0.00016898822795963485]
	TIME [epoch: 8.34 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000613384129835875		[learning rate: 0.00014192]
	Learning Rate: 0.000141923
	LOSS [training: -0.000613384129835875 | validation: 2.1990487514876638e-05]
	TIME [epoch: 8.36 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00024057409393424622		[learning rate: 0.00014159]
	Learning Rate: 0.000141588
	LOSS [training: -0.00024057409393424622 | validation: -2.338903826565497e-05]
	TIME [epoch: 8.37 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003653238192058212		[learning rate: 0.00014125]
	Learning Rate: 0.000141254
	LOSS [training: -0.0003653238192058212 | validation: 0.00014689416499363928]
	TIME [epoch: 8.33 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00046735505313604605		[learning rate: 0.00014092]
	Learning Rate: 0.000140921
	LOSS [training: -0.00046735505313604605 | validation: -0.000781155019647974]
	TIME [epoch: 8.34 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009289635119843954		[learning rate: 0.00014059]
	Learning Rate: 0.000140588
	LOSS [training: -0.0009289635119843954 | validation: 0.00019794153429692862]
	TIME [epoch: 8.34 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007623721288056351		[learning rate: 0.00014026]
	Learning Rate: 0.000140257
	LOSS [training: -0.0007623721288056351 | validation: 3.749754443401225e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007502943703237669		[learning rate: 0.00013993]
	Learning Rate: 0.000139926
	LOSS [training: -0.0007502943703237669 | validation: -0.00020278998875539235]
	TIME [epoch: 8.37 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009372839210433574		[learning rate: 0.0001396]
	Learning Rate: 0.000139596
	LOSS [training: 0.0009372839210433574 | validation: 0.00042945681868923467]
	TIME [epoch: 8.33 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037982462208653643		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.00037982462208653643 | validation: -0.00012439242007018648]
	TIME [epoch: 8.33 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000469543273892467		[learning rate: 0.00013894]
	Learning Rate: 0.000138938
	LOSS [training: -0.000469543273892467 | validation: 0.0001738101825360765]
	TIME [epoch: 8.33 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006646206515270479		[learning rate: 0.00013861]
	Learning Rate: 0.00013861
	LOSS [training: -0.0006646206515270479 | validation: -0.00027784910333845936]
	TIME [epoch: 8.34 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005939206461944515		[learning rate: 0.00013828]
	Learning Rate: 0.000138283
	LOSS [training: -0.0005939206461944515 | validation: -0.0004248825291269274]
	TIME [epoch: 8.38 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004230197295490434		[learning rate: 0.00013796]
	Learning Rate: 0.000137957
	LOSS [training: -0.0004230197295490434 | validation: -0.0005802044764415095]
	TIME [epoch: 8.34 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006925421171842714		[learning rate: 0.00013763]
	Learning Rate: 0.000137632
	LOSS [training: -0.0006925421171842714 | validation: -0.00037844103475684186]
	TIME [epoch: 8.33 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006961596215995947		[learning rate: 0.00013731]
	Learning Rate: 0.000137307
	LOSS [training: -0.0006961596215995947 | validation: -0.000606860281286294]
	TIME [epoch: 8.33 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008353705127657556		[learning rate: 0.00013698]
	Learning Rate: 0.000136983
	LOSS [training: -0.0008353705127657556 | validation: -0.0009909874979707296]
	TIME [epoch: 8.34 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010195700416359126		[learning rate: 0.00013666]
	Learning Rate: 0.00013666
	LOSS [training: -0.0010195700416359126 | validation: -0.0006662430974384148]
	TIME [epoch: 8.38 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007578785116124595		[learning rate: 0.00013634]
	Learning Rate: 0.000136338
	LOSS [training: -0.0007578785116124595 | validation: -0.0011177690165744174]
	TIME [epoch: 8.34 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008707459338376804		[learning rate: 0.00013602]
	Learning Rate: 0.000136016
	LOSS [training: -0.0008707459338376804 | validation: 0.00031559860433933644]
	TIME [epoch: 8.33 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005480920373111959		[learning rate: 0.0001357]
	Learning Rate: 0.000135695
	LOSS [training: -0.0005480920373111959 | validation: -0.00014541903279569903]
	TIME [epoch: 8.33 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008350858431089528		[learning rate: 0.00013538]
	Learning Rate: 0.000135375
	LOSS [training: -0.0008350858431089528 | validation: -0.00034098971213574684]
	TIME [epoch: 8.34 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007524724728289888		[learning rate: 0.00013506]
	Learning Rate: 0.000135056
	LOSS [training: -0.0007524724728289888 | validation: -0.0004728784095901335]
	TIME [epoch: 8.38 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007922323988769844		[learning rate: 0.00013474]
	Learning Rate: 0.000134737
	LOSS [training: -0.0007922323988769844 | validation: -0.0004633045287128943]
	TIME [epoch: 8.33 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005487667908124188		[learning rate: 0.00013442]
	Learning Rate: 0.000134419
	LOSS [training: -0.0005487667908124188 | validation: 0.00010012979610073104]
	TIME [epoch: 8.34 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005518745264466536		[learning rate: 0.0001341]
	Learning Rate: 0.000134102
	LOSS [training: -0.0005518745264466536 | validation: -0.00015837205974606275]
	TIME [epoch: 8.33 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: -4.7011841656422875e-05		[learning rate: 0.00013379]
	Learning Rate: 0.000133786
	LOSS [training: -4.7011841656422875e-05 | validation: -0.00023488051859864978]
	TIME [epoch: 8.33 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: -5.0069915267337395e-05		[learning rate: 0.00013347]
	Learning Rate: 0.00013347
	LOSS [training: -5.0069915267337395e-05 | validation: -0.00020451486943722186]
	TIME [epoch: 8.39 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00034860758700193514		[learning rate: 0.00013316]
	Learning Rate: 0.000133155
	LOSS [training: -0.00034860758700193514 | validation: -0.0009174251330583854]
	TIME [epoch: 8.33 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007585594279770583		[learning rate: 0.00013284]
	Learning Rate: 0.000132841
	LOSS [training: -0.0007585594279770583 | validation: -0.00012593346164138896]
	TIME [epoch: 8.33 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000687017078820863		[learning rate: 0.00013253]
	Learning Rate: 0.000132528
	LOSS [training: -0.000687017078820863 | validation: -0.0003582903194141625]
	TIME [epoch: 8.33 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005935430423986097		[learning rate: 0.00013222]
	Learning Rate: 0.000132215
	LOSS [training: -0.0005935430423986097 | validation: 0.0009822398133958942]
	TIME [epoch: 8.32 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006974401295290872		[learning rate: 0.0001319]
	Learning Rate: 0.000131904
	LOSS [training: -0.0006974401295290872 | validation: -7.995196498499002e-05]
	TIME [epoch: 8.38 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039123341493157266		[learning rate: 0.00013159]
	Learning Rate: 0.000131592
	LOSS [training: -0.00039123341493157266 | validation: -1.6598106350699917e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007251203932560475		[learning rate: 0.00013128]
	Learning Rate: 0.000131282
	LOSS [training: -0.0007251203932560475 | validation: -0.0005089006908697473]
	TIME [epoch: 8.33 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008223026700624248		[learning rate: 0.00013097]
	Learning Rate: 0.000130972
	LOSS [training: -0.0008223026700624248 | validation: -0.0005679972812480694]
	TIME [epoch: 8.33 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005431334577552109		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: -0.0005431334577552109 | validation: -0.0002931225958355514]
	TIME [epoch: 8.32 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005268327580328334		[learning rate: 0.00013036]
	Learning Rate: 0.000130355
	LOSS [training: -0.0005268327580328334 | validation: -0.00038485742020635924]
	TIME [epoch: 8.37 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008614204316704694		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: -0.0008614204316704694 | validation: -3.933160101720956e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006136682120994681		[learning rate: 0.00012974]
	Learning Rate: 0.000129741
	LOSS [training: -0.0006136682120994681 | validation: 0.0005686205356115801]
	TIME [epoch: 8.33 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010303920648603616		[learning rate: 0.00012943]
	Learning Rate: 0.000129435
	LOSS [training: -0.0010303920648603616 | validation: -0.00016102120545612533]
	TIME [epoch: 8.33 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007473388293312786		[learning rate: 0.00012913]
	Learning Rate: 0.00012913
	LOSS [training: -0.0007473388293312786 | validation: 0.00010520723150924738]
	TIME [epoch: 8.33 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008960500954838386		[learning rate: 0.00012882]
	Learning Rate: 0.000128825
	LOSS [training: -0.0008960500954838386 | validation: -0.000876628933450946]
	TIME [epoch: 8.37 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006045706785285454		[learning rate: 0.00012852]
	Learning Rate: 0.000128521
	LOSS [training: -0.0006045706785285454 | validation: -6.603882329430898e-05]
	TIME [epoch: 8.34 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004944321372773089		[learning rate: 0.00012822]
	Learning Rate: 0.000128218
	LOSS [training: -0.0004944321372773089 | validation: 7.367259721048081e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006624767392554157		[learning rate: 0.00012792]
	Learning Rate: 0.000127915
	LOSS [training: -0.0006624767392554157 | validation: -0.0006663978101517513]
	TIME [epoch: 8.32 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006485219280386552		[learning rate: 0.00012761]
	Learning Rate: 0.000127614
	LOSS [training: -0.0006485219280386552 | validation: -0.00048035142226709484]
	TIME [epoch: 8.32 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009083253697594416		[learning rate: 0.00012731]
	Learning Rate: 0.000127313
	LOSS [training: -0.0009083253697594416 | validation: -0.0009463453389609638]
	TIME [epoch: 8.35 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000674335839682714		[learning rate: 0.00012701]
	Learning Rate: 0.000127012
	LOSS [training: -0.000674335839682714 | validation: -0.0005850782456729857]
	TIME [epoch: 8.35 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008357970414965151		[learning rate: 0.00012671]
	Learning Rate: 0.000126713
	LOSS [training: -0.0008357970414965151 | validation: 0.0003255870072576914]
	TIME [epoch: 8.32 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009059091666907054		[learning rate: 0.00012641]
	Learning Rate: 0.000126414
	LOSS [training: -0.0009059091666907054 | validation: -0.0005426987110520241]
	TIME [epoch: 8.33 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0011217719198601895		[learning rate: 0.00012612]
	Learning Rate: 0.000126116
	LOSS [training: -0.0011217719198601895 | validation: -0.00020962519096430208]
	TIME [epoch: 8.32 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007651377822493617		[learning rate: 0.00012582]
	Learning Rate: 0.000125818
	LOSS [training: -0.0007651377822493617 | validation: -0.0005837227209782054]
	TIME [epoch: 8.35 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006570290984279563		[learning rate: 0.00012552]
	Learning Rate: 0.000125521
	LOSS [training: -0.0006570290984279563 | validation: -0.00022984551943328404]
	TIME [epoch: 8.35 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007118776749911058		[learning rate: 0.00012523]
	Learning Rate: 0.000125225
	LOSS [training: -0.0007118776749911058 | validation: -0.0001388752987618851]
	TIME [epoch: 8.33 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005958196033463039		[learning rate: 0.00012493]
	Learning Rate: 0.00012493
	LOSS [training: -0.0005958196033463039 | validation: -0.0007655062262119979]
	TIME [epoch: 8.33 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000458233794885611		[learning rate: 0.00012464]
	Learning Rate: 0.000124635
	LOSS [training: -0.000458233794885611 | validation: -0.0006502638902324742]
	TIME [epoch: 8.33 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006334735205788598		[learning rate: 0.00012434]
	Learning Rate: 0.000124341
	LOSS [training: -0.0006334735205788598 | validation: 6.601487284520546e-05]
	TIME [epoch: 8.35 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039035533268012124		[learning rate: 0.00012405]
	Learning Rate: 0.000124048
	LOSS [training: -0.00039035533268012124 | validation: -0.0012630980082079198]
	TIME [epoch: 8.37 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0012019055771684967		[learning rate: 0.00012376]
	Learning Rate: 0.000123755
	LOSS [training: -0.0012019055771684967 | validation: -0.0006625221098490708]
	TIME [epoch: 8.32 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006136939413281939		[learning rate: 0.00012346]
	Learning Rate: 0.000123463
	LOSS [training: -0.0006136939413281939 | validation: -0.00022101625880576934]
	TIME [epoch: 8.32 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000756202882070623		[learning rate: 0.00012317]
	Learning Rate: 0.000123172
	LOSS [training: -0.000756202882070623 | validation: -0.00021933461984154334]
	TIME [epoch: 8.31 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001701095419455079		[learning rate: 0.00012288]
	Learning Rate: 0.000122882
	LOSS [training: -0.0001701095419455079 | validation: 0.0004091640254640354]
	TIME [epoch: 8.33 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00041328450121604776		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: -0.00041328450121604776 | validation: 6.056613909482201e-05]
	TIME [epoch: 8.38 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.001176435020344052		[learning rate: 0.0001223]
	Learning Rate: 0.000122303
	LOSS [training: -0.001176435020344052 | validation: -0.0007174389678584073]
	TIME [epoch: 8.33 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007342958921171931		[learning rate: 0.00012201]
	Learning Rate: 0.000122014
	LOSS [training: -0.0007342958921171931 | validation: 0.0001455422283874426]
	TIME [epoch: 8.32 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006111315912598787		[learning rate: 0.00012173]
	Learning Rate: 0.000121726
	LOSS [training: -0.0006111315912598787 | validation: -0.00032897307795588175]
	TIME [epoch: 8.32 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008823889247397567		[learning rate: 0.00012144]
	Learning Rate: 0.000121439
	LOSS [training: -0.0008823889247397567 | validation: -0.0008037096667091679]
	TIME [epoch: 8.32 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000499400344154678		[learning rate: 0.00012115]
	Learning Rate: 0.000121153
	LOSS [training: -0.000499400344154678 | validation: 0.0004337047147995384]
	TIME [epoch: 8.37 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008229347067197378		[learning rate: 0.00012087]
	Learning Rate: 0.000120867
	LOSS [training: -0.0008229347067197378 | validation: -0.0004633040983590018]
	TIME [epoch: 8.33 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000700342124448867		[learning rate: 0.00012058]
	Learning Rate: 0.000120582
	LOSS [training: -0.000700342124448867 | validation: -0.00044977046697133497]
	TIME [epoch: 8.32 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006001684412868715		[learning rate: 0.0001203]
	Learning Rate: 0.000120297
	LOSS [training: -0.0006001684412868715 | validation: 6.87954732929761e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006158593605019578		[learning rate: 0.00012001]
	Learning Rate: 0.000120014
	LOSS [training: -0.0006158593605019578 | validation: -0.0003483859398516902]
	TIME [epoch: 8.33 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006185542064400143		[learning rate: 0.00011973]
	Learning Rate: 0.000119731
	LOSS [training: -0.0006185542064400143 | validation: -0.0007308484385236853]
	TIME [epoch: 8.37 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000802097813974449		[learning rate: 0.00011945]
	Learning Rate: 0.000119448
	LOSS [training: -0.000802097813974449 | validation: 2.507777849617421e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021920156521741752		[learning rate: 0.00011917]
	Learning Rate: 0.000119166
	LOSS [training: -0.00021920156521741752 | validation: -0.00029885889056061114]
	TIME [epoch: 8.33 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004123326609426979		[learning rate: 0.00011889]
	Learning Rate: 0.000118885
	LOSS [training: -0.0004123326609426979 | validation: -0.00012248233007854288]
	TIME [epoch: 8.33 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005809302783342764		[learning rate: 0.0001186]
	Learning Rate: 0.000118605
	LOSS [training: -0.0005809302783342764 | validation: -0.0006451151797589221]
	TIME [epoch: 8.33 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000689974343494902		[learning rate: 0.00011833]
	Learning Rate: 0.000118325
	LOSS [training: -0.000689974343494902 | validation: -0.0006903853808762168]
	TIME [epoch: 8.38 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005467906837536965		[learning rate: 0.00011805]
	Learning Rate: 0.000118046
	LOSS [training: -0.0005467906837536965 | validation: -0.00030429324820801677]
	TIME [epoch: 8.33 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009010403692893611		[learning rate: 0.00011777]
	Learning Rate: 0.000117768
	LOSS [training: -0.0009010403692893611 | validation: -0.0006251641389280164]
	TIME [epoch: 8.33 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007664446038878377		[learning rate: 0.00011749]
	Learning Rate: 0.00011749
	LOSS [training: -0.0007664446038878377 | validation: 0.0003193844306072697]
	TIME [epoch: 8.33 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006961534737381448		[learning rate: 0.00011721]
	Learning Rate: 0.000117213
	LOSS [training: -0.0006961534737381448 | validation: -0.00038561296320641385]
	TIME [epoch: 8.33 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0001243838836129383		[learning rate: 0.00011694]
	Learning Rate: 0.000116936
	LOSS [training: -0.0001243838836129383 | validation: -0.0004450777049130812]
	TIME [epoch: 8.37 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007006988793664058		[learning rate: 0.00011666]
	Learning Rate: 0.00011666
	LOSS [training: -0.0007006988793664058 | validation: -0.0006622986921152827]
	TIME [epoch: 8.33 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000412742966109152		[learning rate: 0.00011639]
	Learning Rate: 0.000116385
	LOSS [training: -0.000412742966109152 | validation: -0.0007208047130879591]
	TIME [epoch: 8.33 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000795959607700282		[learning rate: 0.00011611]
	Learning Rate: 0.000116111
	LOSS [training: -0.000795959607700282 | validation: -0.0004120157756641763]
	TIME [epoch: 8.33 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009862512800088712		[learning rate: 0.00011584]
	Learning Rate: 0.000115837
	LOSS [training: -0.0009862512800088712 | validation: -0.0003316268948164063]
	TIME [epoch: 8.33 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008845891865601889		[learning rate: 0.00011556]
	Learning Rate: 0.000115563
	LOSS [training: -0.0008845891865601889 | validation: -0.0002291290760147726]
	TIME [epoch: 8.37 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007254290958611865		[learning rate: 0.00011529]
	Learning Rate: 0.000115291
	LOSS [training: -0.0007254290958611865 | validation: -0.00040741233073518404]
	TIME [epoch: 8.34 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005182398357835889		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: -0.0005182398357835889 | validation: 0.00014999037275477889]
	TIME [epoch: 8.32 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008563231034482107		[learning rate: 0.00011475]
	Learning Rate: 0.000114748
	LOSS [training: -0.0008563231034482107 | validation: 0.0002545082986121469]
	TIME [epoch: 8.33 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004096971189161134		[learning rate: 0.00011448]
	Learning Rate: 0.000114477
	LOSS [training: -0.0004096971189161134 | validation: -0.00012029607794025444]
	TIME [epoch: 8.33 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007293654409814246		[learning rate: 0.00011421]
	Learning Rate: 0.000114207
	LOSS [training: -0.0007293654409814246 | validation: -0.00029210630116047523]
	TIME [epoch: 8.37 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000938194535415938		[learning rate: 0.00011394]
	Learning Rate: 0.000113938
	LOSS [training: -0.000938194535415938 | validation: -0.00016470433256531125]
	TIME [epoch: 8.34 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002303855532329806		[learning rate: 0.00011367]
	Learning Rate: 0.000113669
	LOSS [training: -0.0002303855532329806 | validation: -0.00026889984670114763]
	TIME [epoch: 8.33 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003900963694820769		[learning rate: 0.0001134]
	Learning Rate: 0.000113401
	LOSS [training: -0.0003900963694820769 | validation: 0.00041948057133435723]
	TIME [epoch: 8.33 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008254924563332428		[learning rate: 0.00011313]
	Learning Rate: 0.000113133
	LOSS [training: -0.0008254924563332428 | validation: -0.0008952153101164759]
	TIME [epoch: 8.33 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007666317147591413		[learning rate: 0.00011287]
	Learning Rate: 0.000112866
	LOSS [training: -0.0007666317147591413 | validation: -0.0003164090628672573]
	TIME [epoch: 8.35 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008901889086352173		[learning rate: 0.0001126]
	Learning Rate: 0.0001126
	LOSS [training: -0.0008901889086352173 | validation: -0.0005763281218636834]
	TIME [epoch: 8.36 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004357873824222598		[learning rate: 0.00011233]
	Learning Rate: 0.000112334
	LOSS [training: -0.0004357873824222598 | validation: 0.00010983157736924111]
	TIME [epoch: 8.33 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007219581519819006		[learning rate: 0.00011207]
	Learning Rate: 0.000112069
	LOSS [training: -0.0007219581519819006 | validation: -0.0011847113979083193]
	TIME [epoch: 8.32 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005356062425012304		[learning rate: 0.00011181]
	Learning Rate: 0.000111805
	LOSS [training: -0.0005356062425012304 | validation: 0.0001412325262471703]
	TIME [epoch: 8.32 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005180385615950683		[learning rate: 0.00011154]
	Learning Rate: 0.000111541
	LOSS [training: -0.0005180385615950683 | validation: 0.00023341615203779665]
	TIME [epoch: 8.34 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006271974508942016		[learning rate: 0.00011128]
	Learning Rate: 0.000111278
	LOSS [training: -0.0006271974508942016 | validation: -0.0008224453425805675]
	TIME [epoch: 8.37 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006347978152331186		[learning rate: 0.00011102]
	Learning Rate: 0.000111016
	LOSS [training: -0.0006347978152331186 | validation: 0.00030485735013896823]
	TIME [epoch: 8.32 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005213672239940977		[learning rate: 0.00011075]
	Learning Rate: 0.000110754
	LOSS [training: -0.0005213672239940977 | validation: -8.817229418246785e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006393541919690348		[learning rate: 0.00011049]
	Learning Rate: 0.000110493
	LOSS [training: -0.0006393541919690348 | validation: -6.227357417883447e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0003506175296677978		[learning rate: 0.00011023]
	Learning Rate: 0.000110232
	LOSS [training: -0.0003506175296677978 | validation: -0.00017285276940510433]
	TIME [epoch: 8.34 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010493926901727797		[learning rate: 0.00010997]
	Learning Rate: 0.000109972
	LOSS [training: -0.0010493926901727797 | validation: -0.000569150217977624]
	TIME [epoch: 8.37 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008113961416148654		[learning rate: 0.00010971]
	Learning Rate: 0.000109713
	LOSS [training: -0.0008113961416148654 | validation: -0.0005063364045548293]
	TIME [epoch: 8.34 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008431963577350525		[learning rate: 0.00010945]
	Learning Rate: 0.000109454
	LOSS [training: -0.0008431963577350525 | validation: -0.00030807645755993814]
	TIME [epoch: 8.33 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006493122555172963		[learning rate: 0.0001092]
	Learning Rate: 0.000109196
	LOSS [training: -0.0006493122555172963 | validation: -5.209417568905162e-05]
	TIME [epoch: 8.32 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: -8.26848054548657e-05		[learning rate: 0.00010894]
	Learning Rate: 0.000108938
	LOSS [training: -8.26848054548657e-05 | validation: -0.0008330633513192866]
	TIME [epoch: 8.34 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016534870638999495		[learning rate: 0.00010868]
	Learning Rate: 0.000108681
	LOSS [training: 0.00016534870638999495 | validation: -0.00021861545692234197]
	TIME [epoch: 8.37 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000792622678739805		[learning rate: 0.00010842]
	Learning Rate: 0.000108425
	LOSS [training: -0.000792622678739805 | validation: -0.0008455467555360125]
	TIME [epoch: 8.32 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005572519956922499		[learning rate: 0.00010817]
	Learning Rate: 0.000108169
	LOSS [training: -0.0005572519956922499 | validation: -0.0008101197445045604]
	TIME [epoch: 8.32 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000901091999146108		[learning rate: 0.00010791]
	Learning Rate: 0.000107914
	LOSS [training: -0.000901091999146108 | validation: -0.000152611024021573]
	TIME [epoch: 8.33 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005521054823078375		[learning rate: 0.00010766]
	Learning Rate: 0.000107659
	LOSS [training: -0.0005521054823078375 | validation: -0.0001963844001438262]
	TIME [epoch: 8.33 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004948474880873914		[learning rate: 0.00010741]
	Learning Rate: 0.000107405
	LOSS [training: -0.0004948474880873914 | validation: 0.0005204629506198213]
	TIME [epoch: 8.37 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00014801618448462257		[learning rate: 0.00010715]
	Learning Rate: 0.000107152
	LOSS [training: -0.00014801618448462257 | validation: 0.0009142452093103372]
	TIME [epoch: 8.33 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00039415741327852947		[learning rate: 0.0001069]
	Learning Rate: 0.000106899
	LOSS [training: -0.00039415741327852947 | validation: -0.0003466853277937325]
	TIME [epoch: 8.33 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004828813317873124		[learning rate: 0.00010665]
	Learning Rate: 0.000106647
	LOSS [training: -0.0004828813317873124 | validation: -0.00033727137842073246]
	TIME [epoch: 8.33 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010321731006208324		[learning rate: 0.0001064]
	Learning Rate: 0.000106395
	LOSS [training: -0.0010321731006208324 | validation: -0.0007163806340710379]
	TIME [epoch: 8.32 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00040150783619600117		[learning rate: 0.00010614]
	Learning Rate: 0.000106145
	LOSS [training: -0.00040150783619600117 | validation: -0.0007056758422637631]
	TIME [epoch: 8.38 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004346141067165312		[learning rate: 0.00010589]
	Learning Rate: 0.000105894
	LOSS [training: -0.0004346141067165312 | validation: -7.447965470915819e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008271334533072709		[learning rate: 0.00010564]
	Learning Rate: 0.000105644
	LOSS [training: -0.0008271334533072709 | validation: -0.00028648860612306005]
	TIME [epoch: 8.33 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006579836241518384		[learning rate: 0.0001054]
	Learning Rate: 0.000105395
	LOSS [training: -0.0006579836241518384 | validation: -0.0008725796365544856]
	TIME [epoch: 8.33 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028821057416429977		[learning rate: 0.00010515]
	Learning Rate: 0.000105147
	LOSS [training: -0.00028821057416429977 | validation: 6.0455765023764935e-05]
	TIME [epoch: 8.33 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005793823337309241		[learning rate: 0.0001049]
	Learning Rate: 0.000104899
	LOSS [training: -0.0005793823337309241 | validation: -0.0006179626212799141]
	TIME [epoch: 8.44 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007182116257553648		[learning rate: 0.00010465]
	Learning Rate: 0.000104651
	LOSS [training: -0.0007182116257553648 | validation: -0.0005053031738365603]
	TIME [epoch: 8.34 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009032561335372282		[learning rate: 0.0001044]
	Learning Rate: 0.000104404
	LOSS [training: -0.0009032561335372282 | validation: -0.0009187491679639947]
	TIME [epoch: 8.33 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.000546510897399355		[learning rate: 0.00010416]
	Learning Rate: 0.000104158
	LOSS [training: -0.000546510897399355 | validation: 4.9924142340094245e-06]
	TIME [epoch: 8.33 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0010143307599211693		[learning rate: 0.00010391]
	Learning Rate: 0.000103912
	LOSS [training: -0.0010143307599211693 | validation: 0.00013603447648774568]
	TIME [epoch: 8.33 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00043403056438739876		[learning rate: 0.00010367]
	Learning Rate: 0.000103667
	LOSS [training: -0.00043403056438739876 | validation: -0.0002452240160314303]
	TIME [epoch: 8.37 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008920005868027637		[learning rate: 0.00010342]
	Learning Rate: 0.000103423
	LOSS [training: -0.0008920005868027637 | validation: -0.0010214169567157097]
	TIME [epoch: 8.34 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005113688734646434		[learning rate: 0.00010318]
	Learning Rate: 0.000103179
	LOSS [training: -0.0005113688734646434 | validation: 0.0003403361747360001]
	TIME [epoch: 8.33 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007384058249513728		[learning rate: 0.00010294]
	Learning Rate: 0.000102935
	LOSS [training: -0.0007384058249513728 | validation: -0.0004317650316685496]
	TIME [epoch: 8.33 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: -7.857248533731041e-05		[learning rate: 0.00010269]
	Learning Rate: 0.000102692
	LOSS [training: -7.857248533731041e-05 | validation: -0.00042424767067158564]
	TIME [epoch: 8.33 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002999419906504208		[learning rate: 0.00010245]
	Learning Rate: 0.00010245
	LOSS [training: -0.0002999419906504208 | validation: -0.0007213611004347538]
	TIME [epoch: 8.37 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006375319778047461		[learning rate: 0.00010221]
	Learning Rate: 0.000102209
	LOSS [training: -0.0006375319778047461 | validation: -0.0006636798328528358]
	TIME [epoch: 8.34 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0004497115632736804		[learning rate: 0.00010197]
	Learning Rate: 0.000101967
	LOSS [training: -0.0004497115632736804 | validation: -0.0009319535722218118]
	TIME [epoch: 8.33 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0008204698470717905		[learning rate: 0.00010173]
	Learning Rate: 0.000101727
	LOSS [training: -0.0008204698470717905 | validation: -0.0005359629771305477]
	TIME [epoch: 8.33 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0006697074148186314		[learning rate: 0.00010149]
	Learning Rate: 0.000101487
	LOSS [training: -0.0006697074148186314 | validation: -0.00032588784132013516]
	TIME [epoch: 8.33 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009441435662977914		[learning rate: 0.00010125]
	Learning Rate: 0.000101248
	LOSS [training: -0.0009441435662977914 | validation: -0.00017449027143010684]
	TIME [epoch: 8.35 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0009626975427799217		[learning rate: 0.00010101]
	Learning Rate: 0.000101009
	LOSS [training: -0.0009626975427799217 | validation: -0.0010696833864457065]
	TIME [epoch: 8.36 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007499788302559776		[learning rate: 0.00010077]
	Learning Rate: 0.000100771
	LOSS [training: -0.0007499788302559776 | validation: -0.0008780085063467466]
	TIME [epoch: 8.32 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0007467171041829971		[learning rate: 0.00010053]
	Learning Rate: 0.000100533
	LOSS [training: -0.0007467171041829971 | validation: -0.0003856556395374042]
	TIME [epoch: 8.33 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005915374051725978		[learning rate: 0.0001003]
	Learning Rate: 0.000100296
	LOSS [training: -0.0005915374051725978 | validation: -0.000553927036680081]
	TIME [epoch: 8.32 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0005530244604991042		[learning rate: 0.00010006]
	Learning Rate: 0.000100059
	LOSS [training: -0.0005530244604991042 | validation: 0.000484497005827675]
	TIME [epoch: 8.34 sec]
Finished training in 17428.557 seconds.
